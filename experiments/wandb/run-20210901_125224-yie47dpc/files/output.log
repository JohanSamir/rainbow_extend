Loaded trained dqn in cartpole
Training fixed agent 1, please be patient, may be a while...
I0901 12:52:30.762359 140321497724928 run_experiment.py:549] Creating TrainRunner ...
I0901 12:52:30.770670 140321497724928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:52:30.770959 140321497724928 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:52:30.771183 140321497724928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:52:30.771370 140321497724928 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:52:30.771490 140321497724928 dqn_agent.py:275] 	 update_period: 4
I0901 12:52:30.771587 140321497724928 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:52:30.771693 140321497724928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:52:30.771826 140321497724928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:52:30.771979 140321497724928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:52:30.772064 140321497724928 dqn_agent.py:280] 	 optimizer: adam
I0901 12:52:30.772209 140321497724928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:52:30.772312 140321497724928 dqn_agent.py:283] 	 seed: 1630500750770608
I0901 12:52:30.775774 140321497724928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:52:30.775978 140321497724928 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:52:30.776112 140321497724928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:52:30.776217 140321497724928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:52:30.776525 140321497724928 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:52:30.776681 140321497724928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:52:30.776839 140321497724928 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:52:30.776992 140321497724928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:52:30.777184 140321497724928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:52:30.818856 140321497724928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:52:31.720517 140321497724928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:52:31.737647 140321497724928 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:52:31.747049 140321497724928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:52:31.747331 140321497724928 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:52:31.747487 140321497724928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:52:31.747614 140321497724928 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:52:31.747766 140321497724928 dqn_agent.py:275] 	 update_period: 4
I0901 12:52:31.748043 140321497724928 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:52:31.748269 140321497724928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:52:31.748445 140321497724928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:52:31.748588 140321497724928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:52:31.748773 140321497724928 dqn_agent.py:280] 	 optimizer: adam
I0901 12:52:31.748886 140321497724928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:52:31.748990 140321497724928 dqn_agent.py:283] 	 seed: 1630500751746976
I0901 12:52:31.751736 140321497724928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:52:31.751933 140321497724928 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:52:31.752085 140321497724928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:52:31.752217 140321497724928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:52:31.752346 140321497724928 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:52:31.752505 140321497724928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:52:31.752736 140321497724928 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:52:31.752914 140321497724928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:52:31.753046 140321497724928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:52:31.789936 140321497724928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:52:31.835874 140321497724928 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:52:31.836349 140321497724928 replay_runner.py:41] Starting iteration 0
Steps executed: 201 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 144.39
I0901 12:52:38.762342 140321497724928 replay_runner.py:36] Average training steps per second: 144.39
I0901 12:52:39.969645 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.57
INFO:tensorflow:Starting iteration 1

Steps executed: 204 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 190.24
I0901 12:52:45.422839 140321497724928 replay_runner.py:36] Average training steps per second: 190.24
I0901 12:52:45.579689 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.71
INFO:tensorflow:Starting iteration 2
I0901 12:52:45.769019 140321497724928 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 194.24
I0901 12:52:50.917821 140321497724928 replay_runner.py:36] Average training steps per second: 194.24
I0901 12:52:51.082771 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 59.50
INFO:tensorflow:Starting iteration 3

Steps executed: 238 Episode length: 53 Return: 53.0
INFO:tensorflow:Average training steps per second: 195.12
I0901 12:52:56.386922 140321497724928 replay_runner.py:36] Average training steps per second: 195.12
I0901 12:52:56.537082 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 4

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 192.21
I0901 12:53:01.938279 140321497724928 replay_runner.py:36] Average training steps per second: 192.21
I0901 12:53:02.090388 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 34.33
INFO:tensorflow:Starting iteration 5

Steps executed: 206 Episode length: 35 Return: 35.0.0
INFO:tensorflow:Average training steps per second: 192.17
I0901 12:53:07.487600 140321497724928 replay_runner.py:36] Average training steps per second: 192.17
I0901 12:53:07.639903 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 106.00
INFO:tensorflow:Starting iteration 6

Steps executed: 212 Episode length: 114 Return: 114.0
INFO:tensorflow:Average training steps per second: 195.76
I0901 12:53:12.943571 140321497724928 replay_runner.py:36] Average training steps per second: 195.76
I0901 12:53:13.119945 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 78.00
INFO:tensorflow:Starting iteration 7

Steps executed: 234 Episode length: 76 Return: 76.0.0
INFO:tensorflow:Average training steps per second: 187.85
I0901 12:53:18.638433 140321497724928 replay_runner.py:36] Average training steps per second: 187.85
I0901 12:53:18.788028 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 108.00
INFO:tensorflow:Starting iteration 8

Steps executed: 216 Episode length: 99 Return: 99.0.0
INFO:tensorflow:Average training steps per second: 197.92
I0901 12:53:24.028678 140321497724928 replay_runner.py:36] Average training steps per second: 197.92
I0901 12:53:24.236111 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 93.33
INFO:tensorflow:Starting iteration 9

Steps executed: 280 Episode length: 95 Return: 95.0.0
INFO:tensorflow:Average training steps per second: 190.86
I0901 12:53:29.671007 140321497724928 replay_runner.py:36] Average training steps per second: 190.86
I0901 12:53:29.859003 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 83.00
INFO:tensorflow:Starting iteration 10

Steps executed: 249 Episode length: 77 Return: 77.0.0
INFO:tensorflow:Average training steps per second: 189.11
I0901 12:53:35.339276 140321497724928 replay_runner.py:36] Average training steps per second: 189.11
I0901 12:53:35.492495 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 109.50
INFO:tensorflow:Starting iteration 11

Steps executed: 219 Episode length: 112 Return: 112.0
INFO:tensorflow:Average training steps per second: 196.45

Steps executed: 130 Episode length: 130 Return: 130.0
I0901 12:53:41.005369 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 165.00
INFO:tensorflow:Starting iteration 12

Steps executed: 330 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 198.68
I0901 12:53:46.233876 140321497724928 replay_runner.py:36] Average training steps per second: 198.68
I0901 12:53:46.414939 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 128.50
INFO:tensorflow:Starting iteration 13

Steps executed: 257 Episode length: 136 Return: 136.0
INFO:tensorflow:Average training steps per second: 193.32
I0901 12:53:51.777971 140321497724928 replay_runner.py:36] Average training steps per second: 193.32
I0901 12:53:51.918069 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 14

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 194.40
I0901 12:53:57.244169 140321497724928 replay_runner.py:36] Average training steps per second: 194.40
I0901 12:53:57.384602 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 15

Steps executed: 294 Episode length: 150 Return: 150.0
INFO:tensorflow:Average training steps per second: 191.33
I0901 12:54:02.791404 140321497724928 replay_runner.py:36] Average training steps per second: 191.33
I0901 12:54:02.994891 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 147.00
INFO:tensorflow:Starting iteration 16
I0901 12:54:03.187451 140321497724928 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 196.12
I0901 12:54:08.286916 140321497724928 replay_runner.py:36] Average training steps per second: 196.12

Steps executed: 338 Episode length: 164 Return: 164.0
INFO:tensorflow:Starting iteration 17
I0901 12:54:08.728269 140321497724928 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 194.12
I0901 12:54:13.880091 140321497724928 replay_runner.py:36] Average training steps per second: 194.12
I0901 12:54:14.138305 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 191.00
INFO:tensorflow:Starting iteration 18

Steps executed: 382 Episode length: 187 Return: 187.0
INFO:tensorflow:Average training steps per second: 194.45
I0901 12:54:19.476929 140321497724928 replay_runner.py:36] Average training steps per second: 194.45
I0901 12:54:19.623278 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 19

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 194.25
I0901 12:54:24.960693 140321497724928 replay_runner.py:36] Average training steps per second: 194.25
I0901 12:54:25.195816 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 173.00
INFO:tensorflow:Starting iteration 20

Steps executed: 346 Episode length: 176 Return: 176.0
INFO:tensorflow:Average training steps per second: 187.43

Steps executed: 167 Episode length: 167 Return: 167.0
I0901 12:54:30.965079 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 170.00
INFO:tensorflow:Starting iteration 21

Steps executed: 340 Episode length: 173 Return: 173.0
INFO:tensorflow:Average training steps per second: 197.27
I0901 12:54:36.230958 140321497724928 replay_runner.py:36] Average training steps per second: 197.27
I0901 12:54:36.375391 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 22

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 190.29
I0901 12:54:41.831648 140321497724928 replay_runner.py:36] Average training steps per second: 190.29
I0901 12:54:41.969800 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 23
I0901 12:54:42.154567 140321497724928 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 196.63
I0901 12:54:47.240668 140321497724928 replay_runner.py:36] Average training steps per second: 196.63
I0901 12:54:47.384885 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 24

Steps executed: 355 Episode length: 172 Return: 172.0
INFO:tensorflow:Average training steps per second: 195.12
I0901 12:54:52.725868 140321497724928 replay_runner.py:36] Average training steps per second: 195.12
I0901 12:54:52.973859 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 177.50
INFO:tensorflow:Starting iteration 25

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 193.41
I0901 12:54:58.354996 140321497724928 replay_runner.py:36] Average training steps per second: 193.41
I0901 12:54:58.492929 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26
I0901 12:54:58.680410 140321497724928 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 189.67
I0901 12:55:03.953080 140321497724928 replay_runner.py:36] Average training steps per second: 189.67
I0901 12:55:04.092648 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 27
I0901 12:55:04.291825 140321497724928 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 193.11
I0901 12:55:09.470681 140321497724928 replay_runner.py:36] Average training steps per second: 193.11
I0901 12:55:09.606291 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 28
I0901 12:55:09.799279 140321497724928 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 191.59
I0901 12:55:15.019042 140321497724928 replay_runner.py:36] Average training steps per second: 191.59
I0901 12:55:15.154014 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 201.56
I0901 12:55:20.305644 140321497724928 replay_runner.py:36] Average training steps per second: 201.56
I0901 12:55:20.436234 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00