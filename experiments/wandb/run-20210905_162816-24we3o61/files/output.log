I0905 16:28:23.227728 140035672414208 run_experiment.py:549] Creating TrainRunner ...
I0905 16:28:23.237681 140035672414208 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:28:23.237850 140035672414208 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:28:23.237941 140035672414208 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:28:23.238002 140035672414208 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:28:23.238058 140035672414208 dqn_agent.py:275] 	 update_period: 4
I0905 16:28:23.238144 140035672414208 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:28:23.238226 140035672414208 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:28:23.238282 140035672414208 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:28:23.238336 140035672414208 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:28:23.238389 140035672414208 dqn_agent.py:280] 	 optimizer: adam
I0905 16:28:23.238494 140035672414208 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:28:23.238573 140035672414208 dqn_agent.py:283] 	 seed: 1630859303237623
I0905 16:28:23.240823 140035672414208 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:28:23.241011 140035672414208 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:28:23.241135 140035672414208 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:28:23.241200 140035672414208 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:28:23.241282 140035672414208 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:28:23.241481 140035672414208 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:28:23.241572 140035672414208 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:28:23.241675 140035672414208 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:28:23.241774 140035672414208 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0905 16:28:24.914508 140035672414208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:25.265303 140035672414208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:25.275539 140035672414208 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:28:25.282504 140035672414208 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:28:25.282672 140035672414208 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:28:25.282766 140035672414208 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:28:25.282846 140035672414208 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:28:25.282925 140035672414208 dqn_agent.py:275] 	 update_period: 4
I0905 16:28:25.283019 140035672414208 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:28:25.283136 140035672414208 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:28:25.283248 140035672414208 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:28:25.283406 140035672414208 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:28:25.283521 140035672414208 dqn_agent.py:280] 	 optimizer: adam
I0905 16:28:25.283616 140035672414208 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:28:25.283698 140035672414208 dqn_agent.py:283] 	 seed: 1630859305282467
I0905 16:28:25.286244 140035672414208 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:28:25.286398 140035672414208 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:28:25.286496 140035672414208 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:28:25.286589 140035672414208 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:28:25.286661 140035672414208 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:28:25.286715 140035672414208 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:28:25.286767 140035672414208 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:28:25.286817 140035672414208 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:28:25.286869 140035672414208 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:28:25.311159 140035672414208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:25.326828 140035672414208 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:28:25.327020 140035672414208 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 213.99
I0905 16:28:30.000423 140035672414208 replay_runner.py:36] Average training steps per second: 213.99
Steps executed: 227 Episode length: 105 Return: -438.81509941094095
I0905 16:28:30.903468 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -375.04
INFO:tensorflow:Starting iteration 1

Steps executed: 212 Episode length: 89 Return: -303.209658336232855
INFO:tensorflow:Average training steps per second: 303.35
I0905 16:28:37.890500 140035672414208 replay_runner.py:36] Average training steps per second: 303.35
I0905 16:28:37.999727 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.17
INFO:tensorflow:Starting iteration 2

Steps executed: 211 Episode length: 131 Return: -238.67176776281866
INFO:tensorflow:Average training steps per second: 295.67
I0905 16:28:45.072955 140035672414208 replay_runner.py:36] Average training steps per second: 295.67
I0905 16:28:45.184981 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.47
INFO:tensorflow:Starting iteration 3

Steps executed: 301 Episode length: 149 Return: -332.17189319903684
INFO:tensorflow:Average training steps per second: 303.37
I0905 16:28:52.156047 140035672414208 replay_runner.py:36] Average training steps per second: 303.37
I0905 16:28:52.341686 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.93
INFO:tensorflow:Starting iteration 4

Steps executed: 332 Episode length: 191 Return: 34.5663339135745964
INFO:tensorflow:Average training steps per second: 311.89
I0905 16:28:59.175568 140035672414208 replay_runner.py:36] Average training steps per second: 311.89
I0905 16:28:59.372285 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: 46.91
INFO:tensorflow:Starting iteration 5

Steps executed: 307 Episode length: 307 Return: -7.6301700951185584
INFO:tensorflow:Average training steps per second: 298.95
I0905 16:29:06.231070 140035672414208 replay_runner.py:36] Average training steps per second: 298.95
I0905 16:29:06.523496 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -7.63
INFO:tensorflow:Starting iteration 6
I0905 16:29:10.086968 140035672414208 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 289.73

Steps executed: 902 Episode length: 902 Return: -1942.1600033818854
I0905 16:29:15.844141 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -1942.16
INFO:tensorflow:Starting iteration 7
I0905 16:29:19.845309 140035672414208 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 254.54

Steps executed: 924 Episode length: 924 Return: -1428.7055754809412
I0905 16:29:25.561062 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -1428.71
INFO:tensorflow:Starting iteration 8

Steps executed: 271 Episode length: 271 Return: -968.98407961283032
INFO:tensorflow:Average training steps per second: 237.59
I0905 16:29:33.862419 140035672414208 replay_runner.py:36] Average training steps per second: 237.59
I0905 16:29:34.128198 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -968.98
INFO:tensorflow:Starting iteration 9
I0905 16:29:38.369271 140035672414208 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 237.75

Steps executed: 1000 Episode length: 1000 Return: -337.40340285761465
I0905 16:29:46.209741 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -337.40
INFO:tensorflow:Starting iteration 10
I0905 16:29:50.583574 140035672414208 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 229.17

Steps executed: 578 Episode length: 578 Return: -443.5542571296805465
I0905 16:29:55.774219 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -443.55
INFO:tensorflow:Starting iteration 11
I0905 16:29:59.990097 140035672414208 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 235.79

Steps executed: 1000 Episode length: 1000 Return: -182.69179091969846
I0905 16:30:06.633267 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.69
INFO:tensorflow:Starting iteration 12
I0905 16:30:10.844452 140035672414208 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 239.11

Steps executed: 880 Episode length: 880 Return: -236.9107220905271246
I0905 16:30:16.909930 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.91
INFO:tensorflow:Starting iteration 13
I0905 16:30:21.190554 140035672414208 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 235.02

Steps executed: 827 Episode length: 827 Return: -1513.713848622715746
I0905 16:30:27.935700 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -1513.71
INFO:tensorflow:Starting iteration 14

Steps executed: 395 Episode length: 210 Return: -88.43383533132322746
INFO:tensorflow:Average training steps per second: 233.30
I0905 16:30:36.468634 140035672414208 replay_runner.py:36] Average training steps per second: 233.30
I0905 16:30:36.789347 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.08
INFO:tensorflow:Starting iteration 15
I0905 16:30:40.969840 140035672414208 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 238.81
I0905 16:30:45.158020 140035672414208 replay_runner.py:36] Average training steps per second: 238.81

Steps executed: 243 Episode length: 81 Return: -114.88601635653957746
INFO:tensorflow:Starting iteration 16

Steps executed: 461 Episode length: 386 Return: -23.61999417819690446
INFO:tensorflow:Average training steps per second: 232.74
I0905 16:30:53.867757 140035672414208 replay_runner.py:36] Average training steps per second: 232.74
I0905 16:30:54.468394 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -45.74
INFO:tensorflow:Starting iteration 17

Steps executed: 230 Episode length: 63 Return: -121.57336865231122446
INFO:tensorflow:Average training steps per second: 233.88
I0905 16:31:03.002224 140035672414208 replay_runner.py:36] Average training steps per second: 233.88
I0905 16:31:03.180994 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -56.79
INFO:tensorflow:Starting iteration 18

Steps executed: 570 Episode length: 570 Return: 5.6282810138711882446
INFO:tensorflow:Average training steps per second: 236.82
I0905 16:31:11.582208 140035672414208 replay_runner.py:36] Average training steps per second: 236.82
I0905 16:31:12.519559 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: 5.63
INFO:tensorflow:Starting iteration 19

Steps executed: 220 Episode length: 84 Return: -66.797325228926083446
INFO:tensorflow:Average training steps per second: 233.23
I0905 16:31:21.082353 140035672414208 replay_runner.py:36] Average training steps per second: 233.23
I0905 16:31:21.252630 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -388.79
INFO:tensorflow:Starting iteration 20
I0905 16:31:25.476012 140035672414208 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 235.15

Steps executed: 1000 Episode length: 1000 Return: -102.73697041156596
I0905 16:31:33.083221 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.74
INFO:tensorflow:Starting iteration 21
I0905 16:31:37.351714 140035672414208 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 242.07

Steps executed: 397 Episode length: 397 Return: -662.4797925150078596
I0905 16:31:42.053708 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -662.48
INFO:tensorflow:Starting iteration 22

Steps executed: 312 Episode length: 196 Return: -73.45075927973869596
INFO:tensorflow:Average training steps per second: 256.02
I0905 16:31:50.263664 140035672414208 replay_runner.py:36] Average training steps per second: 256.02
I0905 16:31:50.487155 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -295.11
INFO:tensorflow:Starting iteration 23
I0905 16:31:54.675756 140035672414208 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 244.24

Steps executed: 1000 Episode length: 1000 Return: -103.60212517545996
I0905 16:32:01.157828 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.60
INFO:tensorflow:Starting iteration 24

Steps executed: 266 Episode length: 266 Return: -257.2898499430944996
INFO:tensorflow:Average training steps per second: 208.56
I0905 16:32:10.383562 140035672414208 replay_runner.py:36] Average training steps per second: 208.56
I0905 16:32:10.776656 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.29
INFO:tensorflow:Starting iteration 25

Steps executed: 292 Episode length: 292 Return: -338.3751562934756996
INFO:tensorflow:Average training steps per second: 198.01
I0905 16:32:20.324620 140035672414208 replay_runner.py:36] Average training steps per second: 198.01
I0905 16:32:20.781220 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.38
INFO:tensorflow:Starting iteration 26

Steps executed: 221 Episode length: 82 Return: -157.50456840387406496
INFO:tensorflow:Average training steps per second: 177.84
I0905 16:32:31.019573 140035672414208 replay_runner.py:36] Average training steps per second: 177.84
I0905 16:32:31.244545 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.77
INFO:tensorflow:Starting iteration 27

Steps executed: 306 Episode length: 306 Return: -96.39364356545678496
INFO:tensorflow:Average training steps per second: 158.50
I0905 16:32:42.162834 140035672414208 replay_runner.py:36] Average training steps per second: 158.50
I0905 16:32:42.732727 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.39
INFO:tensorflow:Starting iteration 28
I0905 16:32:48.172093 140035672414208 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 167.23

Steps executed: 1000 Episode length: 1000 Return: -43.302788520095234
I0905 16:32:58.165949 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -43.30
INFO:tensorflow:Starting iteration 29

Steps executed: 60 Episode length: 60 Return: -224.413717273875595234
INFO:tensorflow:Average training steps per second: 164.64

Steps executed: 1005 Episode length: 945 Return: -499.231004367419644

Done fixed training! Episode length: 945 Return: -499.231004367419644