I0905 16:32:58.921306 140199535331328 run_experiment.py:549] Creating TrainRunner ...
I0905 16:32:58.943164 140199535331328 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:32:58.943976 140199535331328 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:32:58.944906 140199535331328 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:32:58.945328 140199535331328 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:32:58.945567 140199535331328 dqn_agent.py:275] 	 update_period: 4
I0905 16:32:58.945907 140199535331328 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:32:58.946478 140199535331328 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:32:58.946794 140199535331328 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:32:58.947815 140199535331328 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:32:58.948122 140199535331328 dqn_agent.py:280] 	 optimizer: adam
I0905 16:32:58.948486 140199535331328 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:32:58.949037 140199535331328 dqn_agent.py:283] 	 seed: 1630859578943079
I0905 16:32:58.956664 140199535331328 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:32:58.957716 140199535331328 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:32:58.957964 140199535331328 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:32:58.958146 140199535331328 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:32:58.958550 140199535331328 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:32:58.959510 140199535331328 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:32:58.959883 140199535331328 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:32:58.960348 140199535331328 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:32:58.961063 140199535331328 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:33:02.187604 140199535331328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0905 16:33:02.839474 140199535331328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:02.863032 140199535331328 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:33:02.899983 140199535331328 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:33:02.900355 140199535331328 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:33:02.900573 140199535331328 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:33:02.908798 140199535331328 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:33:02.909085 140199535331328 dqn_agent.py:275] 	 update_period: 4
I0905 16:33:02.909487 140199535331328 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:33:02.909771 140199535331328 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:33:02.909928 140199535331328 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:33:02.910027 140199535331328 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:33:02.910110 140199535331328 dqn_agent.py:280] 	 optimizer: adam
I0905 16:33:02.910185 140199535331328 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:33:02.910265 140199535331328 dqn_agent.py:283] 	 seed: 1630859582899911
I0905 16:33:02.913804 140199535331328 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:33:02.914101 140199535331328 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:33:02.914530 140199535331328 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:33:02.914828 140199535331328 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:33:02.915272 140199535331328 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:33:02.915648 140199535331328 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:33:02.916007 140199535331328 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:33:02.916190 140199535331328 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:33:02.920652 140199535331328 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:33:02.977252 140199535331328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:03.009909 140199535331328 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:33:03.010835 140199535331328 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 101.75
I0905 16:33:12.839842 140199535331328 replay_runner.py:36] Average training steps per second: 101.75
Steps executed: 338 Episode length: 162 Return: -223.52654821895814
I0905 16:33:14.953894 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -291.92
INFO:tensorflow:Starting iteration 1

Steps executed: 346 Episode length: 156 Return: -444.54609536321857
INFO:tensorflow:Average training steps per second: 151.90
I0905 16:33:26.203196 140199535331328 replay_runner.py:36] Average training steps per second: 151.90
I0905 16:33:26.627508 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -399.13
INFO:tensorflow:Starting iteration 2

Steps executed: 337 Episode length: 167 Return: -355.92813936353367
INFO:tensorflow:Average training steps per second: 152.53
I0905 16:33:37.662302 140199535331328 replay_runner.py:36] Average training steps per second: 152.53
I0905 16:33:38.127855 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.62
INFO:tensorflow:Starting iteration 3

Steps executed: 419 Episode length: 275 Return: -322.70714210648727
INFO:tensorflow:Average training steps per second: 165.21
I0905 16:33:49.420164 140199535331328 replay_runner.py:36] Average training steps per second: 165.21
I0905 16:33:50.138360 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.38
INFO:tensorflow:Starting iteration 4
I0905 16:33:55.070904 140199535331328 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 161.19

Steps executed: 1000 Episode length: 1000 Return: -150.8207397542483
I0905 16:34:04.181086 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -150.82
INFO:tensorflow:Starting iteration 5

Steps executed: 564 Episode length: 564 Return: -674.501161823735583
INFO:tensorflow:Average training steps per second: 159.97
I0905 16:34:15.331958 140199535331328 replay_runner.py:36] Average training steps per second: 159.97
I0905 16:34:16.590324 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -674.50
INFO:tensorflow:Starting iteration 6
I0905 16:34:21.319775 140199535331328 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 153.89

Steps executed: 1000 Episode length: 1000 Return: -58.602664293959286
I0905 16:34:30.235022 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -58.60
INFO:tensorflow:Starting iteration 7
I0905 16:34:35.702433 140199535331328 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 154.18
I0905 16:34:42.189119 140199535331328 replay_runner.py:36] Average training steps per second: 154.18

Steps executed: 835 Episode length: 835 Return: -486.7607801457738286
INFO:tensorflow:Starting iteration 8
I0905 16:34:50.022774 140199535331328 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 153.55

Steps executed: 462 Episode length: 462 Return: -432.4605283447121286
I0905 16:34:57.573158 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -432.46
INFO:tensorflow:Starting iteration 9
I0905 16:35:02.819829 140199535331328 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 164.58

Steps executed: 1000 Episode length: 1000 Return: -342.53095090431185
I0905 16:35:12.429850 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.53
INFO:tensorflow:Starting iteration 10
I0905 16:35:17.554892 140199535331328 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 163.99

Steps executed: 668 Episode length: 668 Return: -965.1305997640537185
I0905 16:35:26.180494 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -965.13
INFO:tensorflow:Starting iteration 11
I0905 16:35:31.187850 140199535331328 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 150.55

Steps executed: 1000 Episode length: 1000 Return: -167.05555904460075
I0905 16:35:41.246915 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.06
INFO:tensorflow:Starting iteration 12
I0905 16:35:45.663696 140199535331328 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 157.03
I0905 16:35:52.032464 140199535331328 replay_runner.py:36] Average training steps per second: 157.03

Steps executed: 566 Episode length: 566 Return: -591.6417045995420075
INFO:tensorflow:Starting iteration 13
I0905 16:35:56.929389 140199535331328 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 180.11
I0905 16:36:02.482662 140199535331328 replay_runner.py:36] Average training steps per second: 180.11

Steps executed: 1000 Episode length: 1000 Return: -167.05903147493473
INFO:tensorflow:Starting iteration 14
I0905 16:36:11.169109 140199535331328 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 195.16

Steps executed: 938 Episode length: 938 Return: -39.33175353526538573
I0905 16:36:18.259416 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -39.33
INFO:tensorflow:Starting iteration 15
I0905 16:36:22.558104 140199535331328 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 229.75

Steps executed: 1000 Episode length: 1000 Return: -144.21316300687107
I0905 16:36:29.528681 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.21
INFO:tensorflow:Starting iteration 16

Steps executed: 310 Episode length: 144 Return: -299.1534214699447607
INFO:tensorflow:Average training steps per second: 328.52
I0905 16:36:36.369091 140199535331328 replay_runner.py:36] Average training steps per second: 328.52
I0905 16:36:36.500642 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.48
INFO:tensorflow:Starting iteration 17

Steps executed: 305 Episode length: 202 Return: -168.6677860324046507
INFO:tensorflow:Average training steps per second: 390.97
I0905 16:36:41.934432 140199535331328 replay_runner.py:36] Average training steps per second: 390.97
I0905 16:36:42.097527 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.84
INFO:tensorflow:Starting iteration 18

Steps executed: 456 Episode length: 456 Return: -346.0545024092829507
INFO:tensorflow:Average training steps per second: 383.94
I0905 16:36:47.706592 140199535331328 replay_runner.py:36] Average training steps per second: 383.94
I0905 16:36:48.182305 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.05
INFO:tensorflow:Starting iteration 19

Steps executed: 390 Episode length: 390 Return: -96.47020466758599507
INFO:tensorflow:Average training steps per second: 395.42
I0905 16:36:53.771511 140199535331328 replay_runner.py:36] Average training steps per second: 395.42
I0905 16:36:54.107886 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.47
INFO:tensorflow:Starting iteration 20

Steps executed: 374 Episode length: 374 Return: -309.4153168392989507
INFO:tensorflow:Average training steps per second: 387.75
I0905 16:36:59.721776 140199535331328 replay_runner.py:36] Average training steps per second: 387.75
I0905 16:37:00.030636 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.42
INFO:tensorflow:Starting iteration 21

Steps executed: 234 Episode length: 66 Return: -176.25434276795596507
INFO:tensorflow:Average training steps per second: 389.15
I0905 16:37:05.603303 140199535331328 replay_runner.py:36] Average training steps per second: 389.15
I0905 16:37:05.701399 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.92
INFO:tensorflow:Starting iteration 22
I0905 16:37:08.688401 140199535331328 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 384.94
I0905 16:37:11.286422 140199535331328 replay_runner.py:36] Average training steps per second: 384.94

Steps executed: 207 Episode length: 102 Return: -326.0888778617632707
INFO:tensorflow:Starting iteration 23
I0905 16:37:14.480259 140199535331328 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 404.94
I0905 16:37:16.950025 140199535331328 replay_runner.py:36] Average training steps per second: 404.94

Steps executed: 233 Episode length: 167 Return: -29.62397706885572307
INFO:tensorflow:Starting iteration 24
I0905 16:37:20.216281 140199535331328 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 402.14

Steps executed: 521 Episode length: 521 Return: -84.16312574384571307
I0905 16:37:23.337348 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.16
INFO:tensorflow:Starting iteration 25

Steps executed: 196 Episode length: 89 Return: -148.33183725905653207
INFO:tensorflow:Average training steps per second: 397.02
I0905 16:37:28.919524 140199535331328 replay_runner.py:36] Average training steps per second: 397.02

Steps executed: 343 Episode length: 147 Return: -388.1118767314055207
INFO:tensorflow:Starting iteration 26

Steps executed: 203 Episode length: 65 Return: -42.305054513928785207
INFO:tensorflow:Average training steps per second: 411.62
I0905 16:37:34.591011 140199535331328 replay_runner.py:36] Average training steps per second: 411.62
I0905 16:37:34.662290 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.91
INFO:tensorflow:Starting iteration 27

Steps executed: 234 Episode length: 122 Return: -190.6509965759648507
INFO:tensorflow:Average training steps per second: 397.43
I0905 16:37:40.330892 140199535331328 replay_runner.py:36] Average training steps per second: 397.43
I0905 16:37:40.429480 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.99
INFO:tensorflow:Starting iteration 28

Steps executed: 240 Episode length: 148 Return: -139.0462184893670207
INFO:tensorflow:Average training steps per second: 410.42
I0905 16:37:46.024484 140199535331328 replay_runner.py:36] Average training steps per second: 410.42
I0905 16:37:46.119888 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.91
INFO:tensorflow:Starting iteration 29

Steps executed: 246 Episode length: 72 Return: -209.65093034787650207
INFO:tensorflow:Average training steps per second: 398.06
I0905 16:37:51.774810 140199535331328 replay_runner.py:36] Average training steps per second: 398.06

Done fixed training!Episode length: 72 Return: -209.65093034787650207