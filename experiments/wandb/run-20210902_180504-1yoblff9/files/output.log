Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0902 18:05:11.130009 140131099109376 run_experiment.py:549] Creating TrainRunner ...
I0902 18:05:11.140421 140131099109376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:05:11.140604 140131099109376 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:05:11.140682 140131099109376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:05:11.140780 140131099109376 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:05:11.140859 140131099109376 dqn_agent.py:275] 	 update_period: 4
I0902 18:05:11.140944 140131099109376 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:05:11.141014 140131099109376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:05:11.141087 140131099109376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:05:11.141166 140131099109376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:05:11.141248 140131099109376 dqn_agent.py:280] 	 optimizer: adam
I0902 18:05:11.141335 140131099109376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:05:11.141421 140131099109376 dqn_agent.py:283] 	 seed: 1630605911140372
I0902 18:05:11.143507 140131099109376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:05:11.143655 140131099109376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:05:11.143787 140131099109376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:05:11.143880 140131099109376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:05:11.143968 140131099109376 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:05:11.144090 140131099109376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:05:11.144253 140131099109376 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:05:11.144452 140131099109376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:05:11.144575 140131099109376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:05:11.177024 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.312500
I0902 18:05:11.518262 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.312500
I0902 18:05:11.529709 140131099109376 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:05:11.537863 140131099109376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:05:11.538052 140131099109376 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:05:11.538136 140131099109376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:05:11.538202 140131099109376 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:05:11.538275 140131099109376 dqn_agent.py:275] 	 update_period: 4
I0902 18:05:11.538359 140131099109376 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:05:11.538452 140131099109376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:05:11.538665 140131099109376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:05:11.538780 140131099109376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:05:11.538880 140131099109376 dqn_agent.py:280] 	 optimizer: adam
I0902 18:05:11.538993 140131099109376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:05:11.539118 140131099109376 dqn_agent.py:283] 	 seed: 1630605911537816
I0902 18:05:11.541923 140131099109376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:05:11.542114 140131099109376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:05:11.542273 140131099109376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:05:11.542416 140131099109376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:05:11.542590 140131099109376 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:05:11.542695 140131099109376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:05:11.542798 140131099109376 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:05:11.543050 140131099109376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:05:11.543231 140131099109376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:05:11.569927 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.312500
I0902 18:05:11.589384 140131099109376 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:05:11.589583 140131099109376 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 171.42
I0902 18:05:17.423402 140131099109376 replay_runner.py:36] Average training steps per second: 171.42
I0902 18:05:18.638778 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -567.55
Steps executed: 261 Episode length: 81 Return: -554.7372405031429
INFO:tensorflow:Starting iteration 1

Steps executed: 296 Episode length: 184 Return: -438.2889373000296
INFO:tensorflow:Average training steps per second: 225.74
I0902 18:05:27.316428 140131099109376 replay_runner.py:36] Average training steps per second: 225.74
I0902 18:05:27.623792 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -569.42
INFO:tensorflow:Starting iteration 2

Steps executed: 209 Episode length: 209 Return: -153.31882653160028
INFO:tensorflow:Average training steps per second: 228.48
I0902 18:05:36.333021 140131099109376 replay_runner.py:36] Average training steps per second: 228.48
I0902 18:05:36.538187 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.32
INFO:tensorflow:Starting iteration 3

Steps executed: 279 Episode length: 96 Return: -393.992984939505968
INFO:tensorflow:Average training steps per second: 227.77
I0902 18:05:45.272976 140131099109376 replay_runner.py:36] Average training steps per second: 227.77
I0902 18:05:45.527287 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -436.14
INFO:tensorflow:Starting iteration 4

Steps executed: 287 Episode length: 202 Return: -333.19039170659848
INFO:tensorflow:Average training steps per second: 231.84
I0902 18:05:54.139963 140131099109376 replay_runner.py:36] Average training steps per second: 231.84
I0902 18:05:54.410294 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -385.12
INFO:tensorflow:Starting iteration 5
I0902 18:05:58.654365 140131099109376 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 233.06

Steps executed: 399 Episode length: 236 Return: -376.51298093218526
I0902 18:06:03.359255 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -247.38
INFO:tensorflow:Starting iteration 6

Steps executed: 207 Episode length: 116 Return: -257.10335145983226
INFO:tensorflow:Average training steps per second: 237.42
I0902 18:06:11.860991 140131099109376 replay_runner.py:36] Average training steps per second: 237.42
I0902 18:06:12.044005 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -478.46
INFO:tensorflow:Starting iteration 7

Steps executed: 218 Episode length: 94 Return: -661.703377497736124
INFO:tensorflow:Average training steps per second: 233.75
I0902 18:06:20.653967 140131099109376 replay_runner.py:36] Average training steps per second: 233.75
I0902 18:06:20.848378 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -433.58
INFO:tensorflow:Starting iteration 8

Steps executed: 307 Episode length: 117 Return: -127.27134033856186
INFO:tensorflow:Average training steps per second: 232.09
I0902 18:06:29.518611 140131099109376 replay_runner.py:36] Average training steps per second: 232.09
I0902 18:06:29.812605 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.95
INFO:tensorflow:Starting iteration 9

Steps executed: 521 Episode length: 323 Return: 240.316537042552346
INFO:tensorflow:Average training steps per second: 230.25
I0902 18:06:38.414200 140131099109376 replay_runner.py:36] Average training steps per second: 230.25
I0902 18:06:39.099865 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.44
INFO:tensorflow:Starting iteration 10

Steps executed: 237 Episode length: 90 Return: -714.494234605956546
INFO:tensorflow:Average training steps per second: 227.01
I0902 18:06:47.734628 140131099109376 replay_runner.py:36] Average training steps per second: 227.01
I0902 18:06:47.943065 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -570.53
INFO:tensorflow:Starting iteration 11

Steps executed: 221 Episode length: 221 Return: -36.021731218523796
INFO:tensorflow:Average training steps per second: 222.50
I0902 18:06:56.875320 140131099109376 replay_runner.py:36] Average training steps per second: 222.50
I0902 18:06:57.134106 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -36.02
INFO:tensorflow:Starting iteration 12

Steps executed: 336 Episode length: 197 Return: -366.81085065466425
INFO:tensorflow:Average training steps per second: 225.19
I0902 18:07:05.977829 140131099109376 replay_runner.py:36] Average training steps per second: 225.19
I0902 18:07:06.293707 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -388.26
INFO:tensorflow:Starting iteration 13

Steps executed: 141 Episode length: 141 Return: -507.10209036333425
INFO:tensorflow:Average training steps per second: 227.42
I0902 18:07:15.127261 140131099109376 replay_runner.py:36] Average training steps per second: 227.42

Steps executed: 369 Episode length: 228 Return: -20.006365344951425
INFO:tensorflow:Starting iteration 14

Steps executed: 224 Episode length: 101 Return: -397.97180333761656
INFO:tensorflow:Average training steps per second: 222.60
I0902 18:07:24.258320 140131099109376 replay_runner.py:36] Average training steps per second: 222.60
I0902 18:07:24.462933 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.56
INFO:tensorflow:Starting iteration 15

Steps executed: 244 Episode length: 129 Return: -358.08039904310726
INFO:tensorflow:Average training steps per second: 229.52
I0902 18:07:33.165699 140131099109376 replay_runner.py:36] Average training steps per second: 229.52
I0902 18:07:33.371910 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -250.15
INFO:tensorflow:Starting iteration 16

Steps executed: 207 Episode length: 121 Return: -311.94606826716376
INFO:tensorflow:Average training steps per second: 230.89
I0902 18:07:42.065367 140131099109376 replay_runner.py:36] Average training steps per second: 230.89
I0902 18:07:42.254682 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -467.82
INFO:tensorflow:Starting iteration 17

Steps executed: 200 Episode length: 200 Return: -212.62898712444075
INFO:tensorflow:Average training steps per second: 231.55
I0902 18:07:50.815643 140131099109376 replay_runner.py:36] Average training steps per second: 231.55
I0902 18:07:51.039689 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.63
INFO:tensorflow:Starting iteration 18

Steps executed: 265 Episode length: 168 Return: -243.66987303187716
INFO:tensorflow:Average training steps per second: 241.09
I0902 18:07:59.507637 140131099109376 replay_runner.py:36] Average training steps per second: 241.09
I0902 18:07:59.738896 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.01
INFO:tensorflow:Starting iteration 19

Steps executed: 273 Episode length: 91 Return: -619.632622425553846
INFO:tensorflow:Average training steps per second: 229.17
I0902 18:08:08.351737 140131099109376 replay_runner.py:36] Average training steps per second: 229.17
I0902 18:08:08.623190 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.12
INFO:tensorflow:Starting iteration 20
I0902 18:08:12.906680 140131099109376 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 235.66

Steps executed: 335 Episode length: 167 Return: -92.578125661950946
I0902 18:08:17.470978 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -334.29
INFO:tensorflow:Starting iteration 21

Steps executed: 320 Episode length: 232 Return: -45.711794000583216
INFO:tensorflow:Average training steps per second: 229.81
I0902 18:08:26.223500 140131099109376 replay_runner.py:36] Average training steps per second: 229.81
I0902 18:08:26.528555 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -286.93
INFO:tensorflow:Starting iteration 22

Steps executed: 225 Episode length: 91 Return: -615.209686174953316
INFO:tensorflow:Average training steps per second: 228.98
I0902 18:08:35.017950 140131099109376 replay_runner.py:36] Average training steps per second: 228.98
I0902 18:08:35.227204 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -562.00
INFO:tensorflow:Starting iteration 23

Steps executed: 208 Episode length: 111 Return: -538.09154976467896
INFO:tensorflow:Average training steps per second: 225.71
I0902 18:08:43.912416 140131099109376 replay_runner.py:36] Average training steps per second: 225.71
I0902 18:08:44.107352 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -598.28
INFO:tensorflow:Starting iteration 24

Steps executed: 234 Episode length: 120 Return: -365.02501356019574
INFO:tensorflow:Average training steps per second: 229.90
I0902 18:08:52.759862 140131099109376 replay_runner.py:36] Average training steps per second: 229.90
I0902 18:08:52.961713 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -321.98
INFO:tensorflow:Starting iteration 25
I0902 18:08:57.390413 140131099109376 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 242.42

Steps executed: 245 Episode length: 80 Return: -487.505781603027974
I0902 18:09:01.741487 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -410.14
INFO:tensorflow:Starting iteration 26

Steps executed: 279 Episode length: 102 Return: -265.16544659683046
INFO:tensorflow:Average training steps per second: 236.06
I0902 18:09:10.341766 140131099109376 replay_runner.py:36] Average training steps per second: 236.06
I0902 18:09:10.570812 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.46
INFO:tensorflow:Starting iteration 27

Steps executed: 206 Episode length: 132 Return: -309.09656890044687
INFO:tensorflow:Average training steps per second: 228.09
I0902 18:09:19.305658 140131099109376 replay_runner.py:36] Average training steps per second: 228.09
I0902 18:09:19.507770 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -387.53
INFO:tensorflow:Starting iteration 28

Steps executed: 208 Episode length: 87 Return: -284.116701453298078
INFO:tensorflow:Average training steps per second: 226.51
I0902 18:09:28.236135 140131099109376 replay_runner.py:36] Average training steps per second: 226.51
I0902 18:09:28.407376 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.62
INFO:tensorflow:Starting iteration 29

Steps executed: 372 Episode length: 182 Return: -275.78013202969987
INFO:tensorflow:Average training steps per second: 230.39
I0902 18:09:37.199043 140131099109376 replay_runner.py:36] Average training steps per second: 230.39

Done fixed training!Episode length: 182 Return: -275.78013202969987