I0903 00:11:47.870133 139803223304192 run_experiment.py:549] Creating TrainRunner ...
I0903 00:11:47.878620 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:11:47.878746 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:11:47.878836 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:11:47.878942 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:11:47.879012 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0903 00:11:47.879108 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:11:47.879173 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:11:47.879230 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:11:47.879286 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:11:47.879388 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0903 00:11:47.879446 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:11:47.879529 139803223304192 dqn_agent.py:283] 	 seed: 1630627907878587
I0903 00:11:47.881495 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:11:47.881633 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:11:47.881779 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:11:47.881884 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:11:47.881965 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:11:47.882144 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:11:47.882326 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:11:47.882447 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:11:47.882536 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:11:47.906757 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:11:48.167751 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:11:48.177613 139803223304192 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:11:48.185150 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:11:48.185321 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:11:48.185399 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:11:48.185461 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:11:48.185521 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0903 00:11:48.185576 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:11:48.185628 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:11:48.185710 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:11:48.185768 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:11:48.185878 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0903 00:11:48.185950 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:11:48.186003 139803223304192 dqn_agent.py:283] 	 seed: 1630627908185111
I0903 00:11:48.187700 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:11:48.187853 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:11:48.187934 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:11:48.188004 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:11:48.188072 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:11:48.188161 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:11:48.188236 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:11:48.188304 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:11:48.188391 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:11:48.210658 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:11:48.227169 139803223304192 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:11:48.227456 139803223304192 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 247.77
I0903 00:11:52.263688 139803223304192 replay_runner.py:36] Average training steps per second: 247.77
I0903 00:11:52.931858 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -523.77
Steps executed: 220 Episode length: 79 Return: -567.81060441534058
INFO:tensorflow:Starting iteration 1

Steps executed: 238 Episode length: 136 Return: -359.2254401055148
INFO:tensorflow:Average training steps per second: 345.77
I0903 00:11:59.222012 139803223304192 replay_runner.py:36] Average training steps per second: 345.77
I0903 00:11:59.350219 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -527.20
INFO:tensorflow:Starting iteration 2

Steps executed: 225 Episode length: 116 Return: -321.79772108944405
INFO:tensorflow:Average training steps per second: 335.01
I0903 00:12:05.678069 139803223304192 replay_runner.py:36] Average training steps per second: 335.01
I0903 00:12:05.796846 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -430.34
INFO:tensorflow:Starting iteration 3

Steps executed: 308 Episode length: 151 Return: -543.03701470453435
INFO:tensorflow:Average training steps per second: 332.31
I0903 00:12:12.228178 139803223304192 replay_runner.py:36] Average training steps per second: 332.31
I0903 00:12:12.400020 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -522.50
INFO:tensorflow:Starting iteration 4

Steps executed: 311 Episode length: 158 Return: -234.37127770818168
INFO:tensorflow:Average training steps per second: 337.13
I0903 00:12:18.748821 139803223304192 replay_runner.py:36] Average training steps per second: 337.13
I0903 00:12:18.932955 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.34
INFO:tensorflow:Starting iteration 5

Steps executed: 315 Episode length: 315 Return: -563.86790672746578
INFO:tensorflow:Average training steps per second: 345.45
I0903 00:12:25.252435 139803223304192 replay_runner.py:36] Average training steps per second: 345.45
I0903 00:12:25.562053 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -563.87
INFO:tensorflow:Starting iteration 6

Steps executed: 671 Episode length: 671 Return: -439.56983909488468
INFO:tensorflow:Average training steps per second: 337.71
I0903 00:12:31.930169 139803223304192 replay_runner.py:36] Average training steps per second: 337.71
I0903 00:12:32.780421 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -439.57
INFO:tensorflow:Starting iteration 7
I0903 00:12:36.268664 139803223304192 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 337.73

Steps executed: 1000 Episode length: 1000 Return: -50.70017800991654
I0903 00:12:41.096770 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -50.70
INFO:tensorflow:Starting iteration 8
I0903 00:12:44.501575 139803223304192 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 347.46

Steps executed: 909 Episode length: 909 Return: -386.062287604510654
I0903 00:12:49.090916 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -386.06
INFO:tensorflow:Starting iteration 9
I0903 00:12:52.437320 139803223304192 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 322.07

Steps executed: 1000 Episode length: 1000 Return: -104.37535708996299
I0903 00:12:57.367841 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.38
INFO:tensorflow:Starting iteration 10
I0903 00:13:00.582818 139803223304192 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 320.38

Steps executed: 593 Episode length: 593 Return: -357.0390567888394299
I0903 00:13:04.473691 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -357.04
INFO:tensorflow:Starting iteration 11

Steps executed: 230 Episode length: 230 Return: -506.2885136543314299
INFO:tensorflow:Average training steps per second: 338.08
I0903 00:13:10.747550 139803223304192 replay_runner.py:36] Average training steps per second: 338.08
I0903 00:13:10.935606 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -506.29
INFO:tensorflow:Starting iteration 12

Steps executed: 346 Episode length: 346 Return: -385.8291310825063299
INFO:tensorflow:Average training steps per second: 349.58
I0903 00:13:17.222199 139803223304192 replay_runner.py:36] Average training steps per second: 349.58
I0903 00:13:17.491549 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -385.83
INFO:tensorflow:Starting iteration 13

Steps executed: 252 Episode length: 194 Return: -464.5632297899441299
INFO:tensorflow:Average training steps per second: 337.09
I0903 00:13:23.878243 139803223304192 replay_runner.py:36] Average training steps per second: 337.09
I0903 00:13:24.047900 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -434.90
INFO:tensorflow:Starting iteration 14

Steps executed: 226 Episode length: 57 Return: -140.99460256569521299
INFO:tensorflow:Average training steps per second: 338.46
I0903 00:13:30.509036 139803223304192 replay_runner.py:36] Average training steps per second: 338.46
I0903 00:13:30.627156 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.29
INFO:tensorflow:Starting iteration 15
I0903 00:13:34.146589 139803223304192 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 360.46
I0903 00:13:36.921147 139803223304192 replay_runner.py:36] Average training steps per second: 360.46

Steps executed: 584 Episode length: 584 Return: -494.0306417482405299
INFO:tensorflow:Starting iteration 16
I0903 00:13:41.393526 139803223304192 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 363.04

Steps executed: 346 Episode length: 185 Return: -203.5625954823359599
I0903 00:13:44.377100 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -238.29
INFO:tensorflow:Starting iteration 17

Steps executed: 227 Episode length: 58 Return: -112.58242498142243599
INFO:tensorflow:Average training steps per second: 355.97
I0903 00:13:50.732536 139803223304192 replay_runner.py:36] Average training steps per second: 355.97
I0903 00:13:50.845330 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.97
INFO:tensorflow:Starting iteration 18

Steps executed: 283 Episode length: 283 Return: -254.1070810893917699
INFO:tensorflow:Average training steps per second: 341.48
I0903 00:13:57.279121 139803223304192 replay_runner.py:36] Average training steps per second: 341.48
I0903 00:13:57.520859 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.11
INFO:tensorflow:Starting iteration 19
I0903 00:14:00.983011 139803223304192 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 342.97
I0903 00:14:03.898946 139803223304192 replay_runner.py:36] Average training steps per second: 342.97

Steps executed: 271 Episode length: 145 Return: -167.2098704505120399
INFO:tensorflow:Starting iteration 20
I0903 00:14:07.538133 139803223304192 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 355.38

Steps executed: 286 Episode length: 129 Return: -94.61609956251385399
I0903 00:14:10.537284 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.70
INFO:tensorflow:Starting iteration 21

Steps executed: 216 Episode length: 77 Return: -729.24321692769835399
INFO:tensorflow:Average training steps per second: 346.95
I0903 00:14:16.987678 139803223304192 replay_runner.py:36] Average training steps per second: 346.95
I0903 00:14:17.112962 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -575.63
INFO:tensorflow:Starting iteration 22

Steps executed: 224 Episode length: 118 Return: -542.9389245598028699
INFO:tensorflow:Average training steps per second: 333.35
I0903 00:14:23.722233 139803223304192 replay_runner.py:36] Average training steps per second: 333.35
I0903 00:14:23.853731 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -524.51
INFO:tensorflow:Starting iteration 23

Steps executed: 268 Episode length: 76 Return: -242.87937820173586699
INFO:tensorflow:Average training steps per second: 361.35
I0903 00:14:30.201735 139803223304192 replay_runner.py:36] Average training steps per second: 361.35
I0903 00:14:30.375722 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -449.12
INFO:tensorflow:Starting iteration 24

Steps executed: 260 Episode length: 107 Return: -134.5889310861492799
INFO:tensorflow:Average training steps per second: 357.18
I0903 00:14:36.708864 139803223304192 replay_runner.py:36] Average training steps per second: 357.18
I0903 00:14:36.875857 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.13
INFO:tensorflow:Starting iteration 25

Steps executed: 328 Episode length: 136 Return: -432.0847963909444799
INFO:tensorflow:Average training steps per second: 344.49
I0903 00:14:43.316484 139803223304192 replay_runner.py:36] Average training steps per second: 344.49
I0903 00:14:43.487291 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -351.25
INFO:tensorflow:Starting iteration 26

Steps executed: 231 Episode length: 56 Return: -395.92078201657046799
INFO:tensorflow:Average training steps per second: 335.57
I0903 00:14:49.944051 139803223304192 replay_runner.py:36] Average training steps per second: 335.57
I0903 00:14:50.072292 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -614.01
INFO:tensorflow:Starting iteration 27

Steps executed: 202 Episode length: 65 Return: -517.85030695169265799
INFO:tensorflow:Average training steps per second: 341.24
I0903 00:14:56.440904 139803223304192 replay_runner.py:36] Average training steps per second: 341.24
I0903 00:14:56.559280 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -616.27
INFO:tensorflow:Starting iteration 28

Steps executed: 257 Episode length: 105 Return: -714.2814624788044799
INFO:tensorflow:Average training steps per second: 333.62
I0903 00:15:02.989997 139803223304192 replay_runner.py:36] Average training steps per second: 333.62
I0903 00:15:03.136585 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -609.42
INFO:tensorflow:Starting iteration 29

Steps executed: 240 Episode length: 56 Return: -411.94879358473133799
INFO:tensorflow:Average training steps per second: 329.42
I0903 00:15:09.603221 139803223304192 replay_runner.py:36] Average training steps per second: 329.42

Done fixed training!Episode length: 56 Return: -411.94879358473133799