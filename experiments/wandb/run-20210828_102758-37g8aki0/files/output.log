Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0828 10:28:05.366649 140214119393280 run_experiment.py:549] Creating TrainRunner ...
I0828 10:28:05.378597 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:28:05.378895 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:28:05.378997 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:28:05.379183 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:28:05.379292 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:28:05.379401 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:28:05.379509 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:28:05.379628 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:28:05.379743 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:28:05.379850 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:28:05.379927 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:28:05.380080 140214119393280 dqn_agent.py:283] 	 seed: 1630146485378543
I0828 10:28:05.383408 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:28:05.383651 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:28:05.383831 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:28:05.384017 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:28:05.384152 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:28:05.384233 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:28:05.384356 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:28:05.384475 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:28:05.384583 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:28:05.423767 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:05.804641 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:05.819654 140214119393280 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:28:05.830155 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:28:05.830384 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:28:05.830497 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:28:05.830626 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:28:05.830823 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:28:05.831052 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:28:05.831143 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:28:05.831219 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:28:05.831297 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:28:05.831367 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:28:05.831443 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:28:05.831514 140214119393280 dqn_agent.py:283] 	 seed: 1630146485830087
I0828 10:28:05.832954 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:28:05.833066 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:28:05.833136 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:28:05.833197 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:28:05.833253 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:28:05.833325 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:28:05.833382 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:28:05.833462 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:28:05.833520 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:28:05.912954 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:05.937377 140214119393280 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:28:05.937677 140214119393280 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 170.46
I0828 10:28:11.804499 140214119393280 replay_runner.py:36] Average training steps per second: 170.46
Steps executed: 210 Episode length: 210 Return: -1196.7393904860771
I0828 10:28:13.123072 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -1196.74
INFO:tensorflow:Starting iteration 1

Steps executed: 209 Episode length: 71 Return: -462.899314378169671
INFO:tensorflow:Average training steps per second: 231.47
I0828 10:28:21.879279 140214119393280 replay_runner.py:36] Average training steps per second: 231.47
I0828 10:28:22.047187 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -477.41
INFO:tensorflow:Starting iteration 2

Steps executed: 202 Episode length: 56 Return: -90.3650353881465791
INFO:tensorflow:Average training steps per second: 231.90
I0828 10:28:30.694870 140214119393280 replay_runner.py:36] Average training steps per second: 231.90
I0828 10:28:30.826451 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.89
INFO:tensorflow:Starting iteration 3

Steps executed: 243 Episode length: 51 Return: -78.4164668303828371
INFO:tensorflow:Average training steps per second: 230.83
I0828 10:28:39.571007 140214119393280 replay_runner.py:36] Average training steps per second: 230.83
I0828 10:28:39.753602 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.20
INFO:tensorflow:Starting iteration 4

Steps executed: 251 Episode length: 73 Return: -126.246365004607211
INFO:tensorflow:Average training steps per second: 231.87
I0828 10:28:48.472913 140214119393280 replay_runner.py:36] Average training steps per second: 231.87
I0828 10:28:48.710702 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.19
INFO:tensorflow:Starting iteration 5

Steps executed: 220 Episode length: 76 Return: -586.438845161068611
INFO:tensorflow:Average training steps per second: 232.34
I0828 10:28:57.519553 140214119393280 replay_runner.py:36] Average training steps per second: 232.34
I0828 10:28:57.709944 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -438.79
INFO:tensorflow:Starting iteration 6

Steps executed: 243 Episode length: 54 Return: -429.788538015178761
INFO:tensorflow:Average training steps per second: 229.43
I0828 10:29:06.418066 140214119393280 replay_runner.py:36] Average training steps per second: 229.43
I0828 10:29:06.631121 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -499.14
INFO:tensorflow:Starting iteration 7

Steps executed: 250 Episode length: 97 Return: -7.57946858892844961
INFO:tensorflow:Average training steps per second: 231.73
I0828 10:29:15.344356 140214119393280 replay_runner.py:36] Average training steps per second: 231.73
I0828 10:29:15.538058 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.74
INFO:tensorflow:Starting iteration 8

Steps executed: 268 Episode length: 109 Return: -801.63384729795561
INFO:tensorflow:Average training steps per second: 232.80
I0828 10:29:24.091514 140214119393280 replay_runner.py:36] Average training steps per second: 232.80
I0828 10:29:24.329112 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -602.64
INFO:tensorflow:Starting iteration 9

Steps executed: 228 Episode length: 73 Return: -450.068410611571471
INFO:tensorflow:Average training steps per second: 231.36
I0828 10:29:32.950963 140214119393280 replay_runner.py:36] Average training steps per second: 231.36
I0828 10:29:33.160830 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -498.58
INFO:tensorflow:Starting iteration 10

Steps executed: 251 Episode length: 54 Return: -172.918274370476721
INFO:tensorflow:Average training steps per second: 233.48
I0828 10:29:41.817918 140214119393280 replay_runner.py:36] Average training steps per second: 233.48
I0828 10:29:42.000431 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -386.55
INFO:tensorflow:Starting iteration 11

Steps executed: 219 Episode length: 115 Return: -594.22203703196561
INFO:tensorflow:Average training steps per second: 231.02
I0828 10:29:50.824152 140214119393280 replay_runner.py:36] Average training steps per second: 231.02
I0828 10:29:51.035573 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -666.53
INFO:tensorflow:Starting iteration 12

Steps executed: 335 Episode length: 237 Return: -2223.8634214057142
INFO:tensorflow:Average training steps per second: 226.88
I0828 10:29:59.857912 140214119393280 replay_runner.py:36] Average training steps per second: 226.88
I0828 10:30:00.227597 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -1374.25
INFO:tensorflow:Starting iteration 13

Steps executed: 262 Episode length: 73 Return: -375.897079821238342
INFO:tensorflow:Average training steps per second: 231.84
I0828 10:30:08.880250 140214119393280 replay_runner.py:36] Average training steps per second: 231.84
I0828 10:30:09.116515 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -523.25
INFO:tensorflow:Starting iteration 14

Steps executed: 251 Episode length: 82 Return: -448.358202707127652
INFO:tensorflow:Average training steps per second: 234.11
I0828 10:30:17.831576 140214119393280 replay_runner.py:36] Average training steps per second: 234.11
I0828 10:30:18.044154 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -469.46
INFO:tensorflow:Starting iteration 15

Steps executed: 243 Episode length: 82 Return: -759.624416079862542
INFO:tensorflow:Average training steps per second: 235.59
I0828 10:30:26.530368 140214119393280 replay_runner.py:36] Average training steps per second: 235.59
I0828 10:30:26.738571 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -507.48
INFO:tensorflow:Starting iteration 16
I0828 10:30:30.950019 140214119393280 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 230.83
I0828 10:30:35.282557 140214119393280 replay_runner.py:36] Average training steps per second: 230.83

Steps executed: 247 Episode length: 53 Return: -438.509612567940962
INFO:tensorflow:Starting iteration 17

Steps executed: 210 Episode length: 69 Return: -632.476405698127962
INFO:tensorflow:Average training steps per second: 232.14
I0828 10:30:44.116000 140214119393280 replay_runner.py:36] Average training steps per second: 232.14
I0828 10:30:44.292698 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -614.42
INFO:tensorflow:Starting iteration 18

Steps executed: 262 Episode length: 76 Return: -728.199959734698242
INFO:tensorflow:Average training steps per second: 234.46
I0828 10:30:52.934426 140214119393280 replay_runner.py:36] Average training steps per second: 234.46
I0828 10:30:53.141420 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -598.56
INFO:tensorflow:Starting iteration 19
I0828 10:30:57.367012 140214119393280 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 248.18

Steps executed: 200 Episode length: 81 Return: -574.964188258306742
I0828 10:31:01.562788 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -508.19
INFO:tensorflow:Starting iteration 20

Steps executed: 268 Episode length: 73 Return: -715.688900670289242
INFO:tensorflow:Average training steps per second: 238.20
I0828 10:31:10.151291 140214119393280 replay_runner.py:36] Average training steps per second: 238.20
I0828 10:31:10.354041 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -612.12
INFO:tensorflow:Starting iteration 21

Steps executed: 251 Episode length: 73 Return: -547.924581434797762
INFO:tensorflow:Average training steps per second: 229.33
I0828 10:31:19.028175 140214119393280 replay_runner.py:36] Average training steps per second: 229.33
I0828 10:31:19.253350 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -634.11
INFO:tensorflow:Starting iteration 22

Steps executed: 228 Episode length: 71 Return: -138.660401809217722
INFO:tensorflow:Average training steps per second: 225.90
I0828 10:31:28.090924 140214119393280 replay_runner.py:36] Average training steps per second: 225.90
I0828 10:31:28.233276 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.24
INFO:tensorflow:Starting iteration 23

Steps executed: 200 Episode length: 63 Return: -680.828661988646722
INFO:tensorflow:Average training steps per second: 227.98
I0828 10:31:36.896562 140214119393280 replay_runner.py:36] Average training steps per second: 227.98
I0828 10:31:37.070080 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -678.30
INFO:tensorflow:Starting iteration 24

Steps executed: 272 Episode length: 76 Return: -178.877558640783552
INFO:tensorflow:Average training steps per second: 228.03
I0828 10:31:45.897594 140214119393280 replay_runner.py:36] Average training steps per second: 228.03
I0828 10:31:46.100947 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -252.57
INFO:tensorflow:Starting iteration 25

Steps executed: 246 Episode length: 85 Return: -645.723248317768935
INFO:tensorflow:Average training steps per second: 227.10
I0828 10:31:54.874691 140214119393280 replay_runner.py:36] Average training steps per second: 227.10
I0828 10:31:55.080463 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -468.82
INFO:tensorflow:Starting iteration 26

Steps executed: 263 Episode length: 68 Return: -628.646226944541365
INFO:tensorflow:Average training steps per second: 224.57
I0828 10:32:03.862800 140214119393280 replay_runner.py:36] Average training steps per second: 224.57
I0828 10:32:04.081765 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -527.03
INFO:tensorflow:Starting iteration 27

Steps executed: 220 Episode length: 89 Return: -156.516347328200965
INFO:tensorflow:Average training steps per second: 222.49
I0828 10:32:13.061950 140214119393280 replay_runner.py:36] Average training steps per second: 222.49
I0828 10:32:13.212299 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.98
INFO:tensorflow:Starting iteration 28

Steps executed: 302 Episode length: 146 Return: -275.21168701601135
INFO:tensorflow:Average training steps per second: 222.35
I0828 10:32:22.095236 140214119393280 replay_runner.py:36] Average training steps per second: 222.35
I0828 10:32:22.345771 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.45
INFO:tensorflow:Starting iteration 29

Steps executed: 207 Episode length: 57 Return: -401.169350768246665
INFO:tensorflow:Average training steps per second: 222.80
I0828 10:32:31.133167 140214119393280 replay_runner.py:36] Average training steps per second: 222.80

Done fixed training!Episode length: 57 Return: -401.169350768246665