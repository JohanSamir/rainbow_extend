Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0828 10:42:27.190554 140251198892032 run_experiment.py:549] Creating TrainRunner ...
I0828 10:42:27.200951 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:27.201241 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:27.201391 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:27.201525 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:27.201669 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:27.201754 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:27.201827 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:27.201900 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:27.202057 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:27.202206 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:27.202325 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:27.202381 140251198892032 dqn_agent.py:283] 	 seed: 1630147347200893
I0828 10:42:27.205515 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:27.205708 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:27.205852 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:27.206000 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:27.206356 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:27.206532 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:27.206716 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:27.206859 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:27.207041 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:27.246533 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:27.606683 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:27.619777 140251198892032 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:42:27.627876 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:27.628155 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:27.628314 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:27.628403 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:27.628521 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:27.628676 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:27.628965 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:27.629134 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:27.629273 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:27.629386 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:27.629584 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:27.629681 140251198892032 dqn_agent.py:283] 	 seed: 1630147347627830
I0828 10:42:27.632678 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:27.632917 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:27.633055 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:27.633148 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:27.633218 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:27.633309 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:27.633517 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:27.633658 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:27.633752 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:27.663971 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:27.720762 140251198892032 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:42:27.721036 140251198892032 replay_runner.py:41] Starting iteration 0
Steps executed: 221 Episode length: 109 Return: -668.3236588025889
INFO:tensorflow:Average training steps per second: 175.04
I0828 10:42:33.434373 140251198892032 replay_runner.py:36] Average training steps per second: 175.04
I0828 10:42:34.614474 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -670.61
INFO:tensorflow:Starting iteration 1

Steps executed: 476 Episode length: 329 Return: -651.4776580319221
INFO:tensorflow:Average training steps per second: 239.17
I0828 10:42:43.213218 140251198892032 replay_runner.py:36] Average training steps per second: 239.17
I0828 10:42:43.775130 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -601.75
INFO:tensorflow:Starting iteration 2

Steps executed: 133 Episode length: 133 Return: -243.76053329158458
INFO:tensorflow:Average training steps per second: 234.12

Steps executed: 1133 Episode length: 1000 Return: -178.09523615464613
I0828 10:42:54.973795 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.93
INFO:tensorflow:Starting iteration 3

Steps executed: 136 Episode length: 136 Return: -84.93119443741264613
INFO:tensorflow:Average training steps per second: 233.79

Steps executed: 1136 Episode length: 1000 Return: -208.03164338887765
I0828 10:43:07.062935 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.48
INFO:tensorflow:Starting iteration 4
I0828 10:43:11.300050 140251198892032 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 233.84

Steps executed: 1000 Episode length: 1000 Return: -250.31383175440232
I0828 10:43:18.081174 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -250.31
INFO:tensorflow:Starting iteration 5
I0828 10:43:22.425970 140251198892032 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 245.14

Steps executed: 1000 Episode length: 1000 Return: -101.73247157060881
I0828 10:43:28.617603 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.73
INFO:tensorflow:Starting iteration 6
I0828 10:43:32.908903 140251198892032 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 232.99

Steps executed: 1000 Episode length: 1000 Return: -145.14628900277754
I0828 10:43:40.202254 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.15
INFO:tensorflow:Starting iteration 7
I0828 10:43:44.478137 140251198892032 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 223.25

Steps executed: 1000 Episode length: 1000 Return: -205.00659986384662
I0828 10:43:52.859853 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.01
INFO:tensorflow:Starting iteration 8
I0828 10:43:57.238878 140251198892032 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 229.96

Steps executed: 1000 Episode length: 1000 Return: -151.54118575626922
I0828 10:44:04.836517 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.54
INFO:tensorflow:Starting iteration 9

Steps executed: 90 Episode length: 90 Return: -136.958820351276626922
INFO:tensorflow:Average training steps per second: 228.76

Steps executed: 823 Episode length: 733 Return: -109.4145032240534822
I0828 10:44:15.614287 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.19
INFO:tensorflow:Starting iteration 10
I0828 10:44:19.990339 140251198892032 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 228.75
I0828 10:44:24.362546 140251198892032 replay_runner.py:36] Average training steps per second: 228.75

Steps executed: 566 Episode length: 566 Return: -237.9020924317724822
INFO:tensorflow:Starting iteration 11
I0828 10:44:29.800684 140251198892032 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 228.08

Steps executed: 1000 Episode length: 1000 Return: -157.03932247139923
I0828 10:44:37.152967 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -157.04
INFO:tensorflow:Starting iteration 12

Steps executed: 622 Episode length: 462 Return: 25.221739971111546923
INFO:tensorflow:Average training steps per second: 223.27
I0828 10:44:45.951102 140251198892032 replay_runner.py:36] Average training steps per second: 223.27
I0828 10:44:46.780951 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -34.49
INFO:tensorflow:Starting iteration 13
I0828 10:44:51.019294 140251198892032 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 226.39

Steps executed: 546 Episode length: 546 Return: -125.5032954437351923
I0828 10:44:56.309092 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.50
INFO:tensorflow:Starting iteration 14

Steps executed: 395 Episode length: 223 Return: -10.99264784556325523
INFO:tensorflow:Average training steps per second: 230.50
I0828 10:45:04.746083 140251198892032 replay_runner.py:36] Average training steps per second: 230.50
I0828 10:45:05.141624 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -1.07
INFO:tensorflow:Starting iteration 15
I0828 10:45:09.300385 140251198892032 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 238.85
I0828 10:45:13.487404 140251198892032 replay_runner.py:36] Average training steps per second: 238.85

Steps executed: 222 Episode length: 106 Return: -58.20830894292328523
INFO:tensorflow:Starting iteration 16

Steps executed: 364 Episode length: 364 Return: -337.2227145381789323
INFO:tensorflow:Average training steps per second: 235.05
I0828 10:45:22.058025 140251198892032 replay_runner.py:36] Average training steps per second: 235.05
I0828 10:45:22.576493 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -337.22
INFO:tensorflow:Starting iteration 17

Steps executed: 496 Episode length: 322 Return: -218.6772124515290423
INFO:tensorflow:Average training steps per second: 250.97
I0828 10:45:30.573994 140251198892032 replay_runner.py:36] Average training steps per second: 250.97
I0828 10:45:31.098341 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.11
INFO:tensorflow:Starting iteration 18
I0828 10:45:35.112263 140251198892032 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 256.32

Steps executed: 543 Episode length: 543 Return: -593.1369820680650423
I0828 10:45:39.867995 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -593.14
INFO:tensorflow:Starting iteration 19

Steps executed: 357 Episode length: 357 Return: -124.7466506967672323
INFO:tensorflow:Average training steps per second: 256.10
I0828 10:45:47.773639 140251198892032 replay_runner.py:36] Average training steps per second: 256.10
I0828 10:45:48.182555 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.75
INFO:tensorflow:Starting iteration 20

Steps executed: 292 Episode length: 106 Return: 0.9720200529098406323
INFO:tensorflow:Average training steps per second: 263.82
I0828 10:45:55.884549 140251198892032 replay_runner.py:36] Average training steps per second: 263.82
I0828 10:45:56.078238 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -15.40
INFO:tensorflow:Starting iteration 21

Steps executed: 477 Episode length: 303 Return: -12.11303781210230623
INFO:tensorflow:Average training steps per second: 269.17
I0828 10:46:03.651788 140251198892032 replay_runner.py:36] Average training steps per second: 269.17
I0828 10:46:04.091058 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -59.04
INFO:tensorflow:Starting iteration 22
I0828 10:46:07.737638 140251198892032 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 282.50
I0828 10:46:11.277766 140251198892032 replay_runner.py:36] Average training steps per second: 282.50

Steps executed: 290 Episode length: 290 Return: -356.2527753657687623
INFO:tensorflow:Starting iteration 23

Steps executed: 358 Episode length: 163 Return: -204.2257627743887323
INFO:tensorflow:Average training steps per second: 302.25
I0828 10:46:18.564696 140251198892032 replay_runner.py:36] Average training steps per second: 302.25
I0828 10:46:18.814066 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -540.88
INFO:tensorflow:Starting iteration 24

Steps executed: 305 Episode length: 127 Return: -58.97880907662642323
INFO:tensorflow:Average training steps per second: 312.64
I0828 10:46:25.313387 140251198892032 replay_runner.py:36] Average training steps per second: 312.64
I0828 10:46:25.517215 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -27.61
INFO:tensorflow:Starting iteration 25

Steps executed: 616 Episode length: 522 Return: 265.33223922969637323
INFO:tensorflow:Average training steps per second: 319.21
I0828 10:46:31.911679 140251198892032 replay_runner.py:36] Average training steps per second: 319.21
I0828 10:46:32.524960 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: 127.04
INFO:tensorflow:Starting iteration 26

Steps executed: 268 Episode length: 268 Return: -127.6481808480157823
INFO:tensorflow:Average training steps per second: 328.30
I0828 10:46:38.827790 140251198892032 replay_runner.py:36] Average training steps per second: 328.30
I0828 10:46:39.062644 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.65
INFO:tensorflow:Starting iteration 27

Steps executed: 227 Episode length: 69 Return: -158.61383346291125823
INFO:tensorflow:Average training steps per second: 352.48
I0828 10:46:45.152834 140251198892032 replay_runner.py:36] Average training steps per second: 352.48
I0828 10:46:45.255044 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.36
INFO:tensorflow:Starting iteration 28

Steps executed: 234 Episode length: 145 Return: 253.89133751356295823
INFO:tensorflow:Average training steps per second: 328.05
I0828 10:46:51.357188 140251198892032 replay_runner.py:36] Average training steps per second: 328.05
I0828 10:46:51.458726 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: 139.82
INFO:tensorflow:Starting iteration 29

Steps executed: 112 Episode length: 112 Return: -130.8462123714131723
INFO:tensorflow:Average training steps per second: 342.87

Steps executed: 795 Episode length: 683 Return: 244.65460947077041723

Done fixed training!Episode length: 683 Return: 244.65460947077041723