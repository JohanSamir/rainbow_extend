Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0902 11:26:35.780361 140481598638080 run_experiment.py:549] Creating TrainRunner ...
I0902 11:26:35.791693 140481598638080 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 11:26:35.791985 140481598638080 dqn_agent.py:272] 	 gamma: 0.990000
I0902 11:26:35.792135 140481598638080 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 11:26:35.792254 140481598638080 dqn_agent.py:274] 	 min_replay_history: 500
I0902 11:26:35.792362 140481598638080 dqn_agent.py:275] 	 update_period: 4
I0902 11:26:35.792477 140481598638080 dqn_agent.py:276] 	 target_update_period: 300
I0902 11:26:35.792585 140481598638080 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 11:26:35.792742 140481598638080 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 11:26:35.792890 140481598638080 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 11:26:35.793013 140481598638080 dqn_agent.py:280] 	 optimizer: adam
I0902 11:26:35.793276 140481598638080 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 11:26:35.793409 140481598638080 dqn_agent.py:283] 	 seed: 1630581995791631
I0902 11:26:35.796378 140481598638080 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 11:26:35.796557 140481598638080 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 11:26:35.796712 140481598638080 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 11:26:35.796854 140481598638080 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 11:26:35.796972 140481598638080 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 11:26:35.797080 140481598638080 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 11:26:35.797187 140481598638080 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 11:26:35.797332 140481598638080 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 11:26:35.797441 140481598638080 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 11:26:35.979452 140481598638080 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:26:36.420434 140481598638080 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:26:36.434092 140481598638080 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 11:26:36.444263 140481598638080 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 11:26:36.444496 140481598638080 dqn_agent.py:272] 	 gamma: 0.990000
I0902 11:26:36.444601 140481598638080 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 11:26:36.444685 140481598638080 dqn_agent.py:274] 	 min_replay_history: 500
I0902 11:26:36.444773 140481598638080 dqn_agent.py:275] 	 update_period: 4
I0902 11:26:36.444861 140481598638080 dqn_agent.py:276] 	 target_update_period: 300
I0902 11:26:36.444919 140481598638080 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 11:26:36.444989 140481598638080 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 11:26:36.445094 140481598638080 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 11:26:36.445153 140481598638080 dqn_agent.py:280] 	 optimizer: adam
I0902 11:26:36.445428 140481598638080 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 11:26:36.445734 140481598638080 dqn_agent.py:283] 	 seed: 1630581996444179
I0902 11:26:36.449077 140481598638080 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 11:26:36.449265 140481598638080 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 11:26:36.449362 140481598638080 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 11:26:36.449485 140481598638080 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 11:26:36.449641 140481598638080 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 11:26:36.449811 140481598638080 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 11:26:36.449973 140481598638080 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 11:26:36.450194 140481598638080 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 11:26:36.450337 140481598638080 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 11:26:36.497102 140481598638080 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:26:36.528935 140481598638080 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 11:26:36.529256 140481598638080 replay_runner.py:41] Starting iteration 0
Steps executed: 157 Episode length: 80 Return: -239.04724590962212
INFO:tensorflow:Average training steps per second: 131.48
I0902 11:26:44.135440 140481598638080 replay_runner.py:36] Average training steps per second: 131.48

Steps executed: 282 Episode length: 125 Return: -294.73852546939986
INFO:tensorflow:Starting iteration 1

Steps executed: 313 Episode length: 132 Return: -230.64246428132937
INFO:tensorflow:Average training steps per second: 215.92
I0902 11:26:54.440140 140481598638080 replay_runner.py:36] Average training steps per second: 215.92
I0902 11:26:54.736347 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -267.11
INFO:tensorflow:Starting iteration 2
I0902 11:26:58.987131 140481598638080 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 230.86

Steps executed: 328 Episode length: 328 Return: -248.63615056632697
I0902 11:27:03.827501 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.64
INFO:tensorflow:Starting iteration 3

Steps executed: 655 Episode length: 655 Return: -77.062099627296227
INFO:tensorflow:Average training steps per second: 262.64
I0902 11:27:11.600498 140481598638080 replay_runner.py:36] Average training steps per second: 262.64
I0902 11:27:13.053836 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.06
INFO:tensorflow:Starting iteration 4
I0902 11:27:17.271235 140481598638080 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 236.07

Steps executed: 588 Episode length: 588 Return: -311.86106341168716
I0902 11:27:22.368574 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.86
INFO:tensorflow:Starting iteration 5
I0902 11:27:26.648732 140481598638080 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 221.39

Steps executed: 971 Episode length: 971 Return: -443.19213047090016
I0902 11:27:33.083374 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -443.19
INFO:tensorflow:Starting iteration 6

Steps executed: 322 Episode length: 322 Return: -738.59913219478296
INFO:tensorflow:Average training steps per second: 213.56
I0902 11:27:42.183456 140481598638080 replay_runner.py:36] Average training steps per second: 213.56
I0902 11:27:42.644364 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -738.60
INFO:tensorflow:Starting iteration 7

Steps executed: 454 Episode length: 454 Return: -542.16983120214796
INFO:tensorflow:Average training steps per second: 213.69
I0902 11:27:51.768252 140481598638080 replay_runner.py:36] Average training steps per second: 213.69
I0902 11:27:52.449409 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -542.17
INFO:tensorflow:Starting iteration 8
I0902 11:27:56.626300 140481598638080 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 211.96

Steps executed: 554 Episode length: 554 Return: -388.58662011023336
I0902 11:28:02.440304 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -388.59
INFO:tensorflow:Starting iteration 9
I0902 11:28:06.890055 140481598638080 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 214.00

Steps executed: 733 Episode length: 733 Return: -292.22299274833726
I0902 11:28:13.158967 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -292.22
INFO:tensorflow:Starting iteration 10
I0902 11:28:17.694596 140481598638080 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 212.79
I0902 11:28:22.394714 140481598638080 replay_runner.py:36] Average training steps per second: 212.79

Steps executed: 764 Episode length: 764 Return: -299.24640446307556
INFO:tensorflow:Starting iteration 11
I0902 11:28:28.187592 140481598638080 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 212.64
I0902 11:28:32.891174 140481598638080 replay_runner.py:36] Average training steps per second: 212.64

Steps executed: 1000 Episode length: 1000 Return: -256.05718861069676
INFO:tensorflow:Starting iteration 12
I0902 11:28:40.229910 140481598638080 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 213.57

Steps executed: 1000 Episode length: 1000 Return: -129.48669986210663
I0902 11:28:48.457938 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.49
INFO:tensorflow:Starting iteration 13
I0902 11:28:52.813008 140481598638080 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 216.12

Steps executed: 1000 Episode length: 1000 Return: -124.12013091259378
I0902 11:29:00.842755 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.12
INFO:tensorflow:Starting iteration 14
I0902 11:29:05.243085 140481598638080 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 211.26

Steps executed: 1000 Episode length: 1000 Return: -90.053950933959958
I0902 11:29:12.844399 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.05
INFO:tensorflow:Starting iteration 15
I0902 11:29:17.242163 140481598638080 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 212.79

Steps executed: 301 Episode length: 130 Return: -509.6879475491669258
I0902 11:29:22.278214 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.39
INFO:tensorflow:Starting iteration 16

Steps executed: 163 Episode length: 163 Return: -132.3384837612727858
INFO:tensorflow:Average training steps per second: 209.36

Steps executed: 738 Episode length: 575 Return: -579.1451436819738858
I0902 11:29:33.103239 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -355.74
INFO:tensorflow:Starting iteration 17
I0902 11:29:37.516061 140481598638080 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 215.23

Steps executed: 232 Episode length: 232 Return: -425.8438095201650558
I0902 11:29:42.449087 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -425.84
INFO:tensorflow:Starting iteration 18

Steps executed: 123 Episode length: 123 Return: -427.5839087535148358
INFO:tensorflow:Average training steps per second: 214.93
I0902 11:29:51.523578 140481598638080 replay_runner.py:36] Average training steps per second: 214.93

Steps executed: 244 Episode length: 121 Return: -863.4883225811706358
INFO:tensorflow:Starting iteration 19

Steps executed: 263 Episode length: 74 Return: -337.80774720730722458
INFO:tensorflow:Average training steps per second: 218.28
I0902 11:30:00.726832 140481598638080 replay_runner.py:36] Average training steps per second: 218.28
I0902 11:30:00.958981 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -564.43
INFO:tensorflow:Starting iteration 20

Steps executed: 272 Episode length: 124 Return: -374.6640505973095458
INFO:tensorflow:Average training steps per second: 241.75
I0902 11:30:09.291542 140481598638080 replay_runner.py:36] Average training steps per second: 241.75
I0902 11:30:09.489763 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.12
INFO:tensorflow:Starting iteration 21

Steps executed: 254 Episode length: 123 Return: -608.7775123390769458
INFO:tensorflow:Average training steps per second: 274.13
I0902 11:30:17.073592 140481598638080 replay_runner.py:36] Average training steps per second: 274.13
I0902 11:30:17.246588 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -546.41
INFO:tensorflow:Starting iteration 22
I0902 11:30:20.870514 140481598638080 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 313.64

Steps executed: 287 Episode length: 129 Return: -549.9810054804046458
I0902 11:30:24.209335 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -219.68
INFO:tensorflow:Starting iteration 23

Steps executed: 319 Episode length: 143 Return: -324.4491378496916458
INFO:tensorflow:Average training steps per second: 336.77
I0902 11:30:30.643589 140481598638080 replay_runner.py:36] Average training steps per second: 336.77
I0902 11:30:30.802263 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -403.73
INFO:tensorflow:Starting iteration 24

Steps executed: 208 Episode length: 99 Return: -781.75977368392366458
INFO:tensorflow:Average training steps per second: 337.75
I0902 11:30:37.250895 140481598638080 replay_runner.py:36] Average training steps per second: 337.75
I0902 11:30:37.353784 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.33
INFO:tensorflow:Starting iteration 25

Steps executed: 204 Episode length: 140 Return: -495.5794204331155458
INFO:tensorflow:Average training steps per second: 332.12
I0902 11:30:43.849181 140481598638080 replay_runner.py:36] Average training steps per second: 332.12
I0902 11:30:43.951878 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.08
INFO:tensorflow:Starting iteration 26

Steps executed: 204 Episode length: 127 Return: -481.3563790658303458
INFO:tensorflow:Average training steps per second: 329.06
I0902 11:30:50.463319 140481598638080 replay_runner.py:36] Average training steps per second: 329.06
I0902 11:30:50.547824 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -339.21
INFO:tensorflow:Starting iteration 27

Steps executed: 220 Episode length: 61 Return: -103.77494938976051458
INFO:tensorflow:Average training steps per second: 310.52
I0902 11:30:57.161206 140481598638080 replay_runner.py:36] Average training steps per second: 310.52
I0902 11:30:57.276392 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -317.70
INFO:tensorflow:Starting iteration 28

Steps executed: 273 Episode length: 76 Return: -177.88069229232196558
INFO:tensorflow:Average training steps per second: 314.52
I0902 11:31:03.668486 140481598638080 replay_runner.py:36] Average training steps per second: 314.52
I0902 11:31:03.796978 140481598638080 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.24
INFO:tensorflow:Starting iteration 29

Steps executed: 244 Episode length: 52 Return: -140.69980667808048558
INFO:tensorflow:Average training steps per second: 336.12
I0902 11:31:10.065692 140481598638080 replay_runner.py:36] Average training steps per second: 336.12

Done fixed training!Episode length: 52 Return: -140.69980667808048558