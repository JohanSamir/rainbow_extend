Loaded trained dqn in cartpole
Training fixed agent 9, please be patient, may be a while...
I0901 12:49:57.309896 140162147342336 run_experiment.py:549] Creating TrainRunner ...
I0901 12:49:57.320158 140162147342336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:49:57.320527 140162147342336 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:49:57.320701 140162147342336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:49:57.320827 140162147342336 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:49:57.320917 140162147342336 dqn_agent.py:275] 	 update_period: 4
I0901 12:49:57.321039 140162147342336 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:49:57.321211 140162147342336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:49:57.321368 140162147342336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:49:57.321492 140162147342336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:49:57.321659 140162147342336 dqn_agent.py:280] 	 optimizer: adam
I0901 12:49:57.321800 140162147342336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:49:57.321940 140162147342336 dqn_agent.py:283] 	 seed: 1630500597320080
I0901 12:49:57.325285 140162147342336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:49:57.325451 140162147342336 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:49:57.325577 140162147342336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:49:57.325675 140162147342336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:49:57.325757 140162147342336 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:49:57.325832 140162147342336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:49:57.325951 140162147342336 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:49:57.326030 140162147342336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:49:57.326134 140162147342336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:49:57.486916 140162147342336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:49:58.012453 140162147342336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:49:58.028164 140162147342336 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:49:58.042783 140162147342336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:49:58.043148 140162147342336 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:49:58.043322 140162147342336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:49:58.043416 140162147342336 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:49:58.043501 140162147342336 dqn_agent.py:275] 	 update_period: 4
I0901 12:49:58.043578 140162147342336 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:49:58.043660 140162147342336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:49:58.043712 140162147342336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:49:58.043763 140162147342336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:49:58.043815 140162147342336 dqn_agent.py:280] 	 optimizer: adam
I0901 12:49:58.043866 140162147342336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:49:58.043918 140162147342336 dqn_agent.py:283] 	 seed: 1630500598042717
I0901 12:49:58.045590 140162147342336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:49:58.045707 140162147342336 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:49:58.045780 140162147342336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:49:58.045843 140162147342336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:49:58.045903 140162147342336 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:49:58.045996 140162147342336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:49:58.046074 140162147342336 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:49:58.046207 140162147342336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:49:58.046314 140162147342336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:49:58.080609 140162147342336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:49:58.103432 140162147342336 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:49:58.103632 140162147342336 replay_runner.py:41] Starting iteration 0
Steps executed: 207 Episode length: 42 Return: 42.0
INFO:tensorflow:Average training steps per second: 145.86
I0901 12:50:04.959552 140162147342336 replay_runner.py:36] Average training steps per second: 145.86
I0901 12:50:06.211011 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 41.40
INFO:tensorflow:Starting iteration 1

Steps executed: 208 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 181.67
I0901 12:50:11.904610 140162147342336 replay_runner.py:36] Average training steps per second: 181.67
I0901 12:50:12.057041 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.45
INFO:tensorflow:Starting iteration 2

Steps executed: 216 Episode length: 46 Return: 46.0
INFO:tensorflow:Average training steps per second: 189.88
I0901 12:50:17.499168 140162147342336 replay_runner.py:36] Average training steps per second: 189.88
I0901 12:50:17.655173 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 43.20
INFO:tensorflow:Starting iteration 3
I0901 12:50:17.842740 140162147342336 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 194.65

Steps executed: 256 Episode length: 110 Return: 110.0
I0901 12:50:23.153246 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 128.00
INFO:tensorflow:Starting iteration 4

Steps executed: 212 Episode length: 56 Return: 56.0.0
INFO:tensorflow:Average training steps per second: 193.73
I0901 12:50:28.496056 140162147342336 replay_runner.py:36] Average training steps per second: 193.73
I0901 12:50:28.649247 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 53.00
INFO:tensorflow:Starting iteration 5

Steps executed: 202 Episode length: 67 Return: 67.0.0
INFO:tensorflow:Average training steps per second: 203.44
I0901 12:50:33.825579 140162147342336 replay_runner.py:36] Average training steps per second: 203.44
I0901 12:50:33.996524 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 67.33
INFO:tensorflow:Starting iteration 6

Steps executed: 297 Episode length: 101 Return: 101.0
INFO:tensorflow:Average training steps per second: 190.01
I0901 12:50:39.452439 140162147342336 replay_runner.py:36] Average training steps per second: 190.01
I0901 12:50:39.636101 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 99.00
INFO:tensorflow:Starting iteration 7

Steps executed: 247 Episode length: 120 Return: 120.0
INFO:tensorflow:Average training steps per second: 196.14
I0901 12:50:44.968046 140162147342336 replay_runner.py:36] Average training steps per second: 196.14
I0901 12:50:45.133606 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 123.50
INFO:tensorflow:Starting iteration 8

Steps executed: 264 Episode length: 68 Return: 68.0.0
INFO:tensorflow:Average training steps per second: 186.07
I0901 12:50:50.693422 140162147342336 replay_runner.py:36] Average training steps per second: 186.07
I0901 12:50:50.874406 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 66.00
INFO:tensorflow:Starting iteration 9

Steps executed: 232 Episode length: 97 Return: 97.0.0
INFO:tensorflow:Average training steps per second: 193.28
I0901 12:50:56.243497 140162147342336 replay_runner.py:36] Average training steps per second: 193.28
I0901 12:50:56.404881 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 116.00
INFO:tensorflow:Starting iteration 10

Steps executed: 369 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 189.12
I0901 12:51:01.889278 140162147342336 replay_runner.py:36] Average training steps per second: 189.12
I0901 12:51:02.155898 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 184.50
INFO:tensorflow:Starting iteration 11

Steps executed: 368 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 189.73
I0901 12:51:07.618036 140162147342336 replay_runner.py:36] Average training steps per second: 189.73
I0901 12:51:07.858509 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 184.00
INFO:tensorflow:Starting iteration 12

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 188.49
I0901 12:51:13.357011 140162147342336 replay_runner.py:36] Average training steps per second: 188.49
I0901 12:51:13.500954 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 13
I0901 12:51:13.692919 140162147342336 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 188.80
I0901 12:51:18.990001 140162147342336 replay_runner.py:36] Average training steps per second: 188.80
I0901 12:51:19.136782 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 14

Steps executed: 287 Episode length: 147 Return: 147.0
INFO:tensorflow:Average training steps per second: 181.85
I0901 12:51:24.832739 140162147342336 replay_runner.py:36] Average training steps per second: 181.85
I0901 12:51:25.038249 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 143.50
INFO:tensorflow:Starting iteration 15

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 189.89
I0901 12:51:30.501846 140162147342336 replay_runner.py:36] Average training steps per second: 189.89
I0901 12:51:30.644503 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 16

Steps executed: 268 Episode length: 134 Return: 134.0
INFO:tensorflow:Average training steps per second: 191.04
I0901 12:51:36.077668 140162147342336 replay_runner.py:36] Average training steps per second: 191.04
I0901 12:51:36.255819 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 134.00
INFO:tensorflow:Starting iteration 17

Steps executed: 277 Episode length: 138 Return: 138.0
INFO:tensorflow:Average training steps per second: 188.42
I0901 12:51:41.741396 140162147342336 replay_runner.py:36] Average training steps per second: 188.42
I0901 12:51:41.941837 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 138.50
INFO:tensorflow:Starting iteration 18

Steps executed: 317 Episode length: 160 Return: 160.0
INFO:tensorflow:Average training steps per second: 191.70
I0901 12:51:47.352351 140162147342336 replay_runner.py:36] Average training steps per second: 191.70
I0901 12:51:47.567022 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 158.50
INFO:tensorflow:Starting iteration 19

Steps executed: 376 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 188.94
I0901 12:51:53.050472 140162147342336 replay_runner.py:36] Average training steps per second: 188.94
I0901 12:51:53.314448 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 188.00
INFO:tensorflow:Starting iteration 20

Steps executed: 324 Episode length: 156 Return: 156.0
INFO:tensorflow:Average training steps per second: 187.90
I0901 12:51:58.833226 140162147342336 replay_runner.py:36] Average training steps per second: 187.90
I0901 12:51:59.081728 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 162.00
INFO:tensorflow:Starting iteration 21

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 184.19
I0901 12:52:04.715440 140162147342336 replay_runner.py:36] Average training steps per second: 184.19
I0901 12:52:04.862490 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 22
I0901 12:52:05.064280 140162147342336 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 188.14
I0901 12:52:10.379955 140162147342336 replay_runner.py:36] Average training steps per second: 188.14
I0901 12:52:10.521105 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 23

Steps executed: 335 Episode length: 175 Return: 175.0
INFO:tensorflow:Average training steps per second: 191.41
I0901 12:52:15.930187 140162147342336 replay_runner.py:36] Average training steps per second: 191.41
I0901 12:52:16.173407 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 167.50
INFO:tensorflow:Starting iteration 24

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 196.01
I0901 12:52:21.479439 140162147342336 replay_runner.py:36] Average training steps per second: 196.01
I0901 12:52:21.609666 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 25
I0901 12:52:21.800627 140162147342336 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 191.97
I0901 12:52:27.010699 140162147342336 replay_runner.py:36] Average training steps per second: 191.97
I0901 12:52:27.139998 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26

Steps executed: 351 Episode length: 177 Return: 177.0
INFO:tensorflow:Average training steps per second: 191.75
I0901 12:52:32.548838 140162147342336 replay_runner.py:36] Average training steps per second: 191.75
I0901 12:52:32.776444 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 175.50
INFO:tensorflow:Starting iteration 27

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 193.32
I0901 12:52:38.161198 140162147342336 replay_runner.py:36] Average training steps per second: 193.32
I0901 12:52:38.304564 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 28
I0901 12:52:38.500041 140162147342336 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 189.45
I0901 12:52:43.778848 140162147342336 replay_runner.py:36] Average training steps per second: 189.45
I0901 12:52:43.924346 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 146 Return: 146.0
INFO:tensorflow:Average training steps per second: 191.23
I0901 12:52:49.350480 140162147342336 replay_runner.py:36] Average training steps per second: 191.23
I0901 12:52:49.569722 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 149.00