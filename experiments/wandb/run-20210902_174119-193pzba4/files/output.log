I0902 17:41:25.679193 140523524642816 run_experiment.py:549] Creating TrainRunner ...
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0902 17:41:25.679670 140523524642816 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0902 17:41:25.830230 140523524642816 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:41:25.831255 140523524642816 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:41:25.831334 140523524642816 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:41:25.831398 140523524642816 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:41:25.831498 140523524642816 dqn_agent.py:275] 	 update_period: 4
I0902 17:41:25.831556 140523524642816 dqn_agent.py:276] 	 target_update_period: 100
I0902 17:41:25.831686 140523524642816 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:41:25.831789 140523524642816 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:41:25.831845 140523524642816 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:41:25.831929 140523524642816 dqn_agent.py:280] 	 optimizer: adam
I0902 17:41:25.831983 140523524642816 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:41:25.832065 140523524642816 dqn_agent.py:283] 	 seed: 1630604485830180
I0902 17:41:25.836015 140523524642816 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:41:25.836226 140523524642816 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0902 17:41:25.836299 140523524642816 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:41:25.836377 140523524642816 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:41:25.836433 140523524642816 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:41:25.836513 140523524642816 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:41:25.836625 140523524642816 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:41:25.836714 140523524642816 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:41:25.836809 140523524642816 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in cartpole
Training fixed agent 9, please be patient, may be a while...
I0902 17:41:27.323304 140523524642816 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=10.000000
I0902 17:41:28.102368 140523524642816 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=10.000000
I0902 17:41:28.113364 140523524642816 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 17:41:28.117323 140523524642816 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:41:28.117475 140523524642816 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:41:28.117554 140523524642816 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:41:28.117624 140523524642816 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:41:28.117688 140523524642816 dqn_agent.py:275] 	 update_period: 4
I0902 17:41:28.117775 140523524642816 dqn_agent.py:276] 	 target_update_period: 100
I0902 17:41:28.117839 140523524642816 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:41:28.117970 140523524642816 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:41:28.118031 140523524642816 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:41:28.118101 140523524642816 dqn_agent.py:280] 	 optimizer: adam
I0902 17:41:28.118202 140523524642816 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:41:28.118258 140523524642816 dqn_agent.py:283] 	 seed: 1630604488117286
I0902 17:41:28.119898 140523524642816 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:41:28.120028 140523524642816 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0902 17:41:28.120106 140523524642816 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:41:28.120178 140523524642816 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:41:28.120269 140523524642816 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:41:28.120378 140523524642816 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:41:28.120457 140523524642816 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:41:28.120536 140523524642816 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:41:28.120612 140523524642816 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:41:28.140882 140523524642816 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=10.000000
I0902 17:41:28.153149 140523524642816 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 17:41:28.153323 140523524642816 replay_runner.py:41] Starting iteration 0
Steps executed: 116 Episode length: 38 Return: 38.0
INFO:tensorflow:Average training steps per second: 160.33
I0902 17:41:34.390834 140523524642816 replay_runner.py:36] Average training steps per second: 160.33

Steps executed: 224 Episode length: 38 Return: 38.0
INFO:tensorflow:Starting iteration 1

Steps executed: 206 Episode length: 27 Return: 27.0
INFO:tensorflow:Average training steps per second: 210.04
I0902 17:41:40.183586 140523524642816 replay_runner.py:36] Average training steps per second: 210.04
I0902 17:41:40.333721 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 29.43
INFO:tensorflow:Starting iteration 2

Steps executed: 207 Episode length: 21 Return: 21.0
INFO:tensorflow:Average training steps per second: 190.90
I0902 17:41:45.769960 140523524642816 replay_runner.py:36] Average training steps per second: 190.90
I0902 17:41:45.904384 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 23.00
INFO:tensorflow:Starting iteration 3

Steps executed: 210 Episode length: 18 Return: 18.0
INFO:tensorflow:Average training steps per second: 199.24
I0902 17:41:51.098293 140523524642816 replay_runner.py:36] Average training steps per second: 199.24
I0902 17:41:51.258666 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 17.50
INFO:tensorflow:Starting iteration 4

Steps executed: 208 Episode length: 17 Return: 17.0
INFO:tensorflow:Average training steps per second: 202.50
I0902 17:41:56.394244 140523524642816 replay_runner.py:36] Average training steps per second: 202.50
I0902 17:41:56.528351 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 14.86
INFO:tensorflow:Starting iteration 5

Steps executed: 209 Episode length: 12 Return: 12.0
INFO:tensorflow:Average training steps per second: 191.53
I0902 17:42:01.929980 140523524642816 replay_runner.py:36] Average training steps per second: 191.53
I0902 17:42:02.084846 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 13.06
INFO:tensorflow:Starting iteration 6

Steps executed: 205 Episode length: 13 Return: 13.0
INFO:tensorflow:Average training steps per second: 211.23
I0902 17:42:07.021418 140523524642816 replay_runner.py:36] Average training steps per second: 211.23
I0902 17:42:07.162438 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 12.06
INFO:tensorflow:Starting iteration 7

Steps executed: 209 Episode length: 11 Return: 11.0
INFO:tensorflow:Average training steps per second: 192.77
I0902 17:42:12.533049 140523524642816 replay_runner.py:36] Average training steps per second: 192.77
I0902 17:42:12.673847 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 11.00
INFO:tensorflow:Starting iteration 8

Steps executed: 207 Episode length: 11 Return: 11.0
INFO:tensorflow:Average training steps per second: 203.27
I0902 17:42:17.772395 140523524642816 replay_runner.py:36] Average training steps per second: 203.27
I0902 17:42:17.921718 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 10.35
INFO:tensorflow:Starting iteration 9

Steps executed: 207 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 199.78
I0902 17:42:23.116653 140523524642816 replay_runner.py:36] Average training steps per second: 199.78
I0902 17:42:23.251481 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 10.35
INFO:tensorflow:Starting iteration 10

Steps executed: 209 Episode length: 11 Return: 11.0
INFO:tensorflow:Average training steps per second: 197.52
I0902 17:42:28.495498 140523524642816 replay_runner.py:36] Average training steps per second: 197.52
I0902 17:42:28.645370 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.95
INFO:tensorflow:Starting iteration 11

Steps executed: 204 Episode length: 11 Return: 11.0
INFO:tensorflow:Average training steps per second: 208.93
I0902 17:42:33.633750 140523524642816 replay_runner.py:36] Average training steps per second: 208.93
I0902 17:42:33.758255 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.71
INFO:tensorflow:Starting iteration 12

Steps executed: 206 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 189.88
I0902 17:42:39.205887 140523524642816 replay_runner.py:36] Average training steps per second: 189.88
I0902 17:42:39.342438 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.36
INFO:tensorflow:Starting iteration 13

Steps executed: 207 Episode length: 9 Return: 9.0.0
INFO:tensorflow:Average training steps per second: 208.43
I0902 17:42:44.327087 140523524642816 replay_runner.py:36] Average training steps per second: 208.43
I0902 17:42:44.477908 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.41
INFO:tensorflow:Starting iteration 14

Steps executed: 203 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 197.61
I0902 17:42:49.736935 140523524642816 replay_runner.py:36] Average training steps per second: 197.61
I0902 17:42:49.867398 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.23
INFO:tensorflow:Starting iteration 15

Steps executed: 207 Episode length: 9 Return: 9.0.0
INFO:tensorflow:Average training steps per second: 201.46
I0902 17:42:55.015365 140523524642816 replay_runner.py:36] Average training steps per second: 201.46
I0902 17:42:55.162664 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.41
INFO:tensorflow:Starting iteration 16

Steps executed: 200 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 201.49
I0902 17:43:00.310375 140523524642816 replay_runner.py:36] Average training steps per second: 201.49
I0902 17:43:00.428767 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.52
INFO:tensorflow:Starting iteration 17

Steps executed: 203 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 192.54
I0902 17:43:05.797044 140523524642816 replay_runner.py:36] Average training steps per second: 192.54
I0902 17:43:05.938514 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.23
INFO:tensorflow:Starting iteration 18

Steps executed: 200 Episode length: 9 Return: 9.0.0
INFO:tensorflow:Average training steps per second: 206.81
I0902 17:43:10.974831 140523524642816 replay_runner.py:36] Average training steps per second: 206.81
I0902 17:43:11.116024 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.09
INFO:tensorflow:Starting iteration 19

Steps executed: 200 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 192.10
I0902 17:43:16.504202 140523524642816 replay_runner.py:36] Average training steps per second: 192.10
I0902 17:43:16.626209 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.52
INFO:tensorflow:Starting iteration 20

Steps executed: 114 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 204.39
I0902 17:43:21.696992 140523524642816 replay_runner.py:36] Average training steps per second: 204.39

Steps executed: 206 Episode length: 8 Return: 8.0.0
INFO:tensorflow:Starting iteration 21

Steps executed: 207 Episode length: 9 Return: 9.0.0
INFO:tensorflow:Average training steps per second: 202.11
I0902 17:43:27.002918 140523524642816 replay_runner.py:36] Average training steps per second: 202.11
I0902 17:43:27.130839 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.41
INFO:tensorflow:Starting iteration 22

Steps executed: 207 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 197.09
I0902 17:43:32.383982 140523524642816 replay_runner.py:36] Average training steps per second: 197.09
I0902 17:43:32.530741 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.41
INFO:tensorflow:Starting iteration 23

Steps executed: 203 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 208.49
I0902 17:43:37.521246 140523524642816 replay_runner.py:36] Average training steps per second: 208.49
I0902 17:43:37.647414 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.23
INFO:tensorflow:Starting iteration 24

Steps executed: 208 Episode length: 9 Return: 9.0.0
INFO:tensorflow:Average training steps per second: 190.19
I0902 17:43:43.083738 140523524642816 replay_runner.py:36] Average training steps per second: 190.19
I0902 17:43:43.224712 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.45
INFO:tensorflow:Starting iteration 25

Steps executed: 200 Episode length: 9 Return: 9.0.0
INFO:tensorflow:Average training steps per second: 205.24
I0902 17:43:48.284005 140523524642816 replay_runner.py:36] Average training steps per second: 205.24
I0902 17:43:48.434225 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.52
INFO:tensorflow:Starting iteration 26

Steps executed: 207 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 193.40
I0902 17:43:53.816012 140523524642816 replay_runner.py:36] Average training steps per second: 193.40
I0902 17:43:53.944562 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.41
INFO:tensorflow:Starting iteration 27

Steps executed: 202 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 198.76
I0902 17:43:59.168441 140523524642816 replay_runner.py:36] Average training steps per second: 198.76
I0902 17:43:59.315268 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.18
INFO:tensorflow:Starting iteration 28
I0902 17:43:59.514439 140523524642816 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 203.43
I0902 17:44:04.430892 140523524642816 replay_runner.py:36] Average training steps per second: 203.43
I0902 17:44:04.565484 140523524642816 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.18
INFO:tensorflow:Starting iteration 29
I0902 17:44:04.768865 140523524642816 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 188.76
I0902 17:44:10.067136 140523524642816 replay_runner.py:36] Average training steps per second: 188.76

Done fixed training!Episode length: 8 Return: 8.0.0