Loaded trained dqn in cartpole
Training fixed agent 9, please be patient, may be a while...
I0901 12:31:16.623911 140162147342336 run_experiment.py:549] Creating TrainRunner ...
I0901 12:31:16.632685 140162147342336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:31:16.632919 140162147342336 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:31:16.633061 140162147342336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:31:16.633256 140162147342336 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:31:16.633507 140162147342336 dqn_agent.py:275] 	 update_period: 4
I0901 12:31:16.633618 140162147342336 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:31:16.633738 140162147342336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:31:16.633858 140162147342336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:31:16.633934 140162147342336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:31:16.634006 140162147342336 dqn_agent.py:280] 	 optimizer: adam
I0901 12:31:16.634143 140162147342336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:31:16.634262 140162147342336 dqn_agent.py:283] 	 seed: 1630499476632622
I0901 12:31:16.637929 140162147342336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:31:16.638249 140162147342336 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:31:16.638415 140162147342336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:31:16.638506 140162147342336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:31:16.638608 140162147342336 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:31:16.638742 140162147342336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:31:16.638890 140162147342336 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:31:16.639039 140162147342336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:31:16.639143 140162147342336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:31:16.677474 140162147342336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:31:17.227888 140162147342336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:31:17.241625 140162147342336 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:31:17.250558 140162147342336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:31:17.250858 140162147342336 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:31:17.251046 140162147342336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:31:17.251207 140162147342336 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:31:17.251357 140162147342336 dqn_agent.py:275] 	 update_period: 4
I0901 12:31:17.251497 140162147342336 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:31:17.251635 140162147342336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:31:17.251759 140162147342336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:31:17.251886 140162147342336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:31:17.252027 140162147342336 dqn_agent.py:280] 	 optimizer: adam
I0901 12:31:17.252157 140162147342336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:31:17.252409 140162147342336 dqn_agent.py:283] 	 seed: 1630499477250508
I0901 12:31:17.255197 140162147342336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:31:17.255419 140162147342336 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:31:17.255563 140162147342336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:31:17.255673 140162147342336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:31:17.255788 140162147342336 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:31:17.255913 140162147342336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:31:17.256032 140162147342336 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:31:17.256146 140162147342336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:31:17.256261 140162147342336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:31:17.292004 140162147342336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:31:17.315383 140162147342336 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:31:17.315724 140162147342336 replay_runner.py:41] Starting iteration 0
Steps executed: 200 Episode length: 9 Return: 9.0.0
INFO:tensorflow:Average training steps per second: 134.43
I0901 12:31:24.754600 140162147342336 replay_runner.py:36] Average training steps per second: 134.43
I0901 12:31:25.880529 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.09
INFO:tensorflow:Starting iteration 1

Steps executed: 202 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 193.93
I0901 12:31:31.224627 140162147342336 replay_runner.py:36] Average training steps per second: 193.93
I0901 12:31:31.362133 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.18
INFO:tensorflow:Starting iteration 2

Steps executed: 212 Episode length: 15 Return: 15.0
INFO:tensorflow:Average training steps per second: 190.73
I0901 12:31:36.783173 140162147342336 replay_runner.py:36] Average training steps per second: 190.73
I0901 12:31:36.934620 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 12.47
INFO:tensorflow:Starting iteration 3

Steps executed: 283 Episode length: 174 Return: 174.0
INFO:tensorflow:Average training steps per second: 194.28
I0901 12:31:42.273535 140162147342336 replay_runner.py:36] Average training steps per second: 194.28
I0901 12:31:42.453520 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 141.50
INFO:tensorflow:Starting iteration 4

Steps executed: 233 Episode length: 55 Return: 55.0.0
INFO:tensorflow:Average training steps per second: 188.67
I0901 12:31:47.935601 140162147342336 replay_runner.py:36] Average training steps per second: 188.67
I0901 12:31:48.108685 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 58.25
INFO:tensorflow:Starting iteration 5

Steps executed: 236 Episode length: 46 Return: 46.0.0
INFO:tensorflow:Average training steps per second: 195.09
I0901 12:31:53.418294 140162147342336 replay_runner.py:36] Average training steps per second: 195.09
I0901 12:31:53.595267 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 47.20
INFO:tensorflow:Starting iteration 6

Steps executed: 210 Episode length: 75 Return: 75.0.0
INFO:tensorflow:Average training steps per second: 191.68
I0901 12:31:59.012322 140162147342336 replay_runner.py:36] Average training steps per second: 191.68
I0901 12:31:59.156952 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 70.00
INFO:tensorflow:Starting iteration 7

Steps executed: 80 Episode length: 80 Return: 80.00.0
INFO:tensorflow:Average training steps per second: 189.28

Steps executed: 240 Episode length: 74 Return: 74.0.0
I0901 12:32:04.801033 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 80.00
INFO:tensorflow:Starting iteration 8

Steps executed: 202 Episode length: 32 Return: 32.0.0
INFO:tensorflow:Average training steps per second: 193.19
I0901 12:32:10.162172 140162147342336 replay_runner.py:36] Average training steps per second: 193.19
I0901 12:32:10.308290 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 33.67
INFO:tensorflow:Starting iteration 9

Steps executed: 208 Episode length: 41 Return: 41.0.0
INFO:tensorflow:Average training steps per second: 187.92
I0901 12:32:15.819614 140162147342336 replay_runner.py:36] Average training steps per second: 187.92
I0901 12:32:15.967043 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 41.60
INFO:tensorflow:Starting iteration 10

Steps executed: 201 Episode length: 48 Return: 48.0.0
INFO:tensorflow:Average training steps per second: 192.98
I0901 12:32:21.342577 140162147342336 replay_runner.py:36] Average training steps per second: 192.98
I0901 12:32:21.491401 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 50.25
INFO:tensorflow:Starting iteration 11

Steps executed: 255 Episode length: 64 Return: 64.0.0
INFO:tensorflow:Average training steps per second: 188.87
I0901 12:32:26.985058 140162147342336 replay_runner.py:36] Average training steps per second: 188.87
I0901 12:32:27.160149 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 63.75
INFO:tensorflow:Starting iteration 12
I0901 12:32:27.351656 140162147342336 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 186.07
I0901 12:32:32.726313 140162147342336 replay_runner.py:36] Average training steps per second: 186.07

Steps executed: 275 Episode length: 136 Return: 136.0
INFO:tensorflow:Starting iteration 13

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 193.33
I0901 12:32:38.271715 140162147342336 replay_runner.py:36] Average training steps per second: 193.33
I0901 12:32:38.410557 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 14

Steps executed: 325 Episode length: 158 Return: 158.0
INFO:tensorflow:Average training steps per second: 187.38
I0901 12:32:43.938683 140162147342336 replay_runner.py:36] Average training steps per second: 187.38
I0901 12:32:44.155425 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 162.50
INFO:tensorflow:Starting iteration 15

Steps executed: 371 Episode length: 180 Return: 180.0
INFO:tensorflow:Average training steps per second: 190.53
I0901 12:32:49.595059 140162147342336 replay_runner.py:36] Average training steps per second: 190.53
I0901 12:32:49.868662 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 185.50
INFO:tensorflow:Starting iteration 16

Steps executed: 338 Episode length: 167 Return: 167.0
INFO:tensorflow:Average training steps per second: 189.22
I0901 12:32:55.354519 140162147342336 replay_runner.py:36] Average training steps per second: 189.22
I0901 12:32:55.599914 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 169.00
INFO:tensorflow:Starting iteration 17

Steps executed: 335 Episode length: 168 Return: 168.0
INFO:tensorflow:Average training steps per second: 186.65
I0901 12:33:01.158448 140162147342336 replay_runner.py:36] Average training steps per second: 186.65
I0901 12:33:01.388877 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 167.50
INFO:tensorflow:Starting iteration 18
I0901 12:33:01.581832 140162147342336 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 193.52

Steps executed: 324 Episode length: 162 Return: 162.0
I0901 12:33:06.986253 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 162.00
INFO:tensorflow:Starting iteration 19

Steps executed: 362 Episode length: 185 Return: 185.0
INFO:tensorflow:Average training steps per second: 187.29
I0901 12:33:12.524253 140162147342336 replay_runner.py:36] Average training steps per second: 187.29
I0901 12:33:12.770657 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 181.00
INFO:tensorflow:Starting iteration 20

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 186.54
I0901 12:33:18.319447 140162147342336 replay_runner.py:36] Average training steps per second: 186.54
I0901 12:33:18.461765 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 21
I0901 12:33:18.652489 140162147342336 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 193.22
I0901 12:33:23.828185 140162147342336 replay_runner.py:36] Average training steps per second: 193.22
I0901 12:33:23.968559 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 22

Steps executed: 327 Episode length: 159 Return: 159.0
INFO:tensorflow:Average training steps per second: 189.63
I0901 12:33:29.423739 140162147342336 replay_runner.py:36] Average training steps per second: 189.63
I0901 12:33:29.645083 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 163.50
INFO:tensorflow:Starting iteration 23
I0901 12:33:29.830790 140162147342336 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 192.94

Steps executed: 200 Episode length: 200 Return: 200.0
I0901 12:33:35.155039 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 24
I0901 12:33:35.346355 140162147342336 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 184.45
I0901 12:33:40.768146 140162147342336 replay_runner.py:36] Average training steps per second: 184.45
I0901 12:33:40.897378 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 25
I0901 12:33:41.084640 140162147342336 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 189.54
I0901 12:33:46.360896 140162147342336 replay_runner.py:36] Average training steps per second: 189.54
I0901 12:33:46.505332 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26
I0901 12:33:46.700849 140162147342336 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 198.15
I0901 12:33:51.747757 140162147342336 replay_runner.py:36] Average training steps per second: 198.15
I0901 12:33:51.873460 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 27
I0901 12:33:52.059096 140162147342336 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 193.01
I0901 12:33:57.240652 140162147342336 replay_runner.py:36] Average training steps per second: 193.01
I0901 12:33:57.381896 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 28

Steps executed: 155 Episode length: 155 Return: 155.0
INFO:tensorflow:Average training steps per second: 200.53
I0901 12:34:02.548612 140162147342336 replay_runner.py:36] Average training steps per second: 200.53
I0901 12:34:02.764199 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 159.50
INFO:tensorflow:Starting iteration 29


Done fixed training!Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 192.81
I0901 12:34:08.140389 140162147342336 replay_runner.py:36] Average training steps per second: 192.81
I0901 12:34:08.276695 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00