Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0902 00:10:09.592384 140413705484288 run_experiment.py:549] Creating TrainRunner ...
I0902 00:10:09.603336 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:10:09.603634 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:10:09.603746 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:10:09.603844 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:10:09.603955 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0902 00:10:09.604210 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:10:09.604419 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:10:09.604644 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:10:09.604748 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:10:09.604854 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0902 00:10:09.605057 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:10:09.605195 140413705484288 dqn_agent.py:283] 	 seed: 1630541409603257
I0902 00:10:09.608485 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:10:09.608667 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:10:09.608851 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:10:09.609001 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:10:09.609292 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:10:09.609455 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:10:09.609652 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:10:09.609889 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:10:09.610021 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:10:09.650404 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:10:10.050327 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:10:10.065088 140413705484288 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:10:10.074145 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:10:10.074501 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:10:10.074658 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:10:10.074838 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:10:10.074948 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0902 00:10:10.075028 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:10:10.075100 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:10:10.075170 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:10:10.075238 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:10:10.075333 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0902 00:10:10.075653 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:10:10.075801 140413705484288 dqn_agent.py:283] 	 seed: 1630541410074074
I0902 00:10:10.109475 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:10:10.109713 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:10:10.109816 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:10:10.109898 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:10:10.109968 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:10:10.110088 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:10:10.110196 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:10:10.110347 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:10:10.110549 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:10:10.142920 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:10:10.165566 140413705484288 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:10:10.165816 140413705484288 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 156.46
I0902 00:10:16.557683 140413705484288 replay_runner.py:36] Average training steps per second: 156.46
Steps executed: 221 Episode length: 96 Return: -212.9757067515785
I0902 00:10:17.840882 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.67
INFO:tensorflow:Starting iteration 1

Steps executed: 275 Episode length: 134 Return: -810.8236683280605
INFO:tensorflow:Average training steps per second: 223.19
I0902 00:10:26.832890 140413705484288 replay_runner.py:36] Average training steps per second: 223.19
I0902 00:10:27.104207 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -571.38
INFO:tensorflow:Starting iteration 2

Steps executed: 298 Episode length: 298 Return: -590.4572538646435
INFO:tensorflow:Average training steps per second: 224.73
I0902 00:10:35.861994 140413705484288 replay_runner.py:36] Average training steps per second: 224.73
I0902 00:10:36.241926 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -590.46
INFO:tensorflow:Starting iteration 3

Steps executed: 213 Episode length: 101 Return: -179.39944108293815
INFO:tensorflow:Average training steps per second: 227.34
I0902 00:10:44.923722 140413705484288 replay_runner.py:36] Average training steps per second: 227.34
I0902 00:10:45.101359 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -318.51
INFO:tensorflow:Starting iteration 4
I0902 00:10:49.243265 140413705484288 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 233.01

Steps executed: 423 Episode length: 423 Return: -50.192600711386945
I0902 00:10:54.273216 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -50.19
INFO:tensorflow:Starting iteration 5
I0902 00:10:58.603519 140413705484288 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 232.91

Steps executed: 1000 Episode length: 1000 Return: -71.34551327289404
I0902 00:11:06.036006 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.35
INFO:tensorflow:Starting iteration 6
I0902 00:11:10.408472 140413705484288 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 230.68

Steps executed: 1000 Episode length: 1000 Return: -121.53418107164357
I0902 00:11:17.491797 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.53
INFO:tensorflow:Starting iteration 7
I0902 00:11:21.884536 140413705484288 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 231.47

Steps executed: 1000 Episode length: 1000 Return: -102.84865885389758
I0902 00:11:29.025900 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.85
INFO:tensorflow:Starting iteration 8

Steps executed: 339 Episode length: 339 Return: -399.3922793435030558
INFO:tensorflow:Average training steps per second: 228.93
I0902 00:11:37.737298 140413705484288 replay_runner.py:36] Average training steps per second: 228.93
I0902 00:11:38.268067 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -399.39
INFO:tensorflow:Starting iteration 9

Steps executed: 265 Episode length: 156 Return: -176.1178986125529558
INFO:tensorflow:Average training steps per second: 230.21
I0902 00:11:46.853337 140413705484288 replay_runner.py:36] Average training steps per second: 230.21
I0902 00:11:47.086956 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.51
INFO:tensorflow:Starting iteration 10
I0902 00:11:51.389986 140413705484288 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 242.03

Steps executed: 1000 Episode length: 1000 Return: -87.012959386227188
I0902 00:11:58.463404 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.01
INFO:tensorflow:Starting iteration 11

Steps executed: 167 Episode length: 167 Return: -209.0218021831373788
INFO:tensorflow:Average training steps per second: 233.57

Steps executed: 817 Episode length: 650 Return: -456.8201828567544788
I0902 00:12:08.935519 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.92
INFO:tensorflow:Starting iteration 12
I0902 00:12:13.182296 140413705484288 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 229.97

Steps executed: 242 Episode length: 111 Return: -146.4423511179539688
I0902 00:12:17.750938 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -403.70
INFO:tensorflow:Starting iteration 13

Steps executed: 377 Episode length: 185 Return: -107.8147274777578188
INFO:tensorflow:Average training steps per second: 230.29
I0902 00:12:26.385448 140413705484288 replay_runner.py:36] Average training steps per second: 230.29
I0902 00:12:26.819478 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -214.57
INFO:tensorflow:Starting iteration 14
I0902 00:12:31.143574 140413705484288 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 227.35

Steps executed: 1000 Episode length: 1000 Return: -167.83083495250477
I0902 00:12:39.200364 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.83
INFO:tensorflow:Starting iteration 15

Steps executed: 307 Episode length: 176 Return: -554.4450748111194477
INFO:tensorflow:Average training steps per second: 233.60
I0902 00:12:47.871694 140413705484288 replay_runner.py:36] Average training steps per second: 233.60
I0902 00:12:48.177683 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -531.55
INFO:tensorflow:Starting iteration 16

Steps executed: 214 Episode length: 75 Return: -147.75993350208654477
INFO:tensorflow:Average training steps per second: 230.78
I0902 00:12:56.942730 140413705484288 replay_runner.py:36] Average training steps per second: 230.78
I0902 00:12:57.131870 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.13
INFO:tensorflow:Starting iteration 17
I0902 00:13:01.448586 140413705484288 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 224.65

Steps executed: 231 Episode length: 115 Return: -89.94313064518128677
I0902 00:13:06.096442 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.98
INFO:tensorflow:Starting iteration 18

Steps executed: 243 Episode length: 111 Return: -36.12426489578454677
INFO:tensorflow:Average training steps per second: 226.88
I0902 00:13:14.853204 140413705484288 replay_runner.py:36] Average training steps per second: 226.88
I0902 00:13:15.073607 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.22
INFO:tensorflow:Starting iteration 19
I0902 00:13:19.443156 140413705484288 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 230.15

Steps executed: 517 Episode length: 329 Return: -335.9075250767787677
I0902 00:13:24.489717 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.33
INFO:tensorflow:Starting iteration 20

Steps executed: 300 Episode length: 146 Return: -83.03736192400046577
INFO:tensorflow:Average training steps per second: 230.65
I0902 00:13:33.235508 140413705484288 replay_runner.py:36] Average training steps per second: 230.65
I0902 00:13:33.520286 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.75
INFO:tensorflow:Starting iteration 21
I0902 00:13:37.817089 140413705484288 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 239.65

Steps executed: 219 Episode length: 120 Return: -356.2160745605339577
I0902 00:13:42.183582 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -375.32
INFO:tensorflow:Starting iteration 22

Steps executed: 208 Episode length: 89 Return: -192.37493132856395577
INFO:tensorflow:Average training steps per second: 227.97
I0902 00:13:51.002565 140413705484288 replay_runner.py:36] Average training steps per second: 227.97
I0902 00:13:51.167228 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.49
INFO:tensorflow:Starting iteration 23
I0902 00:13:55.600952 140413705484288 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 228.97
I0902 00:13:59.968934 140413705484288 replay_runner.py:36] Average training steps per second: 228.97

Steps executed: 219 Episode length: 109 Return: -452.3129938110468577
INFO:tensorflow:Starting iteration 24

Steps executed: 247 Episode length: 71 Return: -556.74562242647146577
INFO:tensorflow:Average training steps per second: 226.62
I0902 00:14:08.991297 140413705484288 replay_runner.py:36] Average training steps per second: 226.62
I0902 00:14:09.223155 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -532.10
INFO:tensorflow:Starting iteration 25

Steps executed: 104 Episode length: 51 Return: -75.470508403421556577
INFO:tensorflow:Average training steps per second: 230.22
I0902 00:14:17.968659 140413705484288 replay_runner.py:36] Average training steps per second: 230.22

Steps executed: 214 Episode length: 110 Return: -351.4002677113116577
INFO:tensorflow:Starting iteration 26

Steps executed: 219 Episode length: 79 Return: -344.46773747417166577
INFO:tensorflow:Average training steps per second: 227.14
I0902 00:14:26.935558 140413705484288 replay_runner.py:36] Average training steps per second: 227.14
I0902 00:14:27.112330 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.14
INFO:tensorflow:Starting iteration 27

Steps executed: 184 Episode length: 184 Return: -331.8011930318798577
INFO:tensorflow:Average training steps per second: 229.26

Steps executed: 617 Episode length: 433 Return: -371.1541809556538577
I0902 00:14:36.718138 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -351.48
INFO:tensorflow:Starting iteration 28

Steps executed: 253 Episode length: 109 Return: -380.3619359647186777
INFO:tensorflow:Average training steps per second: 233.34
I0902 00:14:45.348843 140413705484288 replay_runner.py:36] Average training steps per second: 233.34
I0902 00:14:45.579976 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -529.12
INFO:tensorflow:Starting iteration 29

Steps executed: 227 Episode length: 84 Return: -752.21561101803567777
INFO:tensorflow:Average training steps per second: 235.00
I0902 00:14:54.140267 140413705484288 replay_runner.py:36] Average training steps per second: 235.00

Done fixed training!Episode length: 84 Return: -752.21561101803567777