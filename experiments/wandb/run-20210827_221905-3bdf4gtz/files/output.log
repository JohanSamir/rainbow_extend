error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
Training agent 2, please be patient, may be a while...
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0827 22:19:10.449811 140144978790400 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0827 22:19:10.500685 140144978790400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0827 22:19:10.501679 140144978790400 dqn_agent.py:272] 	 gamma: 0.990000
I0827 22:19:10.501753 140144978790400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0827 22:19:10.501837 140144978790400 dqn_agent.py:274] 	 min_replay_history: 500
I0827 22:19:10.501898 140144978790400 dqn_agent.py:275] 	 update_period: 4
I0827 22:19:10.501950 140144978790400 dqn_agent.py:276] 	 target_update_period: 100
I0827 22:19:10.502027 140144978790400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0827 22:19:10.502121 140144978790400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0827 22:19:10.502207 140144978790400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0827 22:19:10.502274 140144978790400 dqn_agent.py:280] 	 optimizer: adam
I0827 22:19:10.502336 140144978790400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0827 22:19:10.502402 140144978790400 dqn_agent.py:283] 	 seed: 1630102750500631
I0827 22:19:10.503968 140144978790400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0827 22:19:10.504082 140144978790400 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0827 22:19:10.504162 140144978790400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0827 22:19:10.504224 140144978790400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0827 22:19:10.504280 140144978790400 circular_replay_buffer.py:159] 	 stack_size: 1
I0827 22:19:10.504349 140144978790400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0827 22:19:10.504406 140144978790400 circular_replay_buffer.py:161] 	 batch_size: 128
I0827 22:19:10.504459 140144978790400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0827 22:19:10.504549 140144978790400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0827 22:19:11.743023 140144978790400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0827 22:19:11.833414 140144978790400 run_experiment.py:516] Beginning training...
I0827 22:19:11.833575 140144978790400 run_experiment.py:447] Starting iteration 0
error: Choose a correct Normalization Modulern: -409.0
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
W0827 22:19:12.564413 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
Steps executed: 910 Episode length: 500 Return: -500.0
error: Choose a correct Normalization Moduleurn: -167.0
error: Choose a correct Normalization Module
Steps executed: 2553 Episode length: 197 Return: -196.0
W0827 22:19:16.214240 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:19:16.214580 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -358.67
























Steps executed: 120821 Episode length: 290 Return: -289.0
I0827 22:20:07.932030 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.27

Steps executed: 125255 Episode length: 270 Return: -269.0
W0827 22:20:08.487277 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:20:09.061694 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:20:09.418544 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 533 Episode length: 98 Return: -97.0.09.0
W0827 22:20:10.166902 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:20:10.528805 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:20:11.058811 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:20:11.501230 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 931 Episode length: 94 Return: -93.0.09.0
W0827 22:20:13.129839 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:20:13.130147 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -122.30


























Steps executed: 123500 Episode length: 500 Return: -500.0
I0827 22:21:04.890423 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
I0827 22:21:04.952482 140144978790400 run_experiment.py:447] Starting iteration 2

Steps executed: 182 Episode length: 182 Return: -181.00.0

Steps executed: 626 Episode length: 444 Return: -443.00.0
W0827 22:21:08.721085 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:21:09.210545 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:21:09.815010 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:21:09.815331 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -224.40


























Steps executed: 124216 Episode length: 246 Return: -245.0
I0827 22:22:00.979321 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -454.42
I0827 22:22:01.042143 140144978790400 run_experiment.py:447] Starting iteration 3

Steps executed: 355 Episode length: 99 Return: -98.0.00.0
W0827 22:22:02.586640 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:22:03.506646 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 825 Episode length: 123 Return: -122.00.0
W0827 22:22:04.518238 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:22:05.198925 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:22:06.215042 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:22:06.215349 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -177.00

























Steps executed: 121229 Episode length: 136 Return: -135.0
I0827 22:22:56.311676 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.25

Steps executed: 125083 Episode length: 162 Return: -161.0
W0827 22:22:57.520284 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:22:57.936699 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 567 Episode length: 120 Return: -119.01.0
W0827 22:22:58.776088 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:22:59.528240 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 500 Episode length: 500 Return: -500.00.0
W0827 22:23:00.599347 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:23:00.599672 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -142.14

























Steps executed: 120521 Episode length: 500 Return: -500.0
I0827 22:23:52.362991 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -498.06

Steps executed: 125021 Episode length: 500 Return: -500.0
W0827 22:23:53.009476 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:23:53.762789 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:23:54.092202 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 482 Episode length: 88 Return: -87.0.00.0
W0827 22:23:55.005961 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:23:55.374364 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 852 Episode length: 174 Return: -173.00.0
W0827 22:23:57.480920 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:23:57.481253 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -145.62

























Steps executed: 121506 Episode length: 244 Return: -243.0
I0827 22:24:48.305144 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.16
I0827 22:24:48.380011 140144978790400 run_experiment.py:447] Starting iteration 6

Steps executed: 88 Episode length: 88 Return: -87.0-308.0
W0827 22:24:49.225795 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:24:49.571705 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 405 Episode length: 116 Return: -115.08.0
W0827 22:24:51.057716 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:24:51.759284 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:24:52.227893 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:24:52.742789 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:24:52.743201 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -131.25


























Steps executed: 122643 Episode length: 500 Return: -500.0
I0827 22:25:44.067539 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -443.14

Steps executed: 125469 Episode length: 500 Return: -500.0
W0827 22:25:46.117866 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 571 Episode length: 112 Return: -111.00.0
W0827 22:25:47.103771 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:25:47.594878 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:25:48.067842 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:25:48.575271 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:25:48.575619 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -167.83

























Steps executed: 121500 Episode length: 500 Return: -500.0
I0827 22:26:38.416557 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00

Steps executed: 127 Episode length: 127 Return: -126.00.0
W0827 22:26:39.021991 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:26:39.398962 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:26:39.877783 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:26:40.244791 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 511 Episode length: 84 Return: -83.0.00.0
W0827 22:26:41.244651 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:26:41.624278 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:26:42.120314 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:26:42.516618 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:26:42.898692 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:26:42.898997 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -106.30

























Steps executed: 120444 Episode length: 500 Return: -500.0

Steps executed: 125444 Episode length: 500 Return: -500.0
I0827 22:27:33.176963 140144978790400 run_experiment.py:447] Starting iteration 9
W0827 22:27:33.726080 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 260 Episode length: 131 Return: -130.00.0
W0827 22:27:35.513444 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:27:36.082092 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:27:36.636446 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 952 Episode length: 114 Return: -113.00.0
W0827 22:27:37.773650 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:27:37.773949 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -158.57

























Steps executed: 120742 Episode length: 97 Return: -96.0.0
I0827 22:28:29.081526 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.61

Steps executed: 125177 Episode length: 500 Return: -500.0
W0827 22:28:29.648210 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:28:30.264402 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 362 Episode length: 119 Return: -118.00.0
W0827 22:28:31.404006 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:28:31.791384 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:28:32.176280 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:28:32.625172 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 883 Episode length: 93 Return: -92.0.00.0
W0827 22:28:33.511790 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:28:33.512098 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -110.11

























Steps executed: 125047 Episode length: 119 Return: -118.0
I0827 22:29:23.413840 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.42
I0827 22:29:23.506207 140144978790400 run_experiment.py:447] Starting iteration 11

Steps executed: 249 Episode length: 249 Return: -248.08.0
W0827 22:29:26.641656 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 946 Episode length: 89 Return: -88.0.08.0
W0827 22:29:27.443819 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:29:27.961581 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:29:27.961962 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -213.40

























Steps executed: 121078 Episode length: 114 Return: -113.0
I0827 22:30:19.009452 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.43

Steps executed: 125114 Episode length: 123 Return: -122.0
W0827 22:30:19.510220 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:30:20.758858 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 499 Episode length: 117 Return: -116.02.0

Steps executed: 928 Episode length: 429 Return: -428.02.0
W0827 22:30:24.061658 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:30:24.061964 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -230.60

























Steps executed: 123265 Episode length: 500 Return: -500.0
I0827 22:31:14.288393 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -499.06
I0827 22:31:14.388440 140144978790400 run_experiment.py:447] Starting iteration 13

Steps executed: 135 Episode length: 135 Return: -134.00.0

Steps executed: 635 Episode length: 500 Return: -500.00.0
W0827 22:31:17.769787 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:31:18.166990 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:31:18.558039 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:31:18.558338 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -201.00


























Steps executed: 125070 Episode length: 413 Return: -412.0
I0827 22:32:09.910351 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.42
I0827 22:32:10.014684 140144978790400 run_experiment.py:447] Starting iteration 14

Steps executed: 424 Episode length: 124 Return: -123.02.0
W0827 22:32:11.299359 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:32:11.836863 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 748 Episode length: 145 Return: -144.02.0
W0827 22:32:13.231665 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:32:14.165965 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:32:14.681258 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:32:14.681579 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -153.43


























Steps executed: 124775 Episode length: 115 Return: -114.0
I0827 22:33:05.892063 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.34
I0827 22:33:06.002121 140144978790400 run_experiment.py:447] Starting iteration 15

Steps executed: 331 Episode length: 174 Return: -173.04.0
W0827 22:33:07.371673 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:33:08.225576 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 888 Episode length: 256 Return: -255.04.0
W0827 22:33:09.664871 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:33:10.489536 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:33:10.489820 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -180.33


























Steps executed: 125000 Episode length: 500 Return: -500.0
I0827 22:34:01.875801 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
I0827 22:34:01.989644 140144978790400 run_experiment.py:447] Starting iteration 16

Steps executed: 467 Episode length: 136 Return: -135.00.0
W0827 22:34:03.932265 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:34:04.342700 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:34:04.772044 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 925 Episode length: 163 Return: -162.00.0
W0827 22:34:05.869496 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:34:06.639776 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:34:06.640072 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -157.86


























Steps executed: 125271 Episode length: 500 Return: -500.0
I0827 22:34:57.812393 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.74
I0827 22:34:57.932075 140144978790400 run_experiment.py:447] Starting iteration 17
W0827 22:34:58.483008 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:34:58.989435 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 456 Episode length: 111 Return: -110.00.0
W0827 22:35:00.045086 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:35:00.422510 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:35:00.994719 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 897 Episode length: 125 Return: -124.00.0
W0827 22:35:01.910344 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:35:02.764434 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:35:02.764749 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -121.22

























Steps executed: 122000 Episode length: 500 Return: -500.0
I0827 22:35:52.953959 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
I0827 22:35:53.076433 140144978790400 run_experiment.py:447] Starting iteration 18

Steps executed: 133 Episode length: 133 Return: -132.00.0
W0827 22:35:54.099920 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:35:54.536433 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:35:54.928084 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 561 Episode length: 105 Return: -104.00.0
W0827 22:35:56.595241 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:35:57.566905 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:35:57.567223 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -152.71


























Steps executed: 121626 Episode length: 150 Return: -149.0
I0827 22:36:49.660464 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.90

Steps executed: 125012 Episode length: 150 Return: -149.0
W0827 22:36:50.355230 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:36:50.820345 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:36:51.253234 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 484 Episode length: 137 Return: -136.09.0
W0827 22:36:52.922441 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 983 Episode length: 243 Return: -242.09.0
W0827 22:36:54.348519 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:36:54.348826 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -154.86

























Steps executed: 125086 Episode length: 453 Return: -452.0
I0827 22:37:44.556715 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.82
I0827 22:37:44.686878 140144978790400 run_experiment.py:447] Starting iteration 20
W0827 22:37:45.093086 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 467 Episode length: 147 Return: -146.02.0
W0827 22:37:46.575899 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 571 Episode length: 104 Return: -103.02.0
W0827 22:37:48.758638 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:37:48.758926 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -200.00

























Steps executed: 124335 Episode length: 163 Return: -162.0
I0827 22:38:38.643668 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.71
I0827 22:38:38.789756 140144978790400 run_experiment.py:447] Starting iteration 21

Steps executed: 114 Episode length: 114 Return: -113.09.0
W0827 22:38:40.416872 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:38:40.869315 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:38:41.334572 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 813 Episode length: 134 Return: -133.09.0
W0827 22:38:42.330772 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:38:42.930835 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:38:43.446805 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:38:43.447137 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -133.75
























Steps executed: 121011 Episode length: 500 Return: -500.0

Steps executed: 125340 Episode length: 500 Return: -500.0
I0827 22:39:32.290563 140144978790400 run_experiment.py:447] Starting iteration 22
W0827 22:39:32.943436 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:39:33.369039 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 407 Episode length: 142 Return: -141.00.0
W0827 22:39:34.563112 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:39:35.184514 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:39:35.690663 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 943 Episode length: 102 Return: -101.00.0
W0827 22:39:37.398382 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:39:37.398737 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -156.75
























Steps executed: 120666 Episode length: 500 Return: -500.0

Steps executed: 125166 Episode length: 500 Return: -500.0
I0827 22:40:26.452739 140144978790400 run_experiment.py:447] Starting iteration 23
W0827 22:40:26.885609 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:40:27.800898 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 526 Episode length: 94 Return: -93.0.00.0
W0827 22:40:28.568575 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:40:29.049864 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:40:29.642549 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 886 Episode length: 91 Return: -90.0.00.0
W0827 22:40:31.499989 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:40:31.500380 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -156.50

























Steps executed: 122913 Episode length: 77 Return: -76.0.0
I0827 22:41:21.440427 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.29
I0827 22:41:21.583079 140144978790400 run_experiment.py:447] Starting iteration 24

Steps executed: 183 Episode length: 83 Return: -82.0004.0

Steps executed: 658 Episode length: 475 Return: -474.04.0
W0827 22:41:24.238237 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:41:24.772943 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:41:25.325164 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:41:25.948703 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:41:25.949044 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -180.00


























Steps executed: 125093 Episode length: 94 Return: -93.0.0
I0827 22:42:16.682843 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.20
I0827 22:42:16.826033 140144978790400 run_experiment.py:447] Starting iteration 25
W0827 22:42:17.167288 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:42:17.543882 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 434 Episode length: 95 Return: -94.0.00.0
W0827 22:42:18.604506 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:42:19.017655 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:42:19.459501 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 919 Episode length: 104 Return: -103.00.0
W0827 22:42:20.631313 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:42:21.232547 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:42:21.232871 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -117.11

























Steps executed: 125000 Episode length: 500 Return: -500.0
I0827 22:43:10.575749 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
I0827 22:43:10.723555 140144978790400 run_experiment.py:447] Starting iteration 26
W0827 22:43:11.252580 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 514 Episode length: 110 Return: -109.00.0
W0827 22:43:12.348273 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:43:12.799632 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:43:13.233442 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 738 Episode length: 117 Return: -116.00.0
W0827 22:43:15.283899 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:43:15.284212 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -161.00
























Steps executed: 122903 Episode length: 116 Return: -115.0
I0827 22:44:03.737424 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.19
I0827 22:44:03.888044 140144978790400 run_experiment.py:447] Starting iteration 27

Steps executed: 188 Episode length: 96 Return: -95.0126.0
W0827 22:44:04.642258 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:44:05.053041 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:44:05.369563 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:44:05.788228 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 704 Episode length: 96 Return: -95.0.06.0
W0827 22:44:06.684910 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:44:07.255075 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:44:07.906508 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:44:07.906839 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -111.44
























Steps executed: 125138 Episode length: 411 Return: -410.0
I0827 22:44:55.112504 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.34
I0827 22:44:55.263800 140144978790400 run_experiment.py:447] Starting iteration 28

Steps executed: 425 Episode length: 88 Return: -87.0.00.0
W0827 22:44:56.656170 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:44:57.019250 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 908 Episode length: 177 Return: -176.00.0
W0827 22:44:59.060760 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:44:59.539991 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:44:59.540348 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -169.33
























Steps executed: 122820 Episode length: 92 Return: -91.000
I0827 22:45:48.228608 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.32

Steps executed: 185 Episode length: 87 Return: -86.0500.0
W0827 22:45:48.779676 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:45:49.129944 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:45:49.563889 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:45:50.353685 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 700 Episode length: 117 Return: -116.00.0
W0827 22:45:51.175841 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:45:51.630139 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:45:52.035314 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0827 22:45:52.707499 140144978790400 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:45:52.707820 140144978790400 run_experiment.py:406] Average undiscounted return per training episode: -120.22

























Done training!: 125118 Episode length: 194 Return: -193.0
I0827 22:46:41.017451 140144978790400 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.78