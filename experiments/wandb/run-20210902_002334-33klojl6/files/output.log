Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0902 00:23:40.612536 139825600018432 run_experiment.py:549] Creating TrainRunner ...
I0902 00:23:40.620469 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:23:40.620619 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:23:40.620787 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:23:40.620861 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:23:40.620920 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0902 00:23:40.620976 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:23:40.621047 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:23:40.621099 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:23:40.621151 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:23:40.621202 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:23:40.621252 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:23:40.621304 139825600018432 dqn_agent.py:283] 	 seed: 1630542220620433
I0902 00:23:40.623014 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:23:40.623126 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:23:40.623202 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:23:40.623266 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:23:40.623323 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:23:40.623393 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:23:40.623450 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:23:40.623533 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:23:40.623613 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:23:40.650144 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:23:40.904079 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:23:40.912925 139825600018432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:23:40.919382 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:23:40.919520 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:23:40.919595 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:23:40.919656 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:23:40.919713 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0902 00:23:40.919787 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:23:40.919885 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:23:40.919953 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:23:40.920034 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:23:40.920101 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:23:40.920168 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:23:40.920241 139825600018432 dqn_agent.py:283] 	 seed: 1630542220919351
I0902 00:23:40.921799 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:23:40.921933 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:23:40.922096 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:23:40.922317 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:23:40.922441 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:23:40.922521 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:23:40.922613 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:23:40.922691 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:23:40.922824 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:23:40.944530 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:23:40.962209 139825600018432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:23:40.962384 139825600018432 replay_runner.py:41] Starting iteration 0
Steps executed: 220 Episode length: 116 Return: -345.23515440741215
INFO:tensorflow:Average training steps per second: 244.28
I0902 00:23:45.056243 139825600018432 replay_runner.py:36] Average training steps per second: 244.28
I0902 00:23:45.786584 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -347.83
INFO:tensorflow:Starting iteration 1

Steps executed: 193 Episode length: 95 Return: -334.506684814744745
INFO:tensorflow:Average training steps per second: 330.66

Steps executed: 450 Episode length: 257 Return: -224.12330592534545
I0902 00:23:52.424282 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.27
INFO:tensorflow:Starting iteration 2

Steps executed: 221 Episode length: 99 Return: -270.111317806798435
INFO:tensorflow:Average training steps per second: 321.79
I0902 00:23:58.753883 139825600018432 replay_runner.py:36] Average training steps per second: 321.79
I0902 00:23:58.887962 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -312.21
INFO:tensorflow:Starting iteration 3

Steps executed: 324 Episode length: 142 Return: -219.40124367855384
INFO:tensorflow:Average training steps per second: 374.37
I0902 00:24:04.822990 139825600018432 replay_runner.py:36] Average training steps per second: 374.37
I0902 00:24:05.036888 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.25
INFO:tensorflow:Starting iteration 4

Steps executed: 134 Episode length: 134 Return: -96.920136292986514
INFO:tensorflow:Average training steps per second: 369.42

Steps executed: 1134 Episode length: 1000 Return: -165.79479967810295
I0902 00:24:12.651204 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.36
INFO:tensorflow:Starting iteration 5
I0902 00:24:16.012360 139825600018432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 338.75

Steps executed: 1000 Episode length: 1000 Return: -90.135562656691355
I0902 00:24:21.289911 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.14
INFO:tensorflow:Starting iteration 6
I0902 00:24:24.594622 139825600018432 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 334.30

Steps executed: 777 Episode length: 777 Return: -307.2241695177893355
I0902 00:24:28.705872 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.22
INFO:tensorflow:Starting iteration 7
I0902 00:24:32.101683 139825600018432 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 346.87

Steps executed: 1000 Episode length: 1000 Return: -156.21499138153355
I0902 00:24:37.567246 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.21
INFO:tensorflow:Starting iteration 8
I0902 00:24:40.841290 139825600018432 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 342.70

Steps executed: 1000 Episode length: 1000 Return: -101.36138924585039
I0902 00:24:46.417008 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.36
INFO:tensorflow:Starting iteration 9
I0902 00:24:49.697431 139825600018432 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 351.18

Steps executed: 1000 Episode length: 1000 Return: -55.216613501358479
I0902 00:24:54.437369 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -55.22
INFO:tensorflow:Starting iteration 10
I0902 00:24:57.731180 139825600018432 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 351.19

Steps executed: 1000 Episode length: 1000 Return: -280.88487126723805
I0902 00:25:02.148931 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.88
INFO:tensorflow:Starting iteration 11
I0902 00:25:05.515446 139825600018432 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 351.51

Steps executed: 519 Episode length: 519 Return: -216.8756105071665605
I0902 00:25:08.953788 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.88
INFO:tensorflow:Starting iteration 12

Steps executed: 1000 Episode length: 1000 Return: -221.60369833536294
INFO:tensorflow:Average training steps per second: 382.64
I0902 00:25:15.040495 139825600018432 replay_runner.py:36] Average training steps per second: 382.64
I0902 00:25:16.442277 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.60
INFO:tensorflow:Starting iteration 13
I0902 00:25:19.969445 139825600018432 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 346.06

Steps executed: 1000 Episode length: 1000 Return: -117.53239393183436
I0902 00:25:25.889019 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.53
INFO:tensorflow:Starting iteration 14
I0902 00:25:29.246410 139825600018432 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 339.75

Steps executed: 1000 Episode length: 1000 Return: -80.544264799844066
I0902 00:25:34.706362 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.54
INFO:tensorflow:Starting iteration 15

Steps executed: 694 Episode length: 694 Return: -230.2086088024631066
INFO:tensorflow:Average training steps per second: 316.93
I0902 00:25:41.054596 139825600018432 replay_runner.py:36] Average training steps per second: 316.93
I0902 00:25:41.823559 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.21
INFO:tensorflow:Starting iteration 16

Steps executed: 510 Episode length: 510 Return: 224.54700029364111066
INFO:tensorflow:Average training steps per second: 317.78
I0902 00:25:48.226792 139825600018432 replay_runner.py:36] Average training steps per second: 317.78
I0902 00:25:48.800061 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: 224.55
INFO:tensorflow:Starting iteration 17

Steps executed: 316 Episode length: 316 Return: -174.7506044775881366
INFO:tensorflow:Average training steps per second: 317.29
I0902 00:25:55.207216 139825600018432 replay_runner.py:36] Average training steps per second: 317.29
I0902 00:25:55.486798 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.75
INFO:tensorflow:Starting iteration 18

Steps executed: 266 Episode length: 155 Return: -268.3376851574856366
INFO:tensorflow:Average training steps per second: 332.00
I0902 00:26:01.812281 139825600018432 replay_runner.py:36] Average training steps per second: 332.00
I0902 00:26:01.966728 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -362.18
INFO:tensorflow:Starting iteration 19
I0902 00:26:05.355034 139825600018432 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 322.90
I0902 00:26:08.452346 139825600018432 replay_runner.py:36] Average training steps per second: 322.90

Steps executed: 232 Episode length: 232 Return: -450.6954162238807366
INFO:tensorflow:Starting iteration 20
I0902 00:26:12.041732 139825600018432 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 330.79

Steps executed: 332 Episode length: 215 Return: -505.1485392485254366
I0902 00:26:15.298743 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -628.09
INFO:tensorflow:Starting iteration 21

Steps executed: 221 Episode length: 221 Return: -293.1296871563969366
INFO:tensorflow:Average training steps per second: 324.99
I0902 00:26:21.756982 139825600018432 replay_runner.py:36] Average training steps per second: 324.99
I0902 00:26:21.944002 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.13
INFO:tensorflow:Starting iteration 22

Steps executed: 382 Episode length: 184 Return: -8.005720646833609366
INFO:tensorflow:Average training steps per second: 325.60
I0902 00:26:28.357790 139825600018432 replay_runner.py:36] Average training steps per second: 325.60
I0902 00:26:28.624052 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -53.26
INFO:tensorflow:Starting iteration 23
I0902 00:26:31.988039 139825600018432 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 326.01

Steps executed: 305 Episode length: 169 Return: -111.0455333869414966
I0902 00:26:35.247193 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.30
INFO:tensorflow:Starting iteration 24

Steps executed: 389 Episode length: 389 Return: -34.11357768310414966
INFO:tensorflow:Average training steps per second: 338.25
I0902 00:26:41.578554 139825600018432 replay_runner.py:36] Average training steps per second: 338.25
I0902 00:26:42.017201 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -34.11
INFO:tensorflow:Starting iteration 25

Steps executed: 218 Episode length: 87 Return: -314.64059234928385966
INFO:tensorflow:Average training steps per second: 343.81
I0902 00:26:48.318320 139825600018432 replay_runner.py:36] Average training steps per second: 343.81
I0902 00:26:48.459442 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -483.35
INFO:tensorflow:Starting iteration 26

Steps executed: 155 Episode length: 155 Return: -96.90432165491355966
INFO:tensorflow:Average training steps per second: 362.85

Steps executed: 398 Episode length: 243 Return: 16.273102492260725966
I0902 00:26:54.959270 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -40.32
INFO:tensorflow:Starting iteration 27

Steps executed: 219 Episode length: 152 Return: 0.0720003285229040666
INFO:tensorflow:Average training steps per second: 357.62
I0902 00:27:01.212845 139825600018432 replay_runner.py:36] Average training steps per second: 357.62
I0902 00:27:01.326316 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.71
INFO:tensorflow:Starting iteration 28

Steps executed: 505 Episode length: 316 Return: -236.9358846997710766
INFO:tensorflow:Average training steps per second: 338.01
I0902 00:27:07.613191 139825600018432 replay_runner.py:36] Average training steps per second: 338.01
I0902 00:27:08.007258 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.46
INFO:tensorflow:Starting iteration 29

Steps executed: 273 Episode length: 137 Return: -194.2204290430484866
INFO:tensorflow:Average training steps per second: 350.73
I0902 00:27:14.060936 139825600018432 replay_runner.py:36] Average training steps per second: 350.73

Done fixed training!Episode length: 137 Return: -194.2204290430484866