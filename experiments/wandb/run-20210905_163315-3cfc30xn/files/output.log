I0905 16:33:23.125805 139789596633088 run_experiment.py:549] Creating TrainRunner ...
I0905 16:33:23.163555 139789596633088 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:33:23.164131 139789596633088 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:33:23.164367 139789596633088 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:33:23.164827 139789596633088 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:33:23.165481 139789596633088 dqn_agent.py:275] 	 update_period: 4
I0905 16:33:23.165920 139789596633088 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:33:23.169118 139789596633088 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:33:23.169350 139789596633088 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:33:23.170061 139789596633088 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:33:23.170414 139789596633088 dqn_agent.py:280] 	 optimizer: adam
I0905 16:33:23.170676 139789596633088 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:33:23.171214 139789596633088 dqn_agent.py:283] 	 seed: 1630859603163480
I0905 16:33:23.181026 139789596633088 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:33:23.181344 139789596633088 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:33:23.181680 139789596633088 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:33:23.182569 139789596633088 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:33:23.182785 139789596633088 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:33:23.183063 139789596633088 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:33:23.183289 139789596633088 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:33:23.183475 139789596633088 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:33:23.183613 139789596633088 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:33:26.305055 139789596633088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0905 16:33:27.106123 139789596633088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:27.132616 139789596633088 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:33:27.168142 139789596633088 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:33:27.168508 139789596633088 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:33:27.168696 139789596633088 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:33:27.168898 139789596633088 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:33:27.169051 139789596633088 dqn_agent.py:275] 	 update_period: 4
I0905 16:33:27.169339 139789596633088 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:33:27.169727 139789596633088 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:33:27.170047 139789596633088 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:33:27.170503 139789596633088 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:33:27.171858 139789596633088 dqn_agent.py:280] 	 optimizer: adam
I0905 16:33:27.172905 139789596633088 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:33:27.173083 139789596633088 dqn_agent.py:283] 	 seed: 1630859607168078
I0905 16:33:27.197254 139789596633088 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:33:27.198480 139789596633088 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:33:27.198693 139789596633088 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:33:27.198882 139789596633088 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:33:27.199354 139789596633088 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:33:27.199523 139789596633088 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:33:27.199788 139789596633088 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:33:27.200058 139789596633088 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:33:27.200637 139789596633088 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:33:27.260413 139789596633088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:27.302298 139789596633088 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:33:27.302766 139789596633088 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 102.40
I0905 16:33:37.068817 139789596633088 replay_runner.py:36] Average training steps per second: 102.40
Steps executed: 247 Episode length: 247 Return: -331.09159843572655
I0905 16:33:38.950365 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.09
INFO:tensorflow:Starting iteration 1

Steps executed: 326 Episode length: 158 Return: -352.83649617227395
INFO:tensorflow:Average training steps per second: 165.98
I0905 16:33:50.262467 139789596633088 replay_runner.py:36] Average training steps per second: 165.98
I0905 16:33:50.708903 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -360.09
INFO:tensorflow:Starting iteration 2

Steps executed: 222 Episode length: 222 Return: -201.29927148788136
INFO:tensorflow:Average training steps per second: 155.84
I0905 16:34:01.952422 139789596633088 replay_runner.py:36] Average training steps per second: 155.84
I0905 16:34:02.307157 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.30
INFO:tensorflow:Starting iteration 3
I0905 16:34:07.480569 139789596633088 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 156.95
I0905 16:34:13.852977 139789596633088 replay_runner.py:36] Average training steps per second: 156.95

Steps executed: 1000 Episode length: 1000 Return: -11.400091126928352
INFO:tensorflow:Starting iteration 4
I0905 16:34:23.513190 139789596633088 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 161.56

Steps executed: 1000 Episode length: 1000 Return: -133.65993695591575
I0905 16:34:33.767341 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.66
INFO:tensorflow:Starting iteration 5
I0905 16:34:38.098693 139789596633088 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 158.66

Steps executed: 1000 Episode length: 1000 Return: -178.65423502471735
I0905 16:34:48.003288 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.65
INFO:tensorflow:Starting iteration 6
I0905 16:34:53.051017 139789596633088 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 156.12

Steps executed: 1000 Episode length: 1000 Return: -140.69084898087085
I0905 16:35:02.811606 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.69
INFO:tensorflow:Starting iteration 7
I0905 16:35:08.077560 139789596633088 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 171.81

Steps executed: 1000 Episode length: 1000 Return: -173.39368224923385
I0905 16:35:18.596712 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.39
INFO:tensorflow:Starting iteration 8
I0905 16:35:23.582668 139789596633088 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 151.00

Steps executed: 1000 Episode length: 1000 Return: -126.75231841867295
I0905 16:35:35.615057 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.75
INFO:tensorflow:Starting iteration 9
I0905 16:35:40.638076 139789596633088 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 184.20

Steps executed: 1000 Episode length: 1000 Return: -152.42387703794635
I0905 16:35:50.349848 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.42
INFO:tensorflow:Starting iteration 10
I0905 16:35:55.264462 139789596633088 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 176.23

Steps executed: 1000 Episode length: 1000 Return: -172.53072359763294
I0905 16:36:03.355277 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -172.53
INFO:tensorflow:Starting iteration 11
I0905 16:36:08.202262 139789596633088 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 184.13

Steps executed: 1000 Episode length: 1000 Return: -61.588130773091934
I0905 16:36:16.390584 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.59
INFO:tensorflow:Starting iteration 12

Steps executed: 201 Episode length: 201 Return: -180.1878935896720634
INFO:tensorflow:Average training steps per second: 220.98
I0905 16:36:25.397580 139789596633088 replay_runner.py:36] Average training steps per second: 220.98
I0905 16:36:25.537727 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.19
INFO:tensorflow:Starting iteration 13
I0905 16:36:29.485009 139789596633088 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 288.80

Steps executed: 1000 Episode length: 1000 Return: -137.30079801932692
I0905 16:36:35.136178 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.30
INFO:tensorflow:Starting iteration 14
I0905 16:36:38.068903 139789596633088 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 391.08

Steps executed: 1000 Episode length: 1000 Return: -47.441876925540212
I0905 16:36:42.418655 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -47.44
INFO:tensorflow:Starting iteration 15

Steps executed: 1000 Episode length: 1000 Return: -74.614216886571162
INFO:tensorflow:Average training steps per second: 384.89
I0905 16:36:48.017559 139789596633088 replay_runner.py:36] Average training steps per second: 384.89
I0905 16:36:49.250610 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.61
INFO:tensorflow:Starting iteration 16

Steps executed: 335 Episode length: 335 Return: -15.48174692294414162
INFO:tensorflow:Average training steps per second: 390.61
I0905 16:36:54.892548 139789596633088 replay_runner.py:36] Average training steps per second: 390.61
I0905 16:36:55.092125 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -15.48
INFO:tensorflow:Starting iteration 17

Steps executed: 311 Episode length: 147 Return: -242.7971332521834762
INFO:tensorflow:Average training steps per second: 400.36
I0905 16:37:00.659783 139789596633088 replay_runner.py:36] Average training steps per second: 400.36
I0905 16:37:00.777859 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.22
INFO:tensorflow:Starting iteration 18

Steps executed: 239 Episode length: 123 Return: -457.1097071188561462
INFO:tensorflow:Average training steps per second: 384.87
I0905 16:37:06.390290 139789596633088 replay_runner.py:36] Average training steps per second: 384.87
I0905 16:37:06.493751 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -354.32
INFO:tensorflow:Starting iteration 19

Steps executed: 462 Episode length: 407 Return: -155.3515647218252462
INFO:tensorflow:Average training steps per second: 390.43
I0905 16:37:12.064381 139789596633088 replay_runner.py:36] Average training steps per second: 390.43
I0905 16:37:12.405810 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.75
INFO:tensorflow:Starting iteration 20

Steps executed: 408 Episode length: 265 Return: -65.27052606558533662
INFO:tensorflow:Average training steps per second: 394.25
I0905 16:37:18.023002 139789596633088 replay_runner.py:36] Average training steps per second: 394.25
I0905 16:37:18.283543 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.40
INFO:tensorflow:Starting iteration 21

Steps executed: 240 Episode length: 111 Return: -626.0137531931429662
INFO:tensorflow:Average training steps per second: 395.59
I0905 16:37:23.941080 139789596633088 replay_runner.py:36] Average training steps per second: 395.59
I0905 16:37:24.047646 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -388.54
INFO:tensorflow:Starting iteration 22
I0905 16:37:27.073959 139789596633088 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 391.87

Steps executed: 1000 Episode length: 1000 Return: -143.03108661458464
I0905 16:37:30.997452 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.03
INFO:tensorflow:Starting iteration 23

Steps executed: 474 Episode length: 340 Return: 226.88745871092868864
INFO:tensorflow:Average training steps per second: 391.83
I0905 16:37:36.662853 139789596633088 replay_runner.py:36] Average training steps per second: 391.83
I0905 16:37:37.009242 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: 43.17
INFO:tensorflow:Starting iteration 24

Steps executed: 241 Episode length: 119 Return: -337.1396298894411864
INFO:tensorflow:Average training steps per second: 395.87
I0905 16:37:42.664698 139789596633088 replay_runner.py:36] Average training steps per second: 395.87
I0905 16:37:42.785489 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.27
INFO:tensorflow:Starting iteration 25

Steps executed: 101 Episode length: 101 Return: -392.9978633947823864
INFO:tensorflow:Average training steps per second: 394.19

Steps executed: 1101 Episode length: 1000 Return: 33.0044153407675664
I0905 16:37:50.229263 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.00
INFO:tensorflow:Starting iteration 26
I0905 16:37:53.283109 139789596633088 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 399.78

Steps executed: 402 Episode length: 402 Return: -276.7129450919548664
I0905 16:37:56.161178 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.71
INFO:tensorflow:Starting iteration 27
I0905 16:37:59.269564 139789596633088 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 393.05

Steps executed: 147 Episode length: 147 Return: -125.7035859924863864

Steps executed: 1147 Episode length: 1000 Return: 16.8590289007892024
INFO:tensorflow:Starting iteration 28
I0905 16:38:06.688717 139789596633088 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 393.04
I0905 16:38:09.233193 139789596633088 replay_runner.py:36] Average training steps per second: 393.04

Steps executed: 1000 Episode length: 1000 Return: 26.3668237312254724
INFO:tensorflow:Starting iteration 29
I0905 16:38:15.036448 139789596633088 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 348.24
I0905 16:38:17.908263 139789596633088 replay_runner.py:36] Average training steps per second: 348.24


Done fixed training! Episode length: 1000 Return: 107.396922864431474