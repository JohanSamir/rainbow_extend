Loaded trained dqn in acrobot
Training fixed agent 7, please be patient, may be a while...
I0901 12:22:08.724815 140283033229312 run_experiment.py:549] Creating TrainRunner ...
I0901 12:22:08.733780 140283033229312 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:22:08.734282 140283033229312 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:22:08.734539 140283033229312 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:22:08.734710 140283033229312 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:22:08.734895 140283033229312 dqn_agent.py:275] 	 update_period: 4
I0901 12:22:08.735007 140283033229312 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:22:08.735085 140283033229312 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:22:08.735208 140283033229312 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:22:08.735345 140283033229312 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:22:08.735435 140283033229312 dqn_agent.py:280] 	 optimizer: adam
I0901 12:22:08.735533 140283033229312 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:22:08.735599 140283033229312 dqn_agent.py:283] 	 seed: 1630498928733699
I0901 12:22:08.738322 140283033229312 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:22:08.738486 140283033229312 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 12:22:08.738604 140283033229312 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:22:08.738680 140283033229312 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:22:08.738774 140283033229312 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:22:08.738845 140283033229312 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:22:08.738902 140283033229312 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:22:08.738955 140283033229312 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:22:08.739008 140283033229312 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:22:08.995594 140283033229312 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:22:09.400034 140283033229312 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:22:09.412773 140283033229312 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:22:09.420416 140283033229312 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:22:09.420639 140283033229312 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:22:09.420943 140283033229312 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:22:09.421041 140283033229312 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:22:09.421126 140283033229312 dqn_agent.py:275] 	 update_period: 4
I0901 12:22:09.421212 140283033229312 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:22:09.421300 140283033229312 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:22:09.421392 140283033229312 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:22:09.421472 140283033229312 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:22:09.421567 140283033229312 dqn_agent.py:280] 	 optimizer: adam
I0901 12:22:09.421639 140283033229312 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:22:09.421715 140283033229312 dqn_agent.py:283] 	 seed: 1630498929420365
I0901 12:22:09.424495 140283033229312 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:22:09.424739 140283033229312 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 12:22:09.424942 140283033229312 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:22:09.425108 140283033229312 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:22:09.425318 140283033229312 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:22:09.425454 140283033229312 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:22:09.425563 140283033229312 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:22:09.425663 140283033229312 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:22:09.425772 140283033229312 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:22:09.460516 140283033229312 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:22:09.479731 140283033229312 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:22:09.479977 140283033229312 replay_runner.py:41] Starting iteration 0
Steps executed: 376 Episode length: 376 Return: -375.0
INFO:tensorflow:Average training steps per second: 139.20
I0901 12:22:16.664013 140283033229312 replay_runner.py:36] Average training steps per second: 139.20
I0901 12:22:18.168610 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -375.00
INFO:tensorflow:Starting iteration 1

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 196.10
I0901 12:22:23.500228 140283033229312 replay_runner.py:36] Average training steps per second: 196.10
I0901 12:22:23.934006 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 2
I0901 12:22:24.185760 140283033229312 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 193.72
I0901 12:22:29.348400 140283033229312 replay_runner.py:36] Average training steps per second: 193.72
I0901 12:22:29.810510 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 3

Steps executed: 306 Episode length: 146 Return: -145.0
INFO:tensorflow:Average training steps per second: 188.04
I0901 12:22:35.368681 140283033229312 replay_runner.py:36] Average training steps per second: 188.04
I0901 12:22:35.622744 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.00
INFO:tensorflow:Starting iteration 4

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 196.63
I0901 12:22:40.953933 140283033229312 replay_runner.py:36] Average training steps per second: 196.63
I0901 12:22:41.422027 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 5
I0901 12:22:41.672877 140283033229312 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 188.55
I0901 12:22:46.977034 140283033229312 replay_runner.py:36] Average training steps per second: 188.55
I0901 12:22:47.398459 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6
I0901 12:22:47.641629 140283033229312 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 193.67
I0901 12:22:52.805662 140283033229312 replay_runner.py:36] Average training steps per second: 193.67
I0901 12:22:53.278761 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7
I0901 12:22:53.530106 140283033229312 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 195.95
I0901 12:22:58.633807 140283033229312 replay_runner.py:36] Average training steps per second: 195.95
I0901 12:22:59.074315 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 8
I0901 12:22:59.318913 140283033229312 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 191.45
I0901 12:23:04.542539 140283033229312 replay_runner.py:36] Average training steps per second: 191.45
I0901 12:23:04.996546 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 9
I0901 12:23:05.222939 140283033229312 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 188.25
I0901 12:23:10.535608 140283033229312 replay_runner.py:36] Average training steps per second: 188.25
I0901 12:23:10.960610 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 10

Steps executed: 308 Episode length: 161 Return: -160.0
INFO:tensorflow:Average training steps per second: 191.25
I0901 12:23:16.438703 140283033229312 replay_runner.py:36] Average training steps per second: 191.25
I0901 12:23:16.722461 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.00
INFO:tensorflow:Starting iteration 11

Steps executed: 311 Episode length: 145 Return: -144.0
INFO:tensorflow:Average training steps per second: 192.92
I0901 12:23:22.165491 140283033229312 replay_runner.py:36] Average training steps per second: 192.92
I0901 12:23:22.426521 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.50
INFO:tensorflow:Starting iteration 12

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 193.78
I0901 12:23:27.835058 140283033229312 replay_runner.py:36] Average training steps per second: 193.78
I0901 12:23:28.295936 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 13
I0901 12:23:28.525029 140283033229312 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 196.21
I0901 12:23:33.622029 140283033229312 replay_runner.py:36] Average training steps per second: 196.21
I0901 12:23:34.058008 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 14

Steps executed: 264 Episode length: 124 Return: -123.0
INFO:tensorflow:Average training steps per second: 193.26
I0901 12:23:39.456751 140283033229312 replay_runner.py:36] Average training steps per second: 193.26
I0901 12:23:39.685754 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.00
INFO:tensorflow:Starting iteration 15

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 190.97
I0901 12:23:45.166035 140283033229312 replay_runner.py:36] Average training steps per second: 190.97
I0901 12:23:45.629190 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 16

Steps executed: 280 Episode length: 121 Return: -120.0
INFO:tensorflow:Average training steps per second: 197.95
I0901 12:23:50.930555 140283033229312 replay_runner.py:36] Average training steps per second: 197.95
I0901 12:23:51.172354 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.33
INFO:tensorflow:Starting iteration 17
I0901 12:23:51.416917 140283033229312 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 187.63

Steps executed: 433 Episode length: 259 Return: -258.0
I0901 12:23:57.141488 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.33
INFO:tensorflow:Starting iteration 18

Steps executed: 261 Episode length: 98 Return: -97.0.0
INFO:tensorflow:Average training steps per second: 196.12
I0901 12:24:02.482452 140283033229312 replay_runner.py:36] Average training steps per second: 196.12
I0901 12:24:02.716612 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.00
INFO:tensorflow:Starting iteration 19

Steps executed: 200 Episode length: 100 Return: -99.00
INFO:tensorflow:Average training steps per second: 185.42
I0901 12:24:08.351657 140283033229312 replay_runner.py:36] Average training steps per second: 185.42
I0901 12:24:08.518821 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.00
INFO:tensorflow:Starting iteration 20

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 194.22
I0901 12:24:13.903011 140283033229312 replay_runner.py:36] Average training steps per second: 194.22
I0901 12:24:14.374638 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 21

Steps executed: 200 Episode length: 120 Return: -119.0
INFO:tensorflow:Average training steps per second: 190.50
I0901 12:24:19.874253 140283033229312 replay_runner.py:36] Average training steps per second: 190.50
I0901 12:24:20.049481 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.00
INFO:tensorflow:Starting iteration 22

Steps executed: 269 Episode length: 110 Return: -109.0
INFO:tensorflow:Average training steps per second: 190.26
I0901 12:24:25.548884 140283033229312 replay_runner.py:36] Average training steps per second: 190.26
I0901 12:24:25.782779 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.67
INFO:tensorflow:Starting iteration 23

Steps executed: 205 Episode length: 85 Return: -84.0.0
INFO:tensorflow:Average training steps per second: 191.82
I0901 12:24:31.241640 140283033229312 replay_runner.py:36] Average training steps per second: 191.82
I0901 12:24:31.424909 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.50
INFO:tensorflow:Starting iteration 24

Steps executed: 164 Episode length: 92 Return: -91.0.0
INFO:tensorflow:Average training steps per second: 192.64
I0901 12:24:36.861043 140283033229312 replay_runner.py:36] Average training steps per second: 192.64

Steps executed: 253 Episode length: 89 Return: -88.0.0
INFO:tensorflow:Starting iteration 25

Steps executed: 263 Episode length: 142 Return: -141.0
INFO:tensorflow:Average training steps per second: 196.61
I0901 12:24:42.440552 140283033229312 replay_runner.py:36] Average training steps per second: 196.61
I0901 12:24:42.655313 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.50
INFO:tensorflow:Starting iteration 26

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 209.17
I0901 12:24:47.667114 140283033229312 replay_runner.py:36] Average training steps per second: 209.17
I0901 12:24:48.082977 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 27

Steps executed: 202 Episode length: 109 Return: -108.0
INFO:tensorflow:Average training steps per second: 200.56
I0901 12:24:53.283583 140283033229312 replay_runner.py:36] Average training steps per second: 200.56
I0901 12:24:53.444343 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.00
INFO:tensorflow:Starting iteration 28

Steps executed: 594 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 206.43
I0901 12:24:58.506799 140283033229312 replay_runner.py:36] Average training steps per second: 206.43
I0901 12:24:58.995057 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.50
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 93 Return: -92.0.0
INFO:tensorflow:Average training steps per second: 193.69
I0901 12:25:04.395005 140283033229312 replay_runner.py:36] Average training steps per second: 193.69
I0901 12:25:04.596578 140283033229312 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.67