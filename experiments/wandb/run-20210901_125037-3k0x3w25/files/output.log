Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0901 12:50:44.205896 139982171817984 run_experiment.py:549] Creating TrainRunner ...
I0901 12:50:44.217741 139982171817984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:50:44.218222 139982171817984 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:50:44.218428 139982171817984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:50:44.218527 139982171817984 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:50:44.218605 139982171817984 dqn_agent.py:275] 	 update_period: 4
I0901 12:50:44.218679 139982171817984 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:50:44.218848 139982171817984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:50:44.219009 139982171817984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:50:44.219128 139982171817984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:50:44.219414 139982171817984 dqn_agent.py:280] 	 optimizer: adam
I0901 12:50:44.219767 139982171817984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:50:44.219920 139982171817984 dqn_agent.py:283] 	 seed: 1630500644217677
I0901 12:50:44.223914 139982171817984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:50:44.224240 139982171817984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:50:44.224461 139982171817984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:50:44.224647 139982171817984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:50:44.224816 139982171817984 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:50:44.225002 139982171817984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:50:44.225187 139982171817984 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:50:44.225308 139982171817984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:50:44.225517 139982171817984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:50:44.269164 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:44.673184 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:44.688347 139982171817984 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:50:44.722028 139982171817984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:50:44.722337 139982171817984 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:50:44.722521 139982171817984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:50:44.722691 139982171817984 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:50:44.722891 139982171817984 dqn_agent.py:275] 	 update_period: 4
I0901 12:50:44.723119 139982171817984 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:50:44.723253 139982171817984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:50:44.723406 139982171817984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:50:44.723595 139982171817984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:50:44.723828 139982171817984 dqn_agent.py:280] 	 optimizer: adam
I0901 12:50:44.723991 139982171817984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:50:44.724509 139982171817984 dqn_agent.py:283] 	 seed: 1630500644721964
I0901 12:50:44.728118 139982171817984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:50:44.728356 139982171817984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:50:44.728558 139982171817984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:50:44.728819 139982171817984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:50:44.729015 139982171817984 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:50:44.729151 139982171817984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:50:44.729268 139982171817984 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:50:44.729346 139982171817984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:50:44.729589 139982171817984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:50:44.768555 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:44.791140 139982171817984 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:50:44.791373 139982171817984 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 154.29
I0901 12:50:51.273147 139982171817984 replay_runner.py:36] Average training steps per second: 154.29
Steps executed: 222 Episode length: 143 Return: -598.9911097945675
I0901 12:50:52.452675 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -561.58
INFO:tensorflow:Starting iteration 1

Steps executed: 277 Episode length: 121 Return: -498.59531570350975
INFO:tensorflow:Average training steps per second: 218.67
I0901 12:51:01.362449 139982171817984 replay_runner.py:36] Average training steps per second: 218.67
I0901 12:51:01.632347 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -415.15
INFO:tensorflow:Starting iteration 2

Steps executed: 264 Episode length: 87 Return: -516.339864220283545
INFO:tensorflow:Average training steps per second: 221.11
I0901 12:51:10.592535 139982171817984 replay_runner.py:36] Average training steps per second: 221.11
I0901 12:51:10.839020 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -302.08
INFO:tensorflow:Starting iteration 3

Steps executed: 89 Episode length: 89 Return: -640.8378816690105545
INFO:tensorflow:Average training steps per second: 222.14

Steps executed: 247 Episode length: 158 Return: -157.30531044940292
I0901 12:51:20.011650 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -399.07
INFO:tensorflow:Starting iteration 4

Steps executed: 272 Episode length: 112 Return: -42.975390136289576
INFO:tensorflow:Average training steps per second: 222.41
I0901 12:51:28.948404 139982171817984 replay_runner.py:36] Average training steps per second: 222.41
I0901 12:51:29.187624 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.48
INFO:tensorflow:Starting iteration 5

Steps executed: 181 Episode length: 74 Return: -225.202003287597515
INFO:tensorflow:Average training steps per second: 226.61

Steps executed: 254 Episode length: 73 Return: -305.978544001959215
I0901 12:51:38.019255 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.65
INFO:tensorflow:Starting iteration 6

Steps executed: 284 Episode length: 101 Return: -189.49311455449183
INFO:tensorflow:Average training steps per second: 227.60
I0901 12:51:46.823922 139982171817984 replay_runner.py:36] Average training steps per second: 227.60
I0901 12:51:47.063819 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.01
INFO:tensorflow:Starting iteration 7
I0901 12:51:51.512700 139982171817984 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 222.77

Steps executed: 233 Episode length: 118 Return: -39.274960205524943
I0901 12:51:56.192096 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -35.75
INFO:tensorflow:Starting iteration 8

Steps executed: 285 Episode length: 285 Return: 151.697215082741623
INFO:tensorflow:Average training steps per second: 220.62
I0901 12:52:05.170144 139982171817984 replay_runner.py:36] Average training steps per second: 220.62
I0901 12:52:05.513364 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: 151.70
INFO:tensorflow:Starting iteration 9

Steps executed: 305 Episode length: 118 Return: -37.492604714088486
INFO:tensorflow:Average training steps per second: 223.32
I0901 12:52:14.432047 139982171817984 replay_runner.py:36] Average training steps per second: 223.32
I0901 12:52:14.697939 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.03
INFO:tensorflow:Starting iteration 10

Steps executed: 256 Episode length: 82 Return: -142.081128376918346
INFO:tensorflow:Average training steps per second: 229.49
I0901 12:52:23.495331 139982171817984 replay_runner.py:36] Average training steps per second: 229.49
I0901 12:52:23.722791 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.47
INFO:tensorflow:Starting iteration 11

Steps executed: 204 Episode length: 69 Return: -150.451140739095936
INFO:tensorflow:Average training steps per second: 235.34
I0901 12:52:32.406049 139982171817984 replay_runner.py:36] Average training steps per second: 235.34
I0901 12:52:32.552229 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.24
INFO:tensorflow:Starting iteration 12

Steps executed: 220 Episode length: 86 Return: -271.176447585038836
INFO:tensorflow:Average training steps per second: 225.63
I0901 12:52:41.381069 139982171817984 replay_runner.py:36] Average training steps per second: 225.63
I0901 12:52:41.538030 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.23
INFO:tensorflow:Starting iteration 13

Steps executed: 204 Episode length: 80 Return: -327.698715656939166
INFO:tensorflow:Average training steps per second: 222.76
I0901 12:52:50.518405 139982171817984 replay_runner.py:36] Average training steps per second: 222.76
I0901 12:52:50.670710 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.39
INFO:tensorflow:Starting iteration 14

Steps executed: 329 Episode length: 132 Return: -28.822782093658446
INFO:tensorflow:Average training steps per second: 227.30
I0901 12:52:59.287139 139982171817984 replay_runner.py:36] Average training steps per second: 227.30
I0901 12:52:59.559570 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.46
INFO:tensorflow:Starting iteration 15
I0901 12:53:03.906594 139982171817984 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 221.76

Steps executed: 271 Episode length: 83 Return: -488.739428009151636
I0901 12:53:08.625424 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -299.80
INFO:tensorflow:Starting iteration 16

Steps executed: 251 Episode length: 81 Return: -384.168497079029636
INFO:tensorflow:Average training steps per second: 222.02
I0901 12:53:17.487783 139982171817984 replay_runner.py:36] Average training steps per second: 222.02
I0901 12:53:17.667533 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.96
INFO:tensorflow:Starting iteration 17

Steps executed: 119 Episode length: 61 Return: -48.2229152167534536
INFO:tensorflow:Average training steps per second: 232.35

Steps executed: 262 Episode length: 66 Return: -133.965513463622416
I0901 12:53:26.572704 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.08
INFO:tensorflow:Starting iteration 18

Steps executed: 228 Episode length: 82 Return: -158.093405913423686
INFO:tensorflow:Average training steps per second: 223.22
I0901 12:53:35.504306 139982171817984 replay_runner.py:36] Average training steps per second: 223.22
I0901 12:53:35.676923 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.35
INFO:tensorflow:Starting iteration 19
I0901 12:53:40.055765 139982171817984 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 226.82
I0901 12:53:44.465020 139982171817984 replay_runner.py:36] Average training steps per second: 226.82

Steps executed: 230 Episode length: 104 Return: -307.06069511046276
INFO:tensorflow:Starting iteration 20

Steps executed: 272 Episode length: 83 Return: -408.273255155986826
INFO:tensorflow:Average training steps per second: 224.89
I0901 12:53:53.495952 139982171817984 replay_runner.py:36] Average training steps per second: 224.89
I0901 12:53:53.694803 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.74
INFO:tensorflow:Starting iteration 21
I0901 12:53:57.996839 139982171817984 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 218.20

Steps executed: 239 Episode length: 74 Return: -217.291639674651466
I0901 12:54:02.768360 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.49
INFO:tensorflow:Starting iteration 22

Steps executed: 264 Episode length: 198 Return: -284.77988490111636
INFO:tensorflow:Average training steps per second: 223.28
I0901 12:54:11.585635 139982171817984 replay_runner.py:36] Average training steps per second: 223.28
I0901 12:54:11.855991 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -251.96
INFO:tensorflow:Starting iteration 23

Steps executed: 310 Episode length: 155 Return: -246.95745743600696
INFO:tensorflow:Average training steps per second: 221.71
I0901 12:54:20.585222 139982171817984 replay_runner.py:36] Average training steps per second: 221.71
I0901 12:54:20.896710 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -505.97
INFO:tensorflow:Starting iteration 24

Steps executed: 317 Episode length: 317 Return: -785.62589309668346
INFO:tensorflow:Average training steps per second: 221.04
I0901 12:54:29.773324 139982171817984 replay_runner.py:36] Average training steps per second: 221.04
I0901 12:54:30.198198 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -785.63
INFO:tensorflow:Starting iteration 25

Steps executed: 203 Episode length: 53 Return: -101.681529432922366
INFO:tensorflow:Average training steps per second: 219.52
I0901 12:54:39.171485 139982171817984 replay_runner.py:36] Average training steps per second: 219.52
I0901 12:54:39.327279 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.98
INFO:tensorflow:Starting iteration 26
I0901 12:54:43.792055 139982171817984 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 225.90

Steps executed: 517 Episode length: 342 Return: -679.89513450536387
I0901 12:54:48.897048 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.21
INFO:tensorflow:Starting iteration 27

Steps executed: 280 Episode length: 177 Return: -206.85093438502446
INFO:tensorflow:Average training steps per second: 223.36
I0901 12:54:57.709893 139982171817984 replay_runner.py:36] Average training steps per second: 223.36
I0901 12:54:57.984798 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.03
INFO:tensorflow:Starting iteration 28

Steps executed: 232 Episode length: 232 Return: -733.26958742413746
INFO:tensorflow:Average training steps per second: 216.17
I0901 12:55:06.760384 139982171817984 replay_runner.py:36] Average training steps per second: 216.17
I0901 12:55:07.061535 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -733.27
INFO:tensorflow:Starting iteration 29

Steps executed: 204 Episode length: 116 Return: -842.32480803939396
INFO:tensorflow:Average training steps per second: 234.76
I0901 12:55:15.698669 139982171817984 replay_runner.py:36] Average training steps per second: 234.76

Done fixed training!Episode length: 116 Return: -842.32480803939396