Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 23:59:53.997643 140413705484288 run_experiment.py:549] Creating TrainRunner ...
I0901 23:59:54.007071 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:59:54.007284 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:59:54.007362 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:59:54.007437 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:59:54.007521 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0901 23:59:54.007599 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:59:54.007725 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:59:54.007858 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:59:54.007939 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:59:54.008017 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0901 23:59:54.008133 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:59:54.008246 140413705484288 dqn_agent.py:283] 	 seed: 1630540794007006
I0901 23:59:54.011457 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:59:54.011831 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:59:54.012063 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:59:54.012189 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:59:54.012264 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:59:54.012333 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:59:54.012400 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:59:54.012475 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:59:54.012570 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:59:54.045796 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:59:54.408504 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:59:54.422246 140413705484288 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:59:54.431089 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:59:54.431263 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:59:54.431341 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:59:54.431404 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:59:54.431459 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0901 23:59:54.431515 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:59:54.431569 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:59:54.431637 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:59:54.431690 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:59:54.431740 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0901 23:59:54.431793 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:59:54.431844 140413705484288 dqn_agent.py:283] 	 seed: 1630540794431041
I0901 23:59:54.434017 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:59:54.434182 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:59:54.434249 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:59:54.434313 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:59:54.434370 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:59:54.434429 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:59:54.434481 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:59:54.434531 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:59:54.434594 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:59:54.464319 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:59:54.511359 140413705484288 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:59:54.511620 140413705484288 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 171.47
I0902 00:00:00.343750 140413705484288 replay_runner.py:36] Average training steps per second: 171.47
Steps executed: 239 Episode length: 78 Return: -352.089502146116056
I0902 00:00:01.638231 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.45
INFO:tensorflow:Starting iteration 1

Steps executed: 268 Episode length: 139 Return: -558.42691309517534
INFO:tensorflow:Average training steps per second: 234.84
I0902 00:00:10.302666 140413705484288 replay_runner.py:36] Average training steps per second: 234.84
I0902 00:00:10.556362 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -429.39
INFO:tensorflow:Starting iteration 2

Steps executed: 225 Episode length: 114 Return: -332.87355370452994
INFO:tensorflow:Average training steps per second: 226.26
I0902 00:00:19.309102 140413705484288 replay_runner.py:36] Average training steps per second: 226.26
I0902 00:00:19.491724 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -321.65
INFO:tensorflow:Starting iteration 3

Steps executed: 222 Episode length: 222 Return: -279.07815022695094
INFO:tensorflow:Average training steps per second: 233.98
I0902 00:00:28.267042 140413705484288 replay_runner.py:36] Average training steps per second: 233.98
I0902 00:00:28.530689 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.08
INFO:tensorflow:Starting iteration 4
I0902 00:00:32.943208 140413705484288 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 232.37

Steps executed: 461 Episode length: 461 Return: -22.429075376239695
I0902 00:00:38.201378 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -22.43
INFO:tensorflow:Starting iteration 5
I0902 00:00:42.646819 140413705484288 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 225.42

Steps executed: 1000 Episode length: 1000 Return: -136.06476498984324
I0902 00:00:50.287297 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.06
INFO:tensorflow:Starting iteration 6
I0902 00:00:54.722287 140413705484288 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 225.85

Steps executed: 799 Episode length: 799 Return: -390.6756962758965424
I0902 00:01:00.959770 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -390.68
INFO:tensorflow:Starting iteration 7

Steps executed: 56 Episode length: 56 Return: -144.589281786513375424
INFO:tensorflow:Average training steps per second: 230.11

Steps executed: 1056 Episode length: 1000 Return: -106.61187062720559
I0902 00:01:11.496289 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.60
INFO:tensorflow:Starting iteration 8
I0902 00:01:15.845641 140413705484288 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 223.49

Steps executed: 1000 Episode length: 1000 Return: -273.35244989305939
I0902 00:01:24.129575 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.35
INFO:tensorflow:Starting iteration 9
I0902 00:01:28.429395 140413705484288 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 230.43

Steps executed: 1000 Episode length: 1000 Return: -161.72794197354494
I0902 00:01:35.028439 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.73
INFO:tensorflow:Starting iteration 10

Steps executed: 154 Episode length: 154 Return: -171.7017764801212894
INFO:tensorflow:Average training steps per second: 233.33

Steps executed: 1154 Episode length: 1000 Return: -97.300882124710094
I0902 00:01:46.831209 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.50
INFO:tensorflow:Starting iteration 11
I0902 00:01:51.163417 140413705484288 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 229.28

Steps executed: 1000 Episode length: 1000 Return: -131.91016328563254
I0902 00:01:57.929328 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.91
INFO:tensorflow:Starting iteration 12
I0902 00:02:02.239914 140413705484288 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 230.48

Steps executed: 724 Episode length: 724 Return: -256.7892357963016254
I0902 00:02:08.257757 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.79
INFO:tensorflow:Starting iteration 13
I0902 00:02:12.568312 140413705484288 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 231.21

Steps executed: 1000 Episode length: 1000 Return: -212.09337431013424
I0902 00:02:20.070900 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.09
INFO:tensorflow:Starting iteration 14

Steps executed: 640 Episode length: 640 Return: -63.14395496134977424
INFO:tensorflow:Average training steps per second: 226.99
I0902 00:02:28.785900 140413705484288 replay_runner.py:36] Average training steps per second: 226.99
I0902 00:02:30.049195 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -63.14
INFO:tensorflow:Starting iteration 15

Steps executed: 279 Episode length: 123 Return: -357.8609023980241424
INFO:tensorflow:Average training steps per second: 231.28
I0902 00:02:38.698680 140413705484288 replay_runner.py:36] Average training steps per second: 231.28
I0902 00:02:38.972628 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -323.29
INFO:tensorflow:Starting iteration 16

Steps executed: 202 Episode length: 202 Return: -455.0428738904373624
INFO:tensorflow:Average training steps per second: 247.76
I0902 00:02:47.293470 140413705484288 replay_runner.py:36] Average training steps per second: 247.76
I0902 00:02:47.502358 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -455.04
INFO:tensorflow:Starting iteration 17
I0902 00:02:51.814481 140413705484288 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 234.62

Steps executed: 958 Episode length: 958 Return: -104.4586880339515624
I0902 00:02:59.164294 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.46
INFO:tensorflow:Starting iteration 18
I0902 00:03:03.405187 140413705484288 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 230.65

Steps executed: 1000 Episode length: 1000 Return: -69.939071206114694
I0902 00:03:10.294914 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.94
INFO:tensorflow:Starting iteration 19

Steps executed: 682 Episode length: 525 Return: -394.9468923360376694
INFO:tensorflow:Average training steps per second: 223.48
I0902 00:03:19.236344 140413705484288 replay_runner.py:36] Average training steps per second: 223.48
I0902 00:03:20.465695 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.29
INFO:tensorflow:Starting iteration 20

Steps executed: 457 Episode length: 283 Return: 30.513698121903673694
INFO:tensorflow:Average training steps per second: 228.89
I0902 00:03:29.205691 140413705484288 replay_runner.py:36] Average training steps per second: 228.89
I0902 00:03:29.732191 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -26.57
INFO:tensorflow:Starting iteration 21
I0902 00:03:34.081403 140413705484288 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 226.49

Steps executed: 375 Episode length: 195 Return: -279.5000493271387594
I0902 00:03:38.860769 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.97
INFO:tensorflow:Starting iteration 22

Steps executed: 231 Episode length: 80 Return: -205.89622636235427594
INFO:tensorflow:Average training steps per second: 225.16
I0902 00:03:47.580504 140413705484288 replay_runner.py:36] Average training steps per second: 225.16
I0902 00:03:47.781754 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.54
INFO:tensorflow:Starting iteration 23
I0902 00:03:52.169454 140413705484288 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 230.03

Steps executed: 356 Episode length: 231 Return: -52.35249075792578694
I0902 00:03:56.890507 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.16
INFO:tensorflow:Starting iteration 24

Steps executed: 323 Episode length: 323 Return: -83.24376402035335694
INFO:tensorflow:Average training steps per second: 224.47
I0902 00:04:05.739716 140413705484288 replay_runner.py:36] Average training steps per second: 224.47
I0902 00:04:06.217633 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.24
INFO:tensorflow:Starting iteration 25
I0902 00:04:10.584388 140413705484288 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 224.92

Steps executed: 780 Episode length: 780 Return: 122.23460378331123694
I0902 00:04:17.563636 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: 122.23
INFO:tensorflow:Starting iteration 26
I0902 00:04:21.974847 140413705484288 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 228.65

Steps executed: 225 Episode length: 108 Return: -498.0804905817289594
I0902 00:04:26.551271 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -468.35
INFO:tensorflow:Starting iteration 27

Steps executed: 260 Episode length: 101 Return: -394.1198997094279594
INFO:tensorflow:Average training steps per second: 230.85
I0902 00:04:35.251634 140413705484288 replay_runner.py:36] Average training steps per second: 230.85
I0902 00:04:35.475475 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -397.19
INFO:tensorflow:Starting iteration 28

Steps executed: 325 Episode length: 140 Return: -601.1836965420608594
INFO:tensorflow:Average training steps per second: 238.06
I0902 00:04:44.041565 140413705484288 replay_runner.py:36] Average training steps per second: 238.06
I0902 00:04:44.345678 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -403.63
INFO:tensorflow:Starting iteration 29

Steps executed: 370 Episode length: 186 Return: -61.30146972927088594
INFO:tensorflow:Average training steps per second: 235.48
I0902 00:04:52.936739 140413705484288 replay_runner.py:36] Average training steps per second: 235.48

Done fixed training!Episode length: 186 Return: -61.30146972927088594