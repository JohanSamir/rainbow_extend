Loaded trained dqn in acrobot
Training fixed agent 6, please be patient, may be a while...
I0901 23:57:12.040085 140490221283328 run_experiment.py:549] Creating TrainRunner ...
I0901 23:57:12.049593 140490221283328 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:57:12.049814 140490221283328 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:57:12.049919 140490221283328 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:57:12.050004 140490221283328 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:57:12.050082 140490221283328 dqn_agent.py:275] 	 update_period: 4
I0901 23:57:12.050304 140490221283328 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:57:12.050438 140490221283328 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:57:12.050547 140490221283328 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:57:12.050643 140490221283328 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:57:12.050749 140490221283328 dqn_agent.py:280] 	 optimizer: adam
I0901 23:57:12.050855 140490221283328 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:57:12.050959 140490221283328 dqn_agent.py:283] 	 seed: 1630540632049539
I0901 23:57:12.053672 140490221283328 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:57:12.053888 140490221283328 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 23:57:12.053993 140490221283328 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:57:12.054084 140490221283328 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:57:12.054239 140490221283328 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:57:12.054659 140490221283328 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:57:12.054917 140490221283328 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:57:12.055184 140490221283328 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:57:12.055474 140490221283328 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:57:12.097812 140490221283328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:57:12.577668 140490221283328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:57:12.594455 140490221283328 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:57:12.603665 140490221283328 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:57:12.604028 140490221283328 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:57:12.604264 140490221283328 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:57:12.604419 140490221283328 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:57:12.604570 140490221283328 dqn_agent.py:275] 	 update_period: 4
I0901 23:57:12.604709 140490221283328 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:57:12.604868 140490221283328 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:57:12.604991 140490221283328 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:57:12.605475 140490221283328 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:57:12.605716 140490221283328 dqn_agent.py:280] 	 optimizer: adam
I0901 23:57:12.605860 140490221283328 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:57:12.606003 140490221283328 dqn_agent.py:283] 	 seed: 1630540632603439
I0901 23:57:12.609607 140490221283328 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:57:12.609830 140490221283328 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 23:57:12.610009 140490221283328 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:57:12.610176 140490221283328 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:57:12.610282 140490221283328 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:57:12.610362 140490221283328 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:57:12.610607 140490221283328 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:57:12.610854 140490221283328 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:57:12.610978 140490221283328 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:57:12.643980 140490221283328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:57:12.669089 140490221283328 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:57:12.669288 140490221283328 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 145.51
I0901 23:57:19.541959 140490221283328 replay_runner.py:36] Average training steps per second: 145.51
Steps executed: 255 Episode length: 255 Return: -254.0
I0901 23:57:20.797021 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.00
INFO:tensorflow:Starting iteration 1

Steps executed: 358 Episode length: 179 Return: -178.0
INFO:tensorflow:Average training steps per second: 193.74
I0901 23:57:26.262574 140490221283328 replay_runner.py:36] Average training steps per second: 193.74
I0901 23:57:26.526735 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.00
INFO:tensorflow:Starting iteration 2

Steps executed: 279 Episode length: 145 Return: -144.0
INFO:tensorflow:Average training steps per second: 196.86
I0901 23:57:31.849004 140490221283328 replay_runner.py:36] Average training steps per second: 196.86
I0901 23:57:32.083073 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.50
INFO:tensorflow:Starting iteration 3
I0901 23:57:32.331528 140490221283328 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 195.36

Steps executed: 500 Episode length: 500 Return: -500.0
I0901 23:57:37.857596 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 4
I0901 23:57:38.097796 140490221283328 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 194.18
I0901 23:57:43.248107 140490221283328 replay_runner.py:36] Average training steps per second: 194.18
I0901 23:57:43.660935 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 5

Steps executed: 206 Episode length: 95 Return: -94.0.0
INFO:tensorflow:Average training steps per second: 195.86
I0901 23:57:48.985317 140490221283328 replay_runner.py:36] Average training steps per second: 195.86
I0901 23:57:49.168613 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.00
INFO:tensorflow:Starting iteration 6

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 197.83
I0901 23:57:54.471334 140490221283328 replay_runner.py:36] Average training steps per second: 197.83
I0901 23:57:54.895768 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7

Steps executed: 231 Episode length: 151 Return: -150.0
INFO:tensorflow:Average training steps per second: 191.19
I0901 23:58:00.353520 140490221283328 replay_runner.py:36] Average training steps per second: 191.19
I0901 23:58:00.556932 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.50
INFO:tensorflow:Starting iteration 8

Steps executed: 101 Episode length: 101 Return: -100.0
INFO:tensorflow:Average training steps per second: 196.53

Steps executed: 601 Episode length: 500 Return: -500.0
I0901 23:58:06.390211 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.00
INFO:tensorflow:Starting iteration 9
I0901 23:58:06.637595 140490221283328 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 194.65

Steps executed: 500 Episode length: 500 Return: -500.0
I0901 23:58:12.184796 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 10
I0901 23:58:12.428490 140490221283328 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 193.36
I0901 23:58:17.600583 140490221283328 replay_runner.py:36] Average training steps per second: 193.36
I0901 23:58:18.005257 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 11

Steps executed: 231 Episode length: 107 Return: -106.0
INFO:tensorflow:Average training steps per second: 192.89
I0901 23:58:23.437845 140490221283328 replay_runner.py:36] Average training steps per second: 192.89
I0901 23:58:23.642553 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.50
INFO:tensorflow:Starting iteration 12

Steps executed: 237 Episode length: 64 Return: -63.0.0
INFO:tensorflow:Average training steps per second: 189.99
I0901 23:58:29.163565 140490221283328 replay_runner.py:36] Average training steps per second: 189.99
I0901 23:58:29.361696 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.00
INFO:tensorflow:Starting iteration 13

Steps executed: 217 Episode length: 78 Return: -77.0.0
INFO:tensorflow:Average training steps per second: 197.03
I0901 23:58:34.679508 140490221283328 replay_runner.py:36] Average training steps per second: 197.03
I0901 23:58:34.869364 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.33
INFO:tensorflow:Starting iteration 14
I0901 23:58:35.096182 140490221283328 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 191.65

Steps executed: 231 Episode length: 70 Return: -69.0.0
I0901 23:58:40.518886 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.00
INFO:tensorflow:Starting iteration 15

Steps executed: 131 Episode length: 131 Return: -130.0
INFO:tensorflow:Average training steps per second: 200.56
I0901 23:58:45.721094 140490221283328 replay_runner.py:36] Average training steps per second: 200.56

Steps executed: 216 Episode length: 85 Return: -84.0.0
INFO:tensorflow:Starting iteration 16

Steps executed: 254 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Average training steps per second: 196.28
I0901 23:58:51.226084 140490221283328 replay_runner.py:36] Average training steps per second: 196.28
I0901 23:58:51.429698 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.67
INFO:tensorflow:Starting iteration 17

Steps executed: 255 Episode length: 93 Return: -92.0.0
INFO:tensorflow:Average training steps per second: 194.24
I0901 23:58:56.811645 140490221283328 replay_runner.py:36] Average training steps per second: 194.24
I0901 23:58:57.030069 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.00
INFO:tensorflow:Starting iteration 18

Steps executed: 222 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Average training steps per second: 200.66
I0901 23:59:02.261363 140490221283328 replay_runner.py:36] Average training steps per second: 200.66
I0901 23:59:02.445336 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.00
INFO:tensorflow:Starting iteration 19

Steps executed: 247 Episode length: 93 Return: -92.0.0
INFO:tensorflow:Average training steps per second: 197.16
I0901 23:59:07.753910 140490221283328 replay_runner.py:36] Average training steps per second: 197.16
I0901 23:59:07.951278 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.33
INFO:tensorflow:Starting iteration 20

Steps executed: 213 Episode length: 71 Return: -70.0.0
INFO:tensorflow:Average training steps per second: 197.13
I0901 23:59:13.252273 140490221283328 replay_runner.py:36] Average training steps per second: 197.13
I0901 23:59:13.425266 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.00
INFO:tensorflow:Starting iteration 21

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 194.91
I0901 23:59:18.787602 140490221283328 replay_runner.py:36] Average training steps per second: 194.91
I0901 23:59:19.195647 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 22

Steps executed: 256 Episode length: 90 Return: -89.0.0
INFO:tensorflow:Average training steps per second: 194.66
I0901 23:59:24.572003 140490221283328 replay_runner.py:36] Average training steps per second: 194.66
I0901 23:59:24.785947 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.33
INFO:tensorflow:Starting iteration 23
I0901 23:59:25.019493 140490221283328 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 196.65

Steps executed: 500 Episode length: 500 Return: -500.0
I0901 23:59:30.513438 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 24

Steps executed: 273 Episode length: 93 Return: -92.0.0
INFO:tensorflow:Average training steps per second: 199.81
I0901 23:59:35.827529 140490221283328 replay_runner.py:36] Average training steps per second: 199.81
I0901 23:59:36.042695 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.00
INFO:tensorflow:Starting iteration 25

Steps executed: 235 Episode length: 144 Return: -143.0
INFO:tensorflow:Average training steps per second: 206.07
I0901 23:59:41.129721 140490221283328 replay_runner.py:36] Average training steps per second: 206.07
I0901 23:59:41.315355 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.50
INFO:tensorflow:Starting iteration 26

Steps executed: 151 Episode length: 79 Return: -78.0.0
INFO:tensorflow:Average training steps per second: 209.79
I0901 23:59:46.315852 140490221283328 replay_runner.py:36] Average training steps per second: 209.79

Steps executed: 223 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Starting iteration 27

Steps executed: 202 Episode length: 120 Return: -119.0
INFO:tensorflow:Average training steps per second: 210.93
I0901 23:59:51.408459 140490221283328 replay_runner.py:36] Average training steps per second: 210.93
I0901 23:59:51.565459 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.00
INFO:tensorflow:Starting iteration 28

Steps executed: 301 Episode length: 106 Return: -105.0
INFO:tensorflow:Average training steps per second: 201.49
I0901 23:59:56.755786 140490221283328 replay_runner.py:36] Average training steps per second: 201.49
I0901 23:59:56.986658 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.33
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 77 Return: -76.0.0
INFO:tensorflow:Average training steps per second: 207.63
I0902 00:00:02.036927 140490221283328 replay_runner.py:36] Average training steps per second: 207.63
I0902 00:00:02.248834 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.33