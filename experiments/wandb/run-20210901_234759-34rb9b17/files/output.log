Loaded trained dqn in acrobot
Training fixed agent 4, please be patient, may be a while...
I0901 23:48:06.063929 140268518520832 run_experiment.py:549] Creating TrainRunner ...
I0901 23:48:06.073651 140268518520832 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:48:06.074055 140268518520832 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:48:06.074274 140268518520832 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:48:06.074435 140268518520832 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:48:06.074578 140268518520832 dqn_agent.py:275] 	 update_period: 4
I0901 23:48:06.074718 140268518520832 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:48:06.074861 140268518520832 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:48:06.075139 140268518520832 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:48:06.075277 140268518520832 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:48:06.075388 140268518520832 dqn_agent.py:280] 	 optimizer: adam
I0901 23:48:06.075494 140268518520832 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:48:06.075615 140268518520832 dqn_agent.py:283] 	 seed: 1630540086073577
I0901 23:48:06.078904 140268518520832 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:48:06.079268 140268518520832 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 23:48:06.079457 140268518520832 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:48:06.079635 140268518520832 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:48:06.079792 140268518520832 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:48:06.079905 140268518520832 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:48:06.080022 140268518520832 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:48:06.080133 140268518520832 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:48:06.080250 140268518520832 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:48:06.123079 140268518520832 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:48:06.586895 140268518520832 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:48:06.600642 140268518520832 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:48:06.609213 140268518520832 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:48:06.609421 140268518520832 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:48:06.609531 140268518520832 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:48:06.609624 140268518520832 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:48:06.609693 140268518520832 dqn_agent.py:275] 	 update_period: 4
I0901 23:48:06.609781 140268518520832 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:48:06.609990 140268518520832 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:48:06.610167 140268518520832 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:48:06.610328 140268518520832 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:48:06.610474 140268518520832 dqn_agent.py:280] 	 optimizer: adam
I0901 23:48:06.610552 140268518520832 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:48:06.610656 140268518520832 dqn_agent.py:283] 	 seed: 1630540086609170
I0901 23:48:06.613306 140268518520832 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:48:06.613589 140268518520832 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 23:48:06.613801 140268518520832 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:48:06.613935 140268518520832 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:48:06.614076 140268518520832 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:48:06.614393 140268518520832 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:48:06.614548 140268518520832 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:48:06.614660 140268518520832 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:48:06.614863 140268518520832 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:48:06.648505 140268518520832 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:48:06.671973 140268518520832 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:48:06.672234 140268518520832 replay_runner.py:41] Starting iteration 0
Steps executed: 414 Episode length: 414 Return: -413.0
INFO:tensorflow:Average training steps per second: 141.00
I0901 23:48:13.764693 140268518520832 replay_runner.py:36] Average training steps per second: 141.00
I0901 23:48:15.302654 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -413.00
INFO:tensorflow:Starting iteration 1

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 192.32
I0901 23:48:20.749505 140268518520832 replay_runner.py:36] Average training steps per second: 192.32
I0901 23:48:21.185013 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 2

Steps executed: 297 Episode length: 100 Return: -99.00
INFO:tensorflow:Average training steps per second: 190.13
I0901 23:48:26.690586 140268518520832 replay_runner.py:36] Average training steps per second: 190.13
I0901 23:48:26.950475 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.00
INFO:tensorflow:Starting iteration 3
I0901 23:48:27.198368 140268518520832 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 190.75
I0901 23:48:32.441273 140268518520832 replay_runner.py:36] Average training steps per second: 190.75
I0901 23:48:32.714286 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.00
INFO:tensorflow:Starting iteration 4

Steps executed: 312 Episode length: 134 Return: -133.0
INFO:tensorflow:Average training steps per second: 193.76
I0901 23:48:38.111871 140268518520832 replay_runner.py:36] Average training steps per second: 193.76
I0901 23:48:38.541136 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 5

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 193.86
I0901 23:48:43.942260 140268518520832 replay_runner.py:36] Average training steps per second: 193.86
I0901 23:48:44.352793 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6
I0901 23:48:44.601570 140268518520832 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 187.16
I0901 23:48:49.945053 140268518520832 replay_runner.py:36] Average training steps per second: 187.16
I0901 23:48:50.197197 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.67
INFO:tensorflow:Starting iteration 7

Steps executed: 299 Episode length: 115 Return: -114.0
INFO:tensorflow:Average training steps per second: 192.20
I0901 23:48:55.639768 140268518520832 replay_runner.py:36] Average training steps per second: 192.20

Steps executed: 263 Episode length: 71 Return: -70.0.0
INFO:tensorflow:Starting iteration 8
I0901 23:48:56.136519 140268518520832 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 190.35
I0901 23:49:01.390498 140268518520832 replay_runner.py:36] Average training steps per second: 190.35
I0901 23:49:01.804560 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 9

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 191.25
I0901 23:49:07.274635 140268518520832 replay_runner.py:36] Average training steps per second: 191.25
I0901 23:49:07.476910 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.33
INFO:tensorflow:Starting iteration 10

Steps executed: 253 Episode length: 96 Return: -95.0.0
INFO:tensorflow:Average training steps per second: 192.26
I0901 23:49:12.921900 140268518520832 replay_runner.py:36] Average training steps per second: 192.26
I0901 23:49:13.117668 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.50
INFO:tensorflow:Starting iteration 11

Steps executed: 225 Episode length: 118 Return: -117.0
INFO:tensorflow:Average training steps per second: 195.03
I0901 23:49:18.778695 140268518520832 replay_runner.py:36] Average training steps per second: 195.03
I0901 23:49:18.999292 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.00
INFO:tensorflow:Starting iteration 12

Steps executed: 267 Episode length: 119 Return: -118.0
INFO:tensorflow:Average training steps per second: 192.96
I0901 23:49:24.422224 140268518520832 replay_runner.py:36] Average training steps per second: 192.96
I0901 23:49:24.618658 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.00
INFO:tensorflow:Starting iteration 13

Steps executed: 240 Episode length: 155 Return: -154.0
INFO:tensorflow:Average training steps per second: 188.59

Steps executed: 152 Episode length: 77 Return: -76.0.0
I0901 23:49:30.360947 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.67
INFO:tensorflow:Starting iteration 14

Steps executed: 248 Episode length: 96 Return: -95.0.0
INFO:tensorflow:Average training steps per second: 193.85
I0901 23:49:35.752719 140268518520832 replay_runner.py:36] Average training steps per second: 193.85

Steps executed: 258 Episode length: 86 Return: -85.0.0
INFO:tensorflow:Starting iteration 15
I0901 23:49:36.224627 140268518520832 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 189.91
I0901 23:49:41.490670 140268518520832 replay_runner.py:36] Average training steps per second: 189.91
I0901 23:49:41.729865 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.00
INFO:tensorflow:Starting iteration 16


Steps executed: 588 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 191.34
I0901 23:49:47.188818 140268518520832 replay_runner.py:36] Average training steps per second: 191.34
I0901 23:49:47.684285 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.50
INFO:tensorflow:Starting iteration 17
I0901 23:49:47.926879 140268518520832 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 194.55
I0901 23:49:53.067327 140268518520832 replay_runner.py:36] Average training steps per second: 194.55
I0901 23:49:53.311477 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.33
INFO:tensorflow:Starting iteration 18

Steps executed: 295 Episode length: 126 Return: -125.0
INFO:tensorflow:Average training steps per second: 190.33
I0901 23:49:58.869545 140268518520832 replay_runner.py:36] Average training steps per second: 190.33
I0901 23:49:59.101397 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.33
INFO:tensorflow:Starting iteration 19

Steps executed: 283 Episode length: 93 Return: -92.0.0
INFO:tensorflow:Average training steps per second: 196.66
I0901 23:50:04.423264 140268518520832 replay_runner.py:36] Average training steps per second: 196.66
I0901 23:50:04.632974 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.33
INFO:tensorflow:Starting iteration 20

Steps executed: 235 Episode length: 76 Return: -75.0.0
INFO:tensorflow:Average training steps per second: 193.42
I0901 23:50:10.041246 140268518520832 replay_runner.py:36] Average training steps per second: 193.42
I0901 23:50:10.228252 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.33
INFO:tensorflow:Starting iteration 21


Steps executed: 226 Episode length: 78 Return: -77.0.0
INFO:tensorflow:Average training steps per second: 198.09
I0901 23:50:15.506461 140268518520832 replay_runner.py:36] Average training steps per second: 198.09
I0901 23:50:15.740984 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.50
INFO:tensorflow:Starting iteration 22

Steps executed: 253 Episode length: 101 Return: -100.0
INFO:tensorflow:Average training steps per second: 192.99
I0901 23:50:21.168085 140268518520832 replay_runner.py:36] Average training steps per second: 192.99
I0901 23:50:21.411399 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.67
INFO:tensorflow:Starting iteration 23

Steps executed: 287 Episode length: 105 Return: -104.0
INFO:tensorflow:Average training steps per second: 188.96
I0901 23:50:26.944049 140268518520832 replay_runner.py:36] Average training steps per second: 188.96
I0901 23:50:27.163928 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.67
INFO:tensorflow:Starting iteration 24

Steps executed: 248 Episode length: 99 Return: -98.0.0
INFO:tensorflow:Average training steps per second: 195.94
I0901 23:50:32.508800 140268518520832 replay_runner.py:36] Average training steps per second: 195.94
I0901 23:50:32.698270 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.00
INFO:tensorflow:Starting iteration 25

Steps executed: 234 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Average training steps per second: 197.06
I0901 23:50:38.012921 140268518520832 replay_runner.py:36] Average training steps per second: 197.06

Steps executed: 274 Episode length: 129 Return: -128.0
INFO:tensorflow:Starting iteration 26
I0901 23:50:38.437859 140268518520832 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 202.17
I0901 23:50:43.384779 140268518520832 replay_runner.py:36] Average training steps per second: 202.17
I0901 23:50:43.570757 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.67
INFO:tensorflow:Starting iteration 27

Steps executed: 212 Episode length: 63 Return: -62.0.0
INFO:tensorflow:Average training steps per second: 186.36
I0901 23:50:49.166399 140268518520832 replay_runner.py:36] Average training steps per second: 186.36
I0901 23:50:49.554485 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 28

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 200.56
I0901 23:50:54.772442 140268518520832 replay_runner.py:36] Average training steps per second: 200.56
I0901 23:50:54.972046 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.00
INFO:tensorflow:Starting iteration 29

Steps executed: 243 Episode length: 82 Return: -81.0.0
INFO:tensorflow:Average training steps per second: 195.04
I0901 23:51:00.334775 140268518520832 replay_runner.py:36] Average training steps per second: 195.04

Done fixed training!Episode length: 94 Return: -93.0.0