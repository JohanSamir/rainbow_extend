Loaded trained dqn in cartpole
Training fixed agent 9, please be patient, may be a while...
I0828 10:24:26.059844 139874013124608 run_experiment.py:549] Creating TrainRunner ...
I0828 10:24:26.069745 139874013124608 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:24:26.070053 139874013124608 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:24:26.070240 139874013124608 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:24:26.070454 139874013124608 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:24:26.070609 139874013124608 dqn_agent.py:275] 	 update_period: 4
I0828 10:24:26.070750 139874013124608 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:24:26.070886 139874013124608 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:24:26.071027 139874013124608 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:24:26.071150 139874013124608 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:24:26.071284 139874013124608 dqn_agent.py:280] 	 optimizer: adam
I0828 10:24:26.071412 139874013124608 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:24:26.071554 139874013124608 dqn_agent.py:283] 	 seed: 1630146266069659
I0828 10:24:26.074685 139874013124608 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:24:26.074912 139874013124608 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0828 10:24:26.075073 139874013124608 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:24:26.075234 139874013124608 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:24:26.075535 139874013124608 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:24:26.075993 139874013124608 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:24:26.076363 139874013124608 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:24:26.076649 139874013124608 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:24:26.076881 139874013124608 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:24:26.165443 139874013124608 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:24:26.621691 139874013124608 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:24:26.635797 139874013124608 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:24:26.644034 139874013124608 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:24:26.644257 139874013124608 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:24:26.644393 139874013124608 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:24:26.644492 139874013124608 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:24:26.644636 139874013124608 dqn_agent.py:275] 	 update_period: 4
I0828 10:24:26.644763 139874013124608 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:24:26.644864 139874013124608 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:24:26.644951 139874013124608 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:24:26.645088 139874013124608 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:24:26.645189 139874013124608 dqn_agent.py:280] 	 optimizer: adam
I0828 10:24:26.645282 139874013124608 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:24:26.645358 139874013124608 dqn_agent.py:283] 	 seed: 1630146266643977
I0828 10:24:26.647489 139874013124608 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:24:26.647629 139874013124608 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0828 10:24:26.647722 139874013124608 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:24:26.647806 139874013124608 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:24:26.647884 139874013124608 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:24:26.647996 139874013124608 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:24:26.648089 139874013124608 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:24:26.648168 139874013124608 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:24:26.648290 139874013124608 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:24:26.674711 139874013124608 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:24:26.692666 139874013124608 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:24:26.692906 139874013124608 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.00
I0828 10:24:32.865921 139874013124608 replay_runner.py:36] Average training steps per second: 162.00
I0828 10:24:33.963857 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.32
INFO:tensorflow:Starting iteration 1
I0828 10:24:34.135106 139874013124608 replay_runner.py:41] Starting iteration 1
Steps executed: 205 Episode length: 9 Return: 9.0.0
INFO:tensorflow:Average training steps per second: 223.25
I0828 10:24:38.615062 139874013124608 replay_runner.py:36] Average training steps per second: 223.25
I0828 10:24:38.748454 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.36
INFO:tensorflow:Starting iteration 2

Steps executed: 206 Episode length: 9 Return: 9.0.0
INFO:tensorflow:Average training steps per second: 224.37
I0828 10:24:43.375638 139874013124608 replay_runner.py:36] Average training steps per second: 224.37
I0828 10:24:43.488592 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 10.50
INFO:tensorflow:Starting iteration 3

Steps executed: 210 Episode length: 12 Return: 12.0
INFO:tensorflow:Average training steps per second: 196.92
I0828 10:24:48.733442 139874013124608 replay_runner.py:36] Average training steps per second: 196.92
I0828 10:24:48.916352 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 92.67
INFO:tensorflow:Starting iteration 4

Steps executed: 278 Episode length: 95 Return: 95.0
INFO:tensorflow:Average training steps per second: 210.55

Steps executed: 200 Episode length: 200 Return: 200.0
I0828 10:24:54.020716 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 5

Steps executed: 292 Episode length: 97 Return: 97.0.0
INFO:tensorflow:Average training steps per second: 198.29
I0828 10:24:59.255944 139874013124608 replay_runner.py:36] Average training steps per second: 198.29
I0828 10:24:59.441010 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 97.33
INFO:tensorflow:Starting iteration 6

Steps executed: 278 Episode length: 92 Return: 92.0.0
INFO:tensorflow:Average training steps per second: 201.62
I0828 10:25:04.584916 139874013124608 replay_runner.py:36] Average training steps per second: 201.62
I0828 10:25:04.773143 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 92.67
INFO:tensorflow:Starting iteration 7

Steps executed: 296 Episode length: 146 Return: 146.0
INFO:tensorflow:Average training steps per second: 205.16
I0828 10:25:09.830229 139874013124608 replay_runner.py:36] Average training steps per second: 205.16
I0828 10:25:10.012914 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 148.00
INFO:tensorflow:Starting iteration 8

Steps executed: 223 Episode length: 24 Return: 24.0.0
INFO:tensorflow:Average training steps per second: 201.90
I0828 10:25:15.156767 139874013124608 replay_runner.py:36] Average training steps per second: 201.90
I0828 10:25:15.314746 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 31.86
INFO:tensorflow:Starting iteration 9

Steps executed: 343 Episode length: 167 Return: 167.0
INFO:tensorflow:Average training steps per second: 198.36
I0828 10:25:20.552969 139874013124608 replay_runner.py:36] Average training steps per second: 198.36
I0828 10:25:20.789689 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 171.50
INFO:tensorflow:Starting iteration 10
I0828 10:25:20.985501 139874013124608 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 194.70

Steps executed: 379 Episode length: 183 Return: 183.0
I0828 10:25:26.382859 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 126.33
INFO:tensorflow:Starting iteration 11

Steps executed: 204 Episode length: 166 Return: 166.0
INFO:tensorflow:Average training steps per second: 198.13
I0828 10:25:31.619935 139874013124608 replay_runner.py:36] Average training steps per second: 198.13
I0828 10:25:31.751749 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 51.00
INFO:tensorflow:Starting iteration 12

Steps executed: 397 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 201.42
I0828 10:25:36.896979 139874013124608 replay_runner.py:36] Average training steps per second: 201.42
I0828 10:25:37.151797 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 198.50
INFO:tensorflow:Starting iteration 13
I0828 10:25:37.336299 139874013124608 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 198.98

Steps executed: 200 Episode length: 200 Return: 200.0
I0828 10:25:42.500086 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 14

Steps executed: 245 Episode length: 58 Return: 58.0.0
INFO:tensorflow:Average training steps per second: 198.19
I0828 10:25:47.734563 139874013124608 replay_runner.py:36] Average training steps per second: 198.19
I0828 10:25:47.902528 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 49.00
INFO:tensorflow:Starting iteration 15

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 202.01
I0828 10:25:53.046873 139874013124608 replay_runner.py:36] Average training steps per second: 202.01
I0828 10:25:53.181328 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 16

Steps executed: 216 Episode length: 59 Return: 59.0.0
INFO:tensorflow:Average training steps per second: 197.91
I0828 10:25:58.420648 139874013124608 replay_runner.py:36] Average training steps per second: 197.91
I0828 10:25:58.564331 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 54.00
INFO:tensorflow:Starting iteration 17

Steps executed: 298 Episode length: 147 Return: 147.0
INFO:tensorflow:Average training steps per second: 197.87
I0828 10:26:03.805837 139874013124608 replay_runner.py:36] Average training steps per second: 197.87
I0828 10:26:04.011663 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 149.00
INFO:tensorflow:Starting iteration 18

Steps executed: 324 Episode length: 160 Return: 160.0
INFO:tensorflow:Average training steps per second: 197.24
I0828 10:26:09.278396 139874013124608 replay_runner.py:36] Average training steps per second: 197.24
I0828 10:26:09.498512 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 162.00
INFO:tensorflow:Starting iteration 19

Steps executed: 274 Episode length: 137 Return: 137.0
INFO:tensorflow:Average training steps per second: 196.88
I0828 10:26:14.772382 139874013124608 replay_runner.py:36] Average training steps per second: 196.88
I0828 10:26:14.950635 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 137.00
INFO:tensorflow:Starting iteration 20
I0828 10:26:15.131359 139874013124608 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 199.26

Steps executed: 291 Episode length: 95 Return: 95.0.0
I0828 10:26:20.350897 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 97.00
INFO:tensorflow:Starting iteration 21

Steps executed: 252 Episode length: 124 Return: 124.0
INFO:tensorflow:Average training steps per second: 199.12
I0828 10:26:25.572615 139874013124608 replay_runner.py:36] Average training steps per second: 199.12
I0828 10:26:25.738021 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 126.00
INFO:tensorflow:Starting iteration 22

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 197.05
I0828 10:26:31.004811 139874013124608 replay_runner.py:36] Average training steps per second: 197.05
I0828 10:26:31.139683 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 23
I0828 10:26:31.335284 139874013124608 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 201.51

Steps executed: 244 Episode length: 121 Return: 121.0
I0828 10:26:36.464547 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 122.00
INFO:tensorflow:Starting iteration 24

Steps executed: 365 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 199.71
I0828 10:26:41.666072 139874013124608 replay_runner.py:36] Average training steps per second: 199.71
I0828 10:26:41.917536 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 182.50
INFO:tensorflow:Starting iteration 25

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 202.53
I0828 10:26:47.054723 139874013124608 replay_runner.py:36] Average training steps per second: 202.53
I0828 10:26:47.197556 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26
I0828 10:26:47.378286 139874013124608 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 200.47
I0828 10:26:52.367182 139874013124608 replay_runner.py:36] Average training steps per second: 200.47
I0828 10:26:52.500995 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 27
I0828 10:26:52.699030 139874013124608 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 196.85
I0828 10:26:57.779518 139874013124608 replay_runner.py:36] Average training steps per second: 196.85
I0828 10:26:57.910191 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 28
I0828 10:26:58.097683 139874013124608 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 204.02
I0828 10:27:02.999634 139874013124608 replay_runner.py:36] Average training steps per second: 204.02
I0828 10:27:03.141963 139874013124608 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 29

Steps executed: 248 Episode length: 88 Return: 88.0.0
INFO:tensorflow:Average training steps per second: 199.97
I0828 10:27:08.335062 139874013124608 replay_runner.py:36] Average training steps per second: 199.97

Done fixed training!Episode length: 88 Return: 88.0.0