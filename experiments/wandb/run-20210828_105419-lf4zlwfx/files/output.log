I0828 10:54:25.643775 140618562066432 run_experiment.py:549] Creating TrainRunner ...
I0828 10:54:25.651385 140618562066432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:54:25.651507 140618562066432 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:54:25.651581 140618562066432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:54:25.651645 140618562066432 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:54:25.651702 140618562066432 dqn_agent.py:275] 	 update_period: 4
I0828 10:54:25.651774 140618562066432 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:54:25.651855 140618562066432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:54:25.651923 140618562066432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:54:25.651993 140618562066432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:54:25.652054 140618562066432 dqn_agent.py:280] 	 optimizer: adam
I0828 10:54:25.652109 140618562066432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:54:25.652199 140618562066432 dqn_agent.py:283] 	 seed: 1630148065651354
I0828 10:54:25.654193 140618562066432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:54:25.654334 140618562066432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:54:25.654546 140618562066432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:54:25.654695 140618562066432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:54:25.654799 140618562066432 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:54:25.654892 140618562066432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:54:25.655028 140618562066432 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:54:25.655162 140618562066432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:54:25.655260 140618562066432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:54:25.678611 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:25.925251 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:25.933183 140618562066432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:54:25.940161 140618562066432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:54:25.940297 140618562066432 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:54:25.940370 140618562066432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:54:25.940431 140618562066432 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:54:25.940488 140618562066432 dqn_agent.py:275] 	 update_period: 4
I0828 10:54:25.940561 140618562066432 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:54:25.940648 140618562066432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:54:25.940737 140618562066432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:54:25.940813 140618562066432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:54:25.940877 140618562066432 dqn_agent.py:280] 	 optimizer: adam
I0828 10:54:25.940952 140618562066432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:54:25.941018 140618562066432 dqn_agent.py:283] 	 seed: 1630148065940122
I0828 10:54:25.942394 140618562066432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:54:25.942494 140618562066432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:54:25.942568 140618562066432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:54:25.942644 140618562066432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:54:25.942700 140618562066432 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:54:25.942753 140618562066432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:54:25.942807 140618562066432 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:54:25.942858 140618562066432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:54:25.942907 140618562066432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:54:25.963981 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:25.978216 140618562066432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:54:25.978471 140618562066432 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 244.35
I0828 10:54:30.071267 140618562066432 replay_runner.py:36] Average training steps per second: 244.35
I0828 10:54:30.887856 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -581.96
Steps executed: 328 Episode length: 129 Return: -721.0005256815487
INFO:tensorflow:Starting iteration 1

Steps executed: 226 Episode length: 119 Return: -658.5744957367915
INFO:tensorflow:Average training steps per second: 318.38
I0828 10:54:37.335307 140618562066432 replay_runner.py:36] Average training steps per second: 318.38
I0828 10:54:37.465371 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -571.75
INFO:tensorflow:Starting iteration 2

Steps executed: 285 Episode length: 103 Return: -655.2280685949281
INFO:tensorflow:Average training steps per second: 319.38
I0828 10:54:43.868658 140618562066432 replay_runner.py:36] Average training steps per second: 319.38
I0828 10:54:44.032048 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -660.61
INFO:tensorflow:Starting iteration 3
I0828 10:54:47.183937 140618562066432 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 300.45
I0828 10:54:50.512535 140618562066432 replay_runner.py:36] Average training steps per second: 300.45

Steps executed: 324 Episode length: 172 Return: -386.55691020776834
INFO:tensorflow:Starting iteration 4

Steps executed: 236 Episode length: 106 Return: -684.12994699843976
INFO:tensorflow:Average training steps per second: 322.74
I0828 10:54:57.035280 140618562066432 replay_runner.py:36] Average training steps per second: 322.74
I0828 10:54:57.170537 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -461.28
INFO:tensorflow:Starting iteration 5

Steps executed: 209 Episode length: 114 Return: -322.28311971884326
INFO:tensorflow:Average training steps per second: 323.12
I0828 10:55:03.524985 140618562066432 replay_runner.py:36] Average training steps per second: 323.12
I0828 10:55:03.649655 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -477.97
INFO:tensorflow:Starting iteration 6

Steps executed: 284 Episode length: 133 Return: -593.91952308199056
INFO:tensorflow:Average training steps per second: 315.03
I0828 10:55:10.042176 140618562066432 replay_runner.py:36] Average training steps per second: 315.03
I0828 10:55:10.220676 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -657.59
INFO:tensorflow:Starting iteration 7

Steps executed: 207 Episode length: 207 Return: -448.74801687964214
INFO:tensorflow:Average training steps per second: 313.83
I0828 10:55:16.631407 140618562066432 replay_runner.py:36] Average training steps per second: 313.83
I0828 10:55:16.783909 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -448.75
INFO:tensorflow:Starting iteration 8

Steps executed: 344 Episode length: 215 Return: -386.85009289306413
INFO:tensorflow:Average training steps per second: 318.54
I0828 10:55:23.115040 140618562066432 replay_runner.py:36] Average training steps per second: 318.54
I0828 10:55:23.376134 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.51
INFO:tensorflow:Starting iteration 9

Steps executed: 336 Episode length: 336 Return: -287.65112905569513
INFO:tensorflow:Average training steps per second: 312.57
I0828 10:55:29.759926 140618562066432 replay_runner.py:36] Average training steps per second: 312.57
I0828 10:55:30.031108 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.65
INFO:tensorflow:Starting iteration 10

Steps executed: 284 Episode length: 109 Return: -407.55138645611487
INFO:tensorflow:Average training steps per second: 312.87
I0828 10:55:36.391991 140618562066432 replay_runner.py:36] Average training steps per second: 312.87
I0828 10:55:36.572914 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -363.83
INFO:tensorflow:Starting iteration 11

Steps executed: 426 Episode length: 288 Return: -72.344046706398477
INFO:tensorflow:Average training steps per second: 315.45
I0828 10:55:42.914152 140618562066432 replay_runner.py:36] Average training steps per second: 315.45
I0828 10:55:43.208510 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.92
INFO:tensorflow:Starting iteration 12
I0828 10:55:46.389265 140618562066432 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 308.28
I0828 10:55:49.633503 140618562066432 replay_runner.py:36] Average training steps per second: 308.28

Steps executed: 253 Episode length: 253 Return: -69.212559413643737
INFO:tensorflow:Starting iteration 13

Steps executed: 315 Episode length: 173 Return: -191.76250473635585
INFO:tensorflow:Average training steps per second: 312.61
I0828 10:55:56.185139 140618562066432 replay_runner.py:36] Average training steps per second: 312.61
I0828 10:55:56.371748 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.88
INFO:tensorflow:Starting iteration 14

Steps executed: 211 Episode length: 211 Return: -117.70594048128416
INFO:tensorflow:Average training steps per second: 310.26
I0828 10:56:02.762787 140618562066432 replay_runner.py:36] Average training steps per second: 310.26
I0828 10:56:02.897351 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.71
INFO:tensorflow:Starting iteration 15

Steps executed: 269 Episode length: 123 Return: -291.27662914478966
INFO:tensorflow:Average training steps per second: 313.27
I0828 10:56:09.240283 140618562066432 replay_runner.py:36] Average training steps per second: 313.27
I0828 10:56:09.407444 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.03
INFO:tensorflow:Starting iteration 16

Steps executed: 276 Episode length: 137 Return: -286.59135499267694
INFO:tensorflow:Average training steps per second: 318.93
I0828 10:56:15.706634 140618562066432 replay_runner.py:36] Average training steps per second: 318.93
I0828 10:56:15.872967 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.19
INFO:tensorflow:Starting iteration 17

Steps executed: 273 Episode length: 147 Return: -265.21596669426503
INFO:tensorflow:Average training steps per second: 311.07
I0828 10:56:22.273841 140618562066432 replay_runner.py:36] Average training steps per second: 311.07
I0828 10:56:22.433779 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.30
INFO:tensorflow:Starting iteration 18

Steps executed: 263 Episode length: 124 Return: -178.74167067614982
INFO:tensorflow:Average training steps per second: 314.02
I0828 10:56:28.806556 140618562066432 replay_runner.py:36] Average training steps per second: 314.02
I0828 10:56:28.986423 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.85
INFO:tensorflow:Starting iteration 19

Steps executed: 307 Episode length: 179 Return: -16.853772816126952
INFO:tensorflow:Average training steps per second: 315.44
I0828 10:56:35.341688 140618562066432 replay_runner.py:36] Average training steps per second: 315.44
I0828 10:56:35.532509 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.11
INFO:tensorflow:Starting iteration 20

Steps executed: 295 Episode length: 168 Return: -80.521400180688214
INFO:tensorflow:Average training steps per second: 318.37
I0828 10:56:41.864868 140618562066432 replay_runner.py:36] Average training steps per second: 318.37
I0828 10:56:42.034370 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.81
INFO:tensorflow:Starting iteration 21

Steps executed: 282 Episode length: 106 Return: -96.863560397745474
INFO:tensorflow:Average training steps per second: 314.18
I0828 10:56:48.428508 140618562066432 replay_runner.py:36] Average training steps per second: 314.18
I0828 10:56:48.606666 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.69
INFO:tensorflow:Starting iteration 22

Steps executed: 232 Episode length: 124 Return: -167.29874478809734
INFO:tensorflow:Average training steps per second: 317.61
I0828 10:56:54.982100 140618562066432 replay_runner.py:36] Average training steps per second: 317.61
I0828 10:56:55.125904 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.07
INFO:tensorflow:Starting iteration 23

Steps executed: 210 Episode length: 85 Return: -431.812605045608567
INFO:tensorflow:Average training steps per second: 318.92
I0828 10:57:01.486459 140618562066432 replay_runner.py:36] Average training steps per second: 318.92
I0828 10:57:01.612273 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.18
INFO:tensorflow:Starting iteration 24

Steps executed: 225 Episode length: 141 Return: -86.897033480477437
INFO:tensorflow:Average training steps per second: 323.13
I0828 10:57:07.965510 140618562066432 replay_runner.py:36] Average training steps per second: 323.13
I0828 10:57:08.100716 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.87
INFO:tensorflow:Starting iteration 25

Steps executed: 360 Episode length: 195 Return: -67.772715257183057
INFO:tensorflow:Average training steps per second: 321.92
I0828 10:57:14.469174 140618562066432 replay_runner.py:36] Average training steps per second: 321.92
I0828 10:57:14.712695 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.37
INFO:tensorflow:Starting iteration 26

Steps executed: 233 Episode length: 121 Return: -214.11139230027183
INFO:tensorflow:Average training steps per second: 329.11
I0828 10:57:21.033067 140618562066432 replay_runner.py:36] Average training steps per second: 329.11
I0828 10:57:21.186177 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.20
INFO:tensorflow:Starting iteration 27

Steps executed: 215 Episode length: 94 Return: -216.377613870173783
INFO:tensorflow:Average training steps per second: 346.28
I0828 10:57:27.253873 140618562066432 replay_runner.py:36] Average training steps per second: 346.28
I0828 10:57:27.396115 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.08
INFO:tensorflow:Starting iteration 28

Steps executed: 227 Episode length: 150 Return: -227.08214709403828
INFO:tensorflow:Average training steps per second: 365.37
I0828 10:57:33.344154 140618562066432 replay_runner.py:36] Average training steps per second: 365.37
I0828 10:57:33.459515 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -292.99
INFO:tensorflow:Starting iteration 29

Steps executed: 382 Episode length: 186 Return: -63.267693472219848
INFO:tensorflow:Average training steps per second: 361.64
I0828 10:57:39.298443 140618562066432 replay_runner.py:36] Average training steps per second: 361.64

Done fixed training!Episode length: 186 Return: -63.267693472219848