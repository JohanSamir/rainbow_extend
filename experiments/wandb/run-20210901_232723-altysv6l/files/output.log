I0901 23:27:27.698979 139822539352064 run_experiment.py:549] Creating TrainRunner ...
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0901 23:27:27.699439 139822539352064 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0901 23:27:27.751967 139822539352064 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:27:27.753105 139822539352064 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:27:27.753166 139822539352064 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:27:27.753215 139822539352064 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:27:27.753273 139822539352064 dqn_agent.py:275] 	 update_period: 4
I0901 23:27:27.753335 139822539352064 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:27:27.753382 139822539352064 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:27:27.753425 139822539352064 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:27:27.753604 139822539352064 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:27:27.753694 139822539352064 dqn_agent.py:280] 	 optimizer: adam
I0901 23:27:27.753746 139822539352064 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:27:27.753847 139822539352064 dqn_agent.py:283] 	 seed: 1630538847751911
I0901 23:27:27.755449 139822539352064 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:27:27.755588 139822539352064 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 23:27:27.755675 139822539352064 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:27:27.755737 139822539352064 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:27:27.755794 139822539352064 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:27:27.755886 139822539352064 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:27:27.755944 139822539352064 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:27:27.755988 139822539352064 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:27:27.756038 139822539352064 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:27:29.942982 139822539352064 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:27:30.245835 139822539352064 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:27:30.252764 139822539352064 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:27:30.257730 139822539352064 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:27:30.257889 139822539352064 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:27:30.257961 139822539352064 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:27:30.258017 139822539352064 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:27:30.258065 139822539352064 dqn_agent.py:275] 	 update_period: 4
I0901 23:27:30.258121 139822539352064 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:27:30.258170 139822539352064 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:27:30.258248 139822539352064 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:27:30.258348 139822539352064 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:27:30.258398 139822539352064 dqn_agent.py:280] 	 optimizer: adam
I0901 23:27:30.258461 139822539352064 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:27:30.258548 139822539352064 dqn_agent.py:283] 	 seed: 1630538850257690
I0901 23:27:30.260149 139822539352064 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:27:30.260265 139822539352064 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 23:27:30.260333 139822539352064 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:27:30.260392 139822539352064 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:27:30.260444 139822539352064 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:27:30.260492 139822539352064 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:27:30.260538 139822539352064 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:27:30.260627 139822539352064 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:27:30.260702 139822539352064 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:27:30.343256 139822539352064 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:27:30.356651 139822539352064 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:27:30.356885 139822539352064 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in cartpole
Training fixed agent 1, please be patient, may be a while...
Steps executed: 208 Episode length: 11 Return: 11.0
INFO:tensorflow:Average training steps per second: 280.51
I0901 23:27:33.922347 139822539352064 replay_runner.py:36] Average training steps per second: 280.51
I0901 23:27:34.539467 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.04
INFO:tensorflow:Starting iteration 1
I0901 23:27:34.658508 139822539352064 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 370.14

Steps executed: 200 Episode length: 200 Return: 200.0
I0901 23:27:37.430930 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 2

Steps executed: 204 Episode length: 95 Return: 95.0.0
INFO:tensorflow:Average training steps per second: 363.89
I0901 23:27:40.290762 139822539352064 replay_runner.py:36] Average training steps per second: 363.89
I0901 23:27:40.367382 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 102.00
INFO:tensorflow:Starting iteration 3

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 368.67
I0901 23:27:43.193554 139822539352064 replay_runner.py:36] Average training steps per second: 368.67
I0901 23:27:43.260791 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 4
I0901 23:27:43.375299 139822539352064 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 363.95
I0901 23:27:46.124632 139822539352064 replay_runner.py:36] Average training steps per second: 363.95
I0901 23:27:46.251091 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 196.50
INFO:tensorflow:Starting iteration 5

Steps executed: 393 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 369.95
I0901 23:27:49.069075 139822539352064 replay_runner.py:36] Average training steps per second: 369.95
I0901 23:27:49.179941 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 165.50
INFO:tensorflow:Starting iteration 6


Steps executed: 269 Episode length: 130 Return: 130.0
INFO:tensorflow:Average training steps per second: 379.67
I0901 23:27:51.931853 139822539352064 replay_runner.py:36] Average training steps per second: 379.67
I0901 23:27:52.022322 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 134.50
INFO:tensorflow:Starting iteration 7
I0901 23:27:52.137679 139822539352064 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 376.20
I0901 23:27:54.796193 139822539352064 replay_runner.py:36] Average training steps per second: 376.20
I0901 23:27:54.882548 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 141.00
INFO:tensorflow:Starting iteration 8

Steps executed: 282 Episode length: 140 Return: 140.0
INFO:tensorflow:Average training steps per second: 379.62
I0901 23:27:57.629871 139822539352064 replay_runner.py:36] Average training steps per second: 379.62
I0901 23:27:57.719593 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 149.00
INFO:tensorflow:Starting iteration 9


Steps executed: 349 Episode length: 178 Return: 178.0
INFO:tensorflow:Average training steps per second: 378.64
I0901 23:28:00.473146 139822539352064 replay_runner.py:36] Average training steps per second: 378.64
I0901 23:28:00.575676 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 174.50
INFO:tensorflow:Starting iteration 10

Steps executed: 290 Episode length: 142 Return: 142.0
INFO:tensorflow:Average training steps per second: 379.01
I0901 23:28:03.327327 139822539352064 replay_runner.py:36] Average training steps per second: 379.01
I0901 23:28:03.412587 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 145.00
INFO:tensorflow:Starting iteration 11

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 369.31
I0901 23:28:06.232463 139822539352064 replay_runner.py:36] Average training steps per second: 369.31
I0901 23:28:06.294041 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 12

Steps executed: 296 Episode length: 138 Return: 138.0
INFO:tensorflow:Average training steps per second: 377.94
I0901 23:28:09.055069 139822539352064 replay_runner.py:36] Average training steps per second: 377.94
I0901 23:28:09.147143 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 148.00
INFO:tensorflow:Starting iteration 13

Steps executed: 396 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 379.82
I0901 23:28:11.891145 139822539352064 replay_runner.py:36] Average training steps per second: 379.82
I0901 23:28:12.024625 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 198.00
INFO:tensorflow:Starting iteration 14

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 371.89
I0901 23:28:14.834101 139822539352064 replay_runner.py:36] Average training steps per second: 371.89
I0901 23:28:14.905718 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 15
I0901 23:28:15.019109 139822539352064 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 370.96
I0901 23:28:17.715049 139822539352064 replay_runner.py:36] Average training steps per second: 370.96
I0901 23:28:17.789512 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 16

Steps executed: 276 Episode length: 140 Return: 140.0
INFO:tensorflow:Average training steps per second: 372.49
I0901 23:28:20.585366 139822539352064 replay_runner.py:36] Average training steps per second: 372.49
I0901 23:28:20.669227 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 138.00
INFO:tensorflow:Starting iteration 17

Steps executed: 376 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 372.57
I0901 23:28:23.464825 139822539352064 replay_runner.py:36] Average training steps per second: 372.57
I0901 23:28:23.573007 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 188.00
INFO:tensorflow:Starting iteration 18

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 369.54
I0901 23:28:26.412286 139822539352064 replay_runner.py:36] Average training steps per second: 369.54
I0901 23:28:26.475654 139822539352064 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 19
