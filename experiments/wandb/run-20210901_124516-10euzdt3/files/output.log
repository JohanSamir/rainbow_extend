Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0901 12:45:23.500849 140265790818304 run_experiment.py:549] Creating TrainRunner ...
I0901 12:45:23.513154 140265790818304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:45:23.513387 140265790818304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:45:23.513929 140265790818304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:45:23.514268 140265790818304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:45:23.514569 140265790818304 dqn_agent.py:275] 	 update_period: 4
I0901 12:45:23.514809 140265790818304 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:45:23.515120 140265790818304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:45:23.515236 140265790818304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:45:23.515322 140265790818304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:45:23.515396 140265790818304 dqn_agent.py:280] 	 optimizer: adam
I0901 12:45:23.515561 140265790818304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:45:23.515667 140265790818304 dqn_agent.py:283] 	 seed: 1630500323513099
I0901 12:45:23.519128 140265790818304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:45:23.519378 140265790818304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:45:23.519593 140265790818304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:45:23.519963 140265790818304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:45:23.520129 140265790818304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:45:23.520256 140265790818304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:45:23.520458 140265790818304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:45:23.520576 140265790818304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:45:23.520663 140265790818304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:45:23.563468 140265790818304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:45:23.976849 140265790818304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:45:24.014886 140265790818304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:45:24.026487 140265790818304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:45:24.026811 140265790818304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:45:24.027001 140265790818304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:45:24.027299 140265790818304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:45:24.027514 140265790818304 dqn_agent.py:275] 	 update_period: 4
I0901 12:45:24.027832 140265790818304 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:45:24.028040 140265790818304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:45:24.028192 140265790818304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:45:24.028558 140265790818304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:45:24.028722 140265790818304 dqn_agent.py:280] 	 optimizer: adam
I0901 12:45:24.028832 140265790818304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:45:24.028941 140265790818304 dqn_agent.py:283] 	 seed: 1630500324026404
I0901 12:45:24.032250 140265790818304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:45:24.032426 140265790818304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:45:24.032516 140265790818304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:45:24.032582 140265790818304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:45:24.032655 140265790818304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:45:24.032715 140265790818304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:45:24.032774 140265790818304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:45:24.032834 140265790818304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:45:24.032889 140265790818304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:45:24.066568 140265790818304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:45:24.090672 140265790818304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:45:24.091153 140265790818304 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 156.89
I0901 12:45:30.465358 140265790818304 replay_runner.py:36] Average training steps per second: 156.89
Steps executed: 325 Episode length: 132 Return: -265.81185199804656
I0901 12:45:31.893746 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -383.85
INFO:tensorflow:Starting iteration 1

Steps executed: 253 Episode length: 90 Return: -360.535668345350786
INFO:tensorflow:Average training steps per second: 219.45
I0901 12:45:40.780231 140265790818304 replay_runner.py:36] Average training steps per second: 219.45
I0901 12:45:40.992922 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.69
INFO:tensorflow:Starting iteration 2

Steps executed: 292 Episode length: 163 Return: -138.96970199546736
INFO:tensorflow:Average training steps per second: 212.78
I0901 12:45:50.015550 140265790818304 replay_runner.py:36] Average training steps per second: 212.78
I0901 12:45:50.286619 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.37
INFO:tensorflow:Starting iteration 3

Steps executed: 284 Episode length: 127 Return: -185.97759020448177
INFO:tensorflow:Average training steps per second: 211.50
I0901 12:45:59.449814 140265790818304 replay_runner.py:36] Average training steps per second: 211.50
I0901 12:45:59.725748 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.79
INFO:tensorflow:Starting iteration 4

Steps executed: 281 Episode length: 202 Return: -266.31103079364917
INFO:tensorflow:Average training steps per second: 214.31
I0901 12:46:08.798355 140265790818304 replay_runner.py:36] Average training steps per second: 214.31
I0901 12:46:09.087654 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.13
INFO:tensorflow:Starting iteration 5

Steps executed: 235 Episode length: 157 Return: -311.52663165380367
INFO:tensorflow:Average training steps per second: 225.11
I0901 12:46:17.684949 140265790818304 replay_runner.py:36] Average training steps per second: 225.11
I0901 12:46:17.891973 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.76
INFO:tensorflow:Starting iteration 6

Steps executed: 284 Episode length: 132 Return: -480.32061149708744
INFO:tensorflow:Average training steps per second: 228.91
I0901 12:46:26.506703 140265790818304 replay_runner.py:36] Average training steps per second: 228.91
I0901 12:46:26.769582 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -474.26
INFO:tensorflow:Starting iteration 7

Steps executed: 328 Episode length: 130 Return: -215.80938685334016
INFO:tensorflow:Average training steps per second: 220.79
I0901 12:46:35.742744 140265790818304 replay_runner.py:36] Average training steps per second: 220.79
I0901 12:46:36.047716 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.37
INFO:tensorflow:Starting iteration 8

Steps executed: 224 Episode length: 72 Return: -233.146705552536286
INFO:tensorflow:Average training steps per second: 216.64
I0901 12:46:45.073218 140265790818304 replay_runner.py:36] Average training steps per second: 216.64
I0901 12:46:45.251760 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.52
INFO:tensorflow:Starting iteration 9

Steps executed: 318 Episode length: 143 Return: -335.27909477609546
INFO:tensorflow:Average training steps per second: 218.95
I0901 12:46:54.108996 140265790818304 replay_runner.py:36] Average training steps per second: 218.95
I0901 12:46:54.373059 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -340.25
INFO:tensorflow:Starting iteration 10

Steps executed: 142 Episode length: 142 Return: -390.66848414146196
INFO:tensorflow:Average training steps per second: 221.11

Steps executed: 397 Episode length: 255 Return: -421.56835655488766
I0901 12:47:03.666874 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.12
INFO:tensorflow:Starting iteration 11

Steps executed: 237 Episode length: 95 Return: -289.124984795551656
INFO:tensorflow:Average training steps per second: 223.99
I0901 12:47:12.571510 140265790818304 replay_runner.py:36] Average training steps per second: 223.99
I0901 12:47:12.800341 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -391.17
INFO:tensorflow:Starting iteration 12

Steps executed: 209 Episode length: 97 Return: -24.8333603917094256
INFO:tensorflow:Average training steps per second: 225.69
I0901 12:47:21.671610 140265790818304 replay_runner.py:36] Average training steps per second: 225.69
I0901 12:47:21.851072 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -3.99
INFO:tensorflow:Starting iteration 13

Steps executed: 277 Episode length: 84 Return: -284.807235026430366
INFO:tensorflow:Average training steps per second: 226.44
I0901 12:47:30.596104 140265790818304 replay_runner.py:36] Average training steps per second: 226.44
I0901 12:47:30.791632 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.98
INFO:tensorflow:Starting iteration 14
I0901 12:47:35.073006 140265790818304 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 226.04

Steps executed: 261 Episode length: 261 Return: -257.31096927174696
I0901 12:47:39.770338 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.31
INFO:tensorflow:Starting iteration 15

Steps executed: 200 Episode length: 64 Return: 6.644779168310194696
INFO:tensorflow:Average training steps per second: 221.46
I0901 12:47:48.609482 140265790818304 replay_runner.py:36] Average training steps per second: 221.46
I0901 12:47:48.774262 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -59.50
INFO:tensorflow:Starting iteration 16

Steps executed: 331 Episode length: 231 Return: -286.81555242976077
INFO:tensorflow:Average training steps per second: 227.28
I0901 12:47:57.411193 140265790818304 replay_runner.py:36] Average training steps per second: 227.28
I0901 12:47:57.730597 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.96
INFO:tensorflow:Starting iteration 17

Steps executed: 254 Episode length: 81 Return: -87.2493250638409847
INFO:tensorflow:Average training steps per second: 225.05
I0901 12:48:06.522594 140265790818304 replay_runner.py:36] Average training steps per second: 225.05
I0901 12:48:06.707026 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.74
INFO:tensorflow:Starting iteration 18

Steps executed: 283 Episode length: 104 Return: -780.36753923682767
INFO:tensorflow:Average training steps per second: 221.15
I0901 12:48:15.561822 140265790818304 replay_runner.py:36] Average training steps per second: 221.15
I0901 12:48:15.805408 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -323.95
INFO:tensorflow:Starting iteration 19

Steps executed: 253 Episode length: 85 Return: -461.404567304679237
INFO:tensorflow:Average training steps per second: 223.37
I0901 12:48:24.546091 140265790818304 replay_runner.py:36] Average training steps per second: 223.37
I0901 12:48:24.783138 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -449.01
INFO:tensorflow:Starting iteration 20

Steps executed: 226 Episode length: 140 Return: -997.82000777433777
INFO:tensorflow:Average training steps per second: 223.85
I0901 12:48:33.623605 140265790818304 replay_runner.py:36] Average training steps per second: 223.85
I0901 12:48:33.828686 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -780.96
INFO:tensorflow:Starting iteration 21

Steps executed: 222 Episode length: 83 Return: -699.745921996389777
INFO:tensorflow:Average training steps per second: 227.58
I0901 12:48:42.558811 140265790818304 replay_runner.py:36] Average training steps per second: 227.58
I0901 12:48:42.741324 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -503.71
INFO:tensorflow:Starting iteration 22
I0901 12:48:47.265475 140265790818304 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 231.49

Steps executed: 277 Episode length: 82 Return: -568.686874478967977
I0901 12:48:51.818759 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -489.63
INFO:tensorflow:Starting iteration 23

Steps executed: 270 Episode length: 109 Return: -182.84397737081997
INFO:tensorflow:Average training steps per second: 223.88
I0901 12:49:00.682804 140265790818304 replay_runner.py:36] Average training steps per second: 223.88
I0901 12:49:00.907172 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.67
INFO:tensorflow:Starting iteration 24
I0901 12:49:05.348732 140265790818304 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 233.01

Steps executed: 239 Episode length: 73 Return: -557.938900353804197
I0901 12:49:09.849677 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -507.47
INFO:tensorflow:Starting iteration 25

Steps executed: 264 Episode length: 80 Return: -682.386625478631197
INFO:tensorflow:Average training steps per second: 234.89
I0901 12:49:18.509966 140265790818304 replay_runner.py:36] Average training steps per second: 234.89
I0901 12:49:18.714927 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -362.77
INFO:tensorflow:Starting iteration 26

Steps executed: 246 Episode length: 77 Return: -559.717140498346697
INFO:tensorflow:Average training steps per second: 235.51
I0901 12:49:27.260830 140265790818304 replay_runner.py:36] Average training steps per second: 235.51
I0901 12:49:27.483291 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -543.24
INFO:tensorflow:Starting iteration 27

Steps executed: 215 Episode length: 82 Return: -289.752775785075767
INFO:tensorflow:Average training steps per second: 233.65
I0901 12:49:36.075072 140265790818304 replay_runner.py:36] Average training steps per second: 233.65
I0901 12:49:36.251329 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -447.27
INFO:tensorflow:Starting iteration 28

Steps executed: 249 Episode length: 83 Return: -757.331829476780967
INFO:tensorflow:Average training steps per second: 226.31
I0901 12:49:44.954500 140265790818304 replay_runner.py:36] Average training steps per second: 226.31
I0901 12:49:45.167359 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -638.99
INFO:tensorflow:Starting iteration 29
I0901 12:49:49.506791 140265790818304 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 228.06

Steps executed: 208 Episode length: 72 Return: -502.418006397851367

Done fixed training!Episode length: 72 Return: -502.418006397851367