Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0901 12:19:52.089917 139982171817984 run_experiment.py:549] Creating TrainRunner ...
I0901 12:19:52.101226 139982171817984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:19:52.101500 139982171817984 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:19:52.101682 139982171817984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:19:52.101773 139982171817984 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:19:52.101850 139982171817984 dqn_agent.py:275] 	 update_period: 4
I0901 12:19:52.101918 139982171817984 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:19:52.101983 139982171817984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:19:52.102050 139982171817984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:19:52.102144 139982171817984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:19:52.102209 139982171817984 dqn_agent.py:280] 	 optimizer: adam
I0901 12:19:52.102272 139982171817984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:19:52.102339 139982171817984 dqn_agent.py:283] 	 seed: 1630498792101149
I0901 12:19:52.104954 139982171817984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:19:52.105274 139982171817984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:19:52.105467 139982171817984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:19:52.105593 139982171817984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:19:52.105670 139982171817984 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:19:52.105753 139982171817984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:19:52.105875 139982171817984 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:19:52.105991 139982171817984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:19:52.106159 139982171817984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:19:52.177953 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:19:52.601257 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:19:52.615797 139982171817984 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:19:52.624085 139982171817984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:19:52.624318 139982171817984 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:19:52.624466 139982171817984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:19:52.624600 139982171817984 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:19:52.624716 139982171817984 dqn_agent.py:275] 	 update_period: 4
I0901 12:19:52.624833 139982171817984 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:19:52.624938 139982171817984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:19:52.625014 139982171817984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:19:52.625106 139982171817984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:19:52.625197 139982171817984 dqn_agent.py:280] 	 optimizer: adam
I0901 12:19:52.625435 139982171817984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:19:52.625565 139982171817984 dqn_agent.py:283] 	 seed: 1630498792624033
I0901 12:19:52.628597 139982171817984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:19:52.628968 139982171817984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:19:52.629143 139982171817984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:19:52.629273 139982171817984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:19:52.629472 139982171817984 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:19:52.629548 139982171817984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:19:52.629610 139982171817984 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:19:52.629854 139982171817984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:19:52.630038 139982171817984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:19:52.660934 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:19:52.682151 139982171817984 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:19:52.682504 139982171817984 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 161.24
I0901 12:19:58.884552 139982171817984 replay_runner.py:36] Average training steps per second: 161.24
Steps executed: 210 Episode length: 94 Return: -274.43778202056115
I0901 12:19:59.997639 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.38
INFO:tensorflow:Starting iteration 1

Steps executed: 323 Episode length: 149 Return: -354.89283683501997
INFO:tensorflow:Average training steps per second: 224.10
I0901 12:20:08.690520 139982171817984 replay_runner.py:36] Average training steps per second: 224.10
I0901 12:20:09.030729 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.21
INFO:tensorflow:Starting iteration 2

Steps executed: 341 Episode length: 194 Return: -282.81225050008977
INFO:tensorflow:Average training steps per second: 227.88
I0901 12:20:17.776853 139982171817984 replay_runner.py:36] Average training steps per second: 227.88
I0901 12:20:18.103152 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.36
INFO:tensorflow:Starting iteration 3
I0901 12:20:22.229232 139982171817984 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 219.66

Steps executed: 1000 Episode length: 1000 Return: -145.05592660260078
I0901 12:20:29.680397 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.06
INFO:tensorflow:Starting iteration 4
I0901 12:20:33.731392 139982171817984 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 224.15

Steps executed: 1000 Episode length: 1000 Return: -112.23443922937454
I0901 12:20:41.702405 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.23
INFO:tensorflow:Starting iteration 5
I0901 12:20:45.936389 139982171817984 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 222.18

Steps executed: 1000 Episode length: 1000 Return: -176.60584231814744
I0901 12:20:52.235632 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.61
INFO:tensorflow:Starting iteration 6
I0901 12:20:56.573245 139982171817984 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 223.60

Steps executed: 1000 Episode length: 1000 Return: -307.24671277411704
I0901 12:21:03.124142 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.25
INFO:tensorflow:Starting iteration 7
I0901 12:21:07.279257 139982171817984 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 220.01

Steps executed: 406 Episode length: 406 Return: -308.3581195720358304
I0901 12:21:12.580474 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.36
INFO:tensorflow:Starting iteration 8

Steps executed: 262 Episode length: 262 Return: -296.9461485847341504
INFO:tensorflow:Average training steps per second: 217.23
I0901 12:21:21.473665 139982171817984 replay_runner.py:36] Average training steps per second: 217.23
I0901 12:21:21.793436 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.95
INFO:tensorflow:Starting iteration 9
I0901 12:21:25.869689 139982171817984 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 229.19

Steps executed: 1000 Episode length: 1000 Return: -209.10694692176784
I0901 12:21:32.387898 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.11
INFO:tensorflow:Starting iteration 10
I0901 12:21:36.741549 139982171817984 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 231.48

Steps executed: 618 Episode length: 618 Return: -334.8037389146858784
I0901 12:21:42.347638 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -334.80
INFO:tensorflow:Starting iteration 11
I0901 12:21:46.566980 139982171817984 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 237.91

Steps executed: 1000 Episode length: 1000 Return: -352.11580968559224
I0901 12:21:53.594274 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.12
INFO:tensorflow:Starting iteration 12
I0901 12:21:57.897441 139982171817984 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 236.43

Steps executed: 1000 Episode length: 1000 Return: -139.73696051166524
I0901 12:22:04.139148 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.74
INFO:tensorflow:Starting iteration 13

Steps executed: 621 Episode length: 621 Return: 180.20053804519344524
INFO:tensorflow:Average training steps per second: 236.78
I0901 12:22:12.632769 139982171817984 replay_runner.py:36] Average training steps per second: 236.78
I0901 12:22:13.768659 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: 180.20
INFO:tensorflow:Starting iteration 14
I0901 12:22:17.873457 139982171817984 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 223.81
I0901 12:22:22.342432 139982171817984 replay_runner.py:36] Average training steps per second: 223.81

Steps executed: 1000 Episode length: 1000 Return: -76.188718224727854
INFO:tensorflow:Starting iteration 15
I0901 12:22:30.694828 139982171817984 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 215.84

Steps executed: 1000 Episode length: 1000 Return: -64.066995580332954
I0901 12:22:37.771156 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -64.07
INFO:tensorflow:Starting iteration 16
I0901 12:22:42.143148 139982171817984 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 217.01

Steps executed: 1000 Episode length: 1000 Return: -152.07466456059154
I0901 12:22:50.072185 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.07
INFO:tensorflow:Starting iteration 17
I0901 12:22:54.254703 139982171817984 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 216.65
I0901 12:22:58.870996 139982171817984 replay_runner.py:36] Average training steps per second: 216.65

Steps executed: 1000 Episode length: 1000 Return: -216.17498824920003
INFO:tensorflow:Starting iteration 18

Steps executed: 451 Episode length: 451 Return: -137.4197493712220803
INFO:tensorflow:Average training steps per second: 221.28
I0901 12:23:11.130100 139982171817984 replay_runner.py:36] Average training steps per second: 221.28
I0901 12:23:11.799400 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.42
INFO:tensorflow:Starting iteration 19

Steps executed: 409 Episode length: 409 Return: -221.2868383410738603
INFO:tensorflow:Average training steps per second: 219.26
I0901 12:23:20.765811 139982171817984 replay_runner.py:36] Average training steps per second: 219.26
I0901 12:23:21.443403 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.29
INFO:tensorflow:Starting iteration 20

Steps executed: 599 Episode length: 599 Return: -289.7650455788591403
INFO:tensorflow:Average training steps per second: 215.66
I0901 12:23:30.467780 139982171817984 replay_runner.py:36] Average training steps per second: 215.66
I0901 12:23:31.927128 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.77
INFO:tensorflow:Starting iteration 21

Steps executed: 485 Episode length: 353 Return: -370.6074204667406403
INFO:tensorflow:Average training steps per second: 217.64
I0901 12:23:40.553812 139982171817984 replay_runner.py:36] Average training steps per second: 217.64
I0901 12:23:41.256542 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.96
INFO:tensorflow:Starting iteration 22
I0901 12:23:45.716169 139982171817984 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 223.17

Steps executed: 246 Episode length: 246 Return: 21.559355524751822403
I0901 12:23:50.484062 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: 21.56
INFO:tensorflow:Starting iteration 23
I0901 12:23:54.672137 139982171817984 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 218.00

Steps executed: 1000 Episode length: 1000 Return: -96.972386294752403
I0901 12:24:02.485560 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.97
INFO:tensorflow:Starting iteration 24
I0901 12:24:06.921882 139982171817984 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 227.75

Steps executed: 1000 Episode length: 1000 Return: -46.732997045649243
I0901 12:24:14.179684 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -46.73
INFO:tensorflow:Starting iteration 25
I0901 12:24:18.587948 139982171817984 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 213.84
I0901 12:24:23.264812 139982171817984 replay_runner.py:36] Average training steps per second: 213.84

Steps executed: 1000 Episode length: 1000 Return: -38.321687128265594
INFO:tensorflow:Starting iteration 26
I0901 12:24:30.699992 139982171817984 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 217.06

Steps executed: 1000 Episode length: 1000 Return: -70.988999485686484
I0901 12:24:38.740170 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.99
INFO:tensorflow:Starting iteration 27
I0901 12:24:42.879175 139982171817984 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 240.10

Steps executed: 1000 Episode length: 1000 Return: -40.262828986059854
I0901 12:24:49.912200 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -40.26
INFO:tensorflow:Starting iteration 28
I0901 12:24:54.133697 139982171817984 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 233.54

Steps executed: 1000 Episode length: 1000 Return: -74.553869928209424
I0901 12:25:00.937888 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.55
INFO:tensorflow:Starting iteration 29

Steps executed: 240 Episode length: 76 Return: 38.7498089505747926424
INFO:tensorflow:Average training steps per second: 224.14
I0901 12:25:09.677380 139982171817984 replay_runner.py:36] Average training steps per second: 224.14

Done fixed training!Episode length: 76 Return: 38.7498089505747926424