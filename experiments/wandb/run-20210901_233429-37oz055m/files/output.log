Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0901 23:34:36.412874 140149719906304 run_experiment.py:549] Creating TrainRunner ...
I0901 23:34:36.425023 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:34:36.425311 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:34:36.425511 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:34:36.425867 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:34:36.426032 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0901 23:34:36.426192 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:34:36.426314 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:34:36.426448 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:34:36.427047 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:34:36.427242 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0901 23:34:36.427385 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:34:36.427622 140149719906304 dqn_agent.py:283] 	 seed: 1630539276424950
I0901 23:34:36.432162 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:34:36.432406 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:34:36.432585 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:34:36.432721 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:34:36.432847 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:34:36.433002 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:34:36.433137 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:34:36.433264 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:34:36.433384 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:34:36.468685 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:36.864462 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:36.878453 140149719906304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:34:36.887934 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:34:36.888148 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:34:36.888377 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:34:36.888480 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:34:36.888592 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0901 23:34:36.888716 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:34:36.888832 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:34:36.889020 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:34:36.889120 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:34:36.889193 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0901 23:34:36.889289 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:34:36.889390 140149719906304 dqn_agent.py:283] 	 seed: 1630539276887889
I0901 23:34:36.892160 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:34:36.892404 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:34:36.892597 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:34:36.892884 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:34:36.893041 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:34:36.893179 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:34:36.893304 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:34:36.893417 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:34:36.893612 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:34:36.964351 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:36.986947 140149719906304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:34:36.987243 140149719906304 replay_runner.py:41] Starting iteration 0
Steps executed: 197 Episode length: 61 Return: 34.6508168391471268
INFO:tensorflow:Average training steps per second: 172.28
I0901 23:34:42.791931 140149719906304 replay_runner.py:36] Average training steps per second: 172.28

Steps executed: 266 Episode length: 69 Return: -122.71525948042569
INFO:tensorflow:Starting iteration 1

Steps executed: 239 Episode length: 52 Return: -131.33433521597712
INFO:tensorflow:Average training steps per second: 218.46
I0901 23:34:53.002200 140149719906304 replay_runner.py:36] Average training steps per second: 218.46
I0901 23:34:53.174947 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.30
INFO:tensorflow:Starting iteration 2

Steps executed: 82 Episode length: 82 Return: -173.365164090901512
INFO:tensorflow:Average training steps per second: 224.49

Steps executed: 230 Episode length: 88 Return: -173.50530440377568
I0901 23:35:02.112401 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.12
INFO:tensorflow:Starting iteration 3

Steps executed: 215 Episode length: 73 Return: -136.45580887974373
INFO:tensorflow:Average training steps per second: 231.84
I0901 23:35:10.769899 140149719906304 replay_runner.py:36] Average training steps per second: 231.84
I0901 23:35:10.921083 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.38
INFO:tensorflow:Starting iteration 4

Steps executed: 311 Episode length: 114 Return: 12.794406673569881
INFO:tensorflow:Average training steps per second: 243.51
I0901 23:35:18.990595 140149719906304 replay_runner.py:36] Average training steps per second: 243.51
I0901 23:35:19.197353 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.82
INFO:tensorflow:Starting iteration 5

Steps executed: 210 Episode length: 68 Return: -118.89357590817443
INFO:tensorflow:Average training steps per second: 229.91
I0901 23:35:27.598084 140149719906304 replay_runner.py:36] Average training steps per second: 229.91
I0901 23:35:27.738673 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.36
INFO:tensorflow:Starting iteration 6

Steps executed: 241 Episode length: 87 Return: -188.89117319550425
INFO:tensorflow:Average training steps per second: 220.01
I0901 23:35:36.557765 140149719906304 replay_runner.py:36] Average training steps per second: 220.01
I0901 23:35:36.722278 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.06
INFO:tensorflow:Starting iteration 7

Steps executed: 264 Episode length: 69 Return: -159.37627092708075
INFO:tensorflow:Average training steps per second: 217.45
I0901 23:35:45.706617 140149719906304 replay_runner.py:36] Average training steps per second: 217.45
I0901 23:35:45.888355 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.56
INFO:tensorflow:Starting iteration 8

Steps executed: 229 Episode length: 77 Return: -142.05517748217548
INFO:tensorflow:Average training steps per second: 222.75
I0901 23:35:54.598223 140149719906304 replay_runner.py:36] Average training steps per second: 222.75
I0901 23:35:54.757049 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.52
INFO:tensorflow:Starting iteration 9

Steps executed: 250 Episode length: 77 Return: -166.55860848105033
INFO:tensorflow:Average training steps per second: 224.28
I0901 23:36:03.483782 140149719906304 replay_runner.py:36] Average training steps per second: 224.28
I0901 23:36:03.655770 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.60
INFO:tensorflow:Starting iteration 10
I0901 23:36:07.897383 140149719906304 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 219.31

Steps executed: 226 Episode length: 56 Return: -113.71645283446483
I0901 23:36:12.623568 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.14
INFO:tensorflow:Starting iteration 11

Steps executed: 248 Episode length: 70 Return: -138.69375019930465
INFO:tensorflow:Average training steps per second: 220.84
I0901 23:36:21.387902 140149719906304 replay_runner.py:36] Average training steps per second: 220.84
I0901 23:36:21.561966 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.43
INFO:tensorflow:Starting iteration 12

Steps executed: 199 Episode length: 64 Return: -153.41029426573018
INFO:tensorflow:Average training steps per second: 220.33
I0901 23:36:30.365368 140149719906304 replay_runner.py:36] Average training steps per second: 220.33

Steps executed: 260 Episode length: 61 Return: -135.60171195285838
INFO:tensorflow:Starting iteration 13

Steps executed: 218 Episode length: 61 Return: -150.44019371956412
INFO:tensorflow:Average training steps per second: 224.91
I0901 23:36:39.369279 140149719906304 replay_runner.py:36] Average training steps per second: 224.91
I0901 23:36:39.523537 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.02
INFO:tensorflow:Starting iteration 14

Steps executed: 70 Episode length: 70 Return: -125.145195057096542
INFO:tensorflow:Average training steps per second: 216.35
I0901 23:36:48.503930 140149719906304 replay_runner.py:36] Average training steps per second: 216.35

Steps executed: 204 Episode length: 72 Return: -143.22063298473245
INFO:tensorflow:Starting iteration 15

Steps executed: 203 Episode length: 78 Return: -116.30007966906138
INFO:tensorflow:Average training steps per second: 222.62
I0901 23:36:57.446635 140149719906304 replay_runner.py:36] Average training steps per second: 222.62
I0901 23:36:57.587556 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.36
INFO:tensorflow:Starting iteration 16

Steps executed: 233 Episode length: 83 Return: -125.56550911795381
INFO:tensorflow:Average training steps per second: 213.37
I0901 23:37:06.654540 140149719906304 replay_runner.py:36] Average training steps per second: 213.37
I0901 23:37:06.820116 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.72
INFO:tensorflow:Starting iteration 17

Steps executed: 251 Episode length: 54 Return: -95.563802026224127
INFO:tensorflow:Average training steps per second: 218.59
I0901 23:37:15.695893 140149719906304 replay_runner.py:36] Average training steps per second: 218.59
I0901 23:37:15.871995 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.13
INFO:tensorflow:Starting iteration 18

Steps executed: 203 Episode length: 75 Return: -188.82913620716835
INFO:tensorflow:Average training steps per second: 219.46
I0901 23:37:24.596038 140149719906304 replay_runner.py:36] Average training steps per second: 219.46
I0901 23:37:24.734396 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.93
INFO:tensorflow:Starting iteration 19

Steps executed: 206 Episode length: 62 Return: -155.58221684380912
INFO:tensorflow:Average training steps per second: 216.26
I0901 23:37:33.503934 140149719906304 replay_runner.py:36] Average training steps per second: 216.26
I0901 23:37:33.655517 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.85
INFO:tensorflow:Starting iteration 20

Steps executed: 203 Episode length: 72 Return: -133.99488152949291
INFO:tensorflow:Average training steps per second: 219.05
I0901 23:37:42.597274 140149719906304 replay_runner.py:36] Average training steps per second: 219.05
I0901 23:37:42.737912 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.36
INFO:tensorflow:Starting iteration 21

Steps executed: 242 Episode length: 50 Return: -129.38583660692632
INFO:tensorflow:Average training steps per second: 212.88
I0901 23:37:51.614370 140149719906304 replay_runner.py:36] Average training steps per second: 212.88
I0901 23:37:51.784853 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.48
INFO:tensorflow:Starting iteration 22
I0901 23:37:56.225824 140149719906304 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 229.20

Steps executed: 259 Episode length: 75 Return: -165.60793366966432
I0901 23:38:00.763499 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.83
INFO:tensorflow:Starting iteration 23

Steps executed: 223 Episode length: 64 Return: -164.76250602719247
INFO:tensorflow:Average training steps per second: 224.11
I0901 23:38:09.442014 140149719906304 replay_runner.py:36] Average training steps per second: 224.11
I0901 23:38:09.604713 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.90
INFO:tensorflow:Starting iteration 24

Steps executed: 265 Episode length: 68 Return: -149.56654036675155
INFO:tensorflow:Average training steps per second: 227.56
I0901 23:38:18.165172 140149719906304 replay_runner.py:36] Average training steps per second: 227.56
I0901 23:38:18.327050 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.81
INFO:tensorflow:Starting iteration 25

Steps executed: 66 Episode length: 66 Return: -153.842819564249455
INFO:tensorflow:Average training steps per second: 240.92
I0901 23:38:26.581187 140149719906304 replay_runner.py:36] Average training steps per second: 240.92

Steps executed: 208 Episode length: 89 Return: -98.301537021018485
INFO:tensorflow:Starting iteration 26

Steps executed: 275 Episode length: 79 Return: -95.093078032129438
INFO:tensorflow:Average training steps per second: 236.01
I0901 23:38:35.043574 140149719906304 replay_runner.py:36] Average training steps per second: 236.01
I0901 23:38:35.226012 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.97
INFO:tensorflow:Starting iteration 27

Steps executed: 223 Episode length: 59 Return: -125.57540329985949
INFO:tensorflow:Average training steps per second: 223.42
I0901 23:38:43.966956 140149719906304 replay_runner.py:36] Average training steps per second: 223.42
I0901 23:38:44.109713 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.15
INFO:tensorflow:Starting iteration 28
I0901 23:38:48.451195 140149719906304 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 222.99

Steps executed: 220 Episode length: 85 Return: -113.57428680976238
I0901 23:38:53.085395 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.64
INFO:tensorflow:Starting iteration 29

Steps executed: 212 Episode length: 59 Return: -138.29144292569152
INFO:tensorflow:Average training steps per second: 229.00
I0901 23:39:01.709216 140149719906304 replay_runner.py:36] Average training steps per second: 229.00

Done fixed training!Episode length: 59 Return: -138.29144292569152