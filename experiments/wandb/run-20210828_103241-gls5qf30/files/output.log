Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0828 10:32:48.014437 140214119393280 run_experiment.py:549] Creating TrainRunner ...
I0828 10:32:48.024713 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:48.024971 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:48.025098 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:48.025203 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:48.025304 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:48.025416 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:48.025518 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:48.025622 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:48.025718 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:48.025824 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:48.025922 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:48.026029 140214119393280 dqn_agent.py:283] 	 seed: 1630146768024650
I0828 10:32:48.029195 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:48.029404 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:48.029549 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:48.029674 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:48.029783 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:48.029898 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:48.030002 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:48.030318 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:48.030461 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:48.067631 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:48.426899 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:48.438908 140214119393280 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:32:48.447986 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:48.448230 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:48.448391 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:48.448513 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:48.448593 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:48.448666 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:48.448784 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:48.448880 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:48.449000 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:48.449086 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:48.449159 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:48.449232 140214119393280 dqn_agent.py:283] 	 seed: 1630146768447911
I0828 10:32:48.451168 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:48.451308 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:48.451394 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:48.451468 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:48.451537 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:48.451620 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:48.451716 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:48.451790 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:48.451868 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:48.480607 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:48.517300 140214119393280 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:32:48.533494 140214119393280 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 165.31
I0828 10:32:54.583176 140214119393280 replay_runner.py:36] Average training steps per second: 165.31
Steps executed: 219 Episode length: 73 Return: -511.2972726521415
I0828 10:32:56.009771 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -644.58
INFO:tensorflow:Starting iteration 1

Steps executed: 201 Episode length: 201 Return: -934.6554892566037
INFO:tensorflow:Average training steps per second: 227.69
I0828 10:33:04.696328 140214119393280 replay_runner.py:36] Average training steps per second: 227.69
I0828 10:33:04.919450 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -934.66
INFO:tensorflow:Starting iteration 2

Steps executed: 207 Episode length: 82 Return: -765.29534445348517
INFO:tensorflow:Average training steps per second: 218.19
I0828 10:33:13.799952 140214119393280 replay_runner.py:36] Average training steps per second: 218.19
I0828 10:33:13.980549 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -519.59
INFO:tensorflow:Starting iteration 3

Steps executed: 216 Episode length: 126 Return: -763.4333116497328
INFO:tensorflow:Average training steps per second: 225.75
I0828 10:33:22.572184 140214119393280 replay_runner.py:36] Average training steps per second: 225.75
I0828 10:33:22.760741 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -686.03
INFO:tensorflow:Starting iteration 4

Steps executed: 204 Episode length: 204 Return: -1318.0407186704906
INFO:tensorflow:Average training steps per second: 232.72
I0828 10:33:31.201005 140214119393280 replay_runner.py:36] Average training steps per second: 232.72
I0828 10:33:31.434219 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -1318.04
INFO:tensorflow:Starting iteration 5

Steps executed: 223 Episode length: 74 Return: -705.229500316123206
INFO:tensorflow:Average training steps per second: 227.62
I0828 10:33:40.075665 140214119393280 replay_runner.py:36] Average training steps per second: 227.62
I0828 10:33:40.262520 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -514.19
INFO:tensorflow:Starting iteration 6

Steps executed: 256 Episode length: 80 Return: -596.776813912943566
INFO:tensorflow:Average training steps per second: 230.65
I0828 10:33:48.907623 140214119393280 replay_runner.py:36] Average training steps per second: 230.65
I0828 10:33:49.114804 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -466.23
INFO:tensorflow:Starting iteration 7
I0828 10:33:53.402987 140214119393280 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 229.52
I0828 10:33:57.760932 140214119393280 replay_runner.py:36] Average training steps per second: 229.52

Steps executed: 209 Episode length: 209 Return: -1367.0463091227705
INFO:tensorflow:Starting iteration 8

Steps executed: 203 Episode length: 65 Return: -460.283985669740245
INFO:tensorflow:Average training steps per second: 237.89
I0828 10:34:06.471098 140214119393280 replay_runner.py:36] Average training steps per second: 237.89
I0828 10:34:06.627493 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.60
INFO:tensorflow:Starting iteration 9

Steps executed: 212 Episode length: 212 Return: -902.45266210841915
INFO:tensorflow:Average training steps per second: 222.03
I0828 10:34:15.362831 140214119393280 replay_runner.py:36] Average training steps per second: 222.03
I0828 10:34:15.578795 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -902.45
INFO:tensorflow:Starting iteration 10

Steps executed: 336 Episode length: 249 Return: -598.11133233701915
INFO:tensorflow:Average training steps per second: 219.40
I0828 10:34:24.382011 140214119393280 replay_runner.py:36] Average training steps per second: 219.40
I0828 10:34:24.775065 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -455.58
INFO:tensorflow:Starting iteration 11

Steps executed: 201 Episode length: 61 Return: -395.386665265036475
INFO:tensorflow:Average training steps per second: 215.70
I0828 10:34:33.737841 140214119393280 replay_runner.py:36] Average training steps per second: 215.70
I0828 10:34:33.907881 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -449.98
INFO:tensorflow:Starting iteration 12

Steps executed: 220 Episode length: 64 Return: -507.208388641733735
INFO:tensorflow:Average training steps per second: 218.49
I0828 10:34:42.820655 140214119393280 replay_runner.py:36] Average training steps per second: 218.49
I0828 10:34:43.017077 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -628.40
INFO:tensorflow:Starting iteration 13

Steps executed: 230 Episode length: 61 Return: -116.110188864409655
INFO:tensorflow:Average training steps per second: 223.87
I0828 10:34:51.832381 140214119393280 replay_runner.py:36] Average training steps per second: 223.87
I0828 10:34:51.996184 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.15
INFO:tensorflow:Starting iteration 14

Steps executed: 249 Episode length: 86 Return: -163.292097401095425
INFO:tensorflow:Average training steps per second: 217.17
I0828 10:35:00.997495 140214119393280 replay_runner.py:36] Average training steps per second: 217.17
I0828 10:35:01.185594 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.46
INFO:tensorflow:Starting iteration 15

Steps executed: 143 Episode length: 68 Return: -520.401635709343325
INFO:tensorflow:Average training steps per second: 217.08
I0828 10:35:10.138477 140214119393280 replay_runner.py:36] Average training steps per second: 217.08

Steps executed: 200 Episode length: 57 Return: -349.349988395958325
INFO:tensorflow:Starting iteration 16

Steps executed: 355 Episode length: 200 Return: -1397.8239262758095
INFO:tensorflow:Average training steps per second: 219.11
I0828 10:35:19.159341 140214119393280 replay_runner.py:36] Average training steps per second: 219.11
I0828 10:35:19.543864 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -1036.58
INFO:tensorflow:Starting iteration 17
I0828 10:35:23.859978 140214119393280 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 219.03

Steps executed: 289 Episode length: 115 Return: -624.14493955434795
I0828 10:35:28.707651 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -501.68
INFO:tensorflow:Starting iteration 18

Steps executed: 214 Episode length: 72 Return: -583.149934299019295
INFO:tensorflow:Average training steps per second: 217.38
I0828 10:35:37.595949 140214119393280 replay_runner.py:36] Average training steps per second: 217.38
I0828 10:35:37.771354 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -426.71
INFO:tensorflow:Starting iteration 19

Steps executed: 202 Episode length: 67 Return: -138.558159254435825
INFO:tensorflow:Average training steps per second: 219.62
I0828 10:35:46.703449 140214119393280 replay_runner.py:36] Average training steps per second: 219.62
I0828 10:35:46.847093 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -315.02
INFO:tensorflow:Starting iteration 20

Steps executed: 217 Episode length: 54 Return: -403.447424684465765
INFO:tensorflow:Average training steps per second: 223.60
I0828 10:35:55.573068 140214119393280 replay_runner.py:36] Average training steps per second: 223.60
I0828 10:35:55.772115 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -405.88
INFO:tensorflow:Starting iteration 21

Steps executed: 226 Episode length: 89 Return: -699.412447072071565
INFO:tensorflow:Average training steps per second: 224.27
I0828 10:36:04.479947 140214119393280 replay_runner.py:36] Average training steps per second: 224.27
I0828 10:36:04.676445 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -594.98
INFO:tensorflow:Starting iteration 22

Steps executed: 210 Episode length: 77 Return: -677.235567776100765
INFO:tensorflow:Average training steps per second: 226.41
I0828 10:36:13.348504 140214119393280 replay_runner.py:36] Average training steps per second: 226.41
I0828 10:36:13.534156 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -549.33
INFO:tensorflow:Starting iteration 23

Steps executed: 71 Episode length: 71 Return: -735.2716624476783765
INFO:tensorflow:Average training steps per second: 229.50
I0828 10:36:22.036443 140214119393280 replay_runner.py:36] Average training steps per second: 229.50

Steps executed: 233 Episode length: 77 Return: -742.053818957837865
INFO:tensorflow:Starting iteration 24

Steps executed: 250 Episode length: 83 Return: -636.090386743435765
INFO:tensorflow:Average training steps per second: 234.35
I0828 10:36:30.691963 140214119393280 replay_runner.py:36] Average training steps per second: 234.35
I0828 10:36:30.902925 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -612.88
INFO:tensorflow:Starting iteration 25

Steps executed: 266 Episode length: 71 Return: -628.394705288286465
INFO:tensorflow:Average training steps per second: 220.18
I0828 10:36:39.709825 140214119393280 replay_runner.py:36] Average training steps per second: 220.18
I0828 10:36:39.948454 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -539.81
INFO:tensorflow:Starting iteration 26

Steps executed: 257 Episode length: 70 Return: -709.179466891865765
INFO:tensorflow:Average training steps per second: 224.93
I0828 10:36:48.724061 140214119393280 replay_runner.py:36] Average training steps per second: 224.93
I0828 10:36:48.947345 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -634.11
INFO:tensorflow:Starting iteration 27

Steps executed: 256 Episode length: 163 Return: -897.72308455386175
INFO:tensorflow:Average training steps per second: 227.11
I0828 10:36:57.619403 140214119393280 replay_runner.py:36] Average training steps per second: 227.11
I0828 10:36:57.885681 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -675.88
INFO:tensorflow:Starting iteration 28
I0828 10:37:02.099727 140214119393280 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 231.22

Steps executed: 256 Episode length: 71 Return: -528.398513942581575
I0828 10:37:06.640745 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -564.28
INFO:tensorflow:Starting iteration 29

Steps executed: 214 Episode length: 86 Return: -351.855244014653335
INFO:tensorflow:Average training steps per second: 249.59
I0828 10:37:14.959121 140214119393280 replay_runner.py:36] Average training steps per second: 249.59

Done fixed training!Episode length: 86 Return: -351.855244014653335