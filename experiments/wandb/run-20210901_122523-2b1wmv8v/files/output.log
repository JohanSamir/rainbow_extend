Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0901 12:25:30.153099 140536266098688 run_experiment.py:549] Creating TrainRunner ...
I0901 12:25:30.164751 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:25:30.165017 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:25:30.165139 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:25:30.165238 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:25:30.165328 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 12:25:30.165422 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:25:30.165538 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:25:30.165679 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:25:30.165769 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:25:30.165860 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 12:25:30.165978 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:25:30.166134 140536266098688 dqn_agent.py:283] 	 seed: 1630499130164682
I0901 12:25:30.168789 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:25:30.169013 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:25:30.169125 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:25:30.169215 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:25:30.169297 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:25:30.169384 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:25:30.169463 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:25:30.169548 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:25:30.169631 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:25:30.441148 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:30.880119 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:30.895026 140536266098688 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:25:30.904736 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:25:30.904969 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:25:30.905051 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:25:30.905122 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:25:30.905188 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 12:25:30.905307 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:25:30.905382 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:25:30.905442 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:25:30.905497 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:25:30.905636 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 12:25:30.905722 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:25:30.905796 140536266098688 dqn_agent.py:283] 	 seed: 1630499130904678
I0901 12:25:30.908675 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:25:30.908974 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:25:30.909123 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:25:30.909258 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:25:30.909495 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:25:30.909750 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:25:30.910035 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:25:30.910729 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:25:30.911079 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:25:30.945319 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:30.966070 140536266098688 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:25:30.966416 140536266098688 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 146.98
I0901 12:25:37.770234 140536266098688 replay_runner.py:36] Average training steps per second: 146.98
Steps executed: 249 Episode length: 80 Return: -785.26809595860086
I0901 12:25:39.100792 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -589.02
INFO:tensorflow:Starting iteration 1

Steps executed: 218 Episode length: 99 Return: -366.485813707506733
INFO:tensorflow:Average training steps per second: 206.79
I0901 12:25:48.389900 140536266098688 replay_runner.py:36] Average training steps per second: 206.79
I0901 12:25:48.590910 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -306.22
INFO:tensorflow:Starting iteration 2

Steps executed: 312 Episode length: 119 Return: -180.03153126279582
INFO:tensorflow:Average training steps per second: 206.70
I0901 12:25:57.881318 140536266098688 replay_runner.py:36] Average training steps per second: 206.70
I0901 12:25:58.204855 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -348.88
INFO:tensorflow:Starting iteration 3

Steps executed: 302 Episode length: 154 Return: -278.59015669117076
INFO:tensorflow:Average training steps per second: 207.65
I0901 12:26:07.328473 140536266098688 replay_runner.py:36] Average training steps per second: 207.65
I0901 12:26:07.635364 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.00
INFO:tensorflow:Starting iteration 4

Steps executed: 246 Episode length: 107 Return: -162.42787887993425
INFO:tensorflow:Average training steps per second: 205.73
I0901 12:26:16.733450 140536266098688 replay_runner.py:36] Average training steps per second: 205.73
I0901 12:26:16.972014 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.25
INFO:tensorflow:Starting iteration 5

Steps executed: 258 Episode length: 104 Return: -269.00890399261993
INFO:tensorflow:Average training steps per second: 210.03
I0901 12:26:26.095709 140536266098688 replay_runner.py:36] Average training steps per second: 210.03
I0901 12:26:26.369604 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -297.51
INFO:tensorflow:Starting iteration 6

Steps executed: 220 Episode length: 220 Return: -58.253383498478513
INFO:tensorflow:Average training steps per second: 206.32
I0901 12:26:35.639280 140536266098688 replay_runner.py:36] Average training steps per second: 206.32
I0901 12:26:35.876260 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -58.25
INFO:tensorflow:Starting iteration 7

Steps executed: 275 Episode length: 131 Return: -54.910119169752238
INFO:tensorflow:Average training steps per second: 214.07
I0901 12:26:45.000415 140536266098688 replay_runner.py:36] Average training steps per second: 214.07
I0901 12:26:45.296240 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.17
INFO:tensorflow:Starting iteration 8

Steps executed: 295 Episode length: 136 Return: -66.504495796975862
INFO:tensorflow:Average training steps per second: 182.96
I0901 12:26:55.207235 140536266098688 replay_runner.py:36] Average training steps per second: 182.96
I0901 12:26:55.495020 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.44
INFO:tensorflow:Starting iteration 9

Steps executed: 252 Episode length: 126 Return: -70.589465148531052
INFO:tensorflow:Average training steps per second: 213.33
I0901 12:27:04.506245 140536266098688 replay_runner.py:36] Average training steps per second: 213.33
I0901 12:27:04.727365 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.73
INFO:tensorflow:Starting iteration 10

Steps executed: 242 Episode length: 122 Return: -199.57933914849997
INFO:tensorflow:Average training steps per second: 210.83
I0901 12:27:13.611395 140536266098688 replay_runner.py:36] Average training steps per second: 210.83
I0901 12:27:13.863363 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.26
INFO:tensorflow:Starting iteration 11

Steps executed: 276 Episode length: 86 Return: -592.954542378308867
INFO:tensorflow:Average training steps per second: 210.15
I0901 12:27:23.105050 140536266098688 replay_runner.py:36] Average training steps per second: 210.15
I0901 12:27:23.362854 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -449.39
INFO:tensorflow:Starting iteration 12
I0901 12:27:27.717082 140536266098688 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 215.08

Steps executed: 338 Episode length: 140 Return: -333.91284023099854
I0901 12:27:32.682605 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.67
INFO:tensorflow:Starting iteration 13

Steps executed: 370 Episode length: 259 Return: 161.452077197832354
INFO:tensorflow:Average training steps per second: 211.55
I0901 12:27:41.872901 140536266098688 replay_runner.py:36] Average training steps per second: 211.55
I0901 12:27:42.328888 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.15
INFO:tensorflow:Starting iteration 14

Steps executed: 295 Episode length: 106 Return: -83.157196541999744
INFO:tensorflow:Average training steps per second: 225.45
I0901 12:27:51.199910 140536266098688 replay_runner.py:36] Average training steps per second: 225.45
I0901 12:27:51.425184 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.13
INFO:tensorflow:Starting iteration 15
I0901 12:27:55.721586 140536266098688 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 224.00
I0901 12:28:00.186460 140536266098688 replay_runner.py:36] Average training steps per second: 224.00

Steps executed: 278 Episode length: 192 Return: -23.612300610945667
INFO:tensorflow:Starting iteration 16

Steps executed: 279 Episode length: 89 Return: -532.885088912996993
INFO:tensorflow:Average training steps per second: 224.39
I0901 12:28:09.210597 140536266098688 replay_runner.py:36] Average training steps per second: 224.39
I0901 12:28:09.443232 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.98
INFO:tensorflow:Starting iteration 17
I0901 12:28:13.797691 140536266098688 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 226.23
I0901 12:28:18.218460 140536266098688 replay_runner.py:36] Average training steps per second: 226.23

Steps executed: 265 Episode length: 85 Return: -164.701044917034478
INFO:tensorflow:Starting iteration 18

Steps executed: 517 Episode length: 356 Return: 139.534018138153648
INFO:tensorflow:Average training steps per second: 239.39
I0901 12:28:26.823063 140536266098688 replay_runner.py:36] Average training steps per second: 239.39
I0901 12:28:27.498851 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.32
INFO:tensorflow:Starting iteration 19
I0901 12:28:31.754708 140536266098688 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 223.43

Steps executed: 333 Episode length: 254 Return: -86.848396469475938
I0901 12:28:36.604730 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.69
INFO:tensorflow:Starting iteration 20

Steps executed: 284 Episode length: 284 Return: -94.998121322029698
INFO:tensorflow:Average training steps per second: 217.15
I0901 12:28:45.474384 140536266098688 replay_runner.py:36] Average training steps per second: 217.15
I0901 12:28:45.799306 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.00
INFO:tensorflow:Starting iteration 21

Steps executed: 236 Episode length: 89 Return: -749.164194089554368
INFO:tensorflow:Average training steps per second: 217.82
I0901 12:28:54.756079 140536266098688 replay_runner.py:36] Average training steps per second: 217.82
I0901 12:28:54.968914 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.23
INFO:tensorflow:Starting iteration 22

Steps executed: 200 Episode length: 84 Return: -117.697522834825218
INFO:tensorflow:Average training steps per second: 215.32
I0901 12:29:03.617635 140536266098688 replay_runner.py:36] Average training steps per second: 215.32
I0901 12:29:03.771560 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.96
INFO:tensorflow:Starting iteration 23

Steps executed: 251 Episode length: 64 Return: -109.894016886958848
INFO:tensorflow:Average training steps per second: 215.39
I0901 12:29:12.742808 140536266098688 replay_runner.py:36] Average training steps per second: 215.39
I0901 12:29:12.943561 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.93
INFO:tensorflow:Starting iteration 24

Steps executed: 254 Episode length: 183 Return: -139.61475853776258
INFO:tensorflow:Average training steps per second: 213.00
I0901 12:29:21.936423 140536266098688 replay_runner.py:36] Average training steps per second: 213.00
I0901 12:29:22.174827 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -264.81
INFO:tensorflow:Starting iteration 25

Steps executed: 398 Episode length: 236 Return: -148.01932581146698
INFO:tensorflow:Average training steps per second: 214.28
I0901 12:29:30.981101 140536266098688 replay_runner.py:36] Average training steps per second: 214.28
I0901 12:29:31.381710 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.51
INFO:tensorflow:Starting iteration 26

Steps executed: 269 Episode length: 132 Return: -275.03423049096248
INFO:tensorflow:Average training steps per second: 219.53
I0901 12:29:40.135547 140536266098688 replay_runner.py:36] Average training steps per second: 219.53
I0901 12:29:40.373502 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.86
INFO:tensorflow:Starting iteration 27

Steps executed: 268 Episode length: 70 Return: -451.576214489386948
INFO:tensorflow:Average training steps per second: 214.86
I0901 12:29:49.367608 140536266098688 replay_runner.py:36] Average training steps per second: 214.86
I0901 12:29:49.587538 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -446.01
INFO:tensorflow:Starting iteration 28

Steps executed: 272 Episode length: 99 Return: -175.806653880807066
INFO:tensorflow:Average training steps per second: 221.95
I0901 12:29:58.282604 140536266098688 replay_runner.py:36] Average training steps per second: 221.95
I0901 12:29:58.521628 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.72
INFO:tensorflow:Starting iteration 29

Steps executed: 309 Episode length: 152 Return: -476.42654617930876
INFO:tensorflow:Average training steps per second: 219.46
I0901 12:30:07.329621 140536266098688 replay_runner.py:36] Average training steps per second: 219.46

Done fixed training!Episode length: 152 Return: -476.42654617930876