Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0902 23:20:06.243669 140099460519936 run_experiment.py:549] Creating TrainRunner ...
I0902 23:20:06.255639 140099460519936 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:20:06.255915 140099460519936 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:20:06.256063 140099460519936 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:20:06.256160 140099460519936 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:20:06.256246 140099460519936 dqn_agent.py:275] 	 update_period: 4
I0902 23:20:06.256350 140099460519936 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:20:06.256449 140099460519936 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:20:06.256546 140099460519936 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:20:06.256631 140099460519936 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:20:06.256770 140099460519936 dqn_agent.py:280] 	 optimizer: adam
I0902 23:20:06.256863 140099460519936 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:20:06.256951 140099460519936 dqn_agent.py:283] 	 seed: 1630624806255574
I0902 23:20:06.259656 140099460519936 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:20:06.259868 140099460519936 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:20:06.259993 140099460519936 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:20:06.260088 140099460519936 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:20:06.260172 140099460519936 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:20:06.260254 140099460519936 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:20:06.260363 140099460519936 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:20:06.260452 140099460519936 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:20:06.260536 140099460519936 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:20:06.293551 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:20:06.665079 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:20:06.680539 140099460519936 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:20:06.690440 140099460519936 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:20:06.690765 140099460519936 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:20:06.690949 140099460519936 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:20:06.691111 140099460519936 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:20:06.691237 140099460519936 dqn_agent.py:275] 	 update_period: 4
I0902 23:20:06.691375 140099460519936 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:20:06.691720 140099460519936 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:20:06.691874 140099460519936 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:20:06.691992 140099460519936 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:20:06.692147 140099460519936 dqn_agent.py:280] 	 optimizer: adam
I0902 23:20:06.692283 140099460519936 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:20:06.692440 140099460519936 dqn_agent.py:283] 	 seed: 1630624806690384
I0902 23:20:06.695336 140099460519936 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:20:06.695477 140099460519936 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:20:06.695549 140099460519936 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:20:06.695621 140099460519936 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:20:06.695707 140099460519936 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:20:06.695770 140099460519936 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:20:06.695881 140099460519936 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:20:06.696011 140099460519936 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:20:06.696086 140099460519936 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:20:06.724162 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:20:06.791387 140099460519936 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:20:06.791672 140099460519936 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 168.73
I0902 23:20:12.718630 140099460519936 replay_runner.py:36] Average training steps per second: 168.73
Steps executed: 203 Episode length: 82 Return: -758.5849465731485
I0902 23:20:13.943409 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -623.93
INFO:tensorflow:Starting iteration 1

Steps executed: 264 Episode length: 72 Return: -633.8574218610837
INFO:tensorflow:Average training steps per second: 220.92
I0902 23:20:22.871120 140099460519936 replay_runner.py:36] Average training steps per second: 220.92
I0902 23:20:23.127976 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -599.68
INFO:tensorflow:Starting iteration 2

Steps executed: 259 Episode length: 60 Return: -538.68507815676284
INFO:tensorflow:Average training steps per second: 222.16
I0902 23:20:32.081483 140099460519936 replay_runner.py:36] Average training steps per second: 222.16
I0902 23:20:32.319023 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -476.21
INFO:tensorflow:Starting iteration 3

Steps executed: 235 Episode length: 70 Return: -552.18317109252836
INFO:tensorflow:Average training steps per second: 220.95
I0902 23:20:41.278285 140099460519936 replay_runner.py:36] Average training steps per second: 220.95
I0902 23:20:41.506564 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -468.35
INFO:tensorflow:Starting iteration 4

Steps executed: 216 Episode length: 68 Return: -476.03973872697237
INFO:tensorflow:Average training steps per second: 226.25
I0902 23:20:50.210251 140099460519936 replay_runner.py:36] Average training steps per second: 226.25
I0902 23:20:50.411980 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -698.71
INFO:tensorflow:Starting iteration 5

Steps executed: 246 Episode length: 65 Return: -521.51828617291727
INFO:tensorflow:Average training steps per second: 222.67
I0902 23:20:59.268834 140099460519936 replay_runner.py:36] Average training steps per second: 222.67
I0902 23:20:59.490710 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -483.35
INFO:tensorflow:Starting iteration 6

Steps executed: 202 Episode length: 80 Return: -753.25832086342955
INFO:tensorflow:Average training steps per second: 224.83
I0902 23:21:08.308553 140099460519936 replay_runner.py:36] Average training steps per second: 224.83
I0902 23:21:08.505383 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -559.82
INFO:tensorflow:Starting iteration 7

Steps executed: 207 Episode length: 78 Return: -710.55047933796285
INFO:tensorflow:Average training steps per second: 225.92
I0902 23:21:17.261474 140099460519936 replay_runner.py:36] Average training steps per second: 225.92
I0902 23:21:17.454983 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -602.01
INFO:tensorflow:Starting iteration 8

Steps executed: 217 Episode length: 86 Return: -547.30643439410985
INFO:tensorflow:Average training steps per second: 226.65
I0902 23:21:26.267316 140099460519936 replay_runner.py:36] Average training steps per second: 226.65
I0902 23:21:26.494455 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -757.33
INFO:tensorflow:Starting iteration 9

Steps executed: 203 Episode length: 203 Return: -1295.1788132543068
INFO:tensorflow:Average training steps per second: 231.33
I0902 23:21:35.249558 140099460519936 replay_runner.py:36] Average training steps per second: 231.33
I0902 23:21:35.486494 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -1295.18
INFO:tensorflow:Starting iteration 10
I0902 23:21:39.947391 140099460519936 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 233.33

Steps executed: 365 Episode length: 177 Return: -960.43586522893198
I0902 23:21:44.632607 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -685.25
INFO:tensorflow:Starting iteration 11

Steps executed: 278 Episode length: 203 Return: -1508.6665783329936
INFO:tensorflow:Average training steps per second: 232.48
I0902 23:21:53.083561 140099460519936 replay_runner.py:36] Average training steps per second: 232.48
I0902 23:21:53.385558 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -1003.17
INFO:tensorflow:Starting iteration 12

Steps executed: 247 Episode length: 171 Return: -1472.1961424616013
INFO:tensorflow:Average training steps per second: 229.74
I0902 23:22:02.048404 140099460519936 replay_runner.py:36] Average training steps per second: 229.74
I0902 23:22:02.295470 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -979.90
INFO:tensorflow:Starting iteration 13

Steps executed: 261 Episode length: 79 Return: -628.459815583129213
INFO:tensorflow:Average training steps per second: 229.94
I0902 23:22:11.009115 140099460519936 replay_runner.py:36] Average training steps per second: 229.94
I0902 23:22:11.244547 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -606.18
INFO:tensorflow:Starting iteration 14

Steps executed: 244 Episode length: 128 Return: -531.62760104244783
INFO:tensorflow:Average training steps per second: 248.57
I0902 23:22:19.431966 140099460519936 replay_runner.py:36] Average training steps per second: 248.57
I0902 23:22:19.663797 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -660.67
INFO:tensorflow:Starting iteration 15

Steps executed: 187 Episode length: 187 Return: -1237.4084631108283
INFO:tensorflow:Average training steps per second: 242.74

Steps executed: 349 Episode length: 162 Return: -1113.4981032969158
I0902 23:22:28.568062 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -1175.45
INFO:tensorflow:Starting iteration 16

Steps executed: 491 Episode length: 384 Return: -3965.2574950699413
INFO:tensorflow:Average training steps per second: 228.61
I0902 23:22:37.203291 140099460519936 replay_runner.py:36] Average training steps per second: 228.61
I0902 23:22:37.939320 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -2392.39
INFO:tensorflow:Starting iteration 17

Steps executed: 259 Episode length: 103 Return: -636.66007261208423
INFO:tensorflow:Average training steps per second: 221.54
I0902 23:22:46.841573 140099460519936 replay_runner.py:36] Average training steps per second: 221.54
I0902 23:22:47.113028 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -761.66
INFO:tensorflow:Starting iteration 18

Steps executed: 218 Episode length: 73 Return: -485.378739900872793
INFO:tensorflow:Average training steps per second: 225.95
I0902 23:22:55.899073 140099460519936 replay_runner.py:36] Average training steps per second: 225.95
I0902 23:22:56.134011 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -679.75
INFO:tensorflow:Starting iteration 19

Steps executed: 245 Episode length: 80 Return: -536.682389346674963
INFO:tensorflow:Average training steps per second: 224.47
I0902 23:23:04.990474 140099460519936 replay_runner.py:36] Average training steps per second: 224.47
I0902 23:23:05.234360 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -503.95
INFO:tensorflow:Starting iteration 20

Steps executed: 200 Episode length: 112 Return: -710.64092743012953
INFO:tensorflow:Average training steps per second: 228.09
I0902 23:23:14.050694 140099460519936 replay_runner.py:36] Average training steps per second: 228.09
I0902 23:23:14.254700 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -577.04
INFO:tensorflow:Starting iteration 21

Steps executed: 266 Episode length: 100 Return: -563.22926755965683
INFO:tensorflow:Average training steps per second: 226.40
I0902 23:23:23.053794 140099460519936 replay_runner.py:36] Average training steps per second: 226.40
I0902 23:23:23.329038 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -491.93
INFO:tensorflow:Starting iteration 22

Steps executed: 158 Episode length: 80 Return: -628.668058174581783
INFO:tensorflow:Average training steps per second: 227.14

Steps executed: 274 Episode length: 116 Return: -654.33833563541873
I0902 23:23:32.418354 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -590.87
INFO:tensorflow:Starting iteration 23

Steps executed: 385 Episode length: 231 Return: -1885.8620242557472
INFO:tensorflow:Average training steps per second: 229.04
I0902 23:23:41.149533 140099460519936 replay_runner.py:36] Average training steps per second: 229.04
I0902 23:23:41.645570 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -1441.36
INFO:tensorflow:Starting iteration 24

Steps executed: 233 Episode length: 115 Return: -837.25489122712462
INFO:tensorflow:Average training steps per second: 225.28
I0902 23:23:50.538638 140099460519936 replay_runner.py:36] Average training steps per second: 225.28
I0902 23:23:50.777791 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -847.69
INFO:tensorflow:Starting iteration 25

Steps executed: 257 Episode length: 257 Return: -2291.2220997025242
INFO:tensorflow:Average training steps per second: 230.23
I0902 23:23:59.361576 140099460519936 replay_runner.py:36] Average training steps per second: 230.23
I0902 23:23:59.734254 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -2291.22
INFO:tensorflow:Starting iteration 26
I0902 23:24:04.209437 140099460519936 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 228.98

Steps executed: 276 Episode length: 276 Return: -2741.6395009974517
I0902 23:24:08.951915 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -2741.64
INFO:tensorflow:Starting iteration 27

Steps executed: 257 Episode length: 99 Return: -420.700666460137217
INFO:tensorflow:Average training steps per second: 227.70
I0902 23:24:17.525012 140099460519936 replay_runner.py:36] Average training steps per second: 227.70
I0902 23:24:17.778571 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -514.11
INFO:tensorflow:Starting iteration 28
I0902 23:24:22.267660 140099460519936 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 229.24

Steps executed: 306 Episode length: 228 Return: -1360.4339345890514
I0902 23:24:26.984218 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -879.13
INFO:tensorflow:Starting iteration 29

Steps executed: 239 Episode length: 112 Return: -637.76303996708074
INFO:tensorflow:Average training steps per second: 236.30
I0902 23:24:35.621196 140099460519936 replay_runner.py:36] Average training steps per second: 236.30

Done fixed training!Episode length: 112 Return: -637.76303996708074