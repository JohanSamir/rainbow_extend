I0905 16:28:14.042283 139789596633088 run_experiment.py:549] Creating TrainRunner ...
I0905 16:28:14.052104 139789596633088 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:28:14.052440 139789596633088 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:28:14.052593 139789596633088 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:28:14.052680 139789596633088 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:28:14.052764 139789596633088 dqn_agent.py:275] 	 update_period: 4
I0905 16:28:14.052841 139789596633088 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:28:14.052922 139789596633088 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:28:14.053002 139789596633088 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:28:14.053108 139789596633088 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:28:14.053230 139789596633088 dqn_agent.py:280] 	 optimizer: adam
I0905 16:28:14.053313 139789596633088 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:28:14.053404 139789596633088 dqn_agent.py:283] 	 seed: 1630859294052025
I0905 16:28:14.055644 139789596633088 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:28:14.055793 139789596633088 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:28:14.055909 139789596633088 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:28:14.055995 139789596633088 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:28:14.056084 139789596633088 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:28:14.056186 139789596633088 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:28:14.056330 139789596633088 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:28:14.056426 139789596633088 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:28:14.056535 139789596633088 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0905 16:28:15.792560 139789596633088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:16.148546 139789596633088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:16.157982 139789596633088 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:28:16.164590 139789596633088 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:28:16.164740 139789596633088 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:28:16.164898 139789596633088 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:28:16.164963 139789596633088 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:28:16.165021 139789596633088 dqn_agent.py:275] 	 update_period: 4
I0905 16:28:16.165074 139789596633088 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:28:16.165162 139789596633088 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:28:16.165233 139789596633088 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:28:16.165303 139789596633088 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:28:16.165371 139789596633088 dqn_agent.py:280] 	 optimizer: adam
I0905 16:28:16.165437 139789596633088 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:28:16.165502 139789596633088 dqn_agent.py:283] 	 seed: 1630859296164553
I0905 16:28:16.167047 139789596633088 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:28:16.167172 139789596633088 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:28:16.167243 139789596633088 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:28:16.167328 139789596633088 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:28:16.167404 139789596633088 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:28:16.167459 139789596633088 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:28:16.167512 139789596633088 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:28:16.167563 139789596633088 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:28:16.167636 139789596633088 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:28:16.190301 139789596633088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:16.205749 139789596633088 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:28:16.205974 139789596633088 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 205.12
I0905 16:28:21.081592 139789596633088 replay_runner.py:36] Average training steps per second: 205.12
Steps executed: 336 Episode length: 140 Return: -167.4739386099131
I0905 16:28:22.068217 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.86
INFO:tensorflow:Starting iteration 1

Steps executed: 209 Episode length: 124 Return: -327.46702593919366
INFO:tensorflow:Average training steps per second: 290.11
I0905 16:28:29.227358 139789596633088 replay_runner.py:36] Average training steps per second: 290.11
I0905 16:28:29.338791 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -298.73
INFO:tensorflow:Starting iteration 2

Steps executed: 240 Episode length: 129 Return: -184.74706849784872
INFO:tensorflow:Average training steps per second: 302.11
I0905 16:28:36.311078 139789596633088 replay_runner.py:36] Average training steps per second: 302.11
I0905 16:28:36.435541 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.55
INFO:tensorflow:Starting iteration 3

Steps executed: 247 Episode length: 105 Return: -223.78227019717576
INFO:tensorflow:Average training steps per second: 300.65
I0905 16:28:43.450473 139789596633088 replay_runner.py:36] Average training steps per second: 300.65
I0905 16:28:43.580339 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.08
INFO:tensorflow:Starting iteration 4

Steps executed: 93 Episode length: 93 Return: -250.3133212209236376
INFO:tensorflow:Average training steps per second: 303.94

Steps executed: 1093 Episode length: 1000 Return: -117.09927603743829
I0905 16:28:53.544897 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -183.71
INFO:tensorflow:Starting iteration 5
I0905 16:28:57.244339 139789596633088 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 314.35

Steps executed: 968 Episode length: 968 Return: -256.4140925350787829
I0905 16:29:01.983476 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.41
INFO:tensorflow:Starting iteration 6
I0905 16:29:05.608160 139789596633088 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 311.97

Steps executed: 823 Episode length: 823 Return: -229.4688064182492729
I0905 16:29:10.237607 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.47
INFO:tensorflow:Starting iteration 7
I0905 16:29:13.946876 139789596633088 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 295.46

Steps executed: 1000 Episode length: 1000 Return: -121.73858184179305
I0905 16:29:20.438262 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.74
INFO:tensorflow:Starting iteration 8
I0905 16:29:24.443007 139789596633088 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 251.67

Steps executed: 1000 Episode length: 1000 Return: -123.57769307235935
I0905 16:29:31.655741 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.58
INFO:tensorflow:Starting iteration 9
I0905 16:29:35.881695 139789596633088 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 234.34

Steps executed: 1000 Episode length: 1000 Return: -148.70022282341327
I0905 16:29:42.195012 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.70
INFO:tensorflow:Starting iteration 10
I0905 16:29:46.482167 139789596633088 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 231.00

Steps executed: 835 Episode length: 835 Return: -386.0278221960091427
I0905 16:29:52.274331 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -386.03
INFO:tensorflow:Starting iteration 11
I0905 16:29:56.593567 139789596633088 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 235.04

Steps executed: 1000 Episode length: 1000 Return: -75.182812327072047
I0905 16:30:03.002031 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.18
INFO:tensorflow:Starting iteration 12
I0905 16:30:07.253803 139789596633088 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 238.93

Steps executed: 1000 Episode length: 1000 Return: 86.6601530625589547
I0905 16:30:14.212403 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: 86.66
INFO:tensorflow:Starting iteration 13
I0905 16:30:18.371895 139789596633088 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 234.75

Steps executed: 1000 Episode length: 1000 Return: -37.361290786477417
I0905 16:30:26.157308 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.36
INFO:tensorflow:Starting iteration 14
I0905 16:30:30.257113 139789596633088 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 236.18

Steps executed: 1000 Episode length: 1000 Return: -77.642983767079467
I0905 16:30:37.002646 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.64
INFO:tensorflow:Starting iteration 15

Steps executed: 123 Episode length: 55 Return: -212.67896649310075467
INFO:tensorflow:Average training steps per second: 241.73

Steps executed: 1123 Episode length: 1000 Return: -79.133679315692767
I0905 16:30:48.730758 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.40
INFO:tensorflow:Starting iteration 16

Steps executed: 197 Episode length: 197 Return: -643.7815919557453767
INFO:tensorflow:Average training steps per second: 239.14

Steps executed: 995 Episode length: 798 Return: -348.2372165133523767
I0905 16:30:59.564894 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -496.01
INFO:tensorflow:Starting iteration 17
I0905 16:31:03.737003 139789596633088 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 237.73
I0905 16:31:07.944128 139789596633088 replay_runner.py:36] Average training steps per second: 237.73

Steps executed: 313 Episode length: 127 Return: -773.9068054209454767
INFO:tensorflow:Starting iteration 18

Steps executed: 282 Episode length: 146 Return: -304.3494147507414767
INFO:tensorflow:Average training steps per second: 234.75
I0905 16:31:16.767863 139789596633088 replay_runner.py:36] Average training steps per second: 234.75
I0905 16:31:16.992122 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -398.42
INFO:tensorflow:Starting iteration 19

Steps executed: 252 Episode length: 56 Return: -247.01121376032276567
INFO:tensorflow:Average training steps per second: 241.51
I0905 16:31:25.355294 139789596633088 replay_runner.py:36] Average training steps per second: 241.51
I0905 16:31:25.537142 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -324.37
INFO:tensorflow:Starting iteration 20

Steps executed: 150 Episode length: 84 Return: -498.26673881352686567
INFO:tensorflow:Average training steps per second: 238.81
I0905 16:31:34.014678 139789596633088 replay_runner.py:36] Average training steps per second: 238.81

Steps executed: 231 Episode length: 81 Return: -456.28929358364655567
INFO:tensorflow:Starting iteration 21

Steps executed: 247 Episode length: 103 Return: -220.5781780786675567
INFO:tensorflow:Average training steps per second: 239.00
I0905 16:31:42.634769 139789596633088 replay_runner.py:36] Average training steps per second: 239.00
I0905 16:31:42.810195 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -313.05
INFO:tensorflow:Starting iteration 22

Steps executed: 269 Episode length: 269 Return: -368.7636755968910667
INFO:tensorflow:Average training steps per second: 258.47
I0905 16:31:50.876865 139789596633088 replay_runner.py:36] Average training steps per second: 258.47
I0905 16:31:51.113757 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -368.76
INFO:tensorflow:Starting iteration 23

Steps executed: 338 Episode length: 191 Return: -248.8264800175858667
INFO:tensorflow:Average training steps per second: 233.05
I0905 16:31:59.503943 139789596633088 replay_runner.py:36] Average training steps per second: 233.05
I0905 16:31:59.725628 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -403.51
INFO:tensorflow:Starting iteration 24

Steps executed: 207 Episode length: 207 Return: -94.49850647607028667
INFO:tensorflow:Average training steps per second: 198.65
I0905 16:32:08.983061 139789596633088 replay_runner.py:36] Average training steps per second: 198.65
I0905 16:32:09.220145 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.50
INFO:tensorflow:Starting iteration 25

Steps executed: 233 Episode length: 75 Return: -46.131841470285295467
INFO:tensorflow:Average training steps per second: 191.47
I0905 16:32:18.980870 139789596633088 replay_runner.py:36] Average training steps per second: 191.47
I0905 16:32:19.186981 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.45
INFO:tensorflow:Starting iteration 26

Steps executed: 232 Episode length: 98 Return: -450.70023102341825467
INFO:tensorflow:Average training steps per second: 185.63
I0905 16:32:29.600365 139789596633088 replay_runner.py:36] Average training steps per second: 185.63
I0905 16:32:29.832174 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -395.71
INFO:tensorflow:Starting iteration 27

Steps executed: 315 Episode length: 142 Return: -228.2420901969697467
INFO:tensorflow:Average training steps per second: 158.88
I0905 16:32:41.108202 139789596633088 replay_runner.py:36] Average training steps per second: 158.88
I0905 16:32:41.481888 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -247.97
INFO:tensorflow:Starting iteration 28

Steps executed: 259 Episode length: 182 Return: -212.4567514893123567
INFO:tensorflow:Average training steps per second: 159.85
I0905 16:32:51.961693 139789596633088 replay_runner.py:36] Average training steps per second: 159.85
I0905 16:32:52.284339 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -345.34
INFO:tensorflow:Starting iteration 29

Steps executed: 246 Episode length: 246 Return: -192.9277633718991267
INFO:tensorflow:Average training steps per second: 155.66
I0905 16:33:03.660919 139789596633088 replay_runner.py:36] Average training steps per second: 155.66

Done fixed training!Episode length: 246 Return: -192.9277633718991267