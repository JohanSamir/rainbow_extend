Loaded trained dqn in acrobot
Training fixed agent 4, please be patient, may be a while...
I0901 23:57:27.073221 140268518520832 run_experiment.py:549] Creating TrainRunner ...
I0901 23:57:27.083132 140268518520832 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:57:27.083412 140268518520832 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:57:27.083651 140268518520832 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:57:27.083807 140268518520832 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:57:27.084029 140268518520832 dqn_agent.py:275] 	 update_period: 4
I0901 23:57:27.084160 140268518520832 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:57:27.084362 140268518520832 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:57:27.084495 140268518520832 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:57:27.084609 140268518520832 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:57:27.084718 140268518520832 dqn_agent.py:280] 	 optimizer: adam
I0901 23:57:27.084916 140268518520832 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:57:27.085037 140268518520832 dqn_agent.py:283] 	 seed: 1630540647083073
I0901 23:57:27.088801 140268518520832 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:57:27.089081 140268518520832 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 23:57:27.089237 140268518520832 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:57:27.089361 140268518520832 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:57:27.089477 140268518520832 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:57:27.089592 140268518520832 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:57:27.089708 140268518520832 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:57:27.089872 140268518520832 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:57:27.090002 140268518520832 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:57:27.132637 140268518520832 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:57:27.550677 140268518520832 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:57:27.584691 140268518520832 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:57:27.594193 140268518520832 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:57:27.594432 140268518520832 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:57:27.594546 140268518520832 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:57:27.594688 140268518520832 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:57:27.594858 140268518520832 dqn_agent.py:275] 	 update_period: 4
I0901 23:57:27.595018 140268518520832 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:57:27.595228 140268518520832 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:57:27.595512 140268518520832 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:57:27.595788 140268518520832 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:57:27.595907 140268518520832 dqn_agent.py:280] 	 optimizer: adam
I0901 23:57:27.596145 140268518520832 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:57:27.596458 140268518520832 dqn_agent.py:283] 	 seed: 1630540647594104
I0901 23:57:27.600127 140268518520832 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:57:27.600350 140268518520832 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 23:57:27.600497 140268518520832 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:57:27.600617 140268518520832 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:57:27.600737 140268518520832 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:57:27.600883 140268518520832 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:57:27.600995 140268518520832 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:57:27.601120 140268518520832 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:57:27.601307 140268518520832 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:57:27.640267 140268518520832 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:57:27.664281 140268518520832 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:57:27.664595 140268518520832 replay_runner.py:41] Starting iteration 0
Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 138.82
I0901 23:57:34.868423 140268518520832 replay_runner.py:36] Average training steps per second: 138.82
I0901 23:57:36.428379 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1

Steps executed: 370 Episode length: 370 Return: -369.0
INFO:tensorflow:Average training steps per second: 192.22
I0901 23:57:41.848046 140268518520832 replay_runner.py:36] Average training steps per second: 192.22
I0901 23:57:42.166192 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -369.00
INFO:tensorflow:Starting iteration 2

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 192.44
I0901 23:57:47.606319 140268518520832 replay_runner.py:36] Average training steps per second: 192.44
I0901 23:57:48.026809 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 3

Steps executed: 626 Episode length: 480 Return: -479.0
INFO:tensorflow:Average training steps per second: 189.60
I0901 23:57:53.545783 140268518520832 replay_runner.py:36] Average training steps per second: 189.60
I0901 23:57:54.077227 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -312.00
INFO:tensorflow:Starting iteration 4

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 187.15
I0901 23:57:59.663321 140268518520832 replay_runner.py:36] Average training steps per second: 187.15
I0901 23:58:00.097536 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 5
I0901 23:58:00.350404 140268518520832 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 190.20
I0901 23:58:05.608420 140268518520832 replay_runner.py:36] Average training steps per second: 190.20
I0901 23:58:06.049694 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6

Steps executed: 270 Episode length: 101 Return: -100.0
INFO:tensorflow:Average training steps per second: 187.93
I0901 23:58:11.611548 140268518520832 replay_runner.py:36] Average training steps per second: 187.93
I0901 23:58:11.832115 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.00
INFO:tensorflow:Starting iteration 7

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 190.12
I0901 23:58:17.329404 140268518520832 replay_runner.py:36] Average training steps per second: 190.12
I0901 23:58:17.757984 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 8
I0901 23:58:18.000635 140268518520832 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 190.67
I0901 23:58:23.245752 140268518520832 replay_runner.py:36] Average training steps per second: 190.67
I0901 23:58:23.670503 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 9
I0901 23:58:23.913834 140268518520832 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 189.27
I0901 23:58:29.197733 140268518520832 replay_runner.py:36] Average training steps per second: 189.27
I0901 23:58:29.612333 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 10
I0901 23:58:29.846859 140268518520832 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 189.03

Steps executed: 218 Episode length: 124 Return: -123.0
I0901 23:58:35.330375 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.00
INFO:tensorflow:Starting iteration 11

Steps executed: 101 Episode length: 101 Return: -100.0
INFO:tensorflow:Average training steps per second: 189.86

Steps executed: 601 Episode length: 500 Return: -500.0
I0901 23:58:41.355689 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.00
INFO:tensorflow:Starting iteration 12

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 196.38
I0901 23:58:46.694097 140268518520832 replay_runner.py:36] Average training steps per second: 196.38
I0901 23:58:47.092483 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 13

Steps executed: 232 Episode length: 90 Return: -89.0.0
INFO:tensorflow:Average training steps per second: 196.81
I0901 23:58:52.411929 140268518520832 replay_runner.py:36] Average training steps per second: 196.81
I0901 23:58:52.596784 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.00
INFO:tensorflow:Starting iteration 14

Steps executed: 262 Episode length: 84 Return: -83.0.0
INFO:tensorflow:Average training steps per second: 186.06
I0901 23:58:58.212110 140268518520832 replay_runner.py:36] Average training steps per second: 186.06
I0901 23:58:58.426659 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.33
INFO:tensorflow:Starting iteration 15

Steps executed: 231 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Average training steps per second: 199.29
I0901 23:59:03.684020 140268518520832 replay_runner.py:36] Average training steps per second: 199.29
I0901 23:59:03.869811 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.00
INFO:tensorflow:Starting iteration 16

Steps executed: 220 Episode length: 70 Return: -69.0.0
INFO:tensorflow:Average training steps per second: 186.80
I0901 23:59:09.462851 140268518520832 replay_runner.py:36] Average training steps per second: 186.80
I0901 23:59:09.633133 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.33
INFO:tensorflow:Starting iteration 17
I0901 23:59:09.869019 140268518520832 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 188.51

Steps executed: 290 Episode length: 94 Return: -93.0.0
I0901 23:59:15.436186 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.67
INFO:tensorflow:Starting iteration 18

Steps executed: 151 Episode length: 64 Return: -63.0.0
INFO:tensorflow:Average training steps per second: 190.25
I0901 23:59:20.932108 140268518520832 replay_runner.py:36] Average training steps per second: 190.25

Steps executed: 224 Episode length: 73 Return: -72.0.0
INFO:tensorflow:Starting iteration 19

Steps executed: 227 Episode length: 79 Return: -78.0.0
INFO:tensorflow:Average training steps per second: 192.78
I0901 23:59:26.555452 140268518520832 replay_runner.py:36] Average training steps per second: 192.78
I0901 23:59:26.756800 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.67
INFO:tensorflow:Starting iteration 20

Steps executed: 226 Episode length: 61 Return: -60.0.0
INFO:tensorflow:Average training steps per second: 194.54
I0901 23:59:32.150724 140268518520832 replay_runner.py:36] Average training steps per second: 194.54
I0901 23:59:32.338259 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.33
INFO:tensorflow:Starting iteration 21

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 198.72
I0901 23:59:37.618721 140268518520832 replay_runner.py:36] Average training steps per second: 198.72
I0901 23:59:37.997180 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 22
I0901 23:59:38.225853 140268518520832 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 196.82
I0901 23:59:43.306986 140268518520832 replay_runner.py:36] Average training steps per second: 196.82
I0901 23:59:43.701418 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 23

Steps executed: 249 Episode length: 75 Return: -74.0.0
INFO:tensorflow:Average training steps per second: 210.34
I0901 23:59:48.684036 140268518520832 replay_runner.py:36] Average training steps per second: 210.34
I0901 23:59:48.876620 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.00
INFO:tensorflow:Starting iteration 24

Steps executed: 254 Episode length: 76 Return: -75.0.0
INFO:tensorflow:Average training steps per second: 201.50
I0901 23:59:54.065709 140268518520832 replay_runner.py:36] Average training steps per second: 201.50
I0901 23:59:54.271574 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.67
INFO:tensorflow:Starting iteration 25
I0901 23:59:54.491517 140268518520832 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 197.52

Steps executed: 210 Episode length: 64 Return: -63.0.0
I0901 23:59:59.734046 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.00
INFO:tensorflow:Starting iteration 26

Steps executed: 230 Episode length: 75 Return: -74.0.0
INFO:tensorflow:Average training steps per second: 194.07
I0902 00:00:05.128880 140268518520832 replay_runner.py:36] Average training steps per second: 194.07
I0902 00:00:05.321499 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.67
INFO:tensorflow:Starting iteration 27

Steps executed: 219 Episode length: 71 Return: -70.0.0
INFO:tensorflow:Average training steps per second: 197.19
I0902 00:00:10.637831 140268518520832 replay_runner.py:36] Average training steps per second: 197.19
I0902 00:00:10.819652 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.00
INFO:tensorflow:Starting iteration 28

Steps executed: 275 Episode length: 94 Return: -93.0.0
INFO:tensorflow:Average training steps per second: 196.64
I0902 00:00:16.148410 140268518520832 replay_runner.py:36] Average training steps per second: 196.64
I0902 00:00:16.385840 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.67
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 106 Return: -105.0
INFO:tensorflow:Average training steps per second: 190.89
I0902 00:00:21.862877 140268518520832 replay_runner.py:36] Average training steps per second: 190.89
I0902 00:00:22.041082 140268518520832 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.50