Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0902 17:50:58.198359 140216164177920 run_experiment.py:549] Creating TrainRunner ...
I0902 17:50:58.211420 140216164177920 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:50:58.211711 140216164177920 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:50:58.211977 140216164177920 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:50:58.212174 140216164177920 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:50:58.212443 140216164177920 dqn_agent.py:275] 	 update_period: 4
I0902 17:50:58.212710 140216164177920 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:50:58.212890 140216164177920 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:50:58.213035 140216164177920 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:50:58.213994 140216164177920 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:50:58.214450 140216164177920 dqn_agent.py:280] 	 optimizer: adam
I0902 17:50:58.216708 140216164177920 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:50:58.217169 140216164177920 dqn_agent.py:283] 	 seed: 1630605058211353
I0902 17:50:58.220443 140216164177920 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:50:58.220620 140216164177920 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:50:58.220764 140216164177920 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:50:58.220868 140216164177920 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:50:58.220961 140216164177920 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:50:58.221051 140216164177920 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:50:58.221134 140216164177920 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:50:58.221305 140216164177920 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:50:58.221477 140216164177920 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:50:58.265163 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:50:58.652446 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:50:58.666873 140216164177920 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 17:50:58.676674 140216164177920 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:50:58.676962 140216164177920 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:50:58.677185 140216164177920 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:50:58.677310 140216164177920 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:50:58.677410 140216164177920 dqn_agent.py:275] 	 update_period: 4
I0902 17:50:58.677485 140216164177920 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:50:58.677559 140216164177920 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:50:58.677629 140216164177920 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:50:58.677731 140216164177920 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:50:58.677837 140216164177920 dqn_agent.py:280] 	 optimizer: adam
I0902 17:50:58.678081 140216164177920 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:50:58.678251 140216164177920 dqn_agent.py:283] 	 seed: 1630605058676623
I0902 17:50:58.680164 140216164177920 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:50:58.680279 140216164177920 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:50:58.680379 140216164177920 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:50:58.680445 140216164177920 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:50:58.680559 140216164177920 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:50:58.680625 140216164177920 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:50:58.680679 140216164177920 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:50:58.680731 140216164177920 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:50:58.680786 140216164177920 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:50:58.753345 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:50:58.775326 140216164177920 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 17:50:58.775586 140216164177920 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 163.40
I0902 17:51:04.895673 140216164177920 replay_runner.py:36] Average training steps per second: 163.40
Steps executed: 245 Episode length: 61 Return: -412.65852971140254
I0902 17:51:06.151095 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -544.24
INFO:tensorflow:Starting iteration 1

Steps executed: 280 Episode length: 93 Return: -570.62422595288775
INFO:tensorflow:Average training steps per second: 216.66
I0902 17:51:15.024880 140216164177920 replay_runner.py:36] Average training steps per second: 216.66
I0902 17:51:15.277377 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -615.42
INFO:tensorflow:Starting iteration 2

Steps executed: 251 Episode length: 137 Return: -122.50580017001329
INFO:tensorflow:Average training steps per second: 216.34
I0902 17:51:24.156781 140216164177920 replay_runner.py:36] Average training steps per second: 216.34
I0902 17:51:24.336779 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.04
INFO:tensorflow:Starting iteration 3

Steps executed: 205 Episode length: 101 Return: -68.140570621685879
INFO:tensorflow:Average training steps per second: 221.16
I0902 17:51:33.112521 140216164177920 replay_runner.py:36] Average training steps per second: 221.16
I0902 17:51:33.267925 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.20
INFO:tensorflow:Starting iteration 4

Steps executed: 254 Episode length: 182 Return: -125.61972699900933
INFO:tensorflow:Average training steps per second: 217.34
I0902 17:51:42.078430 140216164177920 replay_runner.py:36] Average training steps per second: 217.34
I0902 17:51:42.281170 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.94
INFO:tensorflow:Starting iteration 5

Steps executed: 263 Episode length: 68 Return: -121.661775606295683
INFO:tensorflow:Average training steps per second: 224.26
I0902 17:51:51.084362 140216164177920 replay_runner.py:36] Average training steps per second: 224.26
I0902 17:51:51.308098 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.68
INFO:tensorflow:Starting iteration 6

Steps executed: 285 Episode length: 90 Return: -459.562500015046886
INFO:tensorflow:Average training steps per second: 218.48
I0902 17:52:00.234149 140216164177920 replay_runner.py:36] Average training steps per second: 218.48
I0902 17:52:00.481757 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -251.97
INFO:tensorflow:Starting iteration 7

Steps executed: 215 Episode length: 93 Return: -131.288761795018486
INFO:tensorflow:Average training steps per second: 219.92
I0902 17:52:09.221320 140216164177920 replay_runner.py:36] Average training steps per second: 219.92
I0902 17:52:09.406918 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.40
INFO:tensorflow:Starting iteration 8

Steps executed: 225 Episode length: 71 Return: -164.420954210986086
INFO:tensorflow:Average training steps per second: 218.22
I0902 17:52:18.411768 140216164177920 replay_runner.py:36] Average training steps per second: 218.22
I0902 17:52:18.567643 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.02
INFO:tensorflow:Starting iteration 9

Steps executed: 307 Episode length: 115 Return: -18.987151592880466
INFO:tensorflow:Average training steps per second: 211.28
I0902 17:52:27.676104 140216164177920 replay_runner.py:36] Average training steps per second: 211.28
I0902 17:52:27.906352 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -20.16
INFO:tensorflow:Starting iteration 10

Steps executed: 283 Episode length: 145 Return: -387.87435289001866
INFO:tensorflow:Average training steps per second: 220.79
I0902 17:52:36.672108 140216164177920 replay_runner.py:36] Average training steps per second: 220.79
I0902 17:52:36.936012 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -370.16
INFO:tensorflow:Starting iteration 11

Steps executed: 278 Episode length: 87 Return: -382.431835103548746
INFO:tensorflow:Average training steps per second: 221.11
I0902 17:52:45.857002 140216164177920 replay_runner.py:36] Average training steps per second: 221.11
I0902 17:52:46.096050 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -318.10
INFO:tensorflow:Starting iteration 12

Steps executed: 261 Episode length: 184 Return: -141.99048525571192
INFO:tensorflow:Average training steps per second: 220.01
I0902 17:52:55.023863 140216164177920 replay_runner.py:36] Average training steps per second: 220.01
I0902 17:52:55.242584 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.13
INFO:tensorflow:Starting iteration 13

Steps executed: 294 Episode length: 294 Return: -176.22086907525915
INFO:tensorflow:Average training steps per second: 221.76
I0902 17:53:03.943099 140216164177920 replay_runner.py:36] Average training steps per second: 221.76
I0902 17:53:04.245744 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.22
INFO:tensorflow:Starting iteration 14

Steps executed: 305 Episode length: 186 Return: -165.04345517066622
INFO:tensorflow:Average training steps per second: 237.43
I0902 17:53:12.602356 140216164177920 replay_runner.py:36] Average training steps per second: 237.43
I0902 17:53:12.830740 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.52
INFO:tensorflow:Starting iteration 15

Steps executed: 275 Episode length: 144 Return: -166.71389181550524
INFO:tensorflow:Average training steps per second: 233.62
I0902 17:53:21.448669 140216164177920 replay_runner.py:36] Average training steps per second: 233.62
I0902 17:53:21.692879 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -322.23
INFO:tensorflow:Starting iteration 16
I0902 17:53:26.019813 140216164177920 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 226.21

Steps executed: 202 Episode length: 108 Return: -73.818030128740624
I0902 17:53:30.609388 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.69
INFO:tensorflow:Starting iteration 17

Steps executed: 228 Episode length: 102 Return: -444.96569950954464
INFO:tensorflow:Average training steps per second: 229.97
I0902 17:53:39.240038 140216164177920 replay_runner.py:36] Average training steps per second: 229.97
I0902 17:53:39.426433 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.83
INFO:tensorflow:Starting iteration 18

Steps executed: 232 Episode length: 149 Return: -420.82607765822964
INFO:tensorflow:Average training steps per second: 239.81
I0902 17:53:47.850069 140216164177920 replay_runner.py:36] Average training steps per second: 239.81
I0902 17:53:48.038855 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -441.07
INFO:tensorflow:Starting iteration 19
I0902 17:53:52.184604 140216164177920 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 222.44

Steps executed: 226 Episode length: 134 Return: -436.21273301502164
I0902 17:53:56.876147 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.86
INFO:tensorflow:Starting iteration 20

Steps executed: 226 Episode length: 127 Return: -365.21055577461095
INFO:tensorflow:Average training steps per second: 214.50
I0902 17:54:05.812190 140216164177920 replay_runner.py:36] Average training steps per second: 214.50
I0902 17:54:06.021250 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -349.33
INFO:tensorflow:Starting iteration 21

Steps executed: 262 Episode length: 117 Return: -257.11653706583616
INFO:tensorflow:Average training steps per second: 219.77
I0902 17:54:14.918911 140216164177920 replay_runner.py:36] Average training steps per second: 219.77
I0902 17:54:15.127994 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.07
INFO:tensorflow:Starting iteration 22

Steps executed: 276 Episode length: 140 Return: -420.19427703524956
INFO:tensorflow:Average training steps per second: 218.72
I0902 17:54:23.978041 140216164177920 replay_runner.py:36] Average training steps per second: 218.72
I0902 17:54:24.226058 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -493.16
INFO:tensorflow:Starting iteration 23

Steps executed: 302 Episode length: 203 Return: -147.35160364658043
INFO:tensorflow:Average training steps per second: 216.80
I0902 17:54:33.150704 140216164177920 replay_runner.py:36] Average training steps per second: 216.80
I0902 17:54:33.466647 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.15
INFO:tensorflow:Starting iteration 24
I0902 17:54:37.782913 140216164177920 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 218.48

Steps executed: 371 Episode length: 371 Return: -365.83674673049873
I0902 17:54:42.831717 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -365.84
INFO:tensorflow:Starting iteration 25

Steps executed: 213 Episode length: 93 Return: -248.696563572127273
INFO:tensorflow:Average training steps per second: 223.34
I0902 17:54:51.537901 140216164177920 replay_runner.py:36] Average training steps per second: 223.34
I0902 17:54:51.718336 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.41
INFO:tensorflow:Starting iteration 26
I0902 17:54:56.007548 140216164177920 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 220.99

Steps executed: 201 Episode length: 91 Return: -240.460050400925258
I0902 17:55:00.700165 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.79
INFO:tensorflow:Starting iteration 27

Steps executed: 212 Episode length: 91 Return: -250.011916677532248
INFO:tensorflow:Average training steps per second: 225.11
I0902 17:55:09.337701 140216164177920 replay_runner.py:36] Average training steps per second: 225.11
I0902 17:55:09.505570 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -240.64
INFO:tensorflow:Starting iteration 28

Steps executed: 185 Episode length: 185 Return: -395.53202660856788
INFO:tensorflow:Average training steps per second: 226.12
I0902 17:55:18.253659 140216164177920 replay_runner.py:36] Average training steps per second: 226.12

Steps executed: 341 Episode length: 156 Return: -406.91856439440548
INFO:tensorflow:Starting iteration 29

Steps executed: 559 Episode length: 386 Return: -631.01476928829878
INFO:tensorflow:Average training steps per second: 234.44
I0902 17:55:27.270238 140216164177920 replay_runner.py:36] Average training steps per second: 234.44

Done fixed training!Episode length: 386 Return: -631.01476928829878