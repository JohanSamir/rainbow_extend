Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0901 12:14:37.459994 139809518303232 run_experiment.py:549] Creating TrainRunner ...
I0901 12:14:37.473853 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:14:37.474189 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:14:37.474383 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:14:37.474485 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:14:37.474570 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 12:14:37.474674 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:14:37.474947 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:14:37.475061 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:14:37.475155 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:14:37.475251 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 12:14:37.475409 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:14:37.475513 139809518303232 dqn_agent.py:283] 	 seed: 1630498477473770
I0901 12:14:37.478890 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:14:37.479165 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:14:37.479330 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:14:37.479460 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:14:37.479573 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:14:37.479684 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:14:37.479794 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:14:37.479905 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:14:37.480013 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:14:37.547011 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:14:38.260269 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:14:38.276625 139809518303232 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:14:38.284873 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:14:38.285188 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:14:38.285406 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:14:38.285555 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:14:38.285739 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 12:14:38.286255 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:14:38.286456 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:14:38.286606 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:14:38.286746 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:14:38.286916 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 12:14:38.287017 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:14:38.287114 139809518303232 dqn_agent.py:283] 	 seed: 1630498478284799
I0901 12:14:38.289979 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:14:38.290196 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:14:38.290315 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:14:38.290424 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:14:38.290544 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:14:38.290694 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:14:38.290852 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:14:38.290966 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:14:38.291066 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:14:38.324624 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:14:38.345766 139809518303232 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:14:38.346095 139809518303232 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 158.10
I0901 12:14:44.671856 139809518303232 replay_runner.py:36] Average training steps per second: 158.10
Steps executed: 224 Episode length: 113 Return: -301.43825927574915
I0901 12:14:45.967762 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -330.61
INFO:tensorflow:Starting iteration 1

Steps executed: 213 Episode length: 89 Return: -244.184377206891242
INFO:tensorflow:Average training steps per second: 218.11
I0901 12:14:54.894026 139809518303232 replay_runner.py:36] Average training steps per second: 218.11
I0901 12:14:55.085932 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.51
INFO:tensorflow:Starting iteration 2

Steps executed: 290 Episode length: 158 Return: -269.81641492357792
INFO:tensorflow:Average training steps per second: 220.87
I0901 12:15:03.957144 139809518303232 replay_runner.py:36] Average training steps per second: 220.87
I0901 12:15:04.234933 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.62
INFO:tensorflow:Starting iteration 3

Steps executed: 289 Episode length: 152 Return: -94.563359122998636
INFO:tensorflow:Average training steps per second: 223.17
I0901 12:15:12.901569 139809518303232 replay_runner.py:36] Average training steps per second: 223.17
I0901 12:15:13.168264 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.53
INFO:tensorflow:Starting iteration 4
I0901 12:15:17.551470 139809518303232 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 220.68

Steps executed: 971 Episode length: 971 Return: -266.91125422990136
I0901 12:15:24.237036 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.91
INFO:tensorflow:Starting iteration 5
I0901 12:15:28.647607 139809518303232 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 222.92

Steps executed: 1000 Episode length: 1000 Return: -133.53161121289057
I0901 12:15:35.264679 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.53
INFO:tensorflow:Starting iteration 6
I0901 12:15:39.305900 139809518303232 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 228.96

Steps executed: 1000 Episode length: 1000 Return: -97.772644191910537
I0901 12:15:46.189593 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.77
INFO:tensorflow:Starting iteration 7

Steps executed: 583 Episode length: 583 Return: -196.9247461535516737
INFO:tensorflow:Average training steps per second: 229.00
I0901 12:15:54.538734 139809518303232 replay_runner.py:36] Average training steps per second: 229.00
I0901 12:15:55.488480 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.92
INFO:tensorflow:Starting iteration 8
I0901 12:15:59.508511 139809518303232 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 212.87

Steps executed: 1000 Episode length: 1000 Return: -280.70454612411004
I0901 12:16:06.878794 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.70
INFO:tensorflow:Starting iteration 9
I0901 12:16:11.165173 139809518303232 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 210.76

Steps executed: 939 Episode length: 939 Return: -406.0766328602881604
I0901 12:16:18.045689 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.08
INFO:tensorflow:Starting iteration 10
I0901 12:16:22.488667 139809518303232 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 206.05
I0901 12:16:27.342545 139809518303232 replay_runner.py:36] Average training steps per second: 206.05

Steps executed: 824 Episode length: 824 Return: -453.4106656228367604
INFO:tensorflow:Starting iteration 11

Steps executed: 260 Episode length: 260 Return: -219.3018035712967604
INFO:tensorflow:Average training steps per second: 208.09
I0901 12:16:38.556337 139809518303232 replay_runner.py:36] Average training steps per second: 208.09
I0901 12:16:38.893432 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -219.30
INFO:tensorflow:Starting iteration 12
I0901 12:16:43.133713 139809518303232 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 202.69

Steps executed: 1000 Episode length: 1000 Return: -313.14280960210784
I0901 12:16:50.738931 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -313.14
INFO:tensorflow:Starting iteration 13
I0901 12:16:55.083952 139809518303232 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 202.43

Steps executed: 1000 Episode length: 1000 Return: -71.869812560409534
I0901 12:17:02.608337 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.87
INFO:tensorflow:Starting iteration 14
I0901 12:17:06.992209 139809518303232 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 207.32

Steps executed: 1000 Episode length: 1000 Return: -149.83953515247552
I0901 12:17:14.958348 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.84
INFO:tensorflow:Starting iteration 15

Steps executed: 328 Episode length: 328 Return: -183.0023242363869352
INFO:tensorflow:Average training steps per second: 203.06
I0901 12:17:24.290241 139809518303232 replay_runner.py:36] Average training steps per second: 203.06
I0901 12:17:24.759465 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -183.00
INFO:tensorflow:Starting iteration 16
I0901 12:17:29.195698 139809518303232 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 205.39

Steps executed: 1000 Episode length: 1000 Return: -133.35792531144483
I0901 12:17:36.859669 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.36
INFO:tensorflow:Starting iteration 17

Steps executed: 317 Episode length: 317 Return: -455.1052483760532483
INFO:tensorflow:Average training steps per second: 210.48
I0901 12:17:46.066830 139809518303232 replay_runner.py:36] Average training steps per second: 210.48
I0901 12:17:46.476934 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -455.11
INFO:tensorflow:Starting iteration 18
I0901 12:17:50.870437 139809518303232 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 205.78

Steps executed: 1000 Episode length: 1000 Return: -91.870128887913273
I0901 12:17:58.904246 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.87
INFO:tensorflow:Starting iteration 19

Steps executed: 307 Episode length: 307 Return: -303.9090525086185273
INFO:tensorflow:Average training steps per second: 213.28
I0901 12:18:08.135760 139809518303232 replay_runner.py:36] Average training steps per second: 213.28
I0901 12:18:08.632793 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.91
INFO:tensorflow:Starting iteration 20
I0901 12:18:13.008737 139809518303232 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 209.03

Steps executed: 1000 Episode length: 1000 Return: -91.386934447007533
I0901 12:18:20.662499 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.39
INFO:tensorflow:Starting iteration 21
I0901 12:18:25.138403 139809518303232 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 208.48

Steps executed: 1000 Episode length: 1000 Return: -139.28217166419836
I0901 12:18:33.690329 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.28
INFO:tensorflow:Starting iteration 22
I0901 12:18:38.037117 139809518303232 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 230.15

Steps executed: 1000 Episode length: 1000 Return: 12.7623859598220466
I0901 12:18:46.417072 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: 12.76
INFO:tensorflow:Starting iteration 23
I0901 12:18:50.882719 139809518303232 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 247.80

Steps executed: 606 Episode length: 606 Return: -242.1078664960009866
I0901 12:18:56.079398 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.11
INFO:tensorflow:Starting iteration 24
I0901 12:19:00.140157 139809518303232 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 230.72

Steps executed: 828 Episode length: 828 Return: -389.4895957912129866
I0901 12:19:07.053070 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -389.49
INFO:tensorflow:Starting iteration 25

Steps executed: 111 Episode length: 111 Return: -161.1073669941636866
INFO:tensorflow:Average training steps per second: 219.16
I0901 12:19:15.851642 139809518303232 replay_runner.py:36] Average training steps per second: 219.16

Steps executed: 268 Episode length: 157 Return: -197.9820010061409366
INFO:tensorflow:Starting iteration 26
I0901 12:19:20.402138 139809518303232 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 214.03

Steps executed: 1000 Episode length: 1000 Return: -0.8048122832607134
I0901 12:19:29.031000 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -0.80
INFO:tensorflow:Starting iteration 27
I0901 12:19:33.493887 139809518303232 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 226.13

Steps executed: 436 Episode length: 436 Return: -462.1625997153348634
I0901 12:19:38.633802 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -462.16
INFO:tensorflow:Starting iteration 28
I0901 12:19:42.992154 139809518303232 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 218.37
I0901 12:19:47.572721 139809518303232 replay_runner.py:36] Average training steps per second: 218.37

Steps executed: 230 Episode length: 230 Return: -448.9852293615533634
INFO:tensorflow:Starting iteration 29

Steps executed: 265 Episode length: 111 Return: -437.3825035407782634
INFO:tensorflow:Average training steps per second: 219.02
I0901 12:19:56.868534 139809518303232 replay_runner.py:36] Average training steps per second: 219.02

Done fixed training!Episode length: 111 Return: -437.3825035407782634