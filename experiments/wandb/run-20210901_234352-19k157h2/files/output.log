I0901 23:43:59.335593 140252174653440 run_experiment.py:549] Creating TrainRunner ...
I0901 23:43:59.347548 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:43:59.347765 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:43:59.347855 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:43:59.347925 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:43:59.347987 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0901 23:43:59.348085 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:43:59.348191 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:43:59.348340 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:43:59.348405 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:43:59.348508 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0901 23:43:59.348593 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:43:59.348683 140252174653440 dqn_agent.py:283] 	 seed: 1630539839347495
I0901 23:43:59.351679 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:43:59.351896 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:43:59.352111 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:43:59.352298 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:43:59.352418 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:43:59.352523 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:43:59.352727 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:43:59.352850 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:43:59.353023 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:44:00.757805 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0901 23:44:01.111063 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:44:01.125771 140252174653440 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:44:01.133781 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:44:01.134063 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:44:01.134258 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:44:01.134416 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:44:01.134587 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0901 23:44:01.134689 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:44:01.134834 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:44:01.134961 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:44:01.135112 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:44:01.135251 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0901 23:44:01.135453 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:44:01.135563 140252174653440 dqn_agent.py:283] 	 seed: 1630539841133713
I0901 23:44:01.138317 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:44:01.138456 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:44:01.138553 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:44:01.138653 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:44:01.138712 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:44:01.138778 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:44:01.138835 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:44:01.138950 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:44:01.139107 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:44:01.167679 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:44:01.187283 140252174653440 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:44:01.187917 140252174653440 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 167.57
I0901 23:44:07.156627 140252174653440 replay_runner.py:36] Average training steps per second: 167.57
Steps executed: 283 Episode length: 171 Return: -229.27949449987165
I0901 23:44:08.577440 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.44
INFO:tensorflow:Starting iteration 1

Steps executed: 267 Episode length: 150 Return: -424.52142833016055
INFO:tensorflow:Average training steps per second: 225.15
I0901 23:44:17.378214 140252174653440 replay_runner.py:36] Average training steps per second: 225.15
I0901 23:44:17.623682 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -475.33
INFO:tensorflow:Starting iteration 2

Steps executed: 273 Episode length: 106 Return: -445.47938744730837
INFO:tensorflow:Average training steps per second: 228.90
I0901 23:44:26.265372 140252174653440 replay_runner.py:36] Average training steps per second: 228.90
I0901 23:44:26.502868 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -378.11
INFO:tensorflow:Starting iteration 3
I0901 23:44:30.700244 140252174653440 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 242.31

Steps executed: 899 Episode length: 899 Return: -272.76100190066887
I0901 23:44:37.498274 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -272.76
INFO:tensorflow:Starting iteration 4
I0901 23:44:41.638428 140252174653440 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 234.23

Steps executed: 980 Episode length: 980 Return: -289.70668937432467
I0901 23:44:47.977599 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.71
INFO:tensorflow:Starting iteration 5
I0901 23:44:52.290892 140252174653440 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 227.16

Steps executed: 795 Episode length: 795 Return: -298.08926479781667
I0901 23:44:58.425028 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -298.09
INFO:tensorflow:Starting iteration 6
I0901 23:45:02.570392 140252174653440 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 229.56

Steps executed: 507 Episode length: 507 Return: -907.85444922584837
I0901 23:45:07.642633 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -907.85
INFO:tensorflow:Starting iteration 7
I0901 23:45:11.979713 140252174653440 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 223.47

Steps executed: 587 Episode length: 587 Return: -1388.1030290513672
I0901 23:45:17.638014 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -1388.10
INFO:tensorflow:Starting iteration 8
I0901 23:45:22.042937 140252174653440 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 229.31

Steps executed: 1000 Episode length: 1000 Return: -499.79261594692525
I0901 23:45:28.799831 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -499.79
INFO:tensorflow:Starting iteration 9

Steps executed: 672 Episode length: 672 Return: -517.4273937322563525
INFO:tensorflow:Average training steps per second: 226.42
I0901 23:45:37.535341 140252174653440 replay_runner.py:36] Average training steps per second: 226.42
I0901 23:45:38.680885 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -517.43
INFO:tensorflow:Starting iteration 10
I0901 23:45:43.051374 140252174653440 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 227.31

Steps executed: 531 Episode length: 531 Return: -766.6114317394906525
I0901 23:45:48.478332 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -766.61
INFO:tensorflow:Starting iteration 11
I0901 23:45:52.780654 140252174653440 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 227.42

Steps executed: 412 Episode length: 412 Return: -2315.829657189599525
I0901 23:45:57.971507 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -2315.83
INFO:tensorflow:Starting iteration 12
I0901 23:46:02.281435 140252174653440 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 225.60

Steps executed: 1000 Episode length: 1000 Return: -147.61285909295344
I0901 23:46:09.057317 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.61
INFO:tensorflow:Starting iteration 13
I0901 23:46:13.461700 140252174653440 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 229.87

Steps executed: 1000 Episode length: 1000 Return: -80.628750070759314
I0901 23:46:21.550455 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.63
INFO:tensorflow:Starting iteration 14
I0901 23:46:25.926443 140252174653440 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 232.70

Steps executed: 1000 Episode length: 1000 Return: -143.64193600641966
I0901 23:46:33.554843 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.64
INFO:tensorflow:Starting iteration 15

Steps executed: 602 Episode length: 602 Return: 210.19738417839747966
INFO:tensorflow:Average training steps per second: 226.01
I0901 23:46:42.196303 140252174653440 replay_runner.py:36] Average training steps per second: 226.01
I0901 23:46:43.740679 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: 210.20
INFO:tensorflow:Starting iteration 16
I0901 23:46:48.135471 140252174653440 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 228.04

Steps executed: 1000 Episode length: 1000 Return: -80.468460994973266
I0901 23:46:55.042876 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.47
INFO:tensorflow:Starting iteration 17
I0901 23:46:59.231247 140252174653440 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 217.06

Steps executed: 1000 Episode length: 1000 Return: -107.90329396973945
I0901 23:47:07.380163 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.90
INFO:tensorflow:Starting iteration 18
I0901 23:47:11.632676 140252174653440 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 234.02

Steps executed: 522 Episode length: 351 Return: -39.47687935321961645
I0901 23:47:16.578714 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.91
INFO:tensorflow:Starting iteration 19
I0901 23:47:20.855145 140252174653440 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 230.45

Steps executed: 1000 Episode length: 1000 Return: -83.397716834441245
I0901 23:47:27.829975 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.40
INFO:tensorflow:Starting iteration 20

Steps executed: 141 Episode length: 141 Return: -205.0174179195148245
INFO:tensorflow:Average training steps per second: 247.62
I0901 23:47:36.136792 140252174653440 replay_runner.py:36] Average training steps per second: 247.62

Steps executed: 779 Episode length: 638 Return: -131.8742965552614245
INFO:tensorflow:Starting iteration 21
I0901 23:47:42.077957 140252174653440 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 242.77

Steps executed: 1000 Episode length: 1000 Return: -13.131154743093887
I0901 23:47:48.830060 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -13.13
INFO:tensorflow:Starting iteration 22
I0901 23:47:53.138557 140252174653440 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 230.09
I0901 23:47:57.485677 140252174653440 replay_runner.py:36] Average training steps per second: 230.09

Steps executed: 217 Episode length: 217 Return: -114.5271910201178887
INFO:tensorflow:Starting iteration 23

Steps executed: 433 Episode length: 433 Return: -610.5150553839218887
INFO:tensorflow:Average training steps per second: 222.68
I0901 23:48:06.479841 140252174653440 replay_runner.py:36] Average training steps per second: 222.68
I0901 23:48:07.436002 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -610.52
INFO:tensorflow:Starting iteration 24
I0901 23:48:11.762683 140252174653440 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 219.86

Steps executed: 1000 Episode length: 1000 Return: -53.987493188007547
I0901 23:48:20.798996 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -53.99
INFO:tensorflow:Starting iteration 25
I0901 23:48:25.105039 140252174653440 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 225.60

Steps executed: 913 Episode length: 913 Return: 90.693488738895907547
I0901 23:48:32.623937 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: 90.69
INFO:tensorflow:Starting iteration 26

Steps executed: 340 Episode length: 210 Return: -80.11437710342180847
INFO:tensorflow:Average training steps per second: 228.61
I0901 23:48:41.368867 140252174653440 replay_runner.py:36] Average training steps per second: 228.61
I0901 23:48:41.711496 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.54
INFO:tensorflow:Starting iteration 27
I0901 23:48:46.055028 140252174653440 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 220.67

Steps executed: 1000 Episode length: 1000 Return: -66.337914258556687
I0901 23:48:53.875503 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -66.34
INFO:tensorflow:Starting iteration 28

Steps executed: 475 Episode length: 475 Return: 184.17736512962878687
INFO:tensorflow:Average training steps per second: 227.50
I0901 23:49:02.614765 140252174653440 replay_runner.py:36] Average training steps per second: 227.50
I0901 23:49:03.601587 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: 184.18
INFO:tensorflow:Starting iteration 29

Steps executed: 390 Episode length: 390 Return: -201.3619002900050587
INFO:tensorflow:Average training steps per second: 234.61
I0901 23:49:12.283318 140252174653440 replay_runner.py:36] Average training steps per second: 234.61

Done fixed training!Episode length: 390 Return: -201.3619002900050587