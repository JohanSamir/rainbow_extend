Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0828 10:37:28.821249 140220309850112 run_experiment.py:549] Creating TrainRunner ...
I0828 10:37:28.831629 140220309850112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:28.831936 140220309850112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:28.832108 140220309850112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:28.832201 140220309850112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:28.832317 140220309850112 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:28.832462 140220309850112 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:37:28.832547 140220309850112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:28.832613 140220309850112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:28.832712 140220309850112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:28.832833 140220309850112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:28.832953 140220309850112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:28.833035 140220309850112 dqn_agent.py:283] 	 seed: 1630147048831563
I0828 10:37:28.836463 140220309850112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:28.836732 140220309850112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:37:28.836874 140220309850112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:28.837006 140220309850112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:28.837094 140220309850112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:28.837178 140220309850112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:28.837285 140220309850112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:28.837390 140220309850112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:28.837506 140220309850112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:28.872362 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:29.233906 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:29.247328 140220309850112 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:37:29.257266 140220309850112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:29.257555 140220309850112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:29.257709 140220309850112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:29.257833 140220309850112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:29.257983 140220309850112 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:29.258101 140220309850112 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:37:29.258246 140220309850112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:29.258367 140220309850112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:29.258490 140220309850112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:29.258614 140220309850112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:29.258725 140220309850112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:29.258830 140220309850112 dqn_agent.py:283] 	 seed: 1630147049257199
I0828 10:37:29.262275 140220309850112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:29.262505 140220309850112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:37:29.262639 140220309850112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:29.262762 140220309850112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:29.262879 140220309850112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:29.262995 140220309850112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:29.263102 140220309850112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:29.263209 140220309850112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:29.263313 140220309850112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:29.293868 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:29.362310 140220309850112 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:37:29.362605 140220309850112 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 176.54
I0828 10:37:35.027598 140220309850112 replay_runner.py:36] Average training steps per second: 176.54
I0828 10:37:36.203745 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -770.76
Steps executed: 233 Episode length: 80 Return: -738.75836117606623
INFO:tensorflow:Starting iteration 1

Steps executed: 268 Episode length: 75 Return: -691.50090499047623
INFO:tensorflow:Average training steps per second: 235.25
I0828 10:37:44.870040 140220309850112 replay_runner.py:36] Average training steps per second: 235.25
I0828 10:37:45.104327 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -617.01
INFO:tensorflow:Starting iteration 2

Steps executed: 227 Episode length: 82 Return: -492.91831244438794
INFO:tensorflow:Average training steps per second: 229.53
I0828 10:37:53.729539 140220309850112 replay_runner.py:36] Average training steps per second: 229.53
I0828 10:37:53.909683 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -468.27
INFO:tensorflow:Starting iteration 3

Steps executed: 264 Episode length: 73 Return: -559.15031617925154
INFO:tensorflow:Average training steps per second: 229.69
I0828 10:38:02.642692 140220309850112 replay_runner.py:36] Average training steps per second: 229.69
I0828 10:38:02.842006 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -460.71
INFO:tensorflow:Starting iteration 4

Steps executed: 267 Episode length: 75 Return: -553.64461670278893
INFO:tensorflow:Average training steps per second: 231.28
I0828 10:38:11.602918 140220309850112 replay_runner.py:36] Average training steps per second: 231.28
I0828 10:38:11.849174 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -631.90
INFO:tensorflow:Starting iteration 5
I0828 10:38:16.242459 140220309850112 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 226.92

Steps executed: 266 Episode length: 68 Return: -288.93463172659654
I0828 10:38:20.846063 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.16
INFO:tensorflow:Starting iteration 6

Steps executed: 261 Episode length: 70 Return: -143.64915959599375
INFO:tensorflow:Average training steps per second: 235.18
I0828 10:38:29.490015 140220309850112 replay_runner.py:36] Average training steps per second: 235.18
I0828 10:38:29.655239 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.73
INFO:tensorflow:Starting iteration 7

Steps executed: 245 Episode length: 79 Return: -365.92962651160894
INFO:tensorflow:Average training steps per second: 231.24
I0828 10:38:38.240992 140220309850112 replay_runner.py:36] Average training steps per second: 231.24
I0828 10:38:38.409645 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.96
INFO:tensorflow:Starting iteration 8

Steps executed: 221 Episode length: 68 Return: -156.99978439565774
INFO:tensorflow:Average training steps per second: 224.53
I0828 10:38:47.293060 140220309850112 replay_runner.py:36] Average training steps per second: 224.53
I0828 10:38:47.441859 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.29
INFO:tensorflow:Starting iteration 9

Steps executed: 216 Episode length: 92 Return: -313.26729703241904
INFO:tensorflow:Average training steps per second: 232.63
I0828 10:38:56.128305 140220309850112 replay_runner.py:36] Average training steps per second: 232.63
I0828 10:38:56.269171 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.13
INFO:tensorflow:Starting iteration 10

Steps executed: 224 Episode length: 89 Return: -276.18099099173633
INFO:tensorflow:Average training steps per second: 231.59
I0828 10:39:05.008118 140220309850112 replay_runner.py:36] Average training steps per second: 231.59
I0828 10:39:05.164986 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.51
INFO:tensorflow:Starting iteration 11

Steps executed: 268 Episode length: 82 Return: -86.100330247392013
INFO:tensorflow:Average training steps per second: 236.36
I0828 10:39:13.559978 140220309850112 replay_runner.py:36] Average training steps per second: 236.36
I0828 10:39:13.745417 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.12
INFO:tensorflow:Starting iteration 12

Steps executed: 207 Episode length: 56 Return: -74.327405300165852
INFO:tensorflow:Average training steps per second: 226.83
I0828 10:39:22.505224 140220309850112 replay_runner.py:36] Average training steps per second: 226.83
I0828 10:39:22.650124 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.13
INFO:tensorflow:Starting iteration 13

Steps executed: 254 Episode length: 122 Return: -422.0283634951983
INFO:tensorflow:Average training steps per second: 237.07
I0828 10:39:31.122079 140220309850112 replay_runner.py:36] Average training steps per second: 237.07
I0828 10:39:31.349455 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -525.81
INFO:tensorflow:Starting iteration 14

Steps executed: 288 Episode length: 91 Return: -384.646396137358645
INFO:tensorflow:Average training steps per second: 229.61
I0828 10:39:39.987217 140220309850112 replay_runner.py:36] Average training steps per second: 229.61
I0828 10:39:40.252722 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -395.29
INFO:tensorflow:Starting iteration 15
I0828 10:39:44.582330 140220309850112 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 234.28
I0828 10:39:48.851473 140220309850112 replay_runner.py:36] Average training steps per second: 234.28

Steps executed: 210 Episode length: 65 Return: -484.833276593454725
INFO:tensorflow:Starting iteration 16

Steps executed: 239 Episode length: 78 Return: -420.871671985701565
INFO:tensorflow:Average training steps per second: 231.28
I0828 10:39:57.583670 140220309850112 replay_runner.py:36] Average training steps per second: 231.28
I0828 10:39:57.802541 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.48
INFO:tensorflow:Starting iteration 17

Steps executed: 229 Episode length: 88 Return: -178.021654646808145
INFO:tensorflow:Average training steps per second: 230.55
I0828 10:40:06.486253 140220309850112 replay_runner.py:36] Average training steps per second: 230.55
I0828 10:40:06.694498 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.72
INFO:tensorflow:Starting iteration 18

Steps executed: 226 Episode length: 59 Return: -398.701131437044445
INFO:tensorflow:Average training steps per second: 232.62
I0828 10:40:15.413928 140220309850112 replay_runner.py:36] Average training steps per second: 232.62
I0828 10:40:15.602922 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.10
INFO:tensorflow:Starting iteration 19

Steps executed: 322 Episode length: 175 Return: -451.69626762413635
INFO:tensorflow:Average training steps per second: 226.19
I0828 10:40:24.271800 140220309850112 replay_runner.py:36] Average training steps per second: 226.19
I0828 10:40:24.566654 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.30
INFO:tensorflow:Starting iteration 20
I0828 10:40:28.751859 140220309850112 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 234.86

Steps executed: 518 Episode length: 331 Return: -305.85844846120415
I0828 10:40:33.639984 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -321.69
INFO:tensorflow:Starting iteration 21

Steps executed: 238 Episode length: 85 Return: -517.581420365796565
INFO:tensorflow:Average training steps per second: 229.83
I0828 10:40:42.389498 140220309850112 replay_runner.py:36] Average training steps per second: 229.83
I0828 10:40:42.605593 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -391.87
INFO:tensorflow:Starting iteration 22

Steps executed: 252 Episode length: 92 Return: -286.960869190593945
INFO:tensorflow:Average training steps per second: 224.17
I0828 10:40:51.506189 140220309850112 replay_runner.py:36] Average training steps per second: 224.17
I0828 10:40:51.739649 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.20
INFO:tensorflow:Starting iteration 23

Steps executed: 238 Episode length: 79 Return: -470.958830515154035
INFO:tensorflow:Average training steps per second: 230.36
I0828 10:41:00.484589 140220309850112 replay_runner.py:36] Average training steps per second: 230.36
I0828 10:41:00.710292 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -426.95
INFO:tensorflow:Starting iteration 24

Steps executed: 222 Episode length: 76 Return: -455.987911543061335
INFO:tensorflow:Average training steps per second: 227.29
I0828 10:41:09.427801 140220309850112 replay_runner.py:36] Average training steps per second: 227.29
I0828 10:41:09.625550 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -573.34
INFO:tensorflow:Starting iteration 25

Steps executed: 243 Episode length: 135 Return: -688.56054719513845
INFO:tensorflow:Average training steps per second: 225.42
I0828 10:41:18.346739 140220309850112 replay_runner.py:36] Average training steps per second: 225.42
I0828 10:41:18.570837 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -687.89
INFO:tensorflow:Starting iteration 26

Steps executed: 209 Episode length: 64 Return: -576.427145021738245
INFO:tensorflow:Average training steps per second: 223.93
I0828 10:41:27.453869 140220309850112 replay_runner.py:36] Average training steps per second: 223.93
I0828 10:41:27.640050 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -543.32
INFO:tensorflow:Starting iteration 27

Steps executed: 262 Episode length: 116 Return: -132.02741635750846
INFO:tensorflow:Average training steps per second: 224.07
I0828 10:41:36.471257 140220309850112 replay_runner.py:36] Average training steps per second: 224.07
I0828 10:41:36.692700 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.82
INFO:tensorflow:Starting iteration 28

Steps executed: 233 Episode length: 147 Return: -533.42483168311266
INFO:tensorflow:Average training steps per second: 223.90
I0828 10:41:45.559304 140220309850112 replay_runner.py:36] Average training steps per second: 223.90
I0828 10:41:45.769563 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -514.86
INFO:tensorflow:Starting iteration 29

Steps executed: 257 Episode length: 63 Return: -374.059048173540866
INFO:tensorflow:Average training steps per second: 227.31
I0828 10:41:54.500534 140220309850112 replay_runner.py:36] Average training steps per second: 227.31

Done fixed training!Episode length: 63 Return: -374.059048173540866