WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0828 01:10:58.151401 139918175746048 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0828 01:10:58.701609 139918175746048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 01:10:58.702790 139918175746048 dqn_agent.py:272] 	 gamma: 0.990000
I0828 01:10:58.702882 139918175746048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 01:10:58.702958 139918175746048 dqn_agent.py:274] 	 min_replay_history: 500
I0828 01:10:58.703034 139918175746048 dqn_agent.py:275] 	 update_period: 4
I0828 01:10:58.703112 139918175746048 dqn_agent.py:276] 	 target_update_period: 300
I0828 01:10:58.703190 139918175746048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 01:10:58.703308 139918175746048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 01:10:58.703483 139918175746048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 01:10:58.703577 139918175746048 dqn_agent.py:280] 	 optimizer: adam
I0828 01:10:58.703649 139918175746048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 01:10:58.703713 139918175746048 dqn_agent.py:283] 	 seed: 1630113058701544
I0828 01:10:58.705304 139918175746048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 01:10:58.705456 139918175746048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 01:10:58.705580 139918175746048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 01:10:58.705686 139918175746048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 01:10:58.705749 139918175746048 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 01:10:58.705802 139918175746048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 01:10:58.705862 139918175746048 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 01:10:58.705939 139918175746048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 01:10:58.705996 139918175746048 circular_replay_buffer.py:163] 	 gamma: 0.990000
Training agent 2, please be patient, may be a while...
Steps executed: 488 Episode length: 55 Return: -107.64601616670018
I0828 01:11:00.163562 139918175746048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 01:11:00.607699 139918175746048 run_experiment.py:516] Beginning training...
I0828 01:11:00.607907 139918175746048 run_experiment.py:447] Starting iteration 0
W0828 01:11:01.276893 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 01:11:01.336737 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 01:11:01.364186 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 01:11:01.412646 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 01:11:01.449087 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 691 Episode length: 124 Return: -736.3064455350651
W0828 01:11:02.800702 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 972 Episode length: 163 Return: -591.75951831415982
W0828 01:11:03.909734 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 1509 Episode length: 537 Return: -114.03872276102277
W0828 01:11:07.209055 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 01:11:07.726547 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 01:11:08.353486 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 2031 Episode length: 239 Return: -69.716643371525467


Steps executed: 2948 Episode length: 228 Return: -546.86813031836691
W0828 01:11:12.370420 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 3460 Episode length: 291 Return: -116.18144109421291
W0828 01:11:14.244252 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 01:11:15.491793 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 3634 Episode length: 174 Return: -253.66258314519152
W0828 01:11:18.989329 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:11:18.989960 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -355.74


















































































Steps executed: 125243 Episode length: 581 Return: -521.674299267405357
I0828 01:14:06.326251 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: -466.21
I0828 01:14:06.587195 139918175746048 run_experiment.py:447] Starting iteration 1

Steps executed: 1000 Episode length: 1000 Return: -147.5960990435778857

Steps executed: 2000 Episode length: 1000 Return: -172.7301994039316657

Steps executed: 3000 Episode length: 1000 Return: -114.1086882177064657
W0828 01:14:27.416139 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:14:27.416526 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -141.04





































































































Steps executed: 125570 Episode length: 812 Return: -159.395541483115044
I0828 01:17:48.945163 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: -194.14

Steps executed: 1000 Episode length: 1000 Return: -124.7206710688770444
W0828 01:17:55.087471 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 1057 Episode length: 57 Return: -417.813281132238870444


Steps executed: 2893 Episode length: 1000 Return: -114.6232811225457344
W0828 01:18:04.754299 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 3893 Episode length: 1000 Return: -95.75668788649037344
W0828 01:18:16.100703 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:18:16.101076 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -171.64









































































































Steps executed: 125620 Episode length: 1000 Return: -75.443030582484783
I0828 01:21:55.312532 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.80

Steps executed: 1000 Episode length: 1000 Return: -73.68630343997036783
W0828 01:22:01.354935 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 2000 Episode length: 1000 Return: -60.65909070107690683

Steps executed: 3000 Episode length: 1000 Return: -55.19714053493661583

Steps executed: 3702 Episode length: 261 Return: -417.69416166456366583
W0828 01:22:15.718972 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 01:22:18.104093 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:22:18.104628 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -166.14












































































































Steps executed: 125822 Episode length: 914 Return: -258.426692839341437
I0828 01:26:04.464487 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.86
I0828 01:26:05.389244 139918175746048 run_experiment.py:447] Starting iteration 4


Steps executed: 2000 Episode length: 1000 Return: -94.59576018390638437
W0828 01:26:15.872535 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.


Steps executed: 4000 Episode length: 1000 Return: -34.47506355510291437
W0828 01:26:26.388405 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:26:26.388993 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -45.32












































































































Steps executed: 124150 Episode length: 1000 Return: -91.494281485789445

Steps executed: 125150 Episode length: 1000 Return: -86.080702515598445
I0828 01:30:16.915996 139918175746048 run_experiment.py:447] Starting iteration 5


Steps executed: 1561 Episode length: 561 Return: -75.234650509079698545
W0828 01:30:24.232761 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.


Steps executed: 3561 Episode length: 1000 Return: -75.13846051788748545

Steps executed: 915 Episode length: 447 Return: -404.525122267829155245
W0828 01:30:40.520714 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:30:40.521096 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -80.07































































































Steps executed: 125233 Episode length: 583 Return: -196.753213752968755
I0828 01:33:59.100806 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.61

Steps executed: 689 Episode length: 689 Return: -219.084193552967968755

Steps executed: 1689 Episode length: 1000 Return: -116.0360344894522755

Steps executed: 2689 Episode length: 1000 Return: -71.14094075573372755

Steps executed: 3689 Episode length: 1000 Return: -45.19183527608097755

Steps executed: 4689 Episode length: 1000 Return: -246.2199303567446455
W0828 01:34:24.436654 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:34:24.436957 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -139.53






































































































Steps executed: 124200 Episode length: 1000 Return: -74.712402493674746

Steps executed: 125200 Episode length: 1000 Return: -98.409645084970046
I0828 01:38:05.632607 139918175746048 run_experiment.py:447] Starting iteration 7

Steps executed: 1000 Episode length: 1000 Return: -113.5171693461527646

Steps executed: 2000 Episode length: 1000 Return: -31.81497615350939646

Steps executed: 3000 Episode length: 1000 Return: -64.50457809868799646

Steps executed: 3881 Episode length: 881 Return: -351.38327434278096646
W0828 01:38:29.555816 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:38:29.556314 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -231.07






























































































Steps executed: 123989 Episode length: 1000 Return: -32.392739103641274

Steps executed: 125674 Episode length: 685 Return: -99.2936838219184574
I0828 01:41:40.942222 139918175746048 run_experiment.py:447] Starting iteration 8

Steps executed: 357 Episode length: 357 Return: -345.681616725155664574
W0828 01:41:43.900484 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 868 Episode length: 157 Return: -76.3211876390761764574

Steps executed: 1196 Episode length: 328 Return: -648.76571691050914574
W0828 01:41:48.811965 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 1956 Episode length: 148 Return: -90.749073159854233574

Steps executed: 2543 Episode length: 235 Return: -47.924236708706533574

Steps executed: 2996 Episode length: 453 Return: -30.208000367751552574
W0828 01:41:53.782354 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 3217 Episode length: 221 Return: -256.82109223491522574
W0828 01:41:58.188613 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 01:41:58.838403 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:41:58.838765 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -201.27















































Steps executed: 123855 Episode length: 168 Return: -77.4416407648753954

Steps executed: 125200 Episode length: 288 Return: -63.6247339804588144
I0828 01:43:35.178959 139918175746048 run_experiment.py:447] Starting iteration 9

Steps executed: 316 Episode length: 316 Return: -72.7337656154254588144

Steps executed: 881 Episode length: 565 Return: 99.63320966301401588144

Steps executed: 1648 Episode length: 767 Return: -197.31560923420288144

Steps executed: 2046 Episode length: 398 Return: -292.33599665265158144

Steps executed: 2709 Episode length: 162 Return: -114.62228572154375144
W0828 01:43:47.713663 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.


Steps executed: 4014 Episode length: 1000 Return: -78.02666269827104144
W0828 01:43:53.507325 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:43:53.507670 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -98.67





































































































Steps executed: 125914 Episode length: 1000 Return: -50.367727629740024
I0828 01:47:16.411327 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: -64.54
I0828 01:47:18.676745 139918175746048 run_experiment.py:447] Starting iteration 10

Steps executed: 926 Episode length: 926 Return: -534.221954913839740024


Steps executed: 2926 Episode length: 1000 Return: -58.58116779411352024
W0828 01:47:34.510526 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.


Steps executed: 4810 Episode length: 884 Return: -168.39726591334352024
W0828 01:47:44.144792 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:47:44.145151 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -184.43










































































































Steps executed: 125282 Episode length: 1000 Return: -20.245293439312484
I0828 01:51:23.464790 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: -59.88

Steps executed: 1000 Episode length: 1000 Return: -93.48176459239568484

Steps executed: 2000 Episode length: 1000 Return: -41.53811199833148484
W0828 01:51:35.370796 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.


Steps executed: 4000 Episode length: 1000 Return: -69.78521792951934484
W0828 01:51:44.706146 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:51:44.706750 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -58.97










































































































Steps executed: 125000 Episode length: 1000 Return: -75.519098321804186
I0828 01:55:29.125153 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: -58.97

Steps executed: 1000 Episode length: 1000 Return: -54.15026168814592586

Steps executed: 2000 Episode length: 1000 Return: -93.37088282698728586

Steps executed: 3000 Episode length: 1000 Return: -99.55914165002307586
W0828 01:55:46.078694 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 01:55:50.572193 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:55:50.572823 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -83.82











































































































Steps executed: 125000 Episode length: 1000 Return: -7.2104043359882924
I0828 01:59:38.252614 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: -47.01

Steps executed: 1000 Episode length: 1000 Return: -53.54965307775923924

Steps executed: 2000 Episode length: 1000 Return: -76.58874512505423924

Steps executed: 3000 Episode length: 1000 Return: -67.86988295706678924

Steps executed: 4000 Episode length: 1000 Return: -104.8439437421152924
W0828 02:00:00.958698 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:00:00.959258 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -75.71













































































































Steps executed: 124000 Episode length: 1000 Return: -30.017752173244622

Steps executed: 125000 Episode length: 1000 Return: -41.821672950495432
I0828 02:03:46.963892 139918175746048 run_experiment.py:447] Starting iteration 14

Steps executed: 1000 Episode length: 1000 Return: -77.69486769131065432

Steps executed: 2000 Episode length: 1000 Return: -58.44234942876677532

Steps executed: 3000 Episode length: 1000 Return: -68.37854927794649532
W0828 02:04:05.783828 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:04:05.784210 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -61.13





































































































Steps executed: 124970 Episode length: 1000 Return: -3.8797893381743534

Steps executed: 125970 Episode length: 1000 Return: -3.6820594305665866

Steps executed: 1000 Episode length: 1000 Return: -3.517575706376517666
W0828 02:07:34.207062 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 1168 Episode length: 168 Return: -92.736551235287527666

Steps executed: 2168 Episode length: 1000 Return: -92.00667610481274666


Steps executed: 4168 Episode length: 1000 Return: -80.25791600414044666
W0828 02:07:48.258199 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:07:48.258721 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -70.50































































































Steps executed: 124577 Episode length: 1000 Return: -94.850333218705125

Steps executed: 125577 Episode length: 1000 Return: -84.947610616156015

Steps executed: 486 Episode length: 486 Return: -34.2614867794727766015
W0828 02:11:11.241322 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 1040 Episode length: 371 Return: 12.5607527667096266015
W0828 02:11:13.349410 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 2040 Episode length: 1000 Return: -59.19858826120102415

Steps executed: 2531 Episode length: 491 Return: 224.029093201596772415

Steps executed: 3531 Episode length: 1000 Return: -29.13327092845607415

Steps executed: 3764 Episode length: 233 Return: 9.00036576387064707415
W0828 02:11:30.696141 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:11:30.696495 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: 6.20





































































































Steps executed: 124160 Episode length: 1000 Return: -49.083713059827076

Steps executed: 125160 Episode length: 1000 Return: -122.20429580071625

Steps executed: 959 Episode length: 959 Return: -1162.56816282968071625
W0828 02:15:01.833044 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 02:15:06.585837 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 2284 Episode length: 111 Return: -518.89146642900645225
W0828 02:15:07.358057 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 02:15:07.742727 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 02:15:08.112411 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 2893 Episode length: 77 Return: -619.943218501665865225
W0828 02:15:09.689454 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 02:15:09.974988 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 3309 Episode length: 241 Return: -40.060422939961526225
W0828 02:15:11.509068 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 3994 Episode length: 99 Return: 25.04458304861793736225
W0828 02:15:13.257704 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 02:15:13.652386 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 314 Episode length: 314 Return: -34.8872542975014736225
W0828 02:15:15.643194 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:15:15.643515 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -250.47

























































Steps executed: 125230 Episode length: 246 Return: 4.582670564809078627
I0828 02:17:09.597448 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: -8.72
I0828 02:17:12.224206 139918175746048 run_experiment.py:447] Starting iteration 18

Steps executed: 299 Episode length: 299 Return: -0.93947273821822828627
W0828 02:17:14.934424 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 779 Episode length: 78 Return: -110.5465543293227628627

Steps executed: 1823 Episode length: 298 Return: -26.458875264836635627
W0828 02:17:19.659722 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 2823 Episode length: 1000 Return: -275.0149831370648627

Steps executed: 3292 Episode length: 469 Return: -68.701160168879458627


Steps executed: 4870 Episode length: 1000 Return: -74.09375038850277627
W0828 02:17:33.878132 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:17:33.878508 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -170.36







































































































Steps executed: 125270 Episode length: 1000 Return: -89.175024124913358
I0828 02:21:07.969766 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: -60.36

Steps executed: 1000 Episode length: 1000 Return: -86.98167189135143358

Steps executed: 1574 Episode length: 574 Return: -249.34884908248785358
W0828 02:21:17.855989 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.


Steps executed: 2656 Episode length: 677 Return: -65.090305028833685358

Steps executed: 3161 Episode length: 505 Return: 189.984045580780825358

Steps executed: 916 Episode length: 263 Return: 4.266068842548478678358
W0828 02:21:28.884159 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:21:28.884642 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -57.31





































Steps executed: 123635 Episode length: 234 Return: -34.9258809995541958

Steps executed: 125082 Episode length: 160 Return: -0.07010699424203892
I0828 02:22:46.550414 139918175746048 run_experiment.py:447] Starting iteration 20

Steps executed: 492 Episode length: 265 Return: 23.38755697555410533892
W0828 02:22:48.402411 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 1263 Episode length: 264 Return: 21.3195304918328833892
W0828 02:22:50.293959 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 1669 Episode length: 180 Return: -46.372456332523943892
W0828 02:22:52.102138 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 02:22:52.765984 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 02:22:53.332292 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 2028 Episode length: 203 Return: -15.401422420220754892
W0828 02:22:55.536383 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 2758 Episode length: 188 Return: -58.891776767580955892

Steps executed: 3758 Episode length: 1000 Return: 44.604617653285185892
W0828 02:23:01.265328 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 02:23:05.870534 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:23:05.870836 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: 21.17
































































































Steps executed: 125212 Episode length: 1000 Return: 60.4868384775822744
I0828 02:26:22.953479 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: -20.14

Steps executed: 841 Episode length: 841 Return: 144.6143085448666822744

Steps executed: 1841 Episode length: 1000 Return: -82.24061684905178744

Steps executed: 2670 Episode length: 829 Return: 127.688836025891828744

Steps executed: 3670 Episode length: 1000 Return: -44.60790172705338744

Steps executed: 372 Episode length: 372 Return: 213.6607293812208868744
W0828 02:26:43.606586 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:26:43.606921 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: 75.15



































































































Steps executed: 124846 Episode length: 265 Return: -28.4116594807798751

Steps executed: 125846 Episode length: 1000 Return: -85.304176570071091
I0828 02:30:09.074072 139918175746048 run_experiment.py:447] Starting iteration 22

Steps executed: 1000 Episode length: 1000 Return: -12.43520223679893591

Steps executed: 2000 Episode length: 1000 Return: 21.681325353169246591
W0828 02:30:23.117846 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 3223 Episode length: 223 Return: 27.8019739076380861591

Steps executed: 3692 Episode length: 469 Return: 188.211377344846621591
W0828 02:30:27.138050 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:30:27.138405 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -27.27


































































































Steps executed: 124745 Episode length: 1000 Return: -0.4632918953622063

Steps executed: 125745 Episode length: 1000 Return: -53.998333425761416
I0828 02:33:51.099917 139918175746048 run_experiment.py:447] Starting iteration 23

Steps executed: 121 Episode length: 121 Return: 21.38757193017312461416

Steps executed: 1121 Episode length: 1000 Return: -90.92238637280325416
W0828 02:34:01.613651 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 2379 Episode length: 258 Return: 27.7491441045189053816
W0828 02:34:04.019155 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 3024 Episode length: 279 Return: 243.812687117467143816

Steps executed: 3361 Episode length: 337 Return: 270.622680043899663816
W0828 02:34:10.771641 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:34:10.771996 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: 69.38

























































































Steps executed: 123575 Episode length: 1000 Return: -94.328543431104762

Steps executed: 125174 Episode length: 296 Return: 258.8544314344383252
I0828 02:37:11.688210 139918175746048 run_experiment.py:447] Starting iteration 24

Steps executed: 567 Episode length: 567 Return: 153.9657839456358283252

Steps executed: 1567 Episode length: 1000 Return: -32.08706696577536252


Steps executed: 3111 Episode length: 1000 Return: -41.27945561081937252
W0828 02:37:25.601337 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 3570 Episode length: 459 Return: 169.968809106051827252
W0828 02:37:32.168924 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:37:32.169275 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -20.25
























































































Steps executed: 125130 Episode length: 340 Return: 134.1145397283408714
I0828 02:40:27.806949 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: 17.07
I0828 02:40:30.458559 139918175746048 run_experiment.py:447] Starting iteration 25

Steps executed: 1000 Episode length: 1000 Return: -7.147104269072401714
W0828 02:40:36.791419 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.


Steps executed: 2091 Episode length: 560 Return: 156.125865287361801714

Steps executed: 2742 Episode length: 651 Return: 134.116467826689251714
W0828 02:40:42.600719 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 4145 Episode length: 403 Return: 183.543073077500230614
W0828 02:40:48.693912 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:40:48.694230 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: 71.85


























































Steps executed: 124087 Episode length: 532 Return: 148.1253672567099274

Steps executed: 125143 Episode length: 352 Return: 200.4909536449456883
I0828 02:42:48.318342 139918175746048 run_experiment.py:447] Starting iteration 26

Steps executed: 963 Episode length: 252 Return: 30.41485440621866656883

Steps executed: 1493 Episode length: 530 Return: 220.021752341773076883

Steps executed: 2040 Episode length: 547 Return: 186.325845422014626883

Steps executed: 2474 Episode length: 434 Return: -18.692817963620655883

Steps executed: 3474 Episode length: 1000 Return: -19.08795591584076883
W0828 02:43:02.537237 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 4008 Episode length: 291 Return: 268.857376588279356883
W0828 02:43:04.524819 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:43:04.525108 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: 139.00




































































Steps executed: 124800 Episode length: 396 Return: -302.874308041847934

Steps executed: 125133 Episode length: 333 Return: -11.3934882649507614

Steps executed: 261 Episode length: 261 Return: -34.5626033520705707614
W0828 02:45:24.812163 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 978 Episode length: 717 Return: 200.9522676443293707614

Steps executed: 1630 Episode length: 652 Return: 191.143967302251107614

Steps executed: 1924 Episode length: 294 Return: -28.348411683642013614

Steps executed: 2586 Episode length: 662 Return: 237.756966006290273614

Steps executed: 3264 Episode length: 444 Return: 237.236106973562853614
W0828 02:45:36.992908 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 02:45:41.364430 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:45:41.364792 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: 101.69
































































































Steps executed: 125981 Episode length: 1000 Return: 35.4911522632264887
I0828 02:48:55.204143 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: 41.90

Steps executed: 405 Episode length: 405 Return: 229.3289206115929264887
W0828 02:48:59.465630 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 1021 Episode length: 334 Return: 195.668871393149364887

Steps executed: 1521 Episode length: 132 Return: -50.701086196130454887
W0828 02:49:03.257124 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 2076 Episode length: 226 Return: 31.2063529995118364887
W0828 02:49:04.969287 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 02:49:05.783950 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.


Steps executed: 4076 Episode length: 1000 Return: -23.85827328779963487
W0828 02:49:14.885581 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:49:14.886091 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: 86.81






































































































Steps executed: 125574 Episode length: 1000 Return: 29.5235063236733672
I0828 02:52:43.112292 139918175746048 run_experiment.py:428] Average undiscounted return per evaluation episode: 8.92

Steps executed: 645 Episode length: 645 Return: 169.8795175544842733672

Steps executed: 1949 Episode length: 304 Return: 292.083471637344583672
W0828 02:52:53.577422 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 2949 Episode length: 1000 Return: -129.5854574177781272

Steps executed: 4194 Episode length: 245 Return: -333.75653740915639272
W0828 02:53:03.727271 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 02:53:04.616067 139918175746048 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 02:53:04.616371 139918175746048 run_experiment.py:406] Average undiscounted return per training episode: -11.13






























































































Steps executed: 125437 Episode length: 1000 Return: 4.16106459354755936

Done training!: 125437 Episode length: 1000 Return: 4.16106459354755936