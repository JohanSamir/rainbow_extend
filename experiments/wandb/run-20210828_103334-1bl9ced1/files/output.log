Loaded trained dqn in cartpole
Training fixed agent 3, please be patient, may be a while...
I0828 10:33:40.996777 139788988807168 run_experiment.py:549] Creating TrainRunner ...
I0828 10:33:41.004770 139788988807168 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:33:41.005005 139788988807168 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:33:41.005240 139788988807168 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:33:41.005339 139788988807168 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:33:41.005421 139788988807168 dqn_agent.py:275] 	 update_period: 4
I0828 10:33:41.005703 139788988807168 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:33:41.005929 139788988807168 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:33:41.006211 139788988807168 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:33:41.006367 139788988807168 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:33:41.006579 139788988807168 dqn_agent.py:280] 	 optimizer: adam
I0828 10:33:41.006798 139788988807168 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:33:41.006971 139788988807168 dqn_agent.py:283] 	 seed: 1630146821004705
I0828 10:33:41.009747 139788988807168 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:33:41.009880 139788988807168 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0828 10:33:41.009963 139788988807168 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:33:41.010031 139788988807168 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:33:41.010092 139788988807168 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:33:41.010174 139788988807168 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:33:41.010263 139788988807168 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:33:41.010363 139788988807168 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:33:41.010448 139788988807168 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:33:41.052417 139788988807168 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:33:41.560036 139788988807168 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:33:41.574160 139788988807168 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:33:41.584282 139788988807168 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:33:41.584460 139788988807168 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:33:41.584538 139788988807168 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:33:41.584600 139788988807168 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:33:41.584806 139788988807168 dqn_agent.py:275] 	 update_period: 4
I0828 10:33:41.584886 139788988807168 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:33:41.584948 139788988807168 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:33:41.585029 139788988807168 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:33:41.585113 139788988807168 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:33:41.585195 139788988807168 dqn_agent.py:280] 	 optimizer: adam
I0828 10:33:41.585272 139788988807168 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:33:41.585335 139788988807168 dqn_agent.py:283] 	 seed: 1630146821584233
I0828 10:33:41.587421 139788988807168 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:33:41.587545 139788988807168 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0828 10:33:41.587618 139788988807168 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:33:41.587708 139788988807168 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:33:41.587768 139788988807168 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:33:41.587822 139788988807168 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:33:41.587911 139788988807168 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:33:41.587973 139788988807168 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:33:41.588055 139788988807168 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:33:41.623527 139788988807168 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:33:41.646347 139788988807168 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:33:41.646618 139788988807168 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 146.07
I0828 10:33:48.492993 139788988807168 replay_runner.py:36] Average training steps per second: 146.07
Steps executed: 201 Episode length: 10 Return: 10.0
I0828 10:33:49.710427 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 10.05
INFO:tensorflow:Starting iteration 1
I0828 10:33:49.893724 139788988807168 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 197.52
I0828 10:33:54.957100 139788988807168 replay_runner.py:36] Average training steps per second: 197.52
I0828 10:33:55.091382 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 2

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 199.79
I0828 10:34:00.285108 139788988807168 replay_runner.py:36] Average training steps per second: 199.79
I0828 10:34:00.398789 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 3

Steps executed: 215 Episode length: 109 Return: 109.0
INFO:tensorflow:Average training steps per second: 202.38
I0828 10:34:05.515577 139788988807168 replay_runner.py:36] Average training steps per second: 202.38
I0828 10:34:05.647312 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 107.50
INFO:tensorflow:Starting iteration 4
I0828 10:34:05.827906 139788988807168 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 204.81
I0828 10:34:10.710901 139788988807168 replay_runner.py:36] Average training steps per second: 204.81

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Starting iteration 5
I0828 10:34:11.057005 139788988807168 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 195.76
I0828 10:34:16.166062 139788988807168 replay_runner.py:36] Average training steps per second: 195.76
I0828 10:34:16.289762 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 6

Steps executed: 215 Episode length: 105 Return: 105.0
INFO:tensorflow:Average training steps per second: 202.43
I0828 10:34:21.424117 139788988807168 replay_runner.py:36] Average training steps per second: 202.43
I0828 10:34:21.568291 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 107.50
INFO:tensorflow:Starting iteration 7
I0828 10:34:21.765081 139788988807168 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 195.73
I0828 10:34:26.874516 139788988807168 replay_runner.py:36] Average training steps per second: 195.73

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Starting iteration 8

Steps executed: 205 Episode length: 102 Return: 102.0
INFO:tensorflow:Average training steps per second: 190.13
I0828 10:34:32.446631 139788988807168 replay_runner.py:36] Average training steps per second: 190.13
I0828 10:34:32.598626 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 102.50
INFO:tensorflow:Starting iteration 9

Steps executed: 287 Episode length: 98 Return: 98.0.0
INFO:tensorflow:Average training steps per second: 202.13
I0828 10:34:37.747104 139788988807168 replay_runner.py:36] Average training steps per second: 202.13
I0828 10:34:37.938946 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 95.67
INFO:tensorflow:Starting iteration 10

Steps executed: 252 Episode length: 130 Return: 130.0
INFO:tensorflow:Average training steps per second: 188.40
I0828 10:34:43.438768 139788988807168 replay_runner.py:36] Average training steps per second: 188.40
I0828 10:34:43.605546 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 126.00
INFO:tensorflow:Starting iteration 11

Steps executed: 386 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 197.00
I0828 10:34:48.868661 139788988807168 replay_runner.py:36] Average training steps per second: 197.00
I0828 10:34:49.137610 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 193.00
INFO:tensorflow:Starting iteration 12

Steps executed: 241 Episode length: 124 Return: 124.0
INFO:tensorflow:Average training steps per second: 194.98
I0828 10:34:54.464057 139788988807168 replay_runner.py:36] Average training steps per second: 194.98
I0828 10:34:54.615629 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 120.50
INFO:tensorflow:Starting iteration 13

Steps executed: 207 Episode length: 108 Return: 108.0
INFO:tensorflow:Average training steps per second: 189.23
I0828 10:35:00.084222 139788988807168 replay_runner.py:36] Average training steps per second: 189.23
I0828 10:35:00.243483 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 103.50
INFO:tensorflow:Starting iteration 14

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 198.30
I0828 10:35:05.489227 139788988807168 replay_runner.py:36] Average training steps per second: 198.30
I0828 10:35:05.627241 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 15
I0828 10:35:05.827821 139788988807168 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 185.59
I0828 10:35:11.216782 139788988807168 replay_runner.py:36] Average training steps per second: 185.59
I0828 10:35:11.355984 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 16

Steps executed: 115 Episode length: 115 Return: 115.0
INFO:tensorflow:Average training steps per second: 193.68
I0828 10:35:16.709793 139788988807168 replay_runner.py:36] Average training steps per second: 193.68

Steps executed: 233 Episode length: 118 Return: 118.0
INFO:tensorflow:Starting iteration 17

Steps executed: 251 Episode length: 128 Return: 128.0
INFO:tensorflow:Average training steps per second: 194.15
I0828 10:35:22.227549 139788988807168 replay_runner.py:36] Average training steps per second: 194.15
I0828 10:35:22.392501 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 125.50
INFO:tensorflow:Starting iteration 18

Steps executed: 337 Episode length: 164 Return: 164.0
INFO:tensorflow:Average training steps per second: 190.73
I0828 10:35:27.819231 139788988807168 replay_runner.py:36] Average training steps per second: 190.73
I0828 10:35:28.071119 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 168.50
INFO:tensorflow:Starting iteration 19

Steps executed: 220 Episode length: 107 Return: 107.0
INFO:tensorflow:Average training steps per second: 197.18
I0828 10:35:33.367103 139788988807168 replay_runner.py:36] Average training steps per second: 197.18
I0828 10:35:33.520210 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 110.00
INFO:tensorflow:Starting iteration 20
I0828 10:35:33.699823 139788988807168 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 188.13
I0828 10:35:39.015695 139788988807168 replay_runner.py:36] Average training steps per second: 188.13

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Starting iteration 21
I0828 10:35:39.361418 139788988807168 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 187.94
I0828 10:35:44.682914 139788988807168 replay_runner.py:36] Average training steps per second: 187.94
I0828 10:35:44.832982 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 22

Steps executed: 300 Episode length: 150 Return: 150.0
INFO:tensorflow:Average training steps per second: 194.24
I0828 10:35:50.187040 139788988807168 replay_runner.py:36] Average training steps per second: 194.24
I0828 10:35:50.385419 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 150.00
INFO:tensorflow:Starting iteration 23

Steps executed: 381 Episode length: 190 Return: 190.0
INFO:tensorflow:Average training steps per second: 189.77
I0828 10:35:55.849059 139788988807168 replay_runner.py:36] Average training steps per second: 189.77
I0828 10:35:56.105479 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 190.50
INFO:tensorflow:Starting iteration 24
I0828 10:35:56.371154 139788988807168 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 198.60

Steps executed: 200 Episode length: 200 Return: 200.0
I0828 10:36:01.545640 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 25
I0828 10:36:01.739981 139788988807168 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 192.68
I0828 10:36:06.930451 139788988807168 replay_runner.py:36] Average training steps per second: 192.68
I0828 10:36:07.057929 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26

Steps executed: 397 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 195.45
I0828 10:36:12.360105 139788988807168 replay_runner.py:36] Average training steps per second: 195.45
I0828 10:36:12.633783 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 198.50
INFO:tensorflow:Starting iteration 27

Steps executed: 251 Episode length: 127 Return: 127.0
INFO:tensorflow:Average training steps per second: 202.86
I0828 10:36:17.755933 139788988807168 replay_runner.py:36] Average training steps per second: 202.86
I0828 10:36:17.915290 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 125.50
INFO:tensorflow:Starting iteration 28

Steps executed: 219 Episode length: 104 Return: 104.0
INFO:tensorflow:Average training steps per second: 193.47
I0828 10:36:23.265699 139788988807168 replay_runner.py:36] Average training steps per second: 193.47
I0828 10:36:23.418476 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 109.50
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 117 Return: 117.0
INFO:tensorflow:Average training steps per second: 204.93
I0828 10:36:28.478951 139788988807168 replay_runner.py:36] Average training steps per second: 204.93
I0828 10:36:28.630007 139788988807168 run_experiment.py:428] Average undiscounted return per evaluation episode: 116.00