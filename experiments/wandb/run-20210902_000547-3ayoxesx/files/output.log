Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0902 00:05:53.941909 139929824643072 run_experiment.py:549] Creating TrainRunner ...
I0902 00:05:53.952536 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:05:53.952805 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:05:53.952992 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:05:53.953233 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:05:53.953368 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0902 00:05:53.953567 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:05:53.953700 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:05:53.953810 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:05:53.953953 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:05:53.954080 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0902 00:05:53.954407 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:05:53.954604 139929824643072 dqn_agent.py:283] 	 seed: 1630541153952471
I0902 00:05:53.958330 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:05:53.958571 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:05:53.958719 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:05:53.958843 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:05:53.958960 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:05:53.959060 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:05:53.959153 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:05:53.959256 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:05:53.959349 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:05:53.998448 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:54.333086 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:54.345152 139929824643072 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:05:54.353670 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:05:54.353918 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:05:54.354045 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:05:54.354193 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:05:54.354294 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0902 00:05:54.354400 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:05:54.354467 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:05:54.354530 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:05:54.354604 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:05:54.354657 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0902 00:05:54.354708 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:05:54.354823 139929824643072 dqn_agent.py:283] 	 seed: 1630541154353601
I0902 00:05:54.357810 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:05:54.358070 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:05:54.358270 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:05:54.358418 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:05:54.358509 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:05:54.358608 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:05:54.358698 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:05:54.358762 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:05:54.358814 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:05:54.386184 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:54.405012 139929824643072 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:05:54.405313 139929824643072 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 167.53
I0902 00:06:00.374872 139929824643072 replay_runner.py:36] Average training steps per second: 167.53
Steps executed: 221 Episode length: 146 Return: -530.9038996455395
I0902 00:06:01.664903 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -513.57
INFO:tensorflow:Starting iteration 1

Steps executed: 245 Episode length: 79 Return: -451.24757802369065
INFO:tensorflow:Average training steps per second: 228.84
I0902 00:06:10.316767 139929824643072 replay_runner.py:36] Average training steps per second: 228.84
I0902 00:06:10.519231 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -417.45
INFO:tensorflow:Starting iteration 2

Steps executed: 258 Episode length: 102 Return: -490.8741153542757
INFO:tensorflow:Average training steps per second: 227.52
I0902 00:06:19.346935 139929824643072 replay_runner.py:36] Average training steps per second: 227.52
I0902 00:06:19.555410 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -501.66
INFO:tensorflow:Starting iteration 3

Steps executed: 303 Episode length: 143 Return: -268.63388816100173
INFO:tensorflow:Average training steps per second: 220.31
I0902 00:06:28.351235 139929824643072 replay_runner.py:36] Average training steps per second: 220.31
I0902 00:06:28.641993 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.29
INFO:tensorflow:Starting iteration 4
I0902 00:06:32.935302 139929824643072 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 216.11

Steps executed: 232 Episode length: 112 Return: -257.55899203024063
I0902 00:06:37.780734 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -250.87
INFO:tensorflow:Starting iteration 5

Steps executed: 260 Episode length: 260 Return: -104.39349371241286
INFO:tensorflow:Average training steps per second: 220.98
I0902 00:06:46.625486 139929824643072 replay_runner.py:36] Average training steps per second: 220.98
I0902 00:06:46.931921 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.39
INFO:tensorflow:Starting iteration 6
I0902 00:06:51.231335 139929824643072 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 225.32

Steps executed: 446 Episode length: 446 Return: -210.14249508153296
I0902 00:06:56.298831 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.14
INFO:tensorflow:Starting iteration 7
I0902 00:07:00.591706 139929824643072 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 221.17

Steps executed: 795 Episode length: 795 Return: -434.43416099126136
I0902 00:07:06.726284 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -434.43
INFO:tensorflow:Starting iteration 8
I0902 00:07:11.021770 139929824643072 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 217.68

Steps executed: 1000 Episode length: 1000 Return: -27.66283266394784
I0902 00:07:18.590141 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -27.66
INFO:tensorflow:Starting iteration 9
I0902 00:07:23.011940 139929824643072 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 217.11

Steps executed: 705 Episode length: 705 Return: -164.962724096903464
I0902 00:07:29.413378 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.96
INFO:tensorflow:Starting iteration 10

Steps executed: 246 Episode length: 246 Return: -136.537336031377464
INFO:tensorflow:Average training steps per second: 217.08
I0902 00:07:38.377401 139929824643072 replay_runner.py:36] Average training steps per second: 217.08
I0902 00:07:38.643689 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.54
INFO:tensorflow:Starting iteration 11
I0902 00:07:42.876584 139929824643072 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 224.72

Steps executed: 592 Episode length: 592 Return: -397.285226606862464
I0902 00:07:48.470441 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -397.29
INFO:tensorflow:Starting iteration 12
I0902 00:07:52.667780 139929824643072 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 214.17

Steps executed: 877 Episode length: 877 Return: -459.662424260989964
I0902 00:08:00.288963 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -459.66
INFO:tensorflow:Starting iteration 13

Steps executed: 409 Episode length: 351 Return: -309.906618824099954
INFO:tensorflow:Average training steps per second: 221.77
I0902 00:08:09.224597 139929824643072 replay_runner.py:36] Average training steps per second: 221.77
I0902 00:08:09.868235 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.40
INFO:tensorflow:Starting iteration 14

Steps executed: 441 Episode length: 441 Return: -42.0210814784515754
INFO:tensorflow:Average training steps per second: 223.37
I0902 00:08:18.697935 139929824643072 replay_runner.py:36] Average training steps per second: 223.37
I0902 00:08:19.467339 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -42.02
INFO:tensorflow:Starting iteration 15
I0902 00:08:23.784553 139929824643072 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 222.12

Steps executed: 281 Episode length: 281 Return: -183.714242430341854
I0902 00:08:28.621943 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -183.71
INFO:tensorflow:Starting iteration 16

Steps executed: 133 Episode length: 133 Return: -114.310765461889594
INFO:tensorflow:Average training steps per second: 223.16

Steps executed: 596 Episode length: 463 Return: -66.2823799012817994
I0902 00:08:38.441959 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.30
INFO:tensorflow:Starting iteration 17

Steps executed: 283 Episode length: 84 Return: -547.7095250233458694
INFO:tensorflow:Average training steps per second: 229.08
I0902 00:08:47.160298 139929824643072 replay_runner.py:36] Average training steps per second: 229.08
I0902 00:08:47.395117 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -419.03
INFO:tensorflow:Starting iteration 18
I0902 00:08:51.659778 139929824643072 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 242.23

Steps executed: 270 Episode length: 270 Return: -523.265113071782594
I0902 00:08:56.132686 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -523.27
INFO:tensorflow:Starting iteration 19

Steps executed: 224 Episode length: 52 Return: -193.7875454927184494
INFO:tensorflow:Average training steps per second: 227.56
I0902 00:09:04.748973 139929824643072 replay_runner.py:36] Average training steps per second: 227.56
I0902 00:09:04.919161 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.65
INFO:tensorflow:Starting iteration 20

Steps executed: 111 Episode length: 111 Return: -188.629060192349364
INFO:tensorflow:Average training steps per second: 228.78
I0902 00:09:13.700167 139929824643072 replay_runner.py:36] Average training steps per second: 228.78

Steps executed: 260 Episode length: 149 Return: -160.227429590302734
INFO:tensorflow:Starting iteration 21

Steps executed: 216 Episode length: 68 Return: -171.5203778314783334
INFO:tensorflow:Average training steps per second: 224.09
I0902 00:09:22.723759 139929824643072 replay_runner.py:36] Average training steps per second: 224.09
I0902 00:09:22.878200 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.00
INFO:tensorflow:Starting iteration 22

Steps executed: 57 Episode length: 57 Return: -115.61167927781318334
INFO:tensorflow:Average training steps per second: 220.68
I0902 00:09:31.915991 139929824643072 replay_runner.py:36] Average training steps per second: 220.68

Steps executed: 269 Episode length: 80 Return: -609.9678878300408634
INFO:tensorflow:Starting iteration 23

Steps executed: 127 Episode length: 127 Return: -734.494147498746134
INFO:tensorflow:Average training steps per second: 222.84

Steps executed: 710 Episode length: 583 Return: -87.0524877961299134
I0902 00:09:42.458449 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -410.77
INFO:tensorflow:Starting iteration 24

Steps executed: 218 Episode length: 76 Return: -289.8050710365243134
INFO:tensorflow:Average training steps per second: 221.88
I0902 00:09:51.198931 139929824643072 replay_runner.py:36] Average training steps per second: 221.88
I0902 00:09:51.371668 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -419.61
INFO:tensorflow:Starting iteration 25

Steps executed: 143 Episode length: 86 Return: -501.9092383298558434
INFO:tensorflow:Average training steps per second: 224.02
I0902 00:10:00.023871 139929824643072 replay_runner.py:36] Average training steps per second: 224.02

Steps executed: 244 Episode length: 101 Return: -309.289433559897134
INFO:tensorflow:Starting iteration 26

Steps executed: 224 Episode length: 53 Return: -339.1023467089570434
INFO:tensorflow:Average training steps per second: 222.19
I0902 00:10:09.074620 139929824643072 replay_runner.py:36] Average training steps per second: 222.19
I0902 00:10:09.277410 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -483.83
INFO:tensorflow:Starting iteration 27

Steps executed: 95 Episode length: 95 Return: -606.82907237358040434
INFO:tensorflow:Average training steps per second: 220.24
I0902 00:10:18.149641 139929824643072 replay_runner.py:36] Average training steps per second: 220.24

Steps executed: 214 Episode length: 119 Return: -705.769788745514834
INFO:tensorflow:Starting iteration 28

Steps executed: 345 Episode length: 221 Return: -339.723345411785334
INFO:tensorflow:Average training steps per second: 221.46
I0902 00:10:27.264945 139929824643072 replay_runner.py:36] Average training steps per second: 221.46
I0902 00:10:27.610237 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.04
INFO:tensorflow:Starting iteration 29
I0902 00:10:31.885631 139929824643072 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 223.75

Steps executed: 252 Episode length: 53 Return: -133.9030753562753234

Done fixed training!Episode length: 53 Return: -133.9030753562753234