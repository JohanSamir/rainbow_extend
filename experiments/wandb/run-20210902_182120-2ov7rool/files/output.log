Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0902 18:21:26.138049 140613433649152 run_experiment.py:549] Creating TrainRunner ...
I0902 18:21:26.146783 140613433649152 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:21:26.146952 140613433649152 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:21:26.147049 140613433649152 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:21:26.147111 140613433649152 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:21:26.147166 140613433649152 dqn_agent.py:275] 	 update_period: 4
I0902 18:21:26.147243 140613433649152 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:21:26.147346 140613433649152 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:21:26.147427 140613433649152 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:21:26.147487 140613433649152 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:21:26.147539 140613433649152 dqn_agent.py:280] 	 optimizer: adam
I0902 18:21:26.147642 140613433649152 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:21:26.147703 140613433649152 dqn_agent.py:283] 	 seed: 1630606886146741
I0902 18:21:26.149495 140613433649152 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:21:26.149609 140613433649152 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:21:26.149693 140613433649152 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:21:26.149759 140613433649152 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:21:26.149815 140613433649152 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:21:26.149887 140613433649152 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:21:26.149951 140613433649152 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:21:26.150026 140613433649152 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:21:26.150094 140613433649152 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:21:26.174783 140613433649152 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:26.442401 140613433649152 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:26.452640 140613433649152 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:21:26.460062 140613433649152 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:21:26.460235 140613433649152 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:21:26.460381 140613433649152 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:21:26.460468 140613433649152 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:21:26.460544 140613433649152 dqn_agent.py:275] 	 update_period: 4
I0902 18:21:26.460656 140613433649152 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:21:26.460747 140613433649152 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:21:26.460826 140613433649152 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:21:26.460907 140613433649152 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:21:26.460982 140613433649152 dqn_agent.py:280] 	 optimizer: adam
I0902 18:21:26.461050 140613433649152 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:21:26.461119 140613433649152 dqn_agent.py:283] 	 seed: 1630606886460022
I0902 18:21:26.462538 140613433649152 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:21:26.462660 140613433649152 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:21:26.462733 140613433649152 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:21:26.462835 140613433649152 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:21:26.462902 140613433649152 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:21:26.463002 140613433649152 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:21:26.463096 140613433649152 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:21:26.463165 140613433649152 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:21:26.463224 140613433649152 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:21:26.484218 140613433649152 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:26.502156 140613433649152 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:21:26.502329 140613433649152 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 237.92
I0902 18:21:30.705525 140613433649152 replay_runner.py:36] Average training steps per second: 237.92
I0902 18:21:31.498436 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.67
Steps executed: 260 Episode length: 112 Return: -304.61844052614117
INFO:tensorflow:Starting iteration 1

Steps executed: 149 Episode length: 149 Return: -252.49492739776176
INFO:tensorflow:Average training steps per second: 360.74

Steps executed: 357 Episode length: 208 Return: -285.69498197514827
I0902 18:21:37.771946 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.09
INFO:tensorflow:Starting iteration 2

Steps executed: 687 Episode length: 687 Return: -287.50197043353677
INFO:tensorflow:Average training steps per second: 349.15
I0902 18:21:43.844983 140613433649152 replay_runner.py:36] Average training steps per second: 349.15
I0902 18:21:44.956614 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.50
INFO:tensorflow:Starting iteration 3
I0902 18:21:48.174977 140613433649152 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 329.14

Steps executed: 1000 Episode length: 1000 Return: -120.43084272105094
I0902 18:21:53.066939 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.43
INFO:tensorflow:Starting iteration 4
I0902 18:21:56.356694 140613433649152 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 327.25

Steps executed: 1000 Episode length: 1000 Return: -66.730149281617764
I0902 18:22:01.270525 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -66.73
INFO:tensorflow:Starting iteration 5
I0902 18:22:04.583325 140613433649152 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 330.44

Steps executed: 1000 Episode length: 1000 Return: -151.43557662831194
I0902 18:22:10.364522 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.44
INFO:tensorflow:Starting iteration 6
I0902 18:22:13.742077 140613433649152 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 337.65

Steps executed: 1000 Episode length: 1000 Return: -121.62197579866061
I0902 18:22:18.573900 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.62
INFO:tensorflow:Starting iteration 7

Steps executed: 500 Episode length: 500 Return: -330.7109120910605561
INFO:tensorflow:Average training steps per second: 336.83
I0902 18:22:24.923860 140613433649152 replay_runner.py:36] Average training steps per second: 336.83
I0902 18:22:25.508259 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -330.71
INFO:tensorflow:Starting iteration 8
I0902 18:22:28.827261 140613433649152 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 355.31

Steps executed: 892 Episode length: 892 Return: -422.9563355239697661
I0902 18:22:33.675914 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -422.96
INFO:tensorflow:Starting iteration 9
I0902 18:22:36.970398 140613433649152 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 353.06

Steps executed: 1000 Episode length: 1000 Return: -207.50194820942461
I0902 18:22:41.175959 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.50
INFO:tensorflow:Starting iteration 10

Steps executed: 392 Episode length: 392 Return: -626.3362914420646461
INFO:tensorflow:Average training steps per second: 349.30
I0902 18:22:47.387668 140613433649152 replay_runner.py:36] Average training steps per second: 349.30
I0902 18:22:47.792486 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -626.34
INFO:tensorflow:Starting iteration 11
I0902 18:22:51.228685 140613433649152 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 350.91

Steps executed: 1000 Episode length: 1000 Return: -163.50591103148284
I0902 18:22:55.793112 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.51
INFO:tensorflow:Starting iteration 12
I0902 18:22:59.225169 140613433649152 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 355.00

Steps executed: 1000 Episode length: 1000 Return: -120.42601510749371
I0902 18:23:03.985404 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.43
INFO:tensorflow:Starting iteration 13
I0902 18:23:07.385071 140613433649152 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 357.28

Steps executed: 441 Episode length: 441 Return: -27.29388160858029371
I0902 18:23:10.727745 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -27.29
INFO:tensorflow:Starting iteration 14
I0902 18:23:14.170240 140613433649152 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 347.72

Steps executed: 1000 Episode length: 1000 Return: -60.993929663241275
I0902 18:23:19.639327 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -60.99
INFO:tensorflow:Starting iteration 15
I0902 18:23:23.005125 140613433649152 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 335.01

Steps executed: 1000 Episode length: 1000 Return: -110.58880315116395
I0902 18:23:28.821342 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.59
INFO:tensorflow:Starting iteration 16
I0902 18:23:32.182525 140613433649152 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 324.14

Steps executed: 729 Episode length: 729 Return: -425.2809255256223395
I0902 18:23:36.634214 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -425.28
INFO:tensorflow:Starting iteration 17
I0902 18:23:39.931551 140613433649152 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 322.23

Steps executed: 946 Episode length: 946 Return: -371.2342950263078595
I0902 18:23:44.952848 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -371.23
INFO:tensorflow:Starting iteration 18
I0902 18:23:48.358654 140613433649152 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 327.18

Steps executed: 1000 Episode length: 1000 Return: -73.427011445564055
I0902 18:23:53.367749 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.43
INFO:tensorflow:Starting iteration 19

Steps executed: 271 Episode length: 137 Return: -69.15030753885141055
INFO:tensorflow:Average training steps per second: 355.81
I0902 18:23:59.704852 140613433649152 replay_runner.py:36] Average training steps per second: 355.81
I0902 18:23:59.843950 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.07
INFO:tensorflow:Starting iteration 20
I0902 18:24:03.317254 140613433649152 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 344.93

Steps executed: 1000 Episode length: 1000 Return: 15.0707771550236335
I0902 18:24:08.975733 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: 15.07
INFO:tensorflow:Starting iteration 21
I0902 18:24:12.349156 140613433649152 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 327.64

Steps executed: 840 Episode length: 840 Return: -76.37327353430518335
I0902 18:24:17.063528 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.37
INFO:tensorflow:Starting iteration 22

Steps executed: 253 Episode length: 253 Return: -52.19400581564949335
INFO:tensorflow:Average training steps per second: 315.18
I0902 18:24:23.501241 140613433649152 replay_runner.py:36] Average training steps per second: 315.18
I0902 18:24:23.715323 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -52.19
INFO:tensorflow:Starting iteration 23
I0902 18:24:26.809325 140613433649152 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 313.97

Steps executed: 605 Episode length: 605 Return: -448.2585113222586435
I0902 18:24:30.886126 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -448.26
INFO:tensorflow:Starting iteration 24

Steps executed: 603 Episode length: 603 Return: -80.93123351617436435
INFO:tensorflow:Average training steps per second: 331.17
I0902 18:24:37.058510 140613433649152 replay_runner.py:36] Average training steps per second: 331.17
I0902 18:24:37.923641 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.93
INFO:tensorflow:Starting iteration 25

Steps executed: 179 Episode length: 179 Return: -54.20927608509699435
INFO:tensorflow:Average training steps per second: 332.64

Steps executed: 379 Episode length: 200 Return: -46.70513747286705435
I0902 18:24:44.475860 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -50.46
INFO:tensorflow:Starting iteration 26
I0902 18:24:47.868984 140613433649152 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 383.43

Steps executed: 229 Episode length: 229 Return: -657.2029550083066435
I0902 18:24:50.688607 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -657.20
INFO:tensorflow:Starting iteration 27

Steps executed: 307 Episode length: 307 Return: -47.42871961212383435
INFO:tensorflow:Average training steps per second: 394.93
I0902 18:24:56.766047 140613433649152 replay_runner.py:36] Average training steps per second: 394.93
I0902 18:24:56.962463 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -47.43
INFO:tensorflow:Starting iteration 28

Steps executed: 570 Episode length: 465 Return: -521.6143950590358435
INFO:tensorflow:Average training steps per second: 359.60
I0902 18:25:03.126049 140613433649152 replay_runner.py:36] Average training steps per second: 359.60
I0902 18:25:03.531175 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -473.77
INFO:tensorflow:Starting iteration 29

Steps executed: 456 Episode length: 456 Return: -671.4814363996973435
INFO:tensorflow:Average training steps per second: 343.23
I0902 18:25:09.783566 140613433649152 replay_runner.py:36] Average training steps per second: 343.23

Done fixed training!Episode length: 456 Return: -671.4814363996973435