Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0901 12:20:15.616214 139809518303232 run_experiment.py:549] Creating TrainRunner ...
I0901 12:20:15.632671 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:20:15.632910 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:20:15.633049 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:20:15.633200 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:20:15.633499 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 12:20:15.633620 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:20:15.633809 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:20:15.633944 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:20:15.634148 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:20:15.634310 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 12:20:15.634396 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:20:15.634527 139809518303232 dqn_agent.py:283] 	 seed: 1630498815632590
I0901 12:20:15.636764 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:20:15.636927 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:20:15.637254 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:20:15.637391 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:20:15.637479 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:20:15.637696 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:20:15.637839 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:20:15.637964 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:20:15.638083 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:20:15.730252 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:20:16.157793 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:20:16.173093 139809518303232 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:20:16.183974 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:20:16.184267 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:20:16.184526 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:20:16.184754 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:20:16.184980 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 12:20:16.185117 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:20:16.185297 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:20:16.185434 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:20:16.185633 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:20:16.185762 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 12:20:16.185855 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:20:16.185942 139809518303232 dqn_agent.py:283] 	 seed: 1630498816183906
I0901 12:20:16.188047 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:20:16.188227 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:20:16.188325 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:20:16.188409 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:20:16.188518 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:20:16.188624 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:20:16.188754 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:20:16.188892 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:20:16.189023 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:20:16.224260 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:20:16.249853 139809518303232 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:20:16.250241 139809518303232 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 160.02
I0901 12:20:22.499930 139809518303232 replay_runner.py:36] Average training steps per second: 160.02
Steps executed: 325 Episode length: 130 Return: -253.85967622130577
I0901 12:20:23.880597 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -335.75
INFO:tensorflow:Starting iteration 1

Steps executed: 190 Episode length: 190 Return: -366.78390293738057
INFO:tensorflow:Average training steps per second: 215.80

Steps executed: 366 Episode length: 176 Return: -218.34979639207757
I0901 12:20:33.304804 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -292.57
INFO:tensorflow:Starting iteration 2

Steps executed: 411 Episode length: 256 Return: -42.932356639569316
INFO:tensorflow:Average training steps per second: 222.02
I0901 12:20:42.177865 139809518303232 replay_runner.py:36] Average training steps per second: 222.02
I0901 12:20:42.694680 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -47.10
INFO:tensorflow:Starting iteration 3

Steps executed: 364 Episode length: 180 Return: -222.08696656129484
INFO:tensorflow:Average training steps per second: 217.61
I0901 12:20:51.721171 139809518303232 replay_runner.py:36] Average training steps per second: 217.61
I0901 12:20:52.079967 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.85
INFO:tensorflow:Starting iteration 4
I0901 12:20:56.489705 139809518303232 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 219.09

Steps executed: 1000 Episode length: 1000 Return: -134.11012874151535
I0901 12:21:04.731650 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.11
INFO:tensorflow:Starting iteration 5
I0901 12:21:09.152641 139809518303232 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 218.23

Steps executed: 1000 Episode length: 1000 Return: -121.32441153612745
I0901 12:21:17.970743 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.32
INFO:tensorflow:Starting iteration 6
I0901 12:21:22.265241 139809518303232 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 221.94

Steps executed: 1000 Episode length: 1000 Return: -216.26480679927945
I0901 12:21:29.524389 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.26
INFO:tensorflow:Starting iteration 7

Steps executed: 559 Episode length: 559 Return: -365.2353964472867945
INFO:tensorflow:Average training steps per second: 218.47
I0901 12:21:38.454723 139809518303232 replay_runner.py:36] Average training steps per second: 218.47
I0901 12:21:39.214312 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -365.24
INFO:tensorflow:Starting iteration 8
I0901 12:21:43.347617 139809518303232 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 236.71

Steps executed: 1000 Episode length: 1000 Return: -414.58663122923715
I0901 12:21:49.564880 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -414.59
INFO:tensorflow:Starting iteration 9

Steps executed: 801 Episode length: 699 Return: -481.6307046452676715
INFO:tensorflow:Average training steps per second: 235.19
I0901 12:21:58.023700 139809518303232 replay_runner.py:36] Average training steps per second: 235.19
I0901 12:21:59.341828 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -480.02
INFO:tensorflow:Starting iteration 10
I0901 12:22:03.663209 139809518303232 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 229.73

Steps executed: 1000 Episode length: 1000 Return: -639.48978888374815
I0901 12:22:10.998701 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -639.49
INFO:tensorflow:Starting iteration 11
I0901 12:22:15.426084 139809518303232 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 223.60

Steps executed: 904 Episode length: 904 Return: -517.1882208908598815
I0901 12:22:22.098455 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -517.19
INFO:tensorflow:Starting iteration 12
I0901 12:22:26.476731 139809518303232 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 213.88

Steps executed: 1000 Episode length: 1000 Return: 8.52533001249550715
I0901 12:22:34.620031 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: 8.53
INFO:tensorflow:Starting iteration 13
I0901 12:22:38.944422 139809518303232 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 213.61

Steps executed: 1000 Episode length: 1000 Return: -104.53366246927955
I0901 12:22:47.115229 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.53
INFO:tensorflow:Starting iteration 14
I0901 12:22:51.353495 139809518303232 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 213.45

Steps executed: 1000 Episode length: 1000 Return: -158.56137223053865
I0901 12:22:58.818935 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.56
INFO:tensorflow:Starting iteration 15
I0901 12:23:03.250091 139809518303232 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 210.79

Steps executed: 1000 Episode length: 1000 Return: -195.95038145156815
I0901 12:23:11.293199 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.95
INFO:tensorflow:Starting iteration 16
I0901 12:23:15.733091 139809518303232 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 215.13

Steps executed: 826 Episode length: 826 Return: -145.7241315125321315
I0901 12:23:23.401951 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.72
INFO:tensorflow:Starting iteration 17
I0901 12:23:27.723501 139809518303232 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 219.54

Steps executed: 1000 Episode length: 1000 Return: -59.009751592370776
I0901 12:23:35.431611 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -59.01
INFO:tensorflow:Starting iteration 18

Steps executed: 439 Episode length: 439 Return: 17.146557320717307776
INFO:tensorflow:Average training steps per second: 215.19
I0901 12:23:44.491804 139809518303232 replay_runner.py:36] Average training steps per second: 215.19
I0901 12:23:45.290709 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: 17.15
INFO:tensorflow:Starting iteration 19

Steps executed: 623 Episode length: 623 Return: -163.8379231091473776
INFO:tensorflow:Average training steps per second: 217.16
I0901 12:23:54.335248 139809518303232 replay_runner.py:36] Average training steps per second: 217.16
I0901 12:23:55.635015 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.84
INFO:tensorflow:Starting iteration 20

Steps executed: 222 Episode length: 222 Return: -12.60510998965382676
INFO:tensorflow:Average training steps per second: 215.99
I0901 12:24:04.666513 139809518303232 replay_runner.py:36] Average training steps per second: 215.99
I0901 12:24:04.963282 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -12.61
INFO:tensorflow:Starting iteration 21
I0901 12:24:09.397273 139809518303232 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 224.21

Steps executed: 450 Episode length: 450 Return: 191.20082019873587676
I0901 12:24:14.641426 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: 191.20
INFO:tensorflow:Starting iteration 22

Steps executed: 288 Episode length: 288 Return: -15.57583541824861676
INFO:tensorflow:Average training steps per second: 218.08
I0901 12:24:23.366370 139809518303232 replay_runner.py:36] Average training steps per second: 218.08
I0901 12:24:23.768190 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -15.58
INFO:tensorflow:Starting iteration 23

Steps executed: 226 Episode length: 226 Return: -270.0481188332712576
INFO:tensorflow:Average training steps per second: 222.63
I0901 12:24:32.696547 139809518303232 replay_runner.py:36] Average training steps per second: 222.63
I0901 12:24:32.947683 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.05
INFO:tensorflow:Starting iteration 24
I0901 12:24:37.332031 139809518303232 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 219.97


Steps executed: 914 Episode length: 768 Return: -439.1057007561884576
I0901 12:24:44.521322 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.31
INFO:tensorflow:Starting iteration 25

Steps executed: 356 Episode length: 356 Return: -223.3177483776076476
INFO:tensorflow:Average training steps per second: 223.02
I0901 12:24:53.200650 139809518303232 replay_runner.py:36] Average training steps per second: 223.02
I0901 12:24:53.696900 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.32
INFO:tensorflow:Starting iteration 26

Steps executed: 609 Episode length: 609 Return: -316.9659067345445576
INFO:tensorflow:Average training steps per second: 227.14
I0901 12:25:02.372493 139809518303232 replay_runner.py:36] Average training steps per second: 227.14
I0901 12:25:03.953339 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -316.97
INFO:tensorflow:Starting iteration 27
I0901 12:25:08.312778 139809518303232 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 216.83

Steps executed: 769 Episode length: 769 Return: -409.8867847672623576
I0901 12:25:14.628867 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -409.89
INFO:tensorflow:Starting iteration 28
I0901 12:25:18.893029 139809518303232 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 223.63
I0901 12:25:23.365101 139809518303232 replay_runner.py:36] Average training steps per second: 223.63

Steps executed: 473 Episode length: 473 Return: -546.4015470833587576
INFO:tensorflow:Starting iteration 29
I0901 12:25:28.565051 139809518303232 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 216.25

Steps executed: 1000 Episode length: 1000 Return: 6.81795405119279256

Done fixed training! Episode length: 1000 Return: 6.81795405119279256