Loaded trained dqn in acrobot
Training fixed agent 7, please be patient, may be a while...
I0902 23:52:43.082936 140527680751616 run_experiment.py:549] Creating TrainRunner ...
I0902 23:52:43.092281 140527680751616 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:52:43.092566 140527680751616 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:52:43.092704 140527680751616 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:52:43.092831 140527680751616 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:52:43.092959 140527680751616 dqn_agent.py:275] 	 update_period: 4
I0902 23:52:43.093119 140527680751616 dqn_agent.py:276] 	 target_update_period: 100
I0902 23:52:43.093250 140527680751616 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:52:43.093365 140527680751616 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:52:43.093477 140527680751616 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:52:43.093581 140527680751616 dqn_agent.py:280] 	 optimizer: adam
I0902 23:52:43.093679 140527680751616 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:52:43.093778 140527680751616 dqn_agent.py:283] 	 seed: 1630626763092215
I0902 23:52:43.097025 140527680751616 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:52:43.097262 140527680751616 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0902 23:52:43.097402 140527680751616 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:52:43.097529 140527680751616 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:52:43.097641 140527680751616 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:52:43.097759 140527680751616 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:52:43.097881 140527680751616 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:52:43.097992 140527680751616 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:52:43.098102 140527680751616 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:52:43.138718 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:52:43.602911 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:52:43.616031 140527680751616 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:52:43.625921 140527680751616 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:52:43.626190 140527680751616 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:52:43.626309 140527680751616 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:52:43.626450 140527680751616 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:52:43.626743 140527680751616 dqn_agent.py:275] 	 update_period: 4
I0902 23:52:43.626956 140527680751616 dqn_agent.py:276] 	 target_update_period: 100
I0902 23:52:43.627129 140527680751616 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:52:43.627421 140527680751616 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:52:43.627758 140527680751616 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:52:43.627931 140527680751616 dqn_agent.py:280] 	 optimizer: adam
I0902 23:52:43.628056 140527680751616 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:52:43.628166 140527680751616 dqn_agent.py:283] 	 seed: 1630626763625857
I0902 23:52:43.631480 140527680751616 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:52:43.631693 140527680751616 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0902 23:52:43.631841 140527680751616 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:52:43.631965 140527680751616 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:52:43.632078 140527680751616 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:52:43.632195 140527680751616 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:52:43.632360 140527680751616 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:52:43.632573 140527680751616 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:52:43.632695 140527680751616 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:52:43.669117 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:52:43.694567 140527680751616 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:52:43.694914 140527680751616 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 149.55
I0902 23:52:50.382165 140527680751616 replay_runner.py:36] Average training steps per second: 149.55
Steps executed: 461 Episode length: 461 Return: -460.0
I0902 23:52:51.795021 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -460.00
INFO:tensorflow:Starting iteration 1

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 205.94
I0902 23:52:56.892994 140527680751616 replay_runner.py:36] Average training steps per second: 205.94
I0902 23:52:57.294023 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 2
I0902 23:52:57.529515 140527680751616 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 204.78
I0902 23:53:02.413169 140527680751616 replay_runner.py:36] Average training steps per second: 204.78
I0902 23:53:02.845959 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 3

Steps executed: 254 Episode length: 117 Return: -116.0
INFO:tensorflow:Average training steps per second: 200.79
I0902 23:53:08.068702 140527680751616 replay_runner.py:36] Average training steps per second: 200.79
I0902 23:53:08.272809 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.00
INFO:tensorflow:Starting iteration 4

Steps executed: 279 Episode length: 113 Return: -112.0
INFO:tensorflow:Average training steps per second: 207.83
I0902 23:53:13.311772 140527680751616 replay_runner.py:36] Average training steps per second: 207.83
I0902 23:53:13.550811 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.50
INFO:tensorflow:Starting iteration 5
I0902 23:53:13.788340 140527680751616 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 203.68

Steps executed: 500 Episode length: 500 Return: -500.0
I0902 23:53:19.142150 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6
I0902 23:53:19.390480 140527680751616 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 195.10
I0902 23:53:24.516426 140527680751616 replay_runner.py:36] Average training steps per second: 195.10
I0902 23:53:24.925778 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7

Steps executed: 274 Episode length: 98 Return: -97.0.0
INFO:tensorflow:Average training steps per second: 201.71
I0902 23:53:30.110339 140527680751616 replay_runner.py:36] Average training steps per second: 201.71
I0902 23:53:30.348171 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.33
INFO:tensorflow:Starting iteration 8

Steps executed: 315 Episode length: 155 Return: -154.0
INFO:tensorflow:Average training steps per second: 192.93
I0902 23:53:35.774324 140527680751616 replay_runner.py:36] Average training steps per second: 192.93
I0902 23:53:36.040104 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.50
INFO:tensorflow:Starting iteration 9

Steps executed: 248 Episode length: 127 Return: -126.0
INFO:tensorflow:Average training steps per second: 200.05
I0902 23:53:41.279680 140527680751616 replay_runner.py:36] Average training steps per second: 200.05
I0902 23:53:41.501736 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.00
INFO:tensorflow:Starting iteration 10

Steps executed: 207 Episode length: 106 Return: -105.0
INFO:tensorflow:Average training steps per second: 195.32
I0902 23:53:46.868986 140527680751616 replay_runner.py:36] Average training steps per second: 195.32
I0902 23:53:47.034709 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.50
INFO:tensorflow:Starting iteration 11

Steps executed: 215 Episode length: 103 Return: -102.0
INFO:tensorflow:Average training steps per second: 200.28
I0902 23:53:52.260874 140527680751616 replay_runner.py:36] Average training steps per second: 200.28
I0902 23:53:52.454680 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.50
INFO:tensorflow:Starting iteration 12

Steps executed: 225 Episode length: 114 Return: -113.0
INFO:tensorflow:Average training steps per second: 200.06
I0902 23:53:57.706492 140527680751616 replay_runner.py:36] Average training steps per second: 200.06
I0902 23:53:57.897684 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.50
INFO:tensorflow:Starting iteration 13

Steps executed: 85 Episode length: 85 Return: -84.03.0
INFO:tensorflow:Average training steps per second: 195.52

Steps executed: 272 Episode length: 85 Return: -84.0.0
I0902 23:54:03.489635 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.67
INFO:tensorflow:Starting iteration 14

Steps executed: 145 Episode length: 63 Return: -62.0.0
INFO:tensorflow:Average training steps per second: 202.68
I0902 23:54:08.674586 140527680751616 replay_runner.py:36] Average training steps per second: 202.68
I0902 23:54:08.917375 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.00
INFO:tensorflow:Starting iteration 15


Steps executed: 227 Episode length: 117 Return: -116.0
INFO:tensorflow:Average training steps per second: 198.85
I0902 23:54:14.161553 140527680751616 replay_runner.py:36] Average training steps per second: 198.85
I0902 23:54:14.382890 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.50
INFO:tensorflow:Starting iteration 16
I0902 23:54:14.620248 140527680751616 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 202.76

Steps executed: 307 Episode length: 129 Return: -128.0
I0902 23:54:19.824552 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.33
INFO:tensorflow:Starting iteration 17
I0902 23:54:20.075165 140527680751616 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 196.91
I0902 23:54:25.154020 140527680751616 replay_runner.py:36] Average training steps per second: 196.91
I0902 23:54:25.325513 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.00
INFO:tensorflow:Starting iteration 18


Steps executed: 254 Episode length: 110 Return: -109.0
INFO:tensorflow:Average training steps per second: 193.63
I0902 23:54:30.725338 140527680751616 replay_runner.py:36] Average training steps per second: 193.63
I0902 23:54:30.944390 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.67
INFO:tensorflow:Starting iteration 19

Steps executed: 256 Episode length: 133 Return: -132.0
INFO:tensorflow:Average training steps per second: 198.66
I0902 23:54:36.231407 140527680751616 replay_runner.py:36] Average training steps per second: 198.66
I0902 23:54:36.453878 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.00
INFO:tensorflow:Starting iteration 20
I0902 23:54:36.694257 140527680751616 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 199.68

Steps executed: 232 Episode length: 160 Return: -159.0
I0902 23:54:41.898075 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.00
INFO:tensorflow:Starting iteration 21

Steps executed: 91 Episode length: 91 Return: -90.09.0
INFO:tensorflow:Average training steps per second: 199.46

Steps executed: 231 Episode length: 140 Return: -139.0
I0902 23:54:47.346890 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.50
INFO:tensorflow:Starting iteration 22

Steps executed: 281 Episode length: 97 Return: -96.0.0
INFO:tensorflow:Average training steps per second: 200.37
I0902 23:54:52.573366 140527680751616 replay_runner.py:36] Average training steps per second: 200.37
I0902 23:54:52.802215 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.67
INFO:tensorflow:Starting iteration 23

Steps executed: 261 Episode length: 65 Return: -64.0.0
INFO:tensorflow:Average training steps per second: 192.54
I0902 23:54:58.231867 140527680751616 replay_runner.py:36] Average training steps per second: 192.54
I0902 23:54:58.445066 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -64.25
INFO:tensorflow:Starting iteration 24

Steps executed: 231 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Average training steps per second: 202.90
I0902 23:55:03.609516 140527680751616 replay_runner.py:36] Average training steps per second: 202.90
I0902 23:55:03.814067 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.00
INFO:tensorflow:Starting iteration 25

Steps executed: 204 Episode length: 112 Return: -111.0
INFO:tensorflow:Average training steps per second: 197.79
I0902 23:55:09.116286 140527680751616 replay_runner.py:36] Average training steps per second: 197.79
I0902 23:55:09.280391 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.00
INFO:tensorflow:Starting iteration 26

Steps executed: 205 Episode length: 115 Return: -114.0
INFO:tensorflow:Average training steps per second: 194.01
I0902 23:55:14.674410 140527680751616 replay_runner.py:36] Average training steps per second: 194.01
I0902 23:55:14.849531 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.50
INFO:tensorflow:Starting iteration 27

Steps executed: 211 Episode length: 141 Return: -140.0
INFO:tensorflow:Average training steps per second: 202.49
I0902 23:55:20.033545 140527680751616 replay_runner.py:36] Average training steps per second: 202.49
I0902 23:55:20.212718 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.50
INFO:tensorflow:Starting iteration 28
I0902 23:55:20.458576 140527680751616 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 192.74

Steps executed: 206 Episode length: 110 Return: -109.0
I0902 23:55:25.834145 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.00
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 95 Return: -94.0.0
INFO:tensorflow:Average training steps per second: 201.38
I0902 23:55:31.046144 140527680751616 replay_runner.py:36] Average training steps per second: 201.38
I0902 23:55:31.283056 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.33