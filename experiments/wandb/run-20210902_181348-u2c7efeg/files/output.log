I0902 18:13:53.394581 140182397114368 run_experiment.py:549] Creating TrainRunner ...
I0902 18:13:53.401307 140182397114368 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:13:53.401444 140182397114368 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:13:53.401546 140182397114368 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:13:53.401607 140182397114368 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:13:53.401690 140182397114368 dqn_agent.py:275] 	 update_period: 4
I0902 18:13:53.401750 140182397114368 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:13:53.401862 140182397114368 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:13:53.401961 140182397114368 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:13:53.402079 140182397114368 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:13:53.402177 140182397114368 dqn_agent.py:280] 	 optimizer: adam
I0902 18:13:53.402273 140182397114368 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:13:53.402348 140182397114368 dqn_agent.py:283] 	 seed: 1630606433401270
I0902 18:13:53.404282 140182397114368 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:13:53.404433 140182397114368 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:13:53.404530 140182397114368 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:13:53.404600 140182397114368 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:13:53.404678 140182397114368 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:13:53.404747 140182397114368 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:13:53.404826 140182397114368 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:13:53.404885 140182397114368 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:13:53.404958 140182397114368 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:13:53.429991 140182397114368 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.003125
I0902 18:13:53.658962 140182397114368 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.003125
I0902 18:13:53.666827 140182397114368 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:13:53.673217 140182397114368 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:13:53.673351 140182397114368 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:13:53.673463 140182397114368 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:13:53.673523 140182397114368 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:13:53.673577 140182397114368 dqn_agent.py:275] 	 update_period: 4
I0902 18:13:53.673649 140182397114368 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:13:53.673738 140182397114368 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:13:53.673804 140182397114368 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:13:53.673856 140182397114368 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:13:53.673916 140182397114368 dqn_agent.py:280] 	 optimizer: adam
I0902 18:13:53.673984 140182397114368 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:13:53.674052 140182397114368 dqn_agent.py:283] 	 seed: 1630606433673188
I0902 18:13:53.675388 140182397114368 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:13:53.675497 140182397114368 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:13:53.675588 140182397114368 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:13:53.675650 140182397114368 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:13:53.675707 140182397114368 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:13:53.675793 140182397114368 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:13:53.675869 140182397114368 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:13:53.675925 140182397114368 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:13:53.675992 140182397114368 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:13:53.698963 140182397114368 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.003125
I0902 18:13:53.713287 140182397114368 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:13:53.713459 140182397114368 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 267.58
I0902 18:13:57.450801 140182397114368 replay_runner.py:36] Average training steps per second: 267.58
I0902 18:13:58.209541 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.73
Steps executed: 218 Episode length: 89 Return: -429.238249332507834
INFO:tensorflow:Starting iteration 1

Steps executed: 310 Episode length: 131 Return: -267.40934952728185
INFO:tensorflow:Average training steps per second: 355.32
I0902 18:14:04.247056 140182397114368 replay_runner.py:36] Average training steps per second: 355.32
I0902 18:14:04.431434 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.24
INFO:tensorflow:Starting iteration 2
I0902 18:14:07.703735 140182397114368 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 341.65
I0902 18:14:10.630991 140182397114368 replay_runner.py:36] Average training steps per second: 341.65

Steps executed: 251 Episode length: 108 Return: -215.21213302027255
INFO:tensorflow:Starting iteration 3

Steps executed: 326 Episode length: 157 Return: -236.66621484364737
INFO:tensorflow:Average training steps per second: 348.15
I0902 18:14:17.100660 140182397114368 replay_runner.py:36] Average training steps per second: 348.15
I0902 18:14:17.262094 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.94
INFO:tensorflow:Starting iteration 4

Steps executed: 247 Episode length: 128 Return: -218.98517975889567
INFO:tensorflow:Average training steps per second: 350.58
I0902 18:14:23.588992 140182397114368 replay_runner.py:36] Average training steps per second: 350.58
I0902 18:14:23.714567 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.27
INFO:tensorflow:Starting iteration 5

Steps executed: 263 Episode length: 138 Return: -245.62113908425036
INFO:tensorflow:Average training steps per second: 344.68
I0902 18:14:30.096256 140182397114368 replay_runner.py:36] Average training steps per second: 344.68
I0902 18:14:30.239773 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.50
INFO:tensorflow:Starting iteration 6
I0902 18:14:33.690265 140182397114368 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 337.37

Steps executed: 790 Episode length: 790 Return: -267.05715299141036
I0902 18:14:37.655410 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -267.06
INFO:tensorflow:Starting iteration 7
I0902 18:14:41.052403 140182397114368 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 342.73

Steps executed: 1000 Episode length: 1000 Return: -52.83061476095089
I0902 18:14:45.449405 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -52.83
INFO:tensorflow:Starting iteration 8
I0902 18:14:48.859256 140182397114368 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 338.87

Steps executed: 1000 Episode length: 1000 Return: -116.88488374942001
I0902 18:14:53.465358 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.88
INFO:tensorflow:Starting iteration 9

Steps executed: 456 Episode length: 456 Return: -127.5863992744425001
INFO:tensorflow:Average training steps per second: 332.47
I0902 18:14:59.775898 140182397114368 replay_runner.py:36] Average training steps per second: 332.47
I0902 18:15:00.174690 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.59
INFO:tensorflow:Starting iteration 10

Steps executed: 94 Episode length: 94 Return: -408.910551065121325001
INFO:tensorflow:Average training steps per second: 333.67

Steps executed: 824 Episode length: 730 Return: -197.6460104082343001
I0902 18:15:07.860975 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.28
INFO:tensorflow:Starting iteration 11
I0902 18:15:11.063494 140182397114368 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 319.11
I0902 18:15:14.197672 140182397114368 replay_runner.py:36] Average training steps per second: 319.11

Steps executed: 1000 Episode length: 1000 Return: -112.35304813456882
INFO:tensorflow:Starting iteration 12

Steps executed: 297 Episode length: 192 Return: -94.42125252853528882
INFO:tensorflow:Average training steps per second: 315.64
I0902 18:15:21.763839 140182397114368 replay_runner.py:36] Average training steps per second: 315.64
I0902 18:15:21.964503 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -45.06
INFO:tensorflow:Starting iteration 13
I0902 18:15:25.205614 140182397114368 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 329.45

Steps executed: 1000 Episode length: 1000 Return: -166.34973022814842
I0902 18:15:30.212362 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.35
INFO:tensorflow:Starting iteration 14
I0902 18:15:33.427974 140182397114368 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 331.96

Steps executed: 1000 Episode length: 1000 Return: -45.253201991206495
I0902 18:15:38.888684 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -45.25
INFO:tensorflow:Starting iteration 15

Steps executed: 300 Episode length: 146 Return: -128.4344897084450895
INFO:tensorflow:Average training steps per second: 346.79
I0902 18:15:45.055656 140182397114368 replay_runner.py:36] Average training steps per second: 346.79
I0902 18:15:45.236746 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.33
INFO:tensorflow:Starting iteration 16
I0902 18:15:48.593451 140182397114368 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 338.60

Steps executed: 1000 Episode length: 1000 Return: -71.042354171981595
I0902 18:15:53.589899 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.04
INFO:tensorflow:Starting iteration 17

Steps executed: 460 Episode length: 460 Return: -620.2318009866964595
INFO:tensorflow:Average training steps per second: 337.64
I0902 18:15:59.883187 140182397114368 replay_runner.py:36] Average training steps per second: 337.64
I0902 18:16:00.504957 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -620.23
INFO:tensorflow:Starting iteration 18

Steps executed: 218 Episode length: 110 Return: -259.9164519292454595
INFO:tensorflow:Average training steps per second: 333.61
I0902 18:16:06.770956 140182397114368 replay_runner.py:36] Average training steps per second: 333.61
I0902 18:16:06.890750 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.69
INFO:tensorflow:Starting iteration 19

Steps executed: 275 Episode length: 112 Return: -270.0397160978574595
INFO:tensorflow:Average training steps per second: 343.18
I0902 18:16:13.134333 140182397114368 replay_runner.py:36] Average training steps per second: 343.18
I0902 18:16:13.295768 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.89
INFO:tensorflow:Starting iteration 20


Steps executed: 432 Episode length: 330 Return: -258.5933455258487595
INFO:tensorflow:Average training steps per second: 350.82
I0902 18:16:19.523798 140182397114368 replay_runner.py:36] Average training steps per second: 350.82
I0902 18:16:19.872734 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.13
INFO:tensorflow:Starting iteration 21

Steps executed: 234 Episode length: 111 Return: -172.7929283506264895
INFO:tensorflow:Average training steps per second: 341.25
I0902 18:16:26.168824 140182397114368 replay_runner.py:36] Average training steps per second: 341.25
I0902 18:16:26.304977 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.29
INFO:tensorflow:Starting iteration 22

Steps executed: 317 Episode length: 226 Return: -210.0303280447514695
INFO:tensorflow:Average training steps per second: 330.63
I0902 18:16:32.560361 140182397114368 replay_runner.py:36] Average training steps per second: 330.63
I0902 18:16:32.778566 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -465.70
INFO:tensorflow:Starting iteration 23

Steps executed: 271 Episode length: 79 Return: -159.37819060428120595
INFO:tensorflow:Average training steps per second: 344.47
I0902 18:16:38.944072 140182397114368 replay_runner.py:36] Average training steps per second: 344.47
I0902 18:16:39.112279 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.63
INFO:tensorflow:Starting iteration 24

Steps executed: 233 Episode length: 85 Return: -23.102484161918383595
INFO:tensorflow:Average training steps per second: 357.62
I0902 18:16:45.255946 140182397114368 replay_runner.py:36] Average training steps per second: 357.62
I0902 18:16:45.380106 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.01
INFO:tensorflow:Starting iteration 25

Steps executed: 254 Episode length: 144 Return: -168.1406839482756795
INFO:tensorflow:Average training steps per second: 358.23
I0902 18:16:51.655433 140182397114368 replay_runner.py:36] Average training steps per second: 358.23
I0902 18:16:51.796825 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.52
INFO:tensorflow:Starting iteration 26

Steps executed: 214 Episode length: 214 Return: -508.4882127058284795
INFO:tensorflow:Average training steps per second: 351.45
I0902 18:16:58.110575 140182397114368 replay_runner.py:36] Average training steps per second: 351.45
I0902 18:16:58.235447 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -508.49
INFO:tensorflow:Starting iteration 27

Steps executed: 231 Episode length: 72 Return: -351.37047880124703795
INFO:tensorflow:Average training steps per second: 342.26
I0902 18:17:04.543784 140182397114368 replay_runner.py:36] Average training steps per second: 342.26
I0902 18:17:04.642342 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.22
INFO:tensorflow:Starting iteration 28

Steps executed: 200 Episode length: 63 Return: -334.35829361580776795
INFO:tensorflow:Average training steps per second: 346.05
I0902 18:17:10.894277 140182397114368 replay_runner.py:36] Average training steps per second: 346.05
I0902 18:17:10.998199 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.26
INFO:tensorflow:Starting iteration 29

Steps executed: 200 Episode length: 109 Return: -150.6730208698119895
INFO:tensorflow:Average training steps per second: 352.67
I0902 18:17:17.259931 140182397114368 replay_runner.py:36] Average training steps per second: 352.67

Done fixed training!Episode length: 109 Return: -150.6730208698119895