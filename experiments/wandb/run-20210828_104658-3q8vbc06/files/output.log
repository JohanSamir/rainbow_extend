Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0828 10:47:03.585127 140053337282560 run_experiment.py:549] Creating TrainRunner ...
I0828 10:47:03.592673 140053337282560 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:47:03.592828 140053337282560 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:47:03.592944 140053337282560 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:47:03.593055 140053337282560 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:47:03.593210 140053337282560 dqn_agent.py:275] 	 update_period: 4
I0828 10:47:03.593318 140053337282560 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:47:03.593447 140053337282560 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:47:03.593551 140053337282560 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:47:03.593682 140053337282560 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:47:03.593814 140053337282560 dqn_agent.py:280] 	 optimizer: adam
I0828 10:47:03.593997 140053337282560 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:47:03.594084 140053337282560 dqn_agent.py:283] 	 seed: 1630147623592637
I0828 10:47:03.596491 140053337282560 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:47:03.596612 140053337282560 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:47:03.596692 140053337282560 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:47:03.596789 140053337282560 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:47:03.596861 140053337282560 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:47:03.596939 140053337282560 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:47:03.597021 140053337282560 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:47:03.597105 140053337282560 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:47:03.597170 140053337282560 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:47:03.621564 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:03.885029 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:03.894026 140053337282560 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:47:03.900326 140053337282560 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:47:03.900455 140053337282560 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:47:03.900527 140053337282560 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:47:03.900588 140053337282560 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:47:03.900644 140053337282560 dqn_agent.py:275] 	 update_period: 4
I0828 10:47:03.900717 140053337282560 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:47:03.900785 140053337282560 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:47:03.900875 140053337282560 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:47:03.900939 140053337282560 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:47:03.901006 140053337282560 dqn_agent.py:280] 	 optimizer: adam
I0828 10:47:03.901102 140053337282560 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:47:03.901160 140053337282560 dqn_agent.py:283] 	 seed: 1630147623900299
I0828 10:47:03.903171 140053337282560 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:47:03.903295 140053337282560 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:47:03.903395 140053337282560 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:47:03.903592 140053337282560 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:47:03.903791 140053337282560 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:47:03.904016 140053337282560 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:47:03.904175 140053337282560 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:47:03.904289 140053337282560 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:47:03.904433 140053337282560 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:47:03.929539 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:03.946294 140053337282560 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:47:03.946686 140053337282560 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 238.86
I0828 10:47:08.133629 140053337282560 replay_runner.py:36] Average training steps per second: 238.86
I0828 10:47:08.898010 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -396.90
Steps executed: 250 Episode length: 93 Return: -396.87521074410044
INFO:tensorflow:Starting iteration 1
I0828 10:47:12.285363 140053337282560 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 344.28

Steps executed: 269 Episode length: 168 Return: -305.69978371274436
I0828 10:47:15.341298 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.72
INFO:tensorflow:Starting iteration 2

Steps executed: 405 Episode length: 248 Return: -502.10011707804385
INFO:tensorflow:Average training steps per second: 345.56
I0828 10:47:21.685595 140053337282560 replay_runner.py:36] Average training steps per second: 345.56
I0828 10:47:21.988703 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -362.32
INFO:tensorflow:Starting iteration 3
I0828 10:47:25.390681 140053337282560 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 343.73

Steps executed: 1000 Episode length: 1000 Return: -124.74025531690656
I0828 10:47:30.486570 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.74
INFO:tensorflow:Starting iteration 4
I0828 10:47:33.875581 140053337282560 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 339.76

Steps executed: 1000 Episode length: 1000 Return: -106.22152957712466
I0828 10:47:38.788438 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.22
INFO:tensorflow:Starting iteration 5
I0828 10:47:42.173124 140053337282560 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 353.20

Steps executed: 1000 Episode length: 1000 Return: -56.947786135849756
I0828 10:47:46.690487 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -56.95
INFO:tensorflow:Starting iteration 6
I0828 10:47:49.956266 140053337282560 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 338.90

Steps executed: 1000 Episode length: 1000 Return: -70.485905556773736
I0828 10:47:55.576582 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.49
INFO:tensorflow:Starting iteration 7
I0828 10:47:58.908411 140053337282560 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 327.71

Steps executed: 1000 Episode length: 1000 Return: -90.048464692100386
I0828 10:48:04.320953 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.05
INFO:tensorflow:Starting iteration 8
I0828 10:48:07.728606 140053337282560 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 343.21

Steps executed: 1000 Episode length: 1000 Return: -115.82292479763075
I0828 10:48:12.165205 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.82
INFO:tensorflow:Starting iteration 9

Steps executed: 660 Episode length: 660 Return: -659.5149951591645075
INFO:tensorflow:Average training steps per second: 348.80
I0828 10:48:18.453971 140053337282560 replay_runner.py:36] Average training steps per second: 348.80
I0828 10:48:19.394153 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -659.51
INFO:tensorflow:Starting iteration 10

Steps executed: 588 Episode length: 588 Return: -555.2827379141188075
INFO:tensorflow:Average training steps per second: 348.01
I0828 10:48:25.727294 140053337282560 replay_runner.py:36] Average training steps per second: 348.01
I0828 10:48:26.484413 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -555.28
INFO:tensorflow:Starting iteration 11

Steps executed: 218 Episode length: 218 Return: -31.58956499275174775
INFO:tensorflow:Average training steps per second: 340.56
I0828 10:48:32.849887 140053337282560 replay_runner.py:36] Average training steps per second: 340.56
I0828 10:48:32.987272 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -31.59
INFO:tensorflow:Starting iteration 12

Steps executed: 264 Episode length: 73 Return: -84.927015219687424675
INFO:tensorflow:Average training steps per second: 336.75
I0828 10:48:39.283084 140053337282560 replay_runner.py:36] Average training steps per second: 336.75
I0828 10:48:39.421321 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.41
INFO:tensorflow:Starting iteration 13
I0828 10:48:42.749057 140053337282560 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 338.21

Steps executed: 203 Episode length: 203 Return: -266.3686095224590575
I0828 10:48:45.841296 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.37
INFO:tensorflow:Starting iteration 14

Steps executed: 418 Episode length: 418 Return: -205.2351292465187575
INFO:tensorflow:Average training steps per second: 351.70
I0828 10:48:52.019272 140053337282560 replay_runner.py:36] Average training steps per second: 351.70
I0828 10:48:52.496698 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.24
INFO:tensorflow:Starting iteration 15

Steps executed: 268 Episode length: 268 Return: -287.7684574521942575
INFO:tensorflow:Average training steps per second: 388.99
I0828 10:48:58.490419 140053337282560 replay_runner.py:36] Average training steps per second: 388.99
I0828 10:48:58.721061 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.77
INFO:tensorflow:Starting iteration 16

Steps executed: 282 Episode length: 127 Return: -676.8194102610656575
INFO:tensorflow:Average training steps per second: 403.07
I0828 10:49:04.806579 140053337282560 replay_runner.py:36] Average training steps per second: 403.07
I0828 10:49:04.959909 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -628.36
INFO:tensorflow:Starting iteration 17

Steps executed: 277 Episode length: 115 Return: -225.1866654907217775
INFO:tensorflow:Average training steps per second: 342.04
I0828 10:49:11.284367 140053337282560 replay_runner.py:36] Average training steps per second: 342.04
I0828 10:49:11.406095 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.69
INFO:tensorflow:Starting iteration 18
I0828 10:49:14.530551 140053337282560 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 322.64
I0828 10:49:17.630257 140053337282560 replay_runner.py:36] Average training steps per second: 322.64

Steps executed: 233 Episode length: 85 Return: -172.77133050269845775
INFO:tensorflow:Starting iteration 19
I0828 10:49:20.822867 140053337282560 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 312.84

Steps executed: 240 Episode length: 240 Return: -185.6063568410115275
I0828 10:49:24.198064 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.61
INFO:tensorflow:Starting iteration 20

Steps executed: 213 Episode length: 213 Return: -247.5527541861438275
INFO:tensorflow:Average training steps per second: 326.88
I0828 10:49:30.412480 140053337282560 replay_runner.py:36] Average training steps per second: 326.88
I0828 10:49:30.571987 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -247.55
INFO:tensorflow:Starting iteration 21

Steps executed: 391 Episode length: 259 Return: -257.3057919667266375
INFO:tensorflow:Average training steps per second: 316.93
I0828 10:49:36.997968 140053337282560 replay_runner.py:36] Average training steps per second: 316.93
I0828 10:49:37.295249 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.96
INFO:tensorflow:Starting iteration 22
I0828 10:49:40.484133 140053337282560 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 321.27

Steps executed: 274 Episode length: 139 Return: -147.3794090516668375
I0828 10:49:43.766431 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.36
INFO:tensorflow:Starting iteration 23

Steps executed: 380 Episode length: 190 Return: -263.9236917815184675
INFO:tensorflow:Average training steps per second: 327.31
I0828 10:49:50.103873 140053337282560 replay_runner.py:36] Average training steps per second: 327.31
I0828 10:49:50.359050 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -371.97
INFO:tensorflow:Starting iteration 24

Steps executed: 278 Episode length: 173 Return: -431.4823936610858675
INFO:tensorflow:Average training steps per second: 329.29
I0828 10:49:56.662203 140053337282560 replay_runner.py:36] Average training steps per second: 329.29
I0828 10:49:56.871029 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -536.00
INFO:tensorflow:Starting iteration 25

Steps executed: 220 Episode length: 220 Return: -52.65374454170263675
INFO:tensorflow:Average training steps per second: 320.88
I0828 10:50:03.167164 140053337282560 replay_runner.py:36] Average training steps per second: 320.88
I0828 10:50:03.376377 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -52.65
INFO:tensorflow:Starting iteration 26

Steps executed: 158 Episode length: 158 Return: -209.9506063604726875
INFO:tensorflow:Average training steps per second: 328.31

Steps executed: 323 Episode length: 165 Return: -95.99215182748225875
I0828 10:50:09.868399 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.97
INFO:tensorflow:Starting iteration 27
I0828 10:50:13.163759 140053337282560 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 326.28

Steps executed: 1000 Episode length: 1000 Return: -46.050701176507575
I0828 10:50:18.444659 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -46.05
INFO:tensorflow:Starting iteration 28

Steps executed: 675 Episode length: 502 Return: -591.4911643296667575
INFO:tensorflow:Average training steps per second: 327.81
I0828 10:50:24.799182 140053337282560 replay_runner.py:36] Average training steps per second: 327.81
I0828 10:50:25.511176 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -669.57
INFO:tensorflow:Starting iteration 29

Steps executed: 281 Episode length: 128 Return: -127.9505741685314375
INFO:tensorflow:Average training steps per second: 347.33
I0828 10:50:31.589808 140053337282560 replay_runner.py:36] Average training steps per second: 347.33

Done fixed training!Episode length: 128 Return: -127.9505741685314375