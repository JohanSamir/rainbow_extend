I0828 10:42:31.965595 139779140274176 run_experiment.py:549] Creating TrainRunner ...
I0828 10:42:31.978607 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:31.978949 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:31.979169 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:31.979398 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:31.979557 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:31.979948 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:31.980202 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:31.980442 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:31.980631 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:31.980740 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:31.980875 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:31.981010 139779140274176 dqn_agent.py:283] 	 seed: 1630147351978534
I0828 10:42:31.984749 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:31.985055 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:31.985186 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:31.985276 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:31.985356 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:31.985438 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:31.985510 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:31.985619 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:31.985730 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:32.028639 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:32.417716 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:32.432599 139779140274176 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:42:32.441921 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:32.442218 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:32.442377 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:32.442507 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:32.442622 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:32.442734 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:32.442838 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:32.442950 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:32.443058 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:32.443310 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:32.443463 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:32.443588 139779140274176 dqn_agent.py:283] 	 seed: 1630147352441862
I0828 10:42:32.446380 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:32.446572 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:32.446697 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:32.446828 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:32.446994 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:32.447114 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:32.447232 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:32.448159 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:32.448370 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:32.515028 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:32.537200 139779140274176 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:42:32.537448 139779140274176 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 168.79
I0828 10:42:38.462252 139779140274176 replay_runner.py:36] Average training steps per second: 168.79
Steps executed: 299 Episode length: 118 Return: -356.14605716567996
I0828 10:42:39.711321 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -378.84
INFO:tensorflow:Starting iteration 1
I0828 10:42:43.922313 139779140274176 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 221.34

Steps executed: 1000 Episode length: 1000 Return: -137.74518911704362
I0828 10:42:51.786426 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.75
INFO:tensorflow:Starting iteration 2
I0828 10:42:56.202063 139779140274176 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 224.51

Steps executed: 1000 Episode length: 1000 Return: -106.29188466140852
I0828 10:43:03.512102 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.29
INFO:tensorflow:Starting iteration 3

Steps executed: 1000 Episode length: 1000 Return: -114.62456459623753
INFO:tensorflow:Average training steps per second: 238.50
I0828 10:43:11.961833 139779140274176 replay_runner.py:36] Average training steps per second: 238.50
I0828 10:43:13.710150 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.62
INFO:tensorflow:Starting iteration 4

Steps executed: 166 Episode length: 166 Return: -542.9252525257923753
INFO:tensorflow:Average training steps per second: 237.29

Steps executed: 1166 Episode length: 1000 Return: -195.16265878604256
I0828 10:43:24.599835 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -369.04
INFO:tensorflow:Starting iteration 5
I0828 10:43:28.842716 139779140274176 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 232.56

Steps executed: 1000 Episode length: 1000 Return: -153.53390078112596
I0828 10:43:35.486781 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.53
INFO:tensorflow:Starting iteration 6

Steps executed: 249 Episode length: 249 Return: -154.2997792298823896
INFO:tensorflow:Average training steps per second: 230.57
I0828 10:43:44.224534 139779140274176 replay_runner.py:36] Average training steps per second: 230.57
I0828 10:43:44.494098 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.30
INFO:tensorflow:Starting iteration 7
I0828 10:43:48.806793 139779140274176 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 227.16

Steps executed: 1000 Episode length: 1000 Return: -196.05453635071248
I0828 10:43:55.928628 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.05
INFO:tensorflow:Starting iteration 8

Steps executed: 299 Episode length: 299 Return: -36.57227899246241548
INFO:tensorflow:Average training steps per second: 154.42
I0828 10:44:06.801500 139779140274176 replay_runner.py:36] Average training steps per second: 154.42
I0828 10:44:07.144182 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -36.57
INFO:tensorflow:Starting iteration 9

Steps executed: 88 Episode length: 88 Return: -172.587205602445641548
INFO:tensorflow:Average training steps per second: 221.21

Steps executed: 282 Episode length: 194 Return: -86.85404619948997548
I0828 10:44:16.225774 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.72
INFO:tensorflow:Starting iteration 10

Steps executed: 92 Episode length: 92 Return: -103.243981514580617548
INFO:tensorflow:Average training steps per second: 229.69

Steps executed: 895 Episode length: 803 Return: -280.1145642426657548
I0828 10:44:26.463031 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.68
INFO:tensorflow:Starting iteration 11

Steps executed: 348 Episode length: 205 Return: -123.8780395747024348
INFO:tensorflow:Average training steps per second: 227.35
I0828 10:44:35.207033 139779140274176 replay_runner.py:36] Average training steps per second: 227.35
I0828 10:44:35.549110 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.90
INFO:tensorflow:Starting iteration 12
I0828 10:44:39.832824 139779140274176 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 227.81

Steps executed: 333 Episode length: 157 Return: -135.3727209109815348
I0828 10:44:44.494228 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.97
INFO:tensorflow:Starting iteration 13

Steps executed: 344 Episode length: 239 Return: -411.2038076835415648
INFO:tensorflow:Average training steps per second: 235.44
I0828 10:44:52.950465 139779140274176 replay_runner.py:36] Average training steps per second: 235.44
I0828 10:44:53.299308 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.84
INFO:tensorflow:Starting iteration 14
I0828 10:44:57.430237 139779140274176 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 229.99
I0828 10:45:01.778856 139779140274176 replay_runner.py:36] Average training steps per second: 229.99

Steps executed: 295 Episode length: 295 Return: -114.2169541923810848
INFO:tensorflow:Starting iteration 15

Steps executed: 273 Episode length: 138 Return: -99.05630244036946448
INFO:tensorflow:Average training steps per second: 242.30
I0828 10:45:10.768921 139779140274176 replay_runner.py:36] Average training steps per second: 242.30
I0828 10:45:11.009739 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.60
INFO:tensorflow:Starting iteration 16

Steps executed: 322 Episode length: 123 Return: -64.19438565969083448
INFO:tensorflow:Average training steps per second: 249.53
I0828 10:45:19.244458 139779140274176 replay_runner.py:36] Average training steps per second: 249.53
I0828 10:45:19.563933 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.91
INFO:tensorflow:Starting iteration 17

Steps executed: 86 Episode length: 86 Return: -206.328192979729443448
INFO:tensorflow:Average training steps per second: 251.47

Steps executed: 1065 Episode length: 979 Return: -132.078920967671258
I0828 10:45:29.394721 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.20
INFO:tensorflow:Starting iteration 18

Steps executed: 255 Episode length: 62 Return: -353.17971239369725258
INFO:tensorflow:Average training steps per second: 255.95
I0828 10:45:37.245563 139779140274176 replay_runner.py:36] Average training steps per second: 255.95
I0828 10:45:37.427396 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -411.39
INFO:tensorflow:Starting iteration 19

Steps executed: 62 Episode length: 62 Return: -226.526603510011285258
INFO:tensorflow:Average training steps per second: 260.37

Steps executed: 1062 Episode length: 1000 Return: -185.28405278314788
I0828 10:45:47.192577 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.91
INFO:tensorflow:Starting iteration 20

Steps executed: 239 Episode length: 62 Return: -209.51663518026302788
INFO:tensorflow:Average training steps per second: 268.81
I0828 10:45:54.778029 139779140274176 replay_runner.py:36] Average training steps per second: 268.81
I0828 10:45:54.953141 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -183.65
INFO:tensorflow:Starting iteration 21

Steps executed: 227 Episode length: 73 Return: -55.548617570428874788
INFO:tensorflow:Average training steps per second: 275.04
I0828 10:46:02.467115 139779140274176 replay_runner.py:36] Average training steps per second: 275.04
I0828 10:46:02.624992 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.82
INFO:tensorflow:Starting iteration 22

Steps executed: 118 Episode length: 118 Return: 16.346603448493312788
INFO:tensorflow:Average training steps per second: 292.08
I0828 10:46:09.824252 139779140274176 replay_runner.py:36] Average training steps per second: 292.08

Steps executed: 502 Episode length: 384 Return: 275.38022242294835788
INFO:tensorflow:Starting iteration 23

Steps executed: 272 Episode length: 110 Return: 23.084322228030365788
INFO:tensorflow:Average training steps per second: 299.52
I0828 10:46:17.465264 139779140274176 replay_runner.py:36] Average training steps per second: 299.52
I0828 10:46:17.654814 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.77
INFO:tensorflow:Starting iteration 24

Steps executed: 360 Episode length: 186 Return: -446.6173691940013788
INFO:tensorflow:Average training steps per second: 326.13
I0828 10:46:24.157931 139779140274176 replay_runner.py:36] Average training steps per second: 326.13
I0828 10:46:24.393836 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.00
INFO:tensorflow:Starting iteration 25

Steps executed: 299 Episode length: 126 Return: -15.56212444268786788
INFO:tensorflow:Average training steps per second: 322.56
I0828 10:46:30.832110 139779140274176 replay_runner.py:36] Average training steps per second: 322.56
I0828 10:46:31.025591 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.21
INFO:tensorflow:Starting iteration 26

Steps executed: 261 Episode length: 78 Return: -586.44097891470156788
INFO:tensorflow:Average training steps per second: 328.30
I0828 10:46:37.385636 139779140274176 replay_runner.py:36] Average training steps per second: 328.30
I0828 10:46:37.540756 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -427.05
INFO:tensorflow:Starting iteration 27

Steps executed: 232 Episode length: 77 Return: -345.13975415352076788
INFO:tensorflow:Average training steps per second: 330.44
I0828 10:46:43.819205 139779140274176 replay_runner.py:36] Average training steps per second: 330.44
I0828 10:46:43.920438 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.56
INFO:tensorflow:Starting iteration 28

Steps executed: 222 Episode length: 83 Return: -607.87414843092117788
INFO:tensorflow:Average training steps per second: 339.02
I0828 10:46:49.777169 139779140274176 replay_runner.py:36] Average training steps per second: 339.02
I0828 10:46:49.888794 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -509.05
INFO:tensorflow:Starting iteration 29

Steps executed: 261 Episode length: 88 Return: -596.73346038905777788
INFO:tensorflow:Average training steps per second: 375.27
I0828 10:46:55.716928 139779140274176 replay_runner.py:36] Average training steps per second: 375.27

Done fixed training!Episode length: 88 Return: -596.73346038905777788