Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0902 00:05:00.201899 140252174653440 run_experiment.py:549] Creating TrainRunner ...
I0902 00:05:00.223774 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:05:00.224014 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:05:00.227407 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:05:00.227631 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:05:00.228269 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0902 00:05:00.228450 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:05:00.228919 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:05:00.229091 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:05:00.229224 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:05:00.229353 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0902 00:05:00.229481 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:05:00.229586 140252174653440 dqn_agent.py:283] 	 seed: 1630541100223709
I0902 00:05:00.232758 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:05:00.232938 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:05:00.233063 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:05:00.233175 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:05:00.233277 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:05:00.233376 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:05:00.233473 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:05:00.233577 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:05:00.233673 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:05:00.266755 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:00.726642 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:00.744901 140252174653440 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:05:00.769268 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:05:00.769798 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:05:00.770312 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:05:00.770581 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:05:00.770849 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0902 00:05:00.771101 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:05:00.771345 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:05:00.771596 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:05:00.771866 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:05:00.772114 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0902 00:05:00.772354 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:05:00.772476 140252174653440 dqn_agent.py:283] 	 seed: 1630541100769011
I0902 00:05:00.775975 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:05:00.776372 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:05:00.776719 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:05:00.777027 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:05:00.777253 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:05:00.777495 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:05:00.777733 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:05:00.777951 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:05:00.778193 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:05:00.819224 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:00.842164 140252174653440 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:05:00.842417 140252174653440 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 167.15
I0902 00:05:06.825469 140252174653440 replay_runner.py:36] Average training steps per second: 167.15
Steps executed: 247 Episode length: 86 Return: -328.61330895341416
I0902 00:05:08.239618 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.96
INFO:tensorflow:Starting iteration 1

Steps executed: 200 Episode length: 116 Return: -543.4497917876919
INFO:tensorflow:Average training steps per second: 219.70
I0902 00:05:17.233963 140252174653440 replay_runner.py:36] Average training steps per second: 219.70
I0902 00:05:17.417331 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -472.75
INFO:tensorflow:Starting iteration 2

Steps executed: 249 Episode length: 151 Return: -603.4480720213966
INFO:tensorflow:Average training steps per second: 222.74
I0902 00:05:26.149253 140252174653440 replay_runner.py:36] Average training steps per second: 222.74
I0902 00:05:26.367194 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -505.47
INFO:tensorflow:Starting iteration 3

Steps executed: 266 Episode length: 266 Return: -327.7097589826967
INFO:tensorflow:Average training steps per second: 226.64
I0902 00:05:35.199232 140252174653440 replay_runner.py:36] Average training steps per second: 226.64
I0902 00:05:35.524509 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.71
INFO:tensorflow:Starting iteration 4

Steps executed: 383 Episode length: 202 Return: -374.97857980094054
INFO:tensorflow:Average training steps per second: 231.78
I0902 00:05:44.220992 140252174653440 replay_runner.py:36] Average training steps per second: 231.78
I0902 00:05:44.570905 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -425.05
INFO:tensorflow:Starting iteration 5

Steps executed: 389 Episode length: 389 Return: -274.28377654065354
INFO:tensorflow:Average training steps per second: 231.25
I0902 00:05:53.122881 140252174653440 replay_runner.py:36] Average training steps per second: 231.25
I0902 00:05:53.755956 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.28
INFO:tensorflow:Starting iteration 6
I0902 00:05:57.986713 140252174653440 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 225.75

Steps executed: 1000 Episode length: 1000 Return: -112.84005045258041
I0902 00:06:04.454675 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.84
INFO:tensorflow:Starting iteration 7
I0902 00:06:08.781090 140252174653440 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 227.99
I0902 00:06:13.167781 140252174653440 replay_runner.py:36] Average training steps per second: 227.99

Steps executed: 1000 Episode length: 1000 Return: -109.83984667383798
INFO:tensorflow:Starting iteration 8

Steps executed: 358 Episode length: 199 Return: -306.0608802151438798
INFO:tensorflow:Average training steps per second: 222.29
I0902 00:06:25.050612 140252174653440 replay_runner.py:36] Average training steps per second: 222.29
I0902 00:06:25.402352 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -636.67
INFO:tensorflow:Starting iteration 9
I0902 00:06:29.706431 140252174653440 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 224.57

Steps executed: 282 Episode length: 282 Return: -277.2960267478979798
I0902 00:06:34.515438 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.30
INFO:tensorflow:Starting iteration 10
I0902 00:06:38.917905 140252174653440 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 228.38

Steps executed: 1000 Episode length: 1000 Return: -202.33229229341798
I0902 00:06:47.685560 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.33
INFO:tensorflow:Starting iteration 11
I0902 00:06:51.994455 140252174653440 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 224.25

Steps executed: 1000 Episode length: 1000 Return: -224.08789682078915
I0902 00:06:59.209397 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.09
INFO:tensorflow:Starting iteration 12

Steps executed: 256 Episode length: 68 Return: -438.57278478878883915
INFO:tensorflow:Average training steps per second: 220.49
I0902 00:07:08.093755 140252174653440 replay_runner.py:36] Average training steps per second: 220.49
I0902 00:07:08.335182 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -399.75
INFO:tensorflow:Starting iteration 13

Steps executed: 265 Episode length: 265 Return: -223.1588476467136415
INFO:tensorflow:Average training steps per second: 224.66
I0902 00:07:17.187878 140252174653440 replay_runner.py:36] Average training steps per second: 224.66
I0902 00:07:17.480519 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.16
INFO:tensorflow:Starting iteration 14
I0902 00:07:21.849415 140252174653440 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 217.96

Steps executed: 1000 Episode length: 1000 Return: -331.14835258598055
I0902 00:07:29.675464 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.15
INFO:tensorflow:Starting iteration 15
I0902 00:07:34.113887 140252174653440 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 224.61

Steps executed: 232 Episode length: 77 Return: -207.59841190976914555
I0902 00:07:38.754800 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.56
INFO:tensorflow:Starting iteration 16

Steps executed: 439 Episode length: 286 Return: -328.1428337703692455
INFO:tensorflow:Average training steps per second: 226.87
I0902 00:07:47.435711 140252174653440 replay_runner.py:36] Average training steps per second: 226.87
I0902 00:07:47.934848 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.01
INFO:tensorflow:Starting iteration 17

Steps executed: 274 Episode length: 137 Return: -333.1559028729647455
INFO:tensorflow:Average training steps per second: 219.81
I0902 00:07:56.778368 140252174653440 replay_runner.py:36] Average training steps per second: 219.81
I0902 00:07:57.038051 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -370.94
INFO:tensorflow:Starting iteration 18

Steps executed: 140 Episode length: 140 Return: -747.4176821225726455
INFO:tensorflow:Average training steps per second: 224.65
I0902 00:08:05.798398 140252174653440 replay_runner.py:36] Average training steps per second: 224.65

Steps executed: 376 Episode length: 236 Return: -549.2874587520864455
INFO:tensorflow:Starting iteration 19

Steps executed: 419 Episode length: 358 Return: -395.8991873473131455
INFO:tensorflow:Average training steps per second: 231.77
I0902 00:08:14.990206 140252174653440 replay_runner.py:36] Average training steps per second: 231.77
I0902 00:08:15.528729 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.01
INFO:tensorflow:Starting iteration 20
I0902 00:08:19.933862 140252174653440 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 225.43

Steps executed: 290 Episode length: 105 Return: -52.54367783666738455
I0902 00:08:24.620504 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.21
INFO:tensorflow:Starting iteration 21

Steps executed: 223 Episode length: 57 Return: -102.73490150463266455
INFO:tensorflow:Average training steps per second: 219.59
I0902 00:08:33.557680 140252174653440 replay_runner.py:36] Average training steps per second: 219.59
I0902 00:08:33.741718 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.01
INFO:tensorflow:Starting iteration 22

Steps executed: 301 Episode length: 111 Return: -160.2206618031350455
INFO:tensorflow:Average training steps per second: 227.53
I0902 00:08:42.508373 140252174653440 replay_runner.py:36] Average training steps per second: 227.53
I0902 00:08:42.775139 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.39
INFO:tensorflow:Starting iteration 23

Steps executed: 264 Episode length: 77 Return: -146.86790076359151455
INFO:tensorflow:Average training steps per second: 241.42
I0902 00:08:51.315742 140252174653440 replay_runner.py:36] Average training steps per second: 241.42
I0902 00:08:51.505527 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.67
INFO:tensorflow:Starting iteration 24

Steps executed: 262 Episode length: 75 Return: -333.81953729304234455
INFO:tensorflow:Average training steps per second: 242.85
I0902 00:08:59.993155 140252174653440 replay_runner.py:36] Average training steps per second: 242.85
I0902 00:09:00.212658 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.58
INFO:tensorflow:Starting iteration 25

Steps executed: 307 Episode length: 136 Return: -473.4815212448696455
INFO:tensorflow:Average training steps per second: 232.62
I0902 00:09:08.885243 140252174653440 replay_runner.py:36] Average training steps per second: 232.62
I0902 00:09:09.137350 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.98
INFO:tensorflow:Starting iteration 26

Steps executed: 262 Episode length: 73 Return: -65.136161867411068455
INFO:tensorflow:Average training steps per second: 232.17
I0902 00:09:17.772121 140252174653440 replay_runner.py:36] Average training steps per second: 232.17
I0902 00:09:17.989516 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.70
INFO:tensorflow:Starting iteration 27
I0902 00:09:22.368752 140252174653440 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 229.13

Steps executed: 362 Episode length: 168 Return: -683.8945226331537455
I0902 00:09:27.107321 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -702.86
INFO:tensorflow:Starting iteration 28

Steps executed: 262 Episode length: 76 Return: -434.77406851732716455
INFO:tensorflow:Average training steps per second: 227.76
I0902 00:09:36.023026 140252174653440 replay_runner.py:36] Average training steps per second: 227.76
I0902 00:09:36.252317 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -367.04
INFO:tensorflow:Starting iteration 29

Steps executed: 223 Episode length: 73 Return: -644.54136455781186455
INFO:tensorflow:Average training steps per second: 232.02
I0902 00:09:44.922020 140252174653440 replay_runner.py:36] Average training steps per second: 232.02

Done fixed training!Episode length: 73 Return: -644.54136455781186455