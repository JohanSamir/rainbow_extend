Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0901 12:25:08.484029 140460307478528 run_experiment.py:549] Creating TrainRunner ...
I0901 12:25:08.494907 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:25:08.495142 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:25:08.495318 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:25:08.495462 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:25:08.495574 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 12:25:08.495651 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:25:08.495760 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:25:08.495930 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:25:08.496034 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:25:08.496153 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 12:25:08.496226 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:25:08.496305 140460307478528 dqn_agent.py:283] 	 seed: 1630499108494847
I0901 12:25:08.498846 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:25:08.499021 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:25:08.499122 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:25:08.499232 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:25:08.499299 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:25:08.499354 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:25:08.499407 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:25:08.499489 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:25:08.499550 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:25:08.734703 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:09.139660 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:09.152831 140460307478528 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:25:09.164461 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:25:09.164793 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:25:09.165084 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:25:09.165190 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:25:09.165295 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 12:25:09.165400 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:25:09.165651 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:25:09.165842 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:25:09.165956 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:25:09.166135 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 12:25:09.166354 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:25:09.166478 140460307478528 dqn_agent.py:283] 	 seed: 1630499109164379
I0901 12:25:09.169180 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:25:09.169390 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:25:09.169584 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:25:09.169740 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:25:09.169829 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:25:09.169911 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:25:09.170003 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:25:09.170062 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:25:09.170200 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:25:09.199892 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:09.220309 140460307478528 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:25:09.220924 140460307478528 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 160.48
I0901 12:25:15.452507 140460307478528 replay_runner.py:36] Average training steps per second: 160.48
Steps executed: 259 Episode length: 107 Return: -604.8912232853672
I0901 12:25:16.671084 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -618.07
INFO:tensorflow:Starting iteration 1

Steps executed: 271 Episode length: 130 Return: -31.261677711311094
INFO:tensorflow:Average training steps per second: 225.43
I0901 12:25:25.298507 140460307478528 replay_runner.py:36] Average training steps per second: 225.43
I0901 12:25:25.510641 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -9.89
INFO:tensorflow:Starting iteration 2

Steps executed: 211 Episode length: 118 Return: -67.982317067112324
INFO:tensorflow:Average training steps per second: 218.92
I0901 12:25:34.491868 140460307478528 replay_runner.py:36] Average training steps per second: 218.92
I0901 12:25:34.681694 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.19
INFO:tensorflow:Starting iteration 3

Steps executed: 227 Episode length: 85 Return: -667.597439872093984
INFO:tensorflow:Average training steps per second: 220.66
I0901 12:25:43.641208 140460307478528 replay_runner.py:36] Average training steps per second: 220.66
I0901 12:25:43.878762 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -562.49
INFO:tensorflow:Starting iteration 4

Steps executed: 222 Episode length: 86 Return: -259.084786884001924
INFO:tensorflow:Average training steps per second: 220.58
I0901 12:25:52.799338 140460307478528 replay_runner.py:36] Average training steps per second: 220.58
I0901 12:25:52.997768 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.15
INFO:tensorflow:Starting iteration 5
I0901 12:25:57.390065 140460307478528 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 214.70

Steps executed: 286 Episode length: 286 Return: -29.353779836371828
I0901 12:26:02.402496 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -29.35
INFO:tensorflow:Starting iteration 6

Steps executed: 334 Episode length: 151 Return: -177.68326415673351
INFO:tensorflow:Average training steps per second: 219.63
I0901 12:26:11.458665 140460307478528 replay_runner.py:36] Average training steps per second: 219.63
I0901 12:26:11.778359 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -417.55
INFO:tensorflow:Starting iteration 7

Steps executed: 276 Episode length: 141 Return: -234.74972130184591
INFO:tensorflow:Average training steps per second: 215.64
I0901 12:26:20.920717 140460307478528 replay_runner.py:36] Average training steps per second: 215.64
I0901 12:26:21.205210 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.36
INFO:tensorflow:Starting iteration 8
I0901 12:26:25.610729 140460307478528 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 216.05

Steps executed: 296 Episode length: 161 Return: -258.62757388166631
I0901 12:26:30.555997 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.38
INFO:tensorflow:Starting iteration 9

Steps executed: 304 Episode length: 182 Return: -376.83385850785266
INFO:tensorflow:Average training steps per second: 217.19
I0901 12:26:39.687906 140460307478528 replay_runner.py:36] Average training steps per second: 217.19
I0901 12:26:39.978154 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -401.80
INFO:tensorflow:Starting iteration 10

Steps executed: 279 Episode length: 139 Return: -197.42940032788015
INFO:tensorflow:Average training steps per second: 219.07
I0901 12:26:49.034442 140460307478528 replay_runner.py:36] Average training steps per second: 219.07
I0901 12:26:49.291112 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.95
INFO:tensorflow:Starting iteration 11

Steps executed: 258 Episode length: 96 Return: -237.395082715845325
INFO:tensorflow:Average training steps per second: 222.68
I0901 12:26:58.794236 140460307478528 replay_runner.py:36] Average training steps per second: 222.68
I0901 12:26:59.003702 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.93
INFO:tensorflow:Starting iteration 12

Steps executed: 345 Episode length: 254 Return: 230.013688536514375
INFO:tensorflow:Average training steps per second: 219.77
I0901 12:27:07.653509 140460307478528 replay_runner.py:36] Average training steps per second: 219.77
I0901 12:27:08.031313 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -1.01
INFO:tensorflow:Starting iteration 13

Steps executed: 202 Episode length: 94 Return: -705.116364522563155
INFO:tensorflow:Average training steps per second: 214.68
I0901 12:27:17.251587 140460307478528 replay_runner.py:36] Average training steps per second: 214.68
I0901 12:27:17.442312 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -503.65
INFO:tensorflow:Starting iteration 14

Steps executed: 86 Episode length: 86 Return: -491.9897766842661355
INFO:tensorflow:Average training steps per second: 217.28

Steps executed: 350 Episode length: 158 Return: -188.15504221277982
I0901 12:27:26.873956 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.66
INFO:tensorflow:Starting iteration 15

Steps executed: 377 Episode length: 193 Return: 20.5900383100803172
INFO:tensorflow:Average training steps per second: 220.52
I0901 12:27:35.723847 140460307478528 replay_runner.py:36] Average training steps per second: 220.52
I0901 12:27:36.101748 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: 30.89
INFO:tensorflow:Starting iteration 16

Steps executed: 266 Episode length: 122 Return: -242.12827985217695
INFO:tensorflow:Average training steps per second: 216.82
I0901 12:27:45.139777 140460307478528 replay_runner.py:36] Average training steps per second: 216.82
I0901 12:27:45.388598 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.35
INFO:tensorflow:Starting iteration 17

Steps executed: 275 Episode length: 153 Return: -56.659060997398426
INFO:tensorflow:Average training steps per second: 226.36
I0901 12:27:54.109010 140460307478528 replay_runner.py:36] Average training steps per second: 226.36
I0901 12:27:54.328707 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.60
INFO:tensorflow:Starting iteration 18

Steps executed: 285 Episode length: 156 Return: -246.99642358883193
INFO:tensorflow:Average training steps per second: 226.40
I0901 12:28:02.964985 140460307478528 replay_runner.py:36] Average training steps per second: 226.40
I0901 12:28:03.215214 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.32
INFO:tensorflow:Starting iteration 19

Steps executed: 84 Episode length: 84 Return: -194.4034927272112193
INFO:tensorflow:Average training steps per second: 222.44
I0901 12:28:11.929703 140460307478528 replay_runner.py:36] Average training steps per second: 222.44

Steps executed: 406 Episode length: 322 Return: 184.895311058717543
INFO:tensorflow:Starting iteration 20

Steps executed: 329 Episode length: 201 Return: -54.479068367421114
INFO:tensorflow:Average training steps per second: 233.20
I0901 12:28:20.974092 140460307478528 replay_runner.py:36] Average training steps per second: 233.20
I0901 12:28:21.291744 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.37
INFO:tensorflow:Starting iteration 21

Steps executed: 257 Episode length: 140 Return: -418.45893872006454
INFO:tensorflow:Average training steps per second: 231.16
I0901 12:28:29.852014 140460307478528 replay_runner.py:36] Average training steps per second: 231.16
I0901 12:28:30.069656 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.19
INFO:tensorflow:Starting iteration 22

Steps executed: 219 Episode length: 119 Return: -346.68647742090254
INFO:tensorflow:Average training steps per second: 231.38
I0901 12:28:38.746431 140460307478528 replay_runner.py:36] Average training steps per second: 231.38
I0901 12:28:38.913839 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.14
INFO:tensorflow:Starting iteration 23

Steps executed: 222 Episode length: 81 Return: -170.792426503658055
INFO:tensorflow:Average training steps per second: 227.56
I0901 12:28:47.470789 140460307478528 replay_runner.py:36] Average training steps per second: 227.56
I0901 12:28:47.661581 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.84
INFO:tensorflow:Starting iteration 24

Steps executed: 93 Episode length: 93 Return: -166.1494530951914055
INFO:tensorflow:Average training steps per second: 220.77
I0901 12:28:56.428136 140460307478528 replay_runner.py:36] Average training steps per second: 220.77

Steps executed: 222 Episode length: 129 Return: -80.807964524904855
INFO:tensorflow:Starting iteration 25

Steps executed: 305 Episode length: 305 Return: -468.13159246222625
INFO:tensorflow:Average training steps per second: 223.84
I0901 12:29:05.478674 140460307478528 replay_runner.py:36] Average training steps per second: 223.84
I0901 12:29:05.903093 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -468.13
INFO:tensorflow:Starting iteration 26
I0901 12:29:10.267031 140460307478528 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 222.94
I0901 12:29:14.752855 140460307478528 replay_runner.py:36] Average training steps per second: 222.94

Steps executed: 255 Episode length: 68 Return: -423.444725616400435
INFO:tensorflow:Starting iteration 27

Steps executed: 217 Episode length: 109 Return: -475.05319031800725
INFO:tensorflow:Average training steps per second: 222.45
I0901 12:29:23.854136 140460307478528 replay_runner.py:36] Average training steps per second: 222.45
I0901 12:29:24.056586 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -478.11
INFO:tensorflow:Starting iteration 28
I0901 12:29:28.283407 140460307478528 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 222.20

Steps executed: 304 Episode length: 184 Return: -424.54441679986027
I0901 12:29:33.083926 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -430.50
INFO:tensorflow:Starting iteration 29

Steps executed: 202 Episode length: 120 Return: -237.62455590070664
INFO:tensorflow:Average training steps per second: 223.80
I0901 12:29:41.954628 140460307478528 replay_runner.py:36] Average training steps per second: 223.80

Done fixed training!Episode length: 120 Return: -237.62455590070664