Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0905 18:57:18.422659 140216559990784 run_experiment.py:549] Creating TrainRunner ...
I0905 18:57:18.449888 140216559990784 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 18:57:18.450277 140216559990784 dqn_agent.py:272] 	 gamma: 0.990000
I0905 18:57:18.450759 140216559990784 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 18:57:18.451039 140216559990784 dqn_agent.py:274] 	 min_replay_history: 500
I0905 18:57:18.451714 140216559990784 dqn_agent.py:275] 	 update_period: 4
I0905 18:57:18.452013 140216559990784 dqn_agent.py:276] 	 target_update_period: 300
I0905 18:57:18.452380 140216559990784 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 18:57:18.452834 140216559990784 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 18:57:18.453186 140216559990784 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 18:57:18.453606 140216559990784 dqn_agent.py:280] 	 optimizer: adam
I0905 18:57:18.453831 140216559990784 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 18:57:18.454153 140216559990784 dqn_agent.py:283] 	 seed: 1630868238449801
I0905 18:57:18.459536 140216559990784 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 18:57:18.460210 140216559990784 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 18:57:18.460497 140216559990784 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 18:57:18.460946 140216559990784 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 18:57:18.461142 140216559990784 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 18:57:18.461519 140216559990784 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 18:57:18.461653 140216559990784 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 18:57:18.461789 140216559990784 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 18:57:18.461938 140216559990784 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 18:57:18.528633 140216559990784 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:57:19.137956 140216559990784 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:57:19.159312 140216559990784 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 18:57:19.184819 140216559990784 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 18:57:19.185309 140216559990784 dqn_agent.py:272] 	 gamma: 0.990000
I0905 18:57:19.185623 140216559990784 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 18:57:19.185802 140216559990784 dqn_agent.py:274] 	 min_replay_history: 500
I0905 18:57:19.186329 140216559990784 dqn_agent.py:275] 	 update_period: 4
I0905 18:57:19.186497 140216559990784 dqn_agent.py:276] 	 target_update_period: 300
I0905 18:57:19.186701 140216559990784 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 18:57:19.186944 140216559990784 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 18:57:19.187162 140216559990784 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 18:57:19.187350 140216559990784 dqn_agent.py:280] 	 optimizer: adam
I0905 18:57:19.187494 140216559990784 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 18:57:19.187775 140216559990784 dqn_agent.py:283] 	 seed: 1630868239184749
I0905 18:57:19.192555 140216559990784 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 18:57:19.193357 140216559990784 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 18:57:19.193751 140216559990784 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 18:57:19.193938 140216559990784 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 18:57:19.194183 140216559990784 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 18:57:19.194480 140216559990784 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 18:57:19.194804 140216559990784 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 18:57:19.195232 140216559990784 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 18:57:19.195667 140216559990784 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 18:57:19.269390 140216559990784 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:57:19.318547 140216559990784 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 18:57:19.318903 140216559990784 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 119.01
I0905 18:57:27.723153 140216559990784 replay_runner.py:36] Average training steps per second: 119.01
Steps executed: 292 Episode length: 106 Return: -482.33758060119857
I0905 18:57:29.664602 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.65
INFO:tensorflow:Starting iteration 1

Steps executed: 227 Episode length: 117 Return: -328.93066492110233
INFO:tensorflow:Average training steps per second: 170.61
I0905 18:57:40.477930 140216559990784 replay_runner.py:36] Average training steps per second: 170.61
I0905 18:57:40.848785 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.17
INFO:tensorflow:Starting iteration 2

Steps executed: 176 Episode length: 86 Return: -747.513124842666933
INFO:tensorflow:Average training steps per second: 171.91

Steps executed: 1176 Episode length: 1000 Return: -127.04603744469945
I0905 18:57:56.010804 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -547.72
INFO:tensorflow:Starting iteration 3
I0905 18:58:00.790682 140216559990784 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 177.91

Steps executed: 1000 Episode length: 1000 Return: -175.36172063372485
I0905 18:58:10.354260 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.36
INFO:tensorflow:Starting iteration 4
I0905 18:58:15.231841 140216559990784 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 174.81

Steps executed: 1000 Episode length: 1000 Return: -186.98442446324242
I0905 18:58:25.687552 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.98
INFO:tensorflow:Starting iteration 5
I0905 18:58:30.101560 140216559990784 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 174.16

Steps executed: 1000 Episode length: 1000 Return: -233.68037353652207
I0905 18:58:41.449355 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.68
INFO:tensorflow:Starting iteration 6
I0905 18:58:46.292234 140216559990784 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 163.41

Steps executed: 1000 Episode length: 1000 Return: -376.66054708831577
I0905 18:58:55.755680 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -376.66
INFO:tensorflow:Starting iteration 7
I0905 18:59:00.320744 140216559990784 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 171.35

Steps executed: 1000 Episode length: 1000 Return: -239.16304049754723
I0905 18:59:10.937869 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -239.16
INFO:tensorflow:Starting iteration 8
I0905 18:59:15.235899 140216559990784 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 181.61
I0905 18:59:20.743043 140216559990784 replay_runner.py:36] Average training steps per second: 181.61

Steps executed: 1000 Episode length: 1000 Return: -354.84136250009593
INFO:tensorflow:Starting iteration 9
I0905 18:59:28.823987 140216559990784 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 208.44

Steps executed: 1000 Episode length: 1000 Return: -436.36194926042653
I0905 18:59:37.214543 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -436.36
INFO:tensorflow:Starting iteration 10
I0905 18:59:41.706551 140216559990784 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 231.11

Steps executed: 1000 Episode length: 1000 Return: -208.86975261888404
I0905 18:59:48.311956 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.87
INFO:tensorflow:Starting iteration 11

Steps executed: 552 Episode length: 552 Return: -88.82475275107183404
INFO:tensorflow:Average training steps per second: 297.88
I0905 18:59:55.156847 140216559990784 replay_runner.py:36] Average training steps per second: 297.88
I0905 18:59:56.010479 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.82
INFO:tensorflow:Starting iteration 12

Steps executed: 315 Episode length: 315 Return: -197.1110636012808204
INFO:tensorflow:Average training steps per second: 313.91
I0905 19:00:02.790561 140216559990784 replay_runner.py:36] Average training steps per second: 313.91
I0905 19:00:03.138981 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.11
INFO:tensorflow:Starting iteration 13
I0905 19:00:06.816937 140216559990784 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 316.15
I0905 19:00:09.980266 140216559990784 replay_runner.py:36] Average training steps per second: 316.15

Steps executed: 484 Episode length: 484 Return: -100.4348698472515504
INFO:tensorflow:Starting iteration 14
I0905 19:00:14.529385 140216559990784 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 316.86

Steps executed: 727 Episode length: 727 Return: -202.6544884013664504
I0905 19:00:19.090218 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.65
INFO:tensorflow:Starting iteration 15

Steps executed: 295 Episode length: 149 Return: -62.98932141917519504
INFO:tensorflow:Average training steps per second: 293.11
I0905 19:00:26.139516 140216559990784 replay_runner.py:36] Average training steps per second: 293.11
I0905 19:00:26.350899 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -53.95
INFO:tensorflow:Starting iteration 16
I0905 19:00:29.767617 140216559990784 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 278.28
I0905 19:00:33.361523 140216559990784 replay_runner.py:36] Average training steps per second: 278.28

Steps executed: 1000 Episode length: 1000 Return: -207.86445512531384
INFO:tensorflow:Starting iteration 17

Steps executed: 146 Episode length: 146 Return: -85.70405649910482384
INFO:tensorflow:Average training steps per second: 313.58

Steps executed: 1146 Episode length: 1000 Return: -13.664090265289405
I0905 19:00:46.731581 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -49.68
INFO:tensorflow:Starting iteration 18
I0905 19:00:50.297422 140216559990784 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 309.62

Steps executed: 1000 Episode length: 1000 Return: -15.139214893223311
I0905 19:00:55.980323 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -15.14
INFO:tensorflow:Starting iteration 19

Steps executed: 304 Episode length: 148 Return: -90.61255321748752311
INFO:tensorflow:Average training steps per second: 295.83
I0905 19:01:02.958786 140216559990784 replay_runner.py:36] Average training steps per second: 295.83
I0905 19:01:03.210872 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.30
INFO:tensorflow:Starting iteration 20

Steps executed: 279 Episode length: 279 Return: 9.7169295112459552311
INFO:tensorflow:Average training steps per second: 296.56
I0905 19:01:10.046958 140216559990784 replay_runner.py:36] Average training steps per second: 296.56
I0905 19:01:10.349177 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.72
INFO:tensorflow:Starting iteration 21
I0905 19:01:13.963591 140216559990784 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 307.77

Steps executed: 1000 Episode length: 1000 Return: 4.12658502637587411
I0905 19:01:19.762905 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: 4.13
INFO:tensorflow:Starting iteration 22
I0905 19:01:23.145005 140216559990784 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 288.02

Steps executed: 354 Episode length: 160 Return: -96.13808220836186411
I0905 19:01:26.945378 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.09
INFO:tensorflow:Starting iteration 23
I0905 19:01:30.412398 140216559990784 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 296.69

Steps executed: 1000 Episode length: 1000 Return: -23.278504316508711
I0905 19:01:36.151106 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -23.28
INFO:tensorflow:Starting iteration 24

Steps executed: 280 Episode length: 136 Return: 4.7692557329981753711
INFO:tensorflow:Average training steps per second: 274.22
I0905 19:01:43.245530 140216559990784 replay_runner.py:36] Average training steps per second: 274.22
I0905 19:01:43.456879 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -31.37
INFO:tensorflow:Starting iteration 25

Steps executed: 312 Episode length: 142 Return: 39.599839307279325411
INFO:tensorflow:Average training steps per second: 286.36
I0905 19:01:50.302552 140216559990784 replay_runner.py:36] Average training steps per second: 286.36
I0905 19:01:50.554378 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: 14.01
INFO:tensorflow:Starting iteration 26

Steps executed: 315 Episode length: 164 Return: -24.75196094638323511
INFO:tensorflow:Average training steps per second: 293.04
I0905 19:01:57.347460 140216559990784 replay_runner.py:36] Average training steps per second: 293.04
I0905 19:01:57.602657 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -32.89
INFO:tensorflow:Starting iteration 27
I0905 19:02:01.173884 140216559990784 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 286.83

Steps executed: 332 Episode length: 332 Return: 245.16083651220413511
I0905 19:02:05.109433 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: 245.16
INFO:tensorflow:Starting iteration 28

Steps executed: 273 Episode length: 94 Return: -332.04750621814313511
INFO:tensorflow:Average training steps per second: 324.58
I0905 19:02:11.774923 140216559990784 replay_runner.py:36] Average training steps per second: 324.58
I0905 19:02:11.979091 140216559990784 run_experiment.py:428] Average undiscounted return per evaluation episode: -264.53
INFO:tensorflow:Starting iteration 29

Steps executed: 234 Episode length: 71 Return: -632.19767466998423511
INFO:tensorflow:Average training steps per second: 318.14
I0905 19:02:18.553322 140216559990784 replay_runner.py:36] Average training steps per second: 318.14

Done fixed training!Episode length: 71 Return: -632.19767466998423511