I0901 13:04:34.481270 140460307478528 run_experiment.py:549] Creating TrainRunner ...
I0901 13:04:34.490559 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:04:34.490771 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:04:34.490875 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:04:34.490972 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:04:34.491068 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 13:04:34.491284 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:04:34.491499 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:04:34.491667 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:04:34.491775 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:04:34.491852 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 13:04:34.491926 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:04:34.492003 140460307478528 dqn_agent.py:283] 	 seed: 1630501474490514
I0901 13:04:34.494008 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:04:34.494199 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:04:34.494292 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:04:34.494414 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:04:34.494518 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:04:34.494584 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:04:34.494644 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:04:34.494704 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:04:34.494961 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:04:34.527652 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:04:34.837251 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:04:34.850380 140460307478528 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:04:34.858316 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:04:34.858564 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:04:34.858731 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:04:34.858858 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:04:34.858975 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 13:04:34.859124 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:04:34.859256 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:04:34.859352 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:04:34.859444 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:04:34.859540 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 13:04:34.859708 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:04:34.859833 140460307478528 dqn_agent.py:283] 	 seed: 1630501474858269
I0901 13:04:34.862304 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:04:34.862493 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:04:34.862635 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:04:34.862747 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:04:34.862882 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:04:34.863012 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:04:34.863133 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:04:34.863289 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:04:34.863456 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:04:34.892368 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:04:34.911512 140460307478528 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:04:34.911710 140460307478528 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 191.83
I0901 13:04:40.124744 140460307478528 replay_runner.py:36] Average training steps per second: 191.83
I0901 13:04:41.035509 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -382.83
Steps executed: 205 Episode length: 117 Return: -375.321974756663
INFO:tensorflow:Starting iteration 1
I0901 13:04:44.877303 140460307478528 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 274.20
I0901 13:04:48.524621 140460307478528 replay_runner.py:36] Average training steps per second: 274.20

Steps executed: 286 Episode length: 161 Return: -103.7016779572979
INFO:tensorflow:Starting iteration 2

Steps executed: 272 Episode length: 116 Return: -21.038479176312634
INFO:tensorflow:Average training steps per second: 294.45
I0901 13:04:55.857331 140460307478528 replay_runner.py:36] Average training steps per second: 294.45
I0901 13:04:56.050786 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -41.04
INFO:tensorflow:Starting iteration 3
I0901 13:04:59.862400 140460307478528 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 282.18
I0901 13:05:03.406598 140460307478528 replay_runner.py:36] Average training steps per second: 282.18

Steps executed: 311 Episode length: 223 Return: -50.699670043987724
INFO:tensorflow:Starting iteration 4

Steps executed: 227 Episode length: 113 Return: -247.58479625270638
INFO:tensorflow:Average training steps per second: 275.19
I0901 13:05:11.095104 140460307478528 replay_runner.py:36] Average training steps per second: 275.19
I0901 13:05:11.251913 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.95
INFO:tensorflow:Starting iteration 5

Steps executed: 219 Episode length: 89 Return: -295.736723384499464
INFO:tensorflow:Average training steps per second: 279.23
I0901 13:05:18.647794 140460307478528 replay_runner.py:36] Average training steps per second: 279.23
I0901 13:05:18.783247 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -322.35
INFO:tensorflow:Starting iteration 6

Steps executed: 273 Episode length: 75 Return: -199.136246397060523
INFO:tensorflow:Average training steps per second: 275.38
I0901 13:05:26.122741 140460307478528 replay_runner.py:36] Average training steps per second: 275.38
I0901 13:05:26.315132 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.81
INFO:tensorflow:Starting iteration 7

Steps executed: 273 Episode length: 76 Return: -556.608964065363723
INFO:tensorflow:Average training steps per second: 271.21
I0901 13:05:33.782420 140460307478528 replay_runner.py:36] Average training steps per second: 271.21
I0901 13:05:33.968632 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -490.64
INFO:tensorflow:Starting iteration 8

Steps executed: 227 Episode length: 57 Return: -217.411997620297643
INFO:tensorflow:Average training steps per second: 285.42
I0901 13:05:41.202621 140460307478528 replay_runner.py:36] Average training steps per second: 285.42
I0901 13:05:41.331769 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.57
INFO:tensorflow:Starting iteration 9

Steps executed: 204 Episode length: 132 Return: -237.41864359877653
INFO:tensorflow:Average training steps per second: 294.91
I0901 13:05:48.363936 140460307478528 replay_runner.py:36] Average training steps per second: 294.91
I0901 13:05:48.485500 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -239.73
INFO:tensorflow:Starting iteration 10

Steps executed: 531 Episode length: 531 Return: -283.10234634082906
INFO:tensorflow:Average training steps per second: 300.39
I0901 13:05:55.352691 140460307478528 replay_runner.py:36] Average training steps per second: 300.39
I0901 13:05:56.241760 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.10
INFO:tensorflow:Starting iteration 11

Steps executed: 327 Episode length: 135 Return: -108.12573437736484
INFO:tensorflow:Average training steps per second: 307.74
I0901 13:06:03.043279 140460307478528 replay_runner.py:36] Average training steps per second: 307.74
I0901 13:06:03.218165 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.00
INFO:tensorflow:Starting iteration 12

Steps executed: 424 Episode length: 424 Return: -466.14556888033104
INFO:tensorflow:Average training steps per second: 307.56
I0901 13:06:09.937206 140460307478528 replay_runner.py:36] Average training steps per second: 307.56
I0901 13:06:10.429208 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -466.15
INFO:tensorflow:Starting iteration 13

Steps executed: 247 Episode length: 87 Return: -168.445567719351664
INFO:tensorflow:Average training steps per second: 312.62
I0901 13:06:17.098226 140460307478528 replay_runner.py:36] Average training steps per second: 312.62
I0901 13:06:17.224094 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.93
INFO:tensorflow:Starting iteration 14

Steps executed: 302 Episode length: 106 Return: -576.03202214080724
INFO:tensorflow:Average training steps per second: 308.79
I0901 13:06:23.846750 140460307478528 replay_runner.py:36] Average training steps per second: 308.79
I0901 13:06:24.024121 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -538.63
INFO:tensorflow:Starting iteration 15

Steps executed: 212 Episode length: 100 Return: -30.390634419560826
INFO:tensorflow:Average training steps per second: 319.30
I0901 13:06:30.512064 140460307478528 replay_runner.py:36] Average training steps per second: 319.30
I0901 13:06:30.641921 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.70
INFO:tensorflow:Starting iteration 16

Steps executed: 251 Episode length: 91 Return: -89.3001391898399526
INFO:tensorflow:Average training steps per second: 314.75
I0901 13:06:37.165761 140460307478528 replay_runner.py:36] Average training steps per second: 314.75
I0901 13:06:37.300133 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.23
INFO:tensorflow:Starting iteration 17

Steps executed: 218 Episode length: 116 Return: -454.49503034597946
INFO:tensorflow:Average training steps per second: 315.42
I0901 13:06:43.848057 140460307478528 replay_runner.py:36] Average training steps per second: 315.42
I0901 13:06:43.976747 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -452.56
INFO:tensorflow:Starting iteration 18
I0901 13:06:47.338772 140460307478528 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 319.74

Steps executed: 252 Episode length: 56 Return: -63.9250458578885346
I0901 13:06:50.593242 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.12
INFO:tensorflow:Starting iteration 19

Steps executed: 213 Episode length: 121 Return: -377.92730103813396
INFO:tensorflow:Average training steps per second: 316.11
I0901 13:06:57.141361 140460307478528 replay_runner.py:36] Average training steps per second: 316.11
I0901 13:06:57.275897 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -469.87
INFO:tensorflow:Starting iteration 20

Steps executed: 221 Episode length: 88 Return: -617.588505647385496
INFO:tensorflow:Average training steps per second: 323.61
I0901 13:07:03.730512 140460307478528 replay_runner.py:36] Average training steps per second: 323.61
I0901 13:07:03.866954 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -570.17
INFO:tensorflow:Starting iteration 21

Steps executed: 235 Episode length: 68 Return: -540.013206819578296
INFO:tensorflow:Average training steps per second: 322.56
I0901 13:07:10.336974 140460307478528 replay_runner.py:36] Average training steps per second: 322.56
I0901 13:07:10.484219 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -618.90
INFO:tensorflow:Starting iteration 22

Steps executed: 230 Episode length: 64 Return: -232.350191100712786
INFO:tensorflow:Average training steps per second: 329.25
I0901 13:07:16.894724 140460307478528 replay_runner.py:36] Average training steps per second: 329.25
I0901 13:07:17.044850 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -299.30
INFO:tensorflow:Starting iteration 23

Steps executed: 215 Episode length: 80 Return: -734.546369960679286
INFO:tensorflow:Average training steps per second: 327.62
I0901 13:07:23.530136 140460307478528 replay_runner.py:36] Average training steps per second: 327.62
I0901 13:07:23.678753 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -649.55
INFO:tensorflow:Starting iteration 24

Steps executed: 203 Episode length: 92 Return: -117.512351342605066
INFO:tensorflow:Average training steps per second: 329.28
I0901 13:07:30.147196 140460307478528 replay_runner.py:36] Average training steps per second: 329.28
I0901 13:07:30.271935 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.37
INFO:tensorflow:Starting iteration 25
I0901 13:07:33.714788 140460307478528 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 333.80

Steps executed: 235 Episode length: 81 Return: -690.113376832286266
I0901 13:07:36.885592 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -607.19
INFO:tensorflow:Starting iteration 26

Steps executed: 237 Episode length: 78 Return: -498.497115006506146
INFO:tensorflow:Average training steps per second: 330.20
I0901 13:07:43.409867 140460307478528 replay_runner.py:36] Average training steps per second: 330.20
I0901 13:07:43.561533 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.24
INFO:tensorflow:Starting iteration 27

Steps executed: 218 Episode length: 75 Return: -420.584853496392576
INFO:tensorflow:Average training steps per second: 335.34
I0901 13:07:49.994567 140460307478528 replay_runner.py:36] Average training steps per second: 335.34
I0901 13:07:50.142001 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.08
INFO:tensorflow:Starting iteration 28

Steps executed: 242 Episode length: 88 Return: -60.0842740645010136
INFO:tensorflow:Average training steps per second: 331.97
I0901 13:07:56.549610 140460307478528 replay_runner.py:36] Average training steps per second: 331.97
I0901 13:07:56.673036 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.14
INFO:tensorflow:Starting iteration 29

Steps executed: 228 Episode length: 81 Return: -407.355835187680956
INFO:tensorflow:Average training steps per second: 326.21
I0901 13:08:03.201511 140460307478528 replay_runner.py:36] Average training steps per second: 326.21

Done fixed training!Episode length: 81 Return: -407.355835187680956