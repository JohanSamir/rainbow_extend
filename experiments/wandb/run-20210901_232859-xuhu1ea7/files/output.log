I0901 23:29:06.455954 140149719906304 run_experiment.py:549] Creating TrainRunner ...
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0901 23:29:06.456561 140149719906304 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0901 23:29:06.526706 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:29:06.527904 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:29:06.528033 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:29:06.528103 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:29:06.528159 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0901 23:29:06.528213 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:29:06.528264 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:29:06.528313 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:29:06.528446 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:29:06.528542 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0901 23:29:06.528626 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:29:06.528679 140149719906304 dqn_agent.py:283] 	 seed: 1630538946526639
I0901 23:29:06.530546 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:29:06.530686 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:29:06.530758 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:29:06.530822 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:29:06.530914 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:29:06.530977 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:29:06.531030 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:29:06.531088 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:29:06.531216 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
I0901 23:29:13.051169 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:29:13.981323 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:29:14.088918 140149719906304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:29:14.132425 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:29:14.135367 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:29:14.136491 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:29:14.137460 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:29:14.137606 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0901 23:29:14.138762 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:29:14.139559 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
Training fixed agent 7, please be patient, may be a while...
I0901 23:29:14.139692 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:29:14.140910 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:29:14.141707 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0901 23:29:14.141821 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:29:14.142830 140149719906304 dqn_agent.py:283] 	 seed: 1630538954132353
I0901 23:29:14.155314 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:29:14.155493 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:29:14.155608 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:29:14.155720 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:29:14.155818 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:29:14.155913 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:29:14.156005 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:29:14.156098 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:29:14.156189 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:29:14.671034 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:29:14.704839 140149719906304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:29:14.705168 140149719906304 replay_runner.py:41] Starting iteration 0
Steps executed: 244 Episode length: 128 Return: -188.25749545313977
INFO:tensorflow:Average training steps per second: 130.36
I0901 23:29:22.377532 140149719906304 replay_runner.py:36] Average training steps per second: 130.36
I0901 23:29:23.647348 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.70
INFO:tensorflow:Starting iteration 1

Steps executed: 461 Episode length: 274 Return: -388.45633921677357
INFO:tensorflow:Average training steps per second: 200.88
I0901 23:29:32.840512 140149719906304 replay_runner.py:36] Average training steps per second: 200.88
I0901 23:29:33.448377 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.16
INFO:tensorflow:Starting iteration 2

Steps executed: 260 Episode length: 260 Return: -440.02892962969127
INFO:tensorflow:Average training steps per second: 199.09
I0901 23:29:42.724860 140149719906304 replay_runner.py:36] Average training steps per second: 199.09
I0901 23:29:43.024753 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -440.03
INFO:tensorflow:Starting iteration 3
I0901 23:29:47.239224 140149719906304 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 200.58

Steps executed: 1017 Episode length: 847 Return: -461.1021783810669
I0901 23:29:54.097683 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -371.48
INFO:tensorflow:Starting iteration 4
I0901 23:29:58.409815 140149719906304 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 208.78

Steps executed: 1000 Episode length: 1000 Return: -156.8062280931332
I0901 23:30:05.783464 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.81
INFO:tensorflow:Starting iteration 5

Steps executed: 444 Episode length: 444 Return: -374.676947470702262
INFO:tensorflow:Average training steps per second: 212.65
I0901 23:30:14.598001 140149719906304 replay_runner.py:36] Average training steps per second: 212.65
I0901 23:30:15.547264 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -374.68
INFO:tensorflow:Starting iteration 6
I0901 23:30:19.598360 140149719906304 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 219.20

Steps executed: 1176 Episode length: 1000 Return: -130.74184251778158
I0901 23:30:26.020525 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.51
INFO:tensorflow:Starting iteration 7
I0901 23:30:29.900934 140149719906304 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 225.69


Steps executed: 1193 Episode length: 1000 Return: -120.26505421294488
I0901 23:30:37.164725 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.66
INFO:tensorflow:Starting iteration 8
I0901 23:30:41.482799 140149719906304 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 227.24

Steps executed: 543 Episode length: 543 Return: -211.8161158497747588
I0901 23:30:46.985778 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.82
INFO:tensorflow:Starting iteration 9

Steps executed: 362 Episode length: 362 Return: -120.7417072021604188
INFO:tensorflow:Average training steps per second: 229.08
I0901 23:30:55.617696 140149719906304 replay_runner.py:36] Average training steps per second: 229.08
I0901 23:30:56.201885 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.74
INFO:tensorflow:Starting iteration 10

Steps executed: 285 Episode length: 285 Return: -441.9467860021623688
INFO:tensorflow:Average training steps per second: 224.98
I0901 23:31:04.763303 140149719906304 replay_runner.py:36] Average training steps per second: 224.98
I0901 23:31:05.138991 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -441.95
INFO:tensorflow:Starting iteration 11
I0901 23:31:09.260092 140149719906304 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 216.82

Steps executed: 553 Episode length: 553 Return: -401.4949283366703488
I0901 23:31:15.009880 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -401.49
INFO:tensorflow:Starting iteration 12
I0901 23:31:19.303288 140149719906304 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 211.78

Steps executed: 1000 Episode length: 1000 Return: -196.62593296999918
I0901 23:31:26.548394 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.63
INFO:tensorflow:Starting iteration 13

Steps executed: 322 Episode length: 322 Return: -378.7409309549147918
INFO:tensorflow:Average training steps per second: 225.76
I0901 23:31:35.417268 140149719906304 replay_runner.py:36] Average training steps per second: 225.76
I0901 23:31:35.863884 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -378.74
INFO:tensorflow:Starting iteration 14

Steps executed: 169 Episode length: 169 Return: -134.7890283450316518
INFO:tensorflow:Average training steps per second: 219.21

Steps executed: 983 Episode length: 814 Return: -113.4679606511329818
I0901 23:31:46.312364 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.13
INFO:tensorflow:Starting iteration 15
I0901 23:31:50.480995 140149719906304 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 219.38

Steps executed: 1000 Episode length: 1000 Return: -93.487972763569318
I0901 23:31:58.631630 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.49
INFO:tensorflow:Starting iteration 16
I0901 23:32:02.627876 140149719906304 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 245.95
I0901 23:32:06.694720 140149719906304 replay_runner.py:36] Average training steps per second: 245.95

Steps executed: 1000 Episode length: 1000 Return: -91.038565265679448
INFO:tensorflow:Starting iteration 17
I0901 23:32:12.775004 140149719906304 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 232.08

Steps executed: 1000 Episode length: 1000 Return: -162.29955225130303
I0901 23:32:20.169720 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.30
INFO:tensorflow:Starting iteration 18
I0901 23:32:24.306387 140149719906304 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 220.28

Steps executed: 1000 Episode length: 1000 Return: 28.8956417097175133
I0901 23:32:32.034337 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: 28.90
INFO:tensorflow:Starting iteration 19

Steps executed: 807 Episode length: 622 Return: 213.88969407795798133
INFO:tensorflow:Average training steps per second: 222.85
I0901 23:32:41.443677 140149719906304 replay_runner.py:36] Average training steps per second: 222.85
I0901 23:32:42.725226 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: 42.09
INFO:tensorflow:Starting iteration 20
I0901 23:32:46.770538 140149719906304 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 225.24

Steps executed: 1000 Episode length: 1000 Return: -73.372154382966583
I0901 23:32:54.535200 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.37
INFO:tensorflow:Starting iteration 21

Steps executed: 272 Episode length: 132 Return: -110.2957931359828383
INFO:tensorflow:Average training steps per second: 226.53
I0901 23:33:03.251006 140149719906304 replay_runner.py:36] Average training steps per second: 226.53
I0901 23:33:03.499817 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.55
INFO:tensorflow:Starting iteration 22

Steps executed: 173 Episode length: 173 Return: -75.71243089008948383
INFO:tensorflow:Average training steps per second: 225.14

Steps executed: 800 Episode length: 627 Return: -385.9971589967202683
I0901 23:33:13.938161 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.85
INFO:tensorflow:Starting iteration 23

Steps executed: 338 Episode length: 179 Return: -86.59190617586661483
INFO:tensorflow:Average training steps per second: 227.79
I0901 23:33:22.665261 140149719906304 replay_runner.py:36] Average training steps per second: 227.79
I0901 23:33:22.995898 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.98
INFO:tensorflow:Starting iteration 24

Steps executed: 272 Episode length: 141 Return: -127.9938673522615283
INFO:tensorflow:Average training steps per second: 222.14
I0901 23:33:31.831338 140149719906304 replay_runner.py:36] Average training steps per second: 222.14
I0901 23:33:32.066363 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.12
INFO:tensorflow:Starting iteration 25
I0901 23:33:36.420365 140149719906304 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 221.18

Steps executed: 1000 Episode length: 1000 Return: -48.682892297367773
I0901 23:33:43.981413 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -48.68
INFO:tensorflow:Starting iteration 26

Steps executed: 300 Episode length: 300 Return: -303.4087153755005573
INFO:tensorflow:Average training steps per second: 221.89
I0901 23:33:52.812245 140149719906304 replay_runner.py:36] Average training steps per second: 221.89
I0901 23:33:53.207643 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.41
INFO:tensorflow:Starting iteration 27

Steps executed: 201 Episode length: 63 Return: -155.04558018088858573
INFO:tensorflow:Average training steps per second: 221.25
I0901 23:34:01.929568 140149719906304 replay_runner.py:36] Average training steps per second: 221.25
I0901 23:34:02.102665 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.56
INFO:tensorflow:Starting iteration 28

Steps executed: 261 Episode length: 154 Return: -85.65964640472170373
INFO:tensorflow:Average training steps per second: 223.53
I0901 23:34:10.804626 140149719906304 replay_runner.py:36] Average training steps per second: 223.53
I0901 23:34:11.038491 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.97
INFO:tensorflow:Starting iteration 29

Steps executed: 252 Episode length: 144 Return: -85.37071253611114373
INFO:tensorflow:Average training steps per second: 225.85
I0901 23:34:19.750831 140149719906304 replay_runner.py:36] Average training steps per second: 225.85

Done fixed training!Episode length: 144 Return: -85.37071253611114373