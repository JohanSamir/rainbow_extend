Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0902 17:46:15.466868 140451420674048 run_experiment.py:549] Creating TrainRunner ...
I0902 17:46:15.479464 140451420674048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:46:15.479694 140451420674048 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:46:15.479780 140451420674048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:46:15.479850 140451420674048 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:46:15.479935 140451420674048 dqn_agent.py:275] 	 update_period: 4
I0902 17:46:15.480033 140451420674048 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:46:15.480142 140451420674048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:46:15.480336 140451420674048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:46:15.480442 140451420674048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:46:15.480560 140451420674048 dqn_agent.py:280] 	 optimizer: adam
I0902 17:46:15.480656 140451420674048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:46:15.480823 140451420674048 dqn_agent.py:283] 	 seed: 1630604775479402
I0902 17:46:15.484573 140451420674048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:46:15.485189 140451420674048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:46:15.485367 140451420674048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:46:15.485534 140451420674048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:46:15.485746 140451420674048 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:46:15.485984 140451420674048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:46:15.486074 140451420674048 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:46:15.486196 140451420674048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:46:15.486294 140451420674048 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:46:15.524726 140451420674048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=5.000000
I0902 17:46:16.238462 140451420674048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=5.000000
I0902 17:46:16.253160 140451420674048 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 17:46:16.262517 140451420674048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:46:16.262784 140451420674048 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:46:16.262919 140451420674048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:46:16.263055 140451420674048 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:46:16.263164 140451420674048 dqn_agent.py:275] 	 update_period: 4
I0902 17:46:16.263369 140451420674048 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:46:16.263468 140451420674048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:46:16.263543 140451420674048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:46:16.263654 140451420674048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:46:16.263777 140451420674048 dqn_agent.py:280] 	 optimizer: adam
I0902 17:46:16.263903 140451420674048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:46:16.264124 140451420674048 dqn_agent.py:283] 	 seed: 1630604776262474
I0902 17:46:16.267065 140451420674048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:46:16.267282 140451420674048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:46:16.267406 140451420674048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:46:16.267606 140451420674048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:46:16.267724 140451420674048 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:46:16.267809 140451420674048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:46:16.267931 140451420674048 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:46:16.268020 140451420674048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:46:16.268101 140451420674048 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:46:16.302460 140451420674048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=5.000000
I0902 17:46:16.323624 140451420674048 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 17:46:16.323848 140451420674048 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.38
I0902 17:46:22.482439 140451420674048 replay_runner.py:36] Average training steps per second: 162.38
Steps executed: 213 Episode length: 83 Return: -137.28543139897502
I0902 17:46:23.566018 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.96
INFO:tensorflow:Starting iteration 1

Steps executed: 256 Episode length: 86 Return: -144.31679497553918
INFO:tensorflow:Average training steps per second: 222.08
I0902 17:46:32.502939 140451420674048 replay_runner.py:36] Average training steps per second: 222.08
I0902 17:46:32.664346 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.23
INFO:tensorflow:Starting iteration 2

Steps executed: 205 Episode length: 73 Return: -155.32609852900367
INFO:tensorflow:Average training steps per second: 221.69
I0902 17:46:41.572233 140451420674048 replay_runner.py:36] Average training steps per second: 221.69
I0902 17:46:41.700474 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.41
INFO:tensorflow:Starting iteration 3

Steps executed: 249 Episode length: 53 Return: -120.56734875649923
INFO:tensorflow:Average training steps per second: 219.19
I0902 17:46:50.563009 140451420674048 replay_runner.py:36] Average training steps per second: 219.19
I0902 17:46:50.718975 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.54
INFO:tensorflow:Starting iteration 4

Steps executed: 212 Episode length: 71 Return: -172.61266327384325
INFO:tensorflow:Average training steps per second: 223.16
I0902 17:46:59.578404 140451420674048 replay_runner.py:36] Average training steps per second: 223.16
I0902 17:46:59.711323 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.09
INFO:tensorflow:Starting iteration 5

Steps executed: 258 Episode length: 77 Return: -184.25638923756077
INFO:tensorflow:Average training steps per second: 232.24
I0902 17:47:08.407226 140451420674048 replay_runner.py:36] Average training steps per second: 232.24
I0902 17:47:08.567937 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.40
INFO:tensorflow:Starting iteration 6

Steps executed: 217 Episode length: 91 Return: -90.938183702406757
INFO:tensorflow:Average training steps per second: 229.24
I0902 17:47:17.060279 140451420674048 replay_runner.py:36] Average training steps per second: 229.24
I0902 17:47:17.235135 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.91
INFO:tensorflow:Starting iteration 7
I0902 17:47:21.450826 140451420674048 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 243.58
I0902 17:47:25.556875 140451420674048 replay_runner.py:36] Average training steps per second: 243.58

Steps executed: 224 Episode length: 82 Return: -310.34618427608866
INFO:tensorflow:Starting iteration 8
I0902 17:47:29.721683 140451420674048 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 230.54
I0902 17:47:34.059864 140451420674048 replay_runner.py:36] Average training steps per second: 230.54

Steps executed: 232 Episode length: 120 Return: -155.59888071424518
INFO:tensorflow:Starting iteration 9

Steps executed: 227 Episode length: 103 Return: -350.47536557029918
INFO:tensorflow:Average training steps per second: 226.03
I0902 17:47:42.935049 140451420674048 replay_runner.py:36] Average training steps per second: 226.03
I0902 17:47:43.120638 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -335.33
INFO:tensorflow:Starting iteration 10

Steps executed: 284 Episode length: 142 Return: -206.60162213342522
INFO:tensorflow:Average training steps per second: 222.94
I0902 17:47:51.939722 140451420674048 replay_runner.py:36] Average training steps per second: 222.94
I0902 17:47:52.181720 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.52
INFO:tensorflow:Starting iteration 11

Steps executed: 339 Episode length: 140 Return: -355.29707641678447
INFO:tensorflow:Average training steps per second: 226.47
I0902 17:48:00.998776 140451420674048 replay_runner.py:36] Average training steps per second: 226.47
I0902 17:48:01.281667 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.74
INFO:tensorflow:Starting iteration 12

Steps executed: 253 Episode length: 123 Return: -250.06413558889457
INFO:tensorflow:Average training steps per second: 224.12
I0902 17:48:10.141777 140451420674048 replay_runner.py:36] Average training steps per second: 224.12
I0902 17:48:10.353630 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.63
INFO:tensorflow:Starting iteration 13

Steps executed: 329 Episode length: 135 Return: -144.28964503724978
INFO:tensorflow:Average training steps per second: 223.55
I0902 17:48:19.284909 140451420674048 replay_runner.py:36] Average training steps per second: 223.55
I0902 17:48:19.579065 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.20
INFO:tensorflow:Starting iteration 14

Steps executed: 228 Episode length: 228 Return: -161.31171544314026
INFO:tensorflow:Average training steps per second: 225.79
I0902 17:48:28.372936 140451420674048 replay_runner.py:36] Average training steps per second: 225.79
I0902 17:48:28.595784 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.31
INFO:tensorflow:Starting iteration 15

Steps executed: 310 Episode length: 124 Return: -331.44609967756526
INFO:tensorflow:Average training steps per second: 221.45
I0902 17:48:37.513610 140451420674048 replay_runner.py:36] Average training steps per second: 221.45
I0902 17:48:37.755997 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.61
INFO:tensorflow:Starting iteration 16

Steps executed: 296 Episode length: 198 Return: -207.45935391088852
INFO:tensorflow:Average training steps per second: 223.71
I0902 17:48:46.623186 140451420674048 replay_runner.py:36] Average training steps per second: 223.71
I0902 17:48:46.875086 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.09
INFO:tensorflow:Starting iteration 17

Steps executed: 266 Episode length: 148 Return: -244.51028165789542
INFO:tensorflow:Average training steps per second: 223.82
I0902 17:48:55.940265 140451420674048 replay_runner.py:36] Average training steps per second: 223.82
I0902 17:48:56.166654 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.24
INFO:tensorflow:Starting iteration 18

Steps executed: 208 Episode length: 90 Return: -248.835817569105633
INFO:tensorflow:Average training steps per second: 224.04
I0902 17:49:05.053698 140451420674048 replay_runner.py:36] Average training steps per second: 224.04
I0902 17:49:05.226035 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.99
INFO:tensorflow:Starting iteration 19

Steps executed: 221 Episode length: 132 Return: -211.51763619862436
INFO:tensorflow:Average training steps per second: 221.28
I0902 17:49:14.216876 140451420674048 replay_runner.py:36] Average training steps per second: 221.28
I0902 17:49:14.405156 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.48
INFO:tensorflow:Starting iteration 20
I0902 17:49:18.801683 140451420674048 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 214.61

Steps executed: 345 Episode length: 229 Return: -459.96406158338203
I0902 17:49:23.805768 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.75
INFO:tensorflow:Starting iteration 21

Steps executed: 230 Episode length: 127 Return: -327.40661345567576
INFO:tensorflow:Average training steps per second: 222.60
I0902 17:49:32.748552 140451420674048 replay_runner.py:36] Average training steps per second: 222.60
I0902 17:49:32.942471 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -351.61
INFO:tensorflow:Starting iteration 22
I0902 17:49:37.303328 140451420674048 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 225.73

Steps executed: 214 Episode length: 136 Return: -218.05489449286077
I0902 17:49:41.907964 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.55
INFO:tensorflow:Starting iteration 23

Steps executed: 289 Episode length: 97 Return: -331.022758588677457
INFO:tensorflow:Average training steps per second: 223.84
I0902 17:49:50.798643 140451420674048 replay_runner.py:36] Average training steps per second: 223.84
I0902 17:49:51.046194 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -291.95
INFO:tensorflow:Starting iteration 24

Steps executed: 209 Episode length: 96 Return: -387.772420757738527
INFO:tensorflow:Average training steps per second: 220.82
I0902 17:49:59.966216 140451420674048 replay_runner.py:36] Average training steps per second: 220.82
I0902 17:50:00.140021 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -295.81
INFO:tensorflow:Starting iteration 25

Steps executed: 406 Episode length: 216 Return: -749.63147051086576
INFO:tensorflow:Average training steps per second: 244.93
I0902 17:50:08.579834 140451420674048 replay_runner.py:36] Average training steps per second: 244.93
I0902 17:50:08.894081 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -503.93
INFO:tensorflow:Starting iteration 26

Steps executed: 393 Episode length: 274 Return: -255.19358202905528
INFO:tensorflow:Average training steps per second: 226.43
I0902 17:50:17.437927 140451420674048 replay_runner.py:36] Average training steps per second: 226.43
I0902 17:50:17.772700 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -305.30
INFO:tensorflow:Starting iteration 27

Steps executed: 249 Episode length: 249 Return: -295.47274809147778
INFO:tensorflow:Average training steps per second: 230.20
I0902 17:50:26.501583 140451420674048 replay_runner.py:36] Average training steps per second: 230.20
I0902 17:50:26.764122 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -295.47
INFO:tensorflow:Starting iteration 28

Steps executed: 207 Episode length: 110 Return: -381.55596164017135
INFO:tensorflow:Average training steps per second: 250.22
I0902 17:50:35.208182 140451420674048 replay_runner.py:36] Average training steps per second: 250.22
I0902 17:50:35.363554 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.99
INFO:tensorflow:Starting iteration 29

Steps executed: 112 Episode length: 112 Return: -172.90409765946197
INFO:tensorflow:Average training steps per second: 246.39
I0902 17:50:43.689116 140451420674048 replay_runner.py:36] Average training steps per second: 246.39


Done fixed training!Episode length: 211 Return: -442.15744653972314