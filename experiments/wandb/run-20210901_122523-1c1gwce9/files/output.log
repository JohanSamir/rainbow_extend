Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0901 12:25:30.270953 139683016574976 run_experiment.py:549] Creating TrainRunner ...
I0901 12:25:30.283127 139683016574976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:25:30.283387 139683016574976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:25:30.283591 139683016574976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:25:30.283723 139683016574976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:25:30.283920 139683016574976 dqn_agent.py:275] 	 update_period: 4
I0901 12:25:30.284045 139683016574976 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:25:30.284202 139683016574976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:25:30.284320 139683016574976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:25:30.284438 139683016574976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:25:30.284576 139683016574976 dqn_agent.py:280] 	 optimizer: adam
I0901 12:25:30.284730 139683016574976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:25:30.284841 139683016574976 dqn_agent.py:283] 	 seed: 1630499130283061
I0901 12:25:30.287908 139683016574976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:25:30.288115 139683016574976 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:25:30.288254 139683016574976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:25:30.288404 139683016574976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:25:30.288570 139683016574976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:25:30.288689 139683016574976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:25:30.288799 139683016574976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:25:30.288907 139683016574976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:25:30.289010 139683016574976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:25:30.550610 139683016574976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:30.992705 139683016574976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:31.006679 139683016574976 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:25:31.015053 139683016574976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:25:31.015305 139683016574976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:25:31.015424 139683016574976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:25:31.015558 139683016574976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:25:31.015653 139683016574976 dqn_agent.py:275] 	 update_period: 4
I0901 12:25:31.015744 139683016574976 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:25:31.015925 139683016574976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:25:31.016022 139683016574976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:25:31.016196 139683016574976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:25:31.016334 139683016574976 dqn_agent.py:280] 	 optimizer: adam
I0901 12:25:31.016443 139683016574976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:25:31.016539 139683016574976 dqn_agent.py:283] 	 seed: 1630499131014995
I0901 12:25:31.019056 139683016574976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:25:31.019263 139683016574976 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:25:31.019396 139683016574976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:25:31.019520 139683016574976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:25:31.019634 139683016574976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:25:31.019743 139683016574976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:25:31.019886 139683016574976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:25:31.019996 139683016574976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:25:31.020123 139683016574976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:25:31.052485 139683016574976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:31.074604 139683016574976 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:25:31.075009 139683016574976 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 155.33
I0901 12:25:37.513293 139683016574976 replay_runner.py:36] Average training steps per second: 155.33
Steps executed: 264 Episode length: 81 Return: -132.89679079134473
I0901 12:25:38.727402 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.93
INFO:tensorflow:Starting iteration 1

Steps executed: 91 Episode length: 91 Return: -294.648885380871773
INFO:tensorflow:Average training steps per second: 212.97

Steps executed: 293 Episode length: 97 Return: -150.42356633141645
I0901 12:25:48.033705 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -330.08
INFO:tensorflow:Starting iteration 2

Steps executed: 368 Episode length: 186 Return: -71.53548067056823
INFO:tensorflow:Average training steps per second: 212.06
I0901 12:25:57.202087 139683016574976 replay_runner.py:36] Average training steps per second: 212.06
I0901 12:25:57.584720 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -33.40
INFO:tensorflow:Starting iteration 3

Steps executed: 204 Episode length: 116 Return: -204.21858177462536
INFO:tensorflow:Average training steps per second: 212.27
I0901 12:26:06.803940 139683016574976 replay_runner.py:36] Average training steps per second: 212.27
I0901 12:26:07.000679 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -477.64
INFO:tensorflow:Starting iteration 4

Steps executed: 237 Episode length: 156 Return: -168.48895339418044
INFO:tensorflow:Average training steps per second: 206.80
I0901 12:26:16.284078 139683016574976 replay_runner.py:36] Average training steps per second: 206.80
I0901 12:26:16.524604 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -353.03
INFO:tensorflow:Starting iteration 5

Steps executed: 267 Episode length: 141 Return: -444.68829567481794
INFO:tensorflow:Average training steps per second: 214.47
I0901 12:26:25.478099 139683016574976 replay_runner.py:36] Average training steps per second: 214.47
I0901 12:26:25.746317 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -453.79
INFO:tensorflow:Starting iteration 6

Steps executed: 412 Episode length: 227 Return: -321.46045387832994
INFO:tensorflow:Average training steps per second: 214.59
I0901 12:26:34.882237 139683016574976 replay_runner.py:36] Average training steps per second: 214.59
I0901 12:26:35.349515 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -403.02
INFO:tensorflow:Starting iteration 7

Steps executed: 315 Episode length: 127 Return: -107.83029108629611
INFO:tensorflow:Average training steps per second: 215.46
I0901 12:26:44.272495 139683016574976 replay_runner.py:36] Average training steps per second: 215.46
I0901 12:26:44.582509 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -429.56
INFO:tensorflow:Starting iteration 8
I0901 12:26:48.877209 139683016574976 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 186.24

Steps executed: 252 Episode length: 100 Return: -336.15559413496965
I0901 12:26:54.488038 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.61
INFO:tensorflow:Starting iteration 9

Steps executed: 348 Episode length: 167 Return: -475.03795937331853
INFO:tensorflow:Average training steps per second: 215.37
I0901 12:27:03.539737 139683016574976 replay_runner.py:36] Average training steps per second: 215.37
I0901 12:27:03.911712 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.72
INFO:tensorflow:Starting iteration 10

Steps executed: 222 Episode length: 222 Return: -56.937795683287774
INFO:tensorflow:Average training steps per second: 216.70
I0901 12:27:13.020719 139683016574976 replay_runner.py:36] Average training steps per second: 216.70
I0901 12:27:13.249549 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -56.94
INFO:tensorflow:Starting iteration 11
I0901 12:27:17.571773 139683016574976 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 212.94

Steps executed: 298 Episode length: 196 Return: -95.683607599450063
I0901 12:27:22.604111 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.22
INFO:tensorflow:Starting iteration 12

Steps executed: 256 Episode length: 84 Return: -536.070255005510763
INFO:tensorflow:Average training steps per second: 216.33
I0901 12:27:31.493617 139683016574976 replay_runner.py:36] Average training steps per second: 216.33
I0901 12:27:31.725378 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -531.35
INFO:tensorflow:Starting iteration 13

Steps executed: 320 Episode length: 142 Return: -502.99945767202573
INFO:tensorflow:Average training steps per second: 213.46
I0901 12:27:40.907637 139683016574976 replay_runner.py:36] Average training steps per second: 213.46
I0901 12:27:41.253765 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -278.17
INFO:tensorflow:Starting iteration 14

Steps executed: 268 Episode length: 77 Return: -417.207329575317213
INFO:tensorflow:Average training steps per second: 230.23
I0901 12:27:50.054663 139683016574976 replay_runner.py:36] Average training steps per second: 230.23
I0901 12:27:50.294545 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.72
INFO:tensorflow:Starting iteration 15

Steps executed: 353 Episode length: 177 Return: -29.636930814163186
INFO:tensorflow:Average training steps per second: 229.47
I0901 12:27:59.040895 139683016574976 replay_runner.py:36] Average training steps per second: 229.47
I0901 12:27:59.360450 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.42
INFO:tensorflow:Starting iteration 16

Steps executed: 202 Episode length: 55 Return: -176.500534878411776
INFO:tensorflow:Average training steps per second: 229.06
I0901 12:28:08.207128 139683016574976 replay_runner.py:36] Average training steps per second: 229.06
I0901 12:28:08.348958 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.69
INFO:tensorflow:Starting iteration 17

Steps executed: 569 Episode length: 384 Return: 145.177631856545356
INFO:tensorflow:Average training steps per second: 230.71
I0901 12:28:17.145033 139683016574976 replay_runner.py:36] Average training steps per second: 230.71
I0901 12:28:17.843955 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -2.97
INFO:tensorflow:Starting iteration 18
I0901 12:28:22.224134 139683016574976 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 235.09

Steps executed: 419 Episode length: 419 Return: 176.045448449973266
I0901 12:28:27.104473 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: 176.05
INFO:tensorflow:Starting iteration 19

Steps executed: 209 Episode length: 115 Return: -24.328704450586514
INFO:tensorflow:Average training steps per second: 232.22
I0901 12:28:35.702597 139683016574976 replay_runner.py:36] Average training steps per second: 232.22
I0901 12:28:35.873832 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -25.95
INFO:tensorflow:Starting iteration 20
I0901 12:28:40.289181 139683016574976 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 221.38

Steps executed: 213 Episode length: 90 Return: -219.275610643468224
I0901 12:28:44.977457 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.24
INFO:tensorflow:Starting iteration 21

Steps executed: 301 Episode length: 143 Return: -35.976602185246165
INFO:tensorflow:Average training steps per second: 233.02
I0901 12:28:53.797740 139683016574976 replay_runner.py:36] Average training steps per second: 233.02
I0901 12:28:54.049156 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.77
INFO:tensorflow:Starting iteration 22

Steps executed: 266 Episode length: 70 Return: -141.471879398681447
INFO:tensorflow:Average training steps per second: 222.05
I0901 12:29:02.818218 139683016574976 replay_runner.py:36] Average training steps per second: 222.05
I0901 12:29:03.039158 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.71
INFO:tensorflow:Starting iteration 23

Steps executed: 259 Episode length: 150 Return: -551.20211833302237
INFO:tensorflow:Average training steps per second: 222.12
I0901 12:29:11.919096 139683016574976 replay_runner.py:36] Average training steps per second: 222.12
I0901 12:29:12.173073 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -532.83
INFO:tensorflow:Starting iteration 24

Steps executed: 217 Episode length: 97 Return: -315.189383643947467
INFO:tensorflow:Average training steps per second: 218.87
I0901 12:29:21.083660 139683016574976 replay_runner.py:36] Average training steps per second: 218.87
I0901 12:29:21.268553 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.80
INFO:tensorflow:Starting iteration 25

Steps executed: 203 Episode length: 64 Return: -166.447801087556177
INFO:tensorflow:Average training steps per second: 214.54
I0901 12:29:30.181110 139683016574976 replay_runner.py:36] Average training steps per second: 214.54
I0901 12:29:30.344255 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.22
INFO:tensorflow:Starting iteration 26

Steps executed: 394 Episode length: 394 Return: -293.75596890499167
INFO:tensorflow:Average training steps per second: 223.94
I0901 12:29:39.031373 139683016574976 replay_runner.py:36] Average training steps per second: 223.94
I0901 12:29:39.676515 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.76
INFO:tensorflow:Starting iteration 27
I0901 12:29:44.013847 139683016574976 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 219.78

Steps executed: 666 Episode length: 666 Return: -302.88100551622727
I0901 12:29:50.370824 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -302.88
INFO:tensorflow:Starting iteration 28

Steps executed: 187 Episode length: 187 Return: -187.53924248701537
INFO:tensorflow:Average training steps per second: 226.63

Steps executed: 846 Episode length: 659 Return: -319.10552878500967
I0901 12:30:00.820766 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.32
INFO:tensorflow:Starting iteration 29

Steps executed: 284 Episode length: 284 Return: -279.54486435747417
INFO:tensorflow:Average training steps per second: 225.40
I0901 12:30:09.648476 139683016574976 replay_runner.py:36] Average training steps per second: 225.40

Done fixed training!Episode length: 284 Return: -279.54486435747417