Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 13:08:43.215784 140315766171648 run_experiment.py:549] Creating TrainRunner ...
I0901 13:08:43.223854 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:08:43.224018 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:08:43.224099 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:08:43.224167 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:08:43.224233 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 13:08:43.224325 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:08:43.224460 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:08:43.224579 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:08:43.224658 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:08:43.224764 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 13:08:43.224876 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:08:43.224964 140315766171648 dqn_agent.py:283] 	 seed: 1630501723223812
I0901 13:08:43.227527 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:08:43.227664 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:08:43.227756 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:08:43.227825 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:08:43.227890 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:08:43.227974 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:08:43.228034 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:08:43.228144 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:08:43.228233 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:08:43.333117 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:43.594191 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:43.604008 140315766171648 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:08:43.611443 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:08:43.611608 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:08:43.611681 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:08:43.611752 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:08:43.611806 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 13:08:43.611881 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:08:43.612021 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:08:43.612089 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:08:43.612166 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:08:43.612225 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 13:08:43.612287 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:08:43.612354 140315766171648 dqn_agent.py:283] 	 seed: 1630501723611404
I0901 13:08:43.613695 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:08:43.613807 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:08:43.613878 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:08:43.613940 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:08:43.613995 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:08:43.614052 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:08:43.614131 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:08:43.614221 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:08:43.614301 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:08:43.636215 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:43.650415 140315766171648 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:08:43.650605 140315766171648 replay_runner.py:41] Starting iteration 0
Steps executed: 345 Episode length: 191 Return: -47.402419133746605
INFO:tensorflow:Average training steps per second: 250.23
I0901 13:08:47.647146 140315766171648 replay_runner.py:36] Average training steps per second: 250.23
I0901 13:08:48.514271 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.27
INFO:tensorflow:Starting iteration 1

Steps executed: 305 Episode length: 164 Return: -75.224202620187315
INFO:tensorflow:Average training steps per second: 342.18
I0901 13:08:54.912091 140315766171648 replay_runner.py:36] Average training steps per second: 342.18
I0901 13:08:55.100928 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.49
INFO:tensorflow:Starting iteration 2

Steps executed: 281 Episode length: 192 Return: -62.516195537251704
INFO:tensorflow:Average training steps per second: 343.98
I0901 13:09:01.408265 140315766171648 replay_runner.py:36] Average training steps per second: 343.98
I0901 13:09:01.591925 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.31
INFO:tensorflow:Starting iteration 3

Steps executed: 285 Episode length: 140 Return: -323.46061486886265
INFO:tensorflow:Average training steps per second: 342.24
I0901 13:09:07.972616 140315766171648 replay_runner.py:36] Average training steps per second: 342.24
I0901 13:09:08.147819 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -330.04
INFO:tensorflow:Starting iteration 4

Steps executed: 227 Episode length: 88 Return: -411.136072931566885
INFO:tensorflow:Average training steps per second: 335.76
I0901 13:09:14.593742 140315766171648 replay_runner.py:36] Average training steps per second: 335.76
I0901 13:09:14.720457 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -347.87
INFO:tensorflow:Starting iteration 5

Steps executed: 321 Episode length: 174 Return: -121.97711374710445
INFO:tensorflow:Average training steps per second: 341.71
I0901 13:09:21.106046 140315766171648 replay_runner.py:36] Average training steps per second: 341.71
I0901 13:09:21.293881 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.47
INFO:tensorflow:Starting iteration 6

Steps executed: 284 Episode length: 107 Return: -252.20409354183725
INFO:tensorflow:Average training steps per second: 336.19
I0901 13:09:27.722215 140315766171648 replay_runner.py:36] Average training steps per second: 336.19
I0901 13:09:27.856945 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.91
INFO:tensorflow:Starting iteration 7

Steps executed: 245 Episode length: 154 Return: -32.442730494564525
INFO:tensorflow:Average training steps per second: 338.27
I0901 13:09:34.290092 140315766171648 replay_runner.py:36] Average training steps per second: 338.27
I0901 13:09:34.421149 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.84
INFO:tensorflow:Starting iteration 8

Steps executed: 283 Episode length: 111 Return: -37.003759361689944
INFO:tensorflow:Average training steps per second: 336.93
I0901 13:09:40.884459 140315766171648 replay_runner.py:36] Average training steps per second: 336.93
I0901 13:09:41.029900 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -25.10
INFO:tensorflow:Starting iteration 9

Steps executed: 272 Episode length: 103 Return: -449.23331192586424
INFO:tensorflow:Average training steps per second: 332.88
I0901 13:09:47.545909 140315766171648 replay_runner.py:36] Average training steps per second: 332.88
I0901 13:09:47.674767 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.10
INFO:tensorflow:Starting iteration 10

Steps executed: 304 Episode length: 304 Return: -81.216957590819794
INFO:tensorflow:Average training steps per second: 327.13
I0901 13:09:54.254270 140315766171648 replay_runner.py:36] Average training steps per second: 327.13
I0901 13:09:54.794128 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.22
INFO:tensorflow:Starting iteration 11
I0901 13:09:58.293240 140315766171648 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 351.33
I0901 13:10:01.139963 140315766171648 replay_runner.py:36] Average training steps per second: 351.33

Steps executed: 255 Episode length: 255 Return: 137.459932175118794
INFO:tensorflow:Starting iteration 12

Steps executed: 231 Episode length: 102 Return: -96.599739158352754
INFO:tensorflow:Average training steps per second: 353.35
I0901 13:10:07.680330 140315766171648 replay_runner.py:36] Average training steps per second: 353.35
I0901 13:10:07.797698 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -49.90
INFO:tensorflow:Starting iteration 13
I0901 13:10:11.273291 140315766171648 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 349.16
I0901 13:10:14.137606 140315766171648 replay_runner.py:36] Average training steps per second: 349.16

Steps executed: 826 Episode length: 826 Return: -182.93081979277544
INFO:tensorflow:Starting iteration 14

Steps executed: 241 Episode length: 93 Return: -170.941031092433244
INFO:tensorflow:Average training steps per second: 340.71
I0901 13:10:21.789710 140315766171648 replay_runner.py:36] Average training steps per second: 340.71
I0901 13:10:21.941990 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.77
INFO:tensorflow:Starting iteration 15

Steps executed: 130 Episode length: 130 Return: -66.015893604739184
INFO:tensorflow:Average training steps per second: 352.47

Steps executed: 1130 Episode length: 1000 Return: 59.40950462766234
I0901 13:10:30.266343 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -3.30
INFO:tensorflow:Starting iteration 16
I0901 13:10:33.663188 140315766171648 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 343.11
I0901 13:10:36.577981 140315766171648 replay_runner.py:36] Average training steps per second: 343.11

Steps executed: 656 Episode length: 656 Return: -371.62116690608343
INFO:tensorflow:Starting iteration 17

Steps executed: 268 Episode length: 153 Return: -196.33111677637035
INFO:tensorflow:Average training steps per second: 324.45
I0901 13:10:43.844970 140315766171648 replay_runner.py:36] Average training steps per second: 324.45
I0901 13:10:43.997629 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.44
INFO:tensorflow:Starting iteration 18

Steps executed: 149 Episode length: 149 Return: -139.40713551838275
INFO:tensorflow:Average training steps per second: 319.84

Steps executed: 1127 Episode length: 978 Return: -383.5634631120291
I0901 13:10:52.000834 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.49
INFO:tensorflow:Starting iteration 19

Steps executed: 194 Episode length: 78 Return: -144.604919038538162
INFO:tensorflow:Average training steps per second: 315.86

Steps executed: 1194 Episode length: 1000 Return: -15.353220934060491
I0901 13:11:00.663517 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -53.49
INFO:tensorflow:Starting iteration 20

Steps executed: 303 Episode length: 303 Return: -207.1092676949029791
INFO:tensorflow:Average training steps per second: 353.38
I0901 13:11:06.909726 140315766171648 replay_runner.py:36] Average training steps per second: 353.38
I0901 13:11:07.101112 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.11
INFO:tensorflow:Starting iteration 21

Steps executed: 258 Episode length: 124 Return: -28.36939417324332791
INFO:tensorflow:Average training steps per second: 334.16
I0901 13:11:13.451078 140315766171648 replay_runner.py:36] Average training steps per second: 334.16
I0901 13:11:13.569724 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -2.60
INFO:tensorflow:Starting iteration 22

Steps executed: 256 Episode length: 256 Return: -284.6404525514796791
INFO:tensorflow:Average training steps per second: 311.53
I0901 13:11:19.848036 140315766171648 replay_runner.py:36] Average training steps per second: 311.53
I0901 13:11:20.027846 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.64
INFO:tensorflow:Starting iteration 23

Steps executed: 291 Episode length: 117 Return: -123.5225358138548291
INFO:tensorflow:Average training steps per second: 316.91
I0901 13:11:26.318820 140315766171648 replay_runner.py:36] Average training steps per second: 316.91
I0901 13:11:26.456657 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.74
INFO:tensorflow:Starting iteration 24

Steps executed: 253 Episode length: 253 Return: -29.85512368777770691
INFO:tensorflow:Average training steps per second: 317.23
I0901 13:11:32.681567 140315766171648 replay_runner.py:36] Average training steps per second: 317.23
I0901 13:11:32.845229 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -29.86
INFO:tensorflow:Starting iteration 25

Steps executed: 370 Episode length: 178 Return: -253.8218977367180691
INFO:tensorflow:Average training steps per second: 337.82
I0901 13:11:39.013520 140315766171648 replay_runner.py:36] Average training steps per second: 337.82
I0901 13:11:39.256298 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.66
INFO:tensorflow:Starting iteration 26
I0901 13:11:42.586005 140315766171648 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 345.61
I0901 13:11:45.479719 140315766171648 replay_runner.py:36] Average training steps per second: 345.61

Steps executed: 213 Episode length: 213 Return: -339.6738861965549691
INFO:tensorflow:Starting iteration 27
I0901 13:11:48.926230 140315766171648 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 360.73

Steps executed: 1000 Episode length: 1000 Return: -77.331576260308351
I0901 13:11:53.373908 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.33
INFO:tensorflow:Starting iteration 28
I0901 13:11:56.734737 140315766171648 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 339.72

Steps executed: 371 Episode length: 261 Return: -79.15319286582674551
I0901 13:11:59.942329 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.02
INFO:tensorflow:Starting iteration 29

Steps executed: 571 Episode length: 571 Return: -144.7636637026839751
INFO:tensorflow:Average training steps per second: 356.77
I0901 13:12:06.072082 140315766171648 replay_runner.py:36] Average training steps per second: 356.77

Done fixed training!Episode length: 571 Return: -144.7636637026839751