I0903 00:00:40.410295 139926926592000 run_experiment.py:549] Creating TrainRunner ...
I0903 00:00:40.418266 139926926592000 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:00:40.418394 139926926592000 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:00:40.418454 139926926592000 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:00:40.418533 139926926592000 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:00:40.418605 139926926592000 dqn_agent.py:275] 	 update_period: 4
I0903 00:00:40.418663 139926926592000 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:00:40.418715 139926926592000 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:00:40.418773 139926926592000 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:00:40.418873 139926926592000 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:00:40.418961 139926926592000 dqn_agent.py:280] 	 optimizer: adam
I0903 00:00:40.419035 139926926592000 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:00:40.419099 139926926592000 dqn_agent.py:283] 	 seed: 1630627240418234
I0903 00:00:40.420948 139926926592000 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:00:40.421077 139926926592000 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:00:40.421172 139926926592000 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:00:40.421240 139926926592000 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:00:40.421303 139926926592000 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:00:40.421406 139926926592000 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:00:40.421490 139926926592000 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:00:40.421560 139926926592000 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:00:40.421643 139926926592000 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:00:40.445843 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:00:40.699296 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:00:40.708734 139926926592000 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:00:40.714564 139926926592000 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:00:40.714691 139926926592000 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:00:40.714764 139926926592000 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:00:40.714825 139926926592000 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:00:40.714880 139926926592000 dqn_agent.py:275] 	 update_period: 4
I0903 00:00:40.714952 139926926592000 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:00:40.715035 139926926592000 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:00:40.715111 139926926592000 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:00:40.715166 139926926592000 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:00:40.715241 139926926592000 dqn_agent.py:280] 	 optimizer: adam
I0903 00:00:40.715330 139926926592000 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:00:40.715378 139926926592000 dqn_agent.py:283] 	 seed: 1630627240714536
I0903 00:00:40.716886 139926926592000 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:00:40.717031 139926926592000 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:00:40.717114 139926926592000 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:00:40.717215 139926926592000 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:00:40.717319 139926926592000 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:00:40.717390 139926926592000 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:00:40.717465 139926926592000 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:00:40.717544 139926926592000 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:00:40.717615 139926926592000 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:00:40.737901 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:00:40.752495 139926926592000 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:00:40.752647 139926926592000 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 256.64
I0903 00:00:44.649482 139926926592000 replay_runner.py:36] Average training steps per second: 256.64
I0903 00:00:45.518551 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -619.15
Steps executed: 275 Episode length: 82 Return: -780.45125266203256
INFO:tensorflow:Starting iteration 1

Steps executed: 269 Episode length: 171 Return: -546.0322715275615
INFO:tensorflow:Average training steps per second: 324.71
I0903 00:00:52.035386 139926926592000 replay_runner.py:36] Average training steps per second: 324.71
I0903 00:00:52.242604 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -530.48
INFO:tensorflow:Starting iteration 2

Steps executed: 440 Episode length: 246 Return: -184.24745816144787
INFO:tensorflow:Average training steps per second: 338.87
I0903 00:00:58.597762 139926926592000 replay_runner.py:36] Average training steps per second: 338.87
I0903 00:00:58.992771 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.85
INFO:tensorflow:Starting iteration 3

Steps executed: 608 Episode length: 445 Return: -52.219063453239436
INFO:tensorflow:Average training steps per second: 359.93
I0903 00:01:05.177329 139926926592000 replay_runner.py:36] Average training steps per second: 359.93
I0903 00:01:05.783355 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.24
INFO:tensorflow:Starting iteration 4
I0903 00:01:09.230364 139926926592000 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 363.01

Steps executed: 1000 Episode length: 1000 Return: -47.12925891289156
I0903 00:01:13.270672 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -47.13
INFO:tensorflow:Starting iteration 5
I0903 00:01:16.728967 139926926592000 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 336.48

Steps executed: 1000 Episode length: 1000 Return: -86.00551205465601
I0903 00:01:23.113590 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.01
INFO:tensorflow:Starting iteration 6
I0903 00:01:26.461906 139926926592000 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 345.28

Steps executed: 1000 Episode length: 1000 Return: -88.01155026038481
I0903 00:01:31.596824 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.01
INFO:tensorflow:Starting iteration 7
I0903 00:01:34.879627 139926926592000 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 327.26

Steps executed: 1000 Episode length: 1000 Return: -97.23030793462053
I0903 00:01:39.542250 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.23
INFO:tensorflow:Starting iteration 8
I0903 00:01:42.770914 139926926592000 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 323.74

Steps executed: 720 Episode length: 720 Return: -169.465014947883553
I0903 00:01:46.846950 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.47
INFO:tensorflow:Starting iteration 9

Steps executed: 544 Episode length: 544 Return: -241.428469765482873
INFO:tensorflow:Average training steps per second: 317.19
I0903 00:01:53.327213 139926926592000 replay_runner.py:36] Average training steps per second: 317.19
I0903 00:01:53.917706 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -241.43
INFO:tensorflow:Starting iteration 10
I0903 00:01:57.204005 139926926592000 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 334.87

Steps executed: 439 Episode length: 439 Return: -339.742921055037873
I0903 00:02:00.802546 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -339.74
INFO:tensorflow:Starting iteration 11
I0903 00:02:04.125296 139926926592000 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 334.14

Steps executed: 1000 Episode length: 1000 Return: -54.39216780179173
I0903 00:02:09.123321 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.39
INFO:tensorflow:Starting iteration 12

Steps executed: 129 Episode length: 129 Return: -51.4966892687220873
INFO:tensorflow:Average training steps per second: 346.93

Steps executed: 1129 Episode length: 1000 Return: -74.37440068434414
I0903 00:02:17.499863 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -62.94
INFO:tensorflow:Starting iteration 13
I0903 00:02:20.787004 139926926592000 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 349.78

Steps executed: 1000 Episode length: 1000 Return: -69.15236973876091
I0903 00:02:25.418966 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.15
INFO:tensorflow:Starting iteration 14

Steps executed: 86 Episode length: 86 Return: -93.990356788836046091
INFO:tensorflow:Average training steps per second: 339.36

Steps executed: 1086 Episode length: 1000 Return: -91.52976094564343
I0903 00:02:33.453960 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.76
INFO:tensorflow:Starting iteration 15
I0903 00:02:36.801980 139926926592000 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 333.74

Steps executed: 972 Episode length: 972 Return: -142.281816703775773
I0903 00:02:41.983567 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.28
INFO:tensorflow:Starting iteration 16

Steps executed: 160 Episode length: 160 Return: -152.258831771203123
INFO:tensorflow:Average training steps per second: 329.20

Steps executed: 1063 Episode length: 903 Return: -400.21333747920423
I0903 00:02:49.937375 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.24
INFO:tensorflow:Starting iteration 17
I0903 00:02:53.341367 139926926592000 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 333.51
I0903 00:02:56.340344 139926926592000 replay_runner.py:36] Average training steps per second: 333.51

Steps executed: 329 Episode length: 329 Return: -125.485422160423573
INFO:tensorflow:Starting iteration 18

Steps executed: 920 Episode length: 920 Return: -128.549715477917353
INFO:tensorflow:Average training steps per second: 351.23
I0903 00:03:02.849410 139926926592000 replay_runner.py:36] Average training steps per second: 351.23
I0903 00:03:04.403187 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.55
INFO:tensorflow:Starting iteration 19
I0903 00:03:07.882661 139926926592000 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 348.33

Steps executed: 327 Episode length: 327 Return: -32.5959072379344553
I0903 00:03:11.052063 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -32.60
INFO:tensorflow:Starting iteration 20

Steps executed: 206 Episode length: 206 Return: -335.208875307752853
INFO:tensorflow:Average training steps per second: 360.79
I0903 00:03:17.323244 139926926592000 replay_runner.py:36] Average training steps per second: 360.79
I0903 00:03:17.484607 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -335.21
INFO:tensorflow:Starting iteration 21
I0903 00:03:21.050570 139926926592000 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 363.98

Steps executed: 1000 Episode length: 1000 Return: -94.03328972463511
I0903 00:03:26.380607 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.03
INFO:tensorflow:Starting iteration 22
I0903 00:03:29.749174 139926926592000 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 331.69

Steps executed: 425 Episode length: 425 Return: -95.8333685327344411
I0903 00:03:33.298312 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.83
INFO:tensorflow:Starting iteration 23

Steps executed: 307 Episode length: 169 Return: -81.9541888218727811
INFO:tensorflow:Average training steps per second: 334.47
I0903 00:03:39.648799 139926926592000 replay_runner.py:36] Average training steps per second: 334.47
I0903 00:03:39.858360 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.48
INFO:tensorflow:Starting iteration 24

Steps executed: 263 Episode length: 263 Return: -280.488792234675311
INFO:tensorflow:Average training steps per second: 326.95
I0903 00:03:46.314793 139926926592000 replay_runner.py:36] Average training steps per second: 326.95
I0903 00:03:46.541474 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.49
INFO:tensorflow:Starting iteration 25
I0903 00:03:49.912168 139926926592000 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 331.86

Steps executed: 279 Episode length: 108 Return: -465.407667045113411
I0903 00:03:53.105695 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.51
INFO:tensorflow:Starting iteration 26

Steps executed: 324 Episode length: 175 Return: -65.0707430154684551
INFO:tensorflow:Average training steps per second: 357.92
I0903 00:03:59.291348 139926926592000 replay_runner.py:36] Average training steps per second: 357.92
I0903 00:03:59.507224 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.37
INFO:tensorflow:Starting iteration 27

Steps executed: 211 Episode length: 51 Return: -102.4861410395559351
INFO:tensorflow:Average training steps per second: 357.64
I0903 00:04:05.737378 139926926592000 replay_runner.py:36] Average training steps per second: 357.64
I0903 00:04:05.898177 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.57
INFO:tensorflow:Starting iteration 28

Steps executed: 211 Episode length: 211 Return: -106.235985311650811
INFO:tensorflow:Average training steps per second: 359.59
I0903 00:04:12.152533 139926926592000 replay_runner.py:36] Average training steps per second: 359.59
I0903 00:04:12.305771 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.24
INFO:tensorflow:Starting iteration 29
I0903 00:04:15.815681 139926926592000 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 363.35

Steps executed: 1108 Episode length: 921 Return: 202.154195113177221

Done fixed training! Episode length: 921 Return: 202.154195113177221