Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0828 10:37:44.296097 139779140274176 run_experiment.py:549] Creating TrainRunner ...
I0828 10:37:44.307087 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:44.307295 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:44.307389 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:44.307467 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:44.307531 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:44.307596 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:37:44.307651 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:44.307706 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:44.307804 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:44.307948 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:44.308128 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:44.308257 139779140274176 dqn_agent.py:283] 	 seed: 1630147064307032
I0828 10:37:44.311643 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:44.311849 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:37:44.312029 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:44.312178 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:44.312465 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:44.312587 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:44.312673 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:44.312746 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:44.312860 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:44.352438 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:45.037957 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:45.052029 139779140274176 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:37:45.085919 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:45.086258 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:45.086437 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:45.086583 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:45.087177 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:45.087616 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:37:45.087839 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:45.088253 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:45.088493 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:45.088912 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:45.089272 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:45.089522 139779140274176 dqn_agent.py:283] 	 seed: 1630147065085660
I0828 10:37:45.093429 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:45.093712 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:37:45.093891 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:45.094079 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:45.094337 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:45.094510 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:45.094668 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:45.094827 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:45.094954 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:45.126008 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:45.146876 139779140274176 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:37:45.147175 139779140274176 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 163.35
I0828 10:37:51.269393 139779140274176 replay_runner.py:36] Average training steps per second: 163.35
I0828 10:37:52.547113 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -430.51
Steps executed: 217 Episode length: 86 Return: -764.5647656605224
INFO:tensorflow:Starting iteration 1

Steps executed: 260 Episode length: 65 Return: -576.53679242784343
INFO:tensorflow:Average training steps per second: 224.35
I0828 10:38:01.304352 139779140274176 replay_runner.py:36] Average training steps per second: 224.35
I0828 10:38:01.544150 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -510.15
INFO:tensorflow:Starting iteration 2

Steps executed: 234 Episode length: 234 Return: -359.76862475102075
INFO:tensorflow:Average training steps per second: 219.53
I0828 10:38:10.422457 139779140274176 replay_runner.py:36] Average training steps per second: 219.53
I0828 10:38:10.691833 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.77
INFO:tensorflow:Starting iteration 3

Steps executed: 119 Episode length: 119 Return: -460.11757775346135
INFO:tensorflow:Average training steps per second: 218.73
I0828 10:38:19.669156 139779140274176 replay_runner.py:36] Average training steps per second: 218.73

Steps executed: 322 Episode length: 203 Return: -636.26090800408535
INFO:tensorflow:Starting iteration 4

Steps executed: 206 Episode length: 109 Return: -185.51199205431152
INFO:tensorflow:Average training steps per second: 226.21
I0828 10:38:28.848245 139779140274176 replay_runner.py:36] Average training steps per second: 226.21
I0828 10:38:29.030216 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.51
INFO:tensorflow:Starting iteration 5

Steps executed: 264 Episode length: 102 Return: -158.27547111129255
INFO:tensorflow:Average training steps per second: 224.96
I0828 10:38:37.832544 139779140274176 replay_runner.py:36] Average training steps per second: 224.96
I0828 10:38:38.049305 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.02
INFO:tensorflow:Starting iteration 6

Steps executed: 244 Episode length: 84 Return: -123.533462101174455
INFO:tensorflow:Average training steps per second: 220.67
I0828 10:38:46.997057 139779140274176 replay_runner.py:36] Average training steps per second: 220.67
I0828 10:38:47.177185 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.54
INFO:tensorflow:Starting iteration 7
I0828 10:38:51.620182 139779140274176 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 224.50

Steps executed: 423 Episode length: 256 Return: -1486.7263453832654
I0828 10:38:56.578576 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -1140.79
INFO:tensorflow:Starting iteration 8

Steps executed: 429 Episode length: 234 Return: -1900.9393438481677
INFO:tensorflow:Average training steps per second: 225.98
I0828 10:39:05.367040 139779140274176 replay_runner.py:36] Average training steps per second: 225.98
I0828 10:39:05.777555 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -743.21
INFO:tensorflow:Starting iteration 9

Steps executed: 219 Episode length: 62 Return: -329.137410268037377
INFO:tensorflow:Average training steps per second: 233.92
I0828 10:39:14.523713 139779140274176 replay_runner.py:36] Average training steps per second: 233.92
I0828 10:39:14.695366 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.94
INFO:tensorflow:Starting iteration 10

Steps executed: 204 Episode length: 70 Return: -332.848288711681877
INFO:tensorflow:Average training steps per second: 221.15
I0828 10:39:23.491388 139779140274176 replay_runner.py:36] Average training steps per second: 221.15
I0828 10:39:23.683212 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.43
INFO:tensorflow:Starting iteration 11
I0828 10:39:28.076790 139779140274176 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 234.17

Steps executed: 220 Episode length: 81 Return: -762.944614550524177
I0828 10:39:32.525275 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -609.02
INFO:tensorflow:Starting iteration 12

Steps executed: 257 Episode length: 66 Return: -130.404074265817777
INFO:tensorflow:Average training steps per second: 227.31
I0828 10:39:41.264040 139779140274176 replay_runner.py:36] Average training steps per second: 227.31
I0828 10:39:41.423864 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.26
INFO:tensorflow:Starting iteration 13

Steps executed: 252 Episode length: 106 Return: -126.18689799331361
INFO:tensorflow:Average training steps per second: 227.27
I0828 10:39:50.151704 139779140274176 replay_runner.py:36] Average training steps per second: 227.27
I0828 10:39:50.385047 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.70
INFO:tensorflow:Starting iteration 14

Steps executed: 284 Episode length: 86 Return: -358.178184504475678
INFO:tensorflow:Average training steps per second: 230.15
I0828 10:39:59.121725 139779140274176 replay_runner.py:36] Average training steps per second: 230.15
I0828 10:39:59.337508 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.57
INFO:tensorflow:Starting iteration 15

Steps executed: 220 Episode length: 57 Return: -98.4045853430798238
INFO:tensorflow:Average training steps per second: 230.02
I0828 10:40:08.020840 139779140274176 replay_runner.py:36] Average training steps per second: 230.02
I0828 10:40:08.168039 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.07
INFO:tensorflow:Starting iteration 16

Steps executed: 209 Episode length: 55 Return: -311.563667977734138
INFO:tensorflow:Average training steps per second: 233.43
I0828 10:40:16.851857 139779140274176 replay_runner.py:36] Average training steps per second: 233.43
I0828 10:40:17.021377 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -414.88
INFO:tensorflow:Starting iteration 17

Steps executed: 276 Episode length: 77 Return: -755.904945782882168
INFO:tensorflow:Average training steps per second: 227.86
I0828 10:40:25.642370 139779140274176 replay_runner.py:36] Average training steps per second: 227.86
I0828 10:40:25.859525 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -557.13
INFO:tensorflow:Starting iteration 18
I0828 10:40:30.243587 139779140274176 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 223.73

Steps executed: 229 Episode length: 80 Return: -626.494834599898248
I0828 10:40:34.931954 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -728.12
INFO:tensorflow:Starting iteration 19

Steps executed: 221 Episode length: 84 Return: -152.381948632483348
INFO:tensorflow:Average training steps per second: 222.05
I0828 10:40:43.904266 139779140274176 replay_runner.py:36] Average training steps per second: 222.05
I0828 10:40:44.045127 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.88
INFO:tensorflow:Starting iteration 20

Steps executed: 310 Episode length: 116 Return: -419.28598734559428
INFO:tensorflow:Average training steps per second: 220.17
I0828 10:40:53.059115 139779140274176 replay_runner.py:36] Average training steps per second: 220.17
I0828 10:40:53.307498 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.49
INFO:tensorflow:Starting iteration 21

Steps executed: 256 Episode length: 60 Return: -225.862388104418268
INFO:tensorflow:Average training steps per second: 225.84
I0828 10:41:02.067898 139779140274176 replay_runner.py:36] Average training steps per second: 225.84
I0828 10:41:02.307377 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.69
INFO:tensorflow:Starting iteration 22

Steps executed: 273 Episode length: 80 Return: -228.354869772533828
INFO:tensorflow:Average training steps per second: 223.83
I0828 10:41:11.204107 139779140274176 replay_runner.py:36] Average training steps per second: 223.83
I0828 10:41:11.435028 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.54
INFO:tensorflow:Starting iteration 23

Steps executed: 170 Episode length: 55 Return: -114.129425875505428
INFO:tensorflow:Average training steps per second: 226.07
I0828 10:41:20.346269 139779140274176 replay_runner.py:36] Average training steps per second: 226.07

Steps executed: 231 Episode length: 61 Return: -116.290698856906068
INFO:tensorflow:Starting iteration 24

Steps executed: 213 Episode length: 63 Return: -594.008257632195868
INFO:tensorflow:Average training steps per second: 223.71
I0828 10:41:29.479520 139779140274176 replay_runner.py:36] Average training steps per second: 223.71
I0828 10:41:29.666773 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -602.61
INFO:tensorflow:Starting iteration 25

Steps executed: 222 Episode length: 84 Return: -443.325993870996238
INFO:tensorflow:Average training steps per second: 226.89
I0828 10:41:38.675904 139779140274176 replay_runner.py:36] Average training steps per second: 226.89
I0828 10:41:38.888730 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -675.62
INFO:tensorflow:Starting iteration 26

Steps executed: 311 Episode length: 118 Return: -665.08636719751319
INFO:tensorflow:Average training steps per second: 223.94
I0828 10:41:47.617550 139779140274176 replay_runner.py:36] Average training steps per second: 223.94
I0828 10:41:47.896432 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -448.72
INFO:tensorflow:Starting iteration 27

Steps executed: 76 Episode length: 76 Return: -475.5768747261174719
INFO:tensorflow:Average training steps per second: 226.67

Steps executed: 215 Episode length: 64 Return: -411.190631392086449
I0828 10:41:56.771149 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.38
INFO:tensorflow:Starting iteration 28

Steps executed: 269 Episode length: 76 Return: -503.706473693679649
INFO:tensorflow:Average training steps per second: 221.46
I0828 10:42:05.585387 139779140274176 replay_runner.py:36] Average training steps per second: 221.46
I0828 10:42:05.827934 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -422.22
INFO:tensorflow:Starting iteration 29

Steps executed: 229 Episode length: 82 Return: -364.710436682141859
INFO:tensorflow:Average training steps per second: 232.53
I0828 10:42:14.460513 139779140274176 replay_runner.py:36] Average training steps per second: 232.53

Done fixed training!Episode length: 82 Return: -364.710436682141859