Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0902 00:30:48.282380 140149719906304 run_experiment.py:549] Creating TrainRunner ...
I0902 00:30:48.290323 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:30:48.290458 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:30:48.290539 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:30:48.290607 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:30:48.290670 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0902 00:30:48.290729 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:30:48.290832 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:30:48.290931 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:30:48.291003 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:30:48.291078 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0902 00:30:48.291161 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:30:48.291223 140149719906304 dqn_agent.py:283] 	 seed: 1630542648290283
I0902 00:30:48.293187 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:30:48.293315 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:30:48.293400 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:30:48.293471 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:30:48.293541 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:30:48.293625 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:30:48.293767 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:30:48.293877 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:30:48.293975 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:30:48.319696 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:30:48.575329 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:30:48.585077 140149719906304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:30:48.592087 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:30:48.592278 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:30:48.592360 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:30:48.592429 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:30:48.592507 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0902 00:30:48.592597 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:30:48.592668 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:30:48.592739 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:30:48.592794 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:30:48.592903 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0902 00:30:48.592976 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:30:48.593048 140149719906304 dqn_agent.py:283] 	 seed: 1630542648592055
I0902 00:30:48.594492 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:30:48.594601 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:30:48.594671 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:30:48.594734 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:30:48.594810 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:30:48.594864 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:30:48.594936 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:30:48.595005 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:30:48.595064 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:30:48.614471 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:30:48.630469 140149719906304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:30:48.630610 140149719906304 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 247.44
I0902 00:30:52.672131 140149719906304 replay_runner.py:36] Average training steps per second: 247.44
I0902 00:30:53.440418 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -679.83
Steps executed: 289 Episode length: 102 Return: -649.0227242419385
INFO:tensorflow:Starting iteration 1

Steps executed: 216 Episode length: 110 Return: -117.79058728704149
INFO:tensorflow:Average training steps per second: 341.08
I0902 00:30:59.642717 140149719906304 replay_runner.py:36] Average training steps per second: 341.08
I0902 00:30:59.787635 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -533.53
INFO:tensorflow:Starting iteration 2

Steps executed: 258 Episode length: 135 Return: -426.77750950981479
INFO:tensorflow:Average training steps per second: 348.00
I0902 00:31:05.958167 140149719906304 replay_runner.py:36] Average training steps per second: 348.00
I0902 00:31:06.132943 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -452.47
INFO:tensorflow:Starting iteration 3

Steps executed: 327 Episode length: 327 Return: -539.96488148347439
INFO:tensorflow:Average training steps per second: 352.01
I0902 00:31:12.286842 140149719906304 replay_runner.py:36] Average training steps per second: 352.01
I0902 00:31:12.615311 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -539.96
INFO:tensorflow:Starting iteration 4

Steps executed: 264 Episode length: 160 Return: -247.31758797187805
INFO:tensorflow:Average training steps per second: 342.73
I0902 00:31:18.815420 140149719906304 replay_runner.py:36] Average training steps per second: 342.73
I0902 00:31:18.992406 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -222.04
INFO:tensorflow:Starting iteration 5

Steps executed: 320 Episode length: 212 Return: -62.672061837629094
INFO:tensorflow:Average training steps per second: 346.21
I0902 00:31:25.252706 140149719906304 replay_runner.py:36] Average training steps per second: 346.21
I0902 00:31:25.457414 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.86
INFO:tensorflow:Starting iteration 6
I0902 00:31:28.892175 140149719906304 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 341.78

Steps executed: 814 Episode length: 814 Return: -449.62444965620764
I0902 00:31:33.696697 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -449.62
INFO:tensorflow:Starting iteration 7
I0902 00:31:37.090240 140149719906304 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 330.21

Steps executed: 209 Episode length: 209 Return: -112.83098704585018
I0902 00:31:40.285963 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.83
INFO:tensorflow:Starting iteration 8

Steps executed: 410 Episode length: 217 Return: -531.46316736642058
INFO:tensorflow:Average training steps per second: 348.54
I0902 00:31:46.538655 140149719906304 replay_runner.py:36] Average training steps per second: 348.54
I0902 00:31:46.812479 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -530.55
INFO:tensorflow:Starting iteration 9

Steps executed: 706 Episode length: 706 Return: -456.85611993289314
INFO:tensorflow:Average training steps per second: 353.50
I0902 00:31:53.117989 140149719906304 replay_runner.py:36] Average training steps per second: 353.50
I0902 00:31:54.072866 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -456.86
INFO:tensorflow:Starting iteration 10

Steps executed: 398 Episode length: 398 Return: -289.83657983022596
INFO:tensorflow:Average training steps per second: 339.25
I0902 00:32:00.477385 140149719906304 replay_runner.py:36] Average training steps per second: 339.25
I0902 00:32:00.852389 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.84
INFO:tensorflow:Starting iteration 11

Steps executed: 205 Episode length: 205 Return: -452.14920943143766
INFO:tensorflow:Average training steps per second: 320.37
I0902 00:32:07.241875 140149719906304 replay_runner.py:36] Average training steps per second: 320.37
I0902 00:32:07.367421 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -452.15
INFO:tensorflow:Starting iteration 12

Steps executed: 248 Episode length: 248 Return: -345.89001898160946
INFO:tensorflow:Average training steps per second: 301.73
I0902 00:32:13.852115 140149719906304 replay_runner.py:36] Average training steps per second: 301.73
I0902 00:32:14.050618 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -345.89
INFO:tensorflow:Starting iteration 13
I0902 00:32:17.202797 140149719906304 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 334.99

Steps executed: 357 Episode length: 357 Return: -342.59701132422185
I0902 00:32:20.574858 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.60
INFO:tensorflow:Starting iteration 14

Steps executed: 316 Episode length: 160 Return: -154.23987873896073
INFO:tensorflow:Average training steps per second: 351.15
I0902 00:32:26.771480 140149719906304 replay_runner.py:36] Average training steps per second: 351.15
I0902 00:32:26.966146 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.12
INFO:tensorflow:Starting iteration 15

Steps executed: 466 Episode length: 466 Return: -258.43892562011563
INFO:tensorflow:Average training steps per second: 355.88
I0902 00:32:33.259788 140149719906304 replay_runner.py:36] Average training steps per second: 355.88
I0902 00:32:33.785360 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.44
INFO:tensorflow:Starting iteration 16

Steps executed: 326 Episode length: 136 Return: -452.17152274693723
INFO:tensorflow:Average training steps per second: 339.01
I0902 00:32:40.159300 140149719906304 replay_runner.py:36] Average training steps per second: 339.01
I0902 00:32:40.374325 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -414.48
INFO:tensorflow:Starting iteration 17

Steps executed: 263 Episode length: 122 Return: -314.54133893379933
INFO:tensorflow:Average training steps per second: 348.26
I0902 00:32:46.682803 140149719906304 replay_runner.py:36] Average training steps per second: 348.26
I0902 00:32:46.836594 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.78
INFO:tensorflow:Starting iteration 18

Steps executed: 314 Episode length: 138 Return: -71.809185397289643
INFO:tensorflow:Average training steps per second: 339.53
I0902 00:32:53.236436 140149719906304 replay_runner.py:36] Average training steps per second: 339.53
I0902 00:32:53.388723 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.02
INFO:tensorflow:Starting iteration 19

Steps executed: 208 Episode length: 55 Return: -294.473885754058743
INFO:tensorflow:Average training steps per second: 351.25
I0902 00:32:59.694283 140149719906304 replay_runner.py:36] Average training steps per second: 351.25
I0902 00:32:59.811887 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -356.81
INFO:tensorflow:Starting iteration 20

Steps executed: 271 Episode length: 154 Return: -232.81965543877618
INFO:tensorflow:Average training steps per second: 358.84
I0902 00:33:06.072253 140149719906304 replay_runner.py:36] Average training steps per second: 358.84
I0902 00:33:06.239171 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.95
INFO:tensorflow:Starting iteration 21

Steps executed: 160 Episode length: 160 Return: -123.14661662788018
INFO:tensorflow:Average training steps per second: 359.59
I0902 00:33:12.504388 140149719906304 replay_runner.py:36] Average training steps per second: 359.59

Steps executed: 333 Episode length: 173 Return: -146.66128257914147
INFO:tensorflow:Starting iteration 22

Steps executed: 245 Episode length: 85 Return: -393.930485386185647
INFO:tensorflow:Average training steps per second: 359.60
I0902 00:33:18.973323 140149719906304 replay_runner.py:36] Average training steps per second: 359.60
I0902 00:33:19.094620 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.74
INFO:tensorflow:Starting iteration 23

Steps executed: 304 Episode length: 165 Return: -166.11487428040726
INFO:tensorflow:Average training steps per second: 343.49
I0902 00:33:25.527008 140149719906304 replay_runner.py:36] Average training steps per second: 343.49
I0902 00:33:25.711185 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.45
INFO:tensorflow:Starting iteration 24

Steps executed: 313 Episode length: 136 Return: -97.959416377637542
INFO:tensorflow:Average training steps per second: 348.32
I0902 00:33:32.053757 140149719906304 replay_runner.py:36] Average training steps per second: 348.32
I0902 00:33:32.213134 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -441.26
INFO:tensorflow:Starting iteration 25

Steps executed: 220 Episode length: 155 Return: -637.16900611465942
INFO:tensorflow:Average training steps per second: 339.67
I0902 00:33:38.617084 140149719906304 replay_runner.py:36] Average training steps per second: 339.67
I0902 00:33:38.745553 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -575.75
INFO:tensorflow:Starting iteration 26

Steps executed: 290 Episode length: 114 Return: -162.87054198864558
INFO:tensorflow:Average training steps per second: 340.76
I0902 00:33:45.108608 140149719906304 replay_runner.py:36] Average training steps per second: 340.76
I0902 00:33:45.287764 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.21
INFO:tensorflow:Starting iteration 27

Steps executed: 247 Episode length: 116 Return: -467.33036981280856
INFO:tensorflow:Average training steps per second: 338.63
I0902 00:33:51.693434 140149719906304 replay_runner.py:36] Average training steps per second: 338.63
I0902 00:33:51.831298 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -315.67
INFO:tensorflow:Starting iteration 28

Steps executed: 220 Episode length: 90 Return: -519.978669680906983
INFO:tensorflow:Average training steps per second: 341.24
I0902 00:33:58.228796 140149719906304 replay_runner.py:36] Average training steps per second: 341.24
I0902 00:33:58.338155 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.15
INFO:tensorflow:Starting iteration 29

Steps executed: 223 Episode length: 74 Return: -182.821441881156133
INFO:tensorflow:Average training steps per second: 350.43
I0902 00:34:04.618156 140149719906304 replay_runner.py:36] Average training steps per second: 350.43

Done fixed training!Episode length: 74 Return: -182.821441881156133