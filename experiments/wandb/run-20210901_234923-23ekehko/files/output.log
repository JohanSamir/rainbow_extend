I0901 23:49:30.535199 140252174653440 run_experiment.py:549] Creating TrainRunner ...
I0901 23:49:30.546334 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:30.546574 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:30.546688 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:30.546765 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:30.546833 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:30.546915 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:30.547048 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:30.547227 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:30.547357 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:30.547447 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:30.547578 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:30.547737 140252174653440 dqn_agent.py:283] 	 seed: 1630540170546259
I0901 23:49:30.550351 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:30.550490 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:30.550603 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:30.550795 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:30.550909 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:30.550989 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:30.551061 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:30.551140 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:30.551239 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0901 23:49:32.356933 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:32.726674 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:32.740900 140252174653440 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:49:32.748686 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:32.748923 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:32.749074 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:32.749227 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:32.749323 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:32.749400 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:32.749471 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:32.749568 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:32.749638 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:32.749721 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:32.749790 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:32.749928 140252174653440 dqn_agent.py:283] 	 seed: 1630540172748600
I0901 23:49:32.752506 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:32.752748 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:32.752919 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:32.753077 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:32.753232 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:32.753357 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:32.753481 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:32.753662 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:32.753852 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:49:32.788526 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:32.810127 140252174653440 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:49:32.810393 140252174653440 replay_runner.py:41] Starting iteration 0
Steps executed: 106 Episode length: 106 Return: -373.2098329265552
INFO:tensorflow:Average training steps per second: 164.84

Steps executed: 408 Episode length: 302 Return: -320.1150992209125
I0901 23:49:40.422928 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.66
INFO:tensorflow:Starting iteration 1

Steps executed: 301 Episode length: 163 Return: -383.55964539197726
INFO:tensorflow:Average training steps per second: 222.98
I0901 23:49:49.278537 140252174653440 replay_runner.py:36] Average training steps per second: 222.98
I0901 23:49:49.554235 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.76
INFO:tensorflow:Starting iteration 2
I0901 23:49:53.798533 140252174653440 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 228.71

Steps executed: 279 Episode length: 119 Return: -85.677269436957237
I0901 23:49:58.412410 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.13
INFO:tensorflow:Starting iteration 3
I0901 23:50:02.703291 140252174653440 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 230.57

Steps executed: 1000 Episode length: 1000 Return: -120.10928798638462
I0901 23:50:11.018678 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.11
INFO:tensorflow:Starting iteration 4
I0901 23:50:15.307231 140252174653440 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 229.76

Steps executed: 1000 Episode length: 1000 Return: -194.88921028219994
I0901 23:50:22.707087 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -194.89
INFO:tensorflow:Starting iteration 5
I0901 23:50:27.021446 140252174653440 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 233.89

Steps executed: 1000 Episode length: 1000 Return: -174.82735006614723
I0901 23:50:32.903693 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.83
INFO:tensorflow:Starting iteration 6
I0901 23:50:37.148732 140252174653440 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 253.67

Steps executed: 899 Episode length: 899 Return: -1823.523585043884723
I0901 23:50:43.281780 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -1823.52
INFO:tensorflow:Starting iteration 7

Steps executed: 80 Episode length: 80 Return: -61.4870605849355584723
INFO:tensorflow:Average training steps per second: 246.44

Steps executed: 1080 Episode length: 1000 Return: -72.622366331284213
I0901 23:50:53.914773 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -67.05
INFO:tensorflow:Starting iteration 8
I0901 23:50:58.228532 140252174653440 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 233.35

Steps executed: 866 Episode length: 866 Return: -278.5810541279844213
I0901 23:51:04.319462 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -278.58
INFO:tensorflow:Starting iteration 9

Steps executed: 384 Episode length: 384 Return: -1667.772635242775613
INFO:tensorflow:Average training steps per second: 222.87
I0901 23:51:13.130142 140252174653440 replay_runner.py:36] Average training steps per second: 222.87
I0901 23:51:13.660400 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -1667.77
INFO:tensorflow:Starting iteration 10
I0901 23:51:18.015679 140252174653440 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 221.07

Steps executed: 336 Episode length: 172 Return: -721.6688300131405613
I0901 23:51:22.912754 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -680.53
INFO:tensorflow:Starting iteration 11

Steps executed: 248 Episode length: 73 Return: -134.96237916910252613
INFO:tensorflow:Average training steps per second: 222.38
I0901 23:51:31.759486 140252174653440 replay_runner.py:36] Average training steps per second: 222.38
I0901 23:51:32.007453 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.28
INFO:tensorflow:Starting iteration 12
I0901 23:51:36.355093 140252174653440 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 227.59

Steps executed: 204 Episode length: 204 Return: -176.2626227025820413
I0901 23:51:40.981256 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.26
INFO:tensorflow:Starting iteration 13
I0901 23:51:45.390676 140252174653440 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 229.70

Steps executed: 1000 Episode length: 1000 Return: -238.46793319295193
I0901 23:51:52.736474 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -238.47
INFO:tensorflow:Starting iteration 14

Steps executed: 156 Episode length: 156 Return: -108.4838013910838693
INFO:tensorflow:Average training steps per second: 226.94

Steps executed: 906 Episode length: 750 Return: -291.6066146036269593
I0901 23:52:03.745849 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.05
INFO:tensorflow:Starting iteration 15
I0901 23:52:08.152486 140252174653440 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 226.01

Steps executed: 1000 Episode length: 1000 Return: -132.87453974320593
I0901 23:52:15.327150 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.87
INFO:tensorflow:Starting iteration 16

Steps executed: 148 Episode length: 148 Return: -110.8600057635937693
INFO:tensorflow:Average training steps per second: 223.42
I0901 23:52:24.244719 140252174653440 replay_runner.py:36] Average training steps per second: 223.42

Steps executed: 408 Episode length: 260 Return: -74.21714089532357693
INFO:tensorflow:Starting iteration 17

Steps executed: 317 Episode length: 153 Return: -124.5512441278924693
INFO:tensorflow:Average training steps per second: 222.26
I0901 23:52:33.550634 140252174653440 replay_runner.py:36] Average training steps per second: 222.26
I0901 23:52:33.813312 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.53
INFO:tensorflow:Starting iteration 18
I0901 23:52:38.079118 140252174653440 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 222.77

Steps executed: 230 Episode length: 230 Return: -97.51241548649287693
I0901 23:52:42.823695 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.51
INFO:tensorflow:Starting iteration 19

Steps executed: 216 Episode length: 216 Return: -459.9790477102433693
INFO:tensorflow:Average training steps per second: 228.92
I0901 23:52:51.589746 140252174653440 replay_runner.py:36] Average training steps per second: 228.92
I0901 23:52:51.804310 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -459.98
INFO:tensorflow:Starting iteration 20

Steps executed: 157 Episode length: 157 Return: -29.99834955700619393
INFO:tensorflow:Average training steps per second: 220.04

Steps executed: 289 Episode length: 132 Return: -725.7946709294859393
I0901 23:53:00.772433 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.90
INFO:tensorflow:Starting iteration 21

Steps executed: 288 Episode length: 164 Return: -523.0469939866794393
INFO:tensorflow:Average training steps per second: 227.73
I0901 23:53:09.389404 140252174653440 replay_runner.py:36] Average training steps per second: 227.73
I0901 23:53:09.635636 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -505.06
INFO:tensorflow:Starting iteration 22

Steps executed: 186 Episode length: 123 Return: -111.0325429411176793
INFO:tensorflow:Average training steps per second: 217.04

Steps executed: 1162 Episode length: 976 Return: -67.2140861672026793
I0901 23:53:22.115535 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.69
INFO:tensorflow:Starting iteration 23

Steps executed: 291 Episode length: 156 Return: -338.5405177045358393
INFO:tensorflow:Average training steps per second: 232.65
I0901 23:53:30.891440 140252174653440 replay_runner.py:36] Average training steps per second: 232.65
I0901 23:53:31.132376 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -241.92
INFO:tensorflow:Starting iteration 24

Steps executed: 311 Episode length: 185 Return: -104.3465831135632793
INFO:tensorflow:Average training steps per second: 244.95
I0901 23:53:39.547908 140252174653440 replay_runner.py:36] Average training steps per second: 244.95
I0901 23:53:39.803020 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.68
INFO:tensorflow:Starting iteration 25

Steps executed: 217 Episode length: 71 Return: -136.87684919483198793
INFO:tensorflow:Average training steps per second: 239.26
I0901 23:53:48.186202 140252174653440 replay_runner.py:36] Average training steps per second: 239.26
I0901 23:53:48.344406 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.30
INFO:tensorflow:Starting iteration 26

Steps executed: 53 Episode length: 53 Return: -115.636101941749128793
INFO:tensorflow:Average training steps per second: 234.20

Steps executed: 523 Episode length: 410 Return: -570.2563842208119793
I0901 23:53:57.669991 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.60
INFO:tensorflow:Starting iteration 27

Steps executed: 377 Episode length: 223 Return: -89.86399029461985493
INFO:tensorflow:Average training steps per second: 231.37
I0901 23:54:06.253370 140252174653440 replay_runner.py:36] Average training steps per second: 231.37
I0901 23:54:06.651878 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.44
INFO:tensorflow:Starting iteration 28

Steps executed: 249 Episode length: 79 Return: -436.98847825252795493
INFO:tensorflow:Average training steps per second: 235.12
I0901 23:54:15.201011 140252174653440 replay_runner.py:36] Average training steps per second: 235.12
I0901 23:54:15.406247 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.06
INFO:tensorflow:Starting iteration 29

Steps executed: 374 Episode length: 320 Return: -655.0659009882744493
INFO:tensorflow:Average training steps per second: 221.34
I0901 23:54:24.165833 140252174653440 replay_runner.py:36] Average training steps per second: 221.34

Done fixed training!Episode length: 320 Return: -655.0659009882744493