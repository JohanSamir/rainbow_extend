I0901 13:12:12.113815 140240877414400 run_experiment.py:549] Creating TrainRunner ...
I0901 13:12:12.120784 140240877414400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:12:12.120904 140240877414400 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:12:12.121015 140240877414400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:12:12.121112 140240877414400 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:12:12.121185 140240877414400 dqn_agent.py:275] 	 update_period: 4
I0901 13:12:12.121254 140240877414400 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:12:12.121318 140240877414400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:12:12.121438 140240877414400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:12:12.121517 140240877414400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:12:12.121570 140240877414400 dqn_agent.py:280] 	 optimizer: adam
I0901 13:12:12.121623 140240877414400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:12:12.121707 140240877414400 dqn_agent.py:283] 	 seed: 1630501932120753
I0901 13:12:12.123517 140240877414400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:12:12.123623 140240877414400 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:12:12.123709 140240877414400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:12:12.123789 140240877414400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:12:12.123844 140240877414400 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:12:12.123924 140240877414400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:12:12.123993 140240877414400 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:12:12.124070 140240877414400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:12:12.124166 140240877414400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:12:12.213660 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:12:12.426388 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:12:12.435470 140240877414400 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:12:12.441524 140240877414400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:12:12.441654 140240877414400 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:12:12.441735 140240877414400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:12:12.441797 140240877414400 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:12:12.441854 140240877414400 dqn_agent.py:275] 	 update_period: 4
I0901 13:12:12.441927 140240877414400 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:12:12.442038 140240877414400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:12:12.442106 140240877414400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:12:12.442178 140240877414400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:12:12.442250 140240877414400 dqn_agent.py:280] 	 optimizer: adam
I0901 13:12:12.442321 140240877414400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:12:12.442386 140240877414400 dqn_agent.py:283] 	 seed: 1630501932441494
I0901 13:12:12.443732 140240877414400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:12:12.443839 140240877414400 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:12:12.443908 140240877414400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:12:12.443968 140240877414400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:12:12.444022 140240877414400 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:12:12.444090 140240877414400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:12:12.444147 140240877414400 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:12:12.444219 140240877414400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:12:12.444284 140240877414400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:12:12.463997 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:12:12.478312 140240877414400 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:12:12.478443 140240877414400 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 246.23
I0901 13:12:16.539796 140240877414400 replay_runner.py:36] Average training steps per second: 246.23
I0901 13:12:17.350379 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.41
Steps executed: 258 Episode length: 102 Return: -19.99126314322922
INFO:tensorflow:Starting iteration 1

Steps executed: 309 Episode length: 143 Return: -370.2357850477223
INFO:tensorflow:Average training steps per second: 334.21
I0901 13:12:23.505456 140240877414400 replay_runner.py:36] Average training steps per second: 334.21
I0901 13:12:23.669882 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -323.35
INFO:tensorflow:Starting iteration 2

Steps executed: 352 Episode length: 197 Return: 11.6573018492812114
INFO:tensorflow:Average training steps per second: 329.81
I0901 13:12:30.075642 140240877414400 replay_runner.py:36] Average training steps per second: 329.81
I0901 13:12:30.236954 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.10
INFO:tensorflow:Starting iteration 3

Steps executed: 240 Episode length: 160 Return: -54.934682602743824
INFO:tensorflow:Average training steps per second: 330.03
I0901 13:12:36.517082 140240877414400 replay_runner.py:36] Average training steps per second: 330.03
I0901 13:12:36.624206 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.80
INFO:tensorflow:Starting iteration 4

Steps executed: 278 Episode length: 278 Return: -51.838857031835364
INFO:tensorflow:Average training steps per second: 316.55
I0901 13:12:43.026900 140240877414400 replay_runner.py:36] Average training steps per second: 316.55
I0901 13:12:43.202508 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -51.84
INFO:tensorflow:Starting iteration 5

Steps executed: 283 Episode length: 182 Return: -233.02463112141424
INFO:tensorflow:Average training steps per second: 320.28
I0901 13:12:49.599049 140240877414400 replay_runner.py:36] Average training steps per second: 320.28
I0901 13:12:49.764862 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.70
INFO:tensorflow:Starting iteration 6

Steps executed: 202 Episode length: 58 Return: -132.150526308478965
INFO:tensorflow:Average training steps per second: 322.59
I0901 13:12:56.151112 140240877414400 replay_runner.py:36] Average training steps per second: 322.59
I0901 13:12:56.266055 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -219.51
INFO:tensorflow:Starting iteration 7

Steps executed: 222 Episode length: 90 Return: -300.867798529502865
INFO:tensorflow:Average training steps per second: 322.67
I0901 13:13:02.699634 140240877414400 replay_runner.py:36] Average training steps per second: 322.67
I0901 13:13:02.816996 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -264.92
INFO:tensorflow:Starting iteration 8

Steps executed: 307 Episode length: 143 Return: -176.59885298247588
INFO:tensorflow:Average training steps per second: 317.76
I0901 13:13:09.282804 140240877414400 replay_runner.py:36] Average training steps per second: 317.76
I0901 13:13:09.448312 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.24
INFO:tensorflow:Starting iteration 9
I0901 13:13:12.801485 140240877414400 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 306.66

Steps executed: 260 Episode length: 107 Return: -139.38294893356672
I0901 13:13:16.206905 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.90
INFO:tensorflow:Starting iteration 10

Steps executed: 225 Episode length: 127 Return: -182.43153934960862
INFO:tensorflow:Average training steps per second: 319.82
I0901 13:13:22.705371 140240877414400 replay_runner.py:36] Average training steps per second: 319.82
I0901 13:13:22.842707 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.92
INFO:tensorflow:Starting iteration 11

Steps executed: 206 Episode length: 73 Return: -545.193917270621762
INFO:tensorflow:Average training steps per second: 325.37
I0901 13:13:29.288876 140240877414400 replay_runner.py:36] Average training steps per second: 325.37
I0901 13:13:29.398422 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -488.84
INFO:tensorflow:Starting iteration 12

Steps executed: 221 Episode length: 67 Return: -285.141217255556462
INFO:tensorflow:Average training steps per second: 321.06
I0901 13:13:35.815524 140240877414400 replay_runner.py:36] Average training steps per second: 321.06
I0901 13:13:35.941519 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.56
INFO:tensorflow:Starting iteration 13

Steps executed: 246 Episode length: 93 Return: -80.5230463067941762
INFO:tensorflow:Average training steps per second: 314.59
I0901 13:13:42.424004 140240877414400 replay_runner.py:36] Average training steps per second: 314.59
I0901 13:13:42.564408 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.37
INFO:tensorflow:Starting iteration 14

Steps executed: 272 Episode length: 80 Return: -743.323589407055572
INFO:tensorflow:Average training steps per second: 315.40
I0901 13:13:49.025214 140240877414400 replay_runner.py:36] Average training steps per second: 315.40
I0901 13:13:49.175464 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.49
INFO:tensorflow:Starting iteration 15

Steps executed: 262 Episode length: 73 Return: -185.341861114094772
INFO:tensorflow:Average training steps per second: 316.93
I0901 13:13:55.604363 140240877414400 replay_runner.py:36] Average training steps per second: 316.93
I0901 13:13:55.758967 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.09
INFO:tensorflow:Starting iteration 16

Steps executed: 204 Episode length: 59 Return: -457.742740115723852
INFO:tensorflow:Average training steps per second: 325.51
I0901 13:14:02.136265 140240877414400 replay_runner.py:36] Average training steps per second: 325.51
I0901 13:14:02.254702 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -570.10
INFO:tensorflow:Starting iteration 17

Steps executed: 222 Episode length: 64 Return: -447.414900933618852
INFO:tensorflow:Average training steps per second: 319.43
I0901 13:14:08.795722 140240877414400 replay_runner.py:36] Average training steps per second: 319.43
I0901 13:14:08.926249 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -435.57
INFO:tensorflow:Starting iteration 18

Steps executed: 96 Episode length: 96 Return: -68.85623856735731852
INFO:tensorflow:Average training steps per second: 323.87

Steps executed: 1096 Episode length: 1000 Return: -60.84826755008207
I0901 13:14:17.904039 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -64.85
INFO:tensorflow:Starting iteration 19
I0901 13:14:21.366831 140240877414400 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 319.13

Steps executed: 214 Episode length: 77 Return: -547.9239730999739807
I0901 13:14:24.655505 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -448.89
INFO:tensorflow:Starting iteration 20

Steps executed: 257 Episode length: 75 Return: -470.1101528355037507
INFO:tensorflow:Average training steps per second: 328.13
I0901 13:14:31.127398 140240877414400 replay_runner.py:36] Average training steps per second: 328.13
I0901 13:14:31.280088 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -456.09
INFO:tensorflow:Starting iteration 21

Steps executed: 223 Episode length: 64 Return: -432.4034157083496607
INFO:tensorflow:Average training steps per second: 326.90
I0901 13:14:37.793072 140240877414400 replay_runner.py:36] Average training steps per second: 326.90
I0901 13:14:37.914943 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -557.02
INFO:tensorflow:Starting iteration 22
I0901 13:14:41.356822 140240877414400 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 331.93
I0901 13:14:44.369798 140240877414400 replay_runner.py:36] Average training steps per second: 331.93

Steps executed: 279 Episode length: 108 Return: -278.824403116714057
INFO:tensorflow:Starting iteration 23

Steps executed: 220 Episode length: 107 Return: -629.222850548093857
INFO:tensorflow:Average training steps per second: 334.20
I0901 13:14:50.988427 140240877414400 replay_runner.py:36] Average training steps per second: 334.20
I0901 13:14:51.116172 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -477.74
INFO:tensorflow:Starting iteration 24

Steps executed: 262 Episode length: 85 Return: -747.1716230812664857
INFO:tensorflow:Average training steps per second: 336.63
I0901 13:14:57.548550 140240877414400 replay_runner.py:36] Average training steps per second: 336.63
I0901 13:14:57.720261 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -409.33
INFO:tensorflow:Starting iteration 25

Steps executed: 244 Episode length: 90 Return: -453.3884307551892857
INFO:tensorflow:Average training steps per second: 349.24
I0901 13:15:03.982179 140240877414400 replay_runner.py:36] Average training steps per second: 349.24
I0901 13:15:04.115756 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -391.17
INFO:tensorflow:Starting iteration 26

Steps executed: 246 Episode length: 86 Return: -559.3221335228329047
INFO:tensorflow:Average training steps per second: 344.53
I0901 13:15:10.506133 140240877414400 replay_runner.py:36] Average training steps per second: 344.53
I0901 13:15:10.671980 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -420.56
INFO:tensorflow:Starting iteration 27

Steps executed: 227 Episode length: 227 Return: -540.351328916985647
INFO:tensorflow:Average training steps per second: 344.19
I0901 13:15:17.023559 140240877414400 replay_runner.py:36] Average training steps per second: 344.19
I0901 13:15:17.192715 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -540.35
INFO:tensorflow:Starting iteration 28

Steps executed: 203 Episode length: 151 Return: -369.864812289298847
INFO:tensorflow:Average training steps per second: 342.14
I0901 13:15:23.489000 140240877414400 replay_runner.py:36] Average training steps per second: 342.14
I0901 13:15:23.604752 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.58
INFO:tensorflow:Starting iteration 29

Steps executed: 253 Episode length: 61 Return: -94.08960635330523747
INFO:tensorflow:Average training steps per second: 332.15
I0901 13:15:30.039716 140240877414400 replay_runner.py:36] Average training steps per second: 332.15

Done fixed training!Episode length: 61 Return: -94.08960635330523747