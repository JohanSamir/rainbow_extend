Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0905 18:56:59.195837 139852794812416 run_experiment.py:549] Creating TrainRunner ...
I0905 18:56:59.212836 139852794812416 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 18:56:59.213166 139852794812416 dqn_agent.py:272] 	 gamma: 0.990000
I0905 18:56:59.213341 139852794812416 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 18:56:59.213482 139852794812416 dqn_agent.py:274] 	 min_replay_history: 500
I0905 18:56:59.213887 139852794812416 dqn_agent.py:275] 	 update_period: 4
I0905 18:56:59.214056 139852794812416 dqn_agent.py:276] 	 target_update_period: 300
I0905 18:56:59.214452 139852794812416 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 18:56:59.214615 139852794812416 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 18:56:59.214723 139852794812416 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 18:56:59.214965 139852794812416 dqn_agent.py:280] 	 optimizer: adam
I0905 18:56:59.215157 139852794812416 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 18:56:59.215298 139852794812416 dqn_agent.py:283] 	 seed: 1630868219212754
I0905 18:56:59.219879 139852794812416 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 18:56:59.220261 139852794812416 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 18:56:59.220478 139852794812416 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 18:56:59.220634 139852794812416 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 18:56:59.220770 139852794812416 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 18:56:59.220887 139852794812416 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 18:56:59.220996 139852794812416 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 18:56:59.221134 139852794812416 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 18:56:59.221257 139852794812416 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 18:56:59.282808 139852794812416 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:56:59.888782 139852794812416 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:56:59.909801 139852794812416 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 18:56:59.921553 139852794812416 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 18:56:59.921883 139852794812416 dqn_agent.py:272] 	 gamma: 0.990000
I0905 18:56:59.922126 139852794812416 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 18:56:59.922401 139852794812416 dqn_agent.py:274] 	 min_replay_history: 500
I0905 18:56:59.922547 139852794812416 dqn_agent.py:275] 	 update_period: 4
I0905 18:56:59.922656 139852794812416 dqn_agent.py:276] 	 target_update_period: 300
I0905 18:56:59.922755 139852794812416 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 18:56:59.922981 139852794812416 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 18:56:59.923207 139852794812416 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 18:56:59.923392 139852794812416 dqn_agent.py:280] 	 optimizer: adam
I0905 18:56:59.923547 139852794812416 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 18:56:59.923697 139852794812416 dqn_agent.py:283] 	 seed: 1630868219921493
I0905 18:56:59.926900 139852794812416 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 18:56:59.927128 139852794812416 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 18:56:59.930429 139852794812416 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 18:56:59.930963 139852794812416 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 18:56:59.931134 139852794812416 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 18:56:59.931499 139852794812416 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 18:56:59.931712 139852794812416 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 18:56:59.932003 139852794812416 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 18:56:59.932169 139852794812416 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 18:56:59.993079 139852794812416 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:57:00.021707 139852794812416 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 18:57:00.021991 139852794812416 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 122.49
I0905 18:57:08.186500 139852794812416 replay_runner.py:36] Average training steps per second: 122.49
Steps executed: 299 Episode length: 104 Return: -287.19346757757815
I0905 18:57:09.857552 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.01
INFO:tensorflow:Starting iteration 1

Steps executed: 244 Episode length: 111 Return: -286.41013762875275
INFO:tensorflow:Average training steps per second: 174.24
I0905 18:57:19.945980 139852794812416 replay_runner.py:36] Average training steps per second: 174.24
I0905 18:57:20.285394 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -251.29
INFO:tensorflow:Starting iteration 2
I0905 18:57:25.095014 139852794812416 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 177.56

Steps executed: 270 Episode length: 145 Return: -717.69593789346545
I0905 18:57:31.158182 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -738.90
INFO:tensorflow:Starting iteration 3
I0905 18:57:35.135324 139852794812416 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 181.29

Steps executed: 1000 Episode length: 1000 Return: -167.47583184958734
I0905 18:57:46.188265 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.48
INFO:tensorflow:Starting iteration 4
I0905 18:57:51.097048 139852794812416 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 174.77

Steps executed: 1000 Episode length: 1000 Return: -66.828482505149514
I0905 18:58:00.161008 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -66.83
INFO:tensorflow:Starting iteration 5
I0905 18:58:04.588182 139852794812416 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 180.74

Steps executed: 1000 Episode length: 1000 Return: -176.59500342175594
I0905 18:58:14.794591 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.60
INFO:tensorflow:Starting iteration 6
I0905 18:58:19.444480 139852794812416 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 177.11

Steps executed: 439 Episode length: 439 Return: -397.3094158962112594
I0905 18:58:26.122237 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -397.31
INFO:tensorflow:Starting iteration 7
I0905 18:58:30.341219 139852794812416 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 179.91

Steps executed: 864 Episode length: 864 Return: -382.9516445067643594
I0905 18:58:39.314634 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -382.95
INFO:tensorflow:Starting iteration 8

Steps executed: 464 Episode length: 464 Return: -434.2095956073237694
INFO:tensorflow:Average training steps per second: 176.80
I0905 18:58:49.789108 139852794812416 replay_runner.py:36] Average training steps per second: 176.80
I0905 18:58:50.978888 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -434.21
INFO:tensorflow:Starting iteration 9
I0905 18:58:55.861207 139852794812416 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 176.69

Steps executed: 1000 Episode length: 1000 Return: -133.86583640243333
I0905 18:59:06.215880 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.87
INFO:tensorflow:Starting iteration 10
I0905 18:59:11.007689 139852794812416 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 183.45

Steps executed: 1000 Episode length: 1000 Return: -147.02413708632633
I0905 18:59:20.573246 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.02
INFO:tensorflow:Starting iteration 11

Steps executed: 478 Episode length: 388 Return: -9.816709053240544633
INFO:tensorflow:Average training steps per second: 210.76
I0905 18:59:29.757913 139852794812416 replay_runner.py:36] Average training steps per second: 210.76
I0905 18:59:30.520118 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -39.94
INFO:tensorflow:Starting iteration 12
I0905 18:59:35.078318 139852794812416 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 217.54

Steps executed: 1000 Episode length: 1000 Return: -93.405353919787943
I0905 18:59:42.849376 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.41
INFO:tensorflow:Starting iteration 13
I0905 18:59:47.153352 139852794812416 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 275.85

Steps executed: 558 Episode length: 558 Return: -720.4993625003389943
I0905 18:59:51.668928 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -720.50
INFO:tensorflow:Starting iteration 14

Steps executed: 372 Episode length: 184 Return: -90.20781598024717943
INFO:tensorflow:Average training steps per second: 290.15
I0905 18:59:58.821154 139852794812416 replay_runner.py:36] Average training steps per second: 290.15
I0905 18:59:59.058848 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.55
INFO:tensorflow:Starting iteration 15

Steps executed: 305 Episode length: 305 Return: 232.88648088093174943
INFO:tensorflow:Average training steps per second: 282.56
I0905 19:00:06.148861 139852794812416 replay_runner.py:36] Average training steps per second: 282.56
I0905 19:00:06.436872 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: 232.89
INFO:tensorflow:Starting iteration 16
I0905 19:00:09.990857 139852794812416 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 271.36

Steps executed: 1000 Episode length: 1000 Return: 73.7738254840503943
I0905 19:00:16.040392 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: 73.77
INFO:tensorflow:Starting iteration 17
I0905 19:00:19.629950 139852794812416 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 293.82

Steps executed: 1000 Episode length: 1000 Return: -91.490125502174593
I0905 19:00:25.648799 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.49
INFO:tensorflow:Starting iteration 18

Steps executed: 318 Episode length: 177 Return: -248.9298544446760493
INFO:tensorflow:Average training steps per second: 271.37
I0905 19:00:32.760670 139852794812416 replay_runner.py:36] Average training steps per second: 271.37
I0905 19:00:33.046611 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.25
INFO:tensorflow:Starting iteration 19

Steps executed: 377 Episode length: 228 Return: -223.4673577112552693
INFO:tensorflow:Average training steps per second: 280.49
I0905 19:00:40.188509 139852794812416 replay_runner.py:36] Average training steps per second: 280.49
I0905 19:00:40.532854 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.24
INFO:tensorflow:Starting iteration 20
I0905 19:00:44.149918 139852794812416 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 296.80

Steps executed: 1000 Episode length: 1000 Return: -38.476999858452293
I0905 19:00:50.160653 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -38.48
INFO:tensorflow:Starting iteration 21
I0905 19:00:53.854080 139852794812416 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 283.91

Steps executed: 371 Episode length: 371 Return: 244.79782934750423293
I0905 19:00:57.806414 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: 244.80
INFO:tensorflow:Starting iteration 22
I0905 19:01:01.386706 139852794812416 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 280.77

Steps executed: 1000 Episode length: 1000 Return: -40.538628251761544
I0905 19:01:08.368669 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -40.54
INFO:tensorflow:Starting iteration 23
I0905 19:01:12.175337 139852794812416 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 333.67

Steps executed: 1000 Episode length: 1000 Return: -57.515477322299375
I0905 19:01:17.831150 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.52
INFO:tensorflow:Starting iteration 24
I0905 19:01:21.458548 139852794812416 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 335.52

Steps executed: 1000 Episode length: 1000 Return: 89.5943352311694375
I0905 19:01:28.278203 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: 89.59
INFO:tensorflow:Starting iteration 25
I0905 19:01:31.623732 139852794812416 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 272.84

Steps executed: 494 Episode length: 494 Return: 233.55085399594475375
I0905 19:01:36.044223 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: 233.55
INFO:tensorflow:Starting iteration 26
I0905 19:01:39.519406 139852794812416 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 269.79

Steps executed: 1000 Episode length: 1000 Return: 155.006779704736275
I0905 19:01:44.590202 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: 155.01
INFO:tensorflow:Starting iteration 27
I0905 19:01:48.195567 139852794812416 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 290.54

Steps executed: 285 Episode length: 285 Return: -666.6968381662723275
I0905 19:01:51.893342 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -666.70
INFO:tensorflow:Starting iteration 28

Steps executed: 355 Episode length: 355 Return: -4.713203817054136275
INFO:tensorflow:Average training steps per second: 283.46
I0905 19:01:58.823999 139852794812416 replay_runner.py:36] Average training steps per second: 283.46
I0905 19:01:59.217278 139852794812416 run_experiment.py:428] Average undiscounted return per evaluation episode: -4.71
INFO:tensorflow:Starting iteration 29
I0905 19:02:02.788334 139852794812416 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 277.80

Steps executed: 1000 Episode length: 1000 Return: -62.178077806001755

Done fixed training! Episode length: 1000 Return: -62.178077806001755