I0902 00:30:57.070051 139965167532032 run_experiment.py:549] Creating TrainRunner ...
I0902 00:30:57.079060 139965167532032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:30:57.079211 139965167532032 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:30:57.079297 139965167532032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:30:57.079390 139965167532032 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:30:57.079502 139965167532032 dqn_agent.py:275] 	 update_period: 4
I0902 00:30:57.079711 139965167532032 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:30:57.079877 139965167532032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:30:57.079967 139965167532032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:30:57.080040 139965167532032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:30:57.080119 139965167532032 dqn_agent.py:280] 	 optimizer: adam
I0902 00:30:57.080237 139965167532032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:30:57.080310 139965167532032 dqn_agent.py:283] 	 seed: 1630542657079018
I0902 00:30:57.082020 139965167532032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:30:57.082160 139965167532032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:30:57.082247 139965167532032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:30:57.082311 139965167532032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:30:57.082369 139965167532032 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:30:57.082440 139965167532032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:30:57.082532 139965167532032 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:30:57.082598 139965167532032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:30:57.082683 139965167532032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:30:57.109937 139965167532032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:30:57.380679 139965167532032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:30:57.390910 139965167532032 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:30:57.398091 139965167532032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:30:57.398248 139965167532032 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:30:57.398324 139965167532032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:30:57.398387 139965167532032 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:30:57.398444 139965167532032 dqn_agent.py:275] 	 update_period: 4
I0902 00:30:57.398499 139965167532032 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:30:57.398555 139965167532032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:30:57.398627 139965167532032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:30:57.398710 139965167532032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:30:57.398790 139965167532032 dqn_agent.py:280] 	 optimizer: adam
I0902 00:30:57.398845 139965167532032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:30:57.398914 139965167532032 dqn_agent.py:283] 	 seed: 1630542657398059
I0902 00:30:57.400399 139965167532032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:30:57.400508 139965167532032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:30:57.400578 139965167532032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:30:57.400639 139965167532032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:30:57.400694 139965167532032 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:30:57.400760 139965167532032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:30:57.400831 139965167532032 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:30:57.400907 139965167532032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:30:57.400973 139965167532032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:30:57.422800 139965167532032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:30:57.437907 139965167532032 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:30:57.438080 139965167532032 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
Steps executed: 291 Episode length: 165 Return: -291.58913211786006
INFO:tensorflow:Average training steps per second: 250.87
I0902 00:31:01.424453 139965167532032 replay_runner.py:36] Average training steps per second: 250.87
I0902 00:31:02.210041 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -335.20
INFO:tensorflow:Starting iteration 1

Steps executed: 266 Episode length: 79 Return: -715.033835232436752
INFO:tensorflow:Average training steps per second: 346.69
I0902 00:31:08.428977 139965167532032 replay_runner.py:36] Average training steps per second: 346.69
I0902 00:31:08.555680 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -420.58
INFO:tensorflow:Starting iteration 2
I0902 00:31:11.884547 139965167532032 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 355.44

Steps executed: 220 Episode length: 220 Return: -425.27813151575424
I0902 00:31:14.842693 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -425.28
INFO:tensorflow:Starting iteration 3

Steps executed: 536 Episode length: 536 Return: -366.84058106606014
INFO:tensorflow:Average training steps per second: 343.36
I0902 00:31:21.180751 139965167532032 replay_runner.py:36] Average training steps per second: 343.36
I0902 00:31:21.864363 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -366.84
INFO:tensorflow:Starting iteration 4

Steps executed: 204 Episode length: 107 Return: -510.14695790479774
INFO:tensorflow:Average training steps per second: 348.51
I0902 00:31:28.122678 139965167532032 replay_runner.py:36] Average training steps per second: 348.51
I0902 00:31:28.237091 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -461.68
INFO:tensorflow:Starting iteration 5
I0902 00:31:31.635941 139965167532032 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 338.79

Steps executed: 619 Episode length: 619 Return: -844.28621959230084
I0902 00:31:35.600297 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -844.29
INFO:tensorflow:Starting iteration 6
I0902 00:31:39.006416 139965167532032 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 333.89

Steps executed: 1000 Episode length: 1000 Return: -162.67631150510124
I0902 00:31:44.863415 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.68
INFO:tensorflow:Starting iteration 7
I0902 00:31:48.285717 139965167532032 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 336.89

Steps executed: 1000 Episode length: 1000 Return: -182.77907439664745
I0902 00:31:53.110073 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.78
INFO:tensorflow:Starting iteration 8

Steps executed: 693 Episode length: 637 Return: -881.9627074841944745
INFO:tensorflow:Average training steps per second: 329.57
I0902 00:31:59.509055 139965167532032 replay_runner.py:36] Average training steps per second: 329.57
I0902 00:32:00.560265 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -707.57
INFO:tensorflow:Starting iteration 9
I0902 00:32:03.782644 139965167532032 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 315.41

Steps executed: 781 Episode length: 781 Return: -316.1034441369529345
I0902 00:32:08.309233 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -316.10
INFO:tensorflow:Starting iteration 10
I0902 00:32:11.567257 139965167532032 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 323.84

Steps executed: 1000 Episode length: 1000 Return: -26.448956792567177
I0902 00:32:16.389537 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -26.45
INFO:tensorflow:Starting iteration 11

Steps executed: 268 Episode length: 268 Return: -56.06977481329756177
INFO:tensorflow:Average training steps per second: 328.47
I0902 00:32:22.743088 139965167532032 replay_runner.py:36] Average training steps per second: 328.47
I0902 00:32:22.956244 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -56.07
INFO:tensorflow:Starting iteration 12
I0902 00:32:26.195349 139965167532032 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 333.81

Steps executed: 242 Episode length: 242 Return: -160.1419178959328677
I0902 00:32:29.403527 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.14
INFO:tensorflow:Starting iteration 13

Steps executed: 472 Episode length: 472 Return: -279.4881695459348577
INFO:tensorflow:Average training steps per second: 344.11
I0902 00:32:35.661471 139965167532032 replay_runner.py:36] Average training steps per second: 344.11
I0902 00:32:36.320848 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.49
INFO:tensorflow:Starting iteration 14

Steps executed: 353 Episode length: 353 Return: -615.3186305993706577
INFO:tensorflow:Average training steps per second: 345.94
I0902 00:32:42.645414 139965167532032 replay_runner.py:36] Average training steps per second: 345.94
I0902 00:32:43.012182 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -615.32
INFO:tensorflow:Starting iteration 15

Steps executed: 84 Episode length: 84 Return: -136.772182063236106577
INFO:tensorflow:Average training steps per second: 351.62

Steps executed: 281 Episode length: 112 Return: -152.9261924324735677
I0902 00:32:49.431502 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.39
INFO:tensorflow:Starting iteration 16

Steps executed: 433 Episode length: 274 Return: -82.05897901973599777
INFO:tensorflow:Average training steps per second: 341.34
I0902 00:32:55.830013 139965167532032 replay_runner.py:36] Average training steps per second: 341.34
I0902 00:32:56.130077 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.03
INFO:tensorflow:Starting iteration 17

Steps executed: 243 Episode length: 93 Return: -702.79503234083461777
INFO:tensorflow:Average training steps per second: 327.28
I0902 00:33:02.585971 139965167532032 replay_runner.py:36] Average training steps per second: 327.28
I0902 00:33:02.745760 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -529.15
INFO:tensorflow:Starting iteration 18
I0902 00:33:06.120252 139965167532032 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 331.48
I0902 00:33:09.137305 139965167532032 replay_runner.py:36] Average training steps per second: 331.48

Steps executed: 248 Episode length: 140 Return: -480.4782932322230577
INFO:tensorflow:Starting iteration 19

Steps executed: 243 Episode length: 71 Return: -466.68650344479898577
INFO:tensorflow:Average training steps per second: 328.98
I0902 00:33:15.661417 139965167532032 replay_runner.py:36] Average training steps per second: 328.98
I0902 00:33:15.811804 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.04
INFO:tensorflow:Starting iteration 20

Steps executed: 202 Episode length: 70 Return: 11.4258256381263982877
INFO:tensorflow:Average training steps per second: 335.13
I0902 00:33:22.146352 139965167532032 replay_runner.py:36] Average training steps per second: 335.13
I0902 00:33:22.292338 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.22
INFO:tensorflow:Starting iteration 21

Steps executed: 215 Episode length: 55 Return: -165.83425039322694877
INFO:tensorflow:Average training steps per second: 341.22
I0902 00:33:28.628213 139965167532032 replay_runner.py:36] Average training steps per second: 341.22
I0902 00:33:28.774677 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.08
INFO:tensorflow:Starting iteration 22
I0902 00:33:32.207407 139965167532032 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 347.16

Steps executed: 257 Episode length: 71 Return: -165.95847005543777877
I0902 00:33:35.217654 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.31
INFO:tensorflow:Starting iteration 23

Steps executed: 325 Episode length: 169 Return: -146.2868374887414777
INFO:tensorflow:Average training steps per second: 342.20
I0902 00:33:41.698532 139965167532032 replay_runner.py:36] Average training steps per second: 342.20
I0902 00:33:41.912778 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.76
INFO:tensorflow:Starting iteration 24

Steps executed: 352 Episode length: 184 Return: -272.1363969376345777
INFO:tensorflow:Average training steps per second: 342.89
I0902 00:33:48.297578 139965167532032 replay_runner.py:36] Average training steps per second: 342.89
I0902 00:33:48.536713 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.69
INFO:tensorflow:Starting iteration 25

Steps executed: 286 Episode length: 140 Return: -154.5592809752378677
INFO:tensorflow:Average training steps per second: 342.70
I0902 00:33:54.912734 139965167532032 replay_runner.py:36] Average training steps per second: 342.70
I0902 00:33:55.100107 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.09
INFO:tensorflow:Starting iteration 26

Steps executed: 240 Episode length: 54 Return: -95.483680008145048677
INFO:tensorflow:Average training steps per second: 338.66
I0902 00:34:01.478350 139965167532032 replay_runner.py:36] Average training steps per second: 338.66
I0902 00:34:01.588744 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.67
INFO:tensorflow:Starting iteration 27

Steps executed: 215 Episode length: 59 Return: -116.17362766779902677
INFO:tensorflow:Average training steps per second: 341.70
I0902 00:34:07.874282 139965167532032 replay_runner.py:36] Average training steps per second: 341.70
I0902 00:34:08.010664 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -292.31
INFO:tensorflow:Starting iteration 28

Steps executed: 415 Episode length: 254 Return: -233.4019066659403777
INFO:tensorflow:Average training steps per second: 342.66
I0902 00:34:14.205315 139965167532032 replay_runner.py:36] Average training steps per second: 342.66
I0902 00:34:14.500492 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.33
INFO:tensorflow:Starting iteration 29

Steps executed: 265 Episode length: 68 Return: -574.37208994764763777
INFO:tensorflow:Average training steps per second: 360.34
I0902 00:34:20.673339 139965167532032 replay_runner.py:36] Average training steps per second: 360.34

Done fixed training!Episode length: 68 Return: -574.37208994764763777