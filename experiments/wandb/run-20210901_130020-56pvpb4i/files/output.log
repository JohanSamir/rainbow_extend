Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0901 13:00:26.643815 140536266098688 run_experiment.py:549] Creating TrainRunner ...
I0901 13:00:26.656724 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:00:26.657045 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:00:26.657358 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:00:26.657477 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:00:26.657610 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 13:00:26.657740 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:00:26.657901 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:00:26.658180 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:00:26.658378 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:00:26.658699 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 13:00:26.658878 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:00:26.659093 140536266098688 dqn_agent.py:283] 	 seed: 1630501226656647
I0901 13:00:26.663177 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:00:26.663398 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:00:26.663531 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:00:26.663646 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:00:26.663780 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:00:26.663891 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:00:26.664162 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:00:26.664360 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:00:26.664561 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:00:26.709427 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:00:27.187523 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:00:27.204402 140536266098688 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:00:27.214175 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:00:27.214664 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:00:27.214952 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:00:27.215121 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:00:27.215297 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 13:00:27.215494 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:00:27.215676 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:00:27.215792 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:00:27.215906 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:00:27.216048 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 13:00:27.216218 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:00:27.216357 140536266098688 dqn_agent.py:283] 	 seed: 1630501227214093
I0901 13:00:27.219404 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:00:27.219619 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:00:27.219748 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:00:27.219863 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:00:27.219950 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:00:27.220047 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:00:27.220218 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:00:27.220343 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:00:27.220456 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:00:27.256330 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:00:27.281334 140536266098688 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:00:27.281608 140536266098688 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 156.71
I0901 13:00:33.663119 140536266098688 replay_runner.py:36] Average training steps per second: 156.71
Steps executed: 207 Episode length: 128 Return: -193.35112279671236
I0901 13:00:34.889311 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.78
INFO:tensorflow:Starting iteration 1

Steps executed: 236 Episode length: 126 Return: -359.34142633982635
INFO:tensorflow:Average training steps per second: 219.20
I0901 13:00:44.031634 140536266098688 replay_runner.py:36] Average training steps per second: 219.20
I0901 13:00:44.252639 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.26
INFO:tensorflow:Starting iteration 2

Steps executed: 313 Episode length: 115 Return: -152.35359616522175
INFO:tensorflow:Average training steps per second: 214.29
I0901 13:00:52.857896 140536266098688 replay_runner.py:36] Average training steps per second: 214.29
I0901 13:00:53.165242 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.53
INFO:tensorflow:Starting iteration 3
I0901 13:00:57.697030 140536266098688 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 214.54

Steps executed: 220 Episode length: 220 Return: -173.24835952085772
I0901 13:01:02.611873 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.25
INFO:tensorflow:Starting iteration 4

Steps executed: 264 Episode length: 65 Return: -382.332694421834332
INFO:tensorflow:Average training steps per second: 213.53
I0901 13:01:11.625129 140536266098688 replay_runner.py:36] Average training steps per second: 213.53
I0901 13:01:11.865885 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -315.88
INFO:tensorflow:Starting iteration 5

Steps executed: 246 Episode length: 132 Return: -116.08452959512496
INFO:tensorflow:Average training steps per second: 213.01
I0901 13:01:21.076890 140536266098688 replay_runner.py:36] Average training steps per second: 213.01
I0901 13:01:21.305287 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.69
INFO:tensorflow:Starting iteration 6

Steps executed: 204 Episode length: 81 Return: -314.541714697917946
INFO:tensorflow:Average training steps per second: 218.13
I0901 13:01:29.905385 140536266098688 replay_runner.py:36] Average training steps per second: 218.13
I0901 13:01:30.081415 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.00
INFO:tensorflow:Starting iteration 7

Steps executed: 330 Episode length: 136 Return: -338.95288575280386
INFO:tensorflow:Average training steps per second: 223.84
I0901 13:01:38.618216 140536266098688 replay_runner.py:36] Average training steps per second: 223.84
I0901 13:01:38.892673 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.96
INFO:tensorflow:Starting iteration 8

Steps executed: 327 Episode length: 133 Return: -320.60526967163497
INFO:tensorflow:Average training steps per second: 224.09
I0901 13:01:47.658415 140536266098688 replay_runner.py:36] Average training steps per second: 224.09
I0901 13:01:47.942086 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.37
INFO:tensorflow:Starting iteration 9

Steps executed: 280 Episode length: 84 Return: -352.218734494501427
INFO:tensorflow:Average training steps per second: 230.17
I0901 13:01:56.723320 140536266098688 replay_runner.py:36] Average training steps per second: 230.17
I0901 13:01:56.931336 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.86
INFO:tensorflow:Starting iteration 10

Steps executed: 266 Episode length: 80 Return: -413.178740562583927
INFO:tensorflow:Average training steps per second: 222.96
I0901 13:02:05.688288 140536266098688 replay_runner.py:36] Average training steps per second: 222.96
I0901 13:02:05.933984 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -464.47
INFO:tensorflow:Starting iteration 11
I0901 13:02:10.265537 140536266098688 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 224.80

Steps executed: 239 Episode length: 116 Return: -273.48039593258824
I0901 13:02:14.926994 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -340.37
INFO:tensorflow:Starting iteration 12

Steps executed: 216 Episode length: 129 Return: -570.57229663794544
INFO:tensorflow:Average training steps per second: 224.94
I0901 13:02:23.690395 140536266098688 replay_runner.py:36] Average training steps per second: 224.94
I0901 13:02:23.873566 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -459.49
INFO:tensorflow:Starting iteration 13

Steps executed: 255 Episode length: 85 Return: -264.889032323336444
INFO:tensorflow:Average training steps per second: 224.65
I0901 13:02:32.423709 140536266098688 replay_runner.py:36] Average training steps per second: 224.65
I0901 13:02:32.613567 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -278.86
INFO:tensorflow:Starting iteration 14

Steps executed: 292 Episode length: 117 Return: -531.31323992648284
INFO:tensorflow:Average training steps per second: 219.89
I0901 13:02:41.489343 140536266098688 replay_runner.py:36] Average training steps per second: 219.89
I0901 13:02:41.735337 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -335.84
INFO:tensorflow:Starting iteration 15
I0901 13:02:46.012382 140536266098688 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 216.16

Steps executed: 1000 Episode length: 1000 Return: -29.83088433037802
I0901 13:02:53.728394 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -29.83
INFO:tensorflow:Starting iteration 16

Steps executed: 259 Episode length: 74 Return: -117.1952524103250842
INFO:tensorflow:Average training steps per second: 233.97
I0901 13:03:02.299016 140536266098688 replay_runner.py:36] Average training steps per second: 233.97
I0901 13:03:02.525646 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.62
INFO:tensorflow:Starting iteration 17

Steps executed: 319 Episode length: 204 Return: -75.4682283936515142
INFO:tensorflow:Average training steps per second: 247.46
I0901 13:03:10.820269 140536266098688 replay_runner.py:36] Average training steps per second: 247.46
I0901 13:03:11.114268 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -305.77
INFO:tensorflow:Starting iteration 18

Steps executed: 234 Episode length: 73 Return: -518.5564882038889542
INFO:tensorflow:Average training steps per second: 245.60
I0901 13:03:19.395735 140536266098688 replay_runner.py:36] Average training steps per second: 245.60
I0901 13:03:19.572833 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -360.40
INFO:tensorflow:Starting iteration 19

Steps executed: 222 Episode length: 67 Return: -569.2543553029825342
INFO:tensorflow:Average training steps per second: 248.27
I0901 13:03:27.822458 140536266098688 replay_runner.py:36] Average training steps per second: 248.27
I0901 13:03:27.987248 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -419.61
INFO:tensorflow:Starting iteration 20

Steps executed: 258 Episode length: 81 Return: -531.9446176078505342
INFO:tensorflow:Average training steps per second: 241.62
I0901 13:03:36.210457 140536266098688 replay_runner.py:36] Average training steps per second: 241.62
I0901 13:03:36.401345 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -428.67
INFO:tensorflow:Starting iteration 21

Steps executed: 205 Episode length: 66 Return: -283.3765439999242542
INFO:tensorflow:Average training steps per second: 249.54
I0901 13:03:44.509709 140536266098688 replay_runner.py:36] Average training steps per second: 249.54
I0901 13:03:44.653815 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -454.05
INFO:tensorflow:Starting iteration 22
I0901 13:03:48.721613 140536266098688 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 237.46

Steps executed: 241 Episode length: 65 Return: -394.6926904240386342
I0901 13:03:53.103195 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.41
INFO:tensorflow:Starting iteration 23

Steps executed: 262 Episode length: 76 Return: -132.5874033355093842
INFO:tensorflow:Average training steps per second: 247.70
I0901 13:04:01.207034 140536266098688 replay_runner.py:36] Average training steps per second: 247.70
I0901 13:04:01.364952 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.41
INFO:tensorflow:Starting iteration 24

Steps executed: 220 Episode length: 81 Return: -695.8331719678589342
INFO:tensorflow:Average training steps per second: 245.05
I0901 13:04:09.553440 140536266098688 replay_runner.py:36] Average training steps per second: 245.05
I0901 13:04:09.734030 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -640.86
INFO:tensorflow:Starting iteration 25

Steps executed: 265 Episode length: 71 Return: -613.7231680606227642
INFO:tensorflow:Average training steps per second: 238.58
I0901 13:04:18.027184 140536266098688 replay_runner.py:36] Average training steps per second: 238.58
I0901 13:04:18.222434 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -549.63
INFO:tensorflow:Starting iteration 26

Steps executed: 242 Episode length: 56 Return: -503.7541526441549272
INFO:tensorflow:Average training steps per second: 263.71
I0901 13:04:26.088376 140536266098688 replay_runner.py:36] Average training steps per second: 263.71
I0901 13:04:26.264806 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -438.42
INFO:tensorflow:Starting iteration 27

Steps executed: 252 Episode length: 70 Return: -554.7330479656403472
INFO:tensorflow:Average training steps per second: 266.09
I0901 13:04:34.096142 140536266098688 replay_runner.py:36] Average training steps per second: 266.09
I0901 13:04:34.280235 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -463.39
INFO:tensorflow:Starting iteration 28

Steps executed: 257 Episode length: 68 Return: -567.4420893597619572
INFO:tensorflow:Average training steps per second: 276.14
I0901 13:04:41.893601 140536266098688 replay_runner.py:36] Average training steps per second: 276.14
I0901 13:04:42.063826 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -493.38
INFO:tensorflow:Starting iteration 29

Steps executed: 262 Episode length: 77 Return: -790.7259143929524472
INFO:tensorflow:Average training steps per second: 273.53
I0901 13:04:49.586556 140536266098688 replay_runner.py:36] Average training steps per second: 273.53

Done fixed training!Episode length: 77 Return: -790.7259143929524472