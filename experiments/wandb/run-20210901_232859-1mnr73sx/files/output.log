I0901 23:29:06.527218 139929824643072 run_experiment.py:549] Creating TrainRunner ...
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0901 23:29:06.527776 139929824643072 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0901 23:29:06.618560 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:29:06.619750 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:29:06.619833 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:29:06.619897 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:29:06.620005 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0901 23:29:06.620062 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:29:06.620115 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:29:06.620257 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:29:06.620331 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:29:06.620385 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0901 23:29:06.620489 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:29:06.620582 139929824643072 dqn_agent.py:283] 	 seed: 1630538946618502
I0901 23:29:06.622379 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:29:06.622524 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:29:06.622597 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:29:06.622659 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:29:06.622715 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:29:06.622788 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:29:06.622872 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:29:06.622952 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:29:06.623029 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:29:14.514184 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0901 23:29:16.113660 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:29:16.134682 139929824643072 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:29:16.156467 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:29:16.156803 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:29:16.157186 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:29:16.157465 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:29:16.157738 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0901 23:29:16.157997 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:29:16.158237 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:29:16.158464 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:29:16.158678 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:29:16.158925 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0901 23:29:16.159136 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:29:16.159371 139929824643072 dqn_agent.py:283] 	 seed: 1630538956156413
I0901 23:29:16.162308 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:29:16.162590 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:29:16.162914 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:29:16.163138 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:29:16.163351 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:29:16.163567 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:29:16.163808 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:29:16.164067 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:29:16.164304 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:29:16.895395 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:29:16.942572 139929824643072 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:29:16.943098 139929824643072 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 157.77
I0901 23:29:23.281818 139929824643072 replay_runner.py:36] Average training steps per second: 157.77
Steps executed: 313 Episode length: 146 Return: -433.10791883307314
I0901 23:29:24.298693 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -452.33
INFO:tensorflow:Starting iteration 1

Steps executed: 284 Episode length: 105 Return: -378.05405920174627
INFO:tensorflow:Average training steps per second: 203.74
I0901 23:29:33.559152 139929824643072 replay_runner.py:36] Average training steps per second: 203.74
I0901 23:29:33.831171 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.03
INFO:tensorflow:Starting iteration 2

Steps executed: 307 Episode length: 122 Return: -294.31384992746916
INFO:tensorflow:Average training steps per second: 203.88
I0901 23:29:43.078759 139929824643072 replay_runner.py:36] Average training steps per second: 203.88
I0901 23:29:43.376861 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.86
INFO:tensorflow:Starting iteration 3
I0901 23:29:47.511734 139929824643072 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 207.29

Steps executed: 836 Episode length: 836 Return: -266.96069476386197
I0901 23:29:54.644042 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.96
INFO:tensorflow:Starting iteration 4
I0901 23:29:58.914714 139929824643072 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 212.82

Steps executed: 1000 Episode length: 1000 Return: -94.08425326830343
I0901 23:30:05.779445 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.08
INFO:tensorflow:Starting iteration 5
I0901 23:30:09.944624 139929824643072 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 213.00

Steps executed: 1000 Episode length: 1000 Return: -154.55733854877315
I0901 23:30:17.771073 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.56
INFO:tensorflow:Starting iteration 6

Steps executed: 137 Episode length: 137 Return: -142.7086282080274315
INFO:tensorflow:Average training steps per second: 211.46

Steps executed: 838 Episode length: 701 Return: -183.6021075508315615
I0901 23:30:28.623956 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.16
INFO:tensorflow:Starting iteration 7
I0901 23:30:32.852889 139929824643072 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 214.52

Steps executed: 1000 Episode length: 1000 Return: -312.30006975218465
I0901 23:30:40.715513 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -312.30
INFO:tensorflow:Starting iteration 8
I0901 23:30:44.807282 139929824643072 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 214.44

Steps executed: 1000 Episode length: 1000 Return: -314.72436621047265
I0901 23:30:52.077378 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.72
INFO:tensorflow:Starting iteration 9

Steps executed: 324 Episode length: 324 Return: -178.9004091249646265
INFO:tensorflow:Average training steps per second: 217.63
I0901 23:31:00.869483 139929824643072 replay_runner.py:36] Average training steps per second: 217.63
I0901 23:31:01.302648 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.90
INFO:tensorflow:Starting iteration 10

Steps executed: 297 Episode length: 297 Return: -1279.200321257682465
INFO:tensorflow:Average training steps per second: 219.98
I0901 23:31:10.175235 139929824643072 replay_runner.py:36] Average training steps per second: 219.98
I0901 23:31:10.598015 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -1279.20
INFO:tensorflow:Starting iteration 11

Steps executed: 529 Episode length: 529 Return: -1461.588773438768665
INFO:tensorflow:Average training steps per second: 228.31
I0901 23:31:19.320114 139929824643072 replay_runner.py:36] Average training steps per second: 228.31
I0901 23:31:20.353441 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -1461.59
INFO:tensorflow:Starting iteration 12
I0901 23:31:24.670827 139929824643072 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 226.16

Steps executed: 1000 Episode length: 1000 Return: -98.534569909022615
I0901 23:31:32.013633 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.53
INFO:tensorflow:Starting iteration 13
I0901 23:31:36.187367 139929824643072 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 215.46

Steps executed: 1000 Episode length: 1000 Return: -226.41530166904116
I0901 23:31:43.889386 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.42
INFO:tensorflow:Starting iteration 14
I0901 23:31:48.228018 139929824643072 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 228.99

Steps executed: 1000 Episode length: 1000 Return: -100.40386456677504
I0901 23:31:55.309184 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.40
INFO:tensorflow:Starting iteration 15
I0901 23:31:59.617907 139929824643072 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 226.13

Steps executed: 1000 Episode length: 1000 Return: -31.756984999591875
I0901 23:32:07.350386 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -31.76
INFO:tensorflow:Starting iteration 16
I0901 23:32:11.227191 139929824643072 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 242.62

Steps executed: 1000 Episode length: 1000 Return: -53.100188757480495
I0901 23:32:19.184179 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -53.10
INFO:tensorflow:Starting iteration 17

Steps executed: 58 Episode length: 58 Return: -112.361782119166920495
INFO:tensorflow:Average training steps per second: 223.74

Steps executed: 956 Episode length: 898 Return: -266.9970083719558795
I0901 23:32:30.216048 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.68
INFO:tensorflow:Starting iteration 18
I0901 23:32:35.135197 139929824643072 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 215.59
I0901 23:32:39.774236 139929824643072 replay_runner.py:36] Average training steps per second: 215.59

Steps executed: 579 Episode length: 579 Return: -159.0512247497924295
INFO:tensorflow:Starting iteration 19
I0901 23:32:45.179036 139929824643072 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 223.93

Steps executed: 1000 Episode length: 1000 Return: -65.648286426436995
I0901 23:32:54.160341 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.65
INFO:tensorflow:Starting iteration 20
I0901 23:32:58.195521 139929824643072 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 226.83

Steps executed: 319 Episode length: 156 Return: -101.7091441175393895
I0901 23:33:02.923988 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.95
INFO:tensorflow:Starting iteration 21

Steps executed: 274 Episode length: 155 Return: -195.6786789455114895
INFO:tensorflow:Average training steps per second: 221.77
I0901 23:33:11.841777 139929824643072 replay_runner.py:36] Average training steps per second: 221.77
I0901 23:33:12.073093 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.81
INFO:tensorflow:Starting iteration 22
I0901 23:33:16.349466 139929824643072 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 223.85

Steps executed: 218 Episode length: 76 Return: 37.6513928128125644895
I0901 23:33:20.999073 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -19.30
INFO:tensorflow:Starting iteration 23

Steps executed: 353 Episode length: 164 Return: -274.1773682840928495
INFO:tensorflow:Average training steps per second: 225.10
I0901 23:33:29.648272 139929824643072 replay_runner.py:36] Average training steps per second: 225.10
I0901 23:33:30.017229 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -433.61
INFO:tensorflow:Starting iteration 24
I0901 23:33:34.365864 139929824643072 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 221.88

Steps executed: 1000 Episode length: 1000 Return: -18.697746654618955
I0901 23:33:41.870701 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -18.70
INFO:tensorflow:Starting iteration 25
I0901 23:33:46.234253 139929824643072 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 218.27
I0901 23:33:50.816626 139929824643072 replay_runner.py:36] Average training steps per second: 218.27

Steps executed: 244 Episode length: 52 Return: -109.76461053526452955
INFO:tensorflow:Starting iteration 26

Steps executed: 231 Episode length: 231 Return: -412.2514345657135755
INFO:tensorflow:Average training steps per second: 223.04
I0901 23:33:59.720902 139929824643072 replay_runner.py:36] Average training steps per second: 223.04
I0901 23:33:59.982328 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -412.25
INFO:tensorflow:Starting iteration 27

Steps executed: 225 Episode length: 225 Return: -222.5752297912407655
INFO:tensorflow:Average training steps per second: 225.53
I0901 23:34:08.682091 139929824643072 replay_runner.py:36] Average training steps per second: 225.53
I0901 23:34:08.932253 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -222.58
INFO:tensorflow:Starting iteration 28
I0901 23:34:13.192161 139929824643072 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 228.16

Steps executed: 1000 Episode length: 1000 Return: -439.77381886960545
I0901 23:34:20.681882 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -439.77
INFO:tensorflow:Starting iteration 29
I0901 23:34:24.927898 139929824643072 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 226.22
I0901 23:34:29.348920 139929824643072 replay_runner.py:36] Average training steps per second: 226.22


Done fixed training! Episode length: 1000 Return: -23.898866880359446