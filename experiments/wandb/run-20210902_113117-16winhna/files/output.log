Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0902 11:31:23.141911 139646469900288 run_experiment.py:549] Creating TrainRunner ...
I0902 11:31:23.148680 139646469900288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 11:31:23.148792 139646469900288 dqn_agent.py:272] 	 gamma: 0.990000
I0902 11:31:23.148885 139646469900288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 11:31:23.148940 139646469900288 dqn_agent.py:274] 	 min_replay_history: 500
I0902 11:31:23.148990 139646469900288 dqn_agent.py:275] 	 update_period: 4
I0902 11:31:23.149063 139646469900288 dqn_agent.py:276] 	 target_update_period: 300
I0902 11:31:23.149145 139646469900288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 11:31:23.149209 139646469900288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 11:31:23.149286 139646469900288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 11:31:23.149348 139646469900288 dqn_agent.py:280] 	 optimizer: adam
I0902 11:31:23.149417 139646469900288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 11:31:23.149480 139646469900288 dqn_agent.py:283] 	 seed: 1630582283148651
I0902 11:31:23.151130 139646469900288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 11:31:23.151239 139646469900288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 11:31:23.151312 139646469900288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 11:31:23.151373 139646469900288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 11:31:23.151429 139646469900288 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 11:31:23.151501 139646469900288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 11:31:23.151567 139646469900288 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 11:31:23.151647 139646469900288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 11:31:23.151714 139646469900288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 11:31:23.279546 139646469900288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:23.477391 139646469900288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:23.484742 139646469900288 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 11:31:23.489719 139646469900288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 11:31:23.489887 139646469900288 dqn_agent.py:272] 	 gamma: 0.990000
I0902 11:31:23.489966 139646469900288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 11:31:23.490028 139646469900288 dqn_agent.py:274] 	 min_replay_history: 500
I0902 11:31:23.490083 139646469900288 dqn_agent.py:275] 	 update_period: 4
I0902 11:31:23.490158 139646469900288 dqn_agent.py:276] 	 target_update_period: 300
I0902 11:31:23.490253 139646469900288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 11:31:23.490338 139646469900288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 11:31:23.490412 139646469900288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 11:31:23.490491 139646469900288 dqn_agent.py:280] 	 optimizer: adam
I0902 11:31:23.490571 139646469900288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 11:31:23.490651 139646469900288 dqn_agent.py:283] 	 seed: 1630582283489693
I0902 11:31:23.492055 139646469900288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 11:31:23.492166 139646469900288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 11:31:23.492217 139646469900288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 11:31:23.492261 139646469900288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 11:31:23.492311 139646469900288 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 11:31:23.492357 139646469900288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 11:31:23.492401 139646469900288 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 11:31:23.492460 139646469900288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 11:31:23.492531 139646469900288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 11:31:23.521156 139646469900288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:23.538480 139646469900288 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 11:31:23.538593 139646469900288 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 198.20
I0902 11:31:28.584178 139646469900288 replay_runner.py:36] Average training steps per second: 198.20
Steps executed: 245 Episode length: 138 Return: -190.32405447406347
I0902 11:31:29.548494 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.38
INFO:tensorflow:Starting iteration 1

Steps executed: 260 Episode length: 260 Return: -293.18619468651317
INFO:tensorflow:Average training steps per second: 328.98
I0902 11:31:35.855992 139646469900288 replay_runner.py:36] Average training steps per second: 328.98
I0902 11:31:36.084760 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.19
INFO:tensorflow:Starting iteration 2
I0902 11:31:39.498719 139646469900288 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 323.49

Steps executed: 292 Episode length: 292 Return: -258.83613310955317
I0902 11:31:42.870343 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.84
INFO:tensorflow:Starting iteration 3
I0902 11:31:46.254182 139646469900288 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 324.63

Steps executed: 1000 Episode length: 1000 Return: -194.25823476920885
I0902 11:31:51.601511 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -194.26
INFO:tensorflow:Starting iteration 4
I0902 11:31:54.907113 139646469900288 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 327.88

Steps executed: 1000 Episode length: 1000 Return: -136.46837099295848
I0902 11:31:59.415820 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.47
INFO:tensorflow:Starting iteration 5

Steps executed: 490 Episode length: 490 Return: -79.62525672314871848
INFO:tensorflow:Average training steps per second: 332.47
I0902 11:32:05.636094 139646469900288 replay_runner.py:36] Average training steps per second: 332.47
I0902 11:32:06.292378 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.63
INFO:tensorflow:Starting iteration 6
I0902 11:32:09.648374 139646469900288 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 332.93

Steps executed: 648 Episode length: 648 Return: -146.3237991962076848
I0902 11:32:13.546884 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.32
INFO:tensorflow:Starting iteration 7

Steps executed: 309 Episode length: 309 Return: -177.8644663905061548
INFO:tensorflow:Average training steps per second: 325.94
I0902 11:32:20.015552 139646469900288 replay_runner.py:36] Average training steps per second: 325.94
I0902 11:32:20.288658 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.86
INFO:tensorflow:Starting iteration 8

Steps executed: 326 Episode length: 326 Return: -361.9595222562508648
INFO:tensorflow:Average training steps per second: 328.51
I0902 11:32:26.717952 139646469900288 replay_runner.py:36] Average training steps per second: 328.51
I0902 11:32:26.983944 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.96
INFO:tensorflow:Starting iteration 9

Steps executed: 217 Episode length: 217 Return: -38.62978123561336548
INFO:tensorflow:Average training steps per second: 332.61
I0902 11:32:33.424206 139646469900288 replay_runner.py:36] Average training steps per second: 332.61
I0902 11:32:33.581460 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -38.63
INFO:tensorflow:Starting iteration 10

Steps executed: 344 Episode length: 225 Return: -76.32050804097517548
INFO:tensorflow:Average training steps per second: 314.87
I0902 11:32:40.046100 139646469900288 replay_runner.py:36] Average training steps per second: 314.87
I0902 11:32:40.284803 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.97
INFO:tensorflow:Starting iteration 11

Steps executed: 350 Episode length: 205 Return: -189.6672227344224748
INFO:tensorflow:Average training steps per second: 335.40
I0902 11:32:46.572342 139646469900288 replay_runner.py:36] Average training steps per second: 335.40
I0902 11:32:46.777610 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.50
INFO:tensorflow:Starting iteration 12
I0902 11:32:50.277271 139646469900288 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 345.73

Steps executed: 1000 Episode length: 1000 Return: -92.184916841849518
I0902 11:32:55.974336 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.18
INFO:tensorflow:Starting iteration 13
I0902 11:32:59.345602 139646469900288 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 319.66

Steps executed: 1000 Episode length: 1000 Return: 90.0075853468661818
I0902 11:33:05.105581 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: 90.01
INFO:tensorflow:Starting iteration 14
I0902 11:33:08.458142 139646469900288 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 308.93

Steps executed: 1000 Episode length: 1000 Return: -45.594885907820318
I0902 11:33:14.315586 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -45.59
INFO:tensorflow:Starting iteration 15
I0902 11:33:17.836263 139646469900288 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 338.01

Steps executed: 1000 Episode length: 1000 Return: 127.884674447355968
I0902 11:33:22.459191 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: 127.88
INFO:tensorflow:Starting iteration 16

Steps executed: 131 Episode length: 131 Return: -256.0137888399143568
INFO:tensorflow:Average training steps per second: 352.55

Steps executed: 642 Episode length: 511 Return: 204.30875549404763568
I0902 11:33:29.605934 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -25.85
INFO:tensorflow:Starting iteration 17

Steps executed: 770 Episode length: 770 Return: -198.4674304843785368
INFO:tensorflow:Average training steps per second: 351.65
I0902 11:33:36.012020 139646469900288 replay_runner.py:36] Average training steps per second: 351.65
I0902 11:33:36.869425 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.47
INFO:tensorflow:Starting iteration 18
I0902 11:33:40.459845 139646469900288 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 350.69

Steps executed: 265 Episode length: 265 Return: 274.09449734547245368
I0902 11:33:43.492138 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: 274.09
INFO:tensorflow:Starting iteration 19
I0902 11:33:47.061454 139646469900288 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 354.24

Steps executed: 1000 Episode length: 1000 Return: -7.4428631319114238
I0902 11:33:52.014550 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -7.44
INFO:tensorflow:Starting iteration 20

Steps executed: 247 Episode length: 247 Return: -25.96395102682166238
INFO:tensorflow:Average training steps per second: 351.21
I0902 11:33:58.386154 139646469900288 replay_runner.py:36] Average training steps per second: 351.21
I0902 11:33:58.599299 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -25.96
INFO:tensorflow:Starting iteration 21
I0902 11:34:02.086894 139646469900288 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 325.10

Steps executed: 715 Episode length: 715 Return: -641.5299868219104238
I0902 11:34:06.408960 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -641.53
INFO:tensorflow:Starting iteration 22
I0902 11:34:09.840346 139646469900288 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 317.50

Steps executed: 779 Episode length: 589 Return: -486.2348897733517238
I0902 11:34:13.903494 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -272.89
INFO:tensorflow:Starting iteration 23

Steps executed: 155 Episode length: 155 Return: -24.40578900477835638
INFO:tensorflow:Average training steps per second: 312.88
I0902 11:34:20.440480 139646469900288 replay_runner.py:36] Average training steps per second: 312.88

Steps executed: 667 Episode length: 512 Return: 234.29773082654611638
INFO:tensorflow:Starting iteration 24
I0902 11:34:24.633822 139646469900288 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 312.52

Steps executed: 1000 Episode length: 1000 Return: -110.56469374728682
I0902 11:34:30.638721 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.56
INFO:tensorflow:Starting iteration 25
I0902 11:34:34.140908 139646469900288 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 342.97

Steps executed: 889 Episode length: 889 Return: 162.84025898343018682
I0902 11:34:38.470195 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: 162.84
INFO:tensorflow:Starting iteration 26
I0902 11:34:42.055480 139646469900288 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 372.92

Steps executed: 1000 Episode length: 1000 Return: 133.948610868476522
I0902 11:34:46.059846 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: 133.95
INFO:tensorflow:Starting iteration 27

Steps executed: 221 Episode length: 221 Return: -105.1772508274041722
INFO:tensorflow:Average training steps per second: 374.69
I0902 11:34:52.288172 139646469900288 replay_runner.py:36] Average training steps per second: 374.69
I0902 11:34:52.445092 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.18
INFO:tensorflow:Starting iteration 28

Steps executed: 189 Episode length: 189 Return: -41.73922613274003722
INFO:tensorflow:Average training steps per second: 367.20

Steps executed: 1189 Episode length: 1000 Return: -38.893206960218822
I0902 11:35:01.017947 139646469900288 run_experiment.py:428] Average undiscounted return per evaluation episode: -40.32
INFO:tensorflow:Starting iteration 29

Steps executed: 250 Episode length: 250 Return: -188.7028120666487322
INFO:tensorflow:Average training steps per second: 353.14
I0902 11:35:07.127695 139646469900288 replay_runner.py:36] Average training steps per second: 353.14

Done fixed training!Episode length: 250 Return: -188.7028120666487322