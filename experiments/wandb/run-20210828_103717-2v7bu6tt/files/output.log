Loaded trained dqn in acrobot
Training fixed agent 5, please be patient, may be a while...
I0828 10:37:23.816564 140326915356672 run_experiment.py:549] Creating TrainRunner ...
I0828 10:37:23.825873 140326915356672 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:23.826205 140326915356672 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:23.826461 140326915356672 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:23.826575 140326915356672 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:23.826696 140326915356672 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:23.826793 140326915356672 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:37:23.826888 140326915356672 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:23.826966 140326915356672 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:23.827053 140326915356672 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:23.827131 140326915356672 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:23.827228 140326915356672 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:23.827319 140326915356672 dqn_agent.py:283] 	 seed: 1630147043825814
I0828 10:37:23.830451 140326915356672 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:23.830710 140326915356672 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:37:23.830847 140326915356672 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:23.830994 140326915356672 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:23.831088 140326915356672 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:23.831186 140326915356672 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:23.831290 140326915356672 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:23.831378 140326915356672 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:23.831462 140326915356672 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:23.871041 140326915356672 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:24.342585 140326915356672 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:24.356433 140326915356672 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:37:24.364168 140326915356672 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:24.364412 140326915356672 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:24.364561 140326915356672 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:24.364748 140326915356672 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:24.364886 140326915356672 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:24.365061 140326915356672 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:37:24.365160 140326915356672 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:24.365299 140326915356672 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:24.365421 140326915356672 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:24.365519 140326915356672 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:24.365592 140326915356672 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:24.365679 140326915356672 dqn_agent.py:283] 	 seed: 1630147044364102
I0828 10:37:24.367580 140326915356672 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:24.367707 140326915356672 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:37:24.367780 140326915356672 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:24.367873 140326915356672 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:24.367982 140326915356672 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:24.368042 140326915356672 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:24.368097 140326915356672 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:24.368149 140326915356672 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:24.368257 140326915356672 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:24.401954 140326915356672 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:24.424537 140326915356672 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:37:24.424816 140326915356672 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 146.00
I0828 10:37:31.274376 140326915356672 replay_runner.py:36] Average training steps per second: 146.00
Steps executed: 500 Episode length: 500 Return: -500.0
I0828 10:37:32.726307 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1
I0828 10:37:32.959582 140326915356672 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 200.27
I0828 10:37:37.953321 140326915356672 replay_runner.py:36] Average training steps per second: 200.27
I0828 10:37:38.399418 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 2

Steps executed: 287 Episode length: 168 Return: -167.0
INFO:tensorflow:Average training steps per second: 196.96
I0828 10:37:43.709506 140326915356672 replay_runner.py:36] Average training steps per second: 196.96
I0828 10:37:43.938717 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.50
INFO:tensorflow:Starting iteration 3

Steps executed: 144 Episode length: 73 Return: -72.0.0
INFO:tensorflow:Average training steps per second: 192.71
I0828 10:37:49.364507 140326915356672 replay_runner.py:36] Average training steps per second: 192.71

Steps executed: 236 Episode length: 92 Return: -91.0.0
INFO:tensorflow:Starting iteration 4

Steps executed: 262 Episode length: 98 Return: -97.0.0
INFO:tensorflow:Average training steps per second: 197.13
I0828 10:37:54.878181 140326915356672 replay_runner.py:36] Average training steps per second: 197.13
I0828 10:37:55.092342 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.33
INFO:tensorflow:Starting iteration 5

Steps executed: 201 Episode length: 109 Return: -108.0
INFO:tensorflow:Average training steps per second: 193.84
I0828 10:38:00.500087 140326915356672 replay_runner.py:36] Average training steps per second: 193.84
I0828 10:38:00.668453 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.50
INFO:tensorflow:Starting iteration 6

Steps executed: 336 Episode length: 154 Return: -153.0
INFO:tensorflow:Average training steps per second: 194.52
I0828 10:38:06.058865 140326915356672 replay_runner.py:36] Average training steps per second: 194.52
I0828 10:38:06.356634 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.00
INFO:tensorflow:Starting iteration 7
I0828 10:38:06.603628 140326915356672 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 194.94

Steps executed: 500 Episode length: 500 Return: -500.0
I0828 10:38:12.145404 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 8

Steps executed: 80 Episode length: 80 Return: -79.00.0
INFO:tensorflow:Average training steps per second: 191.17
I0828 10:38:17.622017 140326915356672 replay_runner.py:36] Average training steps per second: 191.17

Steps executed: 258 Episode length: 87 Return: -86.0.0
INFO:tensorflow:Starting iteration 9

Steps executed: 217 Episode length: 125 Return: -124.0
INFO:tensorflow:Average training steps per second: 196.09
I0828 10:38:23.185647 140326915356672 replay_runner.py:36] Average training steps per second: 196.09
I0828 10:38:23.368535 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.50
INFO:tensorflow:Starting iteration 10

Steps executed: 247 Episode length: 107 Return: -106.0
INFO:tensorflow:Average training steps per second: 193.70
I0828 10:38:28.776260 140326915356672 replay_runner.py:36] Average training steps per second: 193.70
I0828 10:38:28.981158 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.50
INFO:tensorflow:Starting iteration 11

Steps executed: 285 Episode length: 186 Return: -185.0
INFO:tensorflow:Average training steps per second: 192.51
I0828 10:38:34.418011 140326915356672 replay_runner.py:36] Average training steps per second: 192.51
I0828 10:38:34.660736 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.50
INFO:tensorflow:Starting iteration 12
I0828 10:38:34.894718 140326915356672 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 196.07

Steps executed: 212 Episode length: 79 Return: -78.0.0
I0828 10:38:40.178964 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.00
INFO:tensorflow:Starting iteration 13

Steps executed: 246 Episode length: 77 Return: -76.0.0
INFO:tensorflow:Average training steps per second: 191.66
I0828 10:38:45.640202 140326915356672 replay_runner.py:36] Average training steps per second: 191.66
I0828 10:38:45.852059 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.00
INFO:tensorflow:Starting iteration 14

Steps executed: 255 Episode length: 90 Return: -89.0.0
INFO:tensorflow:Average training steps per second: 190.48
I0828 10:38:51.348428 140326915356672 replay_runner.py:36] Average training steps per second: 190.48
I0828 10:38:51.560356 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.00
INFO:tensorflow:Starting iteration 15

Steps executed: 219 Episode length: 62 Return: -61.0.0
INFO:tensorflow:Average training steps per second: 193.92
I0828 10:38:56.963981 140326915356672 replay_runner.py:36] Average training steps per second: 193.92
I0828 10:38:57.162561 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.00
INFO:tensorflow:Starting iteration 16

Steps executed: 255 Episode length: 87 Return: -86.0.0
INFO:tensorflow:Average training steps per second: 191.71
I0828 10:39:02.618354 140326915356672 replay_runner.py:36] Average training steps per second: 191.71
I0828 10:39:02.820897 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.00
INFO:tensorflow:Starting iteration 17

Steps executed: 258 Episode length: 90 Return: -89.0.0
INFO:tensorflow:Average training steps per second: 194.80
I0828 10:39:08.193371 140326915356672 replay_runner.py:36] Average training steps per second: 194.80
I0828 10:39:08.415659 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.00
INFO:tensorflow:Starting iteration 18
I0828 10:39:08.633186 140326915356672 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 197.01
I0828 10:39:13.709413 140326915356672 replay_runner.py:36] Average training steps per second: 197.01

Steps executed: 207 Episode length: 115 Return: -114.0
INFO:tensorflow:Starting iteration 19

Steps executed: 252 Episode length: 64 Return: -63.0.0
INFO:tensorflow:Average training steps per second: 193.95
I0828 10:39:19.259493 140326915356672 replay_runner.py:36] Average training steps per second: 193.95
I0828 10:39:19.480286 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.00
INFO:tensorflow:Starting iteration 20

Steps executed: 215 Episode length: 111 Return: -110.0
INFO:tensorflow:Average training steps per second: 195.60
I0828 10:39:24.835950 140326915356672 replay_runner.py:36] Average training steps per second: 195.60
I0828 10:39:25.012143 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.50
INFO:tensorflow:Starting iteration 21

Steps executed: 250 Episode length: 94 Return: -93.0.0
INFO:tensorflow:Average training steps per second: 197.99
I0828 10:39:30.306351 140326915356672 replay_runner.py:36] Average training steps per second: 197.99
I0828 10:39:30.507141 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.33
INFO:tensorflow:Starting iteration 22

Steps executed: 144 Episode length: 73 Return: -72.0.0
INFO:tensorflow:Average training steps per second: 198.94
I0828 10:39:35.768427 140326915356672 replay_runner.py:36] Average training steps per second: 198.94
I0828 10:39:35.951298 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.00
INFO:tensorflow:Starting iteration 23


Steps executed: 295 Episode length: 97 Return: -96.0.0
INFO:tensorflow:Average training steps per second: 196.41
I0828 10:39:41.275930 140326915356672 replay_runner.py:36] Average training steps per second: 196.41
I0828 10:39:41.508071 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.33
INFO:tensorflow:Starting iteration 24

Steps executed: 215 Episode length: 117 Return: -116.0
INFO:tensorflow:Average training steps per second: 194.36
I0828 10:39:46.891195 140326915356672 replay_runner.py:36] Average training steps per second: 194.36
I0828 10:39:47.068027 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.50
INFO:tensorflow:Starting iteration 25

Steps executed: 242 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Average training steps per second: 194.51
I0828 10:39:52.452518 140326915356672 replay_runner.py:36] Average training steps per second: 194.51
I0828 10:39:52.654791 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.67
INFO:tensorflow:Starting iteration 26

Steps executed: 80 Episode length: 80 Return: -79.00.0
INFO:tensorflow:Average training steps per second: 193.48
I0828 10:39:58.064237 140326915356672 replay_runner.py:36] Average training steps per second: 193.48

Steps executed: 232 Episode length: 79 Return: -78.0.0
INFO:tensorflow:Starting iteration 27

Steps executed: 203 Episode length: 116 Return: -115.0
INFO:tensorflow:Average training steps per second: 194.80
I0828 10:40:03.620052 140326915356672 replay_runner.py:36] Average training steps per second: 194.80
I0828 10:40:03.809227 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.50
INFO:tensorflow:Starting iteration 28

Steps executed: 210 Episode length: 119 Return: -118.0
INFO:tensorflow:Average training steps per second: 198.43
I0828 10:40:09.099711 140326915356672 replay_runner.py:36] Average training steps per second: 198.43
I0828 10:40:09.274663 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.00
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 94 Return: -93.0.0
INFO:tensorflow:Average training steps per second: 189.59
I0828 10:40:14.823936 140326915356672 replay_runner.py:36] Average training steps per second: 189.59
I0828 10:40:15.025840 140326915356672 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.00