I0902 18:21:45.090314 140216164177920 run_experiment.py:549] Creating TrainRunner ...
I0902 18:21:45.097540 140216164177920 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:21:45.097662 140216164177920 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:21:45.097737 140216164177920 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:21:45.097813 140216164177920 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:21:45.097863 140216164177920 dqn_agent.py:275] 	 update_period: 4
I0902 18:21:45.097932 140216164177920 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:21:45.098020 140216164177920 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:21:45.098102 140216164177920 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:21:45.098163 140216164177920 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:21:45.098225 140216164177920 dqn_agent.py:280] 	 optimizer: adam
I0902 18:21:45.098293 140216164177920 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:21:45.098364 140216164177920 dqn_agent.py:283] 	 seed: 1630606905097508
I0902 18:21:45.100064 140216164177920 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:21:45.100195 140216164177920 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:21:45.100274 140216164177920 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:21:45.100351 140216164177920 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:21:45.100426 140216164177920 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:21:45.100496 140216164177920 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:21:45.100551 140216164177920 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:21:45.100611 140216164177920 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:21:45.100662 140216164177920 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:21:45.124706 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:45.368667 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:45.377636 140216164177920 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:21:45.383977 140216164177920 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:21:45.384104 140216164177920 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:21:45.384180 140216164177920 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:21:45.384243 140216164177920 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:21:45.384327 140216164177920 dqn_agent.py:275] 	 update_period: 4
I0902 18:21:45.384394 140216164177920 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:21:45.384482 140216164177920 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:21:45.384604 140216164177920 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:21:45.384684 140216164177920 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:21:45.384770 140216164177920 dqn_agent.py:280] 	 optimizer: adam
I0902 18:21:45.384861 140216164177920 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:21:45.384936 140216164177920 dqn_agent.py:283] 	 seed: 1630606905383950
I0902 18:21:45.386794 140216164177920 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:21:45.386922 140216164177920 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:21:45.387112 140216164177920 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:21:45.387300 140216164177920 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:21:45.387396 140216164177920 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:21:45.387476 140216164177920 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:21:45.387588 140216164177920 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:21:45.387778 140216164177920 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:21:45.387883 140216164177920 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:21:45.407816 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:45.421690 140216164177920 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:21:45.421828 140216164177920 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 265.60
I0902 18:21:49.187020 140216164177920 replay_runner.py:36] Average training steps per second: 265.60
I0902 18:21:50.019326 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -320.27
Steps executed: 265 Episode length: 97 Return: -292.0801363130402
INFO:tensorflow:Starting iteration 1

Steps executed: 417 Episode length: 242 Return: -440.0686696151547
INFO:tensorflow:Average training steps per second: 356.72
I0902 18:21:56.217063 140216164177920 replay_runner.py:36] Average training steps per second: 356.72
I0902 18:21:56.509528 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -447.41
INFO:tensorflow:Starting iteration 2

Steps executed: 836 Episode length: 836 Return: -390.91465198892587
INFO:tensorflow:Average training steps per second: 350.43
I0902 18:22:02.840111 140216164177920 replay_runner.py:36] Average training steps per second: 350.43
I0902 18:22:04.588788 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -390.91
INFO:tensorflow:Starting iteration 3

Steps executed: 376 Episode length: 376 Return: -419.14020691263414
INFO:tensorflow:Average training steps per second: 351.62
I0902 18:22:10.894301 140216164177920 replay_runner.py:36] Average training steps per second: 351.62
I0902 18:22:11.216098 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -419.14
INFO:tensorflow:Starting iteration 4
I0902 18:22:14.639163 140216164177920 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 345.68

Steps executed: 1000 Episode length: 1000 Return: -119.33841145320544
I0902 18:22:19.375700 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.34
INFO:tensorflow:Starting iteration 5
I0902 18:22:22.755264 140216164177920 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 334.76

Steps executed: 1000 Episode length: 1000 Return: -88.090219420274324
I0902 18:22:28.619084 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.09
INFO:tensorflow:Starting iteration 6

Steps executed: 1000 Episode length: 1000 Return: -73.398427517416484
INFO:tensorflow:Average training steps per second: 319.37
I0902 18:22:35.110422 140216164177920 replay_runner.py:36] Average training steps per second: 319.37
I0902 18:22:36.742103 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.40
INFO:tensorflow:Starting iteration 7

Steps executed: 407 Episode length: 407 Return: -579.4546991478408484
INFO:tensorflow:Average training steps per second: 320.27
I0902 18:22:43.220669 140216164177920 replay_runner.py:36] Average training steps per second: 320.27
I0902 18:22:43.603008 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -579.45
INFO:tensorflow:Starting iteration 8
I0902 18:22:46.891751 140216164177920 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 334.99

Steps executed: 1000 Episode length: 1000 Return: -48.351242654653254
I0902 18:22:51.452658 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -48.35
INFO:tensorflow:Starting iteration 9

Steps executed: 678 Episode length: 678 Return: -338.4087429191320754
INFO:tensorflow:Average training steps per second: 340.09
I0902 18:22:57.720625 140216164177920 replay_runner.py:36] Average training steps per second: 340.09
I0902 18:22:58.756946 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.41
INFO:tensorflow:Starting iteration 10
I0902 18:23:02.134770 140216164177920 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 334.10

Steps executed: 386 Episode length: 386 Return: -232.0268835500331854
I0902 18:23:05.443749 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.03
INFO:tensorflow:Starting iteration 11

Steps executed: 675 Episode length: 675 Return: -265.7260530798861854
INFO:tensorflow:Average training steps per second: 328.45
I0902 18:23:11.840278 140216164177920 replay_runner.py:36] Average training steps per second: 328.45
I0902 18:23:12.835244 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.73
INFO:tensorflow:Starting iteration 12
I0902 18:23:16.256783 140216164177920 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 340.98

Steps executed: 399 Episode length: 399 Return: -127.9034521703579154
I0902 18:23:19.573539 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.90
INFO:tensorflow:Starting iteration 13
I0902 18:23:22.934099 140216164177920 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 329.07

Steps executed: 1000 Episode length: 1000 Return: -131.21244371574272
I0902 18:23:27.861481 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.21
INFO:tensorflow:Starting iteration 14

Steps executed: 564 Episode length: 564 Return: -226.8089710127856672
INFO:tensorflow:Average training steps per second: 328.28
I0902 18:23:34.221724 140216164177920 replay_runner.py:36] Average training steps per second: 328.28
I0902 18:23:34.917113 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.81
INFO:tensorflow:Starting iteration 15
I0902 18:23:38.237248 140216164177920 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 342.78

Steps executed: 444 Episode length: 444 Return: -217.3547494267211872
I0902 18:23:41.730731 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.35
INFO:tensorflow:Starting iteration 16

Steps executed: 201 Episode length: 99 Return: -99.356625751767271172
INFO:tensorflow:Average training steps per second: 344.49
I0902 18:23:47.999774 140216164177920 replay_runner.py:36] Average training steps per second: 344.49
I0902 18:23:48.154308 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.15
INFO:tensorflow:Starting iteration 17

Steps executed: 408 Episode length: 408 Return: -59.56975830249242472
INFO:tensorflow:Average training steps per second: 379.89
I0902 18:23:54.308818 140216164177920 replay_runner.py:36] Average training steps per second: 379.89
I0902 18:23:54.717121 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -59.57
INFO:tensorflow:Starting iteration 18

Steps executed: 372 Episode length: 372 Return: -223.2745061042877472
INFO:tensorflow:Average training steps per second: 372.21
I0902 18:24:00.934657 140216164177920 replay_runner.py:36] Average training steps per second: 372.21
I0902 18:24:01.286141 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.27
INFO:tensorflow:Starting iteration 19
I0902 18:24:04.830955 140216164177920 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 347.27
I0902 18:24:07.711037 140216164177920 replay_runner.py:36] Average training steps per second: 347.27

Steps executed: 768 Episode length: 768 Return: -151.0920001811073272
INFO:tensorflow:Starting iteration 20

Steps executed: 222 Episode length: 222 Return: -170.5304334992742472
INFO:tensorflow:Average training steps per second: 328.25
I0902 18:24:15.585271 140216164177920 replay_runner.py:36] Average training steps per second: 328.25
I0902 18:24:15.747803 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.53
INFO:tensorflow:Starting iteration 21

Steps executed: 518 Episode length: 518 Return: 226.35765015920512472
INFO:tensorflow:Average training steps per second: 331.88
I0902 18:24:22.058160 140216164177920 replay_runner.py:36] Average training steps per second: 331.88
I0902 18:24:22.778205 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: 226.36
INFO:tensorflow:Starting iteration 22
I0902 18:24:25.996036 140216164177920 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 333.41

Steps executed: 1000 Episode length: 1000 Return: 22.1811986432838072
I0902 18:24:31.163917 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: 22.18
INFO:tensorflow:Starting iteration 23
I0902 18:24:34.345703 140216164177920 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 329.77
I0902 18:24:37.378612 140216164177920 replay_runner.py:36] Average training steps per second: 329.77

Steps executed: 1000 Episode length: 1000 Return: -8.2334228310952982
INFO:tensorflow:Starting iteration 24

Steps executed: 475 Episode length: 475 Return: -299.8034942718041982
INFO:tensorflow:Average training steps per second: 313.97
I0902 18:24:45.553342 140216164177920 replay_runner.py:36] Average training steps per second: 313.97
I0902 18:24:46.359273 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -299.80
INFO:tensorflow:Starting iteration 25
I0902 18:24:49.471568 140216164177920 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 325.47

Steps executed: 742 Episode length: 742 Return: -31.37020603518621482
I0902 18:24:53.906291 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -31.37
INFO:tensorflow:Starting iteration 26

Steps executed: 296 Episode length: 102 Return: -133.2206594663378582
INFO:tensorflow:Average training steps per second: 341.70
I0902 18:24:59.952460 140216164177920 replay_runner.py:36] Average training steps per second: 341.70
I0902 18:25:00.136808 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.54
INFO:tensorflow:Starting iteration 27
I0902 18:25:03.431764 140216164177920 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 368.71

Steps executed: 1000 Episode length: 1000 Return: -110.61464342695682
I0902 18:25:08.014652 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.61
INFO:tensorflow:Starting iteration 28

Steps executed: 559 Episode length: 559 Return: -107.4970606059562882
INFO:tensorflow:Average training steps per second: 329.73
I0902 18:25:14.117451 140216164177920 replay_runner.py:36] Average training steps per second: 329.73
I0902 18:25:14.763961 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.50
INFO:tensorflow:Starting iteration 29

Steps executed: 269 Episode length: 269 Return: 255.35885859322882882
INFO:tensorflow:Average training steps per second: 383.23
I0902 18:25:20.397181 140216164177920 replay_runner.py:36] Average training steps per second: 383.23

Done fixed training!Episode length: 269 Return: 255.35885859322882882