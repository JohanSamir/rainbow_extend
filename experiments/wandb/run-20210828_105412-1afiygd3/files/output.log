Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0828 10:54:18.669786 140214119393280 run_experiment.py:549] Creating TrainRunner ...
I0828 10:54:18.677398 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:54:18.677508 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:54:18.677582 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:54:18.677678 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:54:18.677733 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:54:18.677796 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:54:18.677847 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:54:18.677948 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:54:18.678031 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:54:18.678097 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:54:18.678165 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:54:18.678238 140214119393280 dqn_agent.py:283] 	 seed: 1630148058677371
I0828 10:54:18.680712 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:54:18.680826 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:54:18.680905 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:54:18.681029 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:54:18.681168 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:54:18.681257 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:54:18.681331 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:54:18.681412 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:54:18.681481 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:54:18.707292 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:18.960162 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:18.969619 140214119393280 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:54:18.976819 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:54:18.976963 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:54:18.977049 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:54:18.977127 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:54:18.977190 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:54:18.977256 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:54:18.977346 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:54:18.977412 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:54:18.977507 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:54:18.977591 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:54:18.977728 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:54:18.977812 140214119393280 dqn_agent.py:283] 	 seed: 1630148058976790
I0828 10:54:18.979449 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:54:18.979556 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:54:18.979625 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:54:18.979686 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:54:18.979748 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:54:18.979819 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:54:18.979883 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:54:18.979957 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:54:18.980028 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:54:19.000180 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:19.015845 140214119393280 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:54:19.016011 140214119393280 replay_runner.py:41] Starting iteration 0
Steps executed: 336 Episode length: 182 Return: -569.03541395572965
INFO:tensorflow:Average training steps per second: 259.24
I0828 10:54:22.873523 140214119393280 replay_runner.py:36] Average training steps per second: 259.24
I0828 10:54:23.743117 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -388.39
INFO:tensorflow:Starting iteration 1
I0828 10:54:27.016960 140214119393280 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 315.02

Steps executed: 372 Episode length: 224 Return: -301.91892843590378
I0828 10:54:30.406497 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -278.86
INFO:tensorflow:Starting iteration 2

Steps executed: 407 Episode length: 210 Return: -163.66667403262238
INFO:tensorflow:Average training steps per second: 317.59
I0828 10:54:36.775919 140214119393280 replay_runner.py:36] Average training steps per second: 317.59
I0828 10:54:37.074658 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.33
INFO:tensorflow:Starting iteration 3

Steps executed: 290 Episode length: 97 Return: -677.344490796722272
INFO:tensorflow:Average training steps per second: 326.43
I0828 10:54:43.380662 140214119393280 replay_runner.py:36] Average training steps per second: 326.43
I0828 10:54:43.554011 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -466.39
INFO:tensorflow:Starting iteration 4

Steps executed: 355 Episode length: 201 Return: -510.98480688893912
INFO:tensorflow:Average training steps per second: 323.44
I0828 10:54:49.801003 140214119393280 replay_runner.py:36] Average training steps per second: 323.44
I0828 10:54:50.046175 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -523.74
INFO:tensorflow:Starting iteration 5

Steps executed: 142 Episode length: 142 Return: -642.67576099078372
INFO:tensorflow:Average training steps per second: 331.31
I0828 10:54:56.259438 140214119393280 replay_runner.py:36] Average training steps per second: 331.31

Steps executed: 291 Episode length: 149 Return: -362.83453269762882
INFO:tensorflow:Starting iteration 6

Steps executed: 339 Episode length: 179 Return: -320.91170311660204
INFO:tensorflow:Average training steps per second: 329.88
I0828 10:55:02.716058 140214119393280 replay_runner.py:36] Average training steps per second: 329.88
I0828 10:55:02.956377 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -382.45
INFO:tensorflow:Starting iteration 7

Steps executed: 429 Episode length: 260 Return: -286.40145302860117
INFO:tensorflow:Average training steps per second: 321.59
I0828 10:55:09.319631 140214119393280 replay_runner.py:36] Average training steps per second: 321.59
I0828 10:55:09.656008 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -317.83
INFO:tensorflow:Starting iteration 8

Steps executed: 331 Episode length: 139 Return: -297.22487567440817
INFO:tensorflow:Average training steps per second: 324.96
I0828 10:55:15.945229 140214119393280 replay_runner.py:36] Average training steps per second: 324.96
I0828 10:55:16.174137 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -363.32
INFO:tensorflow:Starting iteration 9
I0828 10:55:19.369178 140214119393280 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 328.67

Steps executed: 316 Episode length: 316 Return: -235.22331490148576
I0828 10:55:22.678743 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.22
INFO:tensorflow:Starting iteration 10

Steps executed: 256 Episode length: 256 Return: -131.96710697268685
INFO:tensorflow:Average training steps per second: 324.06
I0828 10:55:28.949746 140214119393280 replay_runner.py:36] Average training steps per second: 324.06
I0828 10:55:29.176507 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.97
INFO:tensorflow:Starting iteration 11

Steps executed: 306 Episode length: 154 Return: -91.436562454925374
INFO:tensorflow:Average training steps per second: 327.85
I0828 10:55:35.456558 140214119393280 replay_runner.py:36] Average training steps per second: 327.85
I0828 10:55:35.679294 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.89
INFO:tensorflow:Starting iteration 12

Steps executed: 312 Episode length: 138 Return: -303.16107122566723
INFO:tensorflow:Average training steps per second: 328.23
I0828 10:55:41.981303 140214119393280 replay_runner.py:36] Average training steps per second: 328.23
I0828 10:55:42.220497 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.89
INFO:tensorflow:Starting iteration 13

Steps executed: 149 Episode length: 149 Return: -383.72504277468283
INFO:tensorflow:Average training steps per second: 323.87

Steps executed: 313 Episode length: 164 Return: -186.73299730569633
I0828 10:55:48.803216 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.23
INFO:tensorflow:Starting iteration 14

Steps executed: 333 Episode length: 180 Return: -271.17595469238473
INFO:tensorflow:Average training steps per second: 332.06
I0828 10:55:55.012123 140214119393280 replay_runner.py:36] Average training steps per second: 332.06
I0828 10:55:55.229592 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -282.38
INFO:tensorflow:Starting iteration 15

Steps executed: 289 Episode length: 120 Return: -202.08518192476086
INFO:tensorflow:Average training steps per second: 339.01
I0828 10:56:01.446237 140214119393280 replay_runner.py:36] Average training steps per second: 339.01
I0828 10:56:01.663933 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.38
INFO:tensorflow:Starting iteration 16

Steps executed: 298 Episode length: 298 Return: -96.308414887645686
INFO:tensorflow:Average training steps per second: 339.59
I0828 10:56:07.863782 140214119393280 replay_runner.py:36] Average training steps per second: 339.59
I0828 10:56:08.126614 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.31
INFO:tensorflow:Starting iteration 17

Steps executed: 228 Episode length: 228 Return: -81.102296818000786
INFO:tensorflow:Average training steps per second: 336.98
I0828 10:56:14.398406 140214119393280 replay_runner.py:36] Average training steps per second: 336.98
I0828 10:56:14.577721 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.10
INFO:tensorflow:Starting iteration 18
I0828 10:56:17.905734 140214119393280 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 332.99

Steps executed: 272 Episode length: 129 Return: -330.42593068938174
I0828 10:56:21.122408 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.62
INFO:tensorflow:Starting iteration 19

Steps executed: 274 Episode length: 128 Return: -294.68172709076184
INFO:tensorflow:Average training steps per second: 340.03
I0828 10:56:27.380928 140214119393280 replay_runner.py:36] Average training steps per second: 340.03
I0828 10:56:27.583037 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.33
INFO:tensorflow:Starting iteration 20

Steps executed: 268 Episode length: 130 Return: -358.67093258374445
INFO:tensorflow:Average training steps per second: 343.34
I0828 10:56:33.808979 140214119393280 replay_runner.py:36] Average training steps per second: 343.34
I0828 10:56:33.994607 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.52
INFO:tensorflow:Starting iteration 21

Steps executed: 285 Episode length: 159 Return: -209.76107982687583
INFO:tensorflow:Average training steps per second: 349.07
I0828 10:56:40.199844 140214119393280 replay_runner.py:36] Average training steps per second: 349.07
I0828 10:56:40.389731 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.40
INFO:tensorflow:Starting iteration 22

Steps executed: 310 Episode length: 134 Return: -314.16138446207633
INFO:tensorflow:Average training steps per second: 350.19
I0828 10:56:46.612158 140214119393280 replay_runner.py:36] Average training steps per second: 350.19
I0828 10:56:46.821673 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.54
INFO:tensorflow:Starting iteration 23
I0828 10:56:50.196423 140214119393280 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 351.31

Steps executed: 261 Episode length: 134 Return: -202.57920106835733
I0828 10:56:53.228343 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.27
INFO:tensorflow:Starting iteration 24

Steps executed: 238 Episode length: 138 Return: -342.10910840096716
INFO:tensorflow:Average training steps per second: 356.49
I0828 10:56:59.447340 140214119393280 replay_runner.py:36] Average training steps per second: 356.49
I0828 10:56:59.608039 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.65
INFO:tensorflow:Starting iteration 25

Steps executed: 279 Episode length: 118 Return: -219.26517450849042
INFO:tensorflow:Average training steps per second: 356.57
I0828 10:57:05.855572 140214119393280 replay_runner.py:36] Average training steps per second: 356.57
I0828 10:57:06.038606 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -239.00
INFO:tensorflow:Starting iteration 26

Steps executed: 251 Episode length: 125 Return: -9.2785436603138722
INFO:tensorflow:Average training steps per second: 355.97
I0828 10:57:12.333173 140214119393280 replay_runner.py:36] Average training steps per second: 355.97
I0828 10:57:12.511467 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.58
INFO:tensorflow:Starting iteration 27
I0828 10:57:16.016480 140214119393280 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 371.11
I0828 10:57:18.711369 140214119393280 replay_runner.py:36] Average training steps per second: 371.11

Steps executed: 240 Episode length: 156 Return: -174.77981349479268
INFO:tensorflow:Starting iteration 28
I0828 10:57:22.309348 140214119393280 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 396.40
I0828 10:57:24.832304 140214119393280 replay_runner.py:36] Average training steps per second: 396.40

Steps executed: 243 Episode length: 87 Return: -343.203400117373518
INFO:tensorflow:Starting iteration 29
I0828 10:57:28.353575 140214119393280 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 391.74
I0828 10:57:30.906608 140214119393280 replay_runner.py:36] Average training steps per second: 391.74


Done fixed training!Episode length: 130 Return: -272.38615702203418