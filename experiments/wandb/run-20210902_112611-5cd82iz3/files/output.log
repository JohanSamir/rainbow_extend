Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0902 11:26:17.893982 140305128941568 run_experiment.py:549] Creating TrainRunner ...
I0902 11:26:17.905447 140305128941568 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 11:26:17.905725 140305128941568 dqn_agent.py:272] 	 gamma: 0.990000
I0902 11:26:17.905865 140305128941568 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 11:26:17.905984 140305128941568 dqn_agent.py:274] 	 min_replay_history: 500
I0902 11:26:17.906164 140305128941568 dqn_agent.py:275] 	 update_period: 4
I0902 11:26:17.906287 140305128941568 dqn_agent.py:276] 	 target_update_period: 300
I0902 11:26:17.906393 140305128941568 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 11:26:17.906498 140305128941568 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 11:26:17.906607 140305128941568 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 11:26:17.906725 140305128941568 dqn_agent.py:280] 	 optimizer: adam
I0902 11:26:17.907011 140305128941568 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 11:26:17.907237 140305128941568 dqn_agent.py:283] 	 seed: 1630581977905387
I0902 11:26:17.910926 140305128941568 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 11:26:17.911350 140305128941568 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 11:26:17.911555 140305128941568 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 11:26:17.911773 140305128941568 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 11:26:17.912162 140305128941568 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 11:26:17.912332 140305128941568 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 11:26:17.912626 140305128941568 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 11:26:17.912776 140305128941568 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 11:26:17.912950 140305128941568 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 11:26:18.091712 140305128941568 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:26:18.520292 140305128941568 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:26:18.535529 140305128941568 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 11:26:18.544235 140305128941568 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 11:26:18.544449 140305128941568 dqn_agent.py:272] 	 gamma: 0.990000
I0902 11:26:18.544590 140305128941568 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 11:26:18.544719 140305128941568 dqn_agent.py:274] 	 min_replay_history: 500
I0902 11:26:18.544867 140305128941568 dqn_agent.py:275] 	 update_period: 4
I0902 11:26:18.544960 140305128941568 dqn_agent.py:276] 	 target_update_period: 300
I0902 11:26:18.545034 140305128941568 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 11:26:18.545106 140305128941568 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 11:26:18.545267 140305128941568 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 11:26:18.545461 140305128941568 dqn_agent.py:280] 	 optimizer: adam
I0902 11:26:18.545723 140305128941568 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 11:26:18.545820 140305128941568 dqn_agent.py:283] 	 seed: 1630581978544187
I0902 11:26:18.548858 140305128941568 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 11:26:18.549037 140305128941568 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 11:26:18.549137 140305128941568 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 11:26:18.549239 140305128941568 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 11:26:18.549344 140305128941568 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 11:26:18.549432 140305128941568 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 11:26:18.549512 140305128941568 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 11:26:18.549592 140305128941568 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 11:26:18.549674 140305128941568 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 11:26:18.596663 140305128941568 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:26:18.628781 140305128941568 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 11:26:18.629143 140305128941568 replay_runner.py:41] Starting iteration 0
Steps executed: 288 Episode length: 156 Return: -184.7529376467121
INFO:tensorflow:Average training steps per second: 140.59
I0902 11:26:25.742311 140305128941568 replay_runner.py:36] Average training steps per second: 140.59
I0902 11:26:27.029500 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.43
INFO:tensorflow:Starting iteration 1

Steps executed: 301 Episode length: 138 Return: -260.32134310412147
INFO:tensorflow:Average training steps per second: 217.78
I0902 11:26:35.992238 140305128941568 replay_runner.py:36] Average training steps per second: 217.78
I0902 11:26:36.310815 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.29
INFO:tensorflow:Starting iteration 2
I0902 11:26:40.654394 140305128941568 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 215.81

Steps executed: 501 Episode length: 323 Return: -304.09874161291183
I0902 11:26:45.955727 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.55
INFO:tensorflow:Starting iteration 3
I0902 11:26:50.342874 140305128941568 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 213.80

Steps executed: 849 Episode length: 849 Return: -221.05515560164704
I0902 11:26:56.492798 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.06
INFO:tensorflow:Starting iteration 4
I0902 11:27:00.622673 140305128941568 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 235.42

Steps executed: 1000 Episode length: 1000 Return: -127.02769793756539
I0902 11:27:08.813099 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.03
INFO:tensorflow:Starting iteration 5
I0902 11:27:12.648579 140305128941568 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 229.43

Steps executed: 1000 Episode length: 1000 Return: -279.38268107588726
I0902 11:27:19.473483 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.38
INFO:tensorflow:Starting iteration 6
I0902 11:27:23.676520 140305128941568 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 222.24

Steps executed: 1000 Episode length: 1000 Return: -136.94548188817656
I0902 11:27:30.325497 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.95
INFO:tensorflow:Starting iteration 7
I0902 11:27:34.540702 140305128941568 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 212.47

Steps executed: 541 Episode length: 541 Return: -378.6558257079717656
I0902 11:27:40.375884 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -378.66
INFO:tensorflow:Starting iteration 8
I0902 11:27:44.843653 140305128941568 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 217.95
I0902 11:27:49.432605 140305128941568 replay_runner.py:36] Average training steps per second: 217.95

Steps executed: 792 Episode length: 792 Return: -401.4148215102278656
INFO:tensorflow:Starting iteration 9
I0902 11:27:56.214171 140305128941568 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 218.46

Steps executed: 656 Episode length: 656 Return: -327.4294151775768656
I0902 11:28:02.387178 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.43
INFO:tensorflow:Starting iteration 10
I0902 11:28:06.470256 140305128941568 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 210.78

Steps executed: 823 Episode length: 823 Return: -139.7022571441152656
I0902 11:28:13.375551 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.70
INFO:tensorflow:Starting iteration 11
I0902 11:28:17.676971 140305128941568 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 210.35

Steps executed: 784 Episode length: 784 Return: -235.7647101851392656
I0902 11:28:24.084915 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.76
INFO:tensorflow:Starting iteration 12
I0902 11:28:28.346810 140305128941568 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 214.29

Steps executed: 1000 Episode length: 1000 Return: -121.16526513495207
I0902 11:28:35.202729 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.17
INFO:tensorflow:Starting iteration 13
I0902 11:28:39.386155 140305128941568 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 214.84

Steps executed: 883 Episode length: 883 Return: -396.9244544280257207
I0902 11:28:45.973053 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -396.92
INFO:tensorflow:Starting iteration 14
I0902 11:28:50.091607 140305128941568 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 214.06

Steps executed: 1000 Episode length: 1000 Return: -68.914105326591517
I0902 11:28:57.265723 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.91
INFO:tensorflow:Starting iteration 15
I0902 11:29:01.508367 140305128941568 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 209.46

Steps executed: 252 Episode length: 252 Return: -27.90622643561214517
I0902 11:29:06.596533 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -27.91
INFO:tensorflow:Starting iteration 16

Steps executed: 279 Episode length: 96 Return: -17.785441759564329517
INFO:tensorflow:Average training steps per second: 219.33
I0902 11:29:15.573726 140305128941568 replay_runner.py:36] Average training steps per second: 219.33
I0902 11:29:15.851638 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.80
INFO:tensorflow:Starting iteration 17

Steps executed: 154 Episode length: 154 Return: -129.7012097742616317
INFO:tensorflow:Average training steps per second: 222.77
I0902 11:29:24.817259 140305128941568 replay_runner.py:36] Average training steps per second: 222.77

Steps executed: 687 Episode length: 533 Return: -114.7916359595640617
INFO:tensorflow:Starting iteration 18

Steps executed: 398 Episode length: 398 Return: -275.1563234401416617
INFO:tensorflow:Average training steps per second: 217.22
I0902 11:29:34.715484 140305128941568 replay_runner.py:36] Average training steps per second: 217.22
I0902 11:29:35.427676 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -275.16
INFO:tensorflow:Starting iteration 19

Steps executed: 426 Episode length: 235 Return: -9.782984571501999617
INFO:tensorflow:Average training steps per second: 213.09
I0902 11:29:44.513545 140305128941568 replay_runner.py:36] Average training steps per second: 213.09
I0902 11:29:45.035399 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: 0.52
INFO:tensorflow:Starting iteration 20
I0902 11:29:49.523112 140305128941568 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 218.43
I0902 11:29:54.101856 140305128941568 replay_runner.py:36] Average training steps per second: 218.43

Steps executed: 218 Episode length: 98 Return: -283.12234736506554617
INFO:tensorflow:Starting iteration 21

Steps executed: 303 Episode length: 303 Return: -341.9709876129510317
INFO:tensorflow:Average training steps per second: 236.86
I0902 11:30:02.981200 140305128941568 replay_runner.py:36] Average training steps per second: 236.86
I0902 11:30:03.351023 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.97
INFO:tensorflow:Starting iteration 22
I0902 11:30:07.523209 140305128941568 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 254.93

Steps executed: 633 Episode length: 633 Return: -88.28784550966736317
I0902 11:30:12.809897 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.29
INFO:tensorflow:Starting iteration 23
I0902 11:30:16.686333 140305128941568 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 297.97
I0902 11:30:20.042917 140305128941568 replay_runner.py:36] Average training steps per second: 297.97

Steps executed: 436 Episode length: 436 Return: -447.9335709539917617
INFO:tensorflow:Starting iteration 24

Steps executed: 363 Episode length: 275 Return: -252.4280366785809517
INFO:tensorflow:Average training steps per second: 330.42
I0902 11:30:27.098691 140305128941568 replay_runner.py:36] Average training steps per second: 330.42
I0902 11:30:27.370004 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.28
INFO:tensorflow:Starting iteration 25
I0902 11:30:30.792614 140305128941568 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 329.85

Steps executed: 941 Episode length: 941 Return: 94.109937044337789517
I0902 11:30:35.225364 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: 94.11
INFO:tensorflow:Starting iteration 26
I0902 11:30:38.651417 140305128941568 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 322.99
I0902 11:30:41.747781 140305128941568 replay_runner.py:36] Average training steps per second: 322.99

Steps executed: 423 Episode length: 423 Return: -515.4487119123313517
INFO:tensorflow:Starting iteration 27

Steps executed: 268 Episode length: 109 Return: -92.65080191595293517
INFO:tensorflow:Average training steps per second: 302.23
I0902 11:30:48.851263 140305128941568 replay_runner.py:36] Average training steps per second: 302.23
I0902 11:30:49.022904 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.76
INFO:tensorflow:Starting iteration 28

Steps executed: 418 Episode length: 351 Return: -72.41850942470985517
INFO:tensorflow:Average training steps per second: 312.54
I0902 11:30:55.460463 140305128941568 replay_runner.py:36] Average training steps per second: 312.54
I0902 11:30:55.823918 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.57
INFO:tensorflow:Starting iteration 29

Steps executed: 203 Episode length: 71 Return: -215.44990804558876717
INFO:tensorflow:Average training steps per second: 325.89
I0902 11:31:02.071421 140305128941568 replay_runner.py:36] Average training steps per second: 325.89

Done fixed training!Episode length: 71 Return: -215.44990804558876717