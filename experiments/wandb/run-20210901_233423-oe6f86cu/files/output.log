Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0901 23:34:30.383108 140252174653440 run_experiment.py:549] Creating TrainRunner ...
I0901 23:34:30.394369 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:34:30.394609 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:34:30.394863 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:34:30.395010 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:34:30.395126 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0901 23:34:30.395235 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:34:30.395345 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:34:30.395453 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:34:30.395558 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:34:30.395662 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0901 23:34:30.395764 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:34:30.395857 140252174653440 dqn_agent.py:283] 	 seed: 1630539270394306
I0901 23:34:30.398769 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:34:30.398967 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:34:30.399099 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:34:30.399217 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:34:30.399322 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:34:30.399424 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:34:30.399517 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:34:30.399608 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:34:30.399699 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:34:30.432506 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:30.827475 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:30.841238 140252174653440 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:34:30.850538 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:34:30.850818 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:34:30.850977 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:34:30.851142 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:34:30.851278 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0901 23:34:30.851540 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:34:30.851908 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:34:30.852082 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:34:30.852235 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:34:30.852371 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0901 23:34:30.852502 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:34:30.852625 140252174653440 dqn_agent.py:283] 	 seed: 1630539270850473
I0901 23:34:30.855861 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:34:30.856153 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:34:30.856295 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:34:30.856381 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:34:30.856458 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:34:30.856531 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:34:30.856640 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:34:30.856745 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:34:30.856817 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:34:30.918213 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:30.938930 140252174653440 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:34:30.939142 140252174653440 replay_runner.py:41] Starting iteration 0
Steps executed: 200 Episode length: 89 Return: -99.05284057877739
INFO:tensorflow:Average training steps per second: 169.35
I0901 23:34:36.844494 140252174653440 replay_runner.py:36] Average training steps per second: 169.35
I0901 23:34:37.896053 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.28
INFO:tensorflow:Starting iteration 1

Steps executed: 247 Episode length: 54 Return: -122.82839352502509
INFO:tensorflow:Average training steps per second: 231.25
I0901 23:34:46.579809 140252174653440 replay_runner.py:36] Average training steps per second: 231.25
I0901 23:34:46.738627 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.25
INFO:tensorflow:Starting iteration 2

Steps executed: 242 Episode length: 62 Return: -129.78070197713384
INFO:tensorflow:Average training steps per second: 225.36
I0901 23:34:55.552539 140252174653440 replay_runner.py:36] Average training steps per second: 225.36
I0901 23:34:55.730232 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.76
INFO:tensorflow:Starting iteration 3

Steps executed: 203 Episode length: 76 Return: -120.23096277158635
INFO:tensorflow:Average training steps per second: 240.32
I0901 23:35:04.270173 140252174653440 replay_runner.py:36] Average training steps per second: 240.32
I0901 23:35:04.388432 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.97
INFO:tensorflow:Starting iteration 4

Steps executed: 240 Episode length: 66 Return: -169.72401189565005
INFO:tensorflow:Average training steps per second: 252.45
I0901 23:35:12.740749 140252174653440 replay_runner.py:36] Average training steps per second: 252.45
I0901 23:35:12.864160 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.07
INFO:tensorflow:Starting iteration 5

Steps executed: 238 Episode length: 64 Return: -157.61823435428784
INFO:tensorflow:Average training steps per second: 250.51
I0901 23:35:20.842489 140252174653440 replay_runner.py:36] Average training steps per second: 250.51
I0901 23:35:20.975756 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.05
INFO:tensorflow:Starting iteration 6

Steps executed: 288 Episode length: 91 Return: -219.53544637356942
INFO:tensorflow:Average training steps per second: 230.41
I0901 23:35:29.466850 140252174653440 replay_runner.py:36] Average training steps per second: 230.41
I0901 23:35:29.639785 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.63
INFO:tensorflow:Starting iteration 7

Steps executed: 227 Episode length: 59 Return: -154.15184853197112
INFO:tensorflow:Average training steps per second: 226.43
I0901 23:35:38.352128 140252174653440 replay_runner.py:36] Average training steps per second: 226.43
I0901 23:35:38.495642 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.54
INFO:tensorflow:Starting iteration 8

Steps executed: 252 Episode length: 108 Return: -13.714729896442236
INFO:tensorflow:Average training steps per second: 222.80
I0901 23:35:47.367125 140252174653440 replay_runner.py:36] Average training steps per second: 222.80
I0901 23:35:47.528331 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.52
INFO:tensorflow:Starting iteration 9

Steps executed: 146 Episode length: 84 Return: -120.584244693806626
INFO:tensorflow:Average training steps per second: 226.39

Steps executed: 208 Episode length: 62 Return: -97.8727600036328626
I0901 23:35:56.380094 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.58
INFO:tensorflow:Starting iteration 10

Steps executed: 231 Episode length: 74 Return: -157.730501842618346
INFO:tensorflow:Average training steps per second: 225.78
I0901 23:36:05.062071 140252174653440 replay_runner.py:36] Average training steps per second: 225.78
I0901 23:36:05.210605 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.27
INFO:tensorflow:Starting iteration 11

Steps executed: 210 Episode length: 82 Return: -119.598682712668286
INFO:tensorflow:Average training steps per second: 223.36
I0901 23:36:14.053174 140252174653440 replay_runner.py:36] Average training steps per second: 223.36
I0901 23:36:14.193490 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.10
INFO:tensorflow:Starting iteration 12

Steps executed: 233 Episode length: 85 Return: -94.3282483734647986
INFO:tensorflow:Average training steps per second: 225.16
I0901 23:36:23.019172 140252174653440 replay_runner.py:36] Average training steps per second: 225.16
I0901 23:36:23.179903 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.67
INFO:tensorflow:Starting iteration 13

Steps executed: 201 Episode length: 67 Return: -142.391789978600976
INFO:tensorflow:Average training steps per second: 220.18
I0901 23:36:32.053609 140252174653440 replay_runner.py:36] Average training steps per second: 220.18
I0901 23:36:32.184672 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.34
INFO:tensorflow:Starting iteration 14

Steps executed: 202 Episode length: 73 Return: -184.765114792121276
INFO:tensorflow:Average training steps per second: 219.97
I0901 23:36:41.123161 140252174653440 replay_runner.py:36] Average training steps per second: 219.97
I0901 23:36:41.258190 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.46
INFO:tensorflow:Starting iteration 15

Steps executed: 281 Episode length: 88 Return: -154.427106410203276
INFO:tensorflow:Average training steps per second: 220.27
I0901 23:36:50.101303 140252174653440 replay_runner.py:36] Average training steps per second: 220.27
I0901 23:36:50.289919 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.63
INFO:tensorflow:Starting iteration 16

Steps executed: 200 Episode length: 84 Return: -113.973409293936976
INFO:tensorflow:Average training steps per second: 221.95
I0901 23:36:59.171610 140252174653440 replay_runner.py:36] Average training steps per second: 221.95
I0901 23:36:59.305153 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.45
INFO:tensorflow:Starting iteration 17

Steps executed: 259 Episode length: 81 Return: -136.960162933641586
INFO:tensorflow:Average training steps per second: 216.41
I0901 23:37:08.241312 140252174653440 replay_runner.py:36] Average training steps per second: 216.41
I0901 23:37:08.404621 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.40
INFO:tensorflow:Starting iteration 18

Steps executed: 238 Episode length: 68 Return: -147.614834193359036
INFO:tensorflow:Average training steps per second: 224.29
I0901 23:37:17.209800 140252174653440 replay_runner.py:36] Average training steps per second: 224.29
I0901 23:37:17.359252 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.88
INFO:tensorflow:Starting iteration 19

Steps executed: 214 Episode length: 67 Return: -143.348746371345846
INFO:tensorflow:Average training steps per second: 225.79
I0901 23:37:26.149426 140252174653440 replay_runner.py:36] Average training steps per second: 225.79
I0901 23:37:26.292671 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.56
INFO:tensorflow:Starting iteration 20

Steps executed: 236 Episode length: 67 Return: -143.718253242697826
INFO:tensorflow:Average training steps per second: 220.49
I0901 23:37:35.178676 140252174653440 replay_runner.py:36] Average training steps per second: 220.49
I0901 23:37:35.337525 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.82
INFO:tensorflow:Starting iteration 21

Steps executed: 247 Episode length: 68 Return: -175.417600112374776
INFO:tensorflow:Average training steps per second: 220.80
I0901 23:37:44.226430 140252174653440 replay_runner.py:36] Average training steps per second: 220.80
I0901 23:37:44.385879 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.30
INFO:tensorflow:Starting iteration 22

Steps executed: 268 Episode length: 71 Return: -142.926673526112276
INFO:tensorflow:Average training steps per second: 221.26
I0901 23:37:53.265895 140252174653440 replay_runner.py:36] Average training steps per second: 221.26
I0901 23:37:53.442167 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.68
INFO:tensorflow:Starting iteration 23

Steps executed: 222 Episode length: 87 Return: -129.115873265265446
INFO:tensorflow:Average training steps per second: 234.61
I0901 23:38:01.956986 140252174653440 replay_runner.py:36] Average training steps per second: 234.61
I0901 23:38:02.088123 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.29
INFO:tensorflow:Starting iteration 24
I0901 23:38:06.240926 140252174653440 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 227.65
I0901 23:38:10.634328 140252174653440 replay_runner.py:36] Average training steps per second: 227.65

Steps executed: 242 Episode length: 57 Return: -121.967132101051226
INFO:tensorflow:Starting iteration 25

Steps executed: 258 Episode length: 76 Return: -112.704593153402246
INFO:tensorflow:Average training steps per second: 238.35
I0901 23:38:19.144509 140252174653440 replay_runner.py:36] Average training steps per second: 238.35
I0901 23:38:19.293371 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.80
INFO:tensorflow:Starting iteration 26

Steps executed: 209 Episode length: 59 Return: -105.933758293894076
INFO:tensorflow:Average training steps per second: 239.88
I0901 23:38:27.522485 140252174653440 replay_runner.py:36] Average training steps per second: 239.88
I0901 23:38:27.643518 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.08
INFO:tensorflow:Starting iteration 27

Steps executed: 249 Episode length: 59 Return: -150.967045754298546
INFO:tensorflow:Average training steps per second: 234.73
I0901 23:38:36.127840 140252174653440 replay_runner.py:36] Average training steps per second: 234.73
I0901 23:38:36.292939 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.80
INFO:tensorflow:Starting iteration 28

Steps executed: 260 Episode length: 65 Return: -162.667849427871036
INFO:tensorflow:Average training steps per second: 226.62
I0901 23:38:44.989430 140252174653440 replay_runner.py:36] Average training steps per second: 226.62
I0901 23:38:45.165573 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.65
INFO:tensorflow:Starting iteration 29

Steps executed: 241 Episode length: 70 Return: -131.363275465423686
INFO:tensorflow:Average training steps per second: 225.23
I0901 23:38:53.946888 140252174653440 replay_runner.py:36] Average training steps per second: 225.23

Done fixed training!Episode length: 70 Return: -131.363275465423686