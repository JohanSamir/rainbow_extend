Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0902 17:46:13.398925 140613433649152 run_experiment.py:549] Creating TrainRunner ...
I0902 17:46:13.411548 140613433649152 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:46:13.411975 140613433649152 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:46:13.412140 140613433649152 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:46:13.412244 140613433649152 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:46:13.412349 140613433649152 dqn_agent.py:275] 	 update_period: 4
I0902 17:46:13.412434 140613433649152 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:46:13.412724 140613433649152 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:46:13.413027 140613433649152 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:46:13.413175 140613433649152 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:46:13.413363 140613433649152 dqn_agent.py:280] 	 optimizer: adam
I0902 17:46:13.413466 140613433649152 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:46:13.413549 140613433649152 dqn_agent.py:283] 	 seed: 1630604773411474
I0902 17:46:13.416388 140613433649152 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:46:13.416611 140613433649152 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:46:13.416735 140613433649152 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:46:13.416877 140613433649152 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:46:13.416992 140613433649152 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:46:13.417097 140613433649152 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:46:13.417228 140613433649152 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:46:13.417337 140613433649152 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:46:13.417450 140613433649152 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:46:13.455240 140613433649152 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=5.000000
I0902 17:46:13.865397 140613433649152 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=5.000000
I0902 17:46:13.879327 140613433649152 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 17:46:14.176669 140613433649152 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:46:14.176907 140613433649152 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:46:14.177050 140613433649152 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:46:14.177189 140613433649152 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:46:14.177332 140613433649152 dqn_agent.py:275] 	 update_period: 4
I0902 17:46:14.177433 140613433649152 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:46:14.177632 140613433649152 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:46:14.177815 140613433649152 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:46:14.177907 140613433649152 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:46:14.178045 140613433649152 dqn_agent.py:280] 	 optimizer: adam
I0902 17:46:14.178132 140613433649152 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:46:14.178336 140613433649152 dqn_agent.py:283] 	 seed: 1630604774176623
I0902 17:46:14.182198 140613433649152 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:46:14.182482 140613433649152 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:46:14.182880 140613433649152 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:46:14.183069 140613433649152 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:46:14.183200 140613433649152 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:46:14.183727 140613433649152 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:46:14.183879 140613433649152 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:46:14.184171 140613433649152 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:46:14.184500 140613433649152 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:46:14.215299 140613433649152 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=5.000000
I0902 17:46:14.237424 140613433649152 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 17:46:14.237771 140613433649152 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 161.84
I0902 17:46:20.417015 140613433649152 replay_runner.py:36] Average training steps per second: 161.84
Steps executed: 228 Episode length: 81 Return: -223.41930474949876
I0902 17:46:21.587851 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.00
INFO:tensorflow:Starting iteration 1

Steps executed: 209 Episode length: 57 Return: -396.81409954537486
INFO:tensorflow:Average training steps per second: 224.18
I0902 17:46:30.403429 140613433649152 replay_runner.py:36] Average training steps per second: 224.18
I0902 17:46:30.585498 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.63
INFO:tensorflow:Starting iteration 2

Steps executed: 209 Episode length: 51 Return: -364.43424512329244
INFO:tensorflow:Average training steps per second: 221.75
I0902 17:46:39.431651 140613433649152 replay_runner.py:36] Average training steps per second: 221.75
I0902 17:46:39.616984 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -299.12
INFO:tensorflow:Starting iteration 3

Steps executed: 210 Episode length: 86 Return: -242.54001077461694
INFO:tensorflow:Average training steps per second: 221.29
I0902 17:46:48.476778 140613433649152 replay_runner.py:36] Average training steps per second: 221.29
I0902 17:46:48.666203 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.58
INFO:tensorflow:Starting iteration 4

Steps executed: 232 Episode length: 71 Return: -251.07915220229347
INFO:tensorflow:Average training steps per second: 223.41
I0902 17:46:57.453754 140613433649152 replay_runner.py:36] Average training steps per second: 223.41
I0902 17:46:57.640074 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.07
INFO:tensorflow:Starting iteration 5

Steps executed: 247 Episode length: 59 Return: -300.93512378121052
INFO:tensorflow:Average training steps per second: 219.29
I0902 17:47:06.484594 140613433649152 replay_runner.py:36] Average training steps per second: 219.29
I0902 17:47:06.689692 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.96
INFO:tensorflow:Starting iteration 6

Steps executed: 218 Episode length: 77 Return: -308.87367695096884
INFO:tensorflow:Average training steps per second: 242.30
I0902 17:47:14.931170 140613433649152 replay_runner.py:36] Average training steps per second: 242.30
I0902 17:47:15.104506 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.12
INFO:tensorflow:Starting iteration 7

Steps executed: 222 Episode length: 50 Return: -315.58466147515776
INFO:tensorflow:Average training steps per second: 239.75
I0902 17:47:23.559513 140613433649152 replay_runner.py:36] Average training steps per second: 239.75
I0902 17:47:23.715706 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -318.60
INFO:tensorflow:Starting iteration 8

Steps executed: 326 Episode length: 130 Return: -418.1975071205873
INFO:tensorflow:Average training steps per second: 239.41
I0902 17:47:31.972754 140613433649152 replay_runner.py:36] Average training steps per second: 239.41
I0902 17:47:32.235184 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -358.85
INFO:tensorflow:Starting iteration 9

Steps executed: 336 Episode length: 164 Return: -22.890298837439857
INFO:tensorflow:Average training steps per second: 223.55
I0902 17:47:40.959397 140613433649152 replay_runner.py:36] Average training steps per second: 223.55
I0902 17:47:41.245634 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.36
INFO:tensorflow:Starting iteration 10

Steps executed: 244 Episode length: 92 Return: -200.857690587727037
INFO:tensorflow:Average training steps per second: 220.83
I0902 17:47:50.067427 140613433649152 replay_runner.py:36] Average training steps per second: 220.83
I0902 17:47:50.268756 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -470.33
INFO:tensorflow:Starting iteration 11

Steps executed: 288 Episode length: 109 Return: -276.66305521826035
INFO:tensorflow:Average training steps per second: 222.31
I0902 17:47:58.883516 140613433649152 replay_runner.py:36] Average training steps per second: 222.31
I0902 17:47:59.127083 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -355.44
INFO:tensorflow:Starting iteration 12

Steps executed: 317 Episode length: 119 Return: -135.52301584140868
INFO:tensorflow:Average training steps per second: 222.86
I0902 17:48:07.890714 140613433649152 replay_runner.py:36] Average training steps per second: 222.86
I0902 17:48:08.128877 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.29
INFO:tensorflow:Starting iteration 13

Steps executed: 216 Episode length: 120 Return: -333.25767250900058
INFO:tensorflow:Average training steps per second: 220.24
I0902 17:48:16.746586 140613433649152 replay_runner.py:36] Average training steps per second: 220.24
I0902 17:48:16.935967 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.36
INFO:tensorflow:Starting iteration 14

Steps executed: 292 Episode length: 115 Return: -246.01269123861118
INFO:tensorflow:Average training steps per second: 220.10
I0902 17:48:25.749680 140613433649152 replay_runner.py:36] Average training steps per second: 220.10
I0902 17:48:25.995823 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.64
INFO:tensorflow:Starting iteration 15

Steps executed: 219 Episode length: 121 Return: -258.54530862582203
INFO:tensorflow:Average training steps per second: 219.80
I0902 17:48:34.903043 140613433649152 replay_runner.py:36] Average training steps per second: 219.80
I0902 17:48:35.092805 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -358.91
INFO:tensorflow:Starting iteration 16

Steps executed: 242 Episode length: 89 Return: -568.420566744982853
INFO:tensorflow:Average training steps per second: 223.01
I0902 17:48:43.858342 140613433649152 replay_runner.py:36] Average training steps per second: 223.01
I0902 17:48:44.055541 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -318.49
INFO:tensorflow:Starting iteration 17

Steps executed: 250 Episode length: 91 Return: -151.455123868269965
INFO:tensorflow:Average training steps per second: 224.26
I0902 17:48:52.806877 140613433649152 replay_runner.py:36] Average training steps per second: 224.26
I0902 17:48:53.035346 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.62
INFO:tensorflow:Starting iteration 18

Steps executed: 241 Episode length: 120 Return: -227.20127969692182
INFO:tensorflow:Average training steps per second: 226.43
I0902 17:49:01.817874 140613433649152 replay_runner.py:36] Average training steps per second: 226.43
I0902 17:49:02.018020 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.54
INFO:tensorflow:Starting iteration 19

Steps executed: 236 Episode length: 129 Return: -311.71234561894494
INFO:tensorflow:Average training steps per second: 222.99
I0902 17:49:10.655960 140613433649152 replay_runner.py:36] Average training steps per second: 222.99
I0902 17:49:10.884081 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -408.63
INFO:tensorflow:Starting iteration 20
I0902 17:49:15.099879 140613433649152 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 219.14

Steps executed: 311 Episode length: 177 Return: -306.32513871695295
I0902 17:49:19.962918 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -291.35
INFO:tensorflow:Starting iteration 21

Steps executed: 265 Episode length: 160 Return: -173.60245854805775
INFO:tensorflow:Average training steps per second: 221.90
I0902 17:49:28.757619 140613433649152 replay_runner.py:36] Average training steps per second: 221.90
I0902 17:49:28.984944 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.06
INFO:tensorflow:Starting iteration 22

Steps executed: 218 Episode length: 124 Return: -438.64103386939065
INFO:tensorflow:Average training steps per second: 233.81
I0902 17:49:37.471428 140613433649152 replay_runner.py:36] Average training steps per second: 233.81
I0902 17:49:37.657404 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.75
INFO:tensorflow:Starting iteration 23

Steps executed: 294 Episode length: 143 Return: -436.81191235266795
INFO:tensorflow:Average training steps per second: 220.78
I0902 17:49:46.522469 140613433649152 replay_runner.py:36] Average training steps per second: 220.78
I0902 17:49:46.801880 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.24
INFO:tensorflow:Starting iteration 24
I0902 17:49:51.077579 140613433649152 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 218.21

Steps executed: 267 Episode length: 267 Return: -15.796957820205364
I0902 17:49:55.960223 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -15.80
INFO:tensorflow:Starting iteration 25

Steps executed: 286 Episode length: 166 Return: -176.10145127115882
INFO:tensorflow:Average training steps per second: 230.69
I0902 17:50:04.613970 140613433649152 replay_runner.py:36] Average training steps per second: 230.69
I0902 17:50:04.859186 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -214.58
INFO:tensorflow:Starting iteration 26

Steps executed: 200 Episode length: 101 Return: -296.14650988209155
INFO:tensorflow:Average training steps per second: 251.38
I0902 17:50:12.993998 140613433649152 replay_runner.py:36] Average training steps per second: 251.38
I0902 17:50:13.152364 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -478.40
INFO:tensorflow:Starting iteration 27
I0902 17:50:17.458950 140613433649152 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 231.34

Steps executed: 312 Episode length: 196 Return: -403.26772613029735
I0902 17:50:22.069635 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -335.59
INFO:tensorflow:Starting iteration 28

Steps executed: 204 Episode length: 89 Return: -672.028573281873265
INFO:tensorflow:Average training steps per second: 231.98
I0902 17:50:30.670759 140613433649152 replay_runner.py:36] Average training steps per second: 231.98
I0902 17:50:30.851241 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -501.68
INFO:tensorflow:Starting iteration 29

Steps executed: 207 Episode length: 111 Return: -263.42591058562535
INFO:tensorflow:Average training steps per second: 232.18
I0902 17:50:39.269366 140613433649152 replay_runner.py:36] Average training steps per second: 232.18

Done fixed training!Episode length: 111 Return: -263.42591058562535