Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0902 00:15:03.411224 140149719906304 run_experiment.py:549] Creating TrainRunner ...
I0902 00:15:03.421588 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:15:03.421801 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:15:03.422065 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:15:03.422393 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:15:03.422610 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0902 00:15:03.422797 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:15:03.422923 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:15:03.423043 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:15:03.423156 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:15:03.423243 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0902 00:15:03.423362 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:15:03.423454 140149719906304 dqn_agent.py:283] 	 seed: 1630541703421531
I0902 00:15:03.426874 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:15:03.427048 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:15:03.427153 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:15:03.427471 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:15:03.427614 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:15:03.427688 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:15:03.427781 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:15:03.427841 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:15:03.427891 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:15:03.463340 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:03.821851 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:03.836357 140149719906304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:15:03.845809 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:15:03.846161 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:15:03.846394 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:15:03.846667 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:15:03.846986 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0902 00:15:03.847184 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:15:03.847345 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:15:03.847462 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:15:03.847590 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:15:03.847719 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0902 00:15:03.847939 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:15:03.848239 140149719906304 dqn_agent.py:283] 	 seed: 1630541703845724
I0902 00:15:03.852083 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:15:03.852354 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:15:03.852505 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:15:03.852596 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:15:03.852714 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:15:03.852810 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:15:03.852886 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:15:03.852977 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:15:03.853195 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:15:03.889040 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:03.958792 140149719906304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:15:03.959442 140149719906304 replay_runner.py:41] Starting iteration 0
Steps executed: 280 Episode length: 152 Return: -459.53219047866815
INFO:tensorflow:Average training steps per second: 178.83
I0902 00:15:09.551890 140149719906304 replay_runner.py:36] Average training steps per second: 178.83
I0902 00:15:10.800470 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -403.16
INFO:tensorflow:Starting iteration 1

Steps executed: 368 Episode length: 250 Return: -464.80070512643773
INFO:tensorflow:Average training steps per second: 234.25
I0902 00:15:19.405701 140149719906304 replay_runner.py:36] Average training steps per second: 234.25
I0902 00:15:19.799795 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -363.47
INFO:tensorflow:Starting iteration 2

Steps executed: 258 Episode length: 118 Return: -376.84392063193854
INFO:tensorflow:Average training steps per second: 223.16
I0902 00:15:28.484447 140149719906304 replay_runner.py:36] Average training steps per second: 223.16
I0902 00:15:28.704360 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.79
INFO:tensorflow:Starting iteration 3

Steps executed: 288 Episode length: 141 Return: -240.57788322836876
INFO:tensorflow:Average training steps per second: 225.36
I0902 00:15:37.392065 140149719906304 replay_runner.py:36] Average training steps per second: 225.36
I0902 00:15:37.637898 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.73
INFO:tensorflow:Starting iteration 4
I0902 00:15:41.767194 140149719906304 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 222.21

Steps executed: 565 Episode length: 565 Return: -350.56707990567676
I0902 00:15:47.435214 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -350.57
INFO:tensorflow:Starting iteration 5
I0902 00:15:51.817078 140149719906304 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 220.94

Steps executed: 1000 Episode length: 1000 Return: -132.92504081828636
I0902 00:15:59.532096 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.93
INFO:tensorflow:Starting iteration 6
I0902 00:16:03.684622 140149719906304 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 225.89

Steps executed: 1000 Episode length: 1000 Return: -41.491651304752494
I0902 00:16:11.974542 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -41.49
INFO:tensorflow:Starting iteration 7
I0902 00:16:16.178967 140149719906304 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 223.53

Steps executed: 670 Episode length: 670 Return: -304.4138246756112494
I0902 00:16:21.866765 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.41
INFO:tensorflow:Starting iteration 8
I0902 00:16:26.240989 140149719906304 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 226.67

Steps executed: 1000 Episode length: 1000 Return: -139.36647289111883
I0902 00:16:33.206043 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.37
INFO:tensorflow:Starting iteration 9

Steps executed: 259 Episode length: 259 Return: -62.60662205236650483
INFO:tensorflow:Average training steps per second: 231.59
I0902 00:16:41.819024 140149719906304 replay_runner.py:36] Average training steps per second: 231.59
I0902 00:16:42.085877 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -62.61
INFO:tensorflow:Starting iteration 10
I0902 00:16:46.236205 140149719906304 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 231.37

Steps executed: 559 Episode length: 559 Return: -194.6176808883285583
I0902 00:16:51.737465 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -194.62
INFO:tensorflow:Starting iteration 11
I0902 00:16:55.864138 140149719906304 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 238.54

Steps executed: 1000 Episode length: 1000 Return: -160.87777039574397
I0902 00:17:02.780264 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.88
INFO:tensorflow:Starting iteration 12
I0902 00:17:06.924226 140149719906304 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 246.03
I0902 00:17:10.989063 140149719906304 replay_runner.py:36] Average training steps per second: 246.03

Steps executed: 430 Episode length: 430 Return: -361.1577792075064597
INFO:tensorflow:Starting iteration 13

Steps executed: 559 Episode length: 388 Return: -185.1788691045287697
INFO:tensorflow:Average training steps per second: 246.06
I0902 00:17:19.795080 140149719906304 replay_runner.py:36] Average training steps per second: 246.06
I0902 00:17:20.431336 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.27
INFO:tensorflow:Starting iteration 14
I0902 00:17:24.456267 140149719906304 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 248.31

Steps executed: 771 Episode length: 771 Return: -389.1540866380728497
I0902 00:17:29.993876 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -389.15
INFO:tensorflow:Starting iteration 15

Steps executed: 317 Episode length: 317 Return: -303.3743551661732597
INFO:tensorflow:Average training steps per second: 252.12
I0902 00:17:37.995297 140149719906304 replay_runner.py:36] Average training steps per second: 252.12
I0902 00:17:38.417659 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.37
INFO:tensorflow:Starting iteration 16

Steps executed: 249 Episode length: 249 Return: -83.88432435848837597
INFO:tensorflow:Average training steps per second: 252.36
I0902 00:17:46.399486 140149719906304 replay_runner.py:36] Average training steps per second: 252.36
I0902 00:17:46.643435 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.88
INFO:tensorflow:Starting iteration 17

Steps executed: 309 Episode length: 150 Return: 22.622028785013615597
INFO:tensorflow:Average training steps per second: 269.36
I0902 00:17:54.301423 140149719906304 replay_runner.py:36] Average training steps per second: 269.36
I0902 00:17:54.558988 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -58.30
INFO:tensorflow:Starting iteration 18

Steps executed: 395 Episode length: 253 Return: -54.64749714225773497
INFO:tensorflow:Average training steps per second: 295.82
I0902 00:18:01.615600 140149719906304 replay_runner.py:36] Average training steps per second: 295.82
I0902 00:18:01.925308 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.00
INFO:tensorflow:Starting iteration 19

Steps executed: 288 Episode length: 137 Return: -181.2496650313716697
INFO:tensorflow:Average training steps per second: 299.07
I0902 00:18:08.834678 140149719906304 replay_runner.py:36] Average training steps per second: 299.07
I0902 00:18:09.026728 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -157.94
INFO:tensorflow:Starting iteration 20

Steps executed: 283 Episode length: 283 Return: -576.5989159475197697
INFO:tensorflow:Average training steps per second: 308.64
I0902 00:18:15.826052 140149719906304 replay_runner.py:36] Average training steps per second: 308.64
I0902 00:18:16.129770 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -576.60
INFO:tensorflow:Starting iteration 21

Steps executed: 321 Episode length: 144 Return: -219.3680417495199697
INFO:tensorflow:Average training steps per second: 317.85
I0902 00:18:22.768630 140149719906304 replay_runner.py:36] Average training steps per second: 317.85
I0902 00:18:22.961510 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -638.42
INFO:tensorflow:Starting iteration 22

Steps executed: 132 Episode length: 132 Return: -128.9295798874245597
INFO:tensorflow:Average training steps per second: 320.20
I0902 00:18:29.437052 140149719906304 replay_runner.py:36] Average training steps per second: 320.20

Steps executed: 341 Episode length: 209 Return: -164.0510423427467597
INFO:tensorflow:Starting iteration 23

Steps executed: 294 Episode length: 179 Return: -709.9509709666373597
INFO:tensorflow:Average training steps per second: 310.31
I0902 00:18:36.211515 140149719906304 replay_runner.py:36] Average training steps per second: 310.31
I0902 00:18:36.410748 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -713.32
INFO:tensorflow:Starting iteration 24

Steps executed: 261 Episode length: 79 Return: -246.20465603133417497
INFO:tensorflow:Average training steps per second: 318.29
I0902 00:18:42.818866 140149719906304 replay_runner.py:36] Average training steps per second: 318.29
I0902 00:18:42.945184 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -181.02
INFO:tensorflow:Starting iteration 25

Steps executed: 215 Episode length: 127 Return: -171.9827457993163897
INFO:tensorflow:Average training steps per second: 307.51
I0902 00:18:49.300902 140149719906304 replay_runner.py:36] Average training steps per second: 307.51
I0902 00:18:49.406506 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.49
INFO:tensorflow:Starting iteration 26

Steps executed: 215 Episode length: 76 Return: -289.65583357569835897
INFO:tensorflow:Average training steps per second: 310.28
I0902 00:18:55.699521 140149719906304 replay_runner.py:36] Average training steps per second: 310.28
I0902 00:18:55.806769 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.89
INFO:tensorflow:Starting iteration 27

Steps executed: 259 Episode length: 139 Return: -161.8827538589942897
INFO:tensorflow:Average training steps per second: 316.05
I0902 00:19:02.052123 140149719906304 replay_runner.py:36] Average training steps per second: 316.05
I0902 00:19:02.199670 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.66
INFO:tensorflow:Starting iteration 28

Steps executed: 201 Episode length: 65 Return: -156.16925925960396397
INFO:tensorflow:Average training steps per second: 310.66
I0902 00:19:08.512290 140149719906304 replay_runner.py:36] Average training steps per second: 310.66
I0902 00:19:08.623105 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.76
INFO:tensorflow:Starting iteration 29

Steps executed: 296 Episode length: 123 Return: -334.1216625756685697
INFO:tensorflow:Average training steps per second: 320.71
I0902 00:19:14.851823 140149719906304 replay_runner.py:36] Average training steps per second: 320.71

Done fixed training!Episode length: 123 Return: -334.1216625756685697