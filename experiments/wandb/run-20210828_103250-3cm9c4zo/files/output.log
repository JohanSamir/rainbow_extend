Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0828 10:32:57.519155 139779140274176 run_experiment.py:549] Creating TrainRunner ...
I0828 10:32:57.529850 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:57.530121 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:57.530290 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:57.530377 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:57.530473 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:57.530612 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:57.530744 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:57.530866 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:57.530940 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:57.531043 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:57.531132 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:57.531229 139779140274176 dqn_agent.py:283] 	 seed: 1630146777529794
I0828 10:32:57.533420 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:57.533629 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:57.533805 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:57.533952 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:57.534142 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:57.534275 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:57.534608 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:57.534807 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:57.534950 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:57.571871 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:57.939533 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:57.954948 139779140274176 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:32:57.963098 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:57.963337 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:57.963440 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:57.963526 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:57.963659 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:57.963839 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:57.963959 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:57.964087 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:57.964293 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:57.964410 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:57.964505 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:57.964627 139779140274176 dqn_agent.py:283] 	 seed: 1630146777963034
I0828 10:32:57.967556 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:57.967701 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:57.967793 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:57.967863 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:57.967930 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:57.967986 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:57.968073 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:57.968132 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:57.968195 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:57.998795 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:58.058379 139779140274176 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:32:58.058663 139779140274176 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 166.06
I0828 10:33:04.081232 139779140274176 replay_runner.py:36] Average training steps per second: 166.06
Steps executed: 206 Episode length: 64 Return: -567.2312884626473
I0828 10:33:05.287328 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -645.95
INFO:tensorflow:Starting iteration 1

Steps executed: 294 Episode length: 101 Return: -705.5368371154228
INFO:tensorflow:Average training steps per second: 219.36
I0828 10:33:14.236051 139779140274176 replay_runner.py:36] Average training steps per second: 219.36
I0828 10:33:14.495718 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -676.01
INFO:tensorflow:Starting iteration 2
I0828 10:33:18.603008 139779140274176 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 219.64

Steps executed: 249 Episode length: 171 Return: -999.6439757431571
I0828 10:33:23.395965 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -771.98
INFO:tensorflow:Starting iteration 3

Steps executed: 212 Episode length: 63 Return: -574.03611016827721
INFO:tensorflow:Average training steps per second: 227.12
I0828 10:33:31.984428 139779140274176 replay_runner.py:36] Average training steps per second: 227.12
I0828 10:33:32.160568 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -640.74
INFO:tensorflow:Starting iteration 4

Steps executed: 202 Episode length: 56 Return: -489.23834823222711
INFO:tensorflow:Average training steps per second: 228.71
I0828 10:33:40.817503 139779140274176 replay_runner.py:36] Average training steps per second: 228.71
I0828 10:33:40.979460 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -640.70
INFO:tensorflow:Starting iteration 5

Steps executed: 203 Episode length: 82 Return: -786.40148989152983
INFO:tensorflow:Average training steps per second: 223.65
I0828 10:33:49.776762 139779140274176 replay_runner.py:36] Average training steps per second: 223.65
I0828 10:33:49.943903 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.52
INFO:tensorflow:Starting iteration 6

Steps executed: 241 Episode length: 58 Return: -461.01792556913723
INFO:tensorflow:Average training steps per second: 222.44
I0828 10:33:58.719280 139779140274176 replay_runner.py:36] Average training steps per second: 222.44
I0828 10:33:58.909140 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -473.98
INFO:tensorflow:Starting iteration 7
I0828 10:34:03.143456 139779140274176 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 238.31

Steps executed: 205 Episode length: 84 Return: -642.78802153581563
I0828 10:34:07.513110 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -767.54
INFO:tensorflow:Starting iteration 8

Steps executed: 232 Episode length: 59 Return: -464.24960949426983
INFO:tensorflow:Average training steps per second: 221.53
I0828 10:34:16.337018 139779140274176 replay_runner.py:36] Average training steps per second: 221.53
I0828 10:34:16.517331 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -444.86
INFO:tensorflow:Starting iteration 9

Steps executed: 233 Episode length: 77 Return: -756.31199566825893
INFO:tensorflow:Average training steps per second: 220.89
I0828 10:34:25.278896 139779140274176 replay_runner.py:36] Average training steps per second: 220.89
I0828 10:34:25.472994 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -707.01
INFO:tensorflow:Starting iteration 10

Steps executed: 251 Episode length: 53 Return: -462.28037197080937
INFO:tensorflow:Average training steps per second: 213.31
I0828 10:34:34.527472 139779140274176 replay_runner.py:36] Average training steps per second: 213.31
I0828 10:34:34.735126 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -539.06
INFO:tensorflow:Starting iteration 11
I0828 10:34:39.048399 139779140274176 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 219.66

Steps executed: 245 Episode length: 51 Return: -438.35831993205247
I0828 10:34:43.811042 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -538.83
INFO:tensorflow:Starting iteration 12

Steps executed: 261 Episode length: 170 Return: -1154.5716357119948
INFO:tensorflow:Average training steps per second: 221.15
I0828 10:34:52.690821 139779140274176 replay_runner.py:36] Average training steps per second: 221.15
I0828 10:34:52.959790 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -949.40
INFO:tensorflow:Starting iteration 13

Steps executed: 262 Episode length: 90 Return: -487.861432426684248
INFO:tensorflow:Average training steps per second: 217.03
I0828 10:35:01.932754 139779140274176 replay_runner.py:36] Average training steps per second: 217.03
I0828 10:35:02.172902 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -526.40
INFO:tensorflow:Starting iteration 14

Steps executed: 231 Episode length: 80 Return: -637.708755006404848
INFO:tensorflow:Average training steps per second: 215.39
I0828 10:35:11.190310 139779140274176 replay_runner.py:36] Average training steps per second: 215.39
I0828 10:35:11.404522 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -620.15
INFO:tensorflow:Starting iteration 15

Steps executed: 280 Episode length: 90 Return: -628.525709413540918
INFO:tensorflow:Average training steps per second: 218.56
I0828 10:35:20.309093 139779140274176 replay_runner.py:36] Average training steps per second: 218.56
I0828 10:35:20.569272 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -626.89
INFO:tensorflow:Starting iteration 16
I0828 10:35:24.846204 139779140274176 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 215.54
I0828 10:35:29.486438 139779140274176 replay_runner.py:36] Average training steps per second: 215.54

Steps executed: 237 Episode length: 76 Return: -574.566033859582418
INFO:tensorflow:Starting iteration 17

Steps executed: 230 Episode length: 86 Return: -545.216943779461418
INFO:tensorflow:Average training steps per second: 213.09
I0828 10:35:38.689791 139779140274176 replay_runner.py:36] Average training steps per second: 213.09
I0828 10:35:38.921769 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -614.25
INFO:tensorflow:Starting iteration 18
I0828 10:35:43.290304 139779140274176 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 222.08

Steps executed: 254 Episode length: 92 Return: -493.901039116937742
I0828 10:35:48.041756 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -850.17
INFO:tensorflow:Starting iteration 19

Steps executed: 245 Episode length: 123 Return: -582.31501243132112
INFO:tensorflow:Average training steps per second: 222.28
I0828 10:35:56.970514 139779140274176 replay_runner.py:36] Average training steps per second: 222.28
I0828 10:35:57.193853 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -641.19
INFO:tensorflow:Starting iteration 20
I0828 10:36:01.499905 139779140274176 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 223.12

Steps executed: 207 Episode length: 61 Return: -356.452613861116912
I0828 10:36:06.151919 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -581.53
INFO:tensorflow:Starting iteration 21

Steps executed: 211 Episode length: 102 Return: -698.84877684680342
INFO:tensorflow:Average training steps per second: 222.35
I0828 10:36:14.915712 139779140274176 replay_runner.py:36] Average training steps per second: 222.35
I0828 10:36:15.109823 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -610.19
INFO:tensorflow:Starting iteration 22
I0828 10:36:19.396956 139779140274176 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 221.60

Steps executed: 305 Episode length: 305 Return: -2522.1655416643012
I0828 10:36:24.334735 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -2522.17
INFO:tensorflow:Starting iteration 23

Steps executed: 281 Episode length: 91 Return: -515.879840747111812
INFO:tensorflow:Average training steps per second: 231.51
I0828 10:36:32.851393 139779140274176 replay_runner.py:36] Average training steps per second: 231.51
I0828 10:36:33.143959 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -823.47
INFO:tensorflow:Starting iteration 24
I0828 10:36:37.456525 139779140274176 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 223.86
I0828 10:36:41.924611 139779140274176 replay_runner.py:36] Average training steps per second: 223.86

Steps executed: 226 Episode length: 76 Return: -547.544359928772112
INFO:tensorflow:Starting iteration 25

Steps executed: 229 Episode length: 155 Return: -756.99476758681672
INFO:tensorflow:Average training steps per second: 226.44
I0828 10:36:50.906280 139779140274176 replay_runner.py:36] Average training steps per second: 226.44
I0828 10:36:51.133718 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -657.23
INFO:tensorflow:Starting iteration 26
I0828 10:36:55.460449 139779140274176 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 226.12

Steps executed: 393 Episode length: 205 Return: -1291.9656272243649
I0828 10:37:00.301802 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -1478.50
INFO:tensorflow:Starting iteration 27

Steps executed: 297 Episode length: 139 Return: -730.35553340441949
INFO:tensorflow:Average training steps per second: 225.04
I0828 10:37:08.987063 139779140274176 replay_runner.py:36] Average training steps per second: 225.04
I0828 10:37:09.252776 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -554.87
INFO:tensorflow:Starting iteration 28

Steps executed: 255 Episode length: 99 Return: -651.819898875245449
INFO:tensorflow:Average training steps per second: 238.16
I0828 10:37:17.619168 139779140274176 replay_runner.py:36] Average training steps per second: 238.16
I0828 10:37:17.871114 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -536.32
INFO:tensorflow:Starting iteration 29

Steps executed: 201 Episode length: 115 Return: -581.31559282067549
INFO:tensorflow:Average training steps per second: 232.37
I0828 10:37:26.499220 139779140274176 replay_runner.py:36] Average training steps per second: 232.37

Done fixed training!Episode length: 115 Return: -581.31559282067549