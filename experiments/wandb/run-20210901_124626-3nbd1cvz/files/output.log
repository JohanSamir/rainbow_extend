Loaded trained dqn in cartpole
Training fixed agent 7, please be patient, may be a while...
I0901 12:46:33.452460 140540456830976 run_experiment.py:549] Creating TrainRunner ...
I0901 12:46:33.462750 140540456830976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:46:33.463013 140540456830976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:46:33.463151 140540456830976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:46:33.463255 140540456830976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:46:33.463348 140540456830976 dqn_agent.py:275] 	 update_period: 4
I0901 12:46:33.463463 140540456830976 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:46:33.463556 140540456830976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:46:33.463649 140540456830976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:46:33.463738 140540456830976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:46:33.463834 140540456830976 dqn_agent.py:280] 	 optimizer: adam
I0901 12:46:33.463933 140540456830976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:46:33.464028 140540456830976 dqn_agent.py:283] 	 seed: 1630500393462679
I0901 12:46:33.467129 140540456830976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:46:33.467579 140540456830976 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:46:33.467753 140540456830976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:46:33.467873 140540456830976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:46:33.467980 140540456830976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:46:33.468079 140540456830976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:46:33.468181 140540456830976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:46:33.468280 140540456830976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:46:33.468377 140540456830976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:46:33.622671 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:46:34.192743 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:46:34.207077 140540456830976 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:46:34.216082 140540456830976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:46:34.216357 140540456830976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:46:34.216474 140540456830976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:46:34.216575 140540456830976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:46:34.216671 140540456830976 dqn_agent.py:275] 	 update_period: 4
I0901 12:46:34.216793 140540456830976 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:46:34.216935 140540456830976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:46:34.217027 140540456830976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:46:34.217125 140540456830976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:46:34.217214 140540456830976 dqn_agent.py:280] 	 optimizer: adam
I0901 12:46:34.217334 140540456830976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:46:34.217435 140540456830976 dqn_agent.py:283] 	 seed: 1630500394216016
I0901 12:46:34.220303 140540456830976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:46:34.220522 140540456830976 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:46:34.220663 140540456830976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:46:34.220787 140540456830976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:46:34.220907 140540456830976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:46:34.221020 140540456830976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:46:34.221126 140540456830976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:46:34.221248 140540456830976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:46:34.221368 140540456830976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:46:34.256676 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:46:34.279470 140540456830976 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:46:34.279689 140540456830976 replay_runner.py:41] Starting iteration 0
Steps executed: 206 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 142.21
I0901 12:46:41.311933 140540456830976 replay_runner.py:36] Average training steps per second: 142.21
I0901 12:46:42.549924 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.36
INFO:tensorflow:Starting iteration 1

Steps executed: 205 Episode length: 12 Return: 12.0
INFO:tensorflow:Average training steps per second: 197.33
I0901 12:46:47.789807 140540456830976 replay_runner.py:36] Average training steps per second: 197.33
I0901 12:46:47.933359 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 12.81
INFO:tensorflow:Starting iteration 2

Steps executed: 248 Episode length: 76 Return: 76.0
INFO:tensorflow:Average training steps per second: 185.43
I0901 12:46:53.519182 140540456830976 replay_runner.py:36] Average training steps per second: 185.43
I0901 12:46:53.694452 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 82.67
INFO:tensorflow:Starting iteration 3

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 196.55
I0901 12:46:58.973158 140540456830976 replay_runner.py:36] Average training steps per second: 196.55
I0901 12:46:59.110797 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 4

Steps executed: 222 Episode length: 38 Return: 38.0.0
INFO:tensorflow:Average training steps per second: 191.20
I0901 12:47:04.522065 140540456830976 replay_runner.py:36] Average training steps per second: 191.20
I0901 12:47:04.672705 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 37.00
INFO:tensorflow:Starting iteration 5

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 192.92
I0901 12:47:10.044115 140540456830976 replay_runner.py:36] Average training steps per second: 192.92
I0901 12:47:10.183554 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 6

Steps executed: 286 Episode length: 100 Return: 100.0
INFO:tensorflow:Average training steps per second: 198.56
I0901 12:47:15.408704 140540456830976 replay_runner.py:36] Average training steps per second: 198.56
I0901 12:47:15.605876 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 95.33
INFO:tensorflow:Starting iteration 7

Steps executed: 266 Episode length: 131 Return: 131.0
INFO:tensorflow:Average training steps per second: 192.21
I0901 12:47:21.001183 140540456830976 replay_runner.py:36] Average training steps per second: 192.21
I0901 12:47:21.178348 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 133.00
INFO:tensorflow:Starting iteration 8

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 200.18
I0901 12:47:26.366156 140540456830976 replay_runner.py:36] Average training steps per second: 200.18
I0901 12:47:26.508907 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 9

Steps executed: 240 Episode length: 117 Return: 117.0
INFO:tensorflow:Average training steps per second: 196.97
I0901 12:47:31.778348 140540456830976 replay_runner.py:36] Average training steps per second: 196.97
I0901 12:47:31.935668 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 120.00
INFO:tensorflow:Starting iteration 10

Steps executed: 381 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 198.16
I0901 12:47:37.173787 140540456830976 replay_runner.py:36] Average training steps per second: 198.16
I0901 12:47:37.415343 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 190.50
INFO:tensorflow:Starting iteration 11

Steps executed: 360 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 197.91
I0901 12:47:42.655879 140540456830976 replay_runner.py:36] Average training steps per second: 197.91
I0901 12:47:42.896104 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 180.00
INFO:tensorflow:Starting iteration 12

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 193.94
I0901 12:47:48.229921 140540456830976 replay_runner.py:36] Average training steps per second: 193.94
I0901 12:47:48.366926 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 13

Steps executed: 154 Episode length: 154 Return: 154.0
INFO:tensorflow:Average training steps per second: 200.17
I0901 12:47:53.552210 140540456830976 replay_runner.py:36] Average training steps per second: 200.17

Steps executed: 297 Episode length: 143 Return: 143.0
INFO:tensorflow:Starting iteration 14

Steps executed: 250 Episode length: 128 Return: 128.0
INFO:tensorflow:Average training steps per second: 193.77
I0901 12:47:59.092045 140540456830976 replay_runner.py:36] Average training steps per second: 193.77
I0901 12:47:59.284314 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 125.00
INFO:tensorflow:Starting iteration 15

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 198.06
I0901 12:48:04.526483 140540456830976 replay_runner.py:36] Average training steps per second: 198.06
I0901 12:48:04.667687 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 16

Steps executed: 311 Episode length: 161 Return: 161.0
INFO:tensorflow:Average training steps per second: 192.92
I0901 12:48:10.038623 140540456830976 replay_runner.py:36] Average training steps per second: 192.92
I0901 12:48:10.255226 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 155.50
INFO:tensorflow:Starting iteration 17

Steps executed: 312 Episode length: 167 Return: 167.0
INFO:tensorflow:Average training steps per second: 191.89
I0901 12:48:15.654355 140540456830976 replay_runner.py:36] Average training steps per second: 191.89
I0901 12:48:15.873786 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 156.00
INFO:tensorflow:Starting iteration 18
I0901 12:48:16.064497 140540456830976 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 188.47

Steps executed: 353 Episode length: 186 Return: 186.0
I0901 12:48:21.618446 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 176.50
INFO:tensorflow:Starting iteration 19

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 190.60
I0901 12:48:27.058540 140540456830976 replay_runner.py:36] Average training steps per second: 190.60
I0901 12:48:27.209828 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 20

Steps executed: 359 Episode length: 181 Return: 181.0
INFO:tensorflow:Average training steps per second: 194.50
I0901 12:48:32.539464 140540456830976 replay_runner.py:36] Average training steps per second: 194.50
I0901 12:48:32.788797 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 179.50
INFO:tensorflow:Starting iteration 21

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 192.31
I0901 12:48:38.181281 140540456830976 replay_runner.py:36] Average training steps per second: 192.31
I0901 12:48:38.324094 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 22
I0901 12:48:38.513098 140540456830976 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 198.16
I0901 12:48:43.559816 140540456830976 replay_runner.py:36] Average training steps per second: 198.16

Steps executed: 345 Episode length: 173 Return: 173.0
INFO:tensorflow:Starting iteration 23

Steps executed: 331 Episode length: 171 Return: 171.0
INFO:tensorflow:Average training steps per second: 195.38
I0901 12:48:49.145165 140540456830976 replay_runner.py:36] Average training steps per second: 195.38
I0901 12:48:49.369470 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 165.50
INFO:tensorflow:Starting iteration 24

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 197.95
I0901 12:48:54.612410 140540456830976 replay_runner.py:36] Average training steps per second: 197.95
I0901 12:48:54.754168 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 25
I0901 12:48:54.941953 140540456830976 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 193.33
I0901 12:49:00.115077 140540456830976 replay_runner.py:36] Average training steps per second: 193.33
I0901 12:49:00.254481 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26

Steps executed: 247 Episode length: 121 Return: 121.0
INFO:tensorflow:Average training steps per second: 194.34
I0901 12:49:05.593841 140540456830976 replay_runner.py:36] Average training steps per second: 194.34
I0901 12:49:05.776299 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 123.50
INFO:tensorflow:Starting iteration 27

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 196.18
I0901 12:49:11.066151 140540456830976 replay_runner.py:36] Average training steps per second: 196.18
I0901 12:49:11.208611 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 28
I0901 12:49:11.389783 140540456830976 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 195.28
I0901 12:49:16.511023 140540456830976 replay_runner.py:36] Average training steps per second: 195.28
I0901 12:49:16.642806 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 29

Steps executed: 300 Episode length: 145 Return: 145.0
INFO:tensorflow:Average training steps per second: 202.27
I0901 12:49:21.763120 140540456830976 replay_runner.py:36] Average training steps per second: 202.27

Done fixed training!Episode length: 145 Return: 145.0