I0903 00:01:13.812279 140099460519936 run_experiment.py:549] Creating TrainRunner ...
I0903 00:01:13.820846 140099460519936 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:01:13.821014 140099460519936 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:01:13.821104 140099460519936 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:01:13.821172 140099460519936 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:01:13.821234 140099460519936 dqn_agent.py:275] 	 update_period: 4
I0903 00:01:13.821336 140099460519936 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:01:13.821441 140099460519936 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:01:13.821504 140099460519936 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:01:13.821585 140099460519936 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:01:13.821675 140099460519936 dqn_agent.py:280] 	 optimizer: adam
I0903 00:01:13.821763 140099460519936 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:01:13.821850 140099460519936 dqn_agent.py:283] 	 seed: 1630627273820802
I0903 00:01:13.823953 140099460519936 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:01:13.824075 140099460519936 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:01:13.824153 140099460519936 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:01:13.824216 140099460519936 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:01:13.824275 140099460519936 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:01:13.824365 140099460519936 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:01:13.824428 140099460519936 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:01:13.824520 140099460519936 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:01:13.824603 140099460519936 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:01:13.853659 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:01:14.132036 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:01:14.143552 140099460519936 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:01:14.152554 140099460519936 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:01:14.152746 140099460519936 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:01:14.152841 140099460519936 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:01:14.152905 140099460519936 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:01:14.152960 140099460519936 dqn_agent.py:275] 	 update_period: 4
I0903 00:01:14.153162 140099460519936 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:01:14.153234 140099460519936 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:01:14.153321 140099460519936 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:01:14.153397 140099460519936 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:01:14.153481 140099460519936 dqn_agent.py:280] 	 optimizer: adam
I0903 00:01:14.153532 140099460519936 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:01:14.153605 140099460519936 dqn_agent.py:283] 	 seed: 1630627274152509
I0903 00:01:14.155277 140099460519936 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:01:14.155408 140099460519936 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:01:14.155483 140099460519936 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:01:14.155550 140099460519936 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:01:14.155614 140099460519936 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:01:14.155687 140099460519936 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:01:14.155784 140099460519936 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:01:14.155856 140099460519936 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:01:14.155927 140099460519936 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:01:14.182223 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:01:14.198411 140099460519936 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:01:14.198718 140099460519936 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 242.52
I0903 00:01:18.322390 140099460519936 replay_runner.py:36] Average training steps per second: 242.52
I0903 00:01:19.148145 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -366.66
Steps executed: 278 Episode length: 174 Return: -222.2688379306578
INFO:tensorflow:Starting iteration 1
I0903 00:01:22.423834 140099460519936 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 323.21

Steps executed: 246 Episode length: 100 Return: -458.68416073870196
I0903 00:01:25.645176 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -432.99
INFO:tensorflow:Starting iteration 2

Steps executed: 267 Episode length: 107 Return: -352.35147609255354
INFO:tensorflow:Average training steps per second: 334.74
I0903 00:01:32.010316 140099460519936 replay_runner.py:36] Average training steps per second: 334.74
I0903 00:01:32.180579 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -249.48
INFO:tensorflow:Starting iteration 3

Steps executed: 227 Episode length: 227 Return: -226.01250857931414
INFO:tensorflow:Average training steps per second: 327.10
I0903 00:01:38.539920 140099460519936 replay_runner.py:36] Average training steps per second: 327.10
I0903 00:01:38.705749 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.01
INFO:tensorflow:Starting iteration 4
I0903 00:01:42.008618 140099460519936 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 325.38

Steps executed: 1000 Episode length: 1000 Return: -129.88593052884312
I0903 00:01:46.961692 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.89
INFO:tensorflow:Starting iteration 5
I0903 00:01:50.301881 140099460519936 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 313.29

Steps executed: 1000 Episode length: 1000 Return: -95.452257828628792
I0903 00:01:55.113841 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.45
INFO:tensorflow:Starting iteration 6
I0903 00:01:58.525702 140099460519936 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 324.03

Steps executed: 741 Episode length: 741 Return: -288.4063937089792492
I0903 00:02:02.536649 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.41
INFO:tensorflow:Starting iteration 7
I0903 00:02:05.949133 140099460519936 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 336.67

Steps executed: 1000 Episode length: 1000 Return: -167.51103752880698
I0903 00:02:11.018552 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.51
INFO:tensorflow:Starting iteration 8
I0903 00:02:14.465769 140099460519936 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 336.82

Steps executed: 1000 Episode length: 1000 Return: -68.873715832856258
I0903 00:02:19.080955 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.87
INFO:tensorflow:Starting iteration 9
I0903 00:02:22.422301 140099460519936 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 335.22

Steps executed: 1000 Episode length: 1000 Return: -97.976714517734328
I0903 00:02:26.671376 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.98
INFO:tensorflow:Starting iteration 10
I0903 00:02:30.061771 140099460519936 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 338.69

Steps executed: 1000 Episode length: 1000 Return: -98.222743143373888
I0903 00:02:34.987432 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.22
INFO:tensorflow:Starting iteration 11
I0903 00:02:38.359168 140099460519936 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 329.12

Steps executed: 1000 Episode length: 1000 Return: -78.967859702278528
I0903 00:02:43.041087 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.97
INFO:tensorflow:Starting iteration 12
I0903 00:02:46.410731 140099460519936 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 324.72
I0903 00:02:49.490605 140099460519936 replay_runner.py:36] Average training steps per second: 324.72

Steps executed: 1000 Episode length: 1000 Return: -81.621101159503728
INFO:tensorflow:Starting iteration 13

Steps executed: 592 Episode length: 592 Return: -329.7047458462765728
INFO:tensorflow:Average training steps per second: 346.24
I0903 00:02:58.323120 140099460519936 replay_runner.py:36] Average training steps per second: 346.24
I0903 00:02:59.356063 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.70
INFO:tensorflow:Starting iteration 14
I0903 00:03:02.752616 140099460519936 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 331.86
I0903 00:03:05.766179 140099460519936 replay_runner.py:36] Average training steps per second: 331.86

Steps executed: 331 Episode length: 331 Return: -61.32774369721815728
INFO:tensorflow:Starting iteration 15

Steps executed: 543 Episode length: 543 Return: -20.40273888409747428
INFO:tensorflow:Average training steps per second: 318.35
I0903 00:03:12.554469 140099460519936 replay_runner.py:36] Average training steps per second: 318.35
I0903 00:03:13.402655 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -20.40
INFO:tensorflow:Starting iteration 16
I0903 00:03:16.582315 140099460519936 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 317.37

Steps executed: 420 Episode length: 420 Return: -341.0439060585822528
I0903 00:03:20.157900 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.04
INFO:tensorflow:Starting iteration 17

Steps executed: 447 Episode length: 447 Return: -60.69646516773925528
INFO:tensorflow:Average training steps per second: 322.73
I0903 00:03:26.524864 140099460519936 replay_runner.py:36] Average training steps per second: 322.73
I0903 00:03:27.056560 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -60.70
INFO:tensorflow:Starting iteration 18

Steps executed: 182 Episode length: 182 Return: -110.4261985013509528
INFO:tensorflow:Average training steps per second: 314.37

Steps executed: 840 Episode length: 658 Return: 193.42074576392037528
I0903 00:03:34.926897 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: 41.50
INFO:tensorflow:Starting iteration 19

Steps executed: 440 Episode length: 285 Return: -20.14673632440413428
INFO:tensorflow:Average training steps per second: 326.19
I0903 00:03:41.259985 140099460519936 replay_runner.py:36] Average training steps per second: 326.19
I0903 00:03:41.596975 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.60
INFO:tensorflow:Starting iteration 20

Steps executed: 537 Episode length: 379 Return: -118.3707802324025428
INFO:tensorflow:Average training steps per second: 335.88
I0903 00:03:48.051133 140099460519936 replay_runner.py:36] Average training steps per second: 335.88
I0903 00:03:48.550730 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.30
INFO:tensorflow:Starting iteration 21
I0903 00:03:52.028953 140099460519936 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 322.77

Steps executed: 559 Episode length: 559 Return: -74.12807808517468428
I0903 00:03:55.949823 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.13
INFO:tensorflow:Starting iteration 22

Steps executed: 645 Episode length: 645 Return: -290.3340485031577628
INFO:tensorflow:Average training steps per second: 304.02
I0903 00:04:02.606327 140099460519936 replay_runner.py:36] Average training steps per second: 304.02
I0903 00:04:03.532817 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.33
INFO:tensorflow:Starting iteration 23
I0903 00:04:06.932223 140099460519936 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 342.99

Steps executed: 1000 Episode length: 1000 Return: -34.108424236102748
I0903 00:04:11.643788 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -34.11
INFO:tensorflow:Starting iteration 24
I0903 00:04:15.181175 140099460519936 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 354.51

Steps executed: 706 Episode length: 706 Return: -682.9946243196862748
I0903 00:04:19.115822 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -682.99
INFO:tensorflow:Starting iteration 25

Steps executed: 259 Episode length: 259 Return: -17.93384233384735248
INFO:tensorflow:Average training steps per second: 387.81
I0903 00:04:25.066803 140099460519936 replay_runner.py:36] Average training steps per second: 387.81
I0903 00:04:25.252150 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -17.93
INFO:tensorflow:Starting iteration 26

Steps executed: 266 Episode length: 266 Return: 26.283049936441913248
INFO:tensorflow:Average training steps per second: 361.58
I0903 00:04:31.332370 140099460519936 replay_runner.py:36] Average training steps per second: 361.58
I0903 00:04:31.526912 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: 26.28
INFO:tensorflow:Starting iteration 27
I0903 00:04:35.012919 140099460519936 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 364.07

Steps executed: 1000 Episode length: 1000 Return: -5.2091065092110318
I0903 00:04:40.495296 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -5.21
INFO:tensorflow:Starting iteration 28
I0903 00:04:43.822692 140099460519936 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 354.62

Steps executed: 1000 Episode length: 1000 Return: 143.321293563493648
I0903 00:04:48.565468 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: 143.32
INFO:tensorflow:Starting iteration 29
I0903 00:04:51.933728 140099460519936 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 335.11

Steps executed: 1000 Episode length: 1000 Return: 23.1271531600999948

Done fixed training! Episode length: 1000 Return: 23.1271531600999948