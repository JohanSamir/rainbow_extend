Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0828 10:47:04.442495 139825303013376 run_experiment.py:549] Creating TrainRunner ...
I0828 10:47:04.450725 139825303013376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:47:04.450864 139825303013376 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:47:04.450945 139825303013376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:47:04.451008 139825303013376 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:47:04.451067 139825303013376 dqn_agent.py:275] 	 update_period: 4
I0828 10:47:04.451120 139825303013376 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:47:04.451220 139825303013376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:47:04.451275 139825303013376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:47:04.451327 139825303013376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:47:04.451377 139825303013376 dqn_agent.py:280] 	 optimizer: adam
I0828 10:47:04.451437 139825303013376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:47:04.451549 139825303013376 dqn_agent.py:283] 	 seed: 1630147624450689
I0828 10:47:04.453317 139825303013376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:47:04.453431 139825303013376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:47:04.453508 139825303013376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:47:04.453573 139825303013376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:47:04.453631 139825303013376 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:47:04.453685 139825303013376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:47:04.453739 139825303013376 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:47:04.453790 139825303013376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:47:04.453841 139825303013376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:47:04.479003 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:04.732398 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:04.741316 139825303013376 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:47:04.747897 139825303013376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:47:04.748058 139825303013376 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:47:04.748143 139825303013376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:47:04.748204 139825303013376 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:47:04.748272 139825303013376 dqn_agent.py:275] 	 update_period: 4
I0828 10:47:04.748328 139825303013376 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:47:04.748407 139825303013376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:47:04.748501 139825303013376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:47:04.748568 139825303013376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:47:04.748640 139825303013376 dqn_agent.py:280] 	 optimizer: adam
I0828 10:47:04.748688 139825303013376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:47:04.748742 139825303013376 dqn_agent.py:283] 	 seed: 1630147624747863
I0828 10:47:04.750268 139825303013376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:47:04.750386 139825303013376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:47:04.750471 139825303013376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:47:04.750644 139825303013376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:47:04.750751 139825303013376 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:47:04.750834 139825303013376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:47:04.750899 139825303013376 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:47:04.750989 139825303013376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:47:04.751063 139825303013376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:47:04.771623 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:04.785541 139825303013376 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:47:04.785735 139825303013376 replay_runner.py:41] Starting iteration 0
Steps executed: 309 Episode length: 205 Return: -442.46452482089927
INFO:tensorflow:Average training steps per second: 258.20
I0828 10:47:08.658962 139825303013376 replay_runner.py:36] Average training steps per second: 258.20
I0828 10:47:09.769891 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.37
INFO:tensorflow:Starting iteration 1
I0828 10:47:13.171577 139825303013376 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 341.36

Steps executed: 267 Episode length: 167 Return: -527.25141311176513
I0828 10:47:16.259561 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -446.67
INFO:tensorflow:Starting iteration 2

Steps executed: 484 Episode length: 362 Return: -425.69891368914256
INFO:tensorflow:Average training steps per second: 340.24
I0828 10:47:22.639320 139825303013376 replay_runner.py:36] Average training steps per second: 340.24
I0828 10:47:23.051985 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -358.66
INFO:tensorflow:Starting iteration 3
I0828 10:47:26.464765 139825303013376 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 348.26

Steps executed: 1000 Episode length: 1000 Return: -122.1392152285119
I0828 10:47:31.178684 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.14
INFO:tensorflow:Starting iteration 4
I0828 10:47:34.578417 139825303013376 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 347.10

Steps executed: 1000 Episode length: 1000 Return: -113.98649411675878
I0828 10:47:40.068810 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.99
INFO:tensorflow:Starting iteration 5

Steps executed: 504 Episode length: 504 Return: -209.5526253223572478
INFO:tensorflow:Average training steps per second: 340.63
I0828 10:47:46.411672 139825303013376 replay_runner.py:36] Average training steps per second: 340.63
I0828 10:47:47.037686 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.55
INFO:tensorflow:Starting iteration 6
I0828 10:47:50.334389 139825303013376 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 341.31

Steps executed: 1000 Episode length: 1000 Return: -161.30567105379478
I0828 10:47:54.604632 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.31
INFO:tensorflow:Starting iteration 7

Steps executed: 396 Episode length: 396 Return: -213.6826591496207578
INFO:tensorflow:Average training steps per second: 319.64
I0828 10:48:01.018075 139825303013376 replay_runner.py:36] Average training steps per second: 319.64
I0828 10:48:01.483135 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.68
INFO:tensorflow:Starting iteration 8
I0828 10:48:04.709257 139825303013376 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 332.61

Steps executed: 1000 Episode length: 1000 Return: -290.44508819783533
I0828 10:48:09.779759 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.45
INFO:tensorflow:Starting iteration 9

Steps executed: 283 Episode length: 283 Return: -152.9707351814491533
INFO:tensorflow:Average training steps per second: 327.37
I0828 10:48:16.004739 139825303013376 replay_runner.py:36] Average training steps per second: 327.37
I0828 10:48:16.254370 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.97
INFO:tensorflow:Starting iteration 10
I0828 10:48:19.504874 139825303013376 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 335.69

Steps executed: 610 Episode length: 442 Return: -184.4337586706574533
I0828 10:48:23.130762 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.56
INFO:tensorflow:Starting iteration 11

Steps executed: 159 Episode length: 159 Return: -62.74724419410981533
INFO:tensorflow:Average training steps per second: 341.83

Steps executed: 1159 Episode length: 1000 Return: -95.446876769696163
I0828 10:48:31.440483 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.10
INFO:tensorflow:Starting iteration 12
I0828 10:48:34.778723 139825303013376 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 343.29

Steps executed: 892 Episode length: 892 Return: -491.9344659897817163
I0828 10:48:39.263399 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -491.93
INFO:tensorflow:Starting iteration 13
I0828 10:48:42.639575 139825303013376 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 334.24

Steps executed: 1000 Episode length: 1000 Return: -23.006690455678108
I0828 10:48:47.517066 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -23.01
INFO:tensorflow:Starting iteration 14
I0828 10:48:50.900847 139825303013376 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 337.64

Steps executed: 1000 Episode length: 1000 Return: -62.158026593856476
I0828 10:48:55.710988 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -62.16
INFO:tensorflow:Starting iteration 15
I0828 10:48:58.864024 139825303013376 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 309.49

Steps executed: 1000 Episode length: 1000 Return: -38.381053151002196
I0828 10:49:03.924707 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -38.38
INFO:tensorflow:Starting iteration 16

Steps executed: 1000 Episode length: 1000 Return: -129.06279839891067
INFO:tensorflow:Average training steps per second: 310.93
I0828 10:49:10.411514 139825303013376 replay_runner.py:36] Average training steps per second: 310.93
I0828 10:49:12.003054 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.06
INFO:tensorflow:Starting iteration 17

Steps executed: 239 Episode length: 110 Return: -763.9895470918113067
INFO:tensorflow:Average training steps per second: 336.46
I0828 10:49:18.290883 139825303013376 replay_runner.py:36] Average training steps per second: 336.46
I0828 10:49:18.423142 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -694.10
INFO:tensorflow:Starting iteration 18

Steps executed: 353 Episode length: 204 Return: -140.8234703500039667
INFO:tensorflow:Average training steps per second: 320.10
I0828 10:49:24.703836 139825303013376 replay_runner.py:36] Average training steps per second: 320.10
I0828 10:49:24.925974 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.26
INFO:tensorflow:Starting iteration 19

Steps executed: 271 Episode length: 271 Return: -189.5323314762895667
INFO:tensorflow:Average training steps per second: 329.28
I0828 10:49:31.142869 139825303013376 replay_runner.py:36] Average training steps per second: 329.28
I0828 10:49:31.353430 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.53
INFO:tensorflow:Starting iteration 20
I0828 10:49:34.690987 139825303013376 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 318.64

Steps executed: 861 Episode length: 861 Return: 160.17771768282285667
I0828 10:49:39.005453 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: 160.18
INFO:tensorflow:Starting iteration 21

Steps executed: 376 Episode length: 376 Return: -293.1662477690645667
INFO:tensorflow:Average training steps per second: 336.04
I0828 10:49:45.386717 139825303013376 replay_runner.py:36] Average training steps per second: 336.04
I0828 10:49:45.763062 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.17
INFO:tensorflow:Starting iteration 22

Steps executed: 147 Episode length: 147 Return: -90.32863180497595667
INFO:tensorflow:Average training steps per second: 338.71
I0828 10:49:52.163894 139825303013376 replay_runner.py:36] Average training steps per second: 338.71

Steps executed: 420 Episode length: 273 Return: 176.15863835006041667
INFO:tensorflow:Starting iteration 23

Steps executed: 290 Episode length: 290 Return: -610.0307516509984667
INFO:tensorflow:Average training steps per second: 336.64
I0828 10:49:58.789808 139825303013376 replay_runner.py:36] Average training steps per second: 336.64
I0828 10:49:58.968618 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -610.03
INFO:tensorflow:Starting iteration 24
I0828 10:50:02.304584 139825303013376 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 331.68

Steps executed: 1000 Episode length: 1000 Return: -282.22668159282927
I0828 10:50:06.965552 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -282.23
INFO:tensorflow:Starting iteration 25

Steps executed: 206 Episode length: 206 Return: -275.9455977552878527
INFO:tensorflow:Average training steps per second: 366.26
I0828 10:50:13.240388 139825303013376 replay_runner.py:36] Average training steps per second: 366.26
I0828 10:50:13.368219 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -275.95
INFO:tensorflow:Starting iteration 26

Steps executed: 413 Episode length: 248 Return: -118.1740335668778527
INFO:tensorflow:Average training steps per second: 361.09
I0828 10:50:19.650431 139825303013376 replay_runner.py:36] Average training steps per second: 361.09
I0828 10:50:19.927759 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.65
INFO:tensorflow:Starting iteration 27

Steps executed: 456 Episode length: 456 Return: 229.90318910293186527
INFO:tensorflow:Average training steps per second: 359.57
I0828 10:50:26.148998 139825303013376 replay_runner.py:36] Average training steps per second: 359.57
I0828 10:50:26.580082 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: 229.90
INFO:tensorflow:Starting iteration 28
I0828 10:50:29.932905 139825303013376 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 354.87

Steps executed: 480 Episode length: 480 Return: -357.1230584588772727
I0828 10:50:33.285275 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -357.12
INFO:tensorflow:Starting iteration 29

Steps executed: 292 Episode length: 292 Return: -106.0637459134663627
INFO:tensorflow:Average training steps per second: 391.52
I0828 10:50:39.278636 139825303013376 replay_runner.py:36] Average training steps per second: 391.52

Done fixed training!Episode length: 292 Return: -106.0637459134663627