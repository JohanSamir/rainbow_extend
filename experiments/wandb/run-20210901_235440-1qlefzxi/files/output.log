Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0901 23:54:47.071746 140183943698432 run_experiment.py:549] Creating TrainRunner ...
I0901 23:54:47.091966 140183943698432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:54:47.092387 140183943698432 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:54:47.092669 140183943698432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:54:47.092900 140183943698432 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:54:47.093273 140183943698432 dqn_agent.py:275] 	 update_period: 4
I0901 23:54:47.093470 140183943698432 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:54:47.093636 140183943698432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:54:47.093809 140183943698432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:54:47.093915 140183943698432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:54:47.094166 140183943698432 dqn_agent.py:280] 	 optimizer: adam
I0901 23:54:47.094271 140183943698432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:54:47.094377 140183943698432 dqn_agent.py:283] 	 seed: 1630540487091903
I0901 23:54:47.101137 140183943698432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:54:47.101380 140183943698432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:54:47.101539 140183943698432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:54:47.101844 140183943698432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:54:47.102107 140183943698432 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:54:47.102380 140183943698432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:54:47.102647 140183943698432 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:54:47.102830 140183943698432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:54:47.102971 140183943698432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:54:47.138633 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:47.493927 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:47.509626 140183943698432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:54:47.520601 140183943698432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:54:47.520908 140183943698432 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:54:47.521051 140183943698432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:54:47.521134 140183943698432 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:54:47.521211 140183943698432 dqn_agent.py:275] 	 update_period: 4
I0901 23:54:47.521419 140183943698432 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:54:47.521583 140183943698432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:54:47.521753 140183943698432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:54:47.521891 140183943698432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:54:47.522058 140183943698432 dqn_agent.py:280] 	 optimizer: adam
I0901 23:54:47.522239 140183943698432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:54:47.522350 140183943698432 dqn_agent.py:283] 	 seed: 1630540487520556
I0901 23:54:47.525314 140183943698432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:54:47.525524 140183943698432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:54:47.525655 140183943698432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:54:47.525769 140183943698432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:54:47.525857 140183943698432 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:54:47.525935 140183943698432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:54:47.525993 140183943698432 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:54:47.526044 140183943698432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:54:47.526141 140183943698432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:54:47.578537 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:47.616798 140183943698432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:54:47.617114 140183943698432 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 166.22
I0901 23:54:53.633785 140183943698432 replay_runner.py:36] Average training steps per second: 166.22
Steps executed: 282 Episode length: 140 Return: -409.20090588532845
I0901 23:54:55.028514 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -349.40
INFO:tensorflow:Starting iteration 1

Steps executed: 267 Episode length: 126 Return: -187.70473293846828
INFO:tensorflow:Average training steps per second: 227.90
I0901 23:55:03.861346 140183943698432 replay_runner.py:36] Average training steps per second: 227.90
I0901 23:55:04.110560 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.76
INFO:tensorflow:Starting iteration 2
I0901 23:55:08.611306 140183943698432 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 222.36

Steps executed: 1000 Episode length: 1000 Return: -236.73249674619797
I0901 23:55:16.189488 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.73
INFO:tensorflow:Starting iteration 3

Steps executed: 338 Episode length: 338 Return: -475.6877389064118797
INFO:tensorflow:Average training steps per second: 219.82
I0901 23:55:25.068225 140183943698432 replay_runner.py:36] Average training steps per second: 219.82
I0901 23:55:25.525892 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -475.69
INFO:tensorflow:Starting iteration 4

Steps executed: 111 Episode length: 111 Return: 30.617460665410277797
INFO:tensorflow:Average training steps per second: 216.07

Steps executed: 680 Episode length: 569 Return: -281.5441023028204797
I0901 23:55:35.872255 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.46
INFO:tensorflow:Starting iteration 5
I0901 23:55:40.222007 140183943698432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 206.66

Steps executed: 1000 Episode length: 1000 Return: -71.431635362789957
I0901 23:55:47.333377 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.43
INFO:tensorflow:Starting iteration 6
I0901 23:55:51.542752 140183943698432 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 213.50

Steps executed: 1000 Episode length: 1000 Return: 26.2791182903255157
I0901 23:55:58.783610 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: 26.28
INFO:tensorflow:Starting iteration 7
I0901 23:56:03.047425 140183943698432 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 224.28

Steps executed: 914 Episode length: 914 Return: -349.6949856548715157
I0901 23:56:10.092736 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -349.69
INFO:tensorflow:Starting iteration 8

Steps executed: 326 Episode length: 151 Return: -419.0807376715768657
INFO:tensorflow:Average training steps per second: 225.06
I0901 23:56:18.766926 140183943698432 replay_runner.py:36] Average training steps per second: 225.06
I0901 23:56:19.100054 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.61
INFO:tensorflow:Starting iteration 9

Steps executed: 228 Episode length: 50 Return: -192.49973763299647657
INFO:tensorflow:Average training steps per second: 230.72
I0901 23:56:27.747167 140183943698432 replay_runner.py:36] Average training steps per second: 230.72
I0901 23:56:27.961106 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.61
INFO:tensorflow:Starting iteration 10
I0901 23:56:32.433862 140183943698432 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 241.54

Steps executed: 1000 Episode length: 1000 Return: -273.25888946222687
I0901 23:56:39.410417 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.26
INFO:tensorflow:Starting iteration 11

Steps executed: 254 Episode length: 254 Return: -31.38760325547443687
INFO:tensorflow:Average training steps per second: 240.89
I0901 23:56:47.741928 140183943698432 replay_runner.py:36] Average training steps per second: 240.89
I0901 23:56:48.046632 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -31.39
INFO:tensorflow:Starting iteration 12
I0901 23:56:52.285876 140183943698432 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 239.97

Steps executed: 1000 Episode length: 1000 Return: -282.11405151615287
I0901 23:56:59.379351 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -282.11
INFO:tensorflow:Starting iteration 13

Steps executed: 212 Episode length: 212 Return: -40.69209775092271287
INFO:tensorflow:Average training steps per second: 230.99
I0901 23:57:08.073364 140183943698432 replay_runner.py:36] Average training steps per second: 230.99
I0901 23:57:08.308165 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -40.69
INFO:tensorflow:Starting iteration 14
I0901 23:57:12.581497 140183943698432 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 230.20

Steps executed: 313 Episode length: 313 Return: -136.1782355257132687
I0901 23:57:17.360263 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.18
INFO:tensorflow:Starting iteration 15

Steps executed: 412 Episode length: 240 Return: -10.97490359747585887
INFO:tensorflow:Average training steps per second: 225.30
I0901 23:57:26.172218 140183943698432 replay_runner.py:36] Average training steps per second: 225.30
I0901 23:57:26.603170 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.31
INFO:tensorflow:Starting iteration 16

Steps executed: 246 Episode length: 62 Return: -292.35386907111476887
INFO:tensorflow:Average training steps per second: 222.96
I0901 23:57:35.420576 140183943698432 replay_runner.py:36] Average training steps per second: 222.96
I0901 23:57:35.631593 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -366.12
INFO:tensorflow:Starting iteration 17

Steps executed: 249 Episode length: 72 Return: -50.836571234321696887
INFO:tensorflow:Average training steps per second: 223.62
I0901 23:57:44.387580 140183943698432 replay_runner.py:36] Average training steps per second: 223.62
I0901 23:57:44.610676 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.67
INFO:tensorflow:Starting iteration 18

Steps executed: 298 Episode length: 144 Return: -158.8160805190580687
INFO:tensorflow:Average training steps per second: 225.22
I0901 23:57:53.459562 140183943698432 replay_runner.py:36] Average training steps per second: 225.22
I0901 23:57:53.718171 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.85
INFO:tensorflow:Starting iteration 19

Steps executed: 345 Episode length: 148 Return: -183.7302236677885587
INFO:tensorflow:Average training steps per second: 222.60
I0901 23:58:02.535751 140183943698432 replay_runner.py:36] Average training steps per second: 222.60
I0901 23:58:02.838154 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.80
INFO:tensorflow:Starting iteration 20

Steps executed: 241 Episode length: 91 Return: -606.72071469649528587
INFO:tensorflow:Average training steps per second: 222.10
I0901 23:58:11.759038 140183943698432 replay_runner.py:36] Average training steps per second: 222.10
I0901 23:58:11.964448 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -410.19
INFO:tensorflow:Starting iteration 21

Steps executed: 304 Episode length: 109 Return: -674.2325209905983887
INFO:tensorflow:Average training steps per second: 221.32
I0901 23:58:20.897801 140183943698432 replay_runner.py:36] Average training steps per second: 221.32
I0901 23:58:21.162925 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -453.93
INFO:tensorflow:Starting iteration 22

Steps executed: 246 Episode length: 59 Return: -157.55293096833998187
INFO:tensorflow:Average training steps per second: 225.44
I0901 23:58:30.049130 140183943698432 replay_runner.py:36] Average training steps per second: 225.44
I0901 23:58:30.254883 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.76
INFO:tensorflow:Starting iteration 23

Steps executed: 190 Episode length: 68 Return: -80.115691993598437287
INFO:tensorflow:Average training steps per second: 221.78
I0901 23:58:39.221509 140183943698432 replay_runner.py:36] Average training steps per second: 221.78

Steps executed: 323 Episode length: 133 Return: -11.04454099104000987
INFO:tensorflow:Starting iteration 24

Steps executed: 200 Episode length: 75 Return: -436.16170640984046787
INFO:tensorflow:Average training steps per second: 225.02
I0901 23:58:48.292486 140183943698432 replay_runner.py:36] Average training steps per second: 225.02
I0901 23:58:48.444740 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.14
INFO:tensorflow:Starting iteration 25

Steps executed: 176 Episode length: 104 Return: -295.2616772597856787
INFO:tensorflow:Average training steps per second: 218.86
I0901 23:58:57.375692 140183943698432 replay_runner.py:36] Average training steps per second: 218.86

Steps executed: 253 Episode length: 77 Return: -478.78822331966546787
INFO:tensorflow:Starting iteration 26

Steps executed: 211 Episode length: 52 Return: -100.73231374132935787
INFO:tensorflow:Average training steps per second: 229.57
I0901 23:59:06.243909 140183943698432 replay_runner.py:36] Average training steps per second: 229.57
I0901 23:59:06.425399 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -386.80
INFO:tensorflow:Starting iteration 27

Steps executed: 337 Episode length: 156 Return: -928.7548924172569787
INFO:tensorflow:Average training steps per second: 220.71
I0901 23:59:15.299248 140183943698432 replay_runner.py:36] Average training steps per second: 220.71
I0901 23:59:15.620146 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -682.14
INFO:tensorflow:Starting iteration 28

Steps executed: 300 Episode length: 175 Return: -939.2986309483772787
INFO:tensorflow:Average training steps per second: 224.96
I0901 23:59:24.456060 140183943698432 replay_runner.py:36] Average training steps per second: 224.96
I0901 23:59:24.754695 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -755.96
INFO:tensorflow:Starting iteration 29
I0901 23:59:29.066773 140183943698432 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 224.97
I0901 23:59:33.512219 140183943698432 replay_runner.py:36] Average training steps per second: 224.97


Done fixed training!Episode length: 66 Return: -642.58449919948682787