Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0828 10:42:19.169368 140618562066432 run_experiment.py:549] Creating TrainRunner ...
I0828 10:42:19.191845 140618562066432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:19.192020 140618562066432 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:19.195267 140618562066432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:19.195628 140618562066432 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:19.195992 140618562066432 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:19.196346 140618562066432 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:19.196690 140618562066432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:19.197048 140618562066432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:19.197402 140618562066432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:19.197765 140618562066432 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:19.198152 140618562066432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:19.198553 140618562066432 dqn_agent.py:283] 	 seed: 1630147339191805
I0828 10:42:19.204969 140618562066432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:19.205136 140618562066432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:19.207822 140618562066432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:19.208267 140618562066432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:19.208674 140618562066432 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:19.209046 140618562066432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:19.209405 140618562066432 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:19.209676 140618562066432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:19.209811 140618562066432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:19.260004 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:19.596766 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:19.608570 140618562066432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:42:19.617605 140618562066432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:19.617845 140618562066432 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:19.617933 140618562066432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:19.618020 140618562066432 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:19.618090 140618562066432 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:19.618196 140618562066432 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:19.618253 140618562066432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:19.618568 140618562066432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:19.618730 140618562066432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:19.618824 140618562066432 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:19.618906 140618562066432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:19.618984 140618562066432 dqn_agent.py:283] 	 seed: 1630147339617543
I0828 10:42:19.620550 140618562066432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:19.620665 140618562066432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:19.620737 140618562066432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:19.620800 140618562066432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:19.620862 140618562066432 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:19.620932 140618562066432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:19.620991 140618562066432 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:19.621073 140618562066432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:19.621144 140618562066432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:19.671823 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:19.706929 140618562066432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:42:19.707193 140618562066432 replay_runner.py:41] Starting iteration 0
Steps executed: 165 Episode length: 165 Return: -518.6079288494067
INFO:tensorflow:Average training steps per second: 180.49
I0828 10:42:25.248242 140618562066432 replay_runner.py:36] Average training steps per second: 180.49

Steps executed: 413 Episode length: 248 Return: -696.6101354156142
INFO:tensorflow:Starting iteration 1

Steps executed: 122 Episode length: 122 Return: -471.6584078874142
INFO:tensorflow:Average training steps per second: 238.20

Steps executed: 1122 Episode length: 1000 Return: -106.21976737276673
I0828 10:42:39.289696 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.94
INFO:tensorflow:Starting iteration 2

Steps executed: 207 Episode length: 207 Return: -198.9134012932281673
INFO:tensorflow:Average training steps per second: 229.08
I0828 10:42:47.811782 140618562066432 replay_runner.py:36] Average training steps per second: 229.08
I0828 10:42:48.042531 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.91
INFO:tensorflow:Starting iteration 3
I0828 10:42:52.266107 140618562066432 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 233.62
I0828 10:42:56.547049 140618562066432 replay_runner.py:36] Average training steps per second: 233.62

Steps executed: 910 Episode length: 910 Return: -129.5076297782325473
INFO:tensorflow:Starting iteration 4
I0828 10:43:03.271322 140618562066432 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 236.70

Steps executed: 976 Episode length: 976 Return: -259.6422815570273473
I0828 10:43:10.184980 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.64
INFO:tensorflow:Starting iteration 5
I0828 10:43:14.410211 140618562066432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 239.87

Steps executed: 707 Episode length: 707 Return: -375.8589363560334473
I0828 10:43:20.647096 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -375.86
INFO:tensorflow:Starting iteration 6
I0828 10:43:24.870931 140618562066432 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 238.20

Steps executed: 754 Episode length: 754 Return: -242.9836949916718473
I0828 10:43:31.199499 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.98
INFO:tensorflow:Starting iteration 7

Steps executed: 574 Episode length: 504 Return: -528.2421919920591473
INFO:tensorflow:Average training steps per second: 227.49
I0828 10:43:39.842451 140618562066432 replay_runner.py:36] Average training steps per second: 227.49
I0828 10:43:40.818155 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -355.47
INFO:tensorflow:Starting iteration 8

Steps executed: 261 Episode length: 261 Return: -182.1825366957328473
INFO:tensorflow:Average training steps per second: 227.10
I0828 10:43:49.582792 140618562066432 replay_runner.py:36] Average training steps per second: 227.10
I0828 10:43:49.873628 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.18
INFO:tensorflow:Starting iteration 9

Steps executed: 298 Episode length: 298 Return: -127.3920752011314873
INFO:tensorflow:Average training steps per second: 223.46
I0828 10:43:58.765929 140618562066432 replay_runner.py:36] Average training steps per second: 223.46
I0828 10:43:59.140558 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.39
INFO:tensorflow:Starting iteration 10

Steps executed: 677 Episode length: 677 Return: -372.7837278814811873
INFO:tensorflow:Average training steps per second: 231.61
I0828 10:44:07.797203 140618562066432 replay_runner.py:36] Average training steps per second: 231.61
I0828 10:44:08.936245 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -372.78
INFO:tensorflow:Starting iteration 11

Steps executed: 221 Episode length: 157 Return: -116.4848183180291473
INFO:tensorflow:Average training steps per second: 225.62
I0828 10:44:17.667832 140618562066432 replay_runner.py:36] Average training steps per second: 225.62
I0828 10:44:17.889627 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.62
INFO:tensorflow:Starting iteration 12

Steps executed: 268 Episode length: 81 Return: -123.50674810209928473
INFO:tensorflow:Average training steps per second: 226.22
I0828 10:44:26.667235 140618562066432 replay_runner.py:36] Average training steps per second: 226.22
I0828 10:44:26.940598 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.55
INFO:tensorflow:Starting iteration 13

Steps executed: 219 Episode length: 59 Return: -490.08233666233626473
INFO:tensorflow:Average training steps per second: 229.01
I0828 10:44:35.532623 140618562066432 replay_runner.py:36] Average training steps per second: 229.01
I0828 10:44:35.737402 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -427.95
INFO:tensorflow:Starting iteration 14

Steps executed: 261 Episode length: 88 Return: -643.17661040475226473
INFO:tensorflow:Average training steps per second: 228.96
I0828 10:44:44.341280 140618562066432 replay_runner.py:36] Average training steps per second: 228.96
I0828 10:44:44.591332 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -423.42
INFO:tensorflow:Starting iteration 15
I0828 10:44:48.835572 140618562066432 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 231.83
I0828 10:44:53.149348 140618562066432 replay_runner.py:36] Average training steps per second: 231.83

Steps executed: 266 Episode length: 126 Return: -597.5874191960232473
INFO:tensorflow:Starting iteration 16

Steps executed: 227 Episode length: 82 Return: -320.17895060447336473
INFO:tensorflow:Average training steps per second: 236.46
I0828 10:45:01.828953 140618562066432 replay_runner.py:36] Average training steps per second: 236.46
I0828 10:45:02.032095 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -447.07
INFO:tensorflow:Starting iteration 17

Steps executed: 290 Episode length: 109 Return: -48.35479457166088473
INFO:tensorflow:Average training steps per second: 244.69
I0828 10:45:10.292211 140618562066432 replay_runner.py:36] Average training steps per second: 244.69
I0828 10:45:10.564464 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.84
INFO:tensorflow:Starting iteration 18

Steps executed: 244 Episode length: 119 Return: -384.8959649611421773
INFO:tensorflow:Average training steps per second: 252.17
I0828 10:45:18.724577 140618562066432 replay_runner.py:36] Average training steps per second: 252.17
I0828 10:45:18.963351 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -478.31
INFO:tensorflow:Starting iteration 19

Steps executed: 226 Episode length: 83 Return: -487.13366334492906773
INFO:tensorflow:Average training steps per second: 258.61
I0828 10:45:27.027084 140618562066432 replay_runner.py:36] Average training steps per second: 258.61
I0828 10:45:27.204516 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -579.84
INFO:tensorflow:Starting iteration 20

Steps executed: 265 Episode length: 121 Return: -1007.822250275139773
INFO:tensorflow:Average training steps per second: 277.04
I0828 10:45:34.890470 140618562066432 replay_runner.py:36] Average training steps per second: 277.04
I0828 10:45:35.092383 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -580.51
INFO:tensorflow:Starting iteration 21

Steps executed: 201 Episode length: 117 Return: -8.075641253246971773
INFO:tensorflow:Average training steps per second: 271.55
I0828 10:45:42.881883 140618562066432 replay_runner.py:36] Average training steps per second: 271.55
I0828 10:45:43.027286 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: 3.64
INFO:tensorflow:Starting iteration 22

Steps executed: 228 Episode length: 74 Return: -373.78735800239654773
INFO:tensorflow:Average training steps per second: 279.52
I0828 10:45:50.697924 140618562066432 replay_runner.py:36] Average training steps per second: 279.52
I0828 10:45:50.860157 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -391.01
INFO:tensorflow:Starting iteration 23

Steps executed: 225 Episode length: 77 Return: -502.32276032044964773
INFO:tensorflow:Average training steps per second: 279.28
I0828 10:45:58.433012 140618562066432 replay_runner.py:36] Average training steps per second: 279.28
I0828 10:45:58.603074 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -449.20
INFO:tensorflow:Starting iteration 24

Steps executed: 226 Episode length: 83 Return: -60.608217125901242773
INFO:tensorflow:Average training steps per second: 295.66
I0828 10:46:05.958947 140618562066432 replay_runner.py:36] Average training steps per second: 295.66
I0828 10:46:06.107952 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.33
INFO:tensorflow:Starting iteration 25

Steps executed: 278 Episode length: 108 Return: -247.0345993047843773
INFO:tensorflow:Average training steps per second: 300.59
I0828 10:46:13.209039 140618562066432 replay_runner.py:36] Average training steps per second: 300.59
I0828 10:46:13.399450 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.48
INFO:tensorflow:Starting iteration 26

Steps executed: 224 Episode length: 85 Return: -48.046037298561153773
INFO:tensorflow:Average training steps per second: 326.14
I0828 10:46:20.119828 140618562066432 replay_runner.py:36] Average training steps per second: 326.14
I0828 10:46:20.247012 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.21
INFO:tensorflow:Starting iteration 27

Steps executed: 245 Episode length: 83 Return: -520.25592789594053773
INFO:tensorflow:Average training steps per second: 336.38
I0828 10:46:26.610923 140618562066432 replay_runner.py:36] Average training steps per second: 336.38
I0828 10:46:26.745789 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -421.92
INFO:tensorflow:Starting iteration 28

Steps executed: 200 Episode length: 80 Return: -118.81229939609557273
INFO:tensorflow:Average training steps per second: 333.38
I0828 10:46:33.101990 140618562066432 replay_runner.py:36] Average training steps per second: 333.38
I0828 10:46:33.219248 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.32
INFO:tensorflow:Starting iteration 29
I0828 10:46:36.524833 140618562066432 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 341.19
I0828 10:46:39.456134 140618562066432 replay_runner.py:36] Average training steps per second: 341.19


Done fixed training!Episode length: 99 Return: -512.57334238217231273