Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0901 12:14:32.344837 139982171817984 run_experiment.py:549] Creating TrainRunner ...
I0901 12:14:32.356266 139982171817984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:14:32.356533 139982171817984 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:14:32.356696 139982171817984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:14:32.356799 139982171817984 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:14:32.357016 139982171817984 dqn_agent.py:275] 	 update_period: 4
I0901 12:14:32.357129 139982171817984 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:14:32.357219 139982171817984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:14:32.357372 139982171817984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:14:32.357491 139982171817984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:14:32.357597 139982171817984 dqn_agent.py:280] 	 optimizer: adam
I0901 12:14:32.357697 139982171817984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:14:32.357793 139982171817984 dqn_agent.py:283] 	 seed: 1630498472356200
I0901 12:14:32.361288 139982171817984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:14:32.361522 139982171817984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:14:32.361658 139982171817984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:14:32.361803 139982171817984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:14:32.361926 139982171817984 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:14:32.362098 139982171817984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:14:32.366630 139982171817984 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:14:32.366798 139982171817984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:14:32.366923 139982171817984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:14:32.434310 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:14:32.775864 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:14:32.787401 139982171817984 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:14:32.796004 139982171817984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:14:32.796241 139982171817984 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:14:32.796413 139982171817984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:14:32.796579 139982171817984 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:14:32.796714 139982171817984 dqn_agent.py:275] 	 update_period: 4
I0901 12:14:32.796851 139982171817984 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:14:32.797008 139982171817984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:14:32.797127 139982171817984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:14:32.797725 139982171817984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:14:32.798002 139982171817984 dqn_agent.py:280] 	 optimizer: adam
I0901 12:14:32.798175 139982171817984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:14:32.798288 139982171817984 dqn_agent.py:283] 	 seed: 1630498472795926
I0901 12:14:32.801141 139982171817984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:14:32.801281 139982171817984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:14:32.801353 139982171817984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:14:32.801419 139982171817984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:14:32.801477 139982171817984 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:14:32.801554 139982171817984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:14:32.801616 139982171817984 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:14:32.801699 139982171817984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:14:32.801753 139982171817984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:14:33.340696 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:14:33.363005 139982171817984 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:14:33.363351 139982171817984 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 161.60
I0901 12:14:39.551616 139982171817984 replay_runner.py:36] Average training steps per second: 161.60
Steps executed: 207 Episode length: 124 Return: -404.99356626956154
I0901 12:14:40.755457 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -480.56
INFO:tensorflow:Starting iteration 1

Steps executed: 205 Episode length: 98 Return: -293.449868848787994
INFO:tensorflow:Average training steps per second: 220.41
I0901 12:14:49.544844 139982171817984 replay_runner.py:36] Average training steps per second: 220.41
I0901 12:14:49.704845 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.28
INFO:tensorflow:Starting iteration 2

Steps executed: 222 Episode length: 137 Return: -219.49827326080864
INFO:tensorflow:Average training steps per second: 215.65
I0901 12:14:58.685610 139982171817984 replay_runner.py:36] Average training steps per second: 215.65
I0901 12:14:58.872154 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.61
INFO:tensorflow:Starting iteration 3
I0901 12:15:03.203069 139982171817984 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 222.45

Steps executed: 1000 Episode length: 1000 Return: -134.2705028239492
I0901 12:15:11.076417 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.27
INFO:tensorflow:Starting iteration 4
I0901 12:15:15.267634 139982171817984 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 216.27

Steps executed: 1000 Episode length: 1000 Return: -128.77615896382235
I0901 12:15:22.706250 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.78
INFO:tensorflow:Starting iteration 5
I0901 12:15:26.962840 139982171817984 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 220.19

Steps executed: 1000 Episode length: 1000 Return: -89.659192243515015
I0901 12:15:34.693877 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.66
INFO:tensorflow:Starting iteration 6
I0901 12:15:38.802073 139982171817984 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 235.90

Steps executed: 1000 Episode length: 1000 Return: -141.29120132808842
I0901 12:15:45.698873 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.29
INFO:tensorflow:Starting iteration 7
I0901 12:15:49.544113 139982171817984 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 229.99

Steps executed: 1000 Episode length: 1000 Return: -287.87869488750042
I0901 12:15:58.480956 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.88
INFO:tensorflow:Starting iteration 8
I0901 12:16:02.423283 139982171817984 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 229.17

Steps executed: 1000 Episode length: 1000 Return: -330.39836190453696
I0901 12:16:09.426773 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -330.40
INFO:tensorflow:Starting iteration 9
I0901 12:16:13.794955 139982171817984 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 219.40

Steps executed: 361 Episode length: 361 Return: -597.7216856820085696
I0901 12:16:18.833496 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -597.72
INFO:tensorflow:Starting iteration 10

Steps executed: 166 Episode length: 166 Return: -88.86147321802602696
INFO:tensorflow:Average training steps per second: 212.36

Steps executed: 924 Episode length: 758 Return: -568.2125574859049696
I0901 12:16:29.912108 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.54
INFO:tensorflow:Starting iteration 11

Steps executed: 292 Episode length: 292 Return: -480.3937416876260696
INFO:tensorflow:Average training steps per second: 215.53
I0901 12:16:38.840869 139982171817984 replay_runner.py:36] Average training steps per second: 215.53
I0901 12:16:39.238330 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -480.39
INFO:tensorflow:Starting iteration 12
I0901 12:16:43.544105 139982171817984 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 210.91

Steps executed: 508 Episode length: 508 Return: -410.6299493346275696
I0901 12:16:49.358430 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -410.63
INFO:tensorflow:Starting iteration 13
I0901 12:16:53.514712 139982171817984 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 216.24

Steps executed: 1000 Episode length: 1000 Return: -193.13127946794326
I0901 12:17:00.530788 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.13
INFO:tensorflow:Starting iteration 14
I0901 12:17:04.896694 139982171817984 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 218.69

Steps executed: 604 Episode length: 604 Return: -298.9546986154579326
I0901 12:17:10.894362 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -298.95
INFO:tensorflow:Starting iteration 15
I0901 12:17:15.168474 139982171817984 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 218.11

Steps executed: 1000 Episode length: 1000 Return: -108.46522132301763
I0901 12:17:23.619775 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.47
INFO:tensorflow:Starting iteration 16
I0901 12:17:27.953787 139982171817984 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 217.98

Steps executed: 398 Episode length: 398 Return: -286.3733812556752763
I0901 12:17:33.218012 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -286.37
INFO:tensorflow:Starting iteration 17
I0901 12:17:37.491384 139982171817984 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 218.99

Steps executed: 800 Episode length: 800 Return: -162.8179707787527463
I0901 12:17:44.264725 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.82
INFO:tensorflow:Starting iteration 18

Steps executed: 229 Episode length: 156 Return: -197.1417817907487563
INFO:tensorflow:Average training steps per second: 210.22
I0901 12:17:53.272603 139982171817984 replay_runner.py:36] Average training steps per second: 210.22
I0901 12:17:53.494683 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.24
INFO:tensorflow:Starting iteration 19
I0901 12:17:57.875108 139982171817984 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 216.56
I0901 12:18:02.493461 139982171817984 replay_runner.py:36] Average training steps per second: 216.56

Steps executed: 215 Episode length: 120 Return: -503.8053905412187563
INFO:tensorflow:Starting iteration 20

Steps executed: 219 Episode length: 104 Return: -222.5229214887493863
INFO:tensorflow:Average training steps per second: 221.74
I0901 12:18:11.435535 139982171817984 replay_runner.py:36] Average training steps per second: 221.74
I0901 12:18:11.622909 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -275.71
INFO:tensorflow:Starting iteration 21

Steps executed: 86 Episode length: 86 Return: -142.187105478417043863
INFO:tensorflow:Average training steps per second: 220.31
I0901 12:18:20.292487 139982171817984 replay_runner.py:36] Average training steps per second: 220.31

Steps executed: 260 Episode length: 86 Return: -903.94061342979263863
INFO:tensorflow:Starting iteration 22

Steps executed: 389 Episode length: 389 Return: -63.83164975601735863
INFO:tensorflow:Average training steps per second: 210.37
I0901 12:18:29.514576 139982171817984 replay_runner.py:36] Average training steps per second: 210.37
I0901 12:18:30.115170 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -63.83
INFO:tensorflow:Starting iteration 23
I0901 12:18:34.421335 139982171817984 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 223.11

Steps executed: 314 Episode length: 314 Return: -29.43740639868868863
I0901 12:18:39.368645 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -29.44
INFO:tensorflow:Starting iteration 24

Steps executed: 151 Episode length: 151 Return: -762.4919491490131863
INFO:tensorflow:Average training steps per second: 237.94

Steps executed: 862 Episode length: 711 Return: -362.2262160616311363
I0901 12:18:49.844153 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -562.36
INFO:tensorflow:Starting iteration 25

Steps executed: 295 Episode length: 151 Return: -78.03101814904878763
INFO:tensorflow:Average training steps per second: 247.72
I0901 12:18:57.988570 139982171817984 replay_runner.py:36] Average training steps per second: 247.72
I0901 12:18:58.258908 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.35
INFO:tensorflow:Starting iteration 26

Steps executed: 118 Episode length: 118 Return: 6.8787626863667988763
INFO:tensorflow:Average training steps per second: 240.55
I0901 12:19:06.501193 139982171817984 replay_runner.py:36] Average training steps per second: 240.55

Steps executed: 208 Episode length: 90 Return: -113.28140175972331763
INFO:tensorflow:Starting iteration 27

Steps executed: 526 Episode length: 351 Return: 225.31491336875345763
INFO:tensorflow:Average training steps per second: 221.02
I0901 12:19:15.291697 139982171817984 replay_runner.py:36] Average training steps per second: 221.02
I0901 12:19:16.042997 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: 107.75
INFO:tensorflow:Starting iteration 28
I0901 12:19:20.048477 139982171817984 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 216.11

Steps executed: 232 Episode length: 232 Return: -209.9939462516632363
I0901 12:19:24.963138 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.99
INFO:tensorflow:Starting iteration 29

Steps executed: 296 Episode length: 115 Return: -336.0327424818628463
INFO:tensorflow:Average training steps per second: 221.63
I0901 12:19:33.671647 139982171817984 replay_runner.py:36] Average training steps per second: 221.63

Done fixed training!Episode length: 115 Return: -336.0327424818628463