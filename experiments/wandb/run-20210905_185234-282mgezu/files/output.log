Loaded trained dqn in acrobot
Training fixed agent 3, please be patient, may be a while...
I0905 18:52:40.983072 140109285058560 run_experiment.py:549] Creating TrainRunner ...
I0905 18:52:40.993086 140109285058560 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 18:52:40.993315 140109285058560 dqn_agent.py:272] 	 gamma: 0.990000
I0905 18:52:40.993418 140109285058560 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 18:52:40.993509 140109285058560 dqn_agent.py:274] 	 min_replay_history: 500
I0905 18:52:40.993587 140109285058560 dqn_agent.py:275] 	 update_period: 4
I0905 18:52:40.993669 140109285058560 dqn_agent.py:276] 	 target_update_period: 100
I0905 18:52:40.993805 140109285058560 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 18:52:40.994126 140109285058560 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 18:52:40.994390 140109285058560 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 18:52:40.994545 140109285058560 dqn_agent.py:280] 	 optimizer: adam
I0905 18:52:40.994823 140109285058560 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 18:52:40.994993 140109285058560 dqn_agent.py:283] 	 seed: 1630867960993027
I0905 18:52:40.998337 140109285058560 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 18:52:40.998742 140109285058560 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0905 18:52:40.998893 140109285058560 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 18:52:40.999031 140109285058560 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 18:52:40.999186 140109285058560 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 18:52:40.999285 140109285058560 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 18:52:40.999386 140109285058560 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 18:52:40.999478 140109285058560 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 18:52:40.999570 140109285058560 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 18:52:41.053745 140109285058560 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:52:41.618327 140109285058560 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:52:41.635065 140109285058560 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 18:52:41.643996 140109285058560 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 18:52:41.644292 140109285058560 dqn_agent.py:272] 	 gamma: 0.990000
I0905 18:52:41.644777 140109285058560 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 18:52:41.644949 140109285058560 dqn_agent.py:274] 	 min_replay_history: 500
I0905 18:52:41.645215 140109285058560 dqn_agent.py:275] 	 update_period: 4
I0905 18:52:41.645460 140109285058560 dqn_agent.py:276] 	 target_update_period: 100
I0905 18:52:41.645610 140109285058560 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 18:52:41.645739 140109285058560 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 18:52:41.645861 140109285058560 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 18:52:41.646013 140109285058560 dqn_agent.py:280] 	 optimizer: adam
I0905 18:52:41.646180 140109285058560 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 18:52:41.646525 140109285058560 dqn_agent.py:283] 	 seed: 1630867961643941
I0905 18:52:41.650361 140109285058560 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 18:52:41.650638 140109285058560 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0905 18:52:41.651465 140109285058560 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 18:52:41.651632 140109285058560 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 18:52:41.651789 140109285058560 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 18:52:41.652117 140109285058560 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 18:52:41.652294 140109285058560 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 18:52:41.652752 140109285058560 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 18:52:41.653112 140109285058560 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 18:52:41.711421 140109285058560 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:52:41.743540 140109285058560 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 18:52:41.743942 140109285058560 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 124.95
I0905 18:52:49.747915 140109285058560 replay_runner.py:36] Average training steps per second: 124.95
Steps executed: 500 Episode length: 500 Return: -500.0
I0905 18:52:51.699224 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1

Steps executed: 339 Episode length: 168 Return: -167.0
INFO:tensorflow:Average training steps per second: 168.06
I0905 18:52:57.937540 140109285058560 replay_runner.py:36] Average training steps per second: 168.06
I0905 18:52:58.343551 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.50
INFO:tensorflow:Starting iteration 2
I0905 18:52:58.585297 140109285058560 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 169.18

Steps executed: 500 Episode length: 500 Return: -500.0
I0905 18:53:05.019091 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 3
I0905 18:53:05.279145 140109285058560 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 169.36
I0905 18:53:11.184475 140109285058560 replay_runner.py:36] Average training steps per second: 169.36
I0905 18:53:11.725439 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 4

Steps executed: 202 Episode length: 120 Return: -119.0
INFO:tensorflow:Average training steps per second: 172.63
I0905 18:53:17.785660 140109285058560 replay_runner.py:36] Average training steps per second: 172.63
I0905 18:53:18.003530 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.00
INFO:tensorflow:Starting iteration 5

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 171.55
I0905 18:53:24.105139 140109285058560 replay_runner.py:36] Average training steps per second: 171.55
I0905 18:53:24.654479 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6
I0905 18:53:24.928817 140109285058560 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 169.81

Steps executed: 256 Episode length: 256 Return: -255.0
I0905 18:53:31.092898 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.00
INFO:tensorflow:Starting iteration 7

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 172.34
I0905 18:53:37.149976 140109285058560 replay_runner.py:36] Average training steps per second: 172.34
I0905 18:53:37.695831 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 8
I0905 18:53:37.978258 140109285058560 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 171.26
I0905 18:53:43.818036 140109285058560 replay_runner.py:36] Average training steps per second: 171.26
I0905 18:53:44.342325 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 9

Steps executed: 284 Episode length: 100 Return: -99.00
INFO:tensorflow:Average training steps per second: 171.33
I0905 18:53:50.452859 140109285058560 replay_runner.py:36] Average training steps per second: 171.33
I0905 18:53:50.759916 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.67
INFO:tensorflow:Starting iteration 10
I0905 18:53:51.023684 140109285058560 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 170.05

Steps executed: 500 Episode length: 500 Return: -500.0
I0905 18:53:57.448077 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 11
I0905 18:53:57.728880 140109285058560 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 168.48
I0905 18:54:03.664745 140109285058560 replay_runner.py:36] Average training steps per second: 168.48
I0905 18:54:04.223684 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 12

Steps executed: 219 Episode length: 99 Return: -98.0.0
INFO:tensorflow:Average training steps per second: 170.22
I0905 18:54:10.351150 140109285058560 replay_runner.py:36] Average training steps per second: 170.22
I0905 18:54:10.593290 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.50
INFO:tensorflow:Starting iteration 13

Steps executed: 89 Episode length: 89 Return: -88.00.0
INFO:tensorflow:Average training steps per second: 169.67
I0905 18:54:16.770001 140109285058560 replay_runner.py:36] Average training steps per second: 169.67

Steps executed: 241 Episode length: 70 Return: -69.0.0
INFO:tensorflow:Starting iteration 14
I0905 18:54:17.302080 140109285058560 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 173.15

Steps executed: 226 Episode length: 87 Return: -86.0.0
I0905 18:54:23.340519 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.33
INFO:tensorflow:Starting iteration 15

Steps executed: 565 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 170.57
I0905 18:54:29.443886 140109285058560 replay_runner.py:36] Average training steps per second: 170.57
I0905 18:54:30.103490 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -282.00
INFO:tensorflow:Starting iteration 16

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 167.10
I0905 18:54:36.373181 140109285058560 replay_runner.py:36] Average training steps per second: 167.10
I0905 18:54:36.934384 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 17
I0905 18:54:37.200778 140109285058560 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 171.32

Steps executed: 254 Episode length: 84 Return: -83.0.0
I0905 18:54:43.314982 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.67
INFO:tensorflow:Starting iteration 18

Steps executed: 218 Episode length: 62 Return: -61.0.0
INFO:tensorflow:Average training steps per second: 170.96
I0905 18:54:49.437206 140109285058560 replay_runner.py:36] Average training steps per second: 170.96
I0905 18:54:49.674928 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.67
INFO:tensorflow:Starting iteration 19

Steps executed: 282 Episode length: 98 Return: -97.0.0
INFO:tensorflow:Average training steps per second: 173.01
I0905 18:54:55.725299 140109285058560 replay_runner.py:36] Average training steps per second: 173.01
I0905 18:54:56.038461 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.00
INFO:tensorflow:Starting iteration 20

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 168.20
I0905 18:55:02.255859 140109285058560 replay_runner.py:36] Average training steps per second: 168.20
I0905 18:55:02.808872 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 21
I0905 18:55:03.073864 140109285058560 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 165.51

Steps executed: 269 Episode length: 92 Return: -91.0.0
I0905 18:55:09.419753 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.67
INFO:tensorflow:Starting iteration 22

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 168.11
I0905 18:55:15.639792 140109285058560 replay_runner.py:36] Average training steps per second: 168.11
I0905 18:55:16.193190 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 23

Steps executed: 223 Episode length: 73 Return: -72.0.0
INFO:tensorflow:Average training steps per second: 167.60
I0905 18:55:22.426899 140109285058560 replay_runner.py:36] Average training steps per second: 167.60
I0905 18:55:22.660715 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.33
INFO:tensorflow:Starting iteration 24

Steps executed: 235 Episode length: 95 Return: -94.0.0
INFO:tensorflow:Average training steps per second: 181.64
I0905 18:55:28.431775 140109285058560 replay_runner.py:36] Average training steps per second: 181.64
I0905 18:55:28.690876 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.33
INFO:tensorflow:Starting iteration 25

Steps executed: 286 Episode length: 94 Return: -93.0.0
INFO:tensorflow:Average training steps per second: 173.54
I0905 18:55:34.718029 140109285058560 replay_runner.py:36] Average training steps per second: 173.54
I0905 18:55:35.023338 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.33
INFO:tensorflow:Starting iteration 26

Steps executed: 264 Episode length: 114 Return: -113.0
INFO:tensorflow:Average training steps per second: 186.34
I0905 18:55:40.655478 140109285058560 replay_runner.py:36] Average training steps per second: 186.34
I0905 18:55:40.901393 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.00
INFO:tensorflow:Starting iteration 27

Steps executed: 246 Episode length: 86 Return: -85.0.0
INFO:tensorflow:Average training steps per second: 192.93
I0905 18:55:46.320505 140109285058560 replay_runner.py:36] Average training steps per second: 192.93
I0905 18:55:46.537705 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.00
INFO:tensorflow:Starting iteration 28

Steps executed: 224 Episode length: 81 Return: -80.0.0
INFO:tensorflow:Average training steps per second: 183.08
I0905 18:55:52.240551 140109285058560 replay_runner.py:36] Average training steps per second: 183.08
I0905 18:55:52.440457 140109285058560 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.67
INFO:tensorflow:Starting iteration 29

Steps executed: 617 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 181.43
I0905 18:55:58.208478 140109285058560 replay_runner.py:36] Average training steps per second: 181.43

Done fixed training!Episode length: 500 Return: -500.0