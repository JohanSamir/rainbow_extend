I0905 16:28:05.640209 140202555004928 run_experiment.py:549] Creating TrainRunner ...
I0905 16:28:05.648490 140202555004928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:28:05.648642 140202555004928 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:28:05.648737 140202555004928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:28:05.648799 140202555004928 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:28:05.648856 140202555004928 dqn_agent.py:275] 	 update_period: 4
I0905 16:28:05.648942 140202555004928 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:28:05.649129 140202555004928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:28:05.649205 140202555004928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:28:05.649286 140202555004928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:28:05.649343 140202555004928 dqn_agent.py:280] 	 optimizer: adam
I0905 16:28:05.649426 140202555004928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:28:05.649495 140202555004928 dqn_agent.py:283] 	 seed: 1630859285648445
I0905 16:28:05.651999 140202555004928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:28:05.652131 140202555004928 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:28:05.652208 140202555004928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:28:05.652271 140202555004928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:28:05.652379 140202555004928 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:28:05.652490 140202555004928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:28:05.652629 140202555004928 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:28:05.652761 140202555004928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:28:05.652966 140202555004928 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0905 16:28:07.367622 140202555004928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:07.746397 140202555004928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:07.760071 140202555004928 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:28:07.768100 140202555004928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:28:07.768365 140202555004928 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:28:07.768553 140202555004928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:28:07.768680 140202555004928 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:28:07.768848 140202555004928 dqn_agent.py:275] 	 update_period: 4
I0905 16:28:07.768995 140202555004928 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:28:07.769113 140202555004928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:28:07.769227 140202555004928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:28:07.769353 140202555004928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:28:07.769486 140202555004928 dqn_agent.py:280] 	 optimizer: adam
I0905 16:28:07.769596 140202555004928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:28:07.769706 140202555004928 dqn_agent.py:283] 	 seed: 1630859287768047
I0905 16:28:07.772115 140202555004928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:28:07.772294 140202555004928 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:28:07.772457 140202555004928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:28:07.772581 140202555004928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:28:07.772697 140202555004928 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:28:07.772875 140202555004928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:28:07.773026 140202555004928 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:28:07.773180 140202555004928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:28:07.773302 140202555004928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:28:07.799275 140202555004928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:07.814882 140202555004928 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:28:07.815068 140202555004928 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 204.24
I0905 16:28:12.711596 140202555004928 replay_runner.py:36] Average training steps per second: 204.24
Steps executed: 274 Episode length: 135 Return: -327.50344122531544
I0905 16:28:13.584843 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.78
INFO:tensorflow:Starting iteration 1
I0905 16:28:17.273486 140202555004928 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 289.61
I0905 16:28:20.726877 140202555004928 replay_runner.py:36] Average training steps per second: 289.61

Steps executed: 220 Episode length: 139 Return: -281.76268356090124
INFO:tensorflow:Starting iteration 2

Steps executed: 283 Episode length: 88 Return: -314.394031223296854
INFO:tensorflow:Average training steps per second: 307.96
I0905 16:28:27.767735 140202555004928 replay_runner.py:36] Average training steps per second: 307.96
I0905 16:28:27.952242 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.16
INFO:tensorflow:Starting iteration 3

Steps executed: 336 Episode length: 161 Return: -386.42891824597046
INFO:tensorflow:Average training steps per second: 311.76
I0905 16:28:34.832831 140202555004928 replay_runner.py:36] Average training steps per second: 311.76
I0905 16:28:35.042390 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.15
INFO:tensorflow:Starting iteration 4

Steps executed: 297 Episode length: 139 Return: -345.76526147860756
INFO:tensorflow:Average training steps per second: 307.01
I0905 16:28:41.984854 140202555004928 replay_runner.py:36] Average training steps per second: 307.01
I0905 16:28:42.135995 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.99
INFO:tensorflow:Starting iteration 5
I0905 16:28:45.807476 140202555004928 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 302.10
I0905 16:28:49.117872 140202555004928 replay_runner.py:36] Average training steps per second: 302.10

Steps executed: 274 Episode length: 274 Return: -197.81185921488535
INFO:tensorflow:Starting iteration 6

Steps executed: 483 Episode length: 364 Return: -280.28576239826725
INFO:tensorflow:Average training steps per second: 302.89
I0905 16:28:56.368467 140202555004928 replay_runner.py:36] Average training steps per second: 302.89
I0905 16:28:56.764260 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.97
INFO:tensorflow:Starting iteration 7
I0905 16:29:00.390014 140202555004928 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 326.54

Steps executed: 214 Episode length: 214 Return: -387.73000564119675
I0905 16:29:03.623447 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -387.73
INFO:tensorflow:Starting iteration 8

Steps executed: 308 Episode length: 150 Return: -267.26908818040397
INFO:tensorflow:Average training steps per second: 326.29
I0905 16:29:10.313268 140202555004928 replay_runner.py:36] Average training steps per second: 326.29
I0905 16:29:10.489614 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.59
INFO:tensorflow:Starting iteration 9

Steps executed: 536 Episode length: 536 Return: -985.31829521469067
INFO:tensorflow:Average training steps per second: 268.94
I0905 16:29:17.894366 140202555004928 replay_runner.py:36] Average training steps per second: 268.94
I0905 16:29:18.743231 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -985.32
INFO:tensorflow:Starting iteration 10

Steps executed: 247 Episode length: 247 Return: -468.59651650723857
INFO:tensorflow:Average training steps per second: 259.21
I0905 16:29:26.680578 140202555004928 replay_runner.py:36] Average training steps per second: 259.21
I0905 16:29:26.924012 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -468.60
INFO:tensorflow:Starting iteration 11

Steps executed: 229 Episode length: 229 Return: -204.99315139273747
INFO:tensorflow:Average training steps per second: 246.11
I0905 16:29:35.193397 140202555004928 replay_runner.py:36] Average training steps per second: 246.11
I0905 16:29:35.392260 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -204.99
INFO:tensorflow:Starting iteration 12

Steps executed: 638 Episode length: 553 Return: -220.84341320332817
INFO:tensorflow:Average training steps per second: 242.31
I0905 16:29:43.800252 140202555004928 replay_runner.py:36] Average training steps per second: 242.31
I0905 16:29:44.953191 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.62
INFO:tensorflow:Starting iteration 13
I0905 16:29:49.168087 140202555004928 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 240.45

Steps executed: 1000 Episode length: 1000 Return: -121.3550448195695
I0905 16:29:56.404745 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.36
INFO:tensorflow:Starting iteration 14

Steps executed: 384 Episode length: 253 Return: -282.322567372813595
INFO:tensorflow:Average training steps per second: 245.07
I0905 16:30:04.713674 140202555004928 replay_runner.py:36] Average training steps per second: 245.07
I0905 16:30:04.994016 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.23
INFO:tensorflow:Starting iteration 15

Steps executed: 81 Episode length: 81 Return: -222.06594665801717595
INFO:tensorflow:Average training steps per second: 236.46

Steps executed: 915 Episode length: 834 Return: -459.388998607727495
I0905 16:30:15.210869 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -340.73
INFO:tensorflow:Starting iteration 16

Steps executed: 275 Episode length: 79 Return: -212.2954114004834695
INFO:tensorflow:Average training steps per second: 243.26
I0905 16:30:23.530234 140202555004928 replay_runner.py:36] Average training steps per second: 243.26
I0905 16:30:23.743242 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.16
INFO:tensorflow:Starting iteration 17

Steps executed: 229 Episode length: 69 Return: -339.2069998446974695
INFO:tensorflow:Average training steps per second: 239.44
I0905 16:30:32.170145 140202555004928 replay_runner.py:36] Average training steps per second: 239.44
I0905 16:30:32.330184 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.48
INFO:tensorflow:Starting iteration 18

Steps executed: 66 Episode length: 66 Return: -146.26093182494998695
INFO:tensorflow:Average training steps per second: 243.20

Steps executed: 1066 Episode length: 1000 Return: -93.83762936606617
I0905 16:30:44.191908 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.05
INFO:tensorflow:Starting iteration 19

Steps executed: 77 Episode length: 77 Return: -12.621294518456926617
INFO:tensorflow:Average training steps per second: 237.79

Steps executed: 1077 Episode length: 1000 Return: -78.69725465097345
I0905 16:30:54.987421 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -45.66
INFO:tensorflow:Starting iteration 20
I0905 16:30:59.236053 140202555004928 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 239.96

Steps executed: 749 Episode length: 749 Return: -396.574382263608745
I0905 16:31:05.416139 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -396.57
INFO:tensorflow:Starting iteration 21
I0905 16:31:09.565092 140202555004928 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 239.28
I0905 16:31:13.744931 140202555004928 replay_runner.py:36] Average training steps per second: 239.28

Steps executed: 217 Episode length: 100 Return: -446.582916668472655
INFO:tensorflow:Starting iteration 22
I0905 16:31:18.169227 140202555004928 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 242.01

Steps executed: 351 Episode length: 167 Return: -282.304586458244825
I0905 16:31:22.596186 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.10
INFO:tensorflow:Starting iteration 23

Steps executed: 335 Episode length: 180 Return: -13.4973499027639865
INFO:tensorflow:Average training steps per second: 235.05
I0905 16:31:31.144528 140202555004928 replay_runner.py:36] Average training steps per second: 235.05
I0905 16:31:31.414286 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -6.90
INFO:tensorflow:Starting iteration 24

Steps executed: 233 Episode length: 119 Return: -537.939665614291565
INFO:tensorflow:Average training steps per second: 247.76
I0905 16:31:39.726760 140202555004928 replay_runner.py:36] Average training steps per second: 247.76
I0905 16:31:39.899229 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -685.61
INFO:tensorflow:Starting iteration 25
I0905 16:31:44.096408 140202555004928 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 252.04
I0905 16:31:48.064626 140202555004928 replay_runner.py:36] Average training steps per second: 252.04

Steps executed: 246 Episode length: 64 Return: -423.2346007010478665
INFO:tensorflow:Starting iteration 26

Steps executed: 240 Episode length: 67 Return: -496.4443715382535665
INFO:tensorflow:Average training steps per second: 254.01
I0905 16:31:56.231886 140202555004928 replay_runner.py:36] Average training steps per second: 254.01
I0905 16:31:56.402781 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -487.25
INFO:tensorflow:Starting iteration 27

Steps executed: 370 Episode length: 265 Return: -244.259200096285245
INFO:tensorflow:Average training steps per second: 231.89
I0905 16:32:04.819337 140202555004928 replay_runner.py:36] Average training steps per second: 231.89
I0905 16:32:05.233120 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -407.33
INFO:tensorflow:Starting iteration 28

Steps executed: 222 Episode length: 64 Return: -468.3232508428429645
INFO:tensorflow:Average training steps per second: 218.59
I0905 16:32:14.333483 140202555004928 replay_runner.py:36] Average training steps per second: 218.59
I0905 16:32:14.522529 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -412.94
INFO:tensorflow:Starting iteration 29

Steps executed: 273 Episode length: 273 Return: -255.115504792043285
INFO:tensorflow:Average training steps per second: 190.48
I0905 16:32:24.412014 140202555004928 replay_runner.py:36] Average training steps per second: 190.48

Done fixed training!Episode length: 273 Return: -255.115504792043285