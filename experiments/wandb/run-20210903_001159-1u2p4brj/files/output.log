Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0903 00:12:05.712502 140457530894336 run_experiment.py:549] Creating TrainRunner ...
I0903 00:12:05.720007 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:12:05.720143 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:12:05.720244 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:12:05.720350 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:12:05.720414 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0903 00:12:05.720466 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:12:05.720566 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:12:05.720627 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:12:05.720752 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:12:05.720836 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0903 00:12:05.720900 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:12:05.720999 140457530894336 dqn_agent.py:283] 	 seed: 1630627925719973
I0903 00:12:05.722668 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:12:05.722773 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:12:05.722841 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:12:05.722895 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:12:05.722948 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:12:05.723009 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:12:05.723077 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:12:05.723152 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:12:05.723226 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:12:05.745881 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:12:06.080629 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:12:06.089401 140457530894336 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:12:06.095162 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:12:06.095286 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:12:06.095353 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:12:06.095409 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:12:06.095464 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0903 00:12:06.095529 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:12:06.095608 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:12:06.095675 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:12:06.095726 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:12:06.095795 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0903 00:12:06.095884 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:12:06.095954 140457530894336 dqn_agent.py:283] 	 seed: 1630627926095135
I0903 00:12:06.097588 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:12:06.097712 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:12:06.097784 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:12:06.097846 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:12:06.097921 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:12:06.097978 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:12:06.098051 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:12:06.098124 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:12:06.098264 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:12:06.115939 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:12:06.130136 140457530894336 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:12:06.130257 140457530894336 replay_runner.py:41] Starting iteration 0
Steps executed: 228 Episode length: 99 Return: -499.47333507814614
INFO:tensorflow:Average training steps per second: 245.25
I0903 00:12:10.207947 140457530894336 replay_runner.py:36] Average training steps per second: 245.25
I0903 00:12:10.987421 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -323.71
INFO:tensorflow:Starting iteration 1
I0903 00:12:14.222286 140457530894336 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 322.02

Steps executed: 263 Episode length: 89 Return: -550.30704977728464
I0903 00:12:17.464951 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -475.67
INFO:tensorflow:Starting iteration 2

Steps executed: 231 Episode length: 76 Return: -321.85440312589224
INFO:tensorflow:Average training steps per second: 325.01
I0903 00:12:23.786290 140457530894336 replay_runner.py:36] Average training steps per second: 325.01
I0903 00:12:23.925199 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -461.48
INFO:tensorflow:Starting iteration 3

Steps executed: 323 Episode length: 172 Return: -468.08715204362846
INFO:tensorflow:Average training steps per second: 307.24
I0903 00:12:30.370284 140457530894336 replay_runner.py:36] Average training steps per second: 307.24
I0903 00:12:30.586067 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -449.37
INFO:tensorflow:Starting iteration 4

Steps executed: 234 Episode length: 234 Return: -531.92084775251346
INFO:tensorflow:Average training steps per second: 302.14
I0903 00:12:37.075852 140457530894336 replay_runner.py:36] Average training steps per second: 302.14
I0903 00:12:37.250634 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -531.92
INFO:tensorflow:Starting iteration 5

Steps executed: 608 Episode length: 608 Return: -678.40178368303166
INFO:tensorflow:Average training steps per second: 323.09
I0903 00:12:43.624809 140457530894336 replay_runner.py:36] Average training steps per second: 323.09
I0903 00:12:44.414769 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -678.40
INFO:tensorflow:Starting iteration 6

Steps executed: 457 Episode length: 457 Return: -105.79168030395886
INFO:tensorflow:Average training steps per second: 319.58
I0903 00:12:50.892233 140457530894336 replay_runner.py:36] Average training steps per second: 319.58
I0903 00:12:51.397897 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.79
INFO:tensorflow:Starting iteration 7
I0903 00:12:54.710054 140457530894336 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 316.10

Steps executed: 1000 Episode length: 1000 Return: -94.67243244870451
I0903 00:13:00.163330 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.67
INFO:tensorflow:Starting iteration 8
I0903 00:13:03.681377 140457530894336 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 335.52

Steps executed: 1000 Episode length: 1000 Return: -185.84320994446887
I0903 00:13:09.081240 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.84
INFO:tensorflow:Starting iteration 9
I0903 00:13:12.628885 140457530894336 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 347.94

Steps executed: 1000 Episode length: 1000 Return: -104.28343802664448
I0903 00:13:17.548803 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.28
INFO:tensorflow:Starting iteration 10
I0903 00:13:20.960154 140457530894336 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 333.25

Steps executed: 1000 Episode length: 1000 Return: -42.893062008827458
I0903 00:13:25.829971 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -42.89
INFO:tensorflow:Starting iteration 11

Steps executed: 566 Episode length: 566 Return: -250.4968616116753758
INFO:tensorflow:Average training steps per second: 317.54
I0903 00:13:32.296237 140457530894336 replay_runner.py:36] Average training steps per second: 317.54
I0903 00:13:33.133035 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -250.50
INFO:tensorflow:Starting iteration 12

Steps executed: 250 Episode length: 64 Return: -150.09931051278966758
INFO:tensorflow:Average training steps per second: 319.57
I0903 00:13:39.477857 140457530894336 replay_runner.py:36] Average training steps per second: 319.57
I0903 00:13:39.620093 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.06
INFO:tensorflow:Starting iteration 13
I0903 00:13:42.926262 140457530894336 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 341.37

Steps executed: 322 Episode length: 322 Return: -236.1542403846636758
I0903 00:13:46.178939 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.15
INFO:tensorflow:Starting iteration 14

Steps executed: 308 Episode length: 143 Return: -110.4803301774950558
INFO:tensorflow:Average training steps per second: 337.91
I0903 00:13:52.586585 140457530894336 replay_runner.py:36] Average training steps per second: 337.91
I0903 00:13:52.763808 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.02
INFO:tensorflow:Starting iteration 15

Steps executed: 228 Episode length: 228 Return: -273.0556389855909558
INFO:tensorflow:Average training steps per second: 334.16
I0903 00:13:59.204697 140457530894336 replay_runner.py:36] Average training steps per second: 334.16
I0903 00:13:59.383764 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.06
INFO:tensorflow:Starting iteration 16

Steps executed: 160 Episode length: 50 Return: -103.00318657651420658
INFO:tensorflow:Average training steps per second: 320.06
I0903 00:14:05.893644 140457530894336 replay_runner.py:36] Average training steps per second: 320.06

Steps executed: 274 Episode length: 114 Return: -520.6014930516775658
INFO:tensorflow:Starting iteration 17

Steps executed: 219 Episode length: 95 Return: -68.762179290620382258
INFO:tensorflow:Average training steps per second: 315.10
I0903 00:14:12.581018 140457530894336 replay_runner.py:36] Average training steps per second: 315.10
I0903 00:14:12.728473 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.76
INFO:tensorflow:Starting iteration 18

Steps executed: 218 Episode length: 140 Return: -687.9221654912427258
INFO:tensorflow:Average training steps per second: 328.19
I0903 00:14:19.126104 140457530894336 replay_runner.py:36] Average training steps per second: 328.19
I0903 00:14:19.281574 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -625.77
INFO:tensorflow:Starting iteration 19
I0903 00:14:22.680523 140457530894336 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 319.48
I0903 00:14:25.810940 140457530894336 replay_runner.py:36] Average training steps per second: 319.48

Steps executed: 218 Episode length: 110 Return: -59.46964341274162258
INFO:tensorflow:Starting iteration 20

Steps executed: 232 Episode length: 67 Return: -281.13135913128112258
INFO:tensorflow:Average training steps per second: 339.11
I0903 00:14:32.333013 140457530894336 replay_runner.py:36] Average training steps per second: 339.11
I0903 00:14:32.494158 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.05
INFO:tensorflow:Starting iteration 21

Steps executed: 252 Episode length: 99 Return: -742.26171470098147258
INFO:tensorflow:Average training steps per second: 338.76
I0903 00:14:38.904086 140457530894336 replay_runner.py:36] Average training steps per second: 338.76
I0903 00:14:39.086923 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -759.51
INFO:tensorflow:Starting iteration 22

Steps executed: 225 Episode length: 58 Return: -120.41489398940345258
INFO:tensorflow:Average training steps per second: 347.47
I0903 00:14:45.461002 140457530894336 replay_runner.py:36] Average training steps per second: 347.47
I0903 00:14:45.562963 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.75
INFO:tensorflow:Starting iteration 23

Steps executed: 296 Episode length: 192 Return: -844.6695110542257258
INFO:tensorflow:Average training steps per second: 348.46
I0903 00:14:51.958452 140457530894336 replay_runner.py:36] Average training steps per second: 348.46
I0903 00:14:52.141674 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -527.85
INFO:tensorflow:Starting iteration 24

Steps executed: 286 Episode length: 93 Return: -779.39988187259220558
INFO:tensorflow:Average training steps per second: 339.74
I0903 00:14:58.593624 140457530894336 replay_runner.py:36] Average training steps per second: 339.74
I0903 00:14:58.766341 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -544.78
INFO:tensorflow:Starting iteration 25

Steps executed: 272 Episode length: 84 Return: -594.67654435376377558
INFO:tensorflow:Average training steps per second: 343.08
I0903 00:15:05.187213 140457530894336 replay_runner.py:36] Average training steps per second: 343.08
I0903 00:15:05.350722 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -556.34
INFO:tensorflow:Starting iteration 26

Steps executed: 235 Episode length: 87 Return: -757.78858846872987558
INFO:tensorflow:Average training steps per second: 346.61
I0903 00:15:11.758646 140457530894336 replay_runner.py:36] Average training steps per second: 346.61
I0903 00:15:11.901559 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -636.24
INFO:tensorflow:Starting iteration 27

Steps executed: 255 Episode length: 63 Return: -149.03319334147017858
INFO:tensorflow:Average training steps per second: 347.33
I0903 00:15:18.256694 140457530894336 replay_runner.py:36] Average training steps per second: 347.33
I0903 00:15:18.402562 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.07
INFO:tensorflow:Starting iteration 28

Steps executed: 213 Episode length: 78 Return: -641.77177622219185858
INFO:tensorflow:Average training steps per second: 345.86
I0903 00:15:24.745620 140457530894336 replay_runner.py:36] Average training steps per second: 345.86
I0903 00:15:24.863595 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -565.83
INFO:tensorflow:Starting iteration 29

Steps executed: 201 Episode length: 61 Return: -550.20900540000485858
INFO:tensorflow:Average training steps per second: 348.67
I0903 00:15:31.185863 140457530894336 replay_runner.py:36] Average training steps per second: 348.67

Done fixed training!Episode length: 61 Return: -550.20900540000485858