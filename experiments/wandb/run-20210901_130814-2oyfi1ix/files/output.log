Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0901 13:08:20.081668 140265790818304 run_experiment.py:549] Creating TrainRunner ...
I0901 13:08:20.090352 140265790818304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:08:20.090501 140265790818304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:08:20.090582 140265790818304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:08:20.090652 140265790818304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:08:20.090715 140265790818304 dqn_agent.py:275] 	 update_period: 4
I0901 13:08:20.090777 140265790818304 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:08:20.090862 140265790818304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:08:20.090969 140265790818304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:08:20.091046 140265790818304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:08:20.091118 140265790818304 dqn_agent.py:280] 	 optimizer: adam
I0901 13:08:20.091201 140265790818304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:08:20.091273 140265790818304 dqn_agent.py:283] 	 seed: 1630501700090315
I0901 13:08:20.093133 140265790818304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:08:20.093260 140265790818304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:08:20.093344 140265790818304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:08:20.093415 140265790818304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:08:20.093478 140265790818304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:08:20.093541 140265790818304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:08:20.093645 140265790818304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:08:20.093720 140265790818304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:08:20.093782 140265790818304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:08:20.193307 140265790818304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:20.448649 140265790818304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:20.458589 140265790818304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:08:20.465115 140265790818304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:08:20.465247 140265790818304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:08:20.465320 140265790818304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:08:20.465381 140265790818304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:08:20.465451 140265790818304 dqn_agent.py:275] 	 update_period: 4
I0901 13:08:20.465524 140265790818304 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:08:20.465616 140265790818304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:08:20.465686 140265790818304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:08:20.465743 140265790818304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:08:20.465828 140265790818304 dqn_agent.py:280] 	 optimizer: adam
I0901 13:08:20.465898 140265790818304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:08:20.465963 140265790818304 dqn_agent.py:283] 	 seed: 1630501700465085
I0901 13:08:20.467377 140265790818304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:08:20.467502 140265790818304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:08:20.467569 140265790818304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:08:20.467628 140265790818304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:08:20.467683 140265790818304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:08:20.467754 140265790818304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:08:20.467817 140265790818304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:08:20.467873 140265790818304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:08:20.467931 140265790818304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:08:20.490169 140265790818304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:20.505811 140265790818304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:08:20.506002 140265790818304 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 222.10
I0901 13:08:25.008692 140265790818304 replay_runner.py:36] Average training steps per second: 222.10
Steps executed: 271 Episode length: 94 Return: -282.95030078484927
I0901 13:08:26.048939 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.11
INFO:tensorflow:Starting iteration 1

Steps executed: 350 Episode length: 167 Return: -99.38322311847155
INFO:tensorflow:Average training steps per second: 336.61
I0901 13:08:32.344931 140265790818304 replay_runner.py:36] Average training steps per second: 336.61
I0901 13:08:32.533811 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -52.84
INFO:tensorflow:Starting iteration 2

Steps executed: 302 Episode length: 162 Return: -70.22129490623752
INFO:tensorflow:Average training steps per second: 329.22
I0901 13:08:38.564311 140265790818304 replay_runner.py:36] Average training steps per second: 329.22
I0901 13:08:38.742888 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.11
INFO:tensorflow:Starting iteration 3

Steps executed: 269 Episode length: 85 Return: -401.40519853300344
INFO:tensorflow:Average training steps per second: 338.47
I0901 13:08:44.872786 140265790818304 replay_runner.py:36] Average training steps per second: 338.47
I0901 13:08:45.006308 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -365.72
INFO:tensorflow:Starting iteration 4

Steps executed: 315 Episode length: 148 Return: -492.90996367469444
INFO:tensorflow:Average training steps per second: 321.92
I0901 13:08:51.479652 140265790818304 replay_runner.py:36] Average training steps per second: 321.92
I0901 13:08:51.672587 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -477.62
INFO:tensorflow:Starting iteration 5

Steps executed: 112 Episode length: 112 Return: -198.41867777557724
INFO:tensorflow:Average training steps per second: 333.30

Steps executed: 250 Episode length: 138 Return: -319.66738297486054
I0901 13:08:58.124907 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.04
INFO:tensorflow:Starting iteration 6

Steps executed: 315 Episode length: 170 Return: -426.50483466345855
INFO:tensorflow:Average training steps per second: 317.27
I0901 13:09:04.721609 140265790818304 replay_runner.py:36] Average training steps per second: 317.27
I0901 13:09:04.910085 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.86
INFO:tensorflow:Starting iteration 7

Steps executed: 254 Episode length: 96 Return: -210.433727837233455
INFO:tensorflow:Average training steps per second: 328.62
I0901 13:09:11.307973 140265790818304 replay_runner.py:36] Average training steps per second: 328.62
I0901 13:09:11.437709 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.20
INFO:tensorflow:Starting iteration 8

Steps executed: 240 Episode length: 240 Return: -140.74734475145725
INFO:tensorflow:Average training steps per second: 330.26
I0901 13:09:17.858522 140265790818304 replay_runner.py:36] Average training steps per second: 330.26
I0901 13:09:18.035043 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.75
INFO:tensorflow:Starting iteration 9

Steps executed: 205 Episode length: 89 Return: -147.800972370839793
INFO:tensorflow:Average training steps per second: 329.35
I0901 13:09:24.463221 140265790818304 replay_runner.py:36] Average training steps per second: 329.35
I0901 13:09:24.576514 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.27
INFO:tensorflow:Starting iteration 10

Steps executed: 307 Episode length: 203 Return: -81.706796412225196
INFO:tensorflow:Average training steps per second: 332.42
I0901 13:09:30.991824 140265790818304 replay_runner.py:36] Average training steps per second: 332.42
I0901 13:09:31.193129 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.33
INFO:tensorflow:Starting iteration 11

Steps executed: 311 Episode length: 157 Return: -47.452352176306866
INFO:tensorflow:Average training steps per second: 320.78
I0901 13:09:37.706573 140265790818304 replay_runner.py:36] Average training steps per second: 320.78
I0901 13:09:37.913074 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -32.53
INFO:tensorflow:Starting iteration 12

Steps executed: 284 Episode length: 105 Return: -64.934476675406943
INFO:tensorflow:Average training steps per second: 325.24
I0901 13:09:44.361475 140265790818304 replay_runner.py:36] Average training steps per second: 325.24
I0901 13:09:44.541631 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.10
INFO:tensorflow:Starting iteration 13

Steps executed: 224 Episode length: 101 Return: -139.62894939400313
INFO:tensorflow:Average training steps per second: 328.08
I0901 13:09:50.974588 140265790818304 replay_runner.py:36] Average training steps per second: 328.08
I0901 13:09:51.114656 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.60
INFO:tensorflow:Starting iteration 14

Steps executed: 498 Episode length: 381 Return: -137.89587593916693
INFO:tensorflow:Average training steps per second: 329.31
I0901 13:09:57.532205 140265790818304 replay_runner.py:36] Average training steps per second: 329.31
I0901 13:09:57.959765 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.23
INFO:tensorflow:Starting iteration 15
I0901 13:10:01.330160 140265790818304 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 331.34

Steps executed: 251 Episode length: 139 Return: -16.867328919092573
I0901 13:10:04.519344 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -55.24
INFO:tensorflow:Starting iteration 16

Steps executed: 337 Episode length: 144 Return: -26.277772570511928
INFO:tensorflow:Average training steps per second: 334.60
I0901 13:10:10.862920 140265790818304 replay_runner.py:36] Average training steps per second: 334.60
I0901 13:10:11.079930 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.73
INFO:tensorflow:Starting iteration 17

Steps executed: 241 Episode length: 180 Return: 22.0163224938146728
INFO:tensorflow:Average training steps per second: 331.51
I0901 13:10:17.479292 140265790818304 replay_runner.py:36] Average training steps per second: 331.51
I0901 13:10:17.637951 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -45.77
INFO:tensorflow:Starting iteration 18
I0901 13:10:20.993429 140265790818304 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 337.79
I0901 13:10:23.954192 140265790818304 replay_runner.py:36] Average training steps per second: 337.79

Steps executed: 455 Episode length: 455 Return: -72.085573937445868
INFO:tensorflow:Starting iteration 19

Steps executed: 258 Episode length: 103 Return: -136.85941226215917
INFO:tensorflow:Average training steps per second: 325.87
I0901 13:10:30.877820 140265790818304 replay_runner.py:36] Average training steps per second: 325.87
I0901 13:10:31.032561 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.48
INFO:tensorflow:Starting iteration 20

Steps executed: 227 Episode length: 109 Return: -82.161538737149167
INFO:tensorflow:Average training steps per second: 332.83
I0901 13:10:37.389093 140265790818304 replay_runner.py:36] Average training steps per second: 332.83
I0901 13:10:37.523413 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.53
INFO:tensorflow:Starting iteration 21

Steps executed: 247 Episode length: 125 Return: -86.357029200146774
INFO:tensorflow:Average training steps per second: 334.90
I0901 13:10:43.843756 140265790818304 replay_runner.py:36] Average training steps per second: 334.90
I0901 13:10:43.992721 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.59
INFO:tensorflow:Starting iteration 22

Steps executed: 221 Episode length: 221 Return: -42.979445710463084
INFO:tensorflow:Average training steps per second: 324.20
I0901 13:10:50.486091 140265790818304 replay_runner.py:36] Average training steps per second: 324.20
I0901 13:10:50.662567 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -42.98
INFO:tensorflow:Starting iteration 23
I0901 13:10:53.921983 140265790818304 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 337.20

Steps executed: 1000 Episode length: 1000 Return: -62.80469048026989
I0901 13:10:59.035022 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -62.80
INFO:tensorflow:Starting iteration 24
I0901 13:11:02.202468 140265790818304 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 320.99

Steps executed: 1000 Episode length: 1000 Return: -73.20703692090349
I0901 13:11:06.943268 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.21
INFO:tensorflow:Starting iteration 25

Steps executed: 202 Episode length: 202 Return: -37.9571956501173749
INFO:tensorflow:Average training steps per second: 333.88
I0901 13:11:13.217805 140265790818304 replay_runner.py:36] Average training steps per second: 333.88
I0901 13:11:13.340252 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.96
INFO:tensorflow:Starting iteration 26

Steps executed: 258 Episode length: 125 Return: -101.585500101981479
INFO:tensorflow:Average training steps per second: 318.96
I0901 13:11:19.551764 140265790818304 replay_runner.py:36] Average training steps per second: 318.96
I0901 13:11:19.692096 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.87
INFO:tensorflow:Starting iteration 27

Steps executed: 283 Episode length: 153 Return: -122.159460187808699
INFO:tensorflow:Average training steps per second: 324.09
I0901 13:11:25.907878 140265790818304 replay_runner.py:36] Average training steps per second: 324.09
I0901 13:11:26.075382 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.61
INFO:tensorflow:Starting iteration 28

Steps executed: 298 Episode length: 169 Return: -59.8026273020143349
INFO:tensorflow:Average training steps per second: 330.18
I0901 13:11:32.183407 140265790818304 replay_runner.py:36] Average training steps per second: 330.18
I0901 13:11:32.376594 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.70
INFO:tensorflow:Starting iteration 29

Steps executed: 132 Episode length: 132 Return: -51.2212737573178649
INFO:tensorflow:Average training steps per second: 350.54

Steps executed: 268 Episode length: 136 Return: -83.7341484667338649

Done fixed training!Episode length: 136 Return: -83.7341484667338649