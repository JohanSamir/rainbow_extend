Loaded trained dqn in cartpole
Training fixed agent 1, please be patient, may be a while...
I0901 12:43:20.647116 140321497724928 run_experiment.py:549] Creating TrainRunner ...
I0901 12:43:20.656742 140321497724928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:43:20.657063 140321497724928 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:43:20.657277 140321497724928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:43:20.657414 140321497724928 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:43:20.657555 140321497724928 dqn_agent.py:275] 	 update_period: 4
I0901 12:43:20.657686 140321497724928 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:43:20.657829 140321497724928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:43:20.657951 140321497724928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:43:20.658089 140321497724928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:43:20.658208 140321497724928 dqn_agent.py:280] 	 optimizer: adam
I0901 12:43:20.658281 140321497724928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:43:20.658350 140321497724928 dqn_agent.py:283] 	 seed: 1630500200656675
I0901 12:43:20.661910 140321497724928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:43:20.662203 140321497724928 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:43:20.662379 140321497724928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:43:20.662465 140321497724928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:43:20.662537 140321497724928 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:43:20.662604 140321497724928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:43:20.662673 140321497724928 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:43:20.662736 140321497724928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:43:20.662816 140321497724928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:43:20.706426 140321497724928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:43:21.252634 140321497724928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:43:21.269251 140321497724928 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:43:21.280561 140321497724928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:43:21.280867 140321497724928 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:43:21.281075 140321497724928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:43:21.281385 140321497724928 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:43:21.281658 140321497724928 dqn_agent.py:275] 	 update_period: 4
I0901 12:43:21.281808 140321497724928 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:43:21.281908 140321497724928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:43:21.282016 140321497724928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:43:21.282121 140321497724928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:43:21.282217 140321497724928 dqn_agent.py:280] 	 optimizer: adam
I0901 12:43:21.282341 140321497724928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:43:21.282497 140321497724928 dqn_agent.py:283] 	 seed: 1630500201280483
I0901 12:43:21.284859 140321497724928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:43:21.285021 140321497724928 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:43:21.285126 140321497724928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:43:21.285255 140321497724928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:43:21.285358 140321497724928 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:43:21.285512 140321497724928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:43:21.285604 140321497724928 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:43:21.285690 140321497724928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:43:21.285781 140321497724928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:43:21.321244 140321497724928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:43:21.344569 140321497724928 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:43:21.345191 140321497724928 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 143.67
I0901 12:43:28.305782 140321497724928 replay_runner.py:36] Average training steps per second: 143.67
I0901 12:43:29.375393 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.23
INFO:tensorflow:Starting iteration 1
I0901 12:43:29.566947 140321497724928 replay_runner.py:41] Starting iteration 1
Steps executed: 203 Episode length: 9 Return: 9.0.0
INFO:tensorflow:Average training steps per second: 188.38
I0901 12:43:34.875923 140321497724928 replay_runner.py:36] Average training steps per second: 188.38
I0901 12:43:35.035344 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.27
INFO:tensorflow:Starting iteration 2

Steps executed: 204 Episode length: 9 Return: 9.0.0
INFO:tensorflow:Average training steps per second: 192.35
I0901 12:43:40.432211 140321497724928 replay_runner.py:36] Average training steps per second: 192.35
I0901 12:43:40.581558 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 69.00
INFO:tensorflow:Starting iteration 3

Steps executed: 207 Episode length: 69 Return: 69.0
INFO:tensorflow:Average training steps per second: 187.98
I0901 12:43:46.083383 140321497724928 replay_runner.py:36] Average training steps per second: 187.98

Steps executed: 332 Episode length: 200 Return: 200.0
INFO:tensorflow:Starting iteration 4

Steps executed: 328 Episode length: 194 Return: 194.0
INFO:tensorflow:Average training steps per second: 186.87
I0901 12:43:51.859537 140321497724928 replay_runner.py:36] Average training steps per second: 186.87
I0901 12:43:52.099971 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 164.00
INFO:tensorflow:Starting iteration 5

Steps executed: 360 Episode length: 164 Return: 164.0
INFO:tensorflow:Average training steps per second: 188.05
I0901 12:43:57.615676 140321497724928 replay_runner.py:36] Average training steps per second: 188.05
I0901 12:43:57.874996 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 180.00
INFO:tensorflow:Starting iteration 6
I0901 12:43:58.108143 140321497724928 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 189.99
I0901 12:44:03.379925 140321497724928 replay_runner.py:36] Average training steps per second: 189.99
I0901 12:44:03.528706 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 69.00
INFO:tensorflow:Starting iteration 7


Steps executed: 352 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 193.04
I0901 12:44:08.903953 140321497724928 replay_runner.py:36] Average training steps per second: 193.04
I0901 12:44:09.170881 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 176.00
INFO:tensorflow:Starting iteration 8

Steps executed: 123 Episode length: 123 Return: 123.0
INFO:tensorflow:Average training steps per second: 195.35

Steps executed: 261 Episode length: 138 Return: 138.0
I0901 12:44:14.666861 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 130.50
INFO:tensorflow:Starting iteration 9

Steps executed: 229 Episode length: 77 Return: 77.0.0
INFO:tensorflow:Average training steps per second: 192.33
I0901 12:44:20.063307 140321497724928 replay_runner.py:36] Average training steps per second: 192.33
I0901 12:44:20.214391 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 76.33
INFO:tensorflow:Starting iteration 10

Steps executed: 255 Episode length: 85 Return: 85.0.0
INFO:tensorflow:Average training steps per second: 200.41
I0901 12:44:25.394545 140321497724928 replay_runner.py:36] Average training steps per second: 200.41
I0901 12:44:25.573229 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 85.00
INFO:tensorflow:Starting iteration 11

Steps executed: 220 Episode length: 45 Return: 45.0.0
INFO:tensorflow:Average training steps per second: 191.68
I0901 12:44:30.984992 140321497724928 replay_runner.py:36] Average training steps per second: 191.68
I0901 12:44:31.135533 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 44.00
INFO:tensorflow:Starting iteration 12

Steps executed: 203 Episode length: 38 Return: 38.0.0
INFO:tensorflow:Average training steps per second: 191.93
I0901 12:44:36.547003 140321497724928 replay_runner.py:36] Average training steps per second: 191.93
I0901 12:44:36.698053 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 40.60
INFO:tensorflow:Starting iteration 13

Steps executed: 242 Episode length: 43 Return: 43.0.0
INFO:tensorflow:Average training steps per second: 192.42
I0901 12:44:42.093212 140321497724928 replay_runner.py:36] Average training steps per second: 192.42
I0901 12:44:42.269909 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 40.33
INFO:tensorflow:Starting iteration 14

Steps executed: 209 Episode length: 49 Return: 49.0.0
INFO:tensorflow:Average training steps per second: 188.85
I0901 12:44:47.753342 140321497724928 replay_runner.py:36] Average training steps per second: 188.85
I0901 12:44:47.902760 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 52.25
INFO:tensorflow:Starting iteration 15

Steps executed: 223 Episode length: 55 Return: 55.0.0
INFO:tensorflow:Average training steps per second: 186.92
I0901 12:44:53.464601 140321497724928 replay_runner.py:36] Average training steps per second: 186.92
I0901 12:44:53.644230 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 55.75
INFO:tensorflow:Starting iteration 16

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 190.65
I0901 12:44:59.086281 140321497724928 replay_runner.py:36] Average training steps per second: 190.65
I0901 12:44:59.220237 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 17

Steps executed: 304 Episode length: 144 Return: 144.0
INFO:tensorflow:Average training steps per second: 185.61
I0901 12:45:04.806787 140321497724928 replay_runner.py:36] Average training steps per second: 185.61
I0901 12:45:05.013010 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 152.00
INFO:tensorflow:Starting iteration 18

Steps executed: 217 Episode length: 60 Return: 60.0.0
INFO:tensorflow:Average training steps per second: 193.83
I0901 12:45:10.368562 140321497724928 replay_runner.py:36] Average training steps per second: 193.83
I0901 12:45:10.521977 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 54.25
INFO:tensorflow:Starting iteration 19

Steps executed: 374 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 185.91
I0901 12:45:16.100814 140321497724928 replay_runner.py:36] Average training steps per second: 185.91
I0901 12:45:16.361114 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 187.00
INFO:tensorflow:Starting iteration 20

Steps executed: 261 Episode length: 86 Return: 86.0.0
INFO:tensorflow:Average training steps per second: 184.19
I0901 12:45:21.979062 140321497724928 replay_runner.py:36] Average training steps per second: 184.19
I0901 12:45:22.189829 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 87.00
INFO:tensorflow:Starting iteration 21

Steps executed: 222 Episode length: 54 Return: 54.0.0
INFO:tensorflow:Average training steps per second: 190.36
I0901 12:45:27.628377 140321497724928 replay_runner.py:36] Average training steps per second: 190.36
I0901 12:45:27.791989 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 55.50
INFO:tensorflow:Starting iteration 22

Steps executed: 245 Episode length: 88 Return: 88.0.0
INFO:tensorflow:Average training steps per second: 193.38
I0901 12:45:33.163487 140321497724928 replay_runner.py:36] Average training steps per second: 193.38
I0901 12:45:33.328225 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 81.67
INFO:tensorflow:Starting iteration 23

Steps executed: 263 Episode length: 94 Return: 94.0.0
INFO:tensorflow:Average training steps per second: 183.91
I0901 12:45:38.958108 140321497724928 replay_runner.py:36] Average training steps per second: 183.91
I0901 12:45:39.133520 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 87.67
INFO:tensorflow:Starting iteration 24

Steps executed: 287 Episode length: 99 Return: 99.0.0
INFO:tensorflow:Average training steps per second: 197.93
I0901 12:45:44.372330 140321497724928 replay_runner.py:36] Average training steps per second: 197.93
I0901 12:45:44.572236 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 95.67
INFO:tensorflow:Starting iteration 25

Steps executed: 283 Episode length: 86 Return: 86.0.0
INFO:tensorflow:Average training steps per second: 182.66
I0901 12:45:50.238150 140321497724928 replay_runner.py:36] Average training steps per second: 182.66
I0901 12:45:50.425162 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 94.33
INFO:tensorflow:Starting iteration 26

Steps executed: 297 Episode length: 99 Return: 99.0.0
INFO:tensorflow:Average training steps per second: 192.31
I0901 12:45:55.819838 140321497724928 replay_runner.py:36] Average training steps per second: 192.31
I0901 12:45:56.051056 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 99.00
INFO:tensorflow:Starting iteration 27

Steps executed: 273 Episode length: 90 Return: 90.0.0
INFO:tensorflow:Average training steps per second: 186.36
I0901 12:46:01.608972 140321497724928 replay_runner.py:36] Average training steps per second: 186.36
I0901 12:46:01.799361 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 91.00
INFO:tensorflow:Starting iteration 28

Steps executed: 286 Episode length: 145 Return: 145.0
INFO:tensorflow:Average training steps per second: 192.75
I0901 12:46:07.168023 140321497724928 replay_runner.py:36] Average training steps per second: 192.75
I0901 12:46:07.376799 140321497724928 run_experiment.py:428] Average undiscounted return per evaluation episode: 143.00
INFO:tensorflow:Starting iteration 29

Steps executed: 212 Episode length: 107 Return: 107.0
INFO:tensorflow:Average training steps per second: 191.98
I0901 12:46:12.781655 140321497724928 replay_runner.py:36] Average training steps per second: 191.98

Done fixed training!Episode length: 107 Return: 107.0