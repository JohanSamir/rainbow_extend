Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0902 23:35:34.723872 140457530894336 run_experiment.py:549] Creating TrainRunner ...
I0902 23:35:34.735456 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:35:34.735725 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:35:34.735892 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:35:34.736003 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:35:34.736208 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0902 23:35:34.736324 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:35:34.736423 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:35:34.736565 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:35:34.736662 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:35:34.736781 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0902 23:35:34.736871 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:35:34.736956 140457530894336 dqn_agent.py:283] 	 seed: 1630625734735381
I0902 23:35:34.739781 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:35:34.740033 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:35:34.740161 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:35:34.740269 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:35:34.740390 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:35:34.740488 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:35:34.740581 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:35:34.740668 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:35:34.740754 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:35:34.777944 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:35:35.161055 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:35:35.175993 140457530894336 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:35:35.184695 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:35:35.185007 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:35:35.185174 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:35:35.185296 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:35:35.185534 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0902 23:35:35.185759 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:35:35.185908 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:35:35.186054 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:35:35.186220 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:35:35.186396 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0902 23:35:35.186627 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:35:35.186768 140457530894336 dqn_agent.py:283] 	 seed: 1630625735184643
I0902 23:35:35.189506 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:35:35.189701 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:35:35.189855 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:35:35.189985 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:35:35.190224 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:35:35.190332 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:35:35.190453 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:35:35.190584 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:35:35.190699 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:35:35.265614 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:35:35.287071 140457530894336 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:35:35.287282 140457530894336 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.84
I0902 23:35:41.428839 140457530894336 replay_runner.py:36] Average training steps per second: 162.84
Steps executed: 276 Episode length: 276 Return: -312.90906381874015
I0902 23:35:42.837335 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -312.91
INFO:tensorflow:Starting iteration 1

Steps executed: 456 Episode length: 312 Return: 244.947048832373154
INFO:tensorflow:Average training steps per second: 215.89
I0902 23:35:51.731919 140457530894336 replay_runner.py:36] Average training steps per second: 215.89
I0902 23:35:52.283415 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -40.57
INFO:tensorflow:Starting iteration 2

Steps executed: 388 Episode length: 388 Return: -425.25462926415724
INFO:tensorflow:Average training steps per second: 220.38
I0902 23:36:01.192276 140457530894336 replay_runner.py:36] Average training steps per second: 220.38
I0902 23:36:01.842032 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -425.25
INFO:tensorflow:Starting iteration 3

Steps executed: 350 Episode length: 350 Return: -258.68632559938284
INFO:tensorflow:Average training steps per second: 219.90
I0902 23:36:10.784052 140457530894336 replay_runner.py:36] Average training steps per second: 219.90
I0902 23:36:11.323263 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.69
INFO:tensorflow:Starting iteration 4
I0902 23:36:15.723583 140457530894336 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 220.11

Steps executed: 1000 Episode length: 1000 Return: -24.64392622428501
I0902 23:36:24.411694 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -24.64
INFO:tensorflow:Starting iteration 5
I0902 23:36:28.706849 140457530894336 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 232.05

Steps executed: 1000 Episode length: 1000 Return: -84.75823126061948
I0902 23:36:34.893767 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.76
INFO:tensorflow:Starting iteration 6

Steps executed: 108 Episode length: 108 Return: -126.461316219697948
INFO:tensorflow:Average training steps per second: 233.34

Steps executed: 1108 Episode length: 1000 Return: -129.78478779690184
I0902 23:36:46.485466 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.12
INFO:tensorflow:Starting iteration 7
I0902 23:36:50.862415 140457530894336 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 237.02

Steps executed: 1000 Episode length: 1000 Return: -59.593469904430694
I0902 23:36:58.217525 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -59.59
INFO:tensorflow:Starting iteration 8
I0902 23:37:02.537317 140457530894336 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 224.58
I0902 23:37:06.990598 140457530894336 replay_runner.py:36] Average training steps per second: 224.58

Steps executed: 852 Episode length: 852 Return: -438.8404365729599694
INFO:tensorflow:Starting iteration 9
I0902 23:37:13.051472 140457530894336 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 226.77

Steps executed: 1000 Episode length: 1000 Return: -158.37855879394654
I0902 23:37:21.141952 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.38
INFO:tensorflow:Starting iteration 10
I0902 23:37:25.485408 140457530894336 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 235.49

Steps executed: 1000 Episode length: 1000 Return: -125.86486845543452
I0902 23:37:32.598998 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.86
INFO:tensorflow:Starting iteration 11

Steps executed: 351 Episode length: 351 Return: -756.0818202551523452
INFO:tensorflow:Average training steps per second: 227.77
I0902 23:37:41.194057 140457530894336 replay_runner.py:36] Average training steps per second: 227.77
I0902 23:37:41.648185 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -756.08
INFO:tensorflow:Starting iteration 12
I0902 23:37:45.991319 140457530894336 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 228.98

Steps executed: 1000 Episode length: 1000 Return: -138.59029972370703
I0902 23:37:53.638879 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.59
INFO:tensorflow:Starting iteration 13
I0902 23:37:57.882907 140457530894336 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 206.16

Steps executed: 1000 Episode length: 1000 Return: -187.13492538545964
I0902 23:38:06.800821 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.13
INFO:tensorflow:Starting iteration 14

Steps executed: 349 Episode length: 349 Return: -253.0957671785305964
INFO:tensorflow:Average training steps per second: 224.61
I0902 23:38:15.470418 140457530894336 replay_runner.py:36] Average training steps per second: 224.61
I0902 23:38:15.873820 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.10
INFO:tensorflow:Starting iteration 15

Steps executed: 222 Episode length: 222 Return: -210.3681950998117764
INFO:tensorflow:Average training steps per second: 230.17
I0902 23:38:24.618683 140457530894336 replay_runner.py:36] Average training steps per second: 230.17
I0902 23:38:24.845026 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.37
INFO:tensorflow:Starting iteration 16

Steps executed: 225 Episode length: 225 Return: -426.4536571315516764
INFO:tensorflow:Average training steps per second: 229.79
I0902 23:38:33.641786 140457530894336 replay_runner.py:36] Average training steps per second: 229.79
I0902 23:38:33.882764 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -426.45
INFO:tensorflow:Starting iteration 17

Steps executed: 310 Episode length: 113 Return: -656.4231810593205764
INFO:tensorflow:Average training steps per second: 223.71
I0902 23:38:42.731855 140457530894336 replay_runner.py:36] Average training steps per second: 223.71
I0902 23:38:43.028464 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -571.92
INFO:tensorflow:Starting iteration 18

Steps executed: 293 Episode length: 156 Return: -129.5589162289146564
INFO:tensorflow:Average training steps per second: 225.17
I0902 23:38:51.935548 140457530894336 replay_runner.py:36] Average training steps per second: 225.17
I0902 23:38:52.203526 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.34
INFO:tensorflow:Starting iteration 19
I0902 23:38:56.644058 140457530894336 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 226.14

Steps executed: 316 Episode length: 316 Return: -475.9582351744135564
I0902 23:39:01.504463 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -475.96
INFO:tensorflow:Starting iteration 20

Steps executed: 176 Episode length: 176 Return: -120.1869928007893764
INFO:tensorflow:Average training steps per second: 223.73
I0902 23:39:10.427324 140457530894336 replay_runner.py:36] Average training steps per second: 223.73

Steps executed: 407 Episode length: 231 Return: -677.1573677361728764
INFO:tensorflow:Starting iteration 21

Steps executed: 325 Episode length: 149 Return: -95.71245898361849864
INFO:tensorflow:Average training steps per second: 226.71
I0902 23:39:19.784779 140457530894336 replay_runner.py:36] Average training steps per second: 226.71
I0902 23:39:20.090203 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.60
INFO:tensorflow:Starting iteration 22
I0902 23:39:24.523780 140457530894336 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 227.66
I0902 23:39:28.916880 140457530894336 replay_runner.py:36] Average training steps per second: 227.66

Steps executed: 204 Episode length: 86 Return: -723.65282688206386864
INFO:tensorflow:Starting iteration 23

Steps executed: 260 Episode length: 260 Return: -199.6614732802693264
INFO:tensorflow:Average training steps per second: 226.39
I0902 23:39:37.912298 140457530894336 replay_runner.py:36] Average training steps per second: 226.39
I0902 23:39:38.265935 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.66
INFO:tensorflow:Starting iteration 24
I0902 23:39:42.582936 140457530894336 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 225.56

Steps executed: 269 Episode length: 269 Return: -180.9377748960149264
I0902 23:39:47.379257 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.94
INFO:tensorflow:Starting iteration 25

Steps executed: 258 Episode length: 258 Return: 10.835178007140527264
INFO:tensorflow:Average training steps per second: 235.58
I0902 23:39:56.113780 140457530894336 replay_runner.py:36] Average training steps per second: 235.58
I0902 23:39:56.415702 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: 10.84
INFO:tensorflow:Starting iteration 26
I0902 23:40:00.789197 140457530894336 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 220.74

Steps executed: 510 Episode length: 510 Return: -549.9853191154453264
I0902 23:40:06.261789 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -549.99
INFO:tensorflow:Starting iteration 27
I0902 23:40:10.706950 140457530894336 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 227.04
I0902 23:40:15.112167 140457530894336 replay_runner.py:36] Average training steps per second: 227.04

Steps executed: 216 Episode length: 216 Return: -509.9192409276600464
INFO:tensorflow:Starting iteration 28

Steps executed: 232 Episode length: 81 Return: -199.92556829528752464
INFO:tensorflow:Average training steps per second: 229.88
I0902 23:40:24.061770 140457530894336 replay_runner.py:36] Average training steps per second: 229.88
I0902 23:40:24.222037 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.10
INFO:tensorflow:Starting iteration 29

Steps executed: 204 Episode length: 75 Return: -87.025922058985943564
INFO:tensorflow:Average training steps per second: 243.09
I0902 23:40:32.700774 140457530894336 replay_runner.py:36] Average training steps per second: 243.09

Done fixed training!Episode length: 75 Return: -87.025922058985943564