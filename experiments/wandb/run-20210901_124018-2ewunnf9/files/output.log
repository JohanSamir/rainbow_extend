Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0901 12:40:26.511987 140460307478528 run_experiment.py:549] Creating TrainRunner ...
I0901 12:40:26.523813 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:40:26.524274 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:40:26.524777 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:40:26.525015 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:40:26.525196 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 12:40:26.525400 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:40:26.525516 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:40:26.525782 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:40:26.525963 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:40:26.526063 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 12:40:26.526181 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:40:26.526242 140460307478528 dqn_agent.py:283] 	 seed: 1630500026523743
I0901 12:40:26.528747 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:40:26.528879 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:40:26.528950 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:40:26.529008 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:40:26.529060 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:40:26.529108 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:40:26.529156 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:40:26.529201 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:40:26.529247 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:40:26.605284 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:40:27.353607 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:40:27.369428 140460307478528 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:40:27.378531 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:40:27.378803 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:40:27.378962 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:40:27.379092 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:40:27.379201 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 12:40:27.379362 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:40:27.379600 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:40:27.379733 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:40:27.379844 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:40:27.380018 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 12:40:27.380153 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:40:27.380258 140460307478528 dqn_agent.py:283] 	 seed: 1630500027378469
I0901 12:40:27.383430 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:40:27.383660 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:40:27.383800 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:40:27.383964 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:40:27.384094 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:40:27.384299 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:40:27.384437 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:40:27.384552 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:40:27.384723 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:40:27.420303 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:40:27.443788 140460307478528 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:40:27.444109 140460307478528 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 159.79
I0901 12:40:33.702686 140460307478528 replay_runner.py:36] Average training steps per second: 159.79
Steps executed: 240 Episode length: 150 Return: -226.7813910670318
I0901 12:40:34.966842 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.36
INFO:tensorflow:Starting iteration 1
I0901 12:40:39.435274 140460307478528 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 214.15

Steps executed: 237 Episode length: 140 Return: -65.25098899627739
I0901 12:40:44.324851 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.96
INFO:tensorflow:Starting iteration 2

Steps executed: 236 Episode length: 121 Return: -241.01767769296646
INFO:tensorflow:Average training steps per second: 218.75
I0901 12:40:53.355384 140460307478528 replay_runner.py:36] Average training steps per second: 218.75
I0901 12:40:53.591432 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.07
INFO:tensorflow:Starting iteration 3

Steps executed: 236 Episode length: 116 Return: -245.39299310666576
INFO:tensorflow:Average training steps per second: 221.06
I0901 12:41:02.413823 140460307478528 replay_runner.py:36] Average training steps per second: 221.06
I0901 12:41:02.607532 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.16
INFO:tensorflow:Starting iteration 4

Steps executed: 282 Episode length: 122 Return: -268.30969298774437
INFO:tensorflow:Average training steps per second: 219.55
I0901 12:41:11.465683 140460307478528 replay_runner.py:36] Average training steps per second: 219.55
I0901 12:41:11.700564 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -302.05
INFO:tensorflow:Starting iteration 5

Steps executed: 266 Episode length: 266 Return: -217.41582218641474
INFO:tensorflow:Average training steps per second: 217.29
I0901 12:41:20.616016 140460307478528 replay_runner.py:36] Average training steps per second: 217.29
I0901 12:41:20.934989 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.42
INFO:tensorflow:Starting iteration 6

Steps executed: 280 Episode length: 141 Return: -184.35702430499708
INFO:tensorflow:Average training steps per second: 219.86
I0901 12:41:29.855051 140460307478528 replay_runner.py:36] Average training steps per second: 219.86
I0901 12:41:30.116559 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.93
INFO:tensorflow:Starting iteration 7

Steps executed: 276 Episode length: 117 Return: -163.65152671203418
INFO:tensorflow:Average training steps per second: 217.38
I0901 12:41:39.167320 140460307478528 replay_runner.py:36] Average training steps per second: 217.38
I0901 12:41:39.401766 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.70
INFO:tensorflow:Starting iteration 8
I0901 12:41:43.838557 140460307478528 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 215.59

Steps executed: 267 Episode length: 85 Return: -274.865639165912588
I0901 12:41:48.682219 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.62
INFO:tensorflow:Starting iteration 9

Steps executed: 247 Episode length: 89 Return: -407.200696255361958
INFO:tensorflow:Average training steps per second: 210.22
I0901 12:41:57.821325 140460307478528 replay_runner.py:36] Average training steps per second: 210.22
I0901 12:41:58.014177 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.93
INFO:tensorflow:Starting iteration 10

Steps executed: 223 Episode length: 60 Return: -206.061601604512658
INFO:tensorflow:Average training steps per second: 212.97
I0901 12:42:07.148115 140460307478528 replay_runner.py:36] Average training steps per second: 212.97
I0901 12:42:07.331043 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.38
INFO:tensorflow:Starting iteration 11

Steps executed: 251 Episode length: 63 Return: -145.520908711998126
INFO:tensorflow:Average training steps per second: 213.48
I0901 12:42:16.243169 140460307478528 replay_runner.py:36] Average training steps per second: 213.48
I0901 12:42:16.463387 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.92
INFO:tensorflow:Starting iteration 12

Steps executed: 209 Episode length: 57 Return: -339.944836279777866
INFO:tensorflow:Average training steps per second: 214.86
I0901 12:42:25.539672 140460307478528 replay_runner.py:36] Average training steps per second: 214.86
I0901 12:42:25.716140 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -469.43
INFO:tensorflow:Starting iteration 13

Steps executed: 285 Episode length: 285 Return: -156.52780082802144
INFO:tensorflow:Average training steps per second: 215.76
I0901 12:42:34.806693 140460307478528 replay_runner.py:36] Average training steps per second: 215.76
I0901 12:42:35.236543 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.53
INFO:tensorflow:Starting iteration 14

Steps executed: 213 Episode length: 70 Return: -123.043083504480937
INFO:tensorflow:Average training steps per second: 216.51
I0901 12:42:44.257111 140460307478528 replay_runner.py:36] Average training steps per second: 216.51
I0901 12:42:44.442909 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.09
INFO:tensorflow:Starting iteration 15

Steps executed: 210 Episode length: 210 Return: -314.45919063822106
INFO:tensorflow:Average training steps per second: 224.58
I0901 12:42:53.165426 140460307478528 replay_runner.py:36] Average training steps per second: 224.58
I0901 12:42:53.377455 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.46
INFO:tensorflow:Starting iteration 16

Steps executed: 69 Episode length: 69 Return: -401.9263461825027506
INFO:tensorflow:Average training steps per second: 223.38

Steps executed: 1006 Episode length: 937 Return: -319.07216871564975
I0901 12:43:04.431541 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -360.50
INFO:tensorflow:Starting iteration 17

Steps executed: 280 Episode length: 101 Return: -63.3688826804541775
INFO:tensorflow:Average training steps per second: 226.08
I0901 12:43:13.281638 140460307478528 replay_runner.py:36] Average training steps per second: 226.08
I0901 12:43:13.512659 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -41.66
INFO:tensorflow:Starting iteration 18

Steps executed: 140 Episode length: 71 Return: -310.0485333868207775
INFO:tensorflow:Average training steps per second: 234.07
I0901 12:43:22.262040 140460307478528 replay_runner.py:36] Average training steps per second: 234.07

Steps executed: 238 Episode length: 98 Return: -185.6335603857106775
INFO:tensorflow:Starting iteration 19

Steps executed: 350 Episode length: 207 Return: -1435.43583005110055
INFO:tensorflow:Average training steps per second: 221.80
I0901 12:43:31.268399 140460307478528 replay_runner.py:36] Average training steps per second: 221.80
I0901 12:43:31.636611 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -852.84
INFO:tensorflow:Starting iteration 20
I0901 12:43:36.028130 140460307478528 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 215.92
I0901 12:43:40.659758 140460307478528 replay_runner.py:36] Average training steps per second: 215.92

Steps executed: 224 Episode length: 99 Return: -384.0592996842694355
INFO:tensorflow:Starting iteration 21

Steps executed: 228 Episode length: 164 Return: -111.382288878211575
INFO:tensorflow:Average training steps per second: 223.26
I0901 12:43:49.889513 140460307478528 replay_runner.py:36] Average training steps per second: 223.26
I0901 12:43:50.112480 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.22
INFO:tensorflow:Starting iteration 22

Steps executed: 213 Episode length: 64 Return: -263.4927995009410375
INFO:tensorflow:Average training steps per second: 215.11
I0901 12:43:59.244326 140460307478528 replay_runner.py:36] Average training steps per second: 215.11
I0901 12:43:59.427483 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -447.12
INFO:tensorflow:Starting iteration 23

Steps executed: 258 Episode length: 85 Return: -558.6029073580594375
INFO:tensorflow:Average training steps per second: 217.31
I0901 12:44:08.401164 140460307478528 replay_runner.py:36] Average training steps per second: 217.31
I0901 12:44:08.646258 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -537.08
INFO:tensorflow:Starting iteration 24

Steps executed: 215 Episode length: 71 Return: -297.7057263076290775
INFO:tensorflow:Average training steps per second: 221.40
I0901 12:44:17.543244 140460307478528 replay_runner.py:36] Average training steps per second: 221.40
I0901 12:44:17.741813 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.20
INFO:tensorflow:Starting iteration 25

Steps executed: 81 Episode length: 81 Return: -556.29795211423960775
INFO:tensorflow:Average training steps per second: 222.91

Steps executed: 266 Episode length: 69 Return: -575.3863921875839775
I0901 12:44:26.881703 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -541.24
INFO:tensorflow:Starting iteration 26

Steps executed: 217 Episode length: 61 Return: -434.9113445110119275
INFO:tensorflow:Average training steps per second: 223.73
I0901 12:44:35.837263 140460307478528 replay_runner.py:36] Average training steps per second: 223.73
I0901 12:44:36.043725 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -445.17
INFO:tensorflow:Starting iteration 27
I0901 12:44:40.337319 140460307478528 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 221.50

Steps executed: 255 Episode length: 82 Return: -769.5532423146817575
I0901 12:44:45.096622 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -614.64
INFO:tensorflow:Starting iteration 28

Steps executed: 231 Episode length: 78 Return: -572.3156800167428575
INFO:tensorflow:Average training steps per second: 218.48
I0901 12:44:54.126692 140460307478528 replay_runner.py:36] Average training steps per second: 218.48
I0901 12:44:54.324416 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -518.03
INFO:tensorflow:Starting iteration 29

Steps executed: 241 Episode length: 53 Return: -474.4596493661225575
INFO:tensorflow:Average training steps per second: 214.14
I0901 12:45:03.450940 140460307478528 replay_runner.py:36] Average training steps per second: 214.14

Done fixed training!Episode length: 53 Return: -474.4596493661225575