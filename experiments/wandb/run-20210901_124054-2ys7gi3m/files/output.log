Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0901 12:41:00.767940 140536266098688 run_experiment.py:549] Creating TrainRunner ...
I0901 12:41:00.779852 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:41:00.780176 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:41:00.780441 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:41:00.780571 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:41:00.780659 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 12:41:00.780794 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:41:00.781510 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:41:00.781891 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:41:00.782058 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:41:00.782225 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 12:41:00.782347 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:41:00.782456 140536266098688 dqn_agent.py:283] 	 seed: 1630500060779779
I0901 12:41:00.786149 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:41:00.786335 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:41:00.786540 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:41:00.786640 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:41:00.786751 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:41:00.786831 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:41:00.786983 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:41:00.787227 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:41:00.787462 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:41:00.875519 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:41:01.332292 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:41:01.344609 140536266098688 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:41:01.352856 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:41:01.353212 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:41:01.353677 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:41:01.353801 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:41:01.353898 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 12:41:01.353979 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:41:01.354065 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:41:01.354166 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:41:01.354246 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:41:01.354489 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 12:41:01.354607 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:41:01.354691 140536266098688 dqn_agent.py:283] 	 seed: 1630500061352792
I0901 12:41:01.356906 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:41:01.357075 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:41:01.357197 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:41:01.357289 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:41:01.357370 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:41:01.357450 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:41:01.357524 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:41:01.357606 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:41:01.357695 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:41:01.390584 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:41:01.414811 140536266098688 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:41:01.415359 140536266098688 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 163.13
I0901 12:41:07.546007 140536266098688 replay_runner.py:36] Average training steps per second: 163.13
Steps executed: 300 Episode length: 142 Return: -412.7621517256396
I0901 12:41:08.875334 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -434.57
INFO:tensorflow:Starting iteration 1

Steps executed: 255 Episode length: 165 Return: -86.37765781715595
INFO:tensorflow:Average training steps per second: 217.79
I0901 12:41:17.819470 140536266098688 replay_runner.py:36] Average training steps per second: 217.79
I0901 12:41:18.058042 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.83
INFO:tensorflow:Starting iteration 2

Steps executed: 330 Episode length: 135 Return: -447.00106258055865
INFO:tensorflow:Average training steps per second: 221.31
I0901 12:41:26.967642 140536266098688 replay_runner.py:36] Average training steps per second: 221.31
I0901 12:41:27.268353 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.48
INFO:tensorflow:Starting iteration 3

Steps executed: 245 Episode length: 125 Return: -70.809822738032765
INFO:tensorflow:Average training steps per second: 215.92
I0901 12:41:36.174669 140536266098688 replay_runner.py:36] Average training steps per second: 215.92
I0901 12:41:36.413081 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.56
INFO:tensorflow:Starting iteration 4

Steps executed: 294 Episode length: 153 Return: -314.30239910490525
INFO:tensorflow:Average training steps per second: 215.57
I0901 12:41:45.436350 140536266098688 replay_runner.py:36] Average training steps per second: 215.57
I0901 12:41:45.708275 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.76
INFO:tensorflow:Starting iteration 5

Steps executed: 70 Episode length: 70 Return: -158.2417514977077825
INFO:tensorflow:Average training steps per second: 227.77

Steps executed: 321 Episode length: 124 Return: -267.00225061737314
I0901 12:41:54.733522 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.66
INFO:tensorflow:Starting iteration 6

Steps executed: 219 Episode length: 87 Return: -240.903130475762234
INFO:tensorflow:Average training steps per second: 214.95
I0901 12:42:03.801059 140536266098688 replay_runner.py:36] Average training steps per second: 214.95
I0901 12:42:03.995414 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.09
INFO:tensorflow:Starting iteration 7

Steps executed: 232 Episode length: 76 Return: -355.798975347537344
INFO:tensorflow:Average training steps per second: 209.97
I0901 12:42:13.155095 140536266098688 replay_runner.py:36] Average training steps per second: 209.97
I0901 12:42:13.362998 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.46
INFO:tensorflow:Starting iteration 8

Steps executed: 263 Episode length: 87 Return: -217.764274496911206
INFO:tensorflow:Average training steps per second: 216.62
I0901 12:42:22.324301 140536266098688 replay_runner.py:36] Average training steps per second: 216.62
I0901 12:42:22.566190 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.71
INFO:tensorflow:Starting iteration 9

Steps executed: 207 Episode length: 99 Return: -636.964086832686666
INFO:tensorflow:Average training steps per second: 221.19
I0901 12:42:31.518873 140536266098688 replay_runner.py:36] Average training steps per second: 221.19
I0901 12:42:31.704832 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -383.74
INFO:tensorflow:Starting iteration 10

Steps executed: 145 Episode length: 61 Return: -66.3659048274864766
INFO:tensorflow:Average training steps per second: 218.43
I0901 12:42:40.603501 140536266098688 replay_runner.py:36] Average training steps per second: 218.43

Steps executed: 234 Episode length: 89 Return: -39.8250039573736866
INFO:tensorflow:Starting iteration 11

Steps executed: 273 Episode length: 89 Return: -131.544950350512566
INFO:tensorflow:Average training steps per second: 218.09
I0901 12:42:49.601782 140536266098688 replay_runner.py:36] Average training steps per second: 218.09
I0901 12:42:49.820097 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -239.66
INFO:tensorflow:Starting iteration 12

Steps executed: 106 Episode length: 106 Return: -352.27807280697823
INFO:tensorflow:Average training steps per second: 221.04

Steps executed: 247 Episode length: 70 Return: -222.660544868820073
I0901 12:42:58.968261 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.69
INFO:tensorflow:Starting iteration 13

Steps executed: 217 Episode length: 77 Return: -400.115312087094543
INFO:tensorflow:Average training steps per second: 220.38
I0901 12:43:07.933799 140536266098688 replay_runner.py:36] Average training steps per second: 220.38
I0901 12:43:08.127987 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -403.07
INFO:tensorflow:Starting iteration 14
I0901 12:43:12.495212 140536266098688 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 225.04

Steps executed: 288 Episode length: 94 Return: -364.184009623795243
I0901 12:43:17.181115 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -360.89
INFO:tensorflow:Starting iteration 15

Steps executed: 244 Episode length: 168 Return: -224.68361443931823
INFO:tensorflow:Average training steps per second: 220.86
I0901 12:43:26.111274 140536266098688 replay_runner.py:36] Average training steps per second: 220.86
I0901 12:43:26.332541 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.18
INFO:tensorflow:Starting iteration 16

Steps executed: 255 Episode length: 60 Return: -111.171618821247225
INFO:tensorflow:Average training steps per second: 216.80
I0901 12:43:35.294216 140536266098688 replay_runner.py:36] Average training steps per second: 216.80
I0901 12:43:35.541084 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -547.05
INFO:tensorflow:Starting iteration 17

Steps executed: 208 Episode length: 68 Return: -373.240925808170325
INFO:tensorflow:Average training steps per second: 209.71
I0901 12:43:44.589386 140536266098688 replay_runner.py:36] Average training steps per second: 209.71
I0901 12:43:44.761089 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -330.44
INFO:tensorflow:Starting iteration 18

Steps executed: 264 Episode length: 73 Return: -336.547326896841475
INFO:tensorflow:Average training steps per second: 215.35
I0901 12:43:53.816853 140536266098688 replay_runner.py:36] Average training steps per second: 215.35
I0901 12:43:54.044589 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -392.91
INFO:tensorflow:Starting iteration 19
I0901 12:43:58.286547 140536266098688 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 219.68
I0901 12:44:02.839190 140536266098688 replay_runner.py:36] Average training steps per second: 219.68

Steps executed: 260 Episode length: 81 Return: -355.507149809882675
INFO:tensorflow:Starting iteration 20

Steps executed: 251 Episode length: 81 Return: -294.766042765664365
INFO:tensorflow:Average training steps per second: 220.52
I0901 12:44:12.003289 140536266098688 replay_runner.py:36] Average training steps per second: 220.52
I0901 12:44:12.207779 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.52
INFO:tensorflow:Starting iteration 21

Steps executed: 214 Episode length: 62 Return: -572.603193687491365
INFO:tensorflow:Average training steps per second: 224.46
I0901 12:44:21.113082 140536266098688 replay_runner.py:36] Average training steps per second: 224.46
I0901 12:44:21.293329 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -520.68
INFO:tensorflow:Starting iteration 22

Steps executed: 239 Episode length: 68 Return: -416.718800626361945
INFO:tensorflow:Average training steps per second: 220.62
I0901 12:44:30.206892 140536266098688 replay_runner.py:36] Average training steps per second: 220.62
I0901 12:44:30.421490 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -466.21
INFO:tensorflow:Starting iteration 23

Steps executed: 256 Episode length: 83 Return: -362.345463707927765
INFO:tensorflow:Average training steps per second: 209.91
I0901 12:44:39.455443 140536266098688 replay_runner.py:36] Average training steps per second: 209.91
I0901 12:44:39.696038 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -522.05
INFO:tensorflow:Starting iteration 24

Steps executed: 210 Episode length: 80 Return: -697.681540218722765
INFO:tensorflow:Average training steps per second: 219.67
I0901 12:44:48.633524 140536266098688 replay_runner.py:36] Average training steps per second: 219.67
I0901 12:44:48.818899 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.40
INFO:tensorflow:Starting iteration 25

Steps executed: 263 Episode length: 79 Return: -146.525875633980355
INFO:tensorflow:Average training steps per second: 216.71
I0901 12:44:57.973341 140536266098688 replay_runner.py:36] Average training steps per second: 216.71
I0901 12:44:58.209606 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -478.76
INFO:tensorflow:Starting iteration 26
I0901 12:45:02.577845 140536266098688 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 222.89

Steps executed: 254 Episode length: 82 Return: -521.339142820655155
I0901 12:45:07.266605 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.22
INFO:tensorflow:Starting iteration 27

Steps executed: 219 Episode length: 63 Return: -356.408871653964075
INFO:tensorflow:Average training steps per second: 216.88
I0901 12:45:16.299860 140536266098688 replay_runner.py:36] Average training steps per second: 216.88
I0901 12:45:16.490904 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -555.19
INFO:tensorflow:Starting iteration 28

Steps executed: 200 Episode length: 57 Return: -39.2872816630483595
INFO:tensorflow:Average training steps per second: 215.75
I0901 12:45:25.595208 140536266098688 replay_runner.py:36] Average training steps per second: 215.75
I0901 12:45:25.746218 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.91
INFO:tensorflow:Starting iteration 29

Steps executed: 234 Episode length: 57 Return: -507.446243490742635
INFO:tensorflow:Average training steps per second: 217.08
I0901 12:45:34.670380 140536266098688 replay_runner.py:36] Average training steps per second: 217.08

Done fixed training!Episode length: 57 Return: -507.446243490742635