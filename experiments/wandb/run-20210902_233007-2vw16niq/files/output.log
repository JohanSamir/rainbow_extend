I0902 23:30:13.847095 140457530894336 run_experiment.py:549] Creating TrainRunner ...
I0902 23:30:13.859422 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:30:13.859748 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:30:13.859939 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:30:13.860082 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:30:13.860235 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0902 23:30:13.860371 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:30:13.860481 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:30:13.860551 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:30:13.860616 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:30:13.860680 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0902 23:30:13.860743 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:30:13.860808 140457530894336 dqn_agent.py:283] 	 seed: 1630625413859361
I0902 23:30:13.863736 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:30:13.863952 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:30:13.864081 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:30:13.864234 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:30:13.864423 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:30:13.864540 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:30:13.864650 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:30:13.864760 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:30:13.864896 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0902 23:30:15.711228 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:16.110232 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:16.126279 140457530894336 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:30:16.135146 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:30:16.135410 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:30:16.135570 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:30:16.135700 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:30:16.135787 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0902 23:30:16.135958 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:30:16.136140 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:30:16.136297 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:30:16.136421 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:30:16.136483 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0902 23:30:16.136533 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:30:16.136592 140457530894336 dqn_agent.py:283] 	 seed: 1630625416135079
I0902 23:30:16.139679 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:30:16.139884 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:30:16.140068 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:30:16.140174 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:30:16.140275 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:30:16.140404 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:30:16.140509 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:30:16.140620 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:30:16.140781 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:30:16.175119 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:16.198235 140457530894336 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:30:16.198643 140457530894336 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.36
I0902 23:30:22.358332 140457530894336 replay_runner.py:36] Average training steps per second: 162.36
Steps executed: 308 Episode length: 173 Return: -56.69174607706167
I0902 23:30:23.722387 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.49
INFO:tensorflow:Starting iteration 1

Steps executed: 226 Episode length: 226 Return: -315.05334899911236
INFO:tensorflow:Average training steps per second: 218.58
I0902 23:30:32.746179 140457530894336 replay_runner.py:36] Average training steps per second: 218.58
I0902 23:30:32.971081 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -315.05
INFO:tensorflow:Starting iteration 2

Steps executed: 232 Episode length: 127 Return: -272.68386730062355
INFO:tensorflow:Average training steps per second: 212.02
I0902 23:30:42.080864 140457530894336 replay_runner.py:36] Average training steps per second: 212.02
I0902 23:30:42.283832 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.29
INFO:tensorflow:Starting iteration 3
I0902 23:30:46.625962 140457530894336 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 228.26

Steps executed: 1000 Episode length: 1000 Return: -58.90309981740843
I0902 23:30:53.464468 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -58.90
INFO:tensorflow:Starting iteration 4
I0902 23:30:57.681523 140457530894336 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 229.37

Steps executed: 1000 Episode length: 1000 Return: -139.8750243372384
I0902 23:31:05.186607 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.88
INFO:tensorflow:Starting iteration 5
I0902 23:31:09.567175 140457530894336 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 228.80

Steps executed: 1000 Episode length: 1000 Return: -171.1347181938066
I0902 23:31:16.649356 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.13
INFO:tensorflow:Starting iteration 6
I0902 23:31:20.818040 140457530894336 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 228.87

Steps executed: 1000 Episode length: 1000 Return: -112.05194347663354
I0902 23:31:27.660042 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.05
INFO:tensorflow:Starting iteration 7
I0902 23:31:31.910989 140457530894336 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 232.23

Steps executed: 1000 Episode length: 1000 Return: -176.60982606020454
I0902 23:31:39.235619 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.61
INFO:tensorflow:Starting iteration 8
I0902 23:31:43.496145 140457530894336 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 224.94

Steps executed: 766 Episode length: 766 Return: -509.5503010032151754
I0902 23:31:49.748906 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -509.55
INFO:tensorflow:Starting iteration 9
I0902 23:31:54.100078 140457530894336 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 230.54

Steps executed: 1000 Episode length: 1000 Return: -181.59832115759584
I0902 23:32:00.788418 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -181.60
INFO:tensorflow:Starting iteration 10
I0902 23:32:05.192424 140457530894336 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 229.03

Steps executed: 1000 Episode length: 1000 Return: -192.55734431315122
I0902 23:32:11.338963 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.56
INFO:tensorflow:Starting iteration 11

Steps executed: 97 Episode length: 97 Return: -74.7442800982420715122
INFO:tensorflow:Average training steps per second: 222.93

Steps executed: 1097 Episode length: 1000 Return: -315.48822982863874
I0902 23:32:23.125278 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.12
INFO:tensorflow:Starting iteration 12
I0902 23:32:27.473988 140457530894336 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 223.38

Steps executed: 1000 Episode length: 1000 Return: -109.06091909399665
I0902 23:32:34.211364 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.06
INFO:tensorflow:Starting iteration 13

Steps executed: 323 Episode length: 221 Return: -210.8326287652171265
INFO:tensorflow:Average training steps per second: 222.11
I0902 23:32:43.028577 140457530894336 replay_runner.py:36] Average training steps per second: 222.11
I0902 23:32:43.333763 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.64
INFO:tensorflow:Starting iteration 14
I0902 23:32:47.727005 140457530894336 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 227.04

Steps executed: 607 Episode length: 607 Return: -88.75484813769474265
I0902 23:32:53.276820 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.75
INFO:tensorflow:Starting iteration 15
I0902 23:32:57.688845 140457530894336 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 222.04

Steps executed: 285 Episode length: 285 Return: -29.16060583335371365
I0902 23:33:02.592499 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -29.16
INFO:tensorflow:Starting iteration 16
I0902 23:33:06.978820 140457530894336 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 216.42

Steps executed: 1000 Episode length: 1000 Return: -36.913957053374655
I0902 23:33:14.661889 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -36.91
INFO:tensorflow:Starting iteration 17
I0902 23:33:19.095876 140457530894336 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 219.74

Steps executed: 785 Episode length: 785 Return: -340.4385153159111655
I0902 23:33:25.614899 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -340.44
INFO:tensorflow:Starting iteration 18
I0902 23:33:29.963014 140457530894336 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 223.89

Steps executed: 619 Episode length: 482 Return: -657.4795504812123355
I0902 23:33:35.429205 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -428.73
INFO:tensorflow:Starting iteration 19
I0902 23:33:39.808664 140457530894336 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 230.23
I0902 23:33:44.152773 140457530894336 replay_runner.py:36] Average training steps per second: 230.23

Steps executed: 237 Episode length: 237 Return: -330.4038819746872355
INFO:tensorflow:Starting iteration 20
I0902 23:33:48.824867 140457530894336 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 229.32

Steps executed: 606 Episode length: 606 Return: -252.8837427956412355
I0902 23:33:54.566112 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -252.88
INFO:tensorflow:Starting iteration 21

Steps executed: 248 Episode length: 248 Return: 7.0454719837373862355
INFO:tensorflow:Average training steps per second: 225.99
I0902 23:34:03.385481 140457530894336 replay_runner.py:36] Average training steps per second: 225.99
I0902 23:34:03.649639 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: 7.05
INFO:tensorflow:Starting iteration 22

Steps executed: 257 Episode length: 99 Return: -44.912608472562943355
INFO:tensorflow:Average training steps per second: 221.19
I0902 23:34:12.608767 140457530894336 replay_runner.py:36] Average training steps per second: 221.19
I0902 23:34:12.860845 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.27
INFO:tensorflow:Starting iteration 23

Steps executed: 145 Episode length: 145 Return: -75.69112457428187355
INFO:tensorflow:Average training steps per second: 230.58

Steps executed: 691 Episode length: 546 Return: -43.70019116377603355
I0902 23:34:23.198732 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -59.70
INFO:tensorflow:Starting iteration 24

Steps executed: 163 Episode length: 163 Return: -568.8055875573455355
INFO:tensorflow:Average training steps per second: 221.74
I0902 23:34:31.999737 140457530894336 replay_runner.py:36] Average training steps per second: 221.74

Steps executed: 284 Episode length: 121 Return: -484.7623410365946555
INFO:tensorflow:Starting iteration 25

Steps executed: 253 Episode length: 124 Return: -310.5395608253039755
INFO:tensorflow:Average training steps per second: 230.38
I0902 23:34:40.857686 140457530894336 replay_runner.py:36] Average training steps per second: 230.38
I0902 23:34:41.055773 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -323.69
INFO:tensorflow:Starting iteration 26

Steps executed: 253 Episode length: 113 Return: -475.9531024549708655
INFO:tensorflow:Average training steps per second: 225.62
I0902 23:34:49.818765 140457530894336 replay_runner.py:36] Average training steps per second: 225.62
I0902 23:34:50.050028 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -349.70
INFO:tensorflow:Starting iteration 27

Steps executed: 349 Episode length: 172 Return: -164.3762983495652755
INFO:tensorflow:Average training steps per second: 228.08
I0902 23:34:58.718865 140457530894336 replay_runner.py:36] Average training steps per second: 228.08
I0902 23:34:59.043442 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -320.78
INFO:tensorflow:Starting iteration 28

Steps executed: 213 Episode length: 85 Return: -748.36791721485971755
INFO:tensorflow:Average training steps per second: 229.36
I0902 23:35:07.859723 140457530894336 replay_runner.py:36] Average training steps per second: 229.36
I0902 23:35:08.040734 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -621.97
INFO:tensorflow:Starting iteration 29

Steps executed: 215 Episode length: 82 Return: -773.30647224755091755
INFO:tensorflow:Average training steps per second: 225.26
I0902 23:35:16.787595 140457530894336 replay_runner.py:36] Average training steps per second: 225.26

Done fixed training!Episode length: 82 Return: -773.30647224755091755