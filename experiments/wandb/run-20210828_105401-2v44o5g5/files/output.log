I0828 10:54:06.859367 139821415028736 run_experiment.py:549] Creating TrainRunner ...
I0828 10:54:06.866907 139821415028736 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:54:06.867055 139821415028736 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:54:06.867153 139821415028736 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:54:06.867233 139821415028736 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:54:06.867320 139821415028736 dqn_agent.py:275] 	 update_period: 4
I0828 10:54:06.867388 139821415028736 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:54:06.867467 139821415028736 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:54:06.867551 139821415028736 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:54:06.867616 139821415028736 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:54:06.867694 139821415028736 dqn_agent.py:280] 	 optimizer: adam
I0828 10:54:06.867763 139821415028736 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:54:06.867831 139821415028736 dqn_agent.py:283] 	 seed: 1630148046866858
I0828 10:54:06.869427 139821415028736 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:54:06.869537 139821415028736 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:54:06.869621 139821415028736 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:54:06.869685 139821415028736 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:54:06.869742 139821415028736 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:54:06.869814 139821415028736 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:54:06.869878 139821415028736 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:54:06.869960 139821415028736 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:54:06.870028 139821415028736 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:54:06.892678 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:07.126993 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:07.134903 139821415028736 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:54:07.141417 139821415028736 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:54:07.141530 139821415028736 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:54:07.141600 139821415028736 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:54:07.141659 139821415028736 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:54:07.141723 139821415028736 dqn_agent.py:275] 	 update_period: 4
I0828 10:54:07.141797 139821415028736 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:54:07.141894 139821415028736 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:54:07.141962 139821415028736 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:54:07.142016 139821415028736 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:54:07.142081 139821415028736 dqn_agent.py:280] 	 optimizer: adam
I0828 10:54:07.142151 139821415028736 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:54:07.142226 139821415028736 dqn_agent.py:283] 	 seed: 1630148047141393
I0828 10:54:07.143564 139821415028736 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:54:07.143669 139821415028736 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:54:07.143737 139821415028736 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:54:07.143799 139821415028736 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:54:07.143882 139821415028736 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:54:07.143940 139821415028736 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:54:07.144013 139821415028736 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:54:07.144068 139821415028736 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:54:07.144129 139821415028736 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:54:07.163517 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:07.177280 139821415028736 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:54:07.177417 139821415028736 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 252.84
I0828 10:54:11.132745 139821415028736 replay_runner.py:36] Average training steps per second: 252.84
I0828 10:54:11.907830 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -373.94
Steps executed: 251 Episode length: 139 Return: -306.8668124290623
INFO:tensorflow:Starting iteration 1

Steps executed: 212 Episode length: 100 Return: -708.20214266303983
INFO:tensorflow:Average training steps per second: 371.52
I0828 10:54:17.865272 139821415028736 replay_runner.py:36] Average training steps per second: 371.52
I0828 10:54:17.975642 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -512.13
INFO:tensorflow:Starting iteration 2

Steps executed: 299 Episode length: 144 Return: -279.95347172645235
INFO:tensorflow:Average training steps per second: 372.94
I0828 10:54:23.937716 139821415028736 replay_runner.py:36] Average training steps per second: 372.94
I0828 10:54:24.124749 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.95
INFO:tensorflow:Starting iteration 3
I0828 10:54:27.414140 139821415028736 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 327.01

Steps executed: 233 Episode length: 92 Return: -689.210369933681835
I0828 10:54:30.600135 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -472.69
INFO:tensorflow:Starting iteration 4

Steps executed: 211 Episode length: 99 Return: -679.851841064200225
INFO:tensorflow:Average training steps per second: 325.49
I0828 10:54:36.915855 139821415028736 replay_runner.py:36] Average training steps per second: 325.49
I0828 10:54:37.053004 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -530.87
INFO:tensorflow:Starting iteration 5

Steps executed: 367 Episode length: 176 Return: -458.37450234320345
INFO:tensorflow:Average training steps per second: 323.77
I0828 10:54:43.390007 139821415028736 replay_runner.py:36] Average training steps per second: 323.77
I0828 10:54:43.620052 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -407.23
INFO:tensorflow:Starting iteration 6

Steps executed: 364 Episode length: 173 Return: -460.15954969846145
INFO:tensorflow:Average training steps per second: 326.33
I0828 10:54:49.857310 139821415028736 replay_runner.py:36] Average training steps per second: 326.33
I0828 10:54:50.103838 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.02
INFO:tensorflow:Starting iteration 7

Steps executed: 358 Episode length: 194 Return: -412.12747956801354
INFO:tensorflow:Average training steps per second: 332.49
I0828 10:54:56.330036 139821415028736 replay_runner.py:36] Average training steps per second: 332.49
I0828 10:54:56.593523 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.82
INFO:tensorflow:Starting iteration 8

Steps executed: 428 Episode length: 261 Return: -262.42525990073466
INFO:tensorflow:Average training steps per second: 326.60
I0828 10:55:02.884723 139821415028736 replay_runner.py:36] Average training steps per second: 326.60
I0828 10:55:03.217283 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.95
INFO:tensorflow:Starting iteration 9

Steps executed: 312 Episode length: 133 Return: -242.24304200761432
INFO:tensorflow:Average training steps per second: 316.93
I0828 10:55:09.558266 139821415028736 replay_runner.py:36] Average training steps per second: 316.93
I0828 10:55:09.764193 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.19
INFO:tensorflow:Starting iteration 10

Steps executed: 332 Episode length: 157 Return: -199.03000781331878
INFO:tensorflow:Average training steps per second: 324.16
I0828 10:55:16.061314 139821415028736 replay_runner.py:36] Average training steps per second: 324.16
I0828 10:55:16.309309 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.90
INFO:tensorflow:Starting iteration 11

Steps executed: 160 Episode length: 160 Return: -192.25128547899318
INFO:tensorflow:Average training steps per second: 317.99

Steps executed: 389 Episode length: 229 Return: -245.62969306066188
I0828 10:55:22.949563 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.94
INFO:tensorflow:Starting iteration 12

Steps executed: 324 Episode length: 207 Return: -184.38203211096487
INFO:tensorflow:Average training steps per second: 313.28
I0828 10:55:29.316661 139821415028736 replay_runner.py:36] Average training steps per second: 313.28
I0828 10:55:29.544675 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.08
INFO:tensorflow:Starting iteration 13

Steps executed: 330 Episode length: 153 Return: -192.48882207771713
INFO:tensorflow:Average training steps per second: 318.33
I0828 10:55:35.844783 139821415028736 replay_runner.py:36] Average training steps per second: 318.33
I0828 10:55:36.098516 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.34
INFO:tensorflow:Starting iteration 14

Steps executed: 201 Episode length: 201 Return: -35.651954278303413
INFO:tensorflow:Average training steps per second: 321.64
I0828 10:55:42.398656 139821415028736 replay_runner.py:36] Average training steps per second: 321.64
I0828 10:55:42.560774 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -35.65
INFO:tensorflow:Starting iteration 15
I0828 10:55:45.759315 139821415028736 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 322.88

Steps executed: 412 Episode length: 217 Return: -2.3287907107140744
I0828 10:55:49.166412 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.76
INFO:tensorflow:Starting iteration 16

Steps executed: 291 Episode length: 131 Return: -95.226378795426845
INFO:tensorflow:Average training steps per second: 321.51
I0828 10:55:55.438427 139821415028736 replay_runner.py:36] Average training steps per second: 321.51
I0828 10:55:55.648472 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.55
INFO:tensorflow:Starting iteration 17

Steps executed: 281 Episode length: 152 Return: -212.06939868095654
INFO:tensorflow:Average training steps per second: 325.37
I0828 10:56:01.937906 139821415028736 replay_runner.py:36] Average training steps per second: 325.37
I0828 10:56:02.136313 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.02
INFO:tensorflow:Starting iteration 18

Steps executed: 308 Episode length: 168 Return: -48.749015405585844
INFO:tensorflow:Average training steps per second: 322.72
I0828 10:56:08.458265 139821415028736 replay_runner.py:36] Average training steps per second: 322.72
I0828 10:56:08.684400 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.04
INFO:tensorflow:Starting iteration 19

Steps executed: 110 Episode length: 110 Return: -171.49481887271734
INFO:tensorflow:Average training steps per second: 327.33
I0828 10:56:14.952424 139821415028736 replay_runner.py:36] Average training steps per second: 327.33

Steps executed: 347 Episode length: 237 Return: -16.033467811324826
INFO:tensorflow:Starting iteration 20

Steps executed: 210 Episode length: 210 Return: -257.56154364171426
INFO:tensorflow:Average training steps per second: 323.06
I0828 10:56:21.539977 139821415028736 replay_runner.py:36] Average training steps per second: 323.06
I0828 10:56:21.685487 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.56
INFO:tensorflow:Starting iteration 21

Steps executed: 275 Episode length: 138 Return: -295.00596597147556
INFO:tensorflow:Average training steps per second: 330.62
I0828 10:56:27.949616 139821415028736 replay_runner.py:36] Average training steps per second: 330.62
I0828 10:56:28.134060 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.33
INFO:tensorflow:Starting iteration 22

Steps executed: 280 Episode length: 111 Return: -236.72013760589646
INFO:tensorflow:Average training steps per second: 328.60
I0828 10:56:34.393839 139821415028736 replay_runner.py:36] Average training steps per second: 328.60
I0828 10:56:34.611592 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.46
INFO:tensorflow:Starting iteration 23

Steps executed: 260 Episode length: 106 Return: -249.85217850049517
INFO:tensorflow:Average training steps per second: 333.15
I0828 10:56:40.875593 139821415028736 replay_runner.py:36] Average training steps per second: 333.15
I0828 10:56:41.029960 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -241.34
INFO:tensorflow:Starting iteration 24

Steps executed: 284 Episode length: 147 Return: -68.524991597442667
INFO:tensorflow:Average training steps per second: 334.49
I0828 10:56:47.310926 139821415028736 replay_runner.py:36] Average training steps per second: 334.49
I0828 10:56:47.514733 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -51.61
INFO:tensorflow:Starting iteration 25

Steps executed: 354 Episode length: 202 Return: -206.37930597108794
INFO:tensorflow:Average training steps per second: 332.31
I0828 10:56:53.816205 139821415028736 replay_runner.py:36] Average training steps per second: 332.31
I0828 10:56:54.071369 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.03
INFO:tensorflow:Starting iteration 26

Steps executed: 334 Episode length: 225 Return: -9.0414942970769664
INFO:tensorflow:Average training steps per second: 336.18
I0828 10:57:00.353351 139821415028736 replay_runner.py:36] Average training steps per second: 336.18
I0828 10:57:00.583892 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.86
INFO:tensorflow:Starting iteration 27

Steps executed: 107 Episode length: 107 Return: -280.54757493327934
INFO:tensorflow:Average training steps per second: 341.24
I0828 10:57:06.847378 139821415028736 replay_runner.py:36] Average training steps per second: 341.24

Steps executed: 233 Episode length: 126 Return: -212.67147179734814
INFO:tensorflow:Starting iteration 28

Steps executed: 272 Episode length: 91 Return: -295.532324012227865
INFO:tensorflow:Average training steps per second: 342.21
I0828 10:57:13.274667 139821415028736 replay_runner.py:36] Average training steps per second: 342.21
I0828 10:57:13.466432 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.23
INFO:tensorflow:Starting iteration 29

Steps executed: 317 Episode length: 191 Return: -182.92564512259406
INFO:tensorflow:Average training steps per second: 347.14
I0828 10:57:19.696663 139821415028736 replay_runner.py:36] Average training steps per second: 347.14

Done fixed training!Episode length: 191 Return: -182.92564512259406