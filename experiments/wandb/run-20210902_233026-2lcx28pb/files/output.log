I0902 23:30:33.336241 140099460519936 run_experiment.py:549] Creating TrainRunner ...
I0902 23:30:33.347962 140099460519936 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:30:33.348251 140099460519936 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:30:33.348454 140099460519936 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:30:33.348656 140099460519936 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:30:33.348786 140099460519936 dqn_agent.py:275] 	 update_period: 4
I0902 23:30:33.348909 140099460519936 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:30:33.349089 140099460519936 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:30:33.349216 140099460519936 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:30:33.349319 140099460519936 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:30:33.349419 140099460519936 dqn_agent.py:280] 	 optimizer: adam
I0902 23:30:33.349519 140099460519936 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:30:33.349609 140099460519936 dqn_agent.py:283] 	 seed: 1630625433347897
I0902 23:30:33.353066 140099460519936 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:30:33.353292 140099460519936 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:30:33.353478 140099460519936 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:30:33.353618 140099460519936 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:30:33.353720 140099460519936 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:30:33.353812 140099460519936 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:30:33.353906 140099460519936 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:30:33.353992 140099460519936 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:30:33.354078 140099460519936 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0902 23:30:35.157106 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:35.548231 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:35.561383 140099460519936 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:30:35.571169 140099460519936 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:30:35.571471 140099460519936 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:30:35.571600 140099460519936 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:30:35.571685 140099460519936 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:30:35.571757 140099460519936 dqn_agent.py:275] 	 update_period: 4
I0902 23:30:35.571883 140099460519936 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:30:35.571987 140099460519936 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:30:35.572063 140099460519936 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:30:35.572138 140099460519936 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:30:35.572247 140099460519936 dqn_agent.py:280] 	 optimizer: adam
I0902 23:30:35.572336 140099460519936 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:30:35.572405 140099460519936 dqn_agent.py:283] 	 seed: 1630625435571114
I0902 23:30:35.573884 140099460519936 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:30:35.574007 140099460519936 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:30:35.574079 140099460519936 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:30:35.574142 140099460519936 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:30:35.574207 140099460519936 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:30:35.574286 140099460519936 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:30:35.574371 140099460519936 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:30:35.574426 140099460519936 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:30:35.574478 140099460519936 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:30:35.606956 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:35.629566 140099460519936 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:30:35.629893 140099460519936 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 158.52
I0902 23:30:41.938734 140099460519936 replay_runner.py:36] Average training steps per second: 158.52
Steps executed: 223 Episode length: 131 Return: -309.70331589620855
I0902 23:30:43.170959 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -336.46
INFO:tensorflow:Starting iteration 1

Steps executed: 325 Episode length: 149 Return: -376.86464879053295
INFO:tensorflow:Average training steps per second: 227.10
I0902 23:30:51.824905 140099460519936 replay_runner.py:36] Average training steps per second: 227.10
I0902 23:30:52.128382 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -369.91
INFO:tensorflow:Starting iteration 2

Steps executed: 128 Episode length: 128 Return: -291.49326837900055
INFO:tensorflow:Average training steps per second: 228.83
I0902 23:31:00.749938 140099460519936 replay_runner.py:36] Average training steps per second: 228.83

Steps executed: 296 Episode length: 168 Return: -469.00549143327975
INFO:tensorflow:Starting iteration 3
I0902 23:31:05.295824 140099460519936 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 227.01

Steps executed: 1000 Episode length: 1000 Return: -146.52640172687816
I0902 23:31:13.322595 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.53
INFO:tensorflow:Starting iteration 4
I0902 23:31:17.573542 140099460519936 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 242.49

Steps executed: 1000 Episode length: 1000 Return: -270.73495585539825
I0902 23:31:25.259190 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.73
INFO:tensorflow:Starting iteration 5
I0902 23:31:29.573816 140099460519936 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 248.81

Steps executed: 1000 Episode length: 1000 Return: -339.20528117600525
I0902 23:31:36.924239 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -339.21
INFO:tensorflow:Starting iteration 6
I0902 23:31:41.222378 140099460519936 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 232.57

Steps executed: 1000 Episode length: 1000 Return: -105.07042245453695
I0902 23:31:47.782975 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.07
INFO:tensorflow:Starting iteration 7

Steps executed: 288 Episode length: 288 Return: -217.8573693882493695
INFO:tensorflow:Average training steps per second: 228.14
I0902 23:31:56.558186 140099460519936 replay_runner.py:36] Average training steps per second: 228.14
I0902 23:31:56.867153 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.86
INFO:tensorflow:Starting iteration 8

Steps executed: 343 Episode length: 343 Return: -159.3320355460805695
INFO:tensorflow:Average training steps per second: 226.49
I0902 23:32:05.556860 140099460519936 replay_runner.py:36] Average training steps per second: 226.49
I0902 23:32:06.026369 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.33
INFO:tensorflow:Starting iteration 9
I0902 23:32:10.375843 140099460519936 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 221.92
I0902 23:32:14.882702 140099460519936 replay_runner.py:36] Average training steps per second: 221.92

Steps executed: 1000 Episode length: 1000 Return: -316.30940638319163
INFO:tensorflow:Starting iteration 10
I0902 23:32:21.895120 140099460519936 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 227.46

Steps executed: 1000 Episode length: 1000 Return: -432.34490077367565
I0902 23:32:28.273267 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -432.34
INFO:tensorflow:Starting iteration 11
I0902 23:32:32.706344 140099460519936 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 227.33

Steps executed: 1000 Episode length: 1000 Return: -237.33304185982198
I0902 23:32:40.809637 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.33
INFO:tensorflow:Starting iteration 12
I0902 23:32:45.262571 140099460519936 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 229.86

Steps executed: 1000 Episode length: 1000 Return: -80.901931214203028
I0902 23:32:51.528793 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.90
INFO:tensorflow:Starting iteration 13
I0902 23:32:55.826581 140099460519936 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 222.31
I0902 23:33:00.325372 140099460519936 replay_runner.py:36] Average training steps per second: 222.31

Steps executed: 1000 Episode length: 1000 Return: -155.28489567158724
INFO:tensorflow:Starting iteration 14
I0902 23:33:07.891456 140099460519936 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 223.78

Steps executed: 1000 Episode length: 1000 Return: -187.21694708639592
I0902 23:33:15.234806 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.22
INFO:tensorflow:Starting iteration 15
I0902 23:33:19.668700 140099460519936 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 226.28

Steps executed: 1000 Episode length: 1000 Return: -179.58301557689364
I0902 23:33:27.965467 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.58
INFO:tensorflow:Starting iteration 16
I0902 23:33:32.374568 140099460519936 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 228.94

Steps executed: 1000 Episode length: 1000 Return: -131.88059206759755
I0902 23:33:40.119227 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.88
INFO:tensorflow:Starting iteration 17
I0902 23:33:44.390914 140099460519936 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 234.97

Steps executed: 1000 Episode length: 1000 Return: -84.354178590823045
I0902 23:33:52.104363 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.35
INFO:tensorflow:Starting iteration 18

Steps executed: 398 Episode length: 398 Return: -27.12653558741923045
INFO:tensorflow:Average training steps per second: 226.65
I0902 23:34:00.750451 140099460519936 replay_runner.py:36] Average training steps per second: 226.65
I0902 23:34:01.313522 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -27.13
INFO:tensorflow:Starting iteration 19
I0902 23:34:05.665409 140099460519936 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 222.66

Steps executed: 1000 Episode length: 1000 Return: -140.82340760902983
I0902 23:34:13.865178 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.82
INFO:tensorflow:Starting iteration 20

Steps executed: 140 Episode length: 140 Return: -240.8387985848357383
INFO:tensorflow:Average training steps per second: 235.73

Steps executed: 739 Episode length: 599 Return: -162.4417086826004583
I0902 23:34:23.960880 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.64
INFO:tensorflow:Starting iteration 21

Steps executed: 415 Episode length: 415 Return: -31.76155372119178883
INFO:tensorflow:Average training steps per second: 226.71
I0902 23:34:32.726196 140099460519936 replay_runner.py:36] Average training steps per second: 226.71
I0902 23:34:33.383740 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -31.76
INFO:tensorflow:Starting iteration 22
I0902 23:34:37.641015 140099460519936 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 235.97

Steps executed: 745 Episode length: 745 Return: -570.4701896460546883
I0902 23:34:43.868802 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -570.47
INFO:tensorflow:Starting iteration 23

Steps executed: 495 Episode length: 495 Return: -220.3392344709076683
INFO:tensorflow:Average training steps per second: 227.31
I0902 23:34:52.676385 140099460519936 replay_runner.py:36] Average training steps per second: 227.31
I0902 23:34:53.643263 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.34
INFO:tensorflow:Starting iteration 24

Steps executed: 580 Episode length: 580 Return: -76.40812309954018683
INFO:tensorflow:Average training steps per second: 225.70
I0902 23:35:02.394451 140099460519936 replay_runner.py:36] Average training steps per second: 225.70
I0902 23:35:03.716523 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.41
INFO:tensorflow:Starting iteration 25
I0902 23:35:08.061765 140099460519936 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 237.75

Steps executed: 732 Episode length: 732 Return: 183.87885624811088683
I0902 23:35:13.961966 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: 183.88
INFO:tensorflow:Starting iteration 26

Steps executed: 337 Episode length: 153 Return: -24.11818343552737683
INFO:tensorflow:Average training steps per second: 230.44
I0902 23:35:22.745882 140099460519936 replay_runner.py:36] Average training steps per second: 230.44
I0902 23:35:23.106478 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -33.31
INFO:tensorflow:Starting iteration 27
I0902 23:35:27.468506 140099460519936 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 222.21

Steps executed: 222 Episode length: 55 Return: -188.36506847711848683
I0902 23:35:32.157872 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.97
INFO:tensorflow:Starting iteration 28
I0902 23:35:36.367406 140099460519936 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 222.05

Steps executed: 852 Episode length: 852 Return: 184.94276603132022683
I0902 23:35:42.626256 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: 184.94
INFO:tensorflow:Starting iteration 29
I0902 23:35:46.896912 140099460519936 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 220.04

Steps executed: 450 Episode length: 450 Return: 221.20238596436112683

Done fixed training!Episode length: 450 Return: 221.20238596436112683