I0903 00:04:35.594767 139926926592000 run_experiment.py:549] Creating TrainRunner ...
I0903 00:04:35.603399 139926926592000 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:04:35.603582 139926926592000 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:04:35.603680 139926926592000 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:04:35.603766 139926926592000 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:04:35.603902 139926926592000 dqn_agent.py:275] 	 update_period: 4
I0903 00:04:35.604028 139926926592000 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:04:35.604158 139926926592000 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:04:35.604366 139926926592000 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:04:35.604504 139926926592000 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:04:35.604629 139926926592000 dqn_agent.py:280] 	 optimizer: adam
I0903 00:04:35.604748 139926926592000 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:04:35.604977 139926926592000 dqn_agent.py:283] 	 seed: 1630627475603337
I0903 00:04:35.607162 139926926592000 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:04:35.607372 139926926592000 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:04:35.607489 139926926592000 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:04:35.607572 139926926592000 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:04:35.607728 139926926592000 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:04:35.607892 139926926592000 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:04:35.607997 139926926592000 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:04:35.608206 139926926592000 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:04:35.608501 139926926592000 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:04:35.635284 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:04:35.892355 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:04:35.902499 139926926592000 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:04:35.908848 139926926592000 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:04:35.908989 139926926592000 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:04:35.909091 139926926592000 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:04:35.909160 139926926592000 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:04:35.909216 139926926592000 dqn_agent.py:275] 	 update_period: 4
I0903 00:04:35.909269 139926926592000 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:04:35.909331 139926926592000 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:04:35.909383 139926926592000 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:04:35.909492 139926926592000 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:04:35.909547 139926926592000 dqn_agent.py:280] 	 optimizer: adam
I0903 00:04:35.909597 139926926592000 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:04:35.909647 139926926592000 dqn_agent.py:283] 	 seed: 1630627475908808
I0903 00:04:35.911414 139926926592000 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:04:35.911533 139926926592000 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:04:35.911607 139926926592000 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:04:35.911691 139926926592000 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:04:35.911776 139926926592000 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:04:35.911865 139926926592000 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:04:35.911965 139926926592000 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:04:35.912073 139926926592000 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:04:35.912173 139926926592000 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:04:35.937578 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:04:35.953500 139926926592000 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:04:35.953693 139926926592000 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 260.73
I0903 00:04:39.789297 139926926592000 replay_runner.py:36] Average training steps per second: 260.73
I0903 00:04:40.668447 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -468.65
Steps executed: 309 Episode length: 138 Return: -465.3019121746148
INFO:tensorflow:Starting iteration 1

Steps executed: 234 Episode length: 135 Return: -606.2446706502026
INFO:tensorflow:Average training steps per second: 334.77
I0903 00:04:46.988305 139926926592000 replay_runner.py:36] Average training steps per second: 334.77
I0903 00:04:47.151700 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -501.11
INFO:tensorflow:Starting iteration 2

Steps executed: 400 Episode length: 226 Return: -383.85748366070385
INFO:tensorflow:Average training steps per second: 338.88
I0903 00:04:53.525915 139926926592000 replay_runner.py:36] Average training steps per second: 338.88
I0903 00:04:53.837235 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -381.66
INFO:tensorflow:Starting iteration 3

Steps executed: 256 Episode length: 256 Return: -220.99139319809814
INFO:tensorflow:Average training steps per second: 324.75
I0903 00:05:00.287508 139926926592000 replay_runner.py:36] Average training steps per second: 324.75
I0903 00:05:00.501937 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.99
INFO:tensorflow:Starting iteration 4
I0903 00:05:03.780408 139926926592000 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 327.79

Steps executed: 823 Episode length: 823 Return: -156.09915557954105
I0903 00:05:08.259199 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.10
INFO:tensorflow:Starting iteration 5
I0903 00:05:11.576130 139926926592000 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 342.87
I0903 00:05:14.492974 139926926592000 replay_runner.py:36] Average training steps per second: 342.87

Steps executed: 1000 Episode length: 1000 Return: -86.3672034663154
INFO:tensorflow:Starting iteration 6
I0903 00:05:20.963860 139926926592000 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 331.44

Steps executed: 1000 Episode length: 1000 Return: -76.20714655488085
I0903 00:05:26.351348 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.21
INFO:tensorflow:Starting iteration 7
I0903 00:05:29.550049 139926926592000 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 310.94

Steps executed: 701 Episode length: 701 Return: -299.012119226010985
I0903 00:05:33.829137 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -299.01
INFO:tensorflow:Starting iteration 8

Steps executed: 338 Episode length: 338 Return: -255.753536436711365
INFO:tensorflow:Average training steps per second: 308.36
I0903 00:05:40.389788 139926926592000 replay_runner.py:36] Average training steps per second: 308.36
I0903 00:05:40.683583 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.75
INFO:tensorflow:Starting iteration 9
I0903 00:05:43.962889 139926926592000 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 334.30

Steps executed: 1000 Episode length: 1000 Return: -25.158879561205257
I0903 00:05:48.671359 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -25.16
INFO:tensorflow:Starting iteration 10
I0903 00:05:52.020823 139926926592000 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 328.13

Steps executed: 1000 Episode length: 1000 Return: -158.28770677468077
I0903 00:05:56.441058 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.29
INFO:tensorflow:Starting iteration 11
I0903 00:05:59.802630 139926926592000 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 348.37

Steps executed: 1000 Episode length: 1000 Return: -36.543580163484684
I0903 00:06:04.615954 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -36.54
INFO:tensorflow:Starting iteration 12

Steps executed: 468 Episode length: 468 Return: -360.1662842307037684
INFO:tensorflow:Average training steps per second: 357.19
I0903 00:06:10.853842 139926926592000 replay_runner.py:36] Average training steps per second: 357.19
I0903 00:06:11.432742 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -360.17
INFO:tensorflow:Starting iteration 13
I0903 00:06:14.878276 139926926592000 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 338.40

Steps executed: 1000 Episode length: 1000 Return: -132.17263150374382
I0903 00:06:20.678972 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.17
INFO:tensorflow:Starting iteration 14
I0903 00:06:24.070247 139926926592000 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 341.67

Steps executed: 1000 Episode length: 1000 Return: -34.368231684370412
I0903 00:06:28.927437 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -34.37
INFO:tensorflow:Starting iteration 15
I0903 00:06:32.277556 139926926592000 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 317.94

Steps executed: 1000 Episode length: 1000 Return: -179.66587650672375
I0903 00:06:37.169201 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.67
INFO:tensorflow:Starting iteration 16

Steps executed: 151 Episode length: 151 Return: -152.5900370897023275
INFO:tensorflow:Average training steps per second: 325.35

Steps executed: 371 Episode length: 220 Return: -153.3390499743371275
I0903 00:06:43.867635 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.96
INFO:tensorflow:Starting iteration 17

Steps executed: 248 Episode length: 106 Return: -125.8328108139619875
INFO:tensorflow:Average training steps per second: 328.75
I0903 00:06:50.292819 139926926592000 replay_runner.py:36] Average training steps per second: 328.75
I0903 00:06:50.438103 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.71
INFO:tensorflow:Starting iteration 18

Steps executed: 229 Episode length: 229 Return: -248.7145740646969675
INFO:tensorflow:Average training steps per second: 336.89
I0903 00:06:56.834784 139926926592000 replay_runner.py:36] Average training steps per second: 336.89
I0903 00:06:57.015390 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.71
INFO:tensorflow:Starting iteration 19
I0903 00:07:00.512622 139926926592000 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 335.57
I0903 00:07:03.492916 139926926592000 replay_runner.py:36] Average training steps per second: 335.57

Steps executed: 343 Episode length: 161 Return: -57.98174853840639675
INFO:tensorflow:Starting iteration 20
I0903 00:07:07.196072 139926926592000 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 328.35

Steps executed: 1000 Episode length: 1000 Return: -12.985409627322948
I0903 00:07:12.651650 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -12.99
INFO:tensorflow:Starting iteration 21

Steps executed: 449 Episode length: 275 Return: -218.5475733306405548
INFO:tensorflow:Average training steps per second: 325.75
I0903 00:07:19.134972 139926926592000 replay_runner.py:36] Average training steps per second: 325.75
I0903 00:07:19.498095 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.97
INFO:tensorflow:Starting iteration 22
I0903 00:07:22.884524 139926926592000 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 320.66

Steps executed: 237 Episode length: 237 Return: 21.174958398433025548
I0903 00:07:26.189078 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: 21.17
INFO:tensorflow:Starting iteration 23

Steps executed: 327 Episode length: 327 Return: -68.23352564211478548
INFO:tensorflow:Average training steps per second: 319.81
I0903 00:07:32.673592 139926926592000 replay_runner.py:36] Average training steps per second: 319.81
I0903 00:07:33.058541 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.23
INFO:tensorflow:Starting iteration 24

Steps executed: 162 Episode length: 162 Return: 16.013984621762063548
INFO:tensorflow:Average training steps per second: 323.93
I0903 00:07:39.524654 139926926592000 replay_runner.py:36] Average training steps per second: 323.93

Steps executed: 312 Episode length: 150 Return: -37.47995009870013548
INFO:tensorflow:Starting iteration 25
I0903 00:07:43.113275 139926926592000 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 322.26

Steps executed: 324 Episode length: 207 Return: -383.2073373817558748
I0903 00:07:46.467264 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -372.05
INFO:tensorflow:Starting iteration 26

Steps executed: 273 Episode length: 124 Return: -289.7689333224507948
INFO:tensorflow:Average training steps per second: 317.67
I0903 00:07:52.923559 139926926592000 replay_runner.py:36] Average training steps per second: 317.67
I0903 00:07:53.088506 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -204.37
INFO:tensorflow:Starting iteration 27

Steps executed: 190 Episode length: 190 Return: -307.3887461954414948
INFO:tensorflow:Average training steps per second: 333.91

Steps executed: 655 Episode length: 465 Return: -423.5651030759716548
I0903 00:08:00.210877 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -365.48
INFO:tensorflow:Starting iteration 28

Steps executed: 370 Episode length: 370 Return: -300.5149106890511348
INFO:tensorflow:Average training steps per second: 341.15
I0903 00:08:06.386660 139926926592000 replay_runner.py:36] Average training steps per second: 341.15
I0903 00:08:06.764752 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.51
INFO:tensorflow:Starting iteration 29

Steps executed: 270 Episode length: 133 Return: -82.16658391976047648
INFO:tensorflow:Average training steps per second: 316.94
I0903 00:08:13.143319 139926926592000 replay_runner.py:36] Average training steps per second: 316.94

Done fixed training!Episode length: 133 Return: -82.16658391976047648