Loaded trained dqn in cartpole
Training fixed agent 9, please be patient, may be a while...
I0901 12:46:54.686153 140162147342336 run_experiment.py:549] Creating TrainRunner ...
I0901 12:46:54.698269 140162147342336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:46:54.698538 140162147342336 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:46:54.698698 140162147342336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:46:54.698822 140162147342336 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:46:54.698931 140162147342336 dqn_agent.py:275] 	 update_period: 4
I0901 12:46:54.699039 140162147342336 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:46:54.699143 140162147342336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:46:54.699250 140162147342336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:46:54.699356 140162147342336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:46:54.699458 140162147342336 dqn_agent.py:280] 	 optimizer: adam
I0901 12:46:54.699566 140162147342336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:46:54.699856 140162147342336 dqn_agent.py:283] 	 seed: 1630500414698205
I0901 12:46:54.702626 140162147342336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:46:54.702758 140162147342336 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:46:54.702836 140162147342336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:46:54.702905 140162147342336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:46:54.703048 140162147342336 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:46:54.703124 140162147342336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:46:54.703188 140162147342336 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:46:54.703328 140162147342336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:46:54.703529 140162147342336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:46:54.855461 140162147342336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:46:55.408140 140162147342336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:46:55.423494 140162147342336 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:46:55.434833 140162147342336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:46:55.435142 140162147342336 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:46:55.435447 140162147342336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:46:55.435655 140162147342336 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:46:55.436004 140162147342336 dqn_agent.py:275] 	 update_period: 4
I0901 12:46:55.436166 140162147342336 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:46:55.436296 140162147342336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:46:55.436431 140162147342336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:46:55.436556 140162147342336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:46:55.436679 140162147342336 dqn_agent.py:280] 	 optimizer: adam
I0901 12:46:55.436799 140162147342336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:46:55.436924 140162147342336 dqn_agent.py:283] 	 seed: 1630500415434747
I0901 12:46:55.439115 140162147342336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:46:55.439265 140162147342336 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:46:55.439353 140162147342336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:46:55.439467 140162147342336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:46:55.439546 140162147342336 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:46:55.439604 140162147342336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:46:55.439686 140162147342336 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:46:55.439741 140162147342336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:46:55.439835 140162147342336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:46:55.475731 140162147342336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:46:55.497293 140162147342336 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:46:55.497731 140162147342336 replay_runner.py:41] Starting iteration 0
Steps executed: 208 Episode length: 21 Return: 21.0
INFO:tensorflow:Average training steps per second: 141.06
I0901 12:47:02.587188 140162147342336 replay_runner.py:36] Average training steps per second: 141.06
I0901 12:47:03.820189 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 23.11
INFO:tensorflow:Starting iteration 1

Steps executed: 284 Episode length: 99 Return: 99.0
INFO:tensorflow:Average training steps per second: 187.22
I0901 12:47:09.357551 140162147342336 replay_runner.py:36] Average training steps per second: 187.22
I0901 12:47:09.552624 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 94.67
INFO:tensorflow:Starting iteration 2

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 195.37
I0901 12:47:14.863064 140162147342336 replay_runner.py:36] Average training steps per second: 195.37
I0901 12:47:15.007931 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 3

Steps executed: 266 Episode length: 142 Return: 142.0
INFO:tensorflow:Average training steps per second: 187.71
I0901 12:47:20.530433 140162147342336 replay_runner.py:36] Average training steps per second: 187.71
I0901 12:47:20.709503 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 133.00
INFO:tensorflow:Starting iteration 4

Steps executed: 281 Episode length: 152 Return: 152.0
INFO:tensorflow:Average training steps per second: 196.00
I0901 12:47:25.997352 140162147342336 replay_runner.py:36] Average training steps per second: 196.00
I0901 12:47:26.193883 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 140.50
INFO:tensorflow:Starting iteration 5

Steps executed: 208 Episode length: 83 Return: 83.0.0
INFO:tensorflow:Average training steps per second: 196.08
I0901 12:47:31.489723 140162147342336 replay_runner.py:36] Average training steps per second: 196.08
I0901 12:47:31.644433 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 69.33
INFO:tensorflow:Starting iteration 6

Steps executed: 296 Episode length: 145 Return: 145.0
INFO:tensorflow:Average training steps per second: 193.22
I0901 12:47:37.007454 140162147342336 replay_runner.py:36] Average training steps per second: 193.22
I0901 12:47:37.207538 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 148.00
INFO:tensorflow:Starting iteration 7

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 196.73
I0901 12:47:42.478079 140162147342336 replay_runner.py:36] Average training steps per second: 196.73
I0901 12:47:42.615833 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 8

Steps executed: 315 Episode length: 157 Return: 157.0
INFO:tensorflow:Average training steps per second: 193.39
I0901 12:47:47.968396 140162147342336 replay_runner.py:36] Average training steps per second: 193.39
I0901 12:47:48.180550 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 157.50
INFO:tensorflow:Starting iteration 9

Steps executed: 298 Episode length: 139 Return: 139.0
INFO:tensorflow:Average training steps per second: 197.30
I0901 12:47:53.445178 140162147342336 replay_runner.py:36] Average training steps per second: 197.30
I0901 12:47:53.644844 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 149.00
INFO:tensorflow:Starting iteration 10

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 191.55
I0901 12:47:59.052987 140162147342336 replay_runner.py:36] Average training steps per second: 191.55
I0901 12:47:59.193656 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 11

Steps executed: 260 Episode length: 132 Return: 132.0
INFO:tensorflow:Average training steps per second: 192.28
I0901 12:48:04.574964 140162147342336 replay_runner.py:36] Average training steps per second: 192.28
I0901 12:48:04.751434 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 130.00
INFO:tensorflow:Starting iteration 12

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 193.36
I0901 12:48:10.115740 140162147342336 replay_runner.py:36] Average training steps per second: 193.36
I0901 12:48:10.260447 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 13
I0901 12:48:10.447818 140162147342336 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 190.36
I0901 12:48:15.701481 140162147342336 replay_runner.py:36] Average training steps per second: 190.36
I0901 12:48:15.838317 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 14

Steps executed: 298 Episode length: 161 Return: 161.0
INFO:tensorflow:Average training steps per second: 188.88
I0901 12:48:21.323284 140162147342336 replay_runner.py:36] Average training steps per second: 188.88
I0901 12:48:21.532096 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 149.00
INFO:tensorflow:Starting iteration 15
I0901 12:48:21.723933 140162147342336 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 188.83

Steps executed: 282 Episode length: 135 Return: 135.0
I0901 12:48:27.225595 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 141.00
INFO:tensorflow:Starting iteration 16
I0901 12:48:27.418426 140162147342336 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 190.32

Steps executed: 362 Episode length: 197 Return: 197.0
I0901 12:48:32.923270 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 181.00
INFO:tensorflow:Starting iteration 17

Steps executed: 183 Episode length: 183 Return: 183.0
INFO:tensorflow:Average training steps per second: 189.50
I0901 12:48:38.393672 140162147342336 replay_runner.py:36] Average training steps per second: 189.50

Steps executed: 354 Episode length: 171 Return: 171.0
INFO:tensorflow:Starting iteration 18

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 193.07
I0901 12:48:44.075886 140162147342336 replay_runner.py:36] Average training steps per second: 193.07
I0901 12:48:44.217712 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 19

Steps executed: 356 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 193.58
I0901 12:48:49.574092 140162147342336 replay_runner.py:36] Average training steps per second: 193.58
I0901 12:48:49.814803 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 178.00
INFO:tensorflow:Starting iteration 20

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 196.93
I0901 12:48:55.083679 140162147342336 replay_runner.py:36] Average training steps per second: 196.93
I0901 12:48:55.224940 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 21

Steps executed: 356 Episode length: 178 Return: 178.0
INFO:tensorflow:Average training steps per second: 194.78
I0901 12:49:00.554970 140162147342336 replay_runner.py:36] Average training steps per second: 194.78
I0901 12:49:00.797084 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 178.00
INFO:tensorflow:Starting iteration 22

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 191.87
I0901 12:49:06.201193 140162147342336 replay_runner.py:36] Average training steps per second: 191.87
I0901 12:49:06.342441 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 23
I0901 12:49:06.535396 140162147342336 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 196.84
I0901 12:49:11.616132 140162147342336 replay_runner.py:36] Average training steps per second: 196.84
I0901 12:49:11.759976 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 24

Steps executed: 363 Episode length: 195 Return: 195.0
INFO:tensorflow:Average training steps per second: 196.59
I0901 12:49:17.045721 140162147342336 replay_runner.py:36] Average training steps per second: 196.59
I0901 12:49:17.329753 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 181.50
INFO:tensorflow:Starting iteration 25

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 200.62
I0901 12:49:22.501041 140162147342336 replay_runner.py:36] Average training steps per second: 200.62
I0901 12:49:22.631474 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26
I0901 12:49:22.815102 140162147342336 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 198.81
I0901 12:49:27.845751 140162147342336 replay_runner.py:36] Average training steps per second: 198.81
I0901 12:49:27.971134 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 27

Steps executed: 379 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 194.54
I0901 12:49:33.292775 140162147342336 replay_runner.py:36] Average training steps per second: 194.54
I0901 12:49:33.546777 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 189.50
INFO:tensorflow:Starting iteration 28

Steps executed: 340 Episode length: 168 Return: 168.0
INFO:tensorflow:Average training steps per second: 195.33
I0901 12:49:38.852602 140162147342336 replay_runner.py:36] Average training steps per second: 195.33
I0901 12:49:39.088596 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 170.00
INFO:tensorflow:Starting iteration 29

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 189.57
I0901 12:49:44.562479 140162147342336 replay_runner.py:36] Average training steps per second: 189.57

Done fixed training!Episode length: 200 Return: 200.0