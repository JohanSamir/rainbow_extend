Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0903 00:00:49.627664 140310902786048 run_experiment.py:549] Creating TrainRunner ...
I0903 00:00:49.635689 140310902786048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:00:49.635845 140310902786048 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:00:49.635959 140310902786048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:00:49.636079 140310902786048 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:00:49.636205 140310902786048 dqn_agent.py:275] 	 update_period: 4
I0903 00:00:49.636432 140310902786048 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:00:49.636564 140310902786048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:00:49.636711 140310902786048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:00:49.636834 140310902786048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:00:49.636952 140310902786048 dqn_agent.py:280] 	 optimizer: adam
I0903 00:00:49.637120 140310902786048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:00:49.637199 140310902786048 dqn_agent.py:283] 	 seed: 1630627249635652
I0903 00:00:49.639169 140310902786048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:00:49.639279 140310902786048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:00:49.639353 140310902786048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:00:49.639425 140310902786048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:00:49.639485 140310902786048 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:00:49.639563 140310902786048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:00:49.639665 140310902786048 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:00:49.639742 140310902786048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:00:49.639807 140310902786048 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:00:49.664952 140310902786048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:00:49.908147 140310902786048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:00:49.917720 140310902786048 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:00:49.924731 140310902786048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:00:49.924867 140310902786048 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:00:49.924942 140310902786048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:00:49.925004 140310902786048 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:00:49.925063 140310902786048 dqn_agent.py:275] 	 update_period: 4
I0903 00:00:49.925116 140310902786048 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:00:49.925289 140310902786048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:00:49.925528 140310902786048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:00:49.925633 140310902786048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:00:49.925741 140310902786048 dqn_agent.py:280] 	 optimizer: adam
I0903 00:00:49.925834 140310902786048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:00:49.925969 140310902786048 dqn_agent.py:283] 	 seed: 1630627249924699
I0903 00:00:49.927875 140310902786048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:00:49.927984 140310902786048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:00:49.928042 140310902786048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:00:49.928106 140310902786048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:00:49.928164 140310902786048 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:00:49.928225 140310902786048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:00:49.928277 140310902786048 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:00:49.928400 140310902786048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:00:49.928463 140310902786048 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:00:49.947019 140310902786048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:00:49.962999 140310902786048 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:00:49.963147 140310902786048 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 236.26
I0903 00:00:54.195923 140310902786048 replay_runner.py:36] Average training steps per second: 236.26
I0903 00:00:54.926125 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -363.07
Steps executed: 211 Episode length: 95 Return: -430.152462958466747
INFO:tensorflow:Starting iteration 1

Steps executed: 226 Episode length: 123 Return: -214.54886522188377
INFO:tensorflow:Average training steps per second: 313.07
I0903 00:01:01.402703 140310902786048 replay_runner.py:36] Average training steps per second: 313.07
I0903 00:01:01.528694 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.14
INFO:tensorflow:Starting iteration 2

Steps executed: 255 Episode length: 115 Return: -416.50912804107275
INFO:tensorflow:Average training steps per second: 322.55
I0903 00:01:07.717229 140310902786048 replay_runner.py:36] Average training steps per second: 322.55
I0903 00:01:07.891284 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -399.09
INFO:tensorflow:Starting iteration 3

Steps executed: 272 Episode length: 272 Return: -304.11327021549815
INFO:tensorflow:Average training steps per second: 339.09
I0903 00:01:14.159006 140310902786048 replay_runner.py:36] Average training steps per second: 339.09
I0903 00:01:14.392426 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.11
INFO:tensorflow:Starting iteration 4
I0903 00:01:17.881205 140310902786048 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 364.72

Steps executed: 958 Episode length: 958 Return: -233.61808150874835
I0903 00:01:21.932829 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.62
INFO:tensorflow:Starting iteration 5

Steps executed: 753 Episode length: 753 Return: -170.56357803261298
INFO:tensorflow:Average training steps per second: 363.16
I0903 00:01:28.211429 140310902786048 replay_runner.py:36] Average training steps per second: 363.16
I0903 00:01:29.330430 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.56
INFO:tensorflow:Starting iteration 6
I0903 00:01:32.828748 140310902786048 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 362.21

Steps executed: 1000 Episode length: 1000 Return: -83.00890168437002
I0903 00:01:38.594412 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.01
INFO:tensorflow:Starting iteration 7
I0903 00:01:41.909596 140310902786048 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 328.37

Steps executed: 1000 Episode length: 1000 Return: -90.72101650072624
I0903 00:01:46.395575 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.72
INFO:tensorflow:Starting iteration 8
I0903 00:01:49.723861 140310902786048 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 310.68

Steps executed: 1000 Episode length: 1000 Return: -174.63042003074025
I0903 00:01:54.543055 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.63
INFO:tensorflow:Starting iteration 9
I0903 00:01:57.885971 140310902786048 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 323.81

Steps executed: 1000 Episode length: 1000 Return: -98.180364250164815
I0903 00:02:02.790037 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.18
INFO:tensorflow:Starting iteration 10
I0903 00:02:06.225178 140310902786048 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 334.27

Steps executed: 1000 Episode length: 1000 Return: -87.091690951962875
I0903 00:02:10.977268 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.09
INFO:tensorflow:Starting iteration 11
I0903 00:02:14.393839 140310902786048 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 327.38

Steps executed: 1000 Episode length: 1000 Return: -244.83400784037625
I0903 00:02:18.957928 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.83
INFO:tensorflow:Starting iteration 12
I0903 00:02:22.272525 140310902786048 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 331.32

Steps executed: 1000 Episode length: 1000 Return: -151.18466371541416
I0903 00:02:28.004539 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.18
INFO:tensorflow:Starting iteration 13
I0903 00:02:31.364425 140310902786048 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 344.29

Steps executed: 1000 Episode length: 1000 Return: -99.221653804193216
I0903 00:02:36.127450 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.22
INFO:tensorflow:Starting iteration 14

Steps executed: 377 Episode length: 377 Return: -45.04218922077783216
INFO:tensorflow:Average training steps per second: 326.39
I0903 00:02:42.605788 140310902786048 replay_runner.py:36] Average training steps per second: 326.39
I0903 00:02:42.937769 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -45.04
INFO:tensorflow:Starting iteration 15
I0903 00:02:46.302249 140310902786048 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 326.51

Steps executed: 521 Episode length: 521 Return: -49.21500571606095216
I0903 00:02:50.059026 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -49.22
INFO:tensorflow:Starting iteration 16
I0903 00:02:53.494356 140310902786048 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 334.14

Steps executed: 1000 Episode length: 1000 Return: -100.25160856996024
I0903 00:02:58.572361 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.25
INFO:tensorflow:Starting iteration 17
I0903 00:03:02.018798 140310902786048 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 332.76

Steps executed: 1000 Episode length: 1000 Return: -68.155464792528024
I0903 00:03:06.695023 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.16
INFO:tensorflow:Starting iteration 18

Steps executed: 328 Episode length: 328 Return: -99.79784548609248024
INFO:tensorflow:Average training steps per second: 313.21
I0903 00:03:13.197849 140310902786048 replay_runner.py:36] Average training steps per second: 313.21
I0903 00:03:13.490163 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.80
INFO:tensorflow:Starting iteration 19
I0903 00:03:16.675607 140310902786048 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 309.93

Steps executed: 127 Episode length: 127 Return: -39.43895852596954024

Steps executed: 1127 Episode length: 1000 Return: -42.535222202941094
INFO:tensorflow:Starting iteration 20

Steps executed: 286 Episode length: 208 Return: 39.993184691870341094
INFO:tensorflow:Average training steps per second: 323.69
I0903 00:03:28.402188 140310902786048 replay_runner.py:36] Average training steps per second: 323.69
I0903 00:03:28.603478 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.67
INFO:tensorflow:Starting iteration 21

Steps executed: 225 Episode length: 225 Return: -28.60366512453403294
INFO:tensorflow:Average training steps per second: 322.79
I0903 00:03:34.992813 140310902786048 replay_runner.py:36] Average training steps per second: 322.79
I0903 00:03:35.155520 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -28.60
INFO:tensorflow:Starting iteration 22
I0903 00:03:38.430865 140310902786048 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 333.81

Steps executed: 1000 Episode length: 1000 Return: -37.726346990595246
I0903 00:03:44.155196 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.73
INFO:tensorflow:Starting iteration 23

Steps executed: 539 Episode length: 539 Return: 206.36743734850415246
INFO:tensorflow:Average training steps per second: 344.09
I0903 00:03:50.516706 140310902786048 replay_runner.py:36] Average training steps per second: 344.09
I0903 00:03:51.249300 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: 206.37
INFO:tensorflow:Starting iteration 24
I0903 00:03:54.737270 140310902786048 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 341.39

Steps executed: 1000 Episode length: 1000 Return: -9.1484760246933646
I0903 00:03:59.845458 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -9.15
INFO:tensorflow:Starting iteration 25

Steps executed: 281 Episode length: 281 Return: 37.764964356036533646
INFO:tensorflow:Average training steps per second: 350.40
I0903 00:04:06.144153 140310902786048 replay_runner.py:36] Average training steps per second: 350.40
I0903 00:04:06.404379 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: 37.76
INFO:tensorflow:Starting iteration 26
I0903 00:04:09.865226 140310902786048 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 368.55

Steps executed: 1000 Episode length: 1000 Return: 34.8249953566777346
I0903 00:04:14.726890 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: 34.82
INFO:tensorflow:Starting iteration 27
I0903 00:04:18.069106 140310902786048 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 371.77

Steps executed: 1000 Episode length: 1000 Return: -61.683771983894216
I0903 00:04:22.673951 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.68
INFO:tensorflow:Starting iteration 28
I0903 00:04:25.770912 140310902786048 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 348.12

Steps executed: 1000 Episode length: 1000 Return: -63.820759972055626
I0903 00:04:30.496417 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -63.82
INFO:tensorflow:Starting iteration 29
I0903 00:04:33.827267 140310902786048 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 340.96

Steps executed: 1000 Episode length: 1000 Return: -20.044396976911663

Done fixed training! Episode length: 1000 Return: -20.044396976911663