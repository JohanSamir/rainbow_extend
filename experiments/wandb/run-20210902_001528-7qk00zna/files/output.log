Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0902 00:15:35.017843 140053067847680 run_experiment.py:549] Creating TrainRunner ...
I0902 00:15:35.029798 140053067847680 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:15:35.030016 140053067847680 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:15:35.030088 140053067847680 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:15:35.030160 140053067847680 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:15:35.030213 140053067847680 dqn_agent.py:275] 	 update_period: 4
I0902 00:15:35.030263 140053067847680 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:15:35.030311 140053067847680 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:15:35.030523 140053067847680 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:15:35.030699 140053067847680 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:15:35.030779 140053067847680 dqn_agent.py:280] 	 optimizer: adam
I0902 00:15:35.030841 140053067847680 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:15:35.030948 140053067847680 dqn_agent.py:283] 	 seed: 1630541735029736
I0902 00:15:35.034242 140053067847680 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:15:35.034478 140053067847680 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:15:35.034626 140053067847680 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:15:35.034802 140053067847680 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:15:35.034928 140053067847680 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:15:35.035042 140053067847680 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:15:35.035163 140053067847680 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:15:35.035435 140053067847680 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:15:35.035756 140053067847680 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:15:35.074736 140053067847680 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:35.457064 140053067847680 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:35.470372 140053067847680 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:15:35.479323 140053067847680 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:15:35.479508 140053067847680 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:15:35.479619 140053067847680 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:15:35.479925 140053067847680 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:15:35.480103 140053067847680 dqn_agent.py:275] 	 update_period: 4
I0902 00:15:35.480249 140053067847680 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:15:35.480631 140053067847680 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:15:35.480841 140053067847680 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:15:35.480991 140053067847680 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:15:35.481141 140053067847680 dqn_agent.py:280] 	 optimizer: adam
I0902 00:15:35.481270 140053067847680 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:15:35.481381 140053067847680 dqn_agent.py:283] 	 seed: 1630541735479277
I0902 00:15:35.484297 140053067847680 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:15:35.484487 140053067847680 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:15:35.484606 140053067847680 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:15:35.484719 140053067847680 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:15:35.484850 140053067847680 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:15:35.484990 140053067847680 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:15:35.485095 140053067847680 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:15:35.485212 140053067847680 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:15:35.485318 140053067847680 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:15:35.897131 140053067847680 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:35.919894 140053067847680 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:15:35.920171 140053067847680 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 169.24
I0902 00:15:41.829362 140053067847680 replay_runner.py:36] Average training steps per second: 169.24
Steps executed: 201 Episode length: 100 Return: -350.79311387456815
I0902 00:15:43.075747 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -292.12
INFO:tensorflow:Starting iteration 1

Steps executed: 273 Episode length: 121 Return: -141.47236857832965
INFO:tensorflow:Average training steps per second: 231.86
I0902 00:15:51.582248 140053067847680 replay_runner.py:36] Average training steps per second: 231.86
I0902 00:15:51.832660 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -330.26
INFO:tensorflow:Starting iteration 2
I0902 00:15:56.160536 140053067847680 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 226.57

Steps executed: 467 Episode length: 295 Return: -103.48048481741936
I0902 00:16:01.117919 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.42
INFO:tensorflow:Starting iteration 3
I0902 00:16:05.390033 140053067847680 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 224.41
I0902 00:16:09.847050 140053067847680 replay_runner.py:36] Average training steps per second: 224.41

Steps executed: 498 Episode length: 498 Return: -482.30931925553926
INFO:tensorflow:Starting iteration 4

Steps executed: 287 Episode length: 149 Return: -301.13645374620186
INFO:tensorflow:Average training steps per second: 217.96
I0902 00:16:19.534316 140053067847680 replay_runner.py:36] Average training steps per second: 217.96
I0902 00:16:19.818539 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.22
INFO:tensorflow:Starting iteration 5
I0902 00:16:24.151220 140053067847680 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 219.88

Steps executed: 1000 Episode length: 1000 Return: -99.4602200512629
I0902 00:16:30.531929 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.46
INFO:tensorflow:Starting iteration 6
I0902 00:16:34.642605 140053067847680 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 222.44

Steps executed: 1000 Episode length: 1000 Return: -55.186536141337356
I0902 00:16:41.767034 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -55.19
INFO:tensorflow:Starting iteration 7
I0902 00:16:45.917665 140053067847680 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 229.56

Steps executed: 1000 Episode length: 1000 Return: -58.136636406082786
I0902 00:16:53.252102 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -58.14
INFO:tensorflow:Starting iteration 8
I0902 00:16:57.405715 140053067847680 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 243.90

Steps executed: 1000 Episode length: 1000 Return: -51.664466709708385
I0902 00:17:04.360257 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -51.66
INFO:tensorflow:Starting iteration 9
I0902 00:17:08.559065 140053067847680 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 246.34

Steps executed: 491 Episode length: 491 Return: -266.2814450990028485
I0902 00:17:13.324995 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.28
INFO:tensorflow:Starting iteration 10

Steps executed: 645 Episode length: 645 Return: -185.7153415495551885
INFO:tensorflow:Average training steps per second: 243.55
I0902 00:17:21.539941 140053067847680 replay_runner.py:36] Average training steps per second: 243.55
I0902 00:17:22.333510 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.72
INFO:tensorflow:Starting iteration 11
I0902 00:17:26.414304 140053067847680 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 244.45

Steps executed: 734 Episode length: 734 Return: -171.2574697513199885
I0902 00:17:32.434718 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.26
INFO:tensorflow:Starting iteration 12
I0902 00:17:36.505423 140053067847680 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 251.77

Steps executed: 683 Episode length: 683 Return: -289.3611040976511585
I0902 00:17:41.516918 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.36
INFO:tensorflow:Starting iteration 13

Steps executed: 637 Episode length: 637 Return: -332.1008977449402585
INFO:tensorflow:Average training steps per second: 263.07
I0902 00:17:49.412955 140053067847680 replay_runner.py:36] Average training steps per second: 263.07
I0902 00:17:50.277707 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.10
INFO:tensorflow:Starting iteration 14
I0902 00:17:54.217190 140053067847680 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 286.43

Steps executed: 1000 Episode length: 1000 Return: -229.23475054051785
I0902 00:18:00.303445 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.23
INFO:tensorflow:Starting iteration 15

Steps executed: 111 Episode length: 111 Return: -977.3060530012017785
INFO:tensorflow:Average training steps per second: 302.27

Steps executed: 315 Episode length: 204 Return: -339.6137925480816785
I0902 00:18:07.469185 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -658.46
INFO:tensorflow:Starting iteration 16

Steps executed: 229 Episode length: 83 Return: -132.60821385668228785
INFO:tensorflow:Average training steps per second: 311.83
I0902 00:18:14.264790 140053067847680 replay_runner.py:36] Average training steps per second: 311.83
I0902 00:18:14.397432 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.20
INFO:tensorflow:Starting iteration 17
I0902 00:18:17.903870 140053067847680 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 314.36
I0902 00:18:21.085278 140053067847680 replay_runner.py:36] Average training steps per second: 314.36

Steps executed: 303 Episode length: 170 Return: -90.21889116488921385
INFO:tensorflow:Starting iteration 18

Steps executed: 257 Episode length: 116 Return: -182.6288331825156285
INFO:tensorflow:Average training steps per second: 315.69
I0902 00:18:27.793727 140053067847680 replay_runner.py:36] Average training steps per second: 315.69
I0902 00:18:27.973190 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.94
INFO:tensorflow:Starting iteration 19

Steps executed: 299 Episode length: 166 Return: -244.5623906011485485
INFO:tensorflow:Average training steps per second: 311.57
I0902 00:18:34.476357 140053067847680 replay_runner.py:36] Average training steps per second: 311.57
I0902 00:18:34.688282 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -337.27
INFO:tensorflow:Starting iteration 20
I0902 00:18:37.989820 140053067847680 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 311.60
I0902 00:18:41.199486 140053067847680 replay_runner.py:36] Average training steps per second: 311.60

Steps executed: 202 Episode length: 129 Return: -311.2537152145908485
INFO:tensorflow:Starting iteration 21
I0902 00:18:44.508948 140053067847680 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 326.50

Steps executed: 307 Episode length: 122 Return: 13.628448405073414485
I0902 00:18:47.807414 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -6.89
INFO:tensorflow:Starting iteration 22

Steps executed: 343 Episode length: 343 Return: -490.9118787149301485
INFO:tensorflow:Average training steps per second: 333.86
I0902 00:18:53.950625 140053067847680 replay_runner.py:36] Average training steps per second: 333.86
I0902 00:18:54.292997 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -490.91
INFO:tensorflow:Starting iteration 23

Steps executed: 244 Episode length: 97 Return: -534.45297339220875485
INFO:tensorflow:Average training steps per second: 332.62
I0902 00:19:00.514374 140053067847680 replay_runner.py:36] Average training steps per second: 332.62
I0902 00:19:00.693203 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.16
INFO:tensorflow:Starting iteration 24

Steps executed: 274 Episode length: 215 Return: -144.3577762193655885
INFO:tensorflow:Average training steps per second: 343.06
I0902 00:19:06.884319 140053067847680 replay_runner.py:36] Average training steps per second: 343.06
I0902 00:19:07.064513 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.04
INFO:tensorflow:Starting iteration 25

Steps executed: 86 Episode length: 86 Return: -759.547994680688955885
INFO:tensorflow:Average training steps per second: 345.99

Steps executed: 205 Episode length: 119 Return: -752.0339452676171885
I0902 00:19:13.415827 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -755.79
INFO:tensorflow:Starting iteration 26

Steps executed: 247 Episode length: 130 Return: -210.6651476248755485
INFO:tensorflow:Average training steps per second: 355.85
I0902 00:19:19.489277 140053067847680 replay_runner.py:36] Average training steps per second: 355.85
I0902 00:19:19.628255 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.80
INFO:tensorflow:Starting iteration 27

Steps executed: 238 Episode length: 64 Return: -123.90336813897767485
INFO:tensorflow:Average training steps per second: 367.71
I0902 00:19:25.465666 140053067847680 replay_runner.py:36] Average training steps per second: 367.71
I0902 00:19:25.601303 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -432.74
INFO:tensorflow:Starting iteration 28

Steps executed: 298 Episode length: 155 Return: -556.6581742497927485
INFO:tensorflow:Average training steps per second: 367.53
I0902 00:19:31.656203 140053067847680 replay_runner.py:36] Average training steps per second: 367.53
I0902 00:19:31.854701 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -504.02
INFO:tensorflow:Starting iteration 29

Steps executed: 320 Episode length: 123 Return: -595.9940669493642485
INFO:tensorflow:Average training steps per second: 365.03
I0902 00:19:38.053065 140053067847680 replay_runner.py:36] Average training steps per second: 365.03

Done fixed training!Episode length: 123 Return: -595.9940669493642485