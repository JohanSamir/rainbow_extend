Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 12:50:34.954799 140315766171648 run_experiment.py:549] Creating TrainRunner ...
I0901 12:50:34.967328 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:50:34.967535 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:50:34.967624 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:50:34.967686 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:50:34.967782 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 12:50:34.967858 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:50:34.967912 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:50:34.968010 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:50:34.968124 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:50:34.968183 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 12:50:34.968249 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:50:34.968340 140315766171648 dqn_agent.py:283] 	 seed: 1630500634967269
I0901 12:50:34.970831 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:50:34.971130 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:50:34.971275 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:50:34.971363 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:50:34.971443 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:50:34.971561 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:50:34.971746 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:50:34.971898 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:50:34.972021 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:50:35.015747 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:35.408955 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:35.424238 140315766171648 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:50:35.435014 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:50:35.435229 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:50:35.435401 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:50:35.435711 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:50:35.435878 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 12:50:35.435991 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:50:35.436111 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:50:35.436266 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:50:35.436393 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:50:35.436535 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 12:50:35.436689 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:50:35.436836 140315766171648 dqn_agent.py:283] 	 seed: 1630500635434957
I0901 12:50:35.439617 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:50:35.439843 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:50:35.439979 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:50:35.440591 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:50:35.440809 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:50:35.440921 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:50:35.441017 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:50:35.441138 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:50:35.441247 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:50:35.509138 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:35.537383 140315766171648 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:50:35.537840 140315766171648 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 155.68
I0901 12:50:41.961383 140315766171648 replay_runner.py:36] Average training steps per second: 155.68
Steps executed: 246 Episode length: 130 Return: -106.53854650921274
I0901 12:50:43.212701 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.66
INFO:tensorflow:Starting iteration 1

Steps executed: 252 Episode length: 103 Return: -192.50577501945222
INFO:tensorflow:Average training steps per second: 217.30
I0901 12:50:52.280248 140315766171648 replay_runner.py:36] Average training steps per second: 217.30
I0901 12:50:52.495045 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.08
INFO:tensorflow:Starting iteration 2

Steps executed: 268 Episode length: 140 Return: -470.71784469074566
INFO:tensorflow:Average training steps per second: 218.15
I0901 12:51:01.476717 140315766171648 replay_runner.py:36] Average training steps per second: 218.15
I0901 12:51:01.723134 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -369.12
INFO:tensorflow:Starting iteration 3

Steps executed: 237 Episode length: 105 Return: -631.19103678783246
INFO:tensorflow:Average training steps per second: 218.94
I0901 12:51:10.727495 140315766171648 replay_runner.py:36] Average training steps per second: 218.94
I0901 12:51:10.960244 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -497.83
INFO:tensorflow:Starting iteration 4

Steps executed: 204 Episode length: 112 Return: -316.72540029366485
INFO:tensorflow:Average training steps per second: 218.66
I0901 12:51:19.984011 140315766171648 replay_runner.py:36] Average training steps per second: 218.66
I0901 12:51:20.187568 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -513.46
INFO:tensorflow:Starting iteration 5

Steps executed: 225 Episode length: 143 Return: -112.75160204833023
INFO:tensorflow:Average training steps per second: 217.14
I0901 12:51:29.265814 140315766171648 replay_runner.py:36] Average training steps per second: 217.14
I0901 12:51:29.470436 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -429.07
INFO:tensorflow:Starting iteration 6

Steps executed: 274 Episode length: 91 Return: -710.656461016638123
INFO:tensorflow:Average training steps per second: 217.91
I0901 12:51:38.506080 140315766171648 replay_runner.py:36] Average training steps per second: 217.91
I0901 12:51:38.726250 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -385.56
INFO:tensorflow:Starting iteration 7

Steps executed: 260 Episode length: 97 Return: -671.911433049577573
INFO:tensorflow:Average training steps per second: 221.41
I0901 12:51:47.715858 140315766171648 replay_runner.py:36] Average training steps per second: 221.41
I0901 12:51:47.968012 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -354.21
INFO:tensorflow:Starting iteration 8
I0901 12:51:52.298749 140315766171648 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 216.78

Steps executed: 223 Episode length: 115 Return: -176.94406784422006
I0901 12:51:57.128273 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.07
INFO:tensorflow:Starting iteration 9

Steps executed: 309 Episode length: 124 Return: -325.40603257012486
INFO:tensorflow:Average training steps per second: 220.60
I0901 12:52:06.136038 140315766171648 replay_runner.py:36] Average training steps per second: 220.60
I0901 12:52:06.418523 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -496.09
INFO:tensorflow:Starting iteration 10

Steps executed: 201 Episode length: 111 Return: -201.80264456288366
INFO:tensorflow:Average training steps per second: 222.62
I0901 12:52:15.373072 140315766171648 replay_runner.py:36] Average training steps per second: 222.62
I0901 12:52:15.541325 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.20
INFO:tensorflow:Starting iteration 11

Steps executed: 280 Episode length: 143 Return: -164.83317908757869
INFO:tensorflow:Average training steps per second: 232.19
I0901 12:52:24.266133 140315766171648 replay_runner.py:36] Average training steps per second: 232.19
I0901 12:52:24.517060 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.32
INFO:tensorflow:Starting iteration 12

Steps executed: 205 Episode length: 72 Return: -182.329067801739439
INFO:tensorflow:Average training steps per second: 230.61
I0901 12:52:33.308951 140315766171648 replay_runner.py:36] Average training steps per second: 230.61
I0901 12:52:33.474070 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.86
INFO:tensorflow:Starting iteration 13

Steps executed: 205 Episode length: 74 Return: -243.053544636884857
INFO:tensorflow:Average training steps per second: 219.12
I0901 12:52:42.445291 140315766171648 replay_runner.py:36] Average training steps per second: 219.12
I0901 12:52:42.615847 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.98
INFO:tensorflow:Starting iteration 14

Steps executed: 266 Episode length: 109 Return: -167.14652496794383
INFO:tensorflow:Average training steps per second: 220.83
I0901 12:52:51.469876 140315766171648 replay_runner.py:36] Average training steps per second: 220.83
I0901 12:52:51.681698 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.95
INFO:tensorflow:Starting iteration 15

Steps executed: 231 Episode length: 87 Return: -190.108894836932343
INFO:tensorflow:Average training steps per second: 218.05
I0901 12:53:00.631468 140315766171648 replay_runner.py:36] Average training steps per second: 218.05
I0901 12:53:00.822211 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.13
INFO:tensorflow:Starting iteration 16

Steps executed: 224 Episode length: 57 Return: -129.738556286460943
INFO:tensorflow:Average training steps per second: 219.96
I0901 12:53:09.783210 140315766171648 replay_runner.py:36] Average training steps per second: 219.96
I0901 12:53:09.955861 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.66
INFO:tensorflow:Starting iteration 17
I0901 12:53:14.389985 140315766171648 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 217.48
I0901 12:53:18.988653 140315766171648 replay_runner.py:36] Average training steps per second: 217.48

Steps executed: 214 Episode length: 81 Return: -143.943112256152357
INFO:tensorflow:Starting iteration 18

Steps executed: 263 Episode length: 89 Return: -440.862242034659977
INFO:tensorflow:Average training steps per second: 217.36
I0901 12:53:28.220994 140315766171648 replay_runner.py:36] Average training steps per second: 217.36
I0901 12:53:28.446294 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -415.37
INFO:tensorflow:Starting iteration 19
I0901 12:53:32.909424 140315766171648 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 221.64

Steps executed: 204 Episode length: 204 Return: -711.54454214605797
I0901 12:53:37.676762 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -711.54
INFO:tensorflow:Starting iteration 20

Steps executed: 270 Episode length: 76 Return: -368.824464743425617
INFO:tensorflow:Average training steps per second: 218.62
I0901 12:53:46.557655 140315766171648 replay_runner.py:36] Average training steps per second: 218.62
I0901 12:53:46.786840 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -487.74
INFO:tensorflow:Starting iteration 21

Steps executed: 242 Episode length: 77 Return: -191.311192489695327
INFO:tensorflow:Average training steps per second: 224.98
I0901 12:53:55.816635 140315766171648 replay_runner.py:36] Average training steps per second: 224.98
I0901 12:53:56.012063 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.11
INFO:tensorflow:Starting iteration 22

Steps executed: 121 Episode length: 121 Return: -441.05359572586537
INFO:tensorflow:Average training steps per second: 223.37
I0901 12:54:04.935257 140315766171648 replay_runner.py:36] Average training steps per second: 223.37

Steps executed: 209 Episode length: 88 Return: -328.303243503867247
INFO:tensorflow:Starting iteration 23

Steps executed: 273 Episode length: 80 Return: -290.131180735225227
INFO:tensorflow:Average training steps per second: 220.99
I0901 12:54:13.877526 140315766171648 replay_runner.py:36] Average training steps per second: 220.99
I0901 12:54:14.074303 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.30
INFO:tensorflow:Starting iteration 24
I0901 12:54:18.559839 140315766171648 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 217.80

Steps executed: 249 Episode length: 67 Return: -180.809612654922956
I0901 12:54:23.387189 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.91
INFO:tensorflow:Starting iteration 25

Steps executed: 273 Episode length: 75 Return: -148.474963050139375
INFO:tensorflow:Average training steps per second: 213.87
I0901 12:54:32.458706 140315766171648 replay_runner.py:36] Average training steps per second: 213.87
I0901 12:54:32.695061 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.00
INFO:tensorflow:Starting iteration 26

Steps executed: 259 Episode length: 162 Return: -642.76880414551535
INFO:tensorflow:Average training steps per second: 208.25
I0901 12:54:41.925308 140315766171648 replay_runner.py:36] Average training steps per second: 208.25
I0901 12:54:42.159341 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -421.79
INFO:tensorflow:Starting iteration 27

Steps executed: 289 Episode length: 104 Return: -898.04253492939195
INFO:tensorflow:Average training steps per second: 222.69
I0901 12:54:50.990594 140315766171648 replay_runner.py:36] Average training steps per second: 222.69
I0901 12:54:51.262251 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -715.05
INFO:tensorflow:Starting iteration 28

Steps executed: 290 Episode length: 110 Return: -160.15812501885748
INFO:tensorflow:Average training steps per second: 217.19
I0901 12:55:00.302411 140315766171648 replay_runner.py:36] Average training steps per second: 217.19
I0901 12:55:00.604708 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -349.54
INFO:tensorflow:Starting iteration 29

Steps executed: 256 Episode length: 72 Return: -119.942826189030018
INFO:tensorflow:Average training steps per second: 221.83
I0901 12:55:09.467200 140315766171648 replay_runner.py:36] Average training steps per second: 221.83

Done fixed training!Episode length: 72 Return: -119.942826189030018