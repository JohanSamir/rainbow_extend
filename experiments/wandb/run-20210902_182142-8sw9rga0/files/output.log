I0902 18:21:47.420582 140451420674048 run_experiment.py:549] Creating TrainRunner ...
I0902 18:21:47.428650 140451420674048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:21:47.428774 140451420674048 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:21:47.428855 140451420674048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:21:47.428957 140451420674048 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:21:47.429012 140451420674048 dqn_agent.py:275] 	 update_period: 4
I0902 18:21:47.429065 140451420674048 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:21:47.429139 140451420674048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:21:47.429231 140451420674048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:21:47.429307 140451420674048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:21:47.429368 140451420674048 dqn_agent.py:280] 	 optimizer: adam
I0902 18:21:47.429439 140451420674048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:21:47.429509 140451420674048 dqn_agent.py:283] 	 seed: 1630606907428618
I0902 18:21:47.431205 140451420674048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:21:47.431315 140451420674048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:21:47.431391 140451420674048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:21:47.431454 140451420674048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:21:47.431510 140451420674048 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:21:47.431586 140451420674048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:21:47.431644 140451420674048 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:21:47.431710 140451420674048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:21:47.431783 140451420674048 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:21:47.454250 140451420674048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:47.713420 140451420674048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:47.722587 140451420674048 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:21:47.729856 140451420674048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:21:47.729995 140451420674048 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:21:47.730085 140451420674048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:21:47.730149 140451420674048 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:21:47.730208 140451420674048 dqn_agent.py:275] 	 update_period: 4
I0902 18:21:47.730261 140451420674048 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:21:47.730343 140451420674048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:21:47.730407 140451420674048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:21:47.730468 140451420674048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:21:47.730544 140451420674048 dqn_agent.py:280] 	 optimizer: adam
I0902 18:21:47.730620 140451420674048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:21:47.730687 140451420674048 dqn_agent.py:283] 	 seed: 1630606907729822
I0902 18:21:47.732101 140451420674048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:21:47.732210 140451420674048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:21:47.732281 140451420674048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:21:47.732360 140451420674048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:21:47.732445 140451420674048 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:21:47.732527 140451420674048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:21:47.732600 140451420674048 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:21:47.732650 140451420674048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:21:47.732725 140451420674048 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:21:47.755231 140451420674048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:47.772788 140451420674048 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:21:47.772949 140451420674048 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 240.28
I0902 18:21:51.934988 140451420674048 replay_runner.py:36] Average training steps per second: 240.28
I0902 18:21:52.744461 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.28
Steps executed: 258 Episode length: 162 Return: -279.09528901680426
INFO:tensorflow:Starting iteration 1
I0902 18:21:55.980045 140451420674048 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 323.23

Steps executed: 272 Episode length: 101 Return: -317.98268957546626
I0902 18:21:59.242742 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.41
INFO:tensorflow:Starting iteration 2

Steps executed: 234 Episode length: 112 Return: -164.27914658281344
INFO:tensorflow:Average training steps per second: 351.35
I0902 18:22:05.408563 140451420674048 replay_runner.py:36] Average training steps per second: 351.35
I0902 18:22:05.552709 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.78
INFO:tensorflow:Starting iteration 3
I0902 18:22:08.974163 140451420674048 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 360.22

Steps executed: 1000 Episode length: 1000 Return: -93.0329171726802
I0902 18:22:13.832132 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.03
INFO:tensorflow:Starting iteration 4
I0902 18:22:17.221888 140451420674048 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 350.59

Steps executed: 1000 Episode length: 1000 Return: -201.34217907177495
I0902 18:22:22.855220 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.34
INFO:tensorflow:Starting iteration 5
I0902 18:22:26.261790 140451420674048 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 345.78

Steps executed: 1000 Episode length: 1000 Return: -177.24970731109943
I0902 18:22:30.991667 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.25
INFO:tensorflow:Starting iteration 6
I0902 18:22:34.413814 140451420674048 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 364.96

Steps executed: 826 Episode length: 826 Return: -667.6736754038933943
I0902 18:22:38.346366 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -667.67
INFO:tensorflow:Starting iteration 7
I0902 18:22:41.789212 140451420674048 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 349.22

Steps executed: 1000 Episode length: 1000 Return: -208.68300592504497
I0902 18:22:46.103948 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.68
INFO:tensorflow:Starting iteration 8

Steps executed: 482 Episode length: 482 Return: -454.0944796796661497
INFO:tensorflow:Average training steps per second: 340.63
I0902 18:22:52.441904 140451420674048 replay_runner.py:36] Average training steps per second: 340.63
I0902 18:22:52.985575 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -454.09
INFO:tensorflow:Starting iteration 9
I0902 18:22:56.315894 140451420674048 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 346.74

Steps executed: 301 Episode length: 301 Return: -432.3962363820026497
I0902 18:22:59.493674 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -432.40
INFO:tensorflow:Starting iteration 10

Steps executed: 343 Episode length: 343 Return: -301.9770848727008697
INFO:tensorflow:Average training steps per second: 333.83
I0902 18:23:05.846932 140451420674048 replay_runner.py:36] Average training steps per second: 333.83
I0902 18:23:06.175492 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.98
INFO:tensorflow:Starting iteration 11

Steps executed: 357 Episode length: 267 Return: -271.2250323241618697
INFO:tensorflow:Average training steps per second: 341.73
I0902 18:23:12.459579 140451420674048 replay_runner.py:36] Average training steps per second: 341.73
I0902 18:23:12.753407 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.71
INFO:tensorflow:Starting iteration 12

Steps executed: 394 Episode length: 339 Return: -213.2661970094657697
INFO:tensorflow:Average training steps per second: 331.65
I0902 18:23:19.143207 140451420674048 replay_runner.py:36] Average training steps per second: 331.65
I0902 18:23:19.447968 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.02
INFO:tensorflow:Starting iteration 13

Steps executed: 214 Episode length: 214 Return: 12.877008547437896697
INFO:tensorflow:Average training steps per second: 333.17
I0902 18:23:25.772740 140451420674048 replay_runner.py:36] Average training steps per second: 333.17
I0902 18:23:25.924689 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: 12.88
INFO:tensorflow:Starting iteration 14

Steps executed: 417 Episode length: 417 Return: -126.7295636157458997
INFO:tensorflow:Average training steps per second: 349.85
I0902 18:23:32.090537 140451420674048 replay_runner.py:36] Average training steps per second: 349.85
I0902 18:23:32.467297 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.73
INFO:tensorflow:Starting iteration 15

Steps executed: 214 Episode length: 86 Return: -56.783433818109645897
INFO:tensorflow:Average training steps per second: 366.99
I0902 18:23:38.673150 140451420674048 replay_runner.py:36] Average training steps per second: 366.99
I0902 18:23:38.786834 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.06
INFO:tensorflow:Starting iteration 16

Steps executed: 253 Episode length: 253 Return: -32.30150507740905897
INFO:tensorflow:Average training steps per second: 353.97
I0902 18:23:45.052417 140451420674048 replay_runner.py:36] Average training steps per second: 353.97
I0902 18:23:45.242486 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -32.30
INFO:tensorflow:Starting iteration 17

Steps executed: 377 Episode length: 377 Return: -137.2861280887270897
INFO:tensorflow:Average training steps per second: 330.39
I0902 18:23:51.660540 140451420674048 replay_runner.py:36] Average training steps per second: 330.39
I0902 18:23:52.063693 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.29
INFO:tensorflow:Starting iteration 18

Steps executed: 300 Episode length: 181 Return: 26.439042616801885197
INFO:tensorflow:Average training steps per second: 325.71
I0902 18:23:58.368685 140451420674048 replay_runner.py:36] Average training steps per second: 325.71
I0902 18:23:58.545307 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -36.99
INFO:tensorflow:Starting iteration 19
I0902 18:24:01.831420 140451420674048 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 321.82

Steps executed: 663 Episode length: 663 Return: -41.85567404395365197
I0902 18:24:05.934430 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -41.86
INFO:tensorflow:Starting iteration 20

Steps executed: 566 Episode length: 428 Return: -644.7925363303607497
INFO:tensorflow:Average training steps per second: 345.89
I0902 18:24:12.182266 140451420674048 replay_runner.py:36] Average training steps per second: 345.89
I0902 18:24:12.672252 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.71
INFO:tensorflow:Starting iteration 21

Steps executed: 278 Episode length: 140 Return: -163.7793758141448897
INFO:tensorflow:Average training steps per second: 357.07
I0902 18:24:18.954692 140451420674048 replay_runner.py:36] Average training steps per second: 357.07
I0902 18:24:19.092117 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.03
INFO:tensorflow:Starting iteration 22
I0902 18:24:22.578635 140451420674048 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 347.82

Steps executed: 888 Episode length: 888 Return: -92.20768859942918897
I0902 18:24:26.782305 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.21
INFO:tensorflow:Starting iteration 23

Steps executed: 473 Episode length: 421 Return: -54.52413322417906897
INFO:tensorflow:Average training steps per second: 373.68
I0902 18:24:33.032428 140451420674048 replay_runner.py:36] Average training steps per second: 373.68
I0902 18:24:33.433106 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.16
INFO:tensorflow:Starting iteration 24

Steps executed: 319 Episode length: 319 Return: -376.6450557792867897
INFO:tensorflow:Average training steps per second: 336.46
I0902 18:24:39.886515 140451420674048 replay_runner.py:36] Average training steps per second: 336.46
I0902 18:24:40.139498 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -376.65
INFO:tensorflow:Starting iteration 25

Steps executed: 243 Episode length: 49 Return: -337.23818929371484897
INFO:tensorflow:Average training steps per second: 315.64
I0902 18:24:46.548631 140451420674048 replay_runner.py:36] Average training steps per second: 315.64
I0902 18:24:46.686603 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -431.12
INFO:tensorflow:Starting iteration 26
I0902 18:24:49.756439 140451420674048 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 316.97

Steps executed: 1000 Episode length: 1000 Return: -55.707727511561067
I0902 18:24:56.003824 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -55.71
INFO:tensorflow:Starting iteration 27

Steps executed: 748 Episode length: 748 Return: -117.3464820512371367
INFO:tensorflow:Average training steps per second: 318.10
I0902 18:25:02.292206 140451420674048 replay_runner.py:36] Average training steps per second: 318.10
I0902 18:25:03.514040 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.35
INFO:tensorflow:Starting iteration 28
I0902 18:25:06.775039 140451420674048 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 335.13

Steps executed: 357 Episode length: 202 Return: -48.19416343889188567
I0902 18:25:09.955429 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.83
INFO:tensorflow:Starting iteration 29
I0902 18:25:13.057552 140451420674048 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 356.48

Steps executed: 238 Episode length: 125 Return: -44.16470764723307567

Done fixed training!Episode length: 125 Return: -44.16470764723307567