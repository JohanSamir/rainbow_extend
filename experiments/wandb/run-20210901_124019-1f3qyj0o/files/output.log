Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0901 12:40:26.219869 140298343233536 run_experiment.py:549] Creating TrainRunner ...
I0901 12:40:26.230705 140298343233536 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:40:26.230944 140298343233536 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:40:26.231064 140298343233536 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:40:26.231185 140298343233536 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:40:26.231255 140298343233536 dqn_agent.py:275] 	 update_period: 4
I0901 12:40:26.231326 140298343233536 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:40:26.231386 140298343233536 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:40:26.231446 140298343233536 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:40:26.231504 140298343233536 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:40:26.231561 140298343233536 dqn_agent.py:280] 	 optimizer: adam
I0901 12:40:26.231620 140298343233536 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:40:26.231678 140298343233536 dqn_agent.py:283] 	 seed: 1630500026230655
I0901 12:40:26.234820 140298343233536 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:40:26.235074 140298343233536 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:40:26.235290 140298343233536 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:40:26.235468 140298343233536 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:40:26.235760 140298343233536 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:40:26.235986 140298343233536 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:40:26.236159 140298343233536 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:40:26.236258 140298343233536 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:40:26.236343 140298343233536 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:40:26.310358 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:40:26.687986 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:40:26.703639 140298343233536 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:40:26.729674 140298343233536 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:40:26.729933 140298343233536 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:40:26.730232 140298343233536 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:40:26.730390 140298343233536 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:40:26.730553 140298343233536 dqn_agent.py:275] 	 update_period: 4
I0901 12:40:26.730676 140298343233536 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:40:26.730973 140298343233536 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:40:26.731219 140298343233536 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:40:26.731686 140298343233536 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:40:26.731821 140298343233536 dqn_agent.py:280] 	 optimizer: adam
I0901 12:40:26.731904 140298343233536 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:40:26.731989 140298343233536 dqn_agent.py:283] 	 seed: 1630500026729627
I0901 12:40:26.734977 140298343233536 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:40:26.735181 140298343233536 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:40:26.735361 140298343233536 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:40:26.735498 140298343233536 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:40:26.735635 140298343233536 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:40:26.735769 140298343233536 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:40:26.735889 140298343233536 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:40:26.736022 140298343233536 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:40:26.736205 140298343233536 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:40:26.769511 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:40:26.790459 140298343233536 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:40:26.790718 140298343233536 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 157.46
I0901 12:40:33.141938 140298343233536 replay_runner.py:36] Average training steps per second: 157.46
Steps executed: 329 Episode length: 138 Return: -495.66712768799204
I0901 12:40:34.535759 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -506.18
INFO:tensorflow:Starting iteration 1
I0901 12:40:38.969743 140298343233536 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 208.64

Steps executed: 273 Episode length: 169 Return: -39.348283599253864
I0901 12:40:44.022970 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -62.22
INFO:tensorflow:Starting iteration 2

Steps executed: 303 Episode length: 117 Return: -384.01136386675176
INFO:tensorflow:Average training steps per second: 214.93
I0901 12:40:53.058970 140298343233536 replay_runner.py:36] Average training steps per second: 214.93
I0901 12:40:53.333410 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -322.70
INFO:tensorflow:Starting iteration 3

Steps executed: 281 Episode length: 134 Return: -241.17765885863936
INFO:tensorflow:Average training steps per second: 221.21
I0901 12:41:02.284005 140298343233536 replay_runner.py:36] Average training steps per second: 221.21
I0901 12:41:02.510035 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.70
INFO:tensorflow:Starting iteration 4

Steps executed: 215 Episode length: 124 Return: -289.59608954189636
INFO:tensorflow:Average training steps per second: 213.43
I0901 12:41:11.432520 140298343233536 replay_runner.py:36] Average training steps per second: 213.43
I0901 12:41:11.608972 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.22
INFO:tensorflow:Starting iteration 5

Steps executed: 278 Episode length: 92 Return: -227.726771319914728
INFO:tensorflow:Average training steps per second: 218.90
I0901 12:41:20.444016 140298343233536 replay_runner.py:36] Average training steps per second: 218.90
I0901 12:41:20.665230 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -172.49
INFO:tensorflow:Starting iteration 6

Steps executed: 296 Episode length: 158 Return: -267.10188772449794
INFO:tensorflow:Average training steps per second: 222.21
I0901 12:41:29.452725 140298343233536 replay_runner.py:36] Average training steps per second: 222.21
I0901 12:41:29.745203 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -267.22
INFO:tensorflow:Starting iteration 7

Steps executed: 206 Episode length: 120 Return: -174.86937752983198
INFO:tensorflow:Average training steps per second: 213.25
I0901 12:41:38.859663 140298343233536 replay_runner.py:36] Average training steps per second: 213.25
I0901 12:41:39.038582 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.11
INFO:tensorflow:Starting iteration 8
I0901 12:41:43.314206 140298343233536 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 213.60

Steps executed: 315 Episode length: 167 Return: -180.48364572047814
I0901 12:41:48.324689 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.00
INFO:tensorflow:Starting iteration 9

Steps executed: 216 Episode length: 216 Return: -102.59522512192372
INFO:tensorflow:Average training steps per second: 210.14
I0901 12:41:57.417615 140298343233536 replay_runner.py:36] Average training steps per second: 210.14
I0901 12:41:57.630407 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.60
INFO:tensorflow:Starting iteration 10
I0901 12:42:01.908811 140298343233536 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 237.34

Steps executed: 210 Episode length: 210 Return: 19.9027633797617172
I0901 12:42:06.372012 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: 19.90
INFO:tensorflow:Starting iteration 11

Steps executed: 212 Episode length: 56 Return: -138.575321050441268
INFO:tensorflow:Average training steps per second: 212.51
I0901 12:42:15.554188 140298343233536 replay_runner.py:36] Average training steps per second: 212.51
I0901 12:42:15.752769 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -183.49
INFO:tensorflow:Starting iteration 12

Steps executed: 715 Episode length: 550 Return: -1892.7092507044756
INFO:tensorflow:Average training steps per second: 217.35
I0901 12:42:24.645695 140298343233536 replay_runner.py:36] Average training steps per second: 217.35
I0901 12:42:25.834065 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -1107.11
INFO:tensorflow:Starting iteration 13

Steps executed: 367 Episode length: 225 Return: -378.59797089225226
INFO:tensorflow:Average training steps per second: 209.97
I0901 12:42:35.038097 140298343233536 replay_runner.py:36] Average training steps per second: 209.97
I0901 12:42:35.436418 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.02
INFO:tensorflow:Starting iteration 14

Steps executed: 270 Episode length: 95 Return: -633.489484447324646
INFO:tensorflow:Average training steps per second: 222.98
I0901 12:42:44.008016 140298343233536 replay_runner.py:36] Average training steps per second: 222.98
I0901 12:42:44.262142 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -499.06
INFO:tensorflow:Starting iteration 15

Steps executed: 231 Episode length: 116 Return: -101.01156607142379
INFO:tensorflow:Average training steps per second: 216.92
I0901 12:42:53.265613 140298343233536 replay_runner.py:36] Average training steps per second: 216.92
I0901 12:42:53.456243 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.92
INFO:tensorflow:Starting iteration 16

Steps executed: 170 Episode length: 69 Return: -122.452887779568314
INFO:tensorflow:Average training steps per second: 222.11
I0901 12:43:02.279170 140298343233536 replay_runner.py:36] Average training steps per second: 222.11

Steps executed: 284 Episode length: 114 Return: -559.34550115829464
INFO:tensorflow:Starting iteration 17

Steps executed: 204 Episode length: 126 Return: -1076.1814909185887
INFO:tensorflow:Average training steps per second: 224.85
I0901 12:43:11.358170 140298343233536 replay_runner.py:36] Average training steps per second: 224.85
I0901 12:43:11.559179 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -713.90
INFO:tensorflow:Starting iteration 18

Steps executed: 265 Episode length: 77 Return: -672.376182245338617
INFO:tensorflow:Average training steps per second: 224.61
I0901 12:43:20.255624 140298343233536 replay_runner.py:36] Average training steps per second: 224.61
I0901 12:43:20.466232 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -637.11
INFO:tensorflow:Starting iteration 19

Steps executed: 221 Episode length: 147 Return: -441.40061875382987
INFO:tensorflow:Average training steps per second: 223.27
I0901 12:43:29.348131 140298343233536 replay_runner.py:36] Average training steps per second: 223.27
I0901 12:43:29.542593 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -320.86
INFO:tensorflow:Starting iteration 20
I0901 12:43:34.007404 140298343233536 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 218.58

Steps executed: 240 Episode length: 84 Return: -155.395831594274587
I0901 12:43:38.781346 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.75
INFO:tensorflow:Starting iteration 21

Steps executed: 200 Episode length: 80 Return: -496.629386999963467
INFO:tensorflow:Average training steps per second: 217.18
I0901 12:43:47.647860 140298343233536 replay_runner.py:36] Average training steps per second: 217.18
I0901 12:43:47.811087 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -412.55
INFO:tensorflow:Starting iteration 22
I0901 12:43:52.130979 140298343233536 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 215.50

Steps executed: 234 Episode length: 87 Return: -37.7123165277473057
I0901 12:43:56.987246 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.22
INFO:tensorflow:Starting iteration 23

Steps executed: 166 Episode length: 80 Return: -527.788990174943157
INFO:tensorflow:Average training steps per second: 216.49
I0901 12:44:06.093671 140298343233536 replay_runner.py:36] Average training steps per second: 216.49

Steps executed: 241 Episode length: 75 Return: -484.092684729887457
INFO:tensorflow:Starting iteration 24

Steps executed: 253 Episode length: 113 Return: -96.369344027656157
INFO:tensorflow:Average training steps per second: 224.60
I0901 12:44:14.799312 140298343233536 replay_runner.py:36] Average training steps per second: 224.60
I0901 12:44:15.016205 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.24
INFO:tensorflow:Starting iteration 25

Steps executed: 202 Episode length: 79 Return: -476.751813791392157
INFO:tensorflow:Average training steps per second: 226.89
I0901 12:44:23.866048 140298343233536 replay_runner.py:36] Average training steps per second: 226.89
I0901 12:44:24.050065 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -505.00
INFO:tensorflow:Starting iteration 26

Steps executed: 223 Episode length: 75 Return: -177.003181925656857
INFO:tensorflow:Average training steps per second: 226.91
I0901 12:44:32.848917 140298343233536 replay_runner.py:36] Average training steps per second: 226.91
I0901 12:44:33.041085 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -514.63
INFO:tensorflow:Starting iteration 27

Steps executed: 261 Episode length: 118 Return: -227.88870652231412
INFO:tensorflow:Average training steps per second: 219.38
I0901 12:44:42.094528 140298343233536 replay_runner.py:36] Average training steps per second: 219.38
I0901 12:44:42.327799 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -360.50
INFO:tensorflow:Starting iteration 28

Steps executed: 217 Episode length: 68 Return: -408.642643016737612
INFO:tensorflow:Average training steps per second: 213.24
I0901 12:44:51.314339 140298343233536 replay_runner.py:36] Average training steps per second: 213.24
I0901 12:44:51.525960 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -513.32
INFO:tensorflow:Starting iteration 29
I0901 12:44:55.879210 140298343233536 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 215.03

Steps executed: 224 Episode length: 153 Return: -248.82965130964644

Done fixed training!Episode length: 153 Return: -248.82965130964644