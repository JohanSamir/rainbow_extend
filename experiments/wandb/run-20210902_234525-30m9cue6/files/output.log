Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0902 23:45:32.482024 139803223304192 run_experiment.py:549] Creating TrainRunner ...
I0902 23:45:32.493767 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:45:32.494105 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:45:32.494294 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:45:32.494450 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:45:32.494637 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0902 23:45:32.494841 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:45:32.494998 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:45:32.495202 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:45:32.495346 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:45:32.495487 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0902 23:45:32.495611 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:45:32.495738 139803223304192 dqn_agent.py:283] 	 seed: 1630626332493691
I0902 23:45:32.499260 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:45:32.499575 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:45:32.499743 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:45:32.499859 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:45:32.499965 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:45:32.500071 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:45:32.500165 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:45:32.500246 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:45:32.500344 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:45:32.540138 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:45:32.934087 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:45:32.945868 139803223304192 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:45:32.956524 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:45:32.956815 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:45:32.956925 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:45:32.957033 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:45:32.957181 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0902 23:45:32.957324 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:45:32.957433 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:45:32.957530 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:45:32.957639 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:45:32.957711 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0902 23:45:32.957906 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:45:32.958038 139803223304192 dqn_agent.py:283] 	 seed: 1630626332956465
I0902 23:45:32.959742 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:45:32.959888 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:45:32.959980 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:45:32.960132 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:45:32.960252 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:45:32.960352 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:45:32.960419 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:45:32.960518 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:45:32.960610 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:45:33.035239 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:45:33.058965 139803223304192 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:45:33.059282 139803223304192 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 164.93
I0902 23:45:39.122692 139803223304192 replay_runner.py:36] Average training steps per second: 164.93
Steps executed: 308 Episode length: 126 Return: -230.77649552579516
I0902 23:45:40.378807 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -349.09
INFO:tensorflow:Starting iteration 1

Steps executed: 290 Episode length: 108 Return: -265.29938041171826
INFO:tensorflow:Average training steps per second: 232.84
I0902 23:45:48.990169 139803223304192 replay_runner.py:36] Average training steps per second: 232.84
I0902 23:45:49.275763 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -391.32
INFO:tensorflow:Starting iteration 2

Steps executed: 154 Episode length: 154 Return: -416.76675260813766
INFO:tensorflow:Average training steps per second: 224.51
I0902 23:45:57.927696 139803223304192 replay_runner.py:36] Average training steps per second: 224.51

Steps executed: 250 Episode length: 96 Return: -426.295406125180666
INFO:tensorflow:Starting iteration 3

Steps executed: 242 Episode length: 242 Return: -479.48776707155686
INFO:tensorflow:Average training steps per second: 221.17
I0902 23:46:06.916077 139803223304192 replay_runner.py:36] Average training steps per second: 221.17
I0902 23:46:07.192856 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -479.49
INFO:tensorflow:Starting iteration 4
I0902 23:46:11.513677 139803223304192 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 219.54

Steps executed: 1000 Episode length: 1000 Return: -75.73952870360796
I0902 23:46:19.031702 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.74
INFO:tensorflow:Starting iteration 5
I0902 23:46:23.414304 139803223304192 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 216.57

Steps executed: 1000 Episode length: 1000 Return: -108.7210408471929
I0902 23:46:31.378215 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.72
INFO:tensorflow:Starting iteration 6
I0902 23:46:35.720807 139803223304192 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 225.54

Steps executed: 1000 Episode length: 1000 Return: -50.83736665450879
I0902 23:46:42.258112 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -50.84
INFO:tensorflow:Starting iteration 7
I0902 23:46:46.606514 139803223304192 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 230.00

Steps executed: 738 Episode length: 738 Return: -389.604297615666849
I0902 23:46:52.700442 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -389.60
INFO:tensorflow:Starting iteration 8
I0902 23:46:57.137768 139803223304192 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 233.62

Steps executed: 1000 Episode length: 1000 Return: -81.39752628164607
I0902 23:47:05.203142 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.40
INFO:tensorflow:Starting iteration 9
I0902 23:47:09.517663 139803223304192 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 228.30

Steps executed: 1000 Episode length: 1000 Return: -117.82257010974857
I0902 23:47:16.688071 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.82
INFO:tensorflow:Starting iteration 10

Steps executed: 413 Episode length: 413 Return: -232.2135402564221857
INFO:tensorflow:Average training steps per second: 227.43
I0902 23:47:25.356569 139803223304192 replay_runner.py:36] Average training steps per second: 227.43
I0902 23:47:26.059328 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.21
INFO:tensorflow:Starting iteration 11

Steps executed: 459 Episode length: 459 Return: -279.9636285850372857
INFO:tensorflow:Average training steps per second: 227.32
I0902 23:47:34.774756 139803223304192 replay_runner.py:36] Average training steps per second: 227.32
I0902 23:47:35.648796 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.96
INFO:tensorflow:Starting iteration 12

Steps executed: 210 Episode length: 210 Return: -144.2632208377792457
INFO:tensorflow:Average training steps per second: 218.68
I0902 23:47:44.421526 139803223304192 replay_runner.py:36] Average training steps per second: 218.68
I0902 23:47:44.651236 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.26
INFO:tensorflow:Starting iteration 13

Steps executed: 135 Episode length: 135 Return: -451.5561522728368457
INFO:tensorflow:Average training steps per second: 217.76

Steps executed: 1135 Episode length: 1000 Return: -152.39870512944313
I0902 23:47:56.700135 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.98
INFO:tensorflow:Starting iteration 14

Steps executed: 462 Episode length: 462 Return: -162.5601529439282313
INFO:tensorflow:Average training steps per second: 223.53
I0902 23:48:05.401584 139803223304192 replay_runner.py:36] Average training steps per second: 223.53
I0902 23:48:06.196785 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.56
INFO:tensorflow:Starting iteration 15

Steps executed: 295 Episode length: 136 Return: -515.7078743396086313
INFO:tensorflow:Average training steps per second: 221.97
I0902 23:48:15.137292 139803223304192 replay_runner.py:36] Average training steps per second: 221.97
I0902 23:48:15.389749 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -360.72
INFO:tensorflow:Starting iteration 16
I0902 23:48:19.794054 139803223304192 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 220.88
I0902 23:48:24.322002 139803223304192 replay_runner.py:36] Average training steps per second: 220.88

Steps executed: 297 Episode length: 155 Return: -110.5526690063954313
INFO:tensorflow:Starting iteration 17

Steps executed: 417 Episode length: 301 Return: -173.0497467150963213
INFO:tensorflow:Average training steps per second: 216.18
I0902 23:48:33.560210 139803223304192 replay_runner.py:36] Average training steps per second: 216.18
I0902 23:48:34.108804 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.91
INFO:tensorflow:Starting iteration 18
I0902 23:48:38.478668 139803223304192 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 221.42

Steps executed: 240 Episode length: 124 Return: -66.06617448968183213
I0902 23:48:43.212952 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.68
INFO:tensorflow:Starting iteration 19

Steps executed: 257 Episode length: 257 Return: -206.6450027575904213
INFO:tensorflow:Average training steps per second: 222.25
I0902 23:48:52.020093 139803223304192 replay_runner.py:36] Average training steps per second: 222.25
I0902 23:48:52.358081 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.65
INFO:tensorflow:Starting iteration 20

Steps executed: 265 Episode length: 152 Return: -76.63710380568291613
INFO:tensorflow:Average training steps per second: 225.94
I0902 23:49:00.998881 139803223304192 replay_runner.py:36] Average training steps per second: 225.94
I0902 23:49:01.238811 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.69
INFO:tensorflow:Starting iteration 21

Steps executed: 327 Episode length: 139 Return: -102.8118445220346513
INFO:tensorflow:Average training steps per second: 225.74
I0902 23:49:09.920074 139803223304192 replay_runner.py:36] Average training steps per second: 225.74
I0902 23:49:10.210757 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.68
INFO:tensorflow:Starting iteration 22

Steps executed: 227 Episode length: 110 Return: -308.8578965475208413
INFO:tensorflow:Average training steps per second: 224.37
I0902 23:49:18.978283 139803223304192 replay_runner.py:36] Average training steps per second: 224.37
I0902 23:49:19.183746 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.32
INFO:tensorflow:Starting iteration 23

Steps executed: 358 Episode length: 195 Return: -206.7923396115091613
INFO:tensorflow:Average training steps per second: 222.65
I0902 23:49:28.057752 139803223304192 replay_runner.py:36] Average training steps per second: 222.65
I0902 23:49:28.386034 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.44
INFO:tensorflow:Starting iteration 24
I0902 23:49:32.605771 139803223304192 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 219.50

Steps executed: 906 Episode length: 906 Return: -699.6224636840918613
I0902 23:49:39.298338 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -699.62
INFO:tensorflow:Starting iteration 25

Steps executed: 275 Episode length: 275 Return: -303.4847829299723613
INFO:tensorflow:Average training steps per second: 219.52
I0902 23:49:48.007626 139803223304192 replay_runner.py:36] Average training steps per second: 219.52
I0902 23:49:48.341694 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.48
INFO:tensorflow:Starting iteration 26

Steps executed: 307 Episode length: 307 Return: -137.6297398428723613
INFO:tensorflow:Average training steps per second: 222.89
I0902 23:49:57.207281 139803223304192 replay_runner.py:36] Average training steps per second: 222.89
I0902 23:49:57.637915 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.63
INFO:tensorflow:Starting iteration 27

Steps executed: 330 Episode length: 330 Return: -518.4353027795764613
INFO:tensorflow:Average training steps per second: 224.56
I0902 23:50:06.427727 139803223304192 replay_runner.py:36] Average training steps per second: 224.56
I0902 23:50:06.785155 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -518.44
INFO:tensorflow:Starting iteration 28

Steps executed: 497 Episode length: 355 Return: -92.23979598978516613
INFO:tensorflow:Average training steps per second: 212.21
I0902 23:50:15.661788 139803223304192 replay_runner.py:36] Average training steps per second: 212.21
I0902 23:50:16.367577 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -324.67
INFO:tensorflow:Starting iteration 29

Steps executed: 224 Episode length: 122 Return: -350.4061981872826513
INFO:tensorflow:Average training steps per second: 217.08
I0902 23:50:25.292469 139803223304192 replay_runner.py:36] Average training steps per second: 217.08

Done fixed training!Episode length: 122 Return: -350.4061981872826513