Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0828 10:32:58.171988 140078257940480 run_experiment.py:549] Creating TrainRunner ...
I0828 10:32:58.182640 140078257940480 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:58.182897 140078257940480 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:58.183046 140078257940480 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:58.183174 140078257940480 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:58.183287 140078257940480 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:58.183396 140078257940480 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:58.183697 140078257940480 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:58.183861 140078257940480 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:58.183986 140078257940480 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:58.184104 140078257940480 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:58.184221 140078257940480 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:58.184340 140078257940480 dqn_agent.py:283] 	 seed: 1630146778182571
I0828 10:32:58.187482 140078257940480 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:58.187691 140078257940480 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:58.187841 140078257940480 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:58.187998 140078257940480 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:58.188222 140078257940480 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:58.188404 140078257940480 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:58.188529 140078257940480 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:58.188651 140078257940480 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:58.188845 140078257940480 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:58.228029 140078257940480 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:58.609282 140078257940480 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:58.624920 140078257940480 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:32:58.632366 140078257940480 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:58.632638 140078257940480 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:58.632877 140078257940480 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:58.633040 140078257940480 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:58.633177 140078257940480 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:58.633430 140078257940480 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:58.633626 140078257940480 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:58.633789 140078257940480 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:58.633906 140078257940480 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:58.634049 140078257940480 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:58.634212 140078257940480 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:58.634300 140078257940480 dqn_agent.py:283] 	 seed: 1630146778632317
I0828 10:32:58.637040 140078257940480 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:58.637235 140078257940480 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:58.637373 140078257940480 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:58.637546 140078257940480 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:58.637644 140078257940480 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:58.637722 140078257940480 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:58.637833 140078257940480 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:58.637950 140078257940480 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:58.638077 140078257940480 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:58.716140 140078257940480 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:58.740979 140078257940480 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:32:58.741245 140078257940480 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 161.13
I0828 10:33:04.947464 140078257940480 replay_runner.py:36] Average training steps per second: 161.13
Steps executed: 272 Episode length: 272 Return: -2042.1930892838484
I0828 10:33:06.579768 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -2042.19
INFO:tensorflow:Starting iteration 1

Steps executed: 276 Episode length: 82 Return: -29.3057180354523874
INFO:tensorflow:Average training steps per second: 219.38
I0828 10:33:15.320721 140078257940480 replay_runner.py:36] Average training steps per second: 219.38
I0828 10:33:15.503799 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -214.24
INFO:tensorflow:Starting iteration 2

Steps executed: 204 Episode length: 77 Return: -449.024551439986574
INFO:tensorflow:Average training steps per second: 217.05
I0828 10:33:24.327427 140078257940480 replay_runner.py:36] Average training steps per second: 217.05
I0828 10:33:24.487572 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -470.86
INFO:tensorflow:Starting iteration 3

Steps executed: 261 Episode length: 86 Return: -484.986003497673134
INFO:tensorflow:Average training steps per second: 227.58
I0828 10:33:33.122207 140078257940480 replay_runner.py:36] Average training steps per second: 227.58
I0828 10:33:33.293494 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.40
INFO:tensorflow:Starting iteration 4

Steps executed: 280 Episode length: 196 Return: -1442.4804707369526
INFO:tensorflow:Average training steps per second: 213.52
I0828 10:33:42.333455 140078257940480 replay_runner.py:36] Average training steps per second: 213.52
I0828 10:33:42.608168 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -953.38
INFO:tensorflow:Starting iteration 5

Steps executed: 225 Episode length: 134 Return: -779.27660318506186
INFO:tensorflow:Average training steps per second: 224.53
I0828 10:33:51.444454 140078257940480 replay_runner.py:36] Average training steps per second: 224.53
I0828 10:33:51.642161 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -692.57
INFO:tensorflow:Starting iteration 6

Steps executed: 252 Episode length: 252 Return: -2579.8307955303853
INFO:tensorflow:Average training steps per second: 232.43
I0828 10:34:00.285914 140078257940480 replay_runner.py:36] Average training steps per second: 232.43
I0828 10:34:00.570498 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -2579.83
INFO:tensorflow:Starting iteration 7

Steps executed: 301 Episode length: 195 Return: -717.04426723068476
INFO:tensorflow:Average training steps per second: 238.86
I0828 10:34:09.055834 140078257940480 replay_runner.py:36] Average training steps per second: 238.86
I0828 10:34:09.325133 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -493.32
INFO:tensorflow:Starting iteration 8

Steps executed: 178 Episode length: 91 Return: -507.308885510593146
INFO:tensorflow:Average training steps per second: 230.71

Steps executed: 343 Episode length: 165 Return: -1231.3653910604492
I0828 10:34:18.424585 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -710.96
INFO:tensorflow:Starting iteration 9

Steps executed: 247 Episode length: 57 Return: -118.484712717380892
INFO:tensorflow:Average training steps per second: 226.50
I0828 10:34:27.250780 140078257940480 replay_runner.py:36] Average training steps per second: 226.50
I0828 10:34:27.414268 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.88
INFO:tensorflow:Starting iteration 10
I0828 10:34:31.806485 140078257940480 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 220.78

Steps executed: 215 Episode length: 75 Return: -522.751433333692132
I0828 10:34:36.543557 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -687.21
INFO:tensorflow:Starting iteration 11

Steps executed: 218 Episode length: 56 Return: -349.945513173881732
INFO:tensorflow:Average training steps per second: 216.88
I0828 10:34:45.500796 140078257940480 replay_runner.py:36] Average training steps per second: 216.88
I0828 10:34:45.687193 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -399.12
INFO:tensorflow:Starting iteration 12

Steps executed: 216 Episode length: 59 Return: -480.550725355821722
INFO:tensorflow:Average training steps per second: 218.84
I0828 10:34:54.701635 140078257940480 replay_runner.py:36] Average training steps per second: 218.84
I0828 10:34:54.885355 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -446.58
INFO:tensorflow:Starting iteration 13

Steps executed: 167 Episode length: 78 Return: -181.938735317041822
INFO:tensorflow:Average training steps per second: 219.23
I0828 10:35:03.836993 140078257940480 replay_runner.py:36] Average training steps per second: 219.23

Steps executed: 232 Episode length: 65 Return: -145.046084570220472
INFO:tensorflow:Starting iteration 14

Steps executed: 210 Episode length: 127 Return: -957.98302919847362
INFO:tensorflow:Average training steps per second: 216.18
I0828 10:35:12.919808 140078257940480 replay_runner.py:36] Average training steps per second: 216.18
I0828 10:35:13.134262 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -815.59
INFO:tensorflow:Starting iteration 15

Steps executed: 105 Episode length: 105 Return: -538.84222383955512
INFO:tensorflow:Average training steps per second: 221.58
I0828 10:35:21.990153 140078257940480 replay_runner.py:36] Average training steps per second: 221.58

Steps executed: 318 Episode length: 213 Return: -1430.9882532209049
INFO:tensorflow:Starting iteration 16

Steps executed: 355 Episode length: 209 Return: -318.34486845973523
INFO:tensorflow:Average training steps per second: 219.51
I0828 10:35:31.161847 140078257940480 replay_runner.py:36] Average training steps per second: 219.51
I0828 10:35:31.470734 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.76
INFO:tensorflow:Starting iteration 17
I0828 10:35:35.842893 140078257940480 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 212.15

Steps executed: 214 Episode length: 214 Return: -221.87580789511682
I0828 10:35:40.762514 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.88
INFO:tensorflow:Starting iteration 18

Steps executed: 163 Episode length: 82 Return: -465.768986111038582
INFO:tensorflow:Average training steps per second: 219.97
I0828 10:35:49.675188 140078257940480 replay_runner.py:36] Average training steps per second: 219.97

Steps executed: 568 Episode length: 405 Return: -792.65764243984232
INFO:tensorflow:Starting iteration 19

Steps executed: 265 Episode length: 99 Return: -554.090920347395628
INFO:tensorflow:Average training steps per second: 224.95
I0828 10:35:59.379273 140078257940480 replay_runner.py:36] Average training steps per second: 224.95
I0828 10:35:59.640106 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -839.23
INFO:tensorflow:Starting iteration 20
I0828 10:36:04.093729 140078257940480 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 227.58
I0828 10:36:08.488269 140078257940480 replay_runner.py:36] Average training steps per second: 227.58

Steps executed: 262 Episode length: 77 Return: -652.572662038074358
INFO:tensorflow:Starting iteration 21

Steps executed: 282 Episode length: 176 Return: -388.06217041526888
INFO:tensorflow:Average training steps per second: 231.94
I0828 10:36:17.446624 140078257940480 replay_runner.py:36] Average training steps per second: 231.94
I0828 10:36:17.698276 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -322.51
INFO:tensorflow:Starting iteration 22
I0828 10:36:22.159140 140078257940480 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 233.85

Steps executed: 240 Episode length: 78 Return: -729.330690302771788
I0828 10:36:26.638271 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -659.06
INFO:tensorflow:Starting iteration 23

Steps executed: 282 Episode length: 103 Return: -533.70687737284838
INFO:tensorflow:Average training steps per second: 235.40
I0828 10:36:35.222560 140078257940480 replay_runner.py:36] Average training steps per second: 235.40
I0828 10:36:35.492670 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -519.88
INFO:tensorflow:Starting iteration 24

Steps executed: 216 Episode length: 216 Return: -1624.8059533722703
INFO:tensorflow:Average training steps per second: 231.68
I0828 10:36:44.200772 140078257940480 replay_runner.py:36] Average training steps per second: 231.68
I0828 10:36:44.443072 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -1624.81
INFO:tensorflow:Starting iteration 25

Steps executed: 263 Episode length: 93 Return: -458.367075213330703
INFO:tensorflow:Average training steps per second: 225.02
I0828 10:36:53.118994 140078257940480 replay_runner.py:36] Average training steps per second: 225.02
I0828 10:36:53.362199 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -470.21
INFO:tensorflow:Starting iteration 26

Steps executed: 355 Episode length: 159 Return: -1177.1243786061475
INFO:tensorflow:Average training steps per second: 229.17
I0828 10:37:02.152765 140078257940480 replay_runner.py:36] Average training steps per second: 229.17
I0828 10:37:02.466308 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -655.79
INFO:tensorflow:Starting iteration 27

Steps executed: 290 Episode length: 211 Return: -1306.6202710870516
INFO:tensorflow:Average training steps per second: 224.26
I0828 10:37:11.330399 140078257940480 replay_runner.py:36] Average training steps per second: 224.26
I0828 10:37:11.615026 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -937.70
INFO:tensorflow:Starting iteration 28

Steps executed: 255 Episode length: 136 Return: -641.62765948305063
INFO:tensorflow:Average training steps per second: 228.69
I0828 10:37:20.194568 140078257940480 replay_runner.py:36] Average training steps per second: 228.69
I0828 10:37:20.404926 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -535.02
INFO:tensorflow:Starting iteration 29

Steps executed: 230 Episode length: 129 Return: -671.23790546268513
INFO:tensorflow:Average training steps per second: 225.11
I0828 10:37:29.067307 140078257940480 replay_runner.py:36] Average training steps per second: 225.11

Done fixed training!Episode length: 129 Return: -671.23790546268513