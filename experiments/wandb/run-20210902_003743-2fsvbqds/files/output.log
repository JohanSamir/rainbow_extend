Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0902 00:37:49.739938 140149719906304 run_experiment.py:549] Creating TrainRunner ...
I0902 00:37:49.748251 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:37:49.748397 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:37:49.748487 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:37:49.748556 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:37:49.748660 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0902 00:37:49.748796 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:37:49.748912 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:37:49.748992 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:37:49.749094 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:37:49.749171 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0902 00:37:49.749249 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:37:49.749325 140149719906304 dqn_agent.py:283] 	 seed: 1630543069748216
I0902 00:37:49.751643 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:37:49.751755 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:37:49.751830 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:37:49.751893 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:37:49.751949 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:37:49.752021 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:37:49.752110 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:37:49.752192 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:37:49.752260 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:37:49.778172 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:37:50.040399 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:37:50.049918 140149719906304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:37:50.057526 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:37:50.057670 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:37:50.057745 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:37:50.057806 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:37:50.057871 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0902 00:37:50.057958 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:37:50.058099 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:37:50.058224 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:37:50.058323 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:37:50.058480 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0902 00:37:50.058650 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:37:50.058765 140149719906304 dqn_agent.py:283] 	 seed: 1630543070057495
I0902 00:37:50.060312 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:37:50.060433 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:37:50.060503 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:37:50.060565 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:37:50.060621 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:37:50.060688 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:37:50.060751 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:37:50.060828 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:37:50.060895 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:37:50.084172 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:37:50.100915 140149719906304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:37:50.101121 140149719906304 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 247.29
I0902 00:37:54.145476 140149719906304 replay_runner.py:36] Average training steps per second: 247.29
I0902 00:37:54.881798 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -371.56
Steps executed: 220 Episode length: 123 Return: -415.8629171570795
INFO:tensorflow:Starting iteration 1
I0902 00:37:58.158349 140149719906304 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 338.76
I0902 00:38:01.110600 140149719906304 replay_runner.py:36] Average training steps per second: 338.76

Steps executed: 232 Episode length: 64 Return: -431.14345990250393
INFO:tensorflow:Starting iteration 2

Steps executed: 272 Episode length: 75 Return: -553.351383532312407
INFO:tensorflow:Average training steps per second: 340.52
I0902 00:38:07.514701 140149719906304 replay_runner.py:36] Average training steps per second: 340.52
I0902 00:38:07.677482 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -526.88
INFO:tensorflow:Starting iteration 3

Steps executed: 268 Episode length: 180 Return: -445.84740582308317
INFO:tensorflow:Average training steps per second: 329.66
I0902 00:38:13.961520 140149719906304 replay_runner.py:36] Average training steps per second: 329.66
I0902 00:38:14.098376 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -460.40
INFO:tensorflow:Starting iteration 4

Steps executed: 279 Episode length: 86 Return: -473.443309354983537
INFO:tensorflow:Average training steps per second: 360.38
I0902 00:38:19.949487 140149719906304 replay_runner.py:36] Average training steps per second: 360.38
I0902 00:38:20.076660 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.37
INFO:tensorflow:Starting iteration 5

Steps executed: 233 Episode length: 86 Return: -146.312431442920687
INFO:tensorflow:Average training steps per second: 353.03
I0902 00:38:26.314066 140149719906304 replay_runner.py:36] Average training steps per second: 353.03
I0902 00:38:26.422295 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -337.90
INFO:tensorflow:Starting iteration 6

Steps executed: 276 Episode length: 89 Return: -306.194657626686657
INFO:tensorflow:Average training steps per second: 341.82
I0902 00:38:32.694577 140149719906304 replay_runner.py:36] Average training steps per second: 341.82
I0902 00:38:32.825653 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.84
INFO:tensorflow:Starting iteration 7

Steps executed: 327 Episode length: 153 Return: -1241.9195856709491
INFO:tensorflow:Average training steps per second: 327.21
I0902 00:38:39.197349 140149719906304 replay_runner.py:36] Average training steps per second: 327.21
I0902 00:38:39.390997 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -798.39
INFO:tensorflow:Starting iteration 8

Steps executed: 275 Episode length: 109 Return: -634.89092046515951
INFO:tensorflow:Average training steps per second: 331.47
I0902 00:38:45.779161 140149719906304 replay_runner.py:36] Average training steps per second: 331.47
I0902 00:38:45.922860 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -530.55
INFO:tensorflow:Starting iteration 9

Steps executed: 253 Episode length: 105 Return: -582.74206943147066
INFO:tensorflow:Average training steps per second: 338.37
I0902 00:38:52.278822 140149719906304 replay_runner.py:36] Average training steps per second: 338.37
I0902 00:38:52.443468 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -525.99
INFO:tensorflow:Starting iteration 10

Steps executed: 253 Episode length: 125 Return: -611.36710645720646
INFO:tensorflow:Average training steps per second: 336.37
I0902 00:38:58.849538 140149719906304 replay_runner.py:36] Average training steps per second: 336.37
I0902 00:38:59.011653 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -894.64
INFO:tensorflow:Starting iteration 11

Steps executed: 293 Episode length: 143 Return: -264.27367646434236
INFO:tensorflow:Average training steps per second: 341.26
I0902 00:39:05.366036 140149719906304 replay_runner.py:36] Average training steps per second: 341.26
I0902 00:39:05.532938 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.94
INFO:tensorflow:Starting iteration 12

Steps executed: 346 Episode length: 346 Return: -880.63166569781956
INFO:tensorflow:Average training steps per second: 341.88
I0902 00:39:11.905883 140149719906304 replay_runner.py:36] Average training steps per second: 341.88
I0902 00:39:12.199447 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -880.63
INFO:tensorflow:Starting iteration 13

Steps executed: 313 Episode length: 115 Return: -474.84843303664933
INFO:tensorflow:Average training steps per second: 343.65
I0902 00:39:18.738498 140149719906304 replay_runner.py:36] Average training steps per second: 343.65
I0902 00:39:18.935827 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -477.55
INFO:tensorflow:Starting iteration 14

Steps executed: 320 Episode length: 128 Return: -788.54701032312743
INFO:tensorflow:Average training steps per second: 345.24
I0902 00:39:25.283287 140149719906304 replay_runner.py:36] Average training steps per second: 345.24
I0902 00:39:25.498062 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -635.52
INFO:tensorflow:Starting iteration 15

Steps executed: 251 Episode length: 105 Return: -642.87411992902833
INFO:tensorflow:Average training steps per second: 339.42
I0902 00:39:31.898259 140149719906304 replay_runner.py:36] Average training steps per second: 339.42
I0902 00:39:32.056553 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -730.58
INFO:tensorflow:Starting iteration 16

Steps executed: 313 Episode length: 206 Return: -131.82760222464844
INFO:tensorflow:Average training steps per second: 332.97
I0902 00:39:38.488555 140149719906304 replay_runner.py:36] Average training steps per second: 332.97
I0902 00:39:38.659423 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.84
INFO:tensorflow:Starting iteration 17

Steps executed: 245 Episode length: 60 Return: -330.377403017748454
INFO:tensorflow:Average training steps per second: 344.21
I0902 00:39:45.023147 140149719906304 replay_runner.py:36] Average training steps per second: 344.21
I0902 00:39:45.172686 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.83
INFO:tensorflow:Starting iteration 18

Steps executed: 127 Episode length: 127 Return: -660.40343523020314
INFO:tensorflow:Average training steps per second: 348.61
I0902 00:39:51.489949 140149719906304 replay_runner.py:36] Average training steps per second: 348.61

Steps executed: 298 Episode length: 171 Return: -839.35822334365084
INFO:tensorflow:Starting iteration 19

Steps executed: 204 Episode length: 61 Return: -450.596446154914274
INFO:tensorflow:Average training steps per second: 345.07
I0902 00:39:58.094738 140149719906304 replay_runner.py:36] Average training steps per second: 345.07
I0902 00:39:58.206675 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -312.27
INFO:tensorflow:Starting iteration 20

Steps executed: 316 Episode length: 316 Return: -1926.0693313161014
INFO:tensorflow:Average training steps per second: 347.47
I0902 00:40:04.580278 140149719906304 replay_runner.py:36] Average training steps per second: 347.47
I0902 00:40:04.869252 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -1926.07
INFO:tensorflow:Starting iteration 21

Steps executed: 242 Episode length: 50 Return: -121.198759104633244
INFO:tensorflow:Average training steps per second: 346.70
I0902 00:40:11.246025 140149719906304 replay_runner.py:36] Average training steps per second: 346.70
I0902 00:40:11.356724 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.63
INFO:tensorflow:Starting iteration 22

Steps executed: 136 Episode length: 76 Return: -548.372208228598244
INFO:tensorflow:Average training steps per second: 355.13
I0902 00:40:17.673167 140149719906304 replay_runner.py:36] Average training steps per second: 355.13

Steps executed: 205 Episode length: 69 Return: -644.731986193945544
INFO:tensorflow:Starting iteration 23
I0902 00:40:21.304951 140149719906304 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 353.49

Steps executed: 246 Episode length: 52 Return: -424.457754386862144
I0902 00:40:24.278749 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -479.28
INFO:tensorflow:Starting iteration 24

Steps executed: 256 Episode length: 67 Return: -513.465705133850314
INFO:tensorflow:Average training steps per second: 353.67
I0902 00:40:30.625537 140149719906304 replay_runner.py:36] Average training steps per second: 353.67
I0902 00:40:30.775313 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -587.41
INFO:tensorflow:Starting iteration 25

Steps executed: 272 Episode length: 86 Return: -880.642783427087754
INFO:tensorflow:Average training steps per second: 358.11
I0902 00:40:37.105651 140149719906304 replay_runner.py:36] Average training steps per second: 358.11
I0902 00:40:37.262559 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -590.77
INFO:tensorflow:Starting iteration 26

Steps executed: 263 Episode length: 68 Return: -608.864535876822644
INFO:tensorflow:Average training steps per second: 358.88
I0902 00:40:43.564847 140149719906304 replay_runner.py:36] Average training steps per second: 358.88
I0902 00:40:43.728893 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -568.84
INFO:tensorflow:Starting iteration 27
I0902 00:40:47.281922 140149719906304 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 362.35
I0902 00:40:50.042083 140149719906304 replay_runner.py:36] Average training steps per second: 362.35

Steps executed: 252 Episode length: 53 Return: -443.819345926899754
INFO:tensorflow:Starting iteration 28

Steps executed: 261 Episode length: 62 Return: -555.951892403883654
INFO:tensorflow:Average training steps per second: 359.84
I0902 00:40:56.533375 140149719906304 replay_runner.py:36] Average training steps per second: 359.84
I0902 00:40:56.679397 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -579.04
INFO:tensorflow:Starting iteration 29

Steps executed: 263 Episode length: 70 Return: -608.239555617208574
INFO:tensorflow:Average training steps per second: 371.86
I0902 00:41:02.874452 140149719906304 replay_runner.py:36] Average training steps per second: 371.86

Done fixed training!Episode length: 70 Return: -608.239555617208574