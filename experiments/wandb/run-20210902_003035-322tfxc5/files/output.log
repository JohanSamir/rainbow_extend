I0902 00:30:41.457293 140413705484288 run_experiment.py:549] Creating TrainRunner ...
I0902 00:30:41.465831 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:30:41.465986 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:30:41.466081 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:30:41.466206 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:30:41.466287 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0902 00:30:41.466395 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:30:41.466517 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:30:41.466582 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:30:41.466658 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:30:41.466741 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0902 00:30:41.466813 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:30:41.466899 140413705484288 dqn_agent.py:283] 	 seed: 1630542641465789
I0902 00:30:41.468801 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:30:41.468926 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:30:41.469009 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:30:41.469076 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:30:41.469138 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:30:41.469220 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:30:41.469287 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:30:41.469385 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:30:41.469460 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:30:41.498714 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:30:41.773175 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:30:41.784416 140413705484288 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:30:41.790879 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:30:41.791041 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:30:41.791119 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:30:41.791227 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:30:41.791301 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0902 00:30:41.791355 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:30:41.791413 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:30:41.791465 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:30:41.791563 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:30:41.791635 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0902 00:30:41.791754 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:30:41.791883 140413705484288 dqn_agent.py:283] 	 seed: 1630542641790842
I0902 00:30:41.794058 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:30:41.794219 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:30:41.794321 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:30:41.794420 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:30:41.794514 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:30:41.794589 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:30:41.794677 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:30:41.794789 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:30:41.794846 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:30:41.817647 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:30:41.833381 140413705484288 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:30:41.833557 140413705484288 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
Steps executed: 303 Episode length: 146 Return: -317.75449757414824
INFO:tensorflow:Average training steps per second: 260.95
I0902 00:30:45.666046 140413705484288 replay_runner.py:36] Average training steps per second: 260.95
I0902 00:30:46.468683 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -347.65
INFO:tensorflow:Starting iteration 1

Steps executed: 304 Episode length: 115 Return: -403.33366185585484
INFO:tensorflow:Average training steps per second: 337.07
I0902 00:30:52.730354 140413705484288 replay_runner.py:36] Average training steps per second: 337.07
I0902 00:30:52.882052 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -445.65
INFO:tensorflow:Starting iteration 2

Steps executed: 138 Episode length: 138 Return: -487.48928903206954
INFO:tensorflow:Average training steps per second: 344.21
I0902 00:30:58.962704 140413705484288 replay_runner.py:36] Average training steps per second: 344.21

Steps executed: 228 Episode length: 90 Return: -390.324013147055274
INFO:tensorflow:Starting iteration 3
I0902 00:31:02.409057 140413705484288 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 357.81

Steps executed: 312 Episode length: 312 Return: -366.60115467632544
I0902 00:31:05.457916 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -366.60
INFO:tensorflow:Starting iteration 4

Steps executed: 296 Episode length: 169 Return: -108.15519476358072
INFO:tensorflow:Average training steps per second: 360.07
I0902 00:31:11.604184 140413705484288 replay_runner.py:36] Average training steps per second: 360.07
I0902 00:31:11.788090 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.42
INFO:tensorflow:Starting iteration 5
I0902 00:31:15.102703 140413705484288 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 349.48

Steps executed: 925 Episode length: 925 Return: -192.05768011892434
I0902 00:31:19.693604 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.06
INFO:tensorflow:Starting iteration 6
I0902 00:31:23.032545 140413705484288 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 349.89

Steps executed: 1000 Episode length: 1000 Return: -541.3327717192493
I0902 00:31:27.812934 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -541.33
INFO:tensorflow:Starting iteration 7

Steps executed: 218 Episode length: 89 Return: -265.1534649388055433
INFO:tensorflow:Average training steps per second: 337.76
I0902 00:31:34.199345 140413705484288 replay_runner.py:36] Average training steps per second: 337.76
I0902 00:31:34.339015 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.43
INFO:tensorflow:Starting iteration 8
I0902 00:31:37.710954 140413705484288 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 331.91
I0902 00:31:40.724226 140413705484288 replay_runner.py:36] Average training steps per second: 331.91

Steps executed: 569 Episode length: 569 Return: -415.615259637401443
INFO:tensorflow:Starting iteration 9

Steps executed: 476 Episode length: 314 Return: -182.747140872826263
INFO:tensorflow:Average training steps per second: 349.67
I0902 00:31:47.675458 140413705484288 replay_runner.py:36] Average training steps per second: 349.67
I0902 00:31:48.042770 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.87
INFO:tensorflow:Starting iteration 10

Steps executed: 354 Episode length: 354 Return: -365.848121946001263
INFO:tensorflow:Average training steps per second: 356.82
I0902 00:31:54.308746 140413705484288 replay_runner.py:36] Average training steps per second: 356.82
I0902 00:31:54.650183 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -365.85
INFO:tensorflow:Starting iteration 11

Steps executed: 202 Episode length: 97 Return: -126.0292470828972663
INFO:tensorflow:Average training steps per second: 344.24
I0902 00:32:00.978853 140413705484288 replay_runner.py:36] Average training steps per second: 344.24
I0902 00:32:01.083856 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.13
INFO:tensorflow:Starting iteration 12
I0902 00:32:04.345130 140413705484288 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 323.64

Steps executed: 418 Episode length: 294 Return: -119.690913378739073
I0902 00:32:07.702926 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.47
INFO:tensorflow:Starting iteration 13

Steps executed: 251 Episode length: 251 Return: -273.899903732802043
INFO:tensorflow:Average training steps per second: 317.62
I0902 00:32:14.013465 140413705484288 replay_runner.py:36] Average training steps per second: 317.62
I0902 00:32:14.205345 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.90
INFO:tensorflow:Starting iteration 14

Steps executed: 281 Episode length: 281 Return: -347.886431351687243
INFO:tensorflow:Average training steps per second: 336.22
I0902 00:32:20.300355 140413705484288 replay_runner.py:36] Average training steps per second: 336.22
I0902 00:32:20.572612 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -347.89
INFO:tensorflow:Starting iteration 15

Steps executed: 253 Episode length: 56 Return: -134.9064916867928343
INFO:tensorflow:Average training steps per second: 358.59
I0902 00:32:26.681217 140413705484288 replay_runner.py:36] Average training steps per second: 358.59
I0902 00:32:26.809012 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.46
INFO:tensorflow:Starting iteration 16

Steps executed: 219 Episode length: 62 Return: -103.9375694377477573
INFO:tensorflow:Average training steps per second: 365.69
I0902 00:32:33.001888 140413705484288 replay_runner.py:36] Average training steps per second: 365.69
I0902 00:32:33.122059 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -238.40
INFO:tensorflow:Starting iteration 17

Steps executed: 261 Episode length: 143 Return: -701.667189400494773
INFO:tensorflow:Average training steps per second: 349.09
I0902 00:32:39.408232 140413705484288 replay_runner.py:36] Average training steps per second: 349.09
I0902 00:32:39.572722 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -669.35
INFO:tensorflow:Starting iteration 18

Steps executed: 356 Episode length: 356 Return: -314.087700557590973
INFO:tensorflow:Average training steps per second: 347.41
I0902 00:32:45.875905 140413705484288 replay_runner.py:36] Average training steps per second: 347.41
I0902 00:32:46.239378 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.09
INFO:tensorflow:Starting iteration 19

Steps executed: 290 Episode length: 134 Return: -74.2286643210320873
INFO:tensorflow:Average training steps per second: 340.29
I0902 00:32:52.579264 140413705484288 replay_runner.py:36] Average training steps per second: 340.29
I0902 00:32:52.736193 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.45
INFO:tensorflow:Starting iteration 20

Steps executed: 279 Episode length: 102 Return: -90.8940596488278273
INFO:tensorflow:Average training steps per second: 357.68
I0902 00:32:58.969502 140413705484288 replay_runner.py:36] Average training steps per second: 357.68
I0902 00:32:59.119238 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -397.00
INFO:tensorflow:Starting iteration 21
I0902 00:33:02.596796 140413705484288 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 361.06
I0902 00:33:05.366668 140413705484288 replay_runner.py:36] Average training steps per second: 361.06

Steps executed: 217 Episode length: 87 Return: -783.8805785998795273
INFO:tensorflow:Starting iteration 22

Steps executed: 263 Episode length: 105 Return: -170.258406242637823
INFO:tensorflow:Average training steps per second: 352.44
I0902 00:33:11.781158 140413705484288 replay_runner.py:36] Average training steps per second: 352.44
I0902 00:33:11.918689 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.15
INFO:tensorflow:Starting iteration 23

Steps executed: 207 Episode length: 68 Return: -585.3226981558098823
INFO:tensorflow:Average training steps per second: 351.68
I0902 00:33:18.210007 140413705484288 replay_runner.py:36] Average training steps per second: 351.68
I0902 00:33:18.324376 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -490.72
INFO:tensorflow:Starting iteration 24

Steps executed: 230 Episode length: 73 Return: -507.5637295897941823
INFO:tensorflow:Average training steps per second: 335.06
I0902 00:33:24.729061 140413705484288 replay_runner.py:36] Average training steps per second: 335.06
I0902 00:33:24.849875 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -472.20
INFO:tensorflow:Starting iteration 25

Steps executed: 200 Episode length: 67 Return: -578.2973682263103823
INFO:tensorflow:Average training steps per second: 338.25
I0902 00:33:31.248333 140413705484288 replay_runner.py:36] Average training steps per second: 338.25
I0902 00:33:31.365556 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -469.41
INFO:tensorflow:Starting iteration 26
I0902 00:33:34.777782 140413705484288 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 338.53

Steps executed: 243 Episode length: 53 Return: -369.1265030987568823
I0902 00:33:37.870995 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -499.03
INFO:tensorflow:Starting iteration 27

Steps executed: 217 Episode length: 82 Return: -568.5084596668727823
INFO:tensorflow:Average training steps per second: 338.52
I0902 00:33:44.209474 140413705484288 replay_runner.py:36] Average training steps per second: 338.52
I0902 00:33:44.316384 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -306.40
INFO:tensorflow:Starting iteration 28

Steps executed: 231 Episode length: 105 Return: -633.073332960499723
INFO:tensorflow:Average training steps per second: 336.62
I0902 00:33:50.722576 140413705484288 replay_runner.py:36] Average training steps per second: 336.62
I0902 00:33:50.855958 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -554.51
INFO:tensorflow:Starting iteration 29

Steps executed: 273 Episode length: 86 Return: -921.1716934476915423
INFO:tensorflow:Average training steps per second: 336.80
I0902 00:33:57.242803 140413705484288 replay_runner.py:36] Average training steps per second: 336.80

Done fixed training!Episode length: 86 Return: -921.1716934476915423