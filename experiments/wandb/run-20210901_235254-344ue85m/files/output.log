Loaded trained dqn in cartpole
Training fixed agent 3, please be patient, may be a while...
I0901 23:53:01.609322 139876902283264 run_experiment.py:549] Creating TrainRunner ...
I0901 23:53:01.618820 139876902283264 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:53:01.619147 139876902283264 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:53:01.619300 139876902283264 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:53:01.619428 139876902283264 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:53:01.619535 139876902283264 dqn_agent.py:275] 	 update_period: 4
I0901 23:53:01.619625 139876902283264 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:53:01.619729 139876902283264 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:53:01.619903 139876902283264 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:53:01.620018 139876902283264 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:53:01.620108 139876902283264 dqn_agent.py:280] 	 optimizer: adam
I0901 23:53:01.620224 139876902283264 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:53:01.620367 139876902283264 dqn_agent.py:283] 	 seed: 1630540381618735
I0901 23:53:01.622927 139876902283264 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:53:01.623177 139876902283264 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 23:53:01.623348 139876902283264 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:53:01.623441 139876902283264 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:53:01.623535 139876902283264 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:53:01.623671 139876902283264 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:53:01.623795 139876902283264 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:53:01.623905 139876902283264 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:53:01.623997 139876902283264 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:53:01.663369 139876902283264 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:53:02.157881 139876902283264 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:53:02.172444 139876902283264 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:53:02.182963 139876902283264 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:53:02.183186 139876902283264 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:53:02.183295 139876902283264 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:53:02.183382 139876902283264 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:53:02.183497 139876902283264 dqn_agent.py:275] 	 update_period: 4
I0901 23:53:02.183719 139876902283264 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:53:02.183950 139876902283264 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:53:02.184122 139876902283264 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:53:02.184220 139876902283264 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:53:02.184345 139876902283264 dqn_agent.py:280] 	 optimizer: adam
I0901 23:53:02.184916 139876902283264 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:53:02.185047 139876902283264 dqn_agent.py:283] 	 seed: 1630540382182913
I0901 23:53:02.187882 139876902283264 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:53:02.188044 139876902283264 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 23:53:02.188168 139876902283264 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:53:02.188238 139876902283264 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:53:02.188327 139876902283264 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:53:02.188448 139876902283264 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:53:02.188530 139876902283264 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:53:02.188696 139876902283264 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:53:02.188798 139876902283264 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:53:02.223408 139876902283264 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:53:02.245663 139876902283264 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:53:02.246014 139876902283264 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 148.80
I0901 23:53:08.967025 139876902283264 replay_runner.py:36] Average training steps per second: 148.80
Steps executed: 207 Episode length: 9 Return: 9.0.0
I0901 23:53:10.115511 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.86
INFO:tensorflow:Starting iteration 1

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 193.67
I0901 23:53:15.469132 139876902283264 replay_runner.py:36] Average training steps per second: 193.67
I0901 23:53:15.616755 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 2

Steps executed: 320 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 200.38
I0901 23:53:20.786307 139876902283264 replay_runner.py:36] Average training steps per second: 200.38
I0901 23:53:20.996248 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 160.00
INFO:tensorflow:Starting iteration 3
I0901 23:53:21.178333 139876902283264 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 191.72
I0901 23:53:26.394581 139876902283264 replay_runner.py:36] Average training steps per second: 191.72
I0901 23:53:26.561010 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 62.50
INFO:tensorflow:Starting iteration 4

Steps executed: 250 Episode length: 67 Return: 67.0.0
INFO:tensorflow:Average training steps per second: 202.17
I0901 23:53:31.703683 139876902283264 replay_runner.py:36] Average training steps per second: 202.17
I0901 23:53:31.885349 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 137.00
INFO:tensorflow:Starting iteration 5


Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 199.45
I0901 23:53:37.091078 139876902283264 replay_runner.py:36] Average training steps per second: 199.45
I0901 23:53:37.215341 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 6
I0901 23:53:37.390085 139876902283264 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 211.34
I0901 23:53:42.122105 139876902283264 replay_runner.py:36] Average training steps per second: 211.34
I0901 23:53:42.311853 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 151.50
INFO:tensorflow:Starting iteration 7

Steps executed: 303 Episode length: 146 Return: 146.0
INFO:tensorflow:Average training steps per second: 204.54
I0901 23:53:47.387969 139876902283264 replay_runner.py:36] Average training steps per second: 204.54

Steps executed: 279 Episode length: 140 Return: 140.0
INFO:tensorflow:Starting iteration 8

Steps executed: 383 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 205.85
I0901 23:53:52.615936 139876902283264 replay_runner.py:36] Average training steps per second: 205.85
I0901 23:53:52.874647 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 191.50
INFO:tensorflow:Starting iteration 9

Steps executed: 276 Episode length: 129 Return: 129.0
INFO:tensorflow:Average training steps per second: 205.06
I0901 23:53:57.947830 139876902283264 replay_runner.py:36] Average training steps per second: 205.06
I0901 23:53:58.120869 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 138.00
INFO:tensorflow:Starting iteration 10

Steps executed: 289 Episode length: 148 Return: 148.0
INFO:tensorflow:Average training steps per second: 196.94
I0901 23:54:03.379636 139876902283264 replay_runner.py:36] Average training steps per second: 196.94
I0901 23:54:03.562481 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 144.50
INFO:tensorflow:Starting iteration 11

Steps executed: 272 Episode length: 140 Return: 140.0
INFO:tensorflow:Average training steps per second: 195.04
I0901 23:54:08.914884 139876902283264 replay_runner.py:36] Average training steps per second: 195.04
I0901 23:54:09.116286 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 136.00
INFO:tensorflow:Starting iteration 12

Steps executed: 316 Episode length: 145 Return: 145.0
INFO:tensorflow:Average training steps per second: 199.66
I0901 23:54:14.315471 139876902283264 replay_runner.py:36] Average training steps per second: 199.66
I0901 23:54:14.515847 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 158.00
INFO:tensorflow:Starting iteration 13
I0901 23:54:14.705033 139876902283264 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 204.03
I0901 23:54:19.606709 139876902283264 replay_runner.py:36] Average training steps per second: 204.03

Steps executed: 252 Episode length: 126 Return: 126.0
INFO:tensorflow:Starting iteration 14

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 195.21
I0901 23:54:25.091411 139876902283264 replay_runner.py:36] Average training steps per second: 195.21
I0901 23:54:25.232089 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 15

Steps executed: 281 Episode length: 145 Return: 145.0
INFO:tensorflow:Average training steps per second: 203.76
I0901 23:54:30.331588 139876902283264 replay_runner.py:36] Average training steps per second: 203.76
I0901 23:54:30.520485 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 140.50
INFO:tensorflow:Starting iteration 16

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 196.13
I0901 23:54:35.809371 139876902283264 replay_runner.py:36] Average training steps per second: 196.13
I0901 23:54:35.936872 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 17

Steps executed: 316 Episode length: 170 Return: 170.0
INFO:tensorflow:Average training steps per second: 202.67
I0901 23:54:41.061730 139876902283264 replay_runner.py:36] Average training steps per second: 202.67
I0901 23:54:41.271719 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 158.00
INFO:tensorflow:Starting iteration 18

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 196.39
I0901 23:54:46.551616 139876902283264 replay_runner.py:36] Average training steps per second: 196.39
I0901 23:54:46.677714 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 19
I0901 23:54:46.858264 139876902283264 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 202.97
I0901 23:54:51.785311 139876902283264 replay_runner.py:36] Average training steps per second: 202.97
I0901 23:54:51.924537 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 20
I0901 23:54:52.119097 139876902283264 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 192.80
I0901 23:54:57.306093 139876902283264 replay_runner.py:36] Average training steps per second: 192.80
I0901 23:54:57.429194 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 21
I0901 23:54:57.614196 139876902283264 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 203.58
I0901 23:55:02.526912 139876902283264 replay_runner.py:36] Average training steps per second: 203.58
I0901 23:55:02.665232 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 22
I0901 23:55:02.864348 139876902283264 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 196.04
I0901 23:55:07.965920 139876902283264 replay_runner.py:36] Average training steps per second: 196.04
I0901 23:55:08.092314 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 23
I0901 23:55:08.490362 139876902283264 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 195.62
I0901 23:55:13.602777 139876902283264 replay_runner.py:36] Average training steps per second: 195.62
I0901 23:55:13.743111 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 24
I0901 23:55:13.921827 139876902283264 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 196.64
I0901 23:55:19.007814 139876902283264 replay_runner.py:36] Average training steps per second: 196.64
I0901 23:55:19.138926 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 25
I0901 23:55:19.307694 139876902283264 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 195.34
I0901 23:55:24.427305 139876902283264 replay_runner.py:36] Average training steps per second: 195.34
I0901 23:55:24.584182 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26
I0901 23:55:24.789115 139876902283264 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 199.82
I0901 23:55:29.794142 139876902283264 replay_runner.py:36] Average training steps per second: 199.82
I0901 23:55:29.922480 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 27
I0901 23:55:30.111652 139876902283264 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 189.90
I0901 23:55:35.378079 139876902283264 replay_runner.py:36] Average training steps per second: 189.90
I0901 23:55:35.534087 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 28
I0901 23:55:35.732527 139876902283264 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 197.01
I0901 23:55:40.808838 139876902283264 replay_runner.py:36] Average training steps per second: 197.01
I0901 23:55:40.947808 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 194.53
I0901 23:55:46.283037 139876902283264 replay_runner.py:36] Average training steps per second: 194.53
I0901 23:55:46.423274 139876902283264 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00