I0905 16:38:34.777271 139789596633088 run_experiment.py:549] Creating TrainRunner ...
I0905 16:38:34.785879 139789596633088 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:38:34.786024 139789596633088 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:38:34.786098 139789596633088 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:38:34.786158 139789596633088 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:38:34.786213 139789596633088 dqn_agent.py:275] 	 update_period: 4
I0905 16:38:34.786294 139789596633088 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:38:34.786391 139789596633088 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:38:34.786452 139789596633088 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:38:34.786504 139789596633088 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:38:34.786578 139789596633088 dqn_agent.py:280] 	 optimizer: adam
I0905 16:38:34.786655 139789596633088 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:38:34.786721 139789596633088 dqn_agent.py:283] 	 seed: 1630859914785843
I0905 16:38:34.788377 139789596633088 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:38:34.788493 139789596633088 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:38:34.788568 139789596633088 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:38:34.788631 139789596633088 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:38:34.788687 139789596633088 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:38:34.788739 139789596633088 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:38:34.788789 139789596633088 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:38:34.788859 139789596633088 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:38:34.788948 139789596633088 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:38:36.073893 139789596633088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0905 16:38:36.313769 139789596633088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:38:36.322781 139789596633088 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:38:36.328707 139789596633088 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:38:36.328844 139789596633088 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:38:36.328922 139789596633088 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:38:36.328988 139789596633088 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:38:36.329048 139789596633088 dqn_agent.py:275] 	 update_period: 4
I0905 16:38:36.329107 139789596633088 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:38:36.329185 139789596633088 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:38:36.329281 139789596633088 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:38:36.329350 139789596633088 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:38:36.329410 139789596633088 dqn_agent.py:280] 	 optimizer: adam
I0905 16:38:36.329484 139789596633088 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:38:36.329555 139789596633088 dqn_agent.py:283] 	 seed: 1630859916328677
I0905 16:38:36.331118 139789596633088 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:38:36.331236 139789596633088 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:38:36.331313 139789596633088 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:38:36.331390 139789596633088 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:38:36.331452 139789596633088 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:38:36.331512 139789596633088 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:38:36.331574 139789596633088 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:38:36.331649 139789596633088 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:38:36.331723 139789596633088 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:38:36.350511 139789596633088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:38:36.363127 139789596633088 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:38:36.363254 139789596633088 replay_runner.py:41] Starting iteration 0
Steps executed: 220 Episode length: 95 Return: -253.57541300610797
INFO:tensorflow:Average training steps per second: 248.83
I0905 16:38:40.382250 139789596633088 replay_runner.py:36] Average training steps per second: 248.83
I0905 16:38:41.139497 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.34
INFO:tensorflow:Starting iteration 1

Steps executed: 204 Episode length: 104 Return: -226.53671129379538
INFO:tensorflow:Average training steps per second: 343.39
I0905 16:38:47.441358 139789596633088 replay_runner.py:36] Average training steps per second: 343.39
I0905 16:38:47.541572 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -369.74
INFO:tensorflow:Starting iteration 2

Steps executed: 258 Episode length: 258 Return: 244.823959792332528
INFO:tensorflow:Average training steps per second: 341.04
I0905 16:38:53.843022 139789596633088 replay_runner.py:36] Average training steps per second: 341.04
I0905 16:38:54.022036 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: 244.82
INFO:tensorflow:Starting iteration 3
I0905 16:38:57.347112 139789596633088 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 342.09

Steps executed: 1000 Episode length: 1000 Return: -170.04412442897856
I0905 16:39:02.895468 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.04
INFO:tensorflow:Starting iteration 4
I0905 16:39:06.272812 139789596633088 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 343.27

Steps executed: 1000 Episode length: 1000 Return: -142.44239478177363
I0905 16:39:10.651274 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.44
INFO:tensorflow:Starting iteration 5
I0905 16:39:13.925677 139789596633088 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 320.32

Steps executed: 1000 Episode length: 1000 Return: -136.71470912822426
I0905 16:39:19.104722 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.71
INFO:tensorflow:Starting iteration 6
I0905 16:39:22.452971 139789596633088 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 321.01

Steps executed: 1000 Episode length: 1000 Return: -118.37632515811615
I0905 16:39:27.373991 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.38
INFO:tensorflow:Starting iteration 7
I0905 16:39:30.774436 139789596633088 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 328.56

Steps executed: 1000 Episode length: 1000 Return: -163.33707378065645
I0905 16:39:35.190834 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.34
INFO:tensorflow:Starting iteration 8

Steps executed: 285 Episode length: 285 Return: -104.8211579132358245
INFO:tensorflow:Average training steps per second: 339.25
I0905 16:39:41.547182 139789596633088 replay_runner.py:36] Average training steps per second: 339.25
I0905 16:39:41.762739 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.82
INFO:tensorflow:Starting iteration 9

Steps executed: 399 Episode length: 399 Return: -151.9579714598148245
INFO:tensorflow:Average training steps per second: 324.34
I0905 16:39:48.095669 139789596633088 replay_runner.py:36] Average training steps per second: 324.34
I0905 16:39:48.452720 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.96
INFO:tensorflow:Starting iteration 10

Steps executed: 1000 Episode length: 1000 Return: -107.56177732782022
INFO:tensorflow:Average training steps per second: 321.82
I0905 16:39:54.894849 139789596633088 replay_runner.py:36] Average training steps per second: 321.82
I0905 16:39:56.065448 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.56
INFO:tensorflow:Starting iteration 11
I0905 16:39:59.471324 139789596633088 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 330.99

Steps executed: 427 Episode length: 427 Return: -285.4614717751867422
I0905 16:40:02.912633 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.46
INFO:tensorflow:Starting iteration 12

Steps executed: 524 Episode length: 524 Return: -397.5920463813644422
INFO:tensorflow:Average training steps per second: 334.87
I0905 16:40:09.226698 139789596633088 replay_runner.py:36] Average training steps per second: 334.87
I0905 16:40:09.717199 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -397.59
INFO:tensorflow:Starting iteration 13
I0905 16:40:13.146518 139789596633088 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 342.11

Steps executed: 1000 Episode length: 1000 Return: -69.800640729846982
I0905 16:40:18.170062 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.80
INFO:tensorflow:Starting iteration 14
I0905 16:40:21.617567 139789596633088 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 338.37

Steps executed: 1000 Episode length: 1000 Return: -96.156114939352722
I0905 16:40:26.974485 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.16
INFO:tensorflow:Starting iteration 15

Steps executed: 217 Episode length: 217 Return: -240.3103375943934522
INFO:tensorflow:Average training steps per second: 340.84
I0905 16:40:33.371886 139789596633088 replay_runner.py:36] Average training steps per second: 340.84
I0905 16:40:33.495687 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -240.31
INFO:tensorflow:Starting iteration 16

Steps executed: 608 Episode length: 419 Return: -265.9344082119847622
INFO:tensorflow:Average training steps per second: 332.34
I0905 16:40:39.934525 139789596633088 replay_runner.py:36] Average training steps per second: 332.34
I0905 16:40:40.460494 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.31
INFO:tensorflow:Starting iteration 17
I0905 16:40:43.847721 139789596633088 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 327.63

Steps executed: 559 Episode length: 559 Return: -331.1126562140797622
I0905 16:40:47.588243 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.11
INFO:tensorflow:Starting iteration 18

Steps executed: 275 Episode length: 142 Return: -84.81833654469483622
INFO:tensorflow:Average training steps per second: 326.30
I0905 16:40:53.906970 139789596633088 replay_runner.py:36] Average training steps per second: 326.30
I0905 16:40:54.055535 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.94
INFO:tensorflow:Starting iteration 19

Steps executed: 161 Episode length: 161 Return: -82.87745349192826622
INFO:tensorflow:Average training steps per second: 328.30
I0905 16:41:00.405443 139789596633088 replay_runner.py:36] Average training steps per second: 328.30

Steps executed: 547 Episode length: 386 Return: -2.031609467564294422
INFO:tensorflow:Starting iteration 20
I0905 16:41:04.093010 139789596633088 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 315.10

Steps executed: 577 Episode length: 577 Return: -79.69903895248986422
I0905 16:41:08.069583 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.70
INFO:tensorflow:Starting iteration 21
I0905 16:41:11.326206 139789596633088 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 329.22

Steps executed: 659 Episode length: 659 Return: -436.6648294512439422
I0905 16:41:15.321569 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -436.66
INFO:tensorflow:Starting iteration 22
I0905 16:41:18.605000 139789596633088 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 328.82

Steps executed: 614 Episode length: 614 Return: -83.87676250001952422
I0905 16:41:22.886951 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.88
INFO:tensorflow:Starting iteration 23

Steps executed: 604 Episode length: 604 Return: -210.4076607877789822
INFO:tensorflow:Average training steps per second: 337.10
I0905 16:41:29.210115 139789596633088 replay_runner.py:36] Average training steps per second: 337.10
I0905 16:41:30.168400 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.41
INFO:tensorflow:Starting iteration 24

Steps executed: 262 Episode length: 125 Return: -498.8033168205471522
INFO:tensorflow:Average training steps per second: 348.22
I0905 16:41:36.381459 139789596633088 replay_runner.py:36] Average training steps per second: 348.22
I0905 16:41:36.521333 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.41
INFO:tensorflow:Starting iteration 25
I0905 16:41:39.941492 139789596633088 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 337.09

Steps executed: 207 Episode length: 207 Return: -566.2071834444732522
I0905 16:41:43.024897 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -566.21
INFO:tensorflow:Starting iteration 26

Steps executed: 619 Episode length: 619 Return: -61.68279275798755522
INFO:tensorflow:Average training steps per second: 353.37
I0905 16:41:49.553406 139789596633088 replay_runner.py:36] Average training steps per second: 353.37
I0905 16:41:50.507385 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.68
INFO:tensorflow:Starting iteration 27

Steps executed: 280 Episode length: 151 Return: -149.9204117531157322
INFO:tensorflow:Average training steps per second: 352.50
I0905 16:41:57.091485 139789596633088 replay_runner.py:36] Average training steps per second: 352.50
I0905 16:41:57.265758 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.35
INFO:tensorflow:Starting iteration 28

Steps executed: 132 Episode length: 132 Return: -86.65820729018691322
INFO:tensorflow:Average training steps per second: 304.06

Steps executed: 1132 Episode length: 1000 Return: -102.44621157929127
I0905 16:42:06.956177 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.55
INFO:tensorflow:Starting iteration 29

Steps executed: 299 Episode length: 299 Return: -316.0410278954914127
INFO:tensorflow:Average training steps per second: 311.68
I0905 16:42:14.045972 139789596633088 replay_runner.py:36] Average training steps per second: 311.68

Done fixed training!Episode length: 299 Return: -316.0410278954914127