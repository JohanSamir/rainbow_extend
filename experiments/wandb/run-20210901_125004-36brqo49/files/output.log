Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0901 12:50:11.287364 140460307478528 run_experiment.py:549] Creating TrainRunner ...
I0901 12:50:11.299586 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:50:11.299900 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:50:11.299990 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:50:11.300071 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:50:11.300203 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 12:50:11.300379 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:50:11.300511 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:50:11.300651 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:50:11.300732 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:50:11.300808 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 12:50:11.300916 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:50:11.301034 140460307478528 dqn_agent.py:283] 	 seed: 1630500611299516
I0901 12:50:11.304501 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:50:11.304765 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:50:11.305038 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:50:11.305218 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:50:11.305673 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:50:11.305876 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:50:11.306035 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:50:11.306300 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:50:11.306429 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:50:11.350892 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:11.857906 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:11.873637 140460307478528 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:50:11.883716 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:50:11.884194 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:50:11.884381 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:50:11.884524 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:50:11.884640 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 12:50:11.884763 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:50:11.884878 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:50:11.885025 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:50:11.885416 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:50:11.885586 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 12:50:11.885861 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:50:11.886000 140460307478528 dqn_agent.py:283] 	 seed: 1630500611883651
I0901 12:50:11.888787 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:50:11.888950 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:50:11.889052 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:50:11.889142 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:50:11.889221 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:50:11.889297 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:50:11.889371 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:50:11.889443 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:50:11.889514 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:50:11.925015 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:11.949953 140460307478528 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:50:11.950239 140460307478528 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 159.77
I0901 12:50:18.209650 140460307478528 replay_runner.py:36] Average training steps per second: 159.77
Steps executed: 283 Episode length: 152 Return: -35.00388566943697
I0901 12:50:19.543006 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -24.49
INFO:tensorflow:Starting iteration 1

Steps executed: 264 Episode length: 264 Return: -604.3320796055731
INFO:tensorflow:Average training steps per second: 225.35
I0901 12:50:28.296685 140460307478528 replay_runner.py:36] Average training steps per second: 225.35
I0901 12:50:28.613054 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -604.33
INFO:tensorflow:Starting iteration 2

Steps executed: 223 Episode length: 113 Return: -367.58107972692113
INFO:tensorflow:Average training steps per second: 227.04
I0901 12:50:37.209161 140460307478528 replay_runner.py:36] Average training steps per second: 227.04
I0901 12:50:37.424252 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -387.84
INFO:tensorflow:Starting iteration 3

Steps executed: 300 Episode length: 128 Return: -44.843286399788994
INFO:tensorflow:Average training steps per second: 230.82
I0901 12:50:46.167754 140460307478528 replay_runner.py:36] Average training steps per second: 230.82
I0901 12:50:46.437587 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.42
INFO:tensorflow:Starting iteration 4

Steps executed: 210 Episode length: 80 Return: -650.918159299932517
INFO:tensorflow:Average training steps per second: 225.73
I0901 12:50:55.229668 140460307478528 replay_runner.py:36] Average training steps per second: 225.73
I0901 12:50:55.420694 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -414.35
INFO:tensorflow:Starting iteration 5

Steps executed: 313 Episode length: 161 Return: -280.87796453937385
INFO:tensorflow:Average training steps per second: 223.32
I0901 12:51:04.359396 140460307478528 replay_runner.py:36] Average training steps per second: 223.32
I0901 12:51:04.642496 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -363.66
INFO:tensorflow:Starting iteration 6

Steps executed: 220 Episode length: 133 Return: -51.324942603799765
INFO:tensorflow:Average training steps per second: 221.57
I0901 12:51:13.487064 140460307478528 replay_runner.py:36] Average training steps per second: 221.57
I0901 12:51:13.696193 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.67
INFO:tensorflow:Starting iteration 7

Steps executed: 229 Episode length: 110 Return: -239.87158069766727
INFO:tensorflow:Average training steps per second: 222.47
I0901 12:51:22.619978 140460307478528 replay_runner.py:36] Average training steps per second: 222.47
I0901 12:51:22.852278 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.07
INFO:tensorflow:Starting iteration 8

Steps executed: 337 Episode length: 140 Return: 15.1803637559603437
INFO:tensorflow:Average training steps per second: 223.45
I0901 12:51:31.756089 140460307478528 replay_runner.py:36] Average training steps per second: 223.45
I0901 12:51:32.057222 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -28.95
INFO:tensorflow:Starting iteration 9

Steps executed: 325 Episode length: 175 Return: -137.19275728168304
INFO:tensorflow:Average training steps per second: 223.27
I0901 12:51:40.966201 140460307478528 replay_runner.py:36] Average training steps per second: 223.27
I0901 12:51:41.269242 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.38
INFO:tensorflow:Starting iteration 10

Steps executed: 228 Episode length: 73 Return: -503.279624981616964
INFO:tensorflow:Average training steps per second: 224.24
I0901 12:51:50.137491 140460307478528 replay_runner.py:36] Average training steps per second: 224.24
I0901 12:51:50.326065 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -465.71
INFO:tensorflow:Starting iteration 11

Steps executed: 243 Episode length: 60 Return: -78.5636561601143964
INFO:tensorflow:Average training steps per second: 222.32
I0901 12:51:59.160602 140460307478528 replay_runner.py:36] Average training steps per second: 222.32
I0901 12:51:59.364846 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -36.51
INFO:tensorflow:Starting iteration 12

Steps executed: 273 Episode length: 130 Return: 64.0656487735988434
INFO:tensorflow:Average training steps per second: 222.68
I0901 12:52:08.113317 140460307478528 replay_runner.py:36] Average training steps per second: 222.68
I0901 12:52:08.349800 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.84
INFO:tensorflow:Starting iteration 13

Steps executed: 246 Episode length: 84 Return: -223.430221583053144
INFO:tensorflow:Average training steps per second: 225.52
I0901 12:52:17.152098 140460307478528 replay_runner.py:36] Average training steps per second: 225.52
I0901 12:52:17.336340 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.73
INFO:tensorflow:Starting iteration 14

Steps executed: 276 Episode length: 113 Return: -165.99412544319568
INFO:tensorflow:Average training steps per second: 227.95
I0901 12:52:26.041123 140460307478528 replay_runner.py:36] Average training steps per second: 227.95
I0901 12:52:26.267440 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.29
INFO:tensorflow:Starting iteration 15

Steps executed: 269 Episode length: 97 Return: -62.1790015606162538
INFO:tensorflow:Average training steps per second: 232.14
I0901 12:52:35.061185 140460307478528 replay_runner.py:36] Average training steps per second: 232.14
I0901 12:52:35.275372 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.06
INFO:tensorflow:Starting iteration 16

Steps executed: 257 Episode length: 120 Return: -164.58851170823135
INFO:tensorflow:Average training steps per second: 224.64
I0901 12:52:44.136124 140460307478528 replay_runner.py:36] Average training steps per second: 224.64
I0901 12:52:44.363484 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.35
INFO:tensorflow:Starting iteration 17
I0901 12:52:48.827134 140460307478528 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 228.94
I0901 12:52:53.195393 140460307478528 replay_runner.py:36] Average training steps per second: 228.94

Steps executed: 242 Episode length: 161 Return: -116.97523586279269
INFO:tensorflow:Starting iteration 18

Steps executed: 262 Episode length: 93 Return: 3.958848763955743369
INFO:tensorflow:Average training steps per second: 226.43
I0901 12:53:01.943712 140460307478528 replay_runner.py:36] Average training steps per second: 226.43
I0901 12:53:02.142956 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.00
INFO:tensorflow:Starting iteration 19

Steps executed: 209 Episode length: 54 Return: -121.588281260681569
INFO:tensorflow:Average training steps per second: 221.88
I0901 12:53:11.092850 140460307478528 replay_runner.py:36] Average training steps per second: 221.88
I0901 12:53:11.247313 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -204.46
INFO:tensorflow:Starting iteration 20

Steps executed: 260 Episode length: 74 Return: -150.057314768341269
INFO:tensorflow:Average training steps per second: 217.78
I0901 12:53:20.212237 140460307478528 replay_runner.py:36] Average training steps per second: 217.78
I0901 12:53:20.442521 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.37
INFO:tensorflow:Starting iteration 21
I0901 12:53:24.904847 140460307478528 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 223.09
I0901 12:53:29.388084 140460307478528 replay_runner.py:36] Average training steps per second: 223.09

Steps executed: 299 Episode length: 299 Return: -247.76471534238715
INFO:tensorflow:Starting iteration 22

Steps executed: 401 Episode length: 298 Return: -614.07047196072454
INFO:tensorflow:Average training steps per second: 225.24
I0901 12:53:38.581810 140460307478528 replay_runner.py:36] Average training steps per second: 225.24
I0901 12:53:39.036274 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -456.18
INFO:tensorflow:Starting iteration 23

Steps executed: 212 Episode length: 70 Return: -320.728080449723174
INFO:tensorflow:Average training steps per second: 223.04
I0901 12:53:48.022727 140460307478528 replay_runner.py:36] Average training steps per second: 223.04
I0901 12:53:48.212777 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.29
INFO:tensorflow:Starting iteration 24

Steps executed: 216 Episode length: 103 Return: -313.43340484479677
INFO:tensorflow:Average training steps per second: 227.61
I0901 12:53:57.132971 140460307478528 replay_runner.py:36] Average training steps per second: 227.61
I0901 12:53:57.314037 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -340.84
INFO:tensorflow:Starting iteration 25

Steps executed: 265 Episode length: 99 Return: -186.015354142421877
INFO:tensorflow:Average training steps per second: 222.92
I0901 12:54:06.244601 140460307478528 replay_runner.py:36] Average training steps per second: 222.92
I0901 12:54:06.445273 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.96
INFO:tensorflow:Starting iteration 26

Steps executed: 250 Episode length: 82 Return: -334.012594424599347
INFO:tensorflow:Average training steps per second: 226.27
I0901 12:54:15.233178 140460307478528 replay_runner.py:36] Average training steps per second: 226.27
I0901 12:54:15.456217 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -518.65
INFO:tensorflow:Starting iteration 27

Steps executed: 252 Episode length: 70 Return: -229.157690281786647
INFO:tensorflow:Average training steps per second: 228.49
I0901 12:54:24.290438 140460307478528 replay_runner.py:36] Average training steps per second: 228.49
I0901 12:54:24.485808 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.78
INFO:tensorflow:Starting iteration 28

Steps executed: 264 Episode length: 124 Return: -227.85108105482594
INFO:tensorflow:Average training steps per second: 224.06
I0901 12:54:33.454960 140460307478528 replay_runner.py:36] Average training steps per second: 224.06
I0901 12:54:33.674013 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -267.26
INFO:tensorflow:Starting iteration 29

Steps executed: 312 Episode length: 121 Return: -268.72112058394464
INFO:tensorflow:Average training steps per second: 225.98
I0901 12:54:42.547747 140460307478528 replay_runner.py:36] Average training steps per second: 225.98

Done fixed training!Episode length: 121 Return: -268.72112058394464