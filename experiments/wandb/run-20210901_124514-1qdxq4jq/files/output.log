Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0901 12:45:21.250042 140460307478528 run_experiment.py:549] Creating TrainRunner ...
I0901 12:45:21.262353 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:45:21.262550 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:45:21.262650 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:45:21.262718 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:45:21.262822 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 12:45:21.262888 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:45:21.262942 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:45:21.263012 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:45:21.263135 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:45:21.263245 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 12:45:21.263469 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:45:21.263563 140460307478528 dqn_agent.py:283] 	 seed: 1630500321262305
I0901 12:45:21.266856 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:45:21.267091 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:45:21.267250 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:45:21.267370 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:45:21.267741 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:45:21.267916 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:45:21.268054 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:45:21.268198 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:45:21.268326 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:45:21.310069 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:45:21.711106 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:45:21.727041 140460307478528 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:45:21.759662 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:45:21.759929 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:45:21.760083 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:45:21.760319 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:45:21.760589 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 12:45:21.760802 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:45:21.760923 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:45:21.761114 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:45:21.761284 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:45:21.761529 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 12:45:21.761644 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:45:21.762083 140460307478528 dqn_agent.py:283] 	 seed: 1630500321759602
I0901 12:45:21.765021 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:45:21.765207 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:45:21.765596 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:45:21.765804 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:45:21.766019 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:45:21.766214 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:45:21.766418 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:45:21.766537 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:45:21.766710 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:45:21.804445 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:45:21.829849 140460307478528 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:45:21.830365 140460307478528 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 155.40
I0901 12:45:28.265575 140460307478528 replay_runner.py:36] Average training steps per second: 155.40
Steps executed: 236 Episode length: 141 Return: -385.68612864732387
I0901 12:45:29.520874 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -504.18
INFO:tensorflow:Starting iteration 1

Steps executed: 127 Episode length: 127 Return: -414.34203541340057
INFO:tensorflow:Average training steps per second: 213.20
I0901 12:45:38.662778 140460307478528 replay_runner.py:36] Average training steps per second: 213.20

Steps executed: 206 Episode length: 79 Return: -266.781217669534047
INFO:tensorflow:Starting iteration 2

Steps executed: 266 Episode length: 122 Return: -106.91477373077159
INFO:tensorflow:Average training steps per second: 218.77
I0901 12:45:47.919662 140460307478528 replay_runner.py:36] Average training steps per second: 218.77
I0901 12:45:48.230333 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.39
INFO:tensorflow:Starting iteration 3

Steps executed: 226 Episode length: 226 Return: -50.378282698654544
INFO:tensorflow:Average training steps per second: 214.82
I0901 12:45:57.112580 140460307478528 replay_runner.py:36] Average training steps per second: 214.82
I0901 12:45:57.374267 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -50.38
INFO:tensorflow:Starting iteration 4

Steps executed: 210 Episode length: 129 Return: -139.10350660919352
INFO:tensorflow:Average training steps per second: 218.10
I0901 12:46:06.338452 140460307478528 replay_runner.py:36] Average training steps per second: 218.10
I0901 12:46:06.519306 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.40
INFO:tensorflow:Starting iteration 5

Steps executed: 228 Episode length: 75 Return: -282.941993728973352
INFO:tensorflow:Average training steps per second: 228.87
I0901 12:46:15.300899 140460307478528 replay_runner.py:36] Average training steps per second: 228.87
I0901 12:46:15.476685 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.64
INFO:tensorflow:Starting iteration 6

Steps executed: 274 Episode length: 126 Return: 10.7805808837760542
INFO:tensorflow:Average training steps per second: 218.44
I0901 12:46:24.393537 140460307478528 replay_runner.py:36] Average training steps per second: 218.44
I0901 12:46:24.641593 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.02
INFO:tensorflow:Starting iteration 7

Steps executed: 276 Episode length: 85 Return: -91.0006425128711832
INFO:tensorflow:Average training steps per second: 224.32
I0901 12:46:33.324316 140460307478528 replay_runner.py:36] Average training steps per second: 224.32
I0901 12:46:33.511654 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.21
INFO:tensorflow:Starting iteration 8
I0901 12:46:37.883082 140460307478528 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 218.51

Steps executed: 504 Episode length: 504 Return: -1291.1890899081832
I0901 12:46:43.512278 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -1291.19
INFO:tensorflow:Starting iteration 9

Steps executed: 435 Episode length: 251 Return: -190.73264437463242
INFO:tensorflow:Average training steps per second: 217.83
I0901 12:46:52.522897 140460307478528 replay_runner.py:36] Average training steps per second: 217.83
I0901 12:46:53.010232 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.39
INFO:tensorflow:Starting iteration 10

Steps executed: 242 Episode length: 92 Return: -185.794784188146483
INFO:tensorflow:Average training steps per second: 224.22
I0901 12:47:01.869464 140460307478528 replay_runner.py:36] Average training steps per second: 224.22
I0901 12:47:02.094646 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.45
INFO:tensorflow:Starting iteration 11

Steps executed: 270 Episode length: 83 Return: -472.770945041660333
INFO:tensorflow:Average training steps per second: 225.62
I0901 12:47:10.989899 140460307478528 replay_runner.py:36] Average training steps per second: 225.62
I0901 12:47:11.208772 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -422.54
INFO:tensorflow:Starting iteration 12

Steps executed: 237 Episode length: 174 Return: -9.1855786135077153
INFO:tensorflow:Average training steps per second: 223.25
I0901 12:47:20.073929 140460307478528 replay_runner.py:36] Average training steps per second: 223.25
I0901 12:47:20.272047 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.58
INFO:tensorflow:Starting iteration 13

Steps executed: 253 Episode length: 74 Return: -413.553278083933553
INFO:tensorflow:Average training steps per second: 225.52
I0901 12:47:29.106258 140460307478528 replay_runner.py:36] Average training steps per second: 225.52
I0901 12:47:29.310075 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -386.56
INFO:tensorflow:Starting iteration 14

Steps executed: 540 Episode length: 540 Return: 255.036030670402283
INFO:tensorflow:Average training steps per second: 226.82
I0901 12:47:38.093556 140460307478528 replay_runner.py:36] Average training steps per second: 226.82
I0901 12:47:39.023086 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: 255.04
INFO:tensorflow:Starting iteration 15

Steps executed: 285 Episode length: 92 Return: -330.268180644594963
INFO:tensorflow:Average training steps per second: 225.89
I0901 12:47:47.821939 140460307478528 replay_runner.py:36] Average training steps per second: 225.89
I0901 12:47:48.076632 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.73
INFO:tensorflow:Starting iteration 16

Steps executed: 231 Episode length: 54 Return: -385.874275531898963
INFO:tensorflow:Average training steps per second: 224.96
I0901 12:47:56.915319 140460307478528 replay_runner.py:36] Average training steps per second: 224.96
I0901 12:47:57.117710 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -519.00
INFO:tensorflow:Starting iteration 17

Steps executed: 237 Episode length: 91 Return: -215.806544546879263
INFO:tensorflow:Average training steps per second: 230.79
I0901 12:48:05.825845 140460307478528 replay_runner.py:36] Average training steps per second: 230.79
I0901 12:48:06.021049 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.09
INFO:tensorflow:Starting iteration 18

Steps executed: 257 Episode length: 72 Return: -276.326418393919163
INFO:tensorflow:Average training steps per second: 225.84
I0901 12:48:14.857522 140460307478528 replay_runner.py:36] Average training steps per second: 225.84
I0901 12:48:15.080644 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -365.29
INFO:tensorflow:Starting iteration 19

Steps executed: 241 Episode length: 75 Return: -638.625441206411463
INFO:tensorflow:Average training steps per second: 220.15
I0901 12:48:23.989555 140460307478528 replay_runner.py:36] Average training steps per second: 220.15
I0901 12:48:24.195822 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -448.83
INFO:tensorflow:Starting iteration 20

Steps executed: 151 Episode length: 78 Return: -442.349620559576663
INFO:tensorflow:Average training steps per second: 225.38
I0901 12:48:33.024428 140460307478528 replay_runner.py:36] Average training steps per second: 225.38

Steps executed: 220 Episode length: 69 Return: -326.905531913727163
INFO:tensorflow:Starting iteration 21

Steps executed: 205 Episode length: 75 Return: -681.670903425291463
INFO:tensorflow:Average training steps per second: 229.46
I0901 12:48:42.025344 140460307478528 replay_runner.py:36] Average training steps per second: 229.46
I0901 12:48:42.202445 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -627.84
INFO:tensorflow:Starting iteration 22

Steps executed: 269 Episode length: 114 Return: -1038.2814142107022
INFO:tensorflow:Average training steps per second: 230.94
I0901 12:48:50.875558 140460307478528 replay_runner.py:36] Average training steps per second: 230.94
I0901 12:48:51.114051 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -739.02
INFO:tensorflow:Starting iteration 23
I0901 12:48:55.501907 140460307478528 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 229.20

Steps executed: 244 Episode length: 51 Return: -328.186376925076732
I0901 12:49:00.078099 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -462.04
INFO:tensorflow:Starting iteration 24

Steps executed: 256 Episode length: 63 Return: -470.765929623082632
INFO:tensorflow:Average training steps per second: 225.57
I0901 12:49:08.922447 140460307478528 replay_runner.py:36] Average training steps per second: 225.57
I0901 12:49:09.156278 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -489.94
INFO:tensorflow:Starting iteration 25

Steps executed: 240 Episode length: 51 Return: -361.494471722889162
INFO:tensorflow:Average training steps per second: 230.51
I0901 12:49:17.916653 140460307478528 replay_runner.py:36] Average training steps per second: 230.51
I0901 12:49:18.115157 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.29
INFO:tensorflow:Starting iteration 26

Steps executed: 219 Episode length: 67 Return: -473.381806293455552
INFO:tensorflow:Average training steps per second: 233.72
I0901 12:49:26.777397 140460307478528 replay_runner.py:36] Average training steps per second: 233.72
I0901 12:49:26.950620 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -493.80
INFO:tensorflow:Starting iteration 27

Steps executed: 253 Episode length: 86 Return: -695.909253268889292
INFO:tensorflow:Average training steps per second: 227.13
I0901 12:49:35.657445 140460307478528 replay_runner.py:36] Average training steps per second: 227.13
I0901 12:49:35.853687 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -321.79
INFO:tensorflow:Starting iteration 28

Steps executed: 207 Episode length: 85 Return: -739.306243740632692
INFO:tensorflow:Average training steps per second: 223.22
I0901 12:49:44.658639 140460307478528 replay_runner.py:36] Average training steps per second: 223.22
I0901 12:49:44.839976 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -571.44
INFO:tensorflow:Starting iteration 29
I0901 12:49:49.195938 140460307478528 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 224.18

Steps executed: 223 Episode length: 52 Return: -256.480309035516292

Done fixed training!Episode length: 52 Return: -256.480309035516292