Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0902 00:27:29.619583 139825600018432 run_experiment.py:549] Creating TrainRunner ...
I0902 00:27:29.627267 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:27:29.627444 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:27:29.627567 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:27:29.627726 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:27:29.627826 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0902 00:27:29.627903 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:27:29.628065 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:27:29.628145 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:27:29.628216 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:27:29.628322 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:27:29.628395 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:27:29.628486 139825600018432 dqn_agent.py:283] 	 seed: 1630542449627216
I0902 00:27:29.630912 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:27:29.631069 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:27:29.631171 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:27:29.631253 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:27:29.631311 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:27:29.631395 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:27:29.631485 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:27:29.631546 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:27:29.631618 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:27:29.657552 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:27:29.939548 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:27:29.948949 139825600018432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:27:29.955609 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:27:29.955765 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:27:29.955847 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:27:29.955916 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:27:29.955979 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0902 00:27:29.956056 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:27:29.956142 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:27:29.956239 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:27:29.956315 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:27:29.956395 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:27:29.956470 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:27:29.956545 139825600018432 dqn_agent.py:283] 	 seed: 1630542449955573
I0902 00:27:29.958876 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:27:29.959094 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:27:29.959222 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:27:29.959357 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:27:29.959489 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:27:29.959602 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:27:29.959712 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:27:29.959819 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:27:29.959993 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:27:29.979902 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:27:29.997233 139825600018432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:27:29.997421 139825600018432 replay_runner.py:41] Starting iteration 0
Steps executed: 249 Episode length: 117 Return: -404.5490717923089
INFO:tensorflow:Average training steps per second: 244.67
I0902 00:27:34.084775 139825600018432 replay_runner.py:36] Average training steps per second: 244.67
I0902 00:27:34.788342 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -393.62
INFO:tensorflow:Starting iteration 1
I0902 00:27:38.218737 139825600018432 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 327.22

Steps executed: 294 Episode length: 294 Return: -300.2585167685668
I0902 00:27:41.502161 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.26
INFO:tensorflow:Starting iteration 2

Steps executed: 303 Episode length: 160 Return: -466.11336269916694
INFO:tensorflow:Average training steps per second: 338.12
I0902 00:27:47.867244 139825600018432 replay_runner.py:36] Average training steps per second: 338.12
I0902 00:27:48.055800 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -441.29
INFO:tensorflow:Starting iteration 3
I0902 00:27:51.403800 139825600018432 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 342.50
I0902 00:27:54.323804 139825600018432 replay_runner.py:36] Average training steps per second: 342.50

Steps executed: 688 Episode length: 688 Return: -366.23549484204074
INFO:tensorflow:Starting iteration 4

Steps executed: 1000 Episode length: 1000 Return: -114.85404538831517
INFO:tensorflow:Average training steps per second: 329.74
I0902 00:28:01.658270 139825600018432 replay_runner.py:36] Average training steps per second: 329.74
I0902 00:28:03.343845 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.85
INFO:tensorflow:Starting iteration 5

Steps executed: 351 Episode length: 351 Return: -188.2700109091091517
INFO:tensorflow:Average training steps per second: 329.13
I0902 00:28:09.730679 139825600018432 replay_runner.py:36] Average training steps per second: 329.13
I0902 00:28:10.001622 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.27
INFO:tensorflow:Starting iteration 6
I0902 00:28:13.423642 139825600018432 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 336.24

Steps executed: 1000 Episode length: 1000 Return: -64.372969957290767
I0902 00:28:18.837068 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -64.37
INFO:tensorflow:Starting iteration 7
I0902 00:28:22.279621 139825600018432 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 330.70

Steps executed: 746 Episode length: 746 Return: -288.6096493229507667
I0902 00:28:26.808382 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.61
INFO:tensorflow:Starting iteration 8
I0902 00:28:30.214239 139825600018432 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 329.40

Steps executed: 598 Episode length: 598 Return: -244.0125486409979867
I0902 00:28:34.110481 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.01
INFO:tensorflow:Starting iteration 9

Steps executed: 856 Episode length: 680 Return: -156.4431076763151367
INFO:tensorflow:Average training steps per second: 323.42
I0902 00:28:40.419396 139825600018432 replay_runner.py:36] Average training steps per second: 323.42
I0902 00:28:41.302981 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.81
INFO:tensorflow:Starting iteration 10
I0902 00:28:44.466909 139825600018432 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 316.47

Steps executed: 1000 Episode length: 1000 Return: -293.92163025199787
I0902 00:28:49.121444 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.92
INFO:tensorflow:Starting iteration 11

Steps executed: 243 Episode length: 243 Return: -75.32739898219359787
INFO:tensorflow:Average training steps per second: 327.05
I0902 00:28:55.447432 139825600018432 replay_runner.py:36] Average training steps per second: 327.05
I0902 00:28:55.594509 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.33
INFO:tensorflow:Starting iteration 12
I0902 00:28:58.940102 139825600018432 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 351.46

Steps executed: 1000 Episode length: 1000 Return: 18.5246699426663887
I0902 00:29:03.415983 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: 18.52
INFO:tensorflow:Starting iteration 13
I0902 00:29:06.767710 139825600018432 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 340.46

Steps executed: 385 Episode length: 247 Return: -152.3366000976471487
I0902 00:29:09.972884 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.75
INFO:tensorflow:Starting iteration 14

Steps executed: 222 Episode length: 56 Return: -265.05788173615406787
INFO:tensorflow:Average training steps per second: 355.15
I0902 00:29:16.263720 139825600018432 replay_runner.py:36] Average training steps per second: 355.15
I0902 00:29:16.381914 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.83
INFO:tensorflow:Starting iteration 15
I0902 00:29:19.866696 139825600018432 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 337.27

Steps executed: 720 Episode length: 720 Return: -122.0199170165990487
I0902 00:29:24.233973 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.02
INFO:tensorflow:Starting iteration 16

Steps executed: 280 Episode length: 151 Return: -110.7225185047188687
INFO:tensorflow:Average training steps per second: 353.31
I0902 00:29:30.575812 139825600018432 replay_runner.py:36] Average training steps per second: 353.31
I0902 00:29:30.732403 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.36
INFO:tensorflow:Starting iteration 17

Steps executed: 229 Episode length: 229 Return: 24.734334540187198687
INFO:tensorflow:Average training steps per second: 339.24
I0902 00:29:37.134477 139825600018432 replay_runner.py:36] Average training steps per second: 339.24
I0902 00:29:37.315840 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: 24.73
INFO:tensorflow:Starting iteration 18

Steps executed: 1000 Episode length: 1000 Return: -87.917844290142687
INFO:tensorflow:Average training steps per second: 345.77
I0902 00:29:43.672516 139825600018432 replay_runner.py:36] Average training steps per second: 345.77
I0902 00:29:45.323557 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.92
INFO:tensorflow:Starting iteration 19

Steps executed: 427 Episode length: 427 Return: -45.22814769350287687
INFO:tensorflow:Average training steps per second: 332.76
I0902 00:29:51.765534 139825600018432 replay_runner.py:36] Average training steps per second: 332.76
I0902 00:29:52.219208 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -45.23
INFO:tensorflow:Starting iteration 20

Steps executed: 118 Episode length: 118 Return: -26.63405597659691287
INFO:tensorflow:Average training steps per second: 335.25

Steps executed: 1118 Episode length: 1000 Return: 122.081241794561957
I0902 00:30:00.273248 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: 47.72
INFO:tensorflow:Starting iteration 21

Steps executed: 341 Episode length: 178 Return: -550.2999815760438957
INFO:tensorflow:Average training steps per second: 328.65
I0902 00:30:06.644087 139825600018432 replay_runner.py:36] Average training steps per second: 328.65
I0902 00:30:06.868922 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -544.03
INFO:tensorflow:Starting iteration 22

Steps executed: 295 Episode length: 135 Return: -228.6784378947202457
INFO:tensorflow:Average training steps per second: 326.70
I0902 00:30:13.272279 139825600018432 replay_runner.py:36] Average training steps per second: 326.70
I0902 00:30:13.465102 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.31
INFO:tensorflow:Starting iteration 23
I0902 00:30:16.858371 139825600018432 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 350.44

Steps executed: 298 Episode length: 107 Return: -123.9476069154107457
I0902 00:30:19.923860 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.44
INFO:tensorflow:Starting iteration 24

Steps executed: 427 Episode length: 314 Return: -264.8568094315687657
INFO:tensorflow:Average training steps per second: 352.10
I0902 00:30:26.245047 139825600018432 replay_runner.py:36] Average training steps per second: 352.10
I0902 00:30:26.649707 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.02
INFO:tensorflow:Starting iteration 25

Steps executed: 390 Episode length: 209 Return: -413.6454935925883757
INFO:tensorflow:Average training steps per second: 341.48
I0902 00:30:32.969482 139825600018432 replay_runner.py:36] Average training steps per second: 341.48
I0902 00:30:33.265936 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -451.97
INFO:tensorflow:Starting iteration 26

Steps executed: 277 Episode length: 124 Return: -95.94467167619244357
INFO:tensorflow:Average training steps per second: 358.76
I0902 00:30:39.444492 139825600018432 replay_runner.py:36] Average training steps per second: 358.76
I0902 00:30:39.623742 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.06
INFO:tensorflow:Starting iteration 27
I0902 00:30:43.063202 139825600018432 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 351.48

Steps executed: 266 Episode length: 74 Return: -640.30907493948226357
I0902 00:30:46.028824 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.75
INFO:tensorflow:Starting iteration 28

Steps executed: 361 Episode length: 173 Return: 0.3425688270498170657
INFO:tensorflow:Average training steps per second: 338.18
I0902 00:30:52.278841 139825600018432 replay_runner.py:36] Average training steps per second: 338.18
I0902 00:30:52.548161 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -55.62
INFO:tensorflow:Starting iteration 29

Steps executed: 288 Episode length: 110 Return: -120.9363319680990357
INFO:tensorflow:Average training steps per second: 334.55
I0902 00:30:58.710368 139825600018432 replay_runner.py:36] Average training steps per second: 334.55

Done fixed training!Episode length: 110 Return: -120.9363319680990357