Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0905 19:02:22.896106 139920723499008 run_experiment.py:549] Creating TrainRunner ...
I0905 19:02:22.906920 139920723499008 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 19:02:22.907123 139920723499008 dqn_agent.py:272] 	 gamma: 0.990000
I0905 19:02:22.907263 139920723499008 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 19:02:22.907375 139920723499008 dqn_agent.py:274] 	 min_replay_history: 500
I0905 19:02:22.907475 139920723499008 dqn_agent.py:275] 	 update_period: 4
I0905 19:02:22.907579 139920723499008 dqn_agent.py:276] 	 target_update_period: 300
I0905 19:02:22.907674 139920723499008 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 19:02:22.907795 139920723499008 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 19:02:22.907890 139920723499008 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 19:02:22.907977 139920723499008 dqn_agent.py:280] 	 optimizer: adam
I0905 19:02:22.908066 139920723499008 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 19:02:22.908154 139920723499008 dqn_agent.py:283] 	 seed: 1630868542906868
I0905 19:02:22.910996 139920723499008 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 19:02:22.911160 139920723499008 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 19:02:22.911289 139920723499008 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 19:02:22.911398 139920723499008 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 19:02:22.911502 139920723499008 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 19:02:22.911621 139920723499008 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 19:02:22.911724 139920723499008 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 19:02:22.911812 139920723499008 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 19:02:22.911901 139920723499008 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 19:02:22.958758 139920723499008 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 19:02:23.260986 139920723499008 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 19:02:23.272370 139920723499008 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 19:02:23.279989 139920723499008 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 19:02:23.280176 139920723499008 dqn_agent.py:272] 	 gamma: 0.990000
I0905 19:02:23.280278 139920723499008 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 19:02:23.280422 139920723499008 dqn_agent.py:274] 	 min_replay_history: 500
I0905 19:02:23.280529 139920723499008 dqn_agent.py:275] 	 update_period: 4
I0905 19:02:23.280617 139920723499008 dqn_agent.py:276] 	 target_update_period: 300
I0905 19:02:23.280712 139920723499008 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 19:02:23.280846 139920723499008 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 19:02:23.280934 139920723499008 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 19:02:23.281066 139920723499008 dqn_agent.py:280] 	 optimizer: adam
I0905 19:02:23.281177 139920723499008 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 19:02:23.281295 139920723499008 dqn_agent.py:283] 	 seed: 1630868543279935
I0905 19:02:23.283642 139920723499008 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 19:02:23.283824 139920723499008 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 19:02:23.283935 139920723499008 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 19:02:23.284015 139920723499008 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 19:02:23.284097 139920723499008 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 19:02:23.284181 139920723499008 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 19:02:23.284270 139920723499008 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 19:02:23.284353 139920723499008 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 19:02:23.284431 139920723499008 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 19:02:23.318169 139920723499008 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 19:02:23.338902 139920723499008 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 19:02:23.339228 139920723499008 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 186.59
I0905 19:02:28.699272 139920723499008 replay_runner.py:36] Average training steps per second: 186.59
I0905 19:02:29.623271 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -473.76
Steps executed: 245 Episode length: 132 Return: -436.5442407753319
INFO:tensorflow:Starting iteration 1
I0905 19:02:32.993761 139920723499008 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 255.14
I0905 19:02:36.913850 139920723499008 replay_runner.py:36] Average training steps per second: 255.14

Steps executed: 250 Episode length: 250 Return: -558.7224386959921
INFO:tensorflow:Starting iteration 2
I0905 19:02:41.130353 139920723499008 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 277.25
I0905 19:02:44.737823 139920723499008 replay_runner.py:36] Average training steps per second: 277.25

Steps executed: 513 Episode length: 368 Return: -276.8817226029672
INFO:tensorflow:Starting iteration 3
I0905 19:02:49.265631 139920723499008 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 282.67

Steps executed: 1000 Episode length: 1000 Return: -161.7794215223614
I0905 19:02:54.897601 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.78
INFO:tensorflow:Starting iteration 4

Steps executed: 193 Episode length: 193 Return: -96.8215591083527414
INFO:tensorflow:Average training steps per second: 266.87

Steps executed: 1193 Episode length: 1000 Return: -116.72113636654431
I0905 19:03:06.106249 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.77
INFO:tensorflow:Starting iteration 5
I0905 19:03:09.986170 139920723499008 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 280.42

Steps executed: 1000 Episode length: 1000 Return: -196.94859954125357
I0905 19:03:14.999701 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.95
INFO:tensorflow:Starting iteration 6
I0905 19:03:18.898511 139920723499008 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 268.51

Steps executed: 548 Episode length: 359 Return: -574.4457445971497357
I0905 19:03:23.320142 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -486.07
INFO:tensorflow:Starting iteration 7
I0905 19:03:27.318686 139920723499008 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 301.72

Steps executed: 301 Episode length: 301 Return: -372.2236919873506357
I0905 19:03:31.000632 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -372.22
INFO:tensorflow:Starting iteration 8
I0905 19:03:34.992642 139920723499008 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 276.85

Steps executed: 681 Episode length: 681 Return: -475.3437996452591357
I0905 19:03:40.191987 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -475.34
INFO:tensorflow:Starting iteration 9
I0905 19:03:44.191486 139920723499008 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 270.56

Steps executed: 1000 Episode length: 1000 Return: -54.622667013630777
I0905 19:03:50.297919 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.62
INFO:tensorflow:Starting iteration 10
I0905 19:03:54.115846 139920723499008 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 265.29

Steps executed: 1000 Episode length: 1000 Return: -112.32336532552667
I0905 19:03:59.673697 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.32
INFO:tensorflow:Starting iteration 11
I0905 19:04:03.692181 139920723499008 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 288.48

Steps executed: 1000 Episode length: 1000 Return: 0.63267498338706337
I0905 19:04:09.864347 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: 0.63
INFO:tensorflow:Starting iteration 12

Steps executed: 557 Episode length: 557 Return: -61.16326806393592437
INFO:tensorflow:Average training steps per second: 299.24
I0905 19:04:17.188658 139920723499008 replay_runner.py:36] Average training steps per second: 299.24
I0905 19:04:18.436053 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.16
INFO:tensorflow:Starting iteration 13
I0905 19:04:22.367176 139920723499008 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 275.15

Steps executed: 812 Episode length: 812 Return: 155.08142075493142437
I0905 19:04:27.759109 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: 155.08
INFO:tensorflow:Starting iteration 14
I0905 19:04:31.504388 139920723499008 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 279.02

Steps executed: 995 Episode length: 828 Return: 209.97685932665894437
I0905 19:04:37.144804 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: 77.08
INFO:tensorflow:Starting iteration 15

Steps executed: 322 Episode length: 160 Return: -156.8715269674517437
INFO:tensorflow:Average training steps per second: 279.02
I0905 19:04:44.607451 139920723499008 replay_runner.py:36] Average training steps per second: 279.02
I0905 19:04:44.939094 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -453.90
INFO:tensorflow:Starting iteration 16

Steps executed: 233 Episode length: 91 Return: -32.568636392341574337
INFO:tensorflow:Average training steps per second: 290.26
I0905 19:04:52.476343 139920723499008 replay_runner.py:36] Average training steps per second: 290.26
I0905 19:04:52.677439 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.98
INFO:tensorflow:Starting iteration 17
I0905 19:04:56.658273 139920723499008 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 272.30
I0905 19:05:00.331314 139920723499008 replay_runner.py:36] Average training steps per second: 272.30

Steps executed: 515 Episode length: 515 Return: -71.43063986893091337
INFO:tensorflow:Starting iteration 18
I0905 19:05:05.137609 139920723499008 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 266.28

Steps executed: 620 Episode length: 620 Return: 147.77715716224182337
I0905 19:05:09.863340 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: 147.78
INFO:tensorflow:Starting iteration 19

Steps executed: 244 Episode length: 244 Return: -413.7162844660644537
INFO:tensorflow:Average training steps per second: 250.12
I0905 19:05:17.637086 139920723499008 replay_runner.py:36] Average training steps per second: 250.12
I0905 19:05:17.902476 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -413.72
INFO:tensorflow:Starting iteration 20

Steps executed: 116 Episode length: 116 Return: -127.6558743959644537
INFO:tensorflow:Average training steps per second: 269.46

Steps executed: 888 Episode length: 772 Return: -543.3041018484973537
I0905 19:05:27.387514 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -335.48
INFO:tensorflow:Starting iteration 21
I0905 19:05:31.059768 139920723499008 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 281.21

Steps executed: 1000 Episode length: 1000 Return: -47.714217755867327
I0905 19:05:37.881844 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -47.71
INFO:tensorflow:Starting iteration 22

Steps executed: 198 Episode length: 198 Return: -297.6602260415827327
INFO:tensorflow:Average training steps per second: 241.22

Steps executed: 1034 Episode length: 836 Return: -651.785754649702327
I0905 19:05:47.568689 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -474.72
INFO:tensorflow:Starting iteration 23

Steps executed: 73 Episode length: 73 Return: -516.548533854070302327
INFO:tensorflow:Average training steps per second: 239.24

Steps executed: 1073 Episode length: 1000 Return: 141.206116655147327
I0905 19:05:57.414413 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.67
INFO:tensorflow:Starting iteration 24

Steps executed: 776 Episode length: 776 Return: 204.50555467966888327
INFO:tensorflow:Average training steps per second: 246.74
I0905 19:06:05.342678 139920723499008 replay_runner.py:36] Average training steps per second: 246.74
I0905 19:06:06.989200 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: 204.51
INFO:tensorflow:Starting iteration 25

Steps executed: 249 Episode length: 249 Return: -615.1575760256784327
INFO:tensorflow:Average training steps per second: 249.70
I0905 19:06:14.767128 139920723499008 replay_runner.py:36] Average training steps per second: 249.70
I0905 19:06:15.060357 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -615.16
INFO:tensorflow:Starting iteration 26

Steps executed: 256 Episode length: 256 Return: 259.93670550049094327
INFO:tensorflow:Average training steps per second: 255.08
I0905 19:06:22.681277 139920723499008 replay_runner.py:36] Average training steps per second: 255.08
I0905 19:06:23.002300 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: 259.94
INFO:tensorflow:Starting iteration 27

Steps executed: 249 Episode length: 71 Return: -627.70239863704394327
INFO:tensorflow:Average training steps per second: 274.26
I0905 19:06:30.484826 139920723499008 replay_runner.py:36] Average training steps per second: 274.26
I0905 19:06:30.729475 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -373.10
INFO:tensorflow:Starting iteration 28

Steps executed: 219 Episode length: 83 Return: -512.44609054472224327
INFO:tensorflow:Average training steps per second: 300.04
I0905 19:06:37.984054 139920723499008 replay_runner.py:36] Average training steps per second: 300.04
I0905 19:06:38.160248 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -544.11
INFO:tensorflow:Starting iteration 29

Steps executed: 68 Episode length: 68 Return: -585.389266065868524327
INFO:tensorflow:Average training steps per second: 294.46
I0905 19:06:45.293210 139920723499008 replay_runner.py:36] Average training steps per second: 294.46


Done fixed training!Episode length: 200 Return: -419.7704349690882327