Loaded trained dqn in cartpole
Training fixed agent 8, please be patient, may be a while...
I0828 10:36:08.620148 139990128887808 run_experiment.py:549] Creating TrainRunner ...
I0828 10:36:08.630825 139990128887808 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:36:08.631130 139990128887808 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:36:08.631832 139990128887808 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:36:08.632059 139990128887808 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:36:08.632165 139990128887808 dqn_agent.py:275] 	 update_period: 4
I0828 10:36:08.632245 139990128887808 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:36:08.632319 139990128887808 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:36:08.632395 139990128887808 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:36:08.632533 139990128887808 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:36:08.632591 139990128887808 dqn_agent.py:280] 	 optimizer: adam
I0828 10:36:08.632659 139990128887808 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:36:08.632712 139990128887808 dqn_agent.py:283] 	 seed: 1630146968630765
I0828 10:36:08.635070 139990128887808 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:36:08.635260 139990128887808 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0828 10:36:08.635442 139990128887808 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:36:08.635545 139990128887808 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:36:08.635626 139990128887808 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:36:08.635703 139990128887808 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:36:08.635777 139990128887808 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:36:08.635893 139990128887808 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:36:08.636075 139990128887808 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:36:08.675009 139990128887808 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:36:09.209818 139990128887808 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:36:09.225715 139990128887808 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:36:09.240255 139990128887808 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:36:09.240561 139990128887808 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:36:09.240677 139990128887808 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:36:09.240766 139990128887808 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:36:09.240863 139990128887808 dqn_agent.py:275] 	 update_period: 4
I0828 10:36:09.241136 139990128887808 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:36:09.241246 139990128887808 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:36:09.241877 139990128887808 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:36:09.242168 139990128887808 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:36:09.242351 139990128887808 dqn_agent.py:280] 	 optimizer: adam
I0828 10:36:09.242487 139990128887808 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:36:09.242606 139990128887808 dqn_agent.py:283] 	 seed: 1630146969240172
I0828 10:36:09.246273 139990128887808 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:36:09.246530 139990128887808 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0828 10:36:09.246685 139990128887808 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:36:09.246804 139990128887808 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:36:09.246938 139990128887808 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:36:09.247051 139990128887808 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:36:09.247164 139990128887808 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:36:09.247270 139990128887808 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:36:09.247407 139990128887808 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:36:09.285289 139990128887808 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:36:09.309806 139990128887808 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:36:09.310081 139990128887808 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 151.09
I0828 10:36:15.928963 139990128887808 replay_runner.py:36] Average training steps per second: 151.09
Steps executed: 209 Episode length: 10 Return: 10.0
I0828 10:36:17.012912 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.50
INFO:tensorflow:Starting iteration 1
I0828 10:36:17.201002 139990128887808 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 199.64

Steps executed: 207 Episode length: 10 Return: 10.0
I0828 10:36:22.348707 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.41
INFO:tensorflow:Starting iteration 2

Steps executed: 316 Episode length: 159 Return: 159.0
INFO:tensorflow:Average training steps per second: 203.37
I0828 10:36:27.442704 139990128887808 replay_runner.py:36] Average training steps per second: 203.37
I0828 10:36:27.646405 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 158.00
INFO:tensorflow:Starting iteration 3

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 209.35
I0828 10:36:32.614961 139990128887808 replay_runner.py:36] Average training steps per second: 209.35
I0828 10:36:32.736797 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 4

Steps executed: 360 Episode length: 180 Return: 180.0
INFO:tensorflow:Average training steps per second: 207.31
I0828 10:36:37.744026 139990128887808 replay_runner.py:36] Average training steps per second: 207.31
I0828 10:36:37.991200 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 180.00
INFO:tensorflow:Starting iteration 5

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 201.55
I0828 10:36:43.161262 139990128887808 replay_runner.py:36] Average training steps per second: 201.55
I0828 10:36:43.286482 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 6
I0828 10:36:43.470654 139990128887808 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 199.44

Steps executed: 358 Episode length: 173 Return: 173.0
I0828 10:36:48.718742 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 179.00
INFO:tensorflow:Starting iteration 7

Steps executed: 335 Episode length: 178 Return: 178.0
INFO:tensorflow:Average training steps per second: 203.23
I0828 10:36:53.828163 139990128887808 replay_runner.py:36] Average training steps per second: 203.23
I0828 10:36:54.055992 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 167.50
INFO:tensorflow:Starting iteration 8

Steps executed: 303 Episode length: 165 Return: 165.0
INFO:tensorflow:Average training steps per second: 200.23
I0828 10:36:59.480725 139990128887808 replay_runner.py:36] Average training steps per second: 200.23
I0828 10:36:59.672885 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 151.50
INFO:tensorflow:Starting iteration 9
I0828 10:36:59.854443 139990128887808 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 212.11

Steps executed: 330 Episode length: 176 Return: 176.0
I0828 10:37:04.794682 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 165.00
INFO:tensorflow:Starting iteration 10

Steps executed: 278 Episode length: 132 Return: 132.0
INFO:tensorflow:Average training steps per second: 198.10
I0828 10:37:10.047561 139990128887808 replay_runner.py:36] Average training steps per second: 198.10
I0828 10:37:10.210197 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 139.00
INFO:tensorflow:Starting iteration 11

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 215.27
I0828 10:37:15.034573 139990128887808 replay_runner.py:36] Average training steps per second: 215.27
I0828 10:37:15.157494 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 12

Steps executed: 352 Episode length: 191 Return: 191.0
INFO:tensorflow:Average training steps per second: 212.04
I0828 10:37:20.058524 139990128887808 replay_runner.py:36] Average training steps per second: 212.04
I0828 10:37:20.259434 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 176.00
INFO:tensorflow:Starting iteration 13

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 210.16
I0828 10:37:25.189161 139990128887808 replay_runner.py:36] Average training steps per second: 210.16
I0828 10:37:25.308536 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 14
I0828 10:37:25.494302 139990128887808 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 202.42

Steps executed: 359 Episode length: 200 Return: 200.0
I0828 10:37:30.644240 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 179.50
INFO:tensorflow:Starting iteration 15

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 211.83
I0828 10:37:35.540263 139990128887808 replay_runner.py:36] Average training steps per second: 211.83
I0828 10:37:35.678549 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 16

Steps executed: 339 Episode length: 182 Return: 182.0
INFO:tensorflow:Average training steps per second: 197.81
I0828 10:37:40.914597 139990128887808 replay_runner.py:36] Average training steps per second: 197.81
I0828 10:37:41.165527 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 169.50
INFO:tensorflow:Starting iteration 17

Steps executed: 341 Episode length: 184 Return: 184.0
INFO:tensorflow:Average training steps per second: 208.86
I0828 10:37:46.138438 139990128887808 replay_runner.py:36] Average training steps per second: 208.86
I0828 10:37:46.367538 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 170.50
INFO:tensorflow:Starting iteration 18

Steps executed: 322 Episode length: 157 Return: 157.0
INFO:tensorflow:Average training steps per second: 198.67
I0828 10:37:51.580497 139990128887808 replay_runner.py:36] Average training steps per second: 198.67
I0828 10:37:51.805968 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 161.00
INFO:tensorflow:Starting iteration 19

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 200.87
I0828 10:37:56.972710 139990128887808 replay_runner.py:36] Average training steps per second: 200.87
I0828 10:37:57.114833 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 20

Steps executed: 337 Episode length: 155 Return: 155.0
INFO:tensorflow:Average training steps per second: 201.58
I0828 10:38:02.270807 139990128887808 replay_runner.py:36] Average training steps per second: 201.58
I0828 10:38:02.492919 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 168.50
INFO:tensorflow:Starting iteration 21

Steps executed: 262 Episode length: 132 Return: 132.0
INFO:tensorflow:Average training steps per second: 198.44
I0828 10:38:07.727494 139990128887808 replay_runner.py:36] Average training steps per second: 198.44
I0828 10:38:07.906199 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 131.00
INFO:tensorflow:Starting iteration 22

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 205.00
I0828 10:38:12.973709 139990128887808 replay_runner.py:36] Average training steps per second: 205.00
I0828 10:38:13.113820 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 23

Steps executed: 297 Episode length: 153 Return: 153.0
INFO:tensorflow:Average training steps per second: 200.40
I0828 10:38:18.297390 139990128887808 replay_runner.py:36] Average training steps per second: 200.40
I0828 10:38:18.524492 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 148.50
INFO:tensorflow:Starting iteration 24

Steps executed: 377 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 196.35
I0828 10:38:23.817067 139990128887808 replay_runner.py:36] Average training steps per second: 196.35
I0828 10:38:24.062284 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 188.50
INFO:tensorflow:Starting iteration 25

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 196.33
I0828 10:38:29.350749 139990128887808 replay_runner.py:36] Average training steps per second: 196.33
I0828 10:38:29.481052 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26
I0828 10:38:29.671492 139990128887808 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 199.77
I0828 10:38:34.677684 139990128887808 replay_runner.py:36] Average training steps per second: 199.77
I0828 10:38:34.815116 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 27

Steps executed: 378 Episode length: 195 Return: 195.0
INFO:tensorflow:Average training steps per second: 202.58
I0828 10:38:39.948538 139990128887808 replay_runner.py:36] Average training steps per second: 202.58
I0828 10:38:40.213659 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 189.00
INFO:tensorflow:Starting iteration 28

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 195.31
I0828 10:38:45.525789 139990128887808 replay_runner.py:36] Average training steps per second: 195.31
I0828 10:38:45.663037 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 199.65
I0828 10:38:50.863158 139990128887808 replay_runner.py:36] Average training steps per second: 199.65
I0828 10:38:50.999694 139990128887808 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00