Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0902 23:35:21.062177 139803223304192 run_experiment.py:549] Creating TrainRunner ...
I0902 23:35:21.075177 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:35:21.075433 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:35:21.075666 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:35:21.075816 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:35:21.075916 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0902 23:35:21.076038 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:35:21.076349 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:35:21.076473 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:35:21.076582 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:35:21.076672 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0902 23:35:21.076820 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:35:21.076970 139803223304192 dqn_agent.py:283] 	 seed: 1630625721075115
I0902 23:35:21.080951 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:35:21.081173 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:35:21.081365 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:35:21.081525 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:35:21.081678 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:35:21.081779 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:35:21.081853 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:35:21.081926 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:35:21.082032 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:35:21.120428 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:35:21.524943 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:35:21.540104 139803223304192 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:35:21.569840 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:35:21.570223 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:35:21.570409 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:35:21.570533 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:35:21.570710 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0902 23:35:21.570847 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:35:21.570993 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:35:21.571094 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:35:21.571211 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:35:21.571307 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0902 23:35:21.571391 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:35:21.571490 139803223304192 dqn_agent.py:283] 	 seed: 1630625721569779
I0902 23:35:21.573649 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:35:21.573809 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:35:21.573997 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:35:21.574625 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:35:21.574829 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:35:21.574978 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:35:21.575095 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:35:21.575200 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:35:21.575311 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:35:21.612580 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:35:21.637923 139803223304192 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:35:21.638349 139803223304192 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 163.32
I0902 23:35:27.761637 139803223304192 replay_runner.py:36] Average training steps per second: 163.32
Steps executed: 373 Episode length: 235 Return: -356.62010684973546
I0902 23:35:29.161053 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -385.94
INFO:tensorflow:Starting iteration 1

Steps executed: 226 Episode length: 105 Return: -479.25853220997914
INFO:tensorflow:Average training steps per second: 226.16
I0902 23:35:37.941197 139803223304192 replay_runner.py:36] Average training steps per second: 226.16
I0902 23:35:38.137449 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -356.98
INFO:tensorflow:Starting iteration 2

Steps executed: 243 Episode length: 115 Return: -338.99520308038774
INFO:tensorflow:Average training steps per second: 228.12
I0902 23:35:46.826384 139803223304192 replay_runner.py:36] Average training steps per second: 228.12
I0902 23:35:47.029490 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -319.68
INFO:tensorflow:Starting iteration 3

Steps executed: 203 Episode length: 63 Return: -456.315398584256234
INFO:tensorflow:Average training steps per second: 219.72
I0902 23:35:56.003798 139803223304192 replay_runner.py:36] Average training steps per second: 219.72
I0902 23:35:56.192620 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -486.95
INFO:tensorflow:Starting iteration 4

Steps executed: 445 Episode length: 445 Return: -334.72260080236724
INFO:tensorflow:Average training steps per second: 223.52
I0902 23:36:05.077026 139803223304192 replay_runner.py:36] Average training steps per second: 223.52
I0902 23:36:05.736793 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -334.72
INFO:tensorflow:Starting iteration 5
I0902 23:36:10.183202 139803223304192 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 227.76

Steps executed: 1000 Episode length: 1000 Return: 6.011298944749964
I0902 23:36:16.902325 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: 6.01
INFO:tensorflow:Starting iteration 6

Steps executed: 76 Episode length: 76 Return: -222.8192196509820664
INFO:tensorflow:Average training steps per second: 224.79

Steps executed: 1076 Episode length: 1000 Return: -55.07465876147289
I0902 23:36:28.351880 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.95
INFO:tensorflow:Starting iteration 7

Steps executed: 246 Episode length: 246 Return: -154.057051182581689
INFO:tensorflow:Average training steps per second: 219.87
I0902 23:36:37.150051 139803223304192 replay_runner.py:36] Average training steps per second: 219.87
I0902 23:36:37.455616 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.06
INFO:tensorflow:Starting iteration 8
I0902 23:36:41.657001 139803223304192 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 239.10

Steps executed: 1000 Episode length: 1000 Return: -85.14136742559737
I0902 23:36:48.532379 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.14
INFO:tensorflow:Starting iteration 9
I0902 23:36:52.808224 139803223304192 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 240.37

Steps executed: 1000 Episode length: 1000 Return: -112.08066010684975
I0902 23:36:59.466678 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.08
INFO:tensorflow:Starting iteration 10
I0902 23:37:03.766083 139803223304192 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 227.93

Steps executed: 1000 Episode length: 1000 Return: -84.409243432390945
I0902 23:37:10.463518 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.41
INFO:tensorflow:Starting iteration 11
I0902 23:37:14.729309 139803223304192 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 223.09

Steps executed: 1000 Episode length: 1000 Return: -105.21083050867536
I0902 23:37:22.784206 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.21
INFO:tensorflow:Starting iteration 12

Steps executed: 808 Episode length: 808 Return: 157.58352825556798536
INFO:tensorflow:Average training steps per second: 229.97
I0902 23:37:31.366130 139803223304192 replay_runner.py:36] Average training steps per second: 229.97
I0902 23:37:33.133368 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: 157.58
INFO:tensorflow:Starting iteration 13

Steps executed: 574 Episode length: 574 Return: -279.2281723688516536
INFO:tensorflow:Average training steps per second: 229.44
I0902 23:37:41.756914 139803223304192 replay_runner.py:36] Average training steps per second: 229.44
I0902 23:37:42.921593 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.23
INFO:tensorflow:Starting iteration 14
I0902 23:37:47.265047 139803223304192 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 225.29

Steps executed: 826 Episode length: 826 Return: -78.79465431452749536
I0902 23:37:53.996144 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.79
INFO:tensorflow:Starting iteration 15

Steps executed: 292 Episode length: 292 Return: -255.1472923913576436
INFO:tensorflow:Average training steps per second: 221.03
I0902 23:38:02.800948 139803223304192 replay_runner.py:36] Average training steps per second: 221.03
I0902 23:38:03.186830 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.15
INFO:tensorflow:Starting iteration 16

Steps executed: 239 Episode length: 239 Return: -292.3326362701198436
INFO:tensorflow:Average training steps per second: 226.27
I0902 23:38:11.904740 139803223304192 replay_runner.py:36] Average training steps per second: 226.27
I0902 23:38:12.196603 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -292.33
INFO:tensorflow:Starting iteration 17
I0902 23:38:16.521582 139803223304192 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 223.31
I0902 23:38:21.000209 139803223304192 replay_runner.py:36] Average training steps per second: 223.31

Steps executed: 267 Episode length: 267 Return: -33.93886904445983536
INFO:tensorflow:Starting iteration 18

Steps executed: 313 Episode length: 313 Return: -112.7751279197075636
INFO:tensorflow:Average training steps per second: 219.54
I0902 23:38:30.109766 139803223304192 replay_runner.py:36] Average training steps per second: 219.54
I0902 23:38:30.533406 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.78
INFO:tensorflow:Starting iteration 19
I0902 23:38:34.777011 139803223304192 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 213.61

Steps executed: 310 Episode length: 113 Return: -86.35434981126994436
I0902 23:38:39.757609 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.09
INFO:tensorflow:Starting iteration 20
I0902 23:38:43.895426 139803223304192 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 214.13
I0902 23:38:48.566054 139803223304192 replay_runner.py:36] Average training steps per second: 214.13

Steps executed: 397 Episode length: 397 Return: -204.8781133388713236
INFO:tensorflow:Starting iteration 21

Steps executed: 407 Episode length: 298 Return: -31.31293343441548436
INFO:tensorflow:Average training steps per second: 213.77
I0902 23:38:58.020628 139803223304192 replay_runner.py:36] Average training steps per second: 213.77
I0902 23:38:58.528423 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -292.90
INFO:tensorflow:Starting iteration 22

Steps executed: 375 Episode length: 249 Return: -595.9541229228339436
INFO:tensorflow:Average training steps per second: 215.84
I0902 23:39:07.438137 139803223304192 replay_runner.py:36] Average training steps per second: 215.84
I0902 23:39:07.852002 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.00
INFO:tensorflow:Starting iteration 23

Steps executed: 269 Episode length: 100 Return: -198.8728459657988636
INFO:tensorflow:Average training steps per second: 215.81
I0902 23:39:16.775365 139803223304192 replay_runner.py:36] Average training steps per second: 215.81
I0902 23:39:17.033724 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.66
INFO:tensorflow:Starting iteration 24

Steps executed: 286 Episode length: 155 Return: -94.00529013457175636
INFO:tensorflow:Average training steps per second: 216.87
I0902 23:39:25.882192 139803223304192 replay_runner.py:36] Average training steps per second: 216.87
I0902 23:39:26.151519 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.65
INFO:tensorflow:Starting iteration 25

Steps executed: 204 Episode length: 52 Return: -261.59524427021524636
INFO:tensorflow:Average training steps per second: 220.96
I0902 23:39:34.980186 139803223304192 replay_runner.py:36] Average training steps per second: 220.96
I0902 23:39:35.176050 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.35
INFO:tensorflow:Starting iteration 26

Steps executed: 237 Episode length: 52 Return: -116.49826013326029636
INFO:tensorflow:Average training steps per second: 219.24
I0902 23:39:44.060599 139803223304192 replay_runner.py:36] Average training steps per second: 219.24
I0902 23:39:44.235445 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.38
INFO:tensorflow:Starting iteration 27

Steps executed: 314 Episode length: 133 Return: -23.70853856120838536
INFO:tensorflow:Average training steps per second: 221.31
I0902 23:39:52.954872 139803223304192 replay_runner.py:36] Average training steps per second: 221.31
I0902 23:39:53.244021 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.47
INFO:tensorflow:Starting iteration 28

Steps executed: 287 Episode length: 151 Return: -135.4941854830148636
INFO:tensorflow:Average training steps per second: 221.92
I0902 23:40:01.994946 139803223304192 replay_runner.py:36] Average training steps per second: 221.92
I0902 23:40:02.264991 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.68
INFO:tensorflow:Starting iteration 29

Steps executed: 182 Episode length: 121 Return: -207.0149114690095836
INFO:tensorflow:Average training steps per second: 216.66
I0902 23:40:11.214616 139803223304192 replay_runner.py:36] Average training steps per second: 216.66


Done fixed training!Episode length: 124 Return: -438.3424551634501536