I0902 23:30:04.196155 139803223304192 run_experiment.py:549] Creating TrainRunner ...
I0902 23:30:04.206472 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:30:04.206711 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:30:04.206867 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:30:04.206996 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:30:04.207083 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0902 23:30:04.207203 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:30:04.207342 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:30:04.207603 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:30:04.207703 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:30:04.207819 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0902 23:30:04.207905 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:30:04.208140 139803223304192 dqn_agent.py:283] 	 seed: 1630625404206410
I0902 23:30:04.211473 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:30:04.211640 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:30:04.211754 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:30:04.211821 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:30:04.211931 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:30:04.212021 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:30:04.212079 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:30:04.212126 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:30:04.212204 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0902 23:30:06.076635 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:06.478702 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:06.493911 139803223304192 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:30:06.502149 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:30:06.502364 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:30:06.502475 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:30:06.502644 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:30:06.502809 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0902 23:30:06.503033 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:30:06.503151 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:30:06.503280 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:30:06.503365 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:30:06.503487 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0902 23:30:06.503635 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:30:06.503754 139803223304192 dqn_agent.py:283] 	 seed: 1630625406502083
I0902 23:30:06.506529 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:30:06.506707 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:30:06.506795 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:30:06.506891 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:30:06.506973 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:30:06.507048 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:30:06.507129 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:30:06.507216 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:30:06.507324 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:30:06.536326 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:06.560122 139803223304192 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:30:06.560515 139803223304192 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 163.58
I0902 23:30:12.674585 139803223304192 replay_runner.py:36] Average training steps per second: 163.58
Steps executed: 285 Episode length: 133 Return: -477.82003553682296
I0902 23:30:13.958699 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -471.01
INFO:tensorflow:Starting iteration 1

Steps executed: 201 Episode length: 98 Return: -378.423619854267146
INFO:tensorflow:Average training steps per second: 223.42
I0902 23:30:22.748664 139803223304192 replay_runner.py:36] Average training steps per second: 223.42
I0902 23:30:22.908381 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -360.78
INFO:tensorflow:Starting iteration 2
I0902 23:30:27.226961 139803223304192 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 216.61

Steps executed: 375 Episode length: 257 Return: -378.65176444500753
I0902 23:30:32.236482 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -366.73
INFO:tensorflow:Starting iteration 3
I0902 23:30:36.527414 139803223304192 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 215.26

Steps executed: 878 Episode length: 878 Return: -690.01802116282973
I0902 23:30:43.277876 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -690.02
INFO:tensorflow:Starting iteration 4
I0902 23:30:47.522045 139803223304192 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 229.06

Steps executed: 1000 Episode length: 1000 Return: -127.03838313801468
I0902 23:30:54.376567 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.04
INFO:tensorflow:Starting iteration 5
I0902 23:30:58.597781 139803223304192 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 223.51

Steps executed: 1000 Episode length: 1000 Return: -180.88604129094778
I0902 23:31:06.286144 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.89
INFO:tensorflow:Starting iteration 6
I0902 23:31:10.582571 139803223304192 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 223.50

Steps executed: 1000 Episode length: 1000 Return: -178.30196220021898
I0902 23:31:18.345454 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.30
INFO:tensorflow:Starting iteration 7
I0902 23:31:22.483330 139803223304192 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 225.13

Steps executed: 896 Episode length: 896 Return: -556.0289273288111898
I0902 23:31:28.476201 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -556.03
INFO:tensorflow:Starting iteration 8
I0902 23:31:32.547046 139803223304192 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 225.35

Steps executed: 790 Episode length: 790 Return: -570.9405477798377898
I0902 23:31:39.162735 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -570.94
INFO:tensorflow:Starting iteration 9
I0902 23:31:43.317032 139803223304192 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 225.13

Steps executed: 675 Episode length: 675 Return: -479.3273877439188898
I0902 23:31:48.922680 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -479.33
INFO:tensorflow:Starting iteration 10

Steps executed: 281 Episode length: 281 Return: -265.2419101364056498
INFO:tensorflow:Average training steps per second: 226.68
I0902 23:31:57.703523 139803223304192 replay_runner.py:36] Average training steps per second: 226.68
I0902 23:31:58.025192 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.24
INFO:tensorflow:Starting iteration 11
I0902 23:32:02.377064 139803223304192 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 223.29
I0902 23:32:06.856530 139803223304192 replay_runner.py:36] Average training steps per second: 223.29

Steps executed: 1000 Episode length: 1000 Return: -298.49905538321826
INFO:tensorflow:Starting iteration 12

Steps executed: 267 Episode length: 267 Return: -569.4497001151741826
INFO:tensorflow:Average training steps per second: 228.63
I0902 23:32:19.142517 139803223304192 replay_runner.py:36] Average training steps per second: 228.63
I0902 23:32:19.487565 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -569.45
INFO:tensorflow:Starting iteration 13
I0902 23:32:23.913398 139803223304192 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 225.99

Steps executed: 1000 Episode length: 1000 Return: -46.051507158219316
I0902 23:32:32.007814 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -46.05
INFO:tensorflow:Starting iteration 14
I0902 23:32:36.356631 139803223304192 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 229.38

Steps executed: 1000 Episode length: 1000 Return: -209.31791777882935
I0902 23:32:43.447599 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.32
INFO:tensorflow:Starting iteration 15

Steps executed: 217 Episode length: 72 Return: 62.6243424800406412935
INFO:tensorflow:Average training steps per second: 225.75
I0902 23:32:52.265823 139803223304192 replay_runner.py:36] Average training steps per second: 225.75
I0902 23:32:52.473824 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: 4.45
INFO:tensorflow:Starting iteration 16
I0902 23:32:56.761759 139803223304192 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 223.21

Steps executed: 1000 Episode length: 1000 Return: -95.305296148292035
I0902 23:33:03.106712 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.31
INFO:tensorflow:Starting iteration 17
I0902 23:33:07.416489 139803223304192 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 220.92

Steps executed: 261 Episode length: 261 Return: 218.80739772951623035
I0902 23:33:12.266499 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: 218.81
INFO:tensorflow:Starting iteration 18

Steps executed: 466 Episode length: 318 Return: -89.22985107686189035
INFO:tensorflow:Average training steps per second: 221.89
I0902 23:33:21.123205 139803223304192 replay_runner.py:36] Average training steps per second: 221.89
I0902 23:33:21.717349 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.21
INFO:tensorflow:Starting iteration 19

Steps executed: 395 Episode length: 201 Return: 42.103969465378419035
INFO:tensorflow:Average training steps per second: 221.81
I0902 23:33:30.586038 139803223304192 replay_runner.py:36] Average training steps per second: 221.81
I0902 23:33:30.972663 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: 18.15
INFO:tensorflow:Starting iteration 20
I0902 23:33:35.486278 139803223304192 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 222.21
I0902 23:33:39.986892 139803223304192 replay_runner.py:36] Average training steps per second: 222.21

Steps executed: 290 Episode length: 290 Return: 38.037771432470635035
INFO:tensorflow:Starting iteration 21

Steps executed: 329 Episode length: 329 Return: -644.6956342708235035
INFO:tensorflow:Average training steps per second: 228.25
I0902 23:33:48.987633 139803223304192 replay_runner.py:36] Average training steps per second: 228.25
I0902 23:33:49.444224 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -644.70
INFO:tensorflow:Starting iteration 22

Steps executed: 188 Episode length: 188 Return: -166.6416505430471235
INFO:tensorflow:Average training steps per second: 231.03
I0902 23:33:58.173470 139803223304192 replay_runner.py:36] Average training steps per second: 231.03

Steps executed: 319 Episode length: 131 Return: -420.2401207634631535
INFO:tensorflow:Starting iteration 23

Steps executed: 301 Episode length: 301 Return: -268.3621969237484535
INFO:tensorflow:Average training steps per second: 226.06
I0902 23:34:07.109707 139803223304192 replay_runner.py:36] Average training steps per second: 226.06
I0902 23:34:07.592422 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.36
INFO:tensorflow:Starting iteration 24
I0902 23:34:11.933712 139803223304192 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 224.56

Steps executed: 248 Episode length: 248 Return: 5.0943788902188634535
I0902 23:34:16.670950 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: 5.09
INFO:tensorflow:Starting iteration 25

Steps executed: 266 Episode length: 266 Return: -25.35992939502465535
INFO:tensorflow:Average training steps per second: 233.05
I0902 23:34:25.188802 139803223304192 replay_runner.py:36] Average training steps per second: 233.05
I0902 23:34:25.522266 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -25.36
INFO:tensorflow:Starting iteration 26
I0902 23:34:29.763269 139803223304192 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 229.76

Steps executed: 916 Episode length: 916 Return: 257.85423888505195535
I0902 23:34:37.071726 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: 257.85
INFO:tensorflow:Starting iteration 27

Steps executed: 301 Episode length: 117 Return: -326.3518626162611635
INFO:tensorflow:Average training steps per second: 230.58
I0902 23:34:45.667747 139803223304192 replay_runner.py:36] Average training steps per second: 230.58
I0902 23:34:45.961751 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -378.59
INFO:tensorflow:Starting iteration 28
I0902 23:34:50.286177 139803223304192 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 228.78

Steps executed: 301 Episode length: 301 Return: -487.0002748111085635
I0902 23:34:54.993781 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -487.00
INFO:tensorflow:Starting iteration 29

Steps executed: 322 Episode length: 322 Return: -438.3543019011195635
INFO:tensorflow:Average training steps per second: 224.35
I0902 23:35:03.822226 139803223304192 replay_runner.py:36] Average training steps per second: 224.35

Done fixed training!Episode length: 322 Return: -438.3543019011195635