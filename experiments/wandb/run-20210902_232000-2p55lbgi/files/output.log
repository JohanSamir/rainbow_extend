Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0902 23:20:07.292355 139926926592000 run_experiment.py:549] Creating TrainRunner ...
I0902 23:20:07.304213 139926926592000 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:20:07.304538 139926926592000 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:20:07.304837 139926926592000 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:20:07.304974 139926926592000 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:20:07.305088 139926926592000 dqn_agent.py:275] 	 update_period: 4
I0902 23:20:07.305202 139926926592000 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:20:07.305325 139926926592000 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:20:07.305442 139926926592000 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:20:07.305601 139926926592000 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:20:07.305692 139926926592000 dqn_agent.py:280] 	 optimizer: adam
I0902 23:20:07.305810 139926926592000 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:20:07.305938 139926926592000 dqn_agent.py:283] 	 seed: 1630624807304144
I0902 23:20:07.308542 139926926592000 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:20:07.308800 139926926592000 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:20:07.308942 139926926592000 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:20:07.309077 139926926592000 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:20:07.309196 139926926592000 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:20:07.309294 139926926592000 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:20:07.309383 139926926592000 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:20:07.309484 139926926592000 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:20:07.309590 139926926592000 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:20:07.343423 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:20:07.730749 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:20:07.751776 139926926592000 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:20:07.764321 139926926592000 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:20:07.764508 139926926592000 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:20:07.764589 139926926592000 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:20:07.764650 139926926592000 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:20:07.764740 139926926592000 dqn_agent.py:275] 	 update_period: 4
I0902 23:20:07.764858 139926926592000 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:20:07.764942 139926926592000 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:20:07.765022 139926926592000 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:20:07.765095 139926926592000 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:20:07.765161 139926926592000 dqn_agent.py:280] 	 optimizer: adam
I0902 23:20:07.765225 139926926592000 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:20:07.765279 139926926592000 dqn_agent.py:283] 	 seed: 1630624807764257
I0902 23:20:07.768554 139926926592000 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:20:07.768818 139926926592000 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:20:07.769008 139926926592000 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:20:07.769177 139926926592000 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:20:07.769378 139926926592000 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:20:07.769595 139926926592000 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:20:07.769754 139926926592000 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:20:07.769914 139926926592000 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:20:07.770122 139926926592000 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:20:07.846825 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:20:07.872222 139926926592000 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:20:07.872572 139926926592000 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 165.26
I0902 23:20:13.924531 139926926592000 replay_runner.py:36] Average training steps per second: 165.26
Steps executed: 245 Episode length: 61 Return: -541.0458332489178
I0902 23:20:15.148353 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -485.27
INFO:tensorflow:Starting iteration 1

Steps executed: 204 Episode length: 78 Return: -782.5044369420938
INFO:tensorflow:Average training steps per second: 212.70
I0902 23:20:24.224066 139926926592000 replay_runner.py:36] Average training steps per second: 212.70
I0902 23:20:24.420233 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -657.67
INFO:tensorflow:Starting iteration 2

Steps executed: 210 Episode length: 126 Return: -1241.1408426272008
INFO:tensorflow:Average training steps per second: 217.25
I0902 23:20:33.373998 139926926592000 replay_runner.py:36] Average training steps per second: 217.25
I0902 23:20:33.575771 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -1017.66
INFO:tensorflow:Starting iteration 3

Steps executed: 201 Episode length: 85 Return: -991.925796264383308
INFO:tensorflow:Average training steps per second: 210.38
I0902 23:20:42.662564 139926926592000 replay_runner.py:36] Average training steps per second: 210.38
I0902 23:20:42.841263 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -656.58
INFO:tensorflow:Starting iteration 4

Steps executed: 232 Episode length: 53 Return: -434.620288474032858
INFO:tensorflow:Average training steps per second: 215.22
I0902 23:20:51.812259 139926926592000 replay_runner.py:36] Average training steps per second: 215.22
I0902 23:20:52.016175 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -498.14
INFO:tensorflow:Starting iteration 5

Steps executed: 176 Episode length: 52 Return: -366.279508858731458
INFO:tensorflow:Average training steps per second: 211.21

Steps executed: 260 Episode length: 84 Return: -879.296196779357658
I0902 23:21:01.144824 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -592.76
INFO:tensorflow:Starting iteration 6

Steps executed: 205 Episode length: 61 Return: -461.109334019995658
INFO:tensorflow:Average training steps per second: 212.27
I0902 23:21:10.217990 139926926592000 replay_runner.py:36] Average training steps per second: 212.27
I0902 23:21:10.399771 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -525.48
INFO:tensorflow:Starting iteration 7

Steps executed: 254 Episode length: 73 Return: -533.859268113659723
INFO:tensorflow:Average training steps per second: 212.52
I0902 23:21:19.410598 139926926592000 replay_runner.py:36] Average training steps per second: 212.52
I0902 23:21:19.695976 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -803.52
INFO:tensorflow:Starting iteration 8

Steps executed: 291 Episode length: 133 Return: -500.19975898116104
INFO:tensorflow:Average training steps per second: 215.33
I0902 23:21:28.609172 139926926592000 replay_runner.py:36] Average training steps per second: 215.33
I0902 23:21:28.915977 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -770.30
INFO:tensorflow:Starting iteration 9

Steps executed: 275 Episode length: 201 Return: -1239.9130079001034
INFO:tensorflow:Average training steps per second: 214.46
I0902 23:21:37.821049 139926926592000 replay_runner.py:36] Average training steps per second: 214.46
I0902 23:21:38.155671 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -822.59
INFO:tensorflow:Starting iteration 10

Steps executed: 286 Episode length: 153 Return: -1158.2979051528373
INFO:tensorflow:Average training steps per second: 224.49
I0902 23:21:46.882238 139926926592000 replay_runner.py:36] Average training steps per second: 224.49
I0902 23:21:47.146034 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -1043.04
INFO:tensorflow:Starting iteration 11

Steps executed: 262 Episode length: 86 Return: -508.087118127381533
INFO:tensorflow:Average training steps per second: 222.30
I0902 23:21:55.786273 139926926592000 replay_runner.py:36] Average training steps per second: 222.30
I0902 23:21:56.017445 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -556.83
INFO:tensorflow:Starting iteration 12

Steps executed: 288 Episode length: 190 Return: -1584.0994165927655
INFO:tensorflow:Average training steps per second: 230.93
I0902 23:22:04.479954 139926926592000 replay_runner.py:36] Average training steps per second: 230.93
I0902 23:22:04.774196 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -1124.02
INFO:tensorflow:Starting iteration 13

Steps executed: 230 Episode length: 133 Return: -951.57369598796475
INFO:tensorflow:Average training steps per second: 229.16
I0902 23:22:13.263477 139926926592000 replay_runner.py:36] Average training steps per second: 229.16
I0902 23:22:13.465097 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -833.76
INFO:tensorflow:Starting iteration 14

Steps executed: 277 Episode length: 86 Return: -616.210959913636515
INFO:tensorflow:Average training steps per second: 220.97
I0902 23:22:22.011036 139926926592000 replay_runner.py:36] Average training steps per second: 220.97
I0902 23:22:22.257067 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -610.97
INFO:tensorflow:Starting iteration 15

Steps executed: 246 Episode length: 111 Return: -698.18712406962795
INFO:tensorflow:Average training steps per second: 220.03
I0902 23:22:30.955178 139926926592000 replay_runner.py:36] Average training steps per second: 220.03
I0902 23:22:31.215188 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -770.37
INFO:tensorflow:Starting iteration 16

Steps executed: 235 Episode length: 160 Return: -911.22438464092015
INFO:tensorflow:Average training steps per second: 216.18
I0902 23:22:40.147937 139926926592000 replay_runner.py:36] Average training steps per second: 216.18
I0902 23:22:40.388804 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -691.58
INFO:tensorflow:Starting iteration 17
I0902 23:22:44.673270 139926926592000 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 213.89

Steps executed: 439 Episode length: 439 Return: -6161.7963470151235
I0902 23:22:50.123682 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -6161.80
INFO:tensorflow:Starting iteration 18

Steps executed: 81 Episode length: 81 Return: -404.3512247963321235
INFO:tensorflow:Average training steps per second: 215.75
I0902 23:22:59.110046 139926926592000 replay_runner.py:36] Average training steps per second: 215.75

Steps executed: 252 Episode length: 171 Return: -1250.5627525868938
INFO:tensorflow:Starting iteration 19

Steps executed: 286 Episode length: 96 Return: -784.042529719584848
INFO:tensorflow:Average training steps per second: 212.23
I0902 23:23:08.452263 139926926592000 replay_runner.py:36] Average training steps per second: 212.23
I0902 23:23:08.737559 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -607.44
INFO:tensorflow:Starting iteration 20
I0902 23:23:13.059828 139926926592000 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 216.84

Steps executed: 201 Episode length: 95 Return: -528.014991282907598
I0902 23:23:17.881813 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -516.39
INFO:tensorflow:Starting iteration 21

Steps executed: 253 Episode length: 75 Return: -486.117601127091358
INFO:tensorflow:Average training steps per second: 215.49
I0902 23:23:26.697425 139926926592000 replay_runner.py:36] Average training steps per second: 215.49
I0902 23:23:26.947173 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -612.20
INFO:tensorflow:Starting iteration 22

Steps executed: 274 Episode length: 95 Return: -471.678161474957848
INFO:tensorflow:Average training steps per second: 212.09
I0902 23:23:35.981896 139926926592000 replay_runner.py:36] Average training steps per second: 212.09
I0902 23:23:36.240228 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -581.12
INFO:tensorflow:Starting iteration 23

Steps executed: 120 Episode length: 120 Return: -851.25951686695928
INFO:tensorflow:Average training steps per second: 215.06

Steps executed: 346 Episode length: 226 Return: -1580.9445714456622
I0902 23:23:45.645204 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -1216.10
INFO:tensorflow:Starting iteration 24

Steps executed: 231 Episode length: 231 Return: -1841.8491027171692
INFO:tensorflow:Average training steps per second: 212.53
I0902 23:23:54.644737 139926926592000 replay_runner.py:36] Average training steps per second: 212.53
I0902 23:23:54.913298 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -1841.85
INFO:tensorflow:Starting iteration 25

Steps executed: 293 Episode length: 293 Return: -2890.4204552987122
INFO:tensorflow:Average training steps per second: 215.25
I0902 23:24:03.959645 139926926592000 replay_runner.py:36] Average training steps per second: 215.25
I0902 23:24:04.379195 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -2890.42
INFO:tensorflow:Starting iteration 26

Steps executed: 166 Episode length: 80 Return: -477.765010977052622
INFO:tensorflow:Average training steps per second: 213.10
I0902 23:24:13.292865 139926926592000 replay_runner.py:36] Average training steps per second: 213.10

Steps executed: 301 Episode length: 135 Return: -850.04956862298872
INFO:tensorflow:Starting iteration 27

Steps executed: 452 Episode length: 291 Return: -2520.8627595531662
INFO:tensorflow:Average training steps per second: 215.53
I0902 23:24:22.594574 139926926592000 replay_runner.py:36] Average training steps per second: 215.53
I0902 23:24:23.169384 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -1180.75
INFO:tensorflow:Starting iteration 28

Steps executed: 207 Episode length: 91 Return: -591.175681023841092
INFO:tensorflow:Average training steps per second: 218.57
I0902 23:24:32.110943 139926926592000 replay_runner.py:36] Average training steps per second: 218.57
I0902 23:24:32.305582 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -725.04
INFO:tensorflow:Starting iteration 29

Steps executed: 206 Episode length: 120 Return: -917.74339791167762
INFO:tensorflow:Average training steps per second: 233.98
I0902 23:24:40.840657 139926926592000 replay_runner.py:36] Average training steps per second: 233.98

Done fixed training!Episode length: 120 Return: -917.74339791167762