Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0902 00:31:04.911082 140183943698432 run_experiment.py:549] Creating TrainRunner ...
I0902 00:31:04.918575 140183943698432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:31:04.918728 140183943698432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:31:04.918809 140183943698432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:31:04.918879 140183943698432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:31:04.918952 140183943698432 dqn_agent.py:275] 	 update_period: 4
I0902 00:31:04.919060 140183943698432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:31:04.919129 140183943698432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:31:04.919229 140183943698432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:31:04.919304 140183943698432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:31:04.919377 140183943698432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:31:04.919451 140183943698432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:31:04.919517 140183943698432 dqn_agent.py:283] 	 seed: 1630542664918535
I0902 00:31:04.921400 140183943698432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:31:04.921523 140183943698432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:31:04.921603 140183943698432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:31:04.921674 140183943698432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:31:04.921737 140183943698432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:31:04.921834 140183943698432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:31:04.921928 140183943698432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:31:04.921987 140183943698432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:31:04.922102 140183943698432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:31:04.947807 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:31:05.206729 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:31:05.215031 140183943698432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:31:05.221158 140183943698432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:31:05.221292 140183943698432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:31:05.221364 140183943698432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:31:05.221423 140183943698432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:31:05.221477 140183943698432 dqn_agent.py:275] 	 update_period: 4
I0902 00:31:05.221550 140183943698432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:31:05.221605 140183943698432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:31:05.221686 140183943698432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:31:05.221740 140183943698432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:31:05.221801 140183943698432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:31:05.221878 140183943698432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:31:05.221953 140183943698432 dqn_agent.py:283] 	 seed: 1630542665221130
I0902 00:31:05.223345 140183943698432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:31:05.223457 140183943698432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:31:05.223528 140183943698432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:31:05.223589 140183943698432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:31:05.223647 140183943698432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:31:05.223718 140183943698432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:31:05.223793 140183943698432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:31:05.223868 140183943698432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:31:05.223935 140183943698432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:31:05.245897 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:31:05.259375 140183943698432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:31:05.259526 140183943698432 replay_runner.py:41] Starting iteration 0
Steps executed: 275 Episode length: 89 Return: -308.25808767998205
INFO:tensorflow:Average training steps per second: 255.60
I0902 00:31:09.172107 140183943698432 replay_runner.py:36] Average training steps per second: 255.60
I0902 00:31:09.939079 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.91
INFO:tensorflow:Starting iteration 1

Steps executed: 289 Episode length: 131 Return: -422.0806561243035
INFO:tensorflow:Average training steps per second: 355.23
I0902 00:31:16.149658 140183943698432 replay_runner.py:36] Average training steps per second: 355.23
I0902 00:31:16.311913 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -421.69
INFO:tensorflow:Starting iteration 2

Steps executed: 200 Episode length: 200 Return: -286.02428185742383
INFO:tensorflow:Average training steps per second: 347.29
I0902 00:31:22.653960 140183943698432 replay_runner.py:36] Average training steps per second: 347.29
I0902 00:31:22.790128 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -286.02
INFO:tensorflow:Starting iteration 3

Steps executed: 269 Episode length: 104 Return: -686.90249623205244
INFO:tensorflow:Average training steps per second: 346.23
I0902 00:31:29.100568 140183943698432 replay_runner.py:36] Average training steps per second: 346.23
I0902 00:31:29.267407 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.20
INFO:tensorflow:Starting iteration 4

Steps executed: 415 Episode length: 415 Return: -304.48951617894384
INFO:tensorflow:Average training steps per second: 332.94
I0902 00:31:35.681981 140183943698432 replay_runner.py:36] Average training steps per second: 332.94
I0902 00:31:36.130568 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.49
INFO:tensorflow:Starting iteration 5
I0902 00:31:39.581536 140183943698432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 331.69

Steps executed: 1000 Episode length: 1000 Return: -138.00424034357263
I0902 00:31:44.201933 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.00
INFO:tensorflow:Starting iteration 6
I0902 00:31:47.660727 140183943698432 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 332.66

Steps executed: 1000 Episode length: 1000 Return: -135.67691041718763
I0902 00:31:52.443639 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.68
INFO:tensorflow:Starting iteration 7

Steps executed: 1000 Episode length: 1000 Return: -311.35708990968813
INFO:tensorflow:Average training steps per second: 327.64
I0902 00:31:58.870886 140183943698432 replay_runner.py:36] Average training steps per second: 327.64
I0902 00:32:00.321439 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.36
INFO:tensorflow:Starting iteration 8
I0902 00:32:03.548320 140183943698432 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 319.17

Steps executed: 531 Episode length: 343 Return: -214.2127128180967813
I0902 00:32:07.138086 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.62
INFO:tensorflow:Starting iteration 9
I0902 00:32:10.291650 140183943698432 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 317.12

Steps executed: 1000 Episode length: 1000 Return: -338.44261438344853
I0902 00:32:16.348489 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.44
INFO:tensorflow:Starting iteration 10
I0902 00:32:19.635346 140183943698432 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 314.65
I0902 00:32:22.813912 140183943698432 replay_runner.py:36] Average training steps per second: 314.65

Steps executed: 1000 Episode length: 1000 Return: -229.46118913315623
INFO:tensorflow:Starting iteration 11
I0902 00:32:28.437613 140183943698432 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 345.86

Steps executed: 1000 Episode length: 1000 Return: -142.73089829306303
I0902 00:32:33.733523 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.73
INFO:tensorflow:Starting iteration 12

Steps executed: 303 Episode length: 179 Return: -163.7086436484658803
INFO:tensorflow:Average training steps per second: 339.35
I0902 00:32:40.081008 140183943698432 replay_runner.py:36] Average training steps per second: 339.35
I0902 00:32:40.263132 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.27
INFO:tensorflow:Starting iteration 13

Steps executed: 257 Episode length: 257 Return: -63.71160456768985403
INFO:tensorflow:Average training steps per second: 348.83
I0902 00:32:46.544490 140183943698432 replay_runner.py:36] Average training steps per second: 348.83
I0902 00:32:46.755383 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -63.71
INFO:tensorflow:Starting iteration 14

Steps executed: 1000 Episode length: 1000 Return: -119.95327149275785
INFO:tensorflow:Average training steps per second: 330.96
I0902 00:32:53.190576 140183943698432 replay_runner.py:36] Average training steps per second: 330.96
I0902 00:32:54.637088 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.95
INFO:tensorflow:Starting iteration 15
I0902 00:32:58.049188 140183943698432 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 331.01

Steps executed: 334 Episode length: 186 Return: -452.6104582860718385
I0902 00:33:01.309993 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.60
INFO:tensorflow:Starting iteration 16

Steps executed: 201 Episode length: 87 Return: -883.29766493653654385
INFO:tensorflow:Average training steps per second: 346.78
I0902 00:33:07.637609 140183943698432 replay_runner.py:36] Average training steps per second: 346.78
I0902 00:33:07.757440 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -583.92
INFO:tensorflow:Starting iteration 17

Steps executed: 237 Episode length: 57 Return: -120.27530868122909385
INFO:tensorflow:Average training steps per second: 356.83
I0902 00:33:14.042682 140183943698432 replay_runner.py:36] Average training steps per second: 356.83
I0902 00:33:14.198579 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -415.02
INFO:tensorflow:Starting iteration 18

Steps executed: 223 Episode length: 58 Return: -116.75649831447333385
INFO:tensorflow:Average training steps per second: 358.28
I0902 00:33:20.481453 140183943698432 replay_runner.py:36] Average training steps per second: 358.28
I0902 00:33:20.585416 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.29
INFO:tensorflow:Starting iteration 19
I0902 00:33:24.093038 140183943698432 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 358.13

Steps executed: 261 Episode length: 65 Return: -240.93313681518006385
I0902 00:33:27.035470 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.82
INFO:tensorflow:Starting iteration 20

Steps executed: 253 Episode length: 64 Return: -554.48522901741926385
INFO:tensorflow:Average training steps per second: 358.47
I0902 00:33:33.352670 140183943698432 replay_runner.py:36] Average training steps per second: 358.47
I0902 00:33:33.484849 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -397.76
INFO:tensorflow:Starting iteration 21

Steps executed: 213 Episode length: 91 Return: -96.305481363563924385
INFO:tensorflow:Average training steps per second: 356.54
I0902 00:33:39.825382 140183943698432 replay_runner.py:36] Average training steps per second: 356.54
I0902 00:33:39.962807 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.45
INFO:tensorflow:Starting iteration 22

Steps executed: 228 Episode length: 119 Return: -704.2443657649762385
INFO:tensorflow:Average training steps per second: 344.22
I0902 00:33:46.367985 140183943698432 replay_runner.py:36] Average training steps per second: 344.22
I0902 00:33:46.528036 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -668.56
INFO:tensorflow:Starting iteration 23

Steps executed: 62 Episode length: 62 Return: -423.798783806679762385
INFO:tensorflow:Average training steps per second: 343.15

Steps executed: 212 Episode length: 54 Return: -429.58877755829934385
I0902 00:33:53.058475 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -405.14
INFO:tensorflow:Starting iteration 24

Steps executed: 242 Episode length: 75 Return: -629.02564673121476385
INFO:tensorflow:Average training steps per second: 340.59
I0902 00:33:59.500293 140183943698432 replay_runner.py:36] Average training steps per second: 340.59
I0902 00:33:59.636314 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -470.56
INFO:tensorflow:Starting iteration 25

Steps executed: 203 Episode length: 96 Return: -503.52465041360699385
INFO:tensorflow:Average training steps per second: 348.41
I0902 00:34:05.909027 140183943698432 replay_runner.py:36] Average training steps per second: 348.41
I0902 00:34:06.036471 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -531.74
INFO:tensorflow:Starting iteration 26

Steps executed: 243 Episode length: 58 Return: -461.80443934969907385
INFO:tensorflow:Average training steps per second: 353.31
I0902 00:34:12.269119 140183943698432 replay_runner.py:36] Average training steps per second: 353.31
I0902 00:34:12.423605 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -442.03
INFO:tensorflow:Starting iteration 27

Steps executed: 224 Episode length: 73 Return: -488.76158161775967385
INFO:tensorflow:Average training steps per second: 351.60
I0902 00:34:18.724889 140183943698432 replay_runner.py:36] Average training steps per second: 351.60
I0902 00:34:18.845941 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -593.49
INFO:tensorflow:Starting iteration 28

Steps executed: 52 Episode length: 52 Return: -452.997122279247957385
INFO:tensorflow:Average training steps per second: 343.49

Steps executed: 225 Episode length: 68 Return: -530.79153718870527385
I0902 00:34:25.251092 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -450.70
INFO:tensorflow:Starting iteration 29

Steps executed: 204 Episode length: 52 Return: -81.020946696846387385
INFO:tensorflow:Average training steps per second: 334.98
I0902 00:34:31.537542 140183943698432 replay_runner.py:36] Average training steps per second: 334.98

Done fixed training!Episode length: 52 Return: -81.020946696846387385