I0903 00:08:16.026832 140369919707136 run_experiment.py:549] Creating TrainRunner ...
I0903 00:08:16.033842 140369919707136 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:08:16.033978 140369919707136 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:08:16.034058 140369919707136 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:08:16.034125 140369919707136 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:08:16.034187 140369919707136 dqn_agent.py:275] 	 update_period: 4
I0903 00:08:16.034277 140369919707136 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:08:16.034408 140369919707136 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:08:16.034499 140369919707136 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:08:16.034582 140369919707136 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:08:16.034651 140369919707136 dqn_agent.py:280] 	 optimizer: adam
I0903 00:08:16.034709 140369919707136 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:08:16.034790 140369919707136 dqn_agent.py:283] 	 seed: 1630627696033805
I0903 00:08:16.036743 140369919707136 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:08:16.036894 140369919707136 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:08:16.036979 140369919707136 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:08:16.037051 140369919707136 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:08:16.037115 140369919707136 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:08:16.037194 140369919707136 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:08:16.037257 140369919707136 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:08:16.037349 140369919707136 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:08:16.037428 140369919707136 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:08:16.061575 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:16.301592 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:16.310490 140369919707136 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:08:16.316977 140369919707136 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:08:16.317120 140369919707136 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:08:16.317198 140369919707136 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:08:16.317265 140369919707136 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:08:16.317331 140369919707136 dqn_agent.py:275] 	 update_period: 4
I0903 00:08:16.317412 140369919707136 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:08:16.317506 140369919707136 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:08:16.317581 140369919707136 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:08:16.317651 140369919707136 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:08:16.317725 140369919707136 dqn_agent.py:280] 	 optimizer: adam
I0903 00:08:16.317798 140369919707136 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:08:16.317877 140369919707136 dqn_agent.py:283] 	 seed: 1630627696316946
I0903 00:08:16.319533 140369919707136 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:08:16.319658 140369919707136 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:08:16.319738 140369919707136 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:08:16.319818 140369919707136 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:08:16.320023 140369919707136 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:08:16.320196 140369919707136 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:08:16.320364 140369919707136 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:08:16.320498 140369919707136 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:08:16.320643 140369919707136 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:08:16.340946 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:16.356686 140369919707136 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:08:16.356844 140369919707136 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 243.27
I0903 00:08:20.467740 140369919707136 replay_runner.py:36] Average training steps per second: 243.27
I0903 00:08:21.257709 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -351.44
Steps executed: 326 Episode length: 142 Return: -417.5905796246252
INFO:tensorflow:Starting iteration 1

Steps executed: 154 Episode length: 154 Return: -442.3273971873522
INFO:tensorflow:Average training steps per second: 327.52

Steps executed: 305 Episode length: 151 Return: -244.76929524307155
I0903 00:08:27.712640 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -343.55
INFO:tensorflow:Starting iteration 2

Steps executed: 335 Episode length: 152 Return: -344.72536762578943
INFO:tensorflow:Average training steps per second: 317.08
I0903 00:08:34.042783 140369919707136 replay_runner.py:36] Average training steps per second: 317.08
I0903 00:08:34.302720 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -428.29
INFO:tensorflow:Starting iteration 3

Steps executed: 244 Episode length: 244 Return: -587.68016717656083
INFO:tensorflow:Average training steps per second: 316.49
I0903 00:08:40.687716 140369919707136 replay_runner.py:36] Average training steps per second: 316.49
I0903 00:08:40.870887 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -587.68
INFO:tensorflow:Starting iteration 4

Steps executed: 184 Episode length: 184 Return: -46.673072402974173
INFO:tensorflow:Average training steps per second: 315.14

Steps executed: 596 Episode length: 412 Return: -313.21930701285066
I0903 00:08:47.871665 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.95
INFO:tensorflow:Starting iteration 5
I0903 00:08:51.182787 140369919707136 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 318.56

Steps executed: 1000 Episode length: 1000 Return: -79.83233645197154
I0903 00:08:56.744258 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.83
INFO:tensorflow:Starting iteration 6
I0903 00:08:59.954605 140369919707136 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 321.04

Steps executed: 1000 Episode length: 1000 Return: -73.97093750628135
I0903 00:09:05.159109 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.97
INFO:tensorflow:Starting iteration 7
I0903 00:09:08.535108 140369919707136 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 326.87

Steps executed: 1000 Episode length: 1000 Return: -152.4329203574678
I0903 00:09:13.563638 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.43
INFO:tensorflow:Starting iteration 8
I0903 00:09:16.971568 140369919707136 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 335.41


Steps executed: 1131 Episode length: 1000 Return: -82.60712885355365
I0903 00:09:22.283103 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.95
INFO:tensorflow:Starting iteration 9
I0903 00:09:25.720731 140369919707136 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 358.33

Steps executed: 1000 Episode length: 1000 Return: -88.06786854607346
I0903 00:09:31.314825 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.07
INFO:tensorflow:Starting iteration 10
I0903 00:09:34.720014 140369919707136 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 356.45

Steps executed: 1000 Episode length: 1000 Return: -182.83214234039514
I0903 00:09:39.905673 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.83
INFO:tensorflow:Starting iteration 11

Steps executed: 1000 Episode length: 1000 Return: -139.40286382198274
INFO:tensorflow:Average training steps per second: 322.44
I0903 00:09:46.365200 140369919707136 replay_runner.py:36] Average training steps per second: 322.44
I0903 00:09:47.892762 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.40
INFO:tensorflow:Starting iteration 12
I0903 00:09:51.123471 140369919707136 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 332.53

Steps executed: 361 Episode length: 205 Return: -151.7362980312646574
I0903 00:09:54.374229 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.46
INFO:tensorflow:Starting iteration 13

Steps executed: 397 Episode length: 292 Return: -452.1184702332084674
INFO:tensorflow:Average training steps per second: 345.64
I0903 00:10:00.612928 140369919707136 replay_runner.py:36] Average training steps per second: 345.64
I0903 00:10:00.991813 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.38
INFO:tensorflow:Starting iteration 14

Steps executed: 413 Episode length: 244 Return: -494.4485916695292674
INFO:tensorflow:Average training steps per second: 343.46
I0903 00:10:07.270610 140369919707136 replay_runner.py:36] Average training steps per second: 343.46
I0903 00:10:07.595054 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -533.34
INFO:tensorflow:Starting iteration 15
I0903 00:10:11.015547 140369919707136 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 357.85

Steps executed: 1000 Episode length: 1000 Return: -113.03164525070093
I0903 00:10:16.720527 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.03
INFO:tensorflow:Starting iteration 16

Steps executed: 390 Episode length: 390 Return: -407.5907086592229793
INFO:tensorflow:Average training steps per second: 328.41
I0903 00:10:23.105958 140369919707136 replay_runner.py:36] Average training steps per second: 328.41
I0903 00:10:23.563245 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -407.59
INFO:tensorflow:Starting iteration 17

Steps executed: 304 Episode length: 122 Return: -98.60743795733352593
INFO:tensorflow:Average training steps per second: 325.07
I0903 00:10:29.957841 140369919707136 replay_runner.py:36] Average training steps per second: 325.07
I0903 00:10:30.143149 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.77
INFO:tensorflow:Starting iteration 18

Steps executed: 336 Episode length: 273 Return: -278.3343750057229593
INFO:tensorflow:Average training steps per second: 319.85
I0903 00:10:36.549314 140369919707136 replay_runner.py:36] Average training steps per second: 319.85
I0903 00:10:36.836615 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -204.49
INFO:tensorflow:Starting iteration 19

Steps executed: 253 Episode length: 109 Return: -645.9228889906404593
INFO:tensorflow:Average training steps per second: 301.53
I0903 00:10:43.403816 140369919707136 replay_runner.py:36] Average training steps per second: 301.53
I0903 00:10:43.586493 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -496.11
INFO:tensorflow:Starting iteration 20
I0903 00:10:46.828260 140369919707136 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 307.32
I0903 00:10:50.082512 140369919707136 replay_runner.py:36] Average training steps per second: 307.32

Steps executed: 224 Episode length: 108 Return: -785.9559899085464593
INFO:tensorflow:Starting iteration 21

Steps executed: 205 Episode length: 53 Return: -63.009841118863024593
INFO:tensorflow:Average training steps per second: 318.79
I0903 00:10:56.627392 140369919707136 replay_runner.py:36] Average training steps per second: 318.79
I0903 00:10:56.737611 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.63
INFO:tensorflow:Starting iteration 22

Steps executed: 239 Episode length: 114 Return: -90.81138454475687693
INFO:tensorflow:Average training steps per second: 318.11
I0903 00:11:03.178489 140369919707136 replay_runner.py:36] Average training steps per second: 318.11
I0903 00:11:03.327328 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.32
INFO:tensorflow:Starting iteration 23

Steps executed: 344 Episode length: 221 Return: -557.6056745502774693
INFO:tensorflow:Average training steps per second: 318.99
I0903 00:11:09.814584 140369919707136 replay_runner.py:36] Average training steps per second: 318.99
I0903 00:11:10.083847 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -526.14
INFO:tensorflow:Starting iteration 24

Steps executed: 267 Episode length: 137 Return: -120.8749999432756393
INFO:tensorflow:Average training steps per second: 322.86
I0903 00:11:16.496902 140369919707136 replay_runner.py:36] Average training steps per second: 322.86
I0903 00:11:16.689953 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.54
INFO:tensorflow:Starting iteration 25

Steps executed: 231 Episode length: 68 Return: -378.04145417588285393
INFO:tensorflow:Average training steps per second: 342.63
I0903 00:11:22.906448 140369919707136 replay_runner.py:36] Average training steps per second: 342.63
I0903 00:11:23.046825 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -358.16
INFO:tensorflow:Starting iteration 26

Steps executed: 267 Episode length: 71 Return: -171.30726150996526393
INFO:tensorflow:Average training steps per second: 346.27
I0903 00:11:29.330353 140369919707136 replay_runner.py:36] Average training steps per second: 346.27
I0903 00:11:29.465673 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.76
INFO:tensorflow:Starting iteration 27

Steps executed: 303 Episode length: 105 Return: -477.3667579689435393
INFO:tensorflow:Average training steps per second: 350.89
I0903 00:11:35.750224 140369919707136 replay_runner.py:36] Average training steps per second: 350.89
I0903 00:11:35.955911 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -541.82
INFO:tensorflow:Starting iteration 28

Steps executed: 264 Episode length: 86 Return: -775.87240226769033393
INFO:tensorflow:Average training steps per second: 356.16
I0903 00:11:42.125519 140369919707136 replay_runner.py:36] Average training steps per second: 356.16
I0903 00:11:42.282880 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -540.58
INFO:tensorflow:Starting iteration 29
I0903 00:11:45.639568 140369919707136 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 356.73

Steps executed: 278 Episode length: 95 Return: -681.98208656933083393

Done fixed training!Episode length: 95 Return: -681.98208656933083393