Loaded trained dqn in acrobot
Training fixed agent 4, please be patient, may be a while...
I0828 10:40:14.979807 140160266885120 run_experiment.py:549] Creating TrainRunner ...
I0828 10:40:14.988839 140160266885120 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:40:14.989049 140160266885120 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:40:14.989136 140160266885120 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:40:14.989207 140160266885120 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:40:14.989267 140160266885120 dqn_agent.py:275] 	 update_period: 4
I0828 10:40:14.989321 140160266885120 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:40:14.989380 140160266885120 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:40:14.989506 140160266885120 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:40:14.989574 140160266885120 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:40:14.989663 140160266885120 dqn_agent.py:280] 	 optimizer: adam
I0828 10:40:14.989717 140160266885120 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:40:14.989769 140160266885120 dqn_agent.py:283] 	 seed: 1630147214988777
I0828 10:40:14.993264 140160266885120 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:40:14.993649 140160266885120 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:40:14.993948 140160266885120 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:40:14.994140 140160266885120 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:40:14.994263 140160266885120 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:40:14.994347 140160266885120 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:40:14.994525 140160266885120 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:40:14.994629 140160266885120 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:40:14.994880 140160266885120 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:40:15.032150 140160266885120 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:40:15.438981 140160266885120 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:40:15.451834 140160266885120 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:40:15.458612 140160266885120 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:40:15.458779 140160266885120 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:40:15.458866 140160266885120 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:40:15.459192 140160266885120 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:40:15.459366 140160266885120 dqn_agent.py:275] 	 update_period: 4
I0828 10:40:15.459483 140160266885120 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:40:15.459583 140160266885120 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:40:15.459683 140160266885120 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:40:15.459852 140160266885120 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:40:15.459995 140160266885120 dqn_agent.py:280] 	 optimizer: adam
I0828 10:40:15.460110 140160266885120 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:40:15.460225 140160266885120 dqn_agent.py:283] 	 seed: 1630147215458572
I0828 10:40:15.490234 140160266885120 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:40:15.490473 140160266885120 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:40:15.490558 140160266885120 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:40:15.491022 140160266885120 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:40:15.491270 140160266885120 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:40:15.491574 140160266885120 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:40:15.491760 140160266885120 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:40:15.491924 140160266885120 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:40:15.492044 140160266885120 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:40:15.522442 140160266885120 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:40:15.544290 140160266885120 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:40:15.544672 140160266885120 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 144.01
I0828 10:40:22.489344 140160266885120 replay_runner.py:36] Average training steps per second: 144.01
Steps executed: 500 Episode length: 500 Return: -500.0
I0828 10:40:23.991969 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1

Steps executed: 243 Episode length: 120 Return: -119.0
INFO:tensorflow:Average training steps per second: 202.65
I0828 10:40:29.156156 140160266885120 replay_runner.py:36] Average training steps per second: 202.65
I0828 10:40:29.357757 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.50
INFO:tensorflow:Starting iteration 2

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 195.61
I0828 10:40:34.707556 140160266885120 replay_runner.py:36] Average training steps per second: 195.61
I0828 10:40:35.111735 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 3
I0828 10:40:35.351572 140160266885120 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 189.88
I0828 10:40:40.618380 140160266885120 replay_runner.py:36] Average training steps per second: 189.88
I0828 10:40:41.058474 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 4
I0828 10:40:41.304713 140160266885120 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 192.76
I0828 10:40:46.492890 140160266885120 replay_runner.py:36] Average training steps per second: 192.76
I0828 10:40:46.948349 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 5

Steps executed: 160 Episode length: 160 Return: -159.0
INFO:tensorflow:Average training steps per second: 190.38

Steps executed: 660 Episode length: 500 Return: -500.0
I0828 10:40:53.014003 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.50
INFO:tensorflow:Starting iteration 6

Steps executed: 250 Episode length: 124 Return: -123.0
INFO:tensorflow:Average training steps per second: 193.85
I0828 10:40:58.418845 140160266885120 replay_runner.py:36] Average training steps per second: 193.85
I0828 10:40:58.622821 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.00
INFO:tensorflow:Starting iteration 7

Steps executed: 442 Episode length: 283 Return: -282.0
INFO:tensorflow:Average training steps per second: 195.97
I0828 10:41:03.972997 140160266885120 replay_runner.py:36] Average training steps per second: 195.97
I0828 10:41:04.341845 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.00
INFO:tensorflow:Starting iteration 8

Steps executed: 273 Episode length: 133 Return: -132.0
INFO:tensorflow:Average training steps per second: 199.47
I0828 10:41:09.602909 140160266885120 replay_runner.py:36] Average training steps per second: 199.47
I0828 10:41:09.830504 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.50
INFO:tensorflow:Starting iteration 9

Steps executed: 292 Episode length: 187 Return: -186.0
INFO:tensorflow:Average training steps per second: 191.82
I0828 10:41:15.278342 140160266885120 replay_runner.py:36] Average training steps per second: 191.82
I0828 10:41:15.540896 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.00
INFO:tensorflow:Starting iteration 10
I0828 10:41:15.797053 140160266885120 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 195.96

Steps executed: 330 Episode length: 157 Return: -156.0
I0828 10:41:21.183256 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.00
INFO:tensorflow:Starting iteration 11

Steps executed: 311 Episode length: 311 Return: -310.0
INFO:tensorflow:Average training steps per second: 197.65
I0828 10:41:26.495344 140160266885120 replay_runner.py:36] Average training steps per second: 197.65
I0828 10:41:26.762758 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.00
INFO:tensorflow:Starting iteration 12

Steps executed: 371 Episode length: 183 Return: -182.0
INFO:tensorflow:Average training steps per second: 194.60
I0828 10:41:32.143252 140160266885120 replay_runner.py:36] Average training steps per second: 194.60
I0828 10:41:32.467733 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.50
INFO:tensorflow:Starting iteration 13

Steps executed: 214 Episode length: 122 Return: -121.0
INFO:tensorflow:Average training steps per second: 190.02
I0828 10:41:37.988707 140160266885120 replay_runner.py:36] Average training steps per second: 190.02
I0828 10:41:38.170027 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.00
INFO:tensorflow:Starting iteration 14

Steps executed: 244 Episode length: 149 Return: -148.0
INFO:tensorflow:Average training steps per second: 191.71
I0828 10:41:43.630590 140160266885120 replay_runner.py:36] Average training steps per second: 191.71
I0828 10:41:43.846880 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.00
INFO:tensorflow:Starting iteration 15
I0828 10:41:44.087681 140160266885120 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 203.44
I0828 10:41:49.003464 140160266885120 replay_runner.py:36] Average training steps per second: 203.44

Steps executed: 299 Episode length: 165 Return: -164.0
INFO:tensorflow:Starting iteration 16

Steps executed: 80 Episode length: 80 Return: -79.04.0
INFO:tensorflow:Average training steps per second: 190.23
I0828 10:41:54.752123 140160266885120 replay_runner.py:36] Average training steps per second: 190.23
I0828 10:41:54.939187 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.00
INFO:tensorflow:Starting iteration 17


Steps executed: 223 Episode length: 147 Return: -146.0
INFO:tensorflow:Average training steps per second: 199.43
I0828 10:42:00.187728 140160266885120 replay_runner.py:36] Average training steps per second: 199.43
I0828 10:42:00.375733 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.50
INFO:tensorflow:Starting iteration 18

Steps executed: 221 Episode length: 127 Return: -126.0
INFO:tensorflow:Average training steps per second: 192.11
I0828 10:42:05.825397 140160266885120 replay_runner.py:36] Average training steps per second: 192.11
I0828 10:42:06.018142 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.50
INFO:tensorflow:Starting iteration 19

Steps executed: 571 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 202.07
I0828 10:42:11.206857 140160266885120 replay_runner.py:36] Average training steps per second: 202.07
I0828 10:42:11.671030 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.00
INFO:tensorflow:Starting iteration 20

Steps executed: 114 Episode length: 114 Return: -113.0
INFO:tensorflow:Average training steps per second: 208.48

Steps executed: 614 Episode length: 500 Return: -500.0
I0828 10:42:17.175610 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -306.50
INFO:tensorflow:Starting iteration 21

Steps executed: 253 Episode length: 132 Return: -131.0
INFO:tensorflow:Average training steps per second: 206.23
I0828 10:42:22.253856 140160266885120 replay_runner.py:36] Average training steps per second: 206.23
I0828 10:42:22.436821 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.50
INFO:tensorflow:Starting iteration 22
I0828 10:42:22.663771 140160266885120 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 203.02
I0828 10:42:27.591259 140160266885120 replay_runner.py:36] Average training steps per second: 203.02
I0828 10:42:27.810780 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.00
INFO:tensorflow:Starting iteration 23

Steps executed: 288 Episode length: 109 Return: -108.0
INFO:tensorflow:Average training steps per second: 205.08

Steps executed: 101 Episode length: 101 Return: -100.0
I0828 10:42:33.434743 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.00
INFO:tensorflow:Starting iteration 24


Steps executed: 285 Episode length: 114 Return: -113.0
INFO:tensorflow:Average training steps per second: 198.34
I0828 10:42:38.702596 140160266885120 replay_runner.py:36] Average training steps per second: 198.34
I0828 10:42:38.931024 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.00
INFO:tensorflow:Starting iteration 25

Steps executed: 235 Episode length: 85 Return: -84.0.0
INFO:tensorflow:Average training steps per second: 206.53
I0828 10:42:44.003430 140160266885120 replay_runner.py:36] Average training steps per second: 206.53
I0828 10:42:44.199428 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.33
INFO:tensorflow:Starting iteration 26

Steps executed: 256 Episode length: 73 Return: -72.0.0
INFO:tensorflow:Average training steps per second: 197.58
I0828 10:42:49.494649 140160266885120 replay_runner.py:36] Average training steps per second: 197.58
I0828 10:42:49.692957 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.33
INFO:tensorflow:Starting iteration 27

Steps executed: 221 Episode length: 221 Return: -220.0
INFO:tensorflow:Average training steps per second: 204.94
I0828 10:42:54.806876 140160266885120 replay_runner.py:36] Average training steps per second: 204.94
I0828 10:42:54.998836 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.00
INFO:tensorflow:Starting iteration 28

Steps executed: 259 Episode length: 85 Return: -84.000
INFO:tensorflow:Average training steps per second: 200.67
I0828 10:43:00.422924 140160266885120 replay_runner.py:36] Average training steps per second: 200.67
I0828 10:43:00.643393 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.33
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 99 Return: -98.000
INFO:tensorflow:Average training steps per second: 206.06
I0828 10:43:05.727401 140160266885120 replay_runner.py:36] Average training steps per second: 206.06
I0828 10:43:05.948351 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.00