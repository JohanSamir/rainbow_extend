Loaded trained dqn in acrobot
Training fixed agent 6, please be patient, may be a while...
I0828 10:40:27.177990 140591351420928 run_experiment.py:549] Creating TrainRunner ...
I0828 10:40:27.187244 140591351420928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:40:27.187450 140591351420928 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:40:27.187564 140591351420928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:40:27.187633 140591351420928 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:40:27.187690 140591351420928 dqn_agent.py:275] 	 update_period: 4
I0828 10:40:27.187743 140591351420928 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:40:27.187808 140591351420928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:40:27.187895 140591351420928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:40:27.188233 140591351420928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:40:27.188588 140591351420928 dqn_agent.py:280] 	 optimizer: adam
I0828 10:40:27.188768 140591351420928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:40:27.188895 140591351420928 dqn_agent.py:283] 	 seed: 1630147227187191
I0828 10:40:27.192168 140591351420928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:40:27.192313 140591351420928 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:40:27.192394 140591351420928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:40:27.192457 140591351420928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:40:27.192516 140591351420928 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:40:27.192606 140591351420928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:40:27.192670 140591351420928 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:40:27.192759 140591351420928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:40:27.192834 140591351420928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:40:27.232008 140591351420928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:40:27.660236 140591351420928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:40:27.693653 140591351420928 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:40:27.702206 140591351420928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:40:27.702494 140591351420928 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:40:27.702619 140591351420928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:40:27.702708 140591351420928 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:40:27.702783 140591351420928 dqn_agent.py:275] 	 update_period: 4
I0828 10:40:27.702853 140591351420928 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:40:27.702956 140591351420928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:40:27.703060 140591351420928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:40:27.703155 140591351420928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:40:27.703219 140591351420928 dqn_agent.py:280] 	 optimizer: adam
I0828 10:40:27.703284 140591351420928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:40:27.703347 140591351420928 dqn_agent.py:283] 	 seed: 1630147227702098
I0828 10:40:27.706186 140591351420928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:40:27.706551 140591351420928 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:40:27.706768 140591351420928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:40:27.706999 140591351420928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:40:27.707118 140591351420928 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:40:27.707237 140591351420928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:40:27.707374 140591351420928 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:40:27.707490 140591351420928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:40:27.707619 140591351420928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:40:27.744031 140591351420928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:40:27.768386 140591351420928 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:40:27.768712 140591351420928 replay_runner.py:41] Starting iteration 0
Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 139.02
I0828 10:40:34.962388 140591351420928 replay_runner.py:36] Average training steps per second: 139.02
I0828 10:40:36.495786 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1
I0828 10:40:36.738183 140591351420928 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 189.23
I0828 10:40:42.023507 140591351420928 replay_runner.py:36] Average training steps per second: 189.23
I0828 10:40:42.437981 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 2

Steps executed: 265 Episode length: 265 Return: -264.0
INFO:tensorflow:Average training steps per second: 191.53
I0828 10:40:47.900068 140591351420928 replay_runner.py:36] Average training steps per second: 191.53
I0828 10:40:48.164325 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -264.00
INFO:tensorflow:Starting iteration 3

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 194.21
I0828 10:40:53.564271 140591351420928 replay_runner.py:36] Average training steps per second: 194.21
I0828 10:40:54.010030 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 4
I0828 10:40:54.243064 140591351420928 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 193.56
I0828 10:40:59.409771 140591351420928 replay_runner.py:36] Average training steps per second: 193.56
I0828 10:40:59.825941 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 5
I0828 10:41:00.069958 140591351420928 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 191.90
I0828 10:41:05.281388 140591351420928 replay_runner.py:36] Average training steps per second: 191.90
I0828 10:41:05.727011 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6
I0828 10:41:05.969530 140591351420928 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 193.04
I0828 10:41:11.150033 140591351420928 replay_runner.py:36] Average training steps per second: 193.04
I0828 10:41:11.551894 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7

Steps executed: 467 Episode length: 287 Return: -286.0
INFO:tensorflow:Average training steps per second: 186.89
I0828 10:41:17.148566 140591351420928 replay_runner.py:36] Average training steps per second: 186.89
I0828 10:41:17.539912 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.50
INFO:tensorflow:Starting iteration 8

Steps executed: 140 Episode length: 140 Return: -139.0
INFO:tensorflow:Average training steps per second: 192.63

Steps executed: 279 Episode length: 139 Return: -138.0
I0828 10:41:23.226915 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.50
INFO:tensorflow:Starting iteration 9

Steps executed: 275 Episode length: 141 Return: -140.0
INFO:tensorflow:Average training steps per second: 189.52
I0828 10:41:28.742303 140591351420928 replay_runner.py:36] Average training steps per second: 189.52
I0828 10:41:28.973816 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.50
INFO:tensorflow:Starting iteration 10

Steps executed: 229 Episode length: 136 Return: -135.0
INFO:tensorflow:Average training steps per second: 188.01
I0828 10:41:34.540405 140591351420928 replay_runner.py:36] Average training steps per second: 188.01
I0828 10:41:34.738298 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.50
INFO:tensorflow:Starting iteration 11

Steps executed: 312 Episode length: 165 Return: -164.0
INFO:tensorflow:Average training steps per second: 193.33
I0828 10:41:40.157841 140591351420928 replay_runner.py:36] Average training steps per second: 193.33
I0828 10:41:40.429586 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.00
INFO:tensorflow:Starting iteration 12

Steps executed: 313 Episode length: 199 Return: -198.0
INFO:tensorflow:Average training steps per second: 192.13
I0828 10:41:45.886594 140591351420928 replay_runner.py:36] Average training steps per second: 192.13
I0828 10:41:46.140873 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.50
INFO:tensorflow:Starting iteration 13

Steps executed: 624 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 190.36
I0828 10:41:51.635971 140591351420928 replay_runner.py:36] Average training steps per second: 190.36
I0828 10:41:52.146774 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.50
INFO:tensorflow:Starting iteration 14
I0828 10:41:52.389662 140591351420928 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 198.04

Steps executed: 233 Episode length: 116 Return: -115.0
I0828 10:41:57.633874 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.50
INFO:tensorflow:Starting iteration 15

Steps executed: 245 Episode length: 110 Return: -109.0
INFO:tensorflow:Average training steps per second: 193.97
I0828 10:42:03.024419 140591351420928 replay_runner.py:36] Average training steps per second: 193.97
I0828 10:42:03.237636 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.50
INFO:tensorflow:Starting iteration 16

Steps executed: 284 Episode length: 90 Return: -89.0.0
INFO:tensorflow:Average training steps per second: 195.58
I0828 10:42:08.743815 140591351420928 replay_runner.py:36] Average training steps per second: 195.58
I0828 10:42:09.002775 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.67
INFO:tensorflow:Starting iteration 17

Steps executed: 267 Episode length: 95 Return: -94.0.0
INFO:tensorflow:Average training steps per second: 206.09
I0828 10:42:14.089659 140591351420928 replay_runner.py:36] Average training steps per second: 206.09
I0828 10:42:14.302393 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.00
INFO:tensorflow:Starting iteration 18

Steps executed: 231 Episode length: 105 Return: -104.0
INFO:tensorflow:Average training steps per second: 196.48
I0828 10:42:19.623288 140591351420928 replay_runner.py:36] Average training steps per second: 196.48
I0828 10:42:19.793567 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.50
INFO:tensorflow:Starting iteration 19

Steps executed: 190 Episode length: 93 Return: -92.0.0
INFO:tensorflow:Average training steps per second: 201.73
I0828 10:42:24.974959 140591351420928 replay_runner.py:36] Average training steps per second: 201.73

Steps executed: 280 Episode length: 90 Return: -89.0.0
INFO:tensorflow:Starting iteration 20

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 199.45
I0828 10:42:30.459057 140591351420928 replay_runner.py:36] Average training steps per second: 199.45
I0828 10:42:30.838206 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 21

Steps executed: 244 Episode length: 90 Return: -89.0.0
INFO:tensorflow:Average training steps per second: 198.28
I0828 10:42:36.240704 140591351420928 replay_runner.py:36] Average training steps per second: 198.28
I0828 10:42:36.445040 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.00
INFO:tensorflow:Starting iteration 22

Steps executed: 224 Episode length: 104 Return: -103.0
INFO:tensorflow:Average training steps per second: 201.30
I0828 10:42:41.645172 140591351420928 replay_runner.py:36] Average training steps per second: 201.30
I0828 10:42:41.827915 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.00
INFO:tensorflow:Starting iteration 23

Steps executed: 321 Episode length: 135 Return: -134.0
INFO:tensorflow:Average training steps per second: 199.68
I0828 10:42:47.064731 140591351420928 replay_runner.py:36] Average training steps per second: 199.68
I0828 10:42:47.336945 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.00
INFO:tensorflow:Starting iteration 24

Steps executed: 279 Episode length: 107 Return: -106.0
INFO:tensorflow:Average training steps per second: 202.86
I0828 10:42:52.515277 140591351420928 replay_runner.py:36] Average training steps per second: 202.86
I0828 10:42:52.732644 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.00
INFO:tensorflow:Starting iteration 25

Steps executed: 218 Episode length: 64 Return: -63.0.0
INFO:tensorflow:Average training steps per second: 194.68
I0828 10:42:58.102097 140591351420928 replay_runner.py:36] Average training steps per second: 194.68
I0828 10:42:58.282908 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.67
INFO:tensorflow:Starting iteration 26
I0828 10:42:58.518162 140591351420928 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 198.70

Steps executed: 235 Episode length: 235 Return: -234.0
I0828 10:43:03.736307 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.00
INFO:tensorflow:Starting iteration 27

Steps executed: 245 Episode length: 83 Return: -82.0.0
INFO:tensorflow:Average training steps per second: 201.67
I0828 10:43:08.928730 140591351420928 replay_runner.py:36] Average training steps per second: 201.67
I0828 10:43:09.123698 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.67
INFO:tensorflow:Starting iteration 28

Steps executed: 239 Episode length: 86 Return: -85.0.0
INFO:tensorflow:Average training steps per second: 200.21
I0828 10:43:14.342722 140591351420928 replay_runner.py:36] Average training steps per second: 200.21
I0828 10:43:14.528348 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.67
INFO:tensorflow:Starting iteration 29

Steps executed: 94 Episode length: 94 Return: -93.00.0
INFO:tensorflow:Average training steps per second: 203.89

Done fixed training!Episode length: 79 Return: -78.0.0
I0828 10:43:19.874044 140591351420928 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.33