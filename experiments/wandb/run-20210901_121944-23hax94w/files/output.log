Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0901 12:19:51.306332 140536266098688 run_experiment.py:549] Creating TrainRunner ...
I0901 12:19:51.317768 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:19:51.318041 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:19:51.318152 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:19:51.318219 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:19:51.318301 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 12:19:51.318378 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:19:51.318433 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:19:51.318541 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:19:51.318703 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:19:51.318894 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 12:19:51.319025 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:19:51.319246 140536266098688 dqn_agent.py:283] 	 seed: 1630498791317705
I0901 12:19:51.322780 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:19:51.323115 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:19:51.323319 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:19:51.323468 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:19:51.323596 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:19:51.323720 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:19:51.323860 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:19:51.324022 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:19:51.324141 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:19:51.395401 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:19:51.789946 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:19:51.824747 140536266098688 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:19:51.834077 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:19:51.834314 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:19:51.834425 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:19:51.834597 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:19:51.834819 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 12:19:51.834921 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:19:51.835020 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:19:51.835121 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:19:51.835196 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:19:51.835269 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 12:19:51.835370 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:19:51.835670 140536266098688 dqn_agent.py:283] 	 seed: 1630498791834022
I0901 12:19:51.838896 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:19:51.839109 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:19:51.839208 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:19:51.839293 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:19:51.839422 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:19:51.839680 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:19:51.839857 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:19:51.840000 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:19:51.840116 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:19:51.873413 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:19:51.893255 140536266098688 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:19:51.893587 140536266098688 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 164.15
I0901 12:19:57.985791 140536266098688 replay_runner.py:36] Average training steps per second: 164.15
Steps executed: 294 Episode length: 132 Return: -326.76730735670497
I0901 12:19:59.271149 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -302.03
INFO:tensorflow:Starting iteration 1

Steps executed: 232 Episode length: 122 Return: -214.20433506078497
INFO:tensorflow:Average training steps per second: 224.38
I0901 12:20:08.032321 140536266098688 replay_runner.py:36] Average training steps per second: 224.38
I0901 12:20:08.236814 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -214.43
INFO:tensorflow:Starting iteration 2

Steps executed: 331 Episode length: 201 Return: -134.19870462463817
INFO:tensorflow:Average training steps per second: 211.97
I0901 12:20:17.094878 140536266098688 replay_runner.py:36] Average training steps per second: 211.97
I0901 12:20:17.465201 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.53
INFO:tensorflow:Starting iteration 3

Steps executed: 258 Episode length: 258 Return: -265.69546961305605
INFO:tensorflow:Average training steps per second: 209.32
I0901 12:20:26.419149 140536266098688 replay_runner.py:36] Average training steps per second: 209.32
I0901 12:20:26.759923 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.70
INFO:tensorflow:Starting iteration 4
I0901 12:20:30.929348 140536266098688 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 217.40

Steps executed: 1000 Episode length: 1000 Return: -103.46230872402502
I0901 12:20:38.661645 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.46
INFO:tensorflow:Starting iteration 5
I0901 12:20:42.873192 140536266098688 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 212.67

Steps executed: 1000 Episode length: 1000 Return: -171.25552917594202
I0901 12:20:49.542894 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.26
INFO:tensorflow:Starting iteration 6
I0901 12:20:53.900610 140536266098688 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 214.81

Steps executed: 1000 Episode length: 1000 Return: -102.23684296597001
I0901 12:21:01.811120 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.24
INFO:tensorflow:Starting iteration 7
I0901 12:21:06.192213 140536266098688 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 213.00

Steps executed: 1000 Episode length: 1000 Return: -302.29710441925761
I0901 12:21:13.368608 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -302.30
INFO:tensorflow:Starting iteration 8
I0901 12:21:17.673144 140536266098688 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 214.27

Steps executed: 1000 Episode length: 1000 Return: -305.85578117475111
I0901 12:21:25.371066 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -305.86
INFO:tensorflow:Starting iteration 9
I0901 12:21:29.674172 140536266098688 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 210.24

Steps executed: 1000 Episode length: 1000 Return: -118.70037249788807
I0901 12:21:37.118678 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.70
INFO:tensorflow:Starting iteration 10
I0901 12:21:41.433026 140536266098688 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 231.39

Steps executed: 1000 Episode length: 1000 Return: -127.04405008971801
I0901 12:21:48.092282 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.04
INFO:tensorflow:Starting iteration 11
I0901 12:21:52.347105 140536266098688 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 224.12

Steps executed: 1000 Episode length: 1000 Return: -46.787925910047164
I0901 12:21:58.964359 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -46.79
INFO:tensorflow:Starting iteration 12
I0901 12:22:03.112090 140536266098688 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 233.21
I0901 12:22:07.400741 140536266098688 replay_runner.py:36] Average training steps per second: 233.21

Steps executed: 1000 Episode length: 1000 Return: -214.00473637530514
INFO:tensorflow:Starting iteration 13
I0901 12:22:13.904672 140536266098688 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 222.75

Steps executed: 1000 Episode length: 1000 Return: -84.937001931573254
I0901 12:22:21.654843 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.94
INFO:tensorflow:Starting iteration 14
I0901 12:22:25.832844 140536266098688 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 210.71

Steps executed: 1000 Episode length: 1000 Return: -65.488638933244774
I0901 12:22:33.720324 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.49
INFO:tensorflow:Starting iteration 15
I0901 12:22:38.132116 140536266098688 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 211.31

Steps executed: 1000 Episode length: 1000 Return: -60.189304485436924
I0901 12:22:45.963823 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -60.19
INFO:tensorflow:Starting iteration 16
I0901 12:22:50.218916 140536266098688 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 207.79

Steps executed: 1000 Episode length: 1000 Return: -111.05943192940829
I0901 12:22:58.121993 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.06
INFO:tensorflow:Starting iteration 17
I0901 12:23:02.494418 140536266098688 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 209.83

Steps executed: 1000 Episode length: 1000 Return: -135.58538429819529
I0901 12:23:09.498271 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.59
INFO:tensorflow:Starting iteration 18
I0901 12:23:13.712801 140536266098688 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 211.31

Steps executed: 1000 Episode length: 1000 Return: -54.550144632639549
I0901 12:23:21.075769 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.55
INFO:tensorflow:Starting iteration 19

Steps executed: 269 Episode length: 107 Return: 6.3316603187757041549
INFO:tensorflow:Average training steps per second: 213.19
I0901 12:23:30.091519 140536266098688 replay_runner.py:36] Average training steps per second: 213.19
I0901 12:23:30.367206 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -7.42
INFO:tensorflow:Starting iteration 20
I0901 12:23:34.413299 140536266098688 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 228.20

Steps executed: 641 Episode length: 641 Return: -343.7964334189128549
I0901 12:23:40.323732 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -343.80
INFO:tensorflow:Starting iteration 21

Steps executed: 80 Episode length: 80 Return: -16.4888939158560428549
INFO:tensorflow:Average training steps per second: 218.22

Steps executed: 478 Episode length: 398 Return: -3.846415541732597549
I0901 12:23:49.850349 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -10.17
INFO:tensorflow:Starting iteration 22
I0901 12:23:54.061449 140536266098688 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 217.06
I0901 12:23:58.669477 140536266098688 replay_runner.py:36] Average training steps per second: 217.06

Steps executed: 444 Episode length: 444 Return: -295.6060349837811549
INFO:tensorflow:Starting iteration 23

Steps executed: 311 Episode length: 164 Return: 9.1964683470774138549
INFO:tensorflow:Average training steps per second: 214.72
I0901 12:24:08.386599 140536266098688 replay_runner.py:36] Average training steps per second: 214.72
I0901 12:24:08.661510 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -25.62
INFO:tensorflow:Starting iteration 24
I0901 12:24:12.852828 140536266098688 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 208.31
I0901 12:24:17.654145 140536266098688 replay_runner.py:36] Average training steps per second: 208.31

Steps executed: 990 Episode length: 990 Return: -466.3575398747955549
INFO:tensorflow:Starting iteration 25

Steps executed: 546 Episode length: 386 Return: -335.1653250519725549
INFO:tensorflow:Average training steps per second: 218.51
I0901 12:24:30.453333 140536266098688 replay_runner.py:36] Average training steps per second: 218.51
I0901 12:24:31.190809 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.97
INFO:tensorflow:Starting iteration 26
I0901 12:24:35.622288 140536266098688 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 217.92

Steps executed: 692 Episode length: 692 Return: -391.3685524048986549
I0901 12:24:42.123510 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -391.37
INFO:tensorflow:Starting iteration 27

Steps executed: 276 Episode length: 175 Return: 0.2273622687856971549
INFO:tensorflow:Average training steps per second: 226.21
I0901 12:24:50.741607 140536266098688 replay_runner.py:36] Average training steps per second: 226.21
I0901 12:24:51.063577 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: 14.32
INFO:tensorflow:Starting iteration 28
I0901 12:24:55.268306 140536266098688 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 226.68

Steps executed: 1000 Episode length: 1000 Return: 74.6197258785479449
I0901 12:25:03.617779 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: 74.62
INFO:tensorflow:Starting iteration 29

Steps executed: 264 Episode length: 264 Return: -124.9102386227506749
INFO:tensorflow:Average training steps per second: 217.83
I0901 12:25:12.438943 140536266098688 replay_runner.py:36] Average training steps per second: 217.83

Done fixed training!Episode length: 264 Return: -124.9102386227506749