I0903 00:08:21.192164 140457530894336 run_experiment.py:549] Creating TrainRunner ...
I0903 00:08:21.199730 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:08:21.199848 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:08:21.199904 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:08:21.199980 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:08:21.200047 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0903 00:08:21.200137 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:08:21.200185 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:08:21.200250 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:08:21.200296 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:08:21.200356 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0903 00:08:21.200421 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:08:21.200470 140457530894336 dqn_agent.py:283] 	 seed: 1630627701199700
I0903 00:08:21.202235 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:08:21.202370 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:08:21.202445 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:08:21.202508 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:08:21.202565 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:08:21.202626 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:08:21.202680 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:08:21.202729 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:08:21.202805 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:08:21.226636 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:21.475057 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:21.484654 140457530894336 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:08:21.491291 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:08:21.491436 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:08:21.491515 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:08:21.491586 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:08:21.491654 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0903 00:08:21.491737 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:08:21.491802 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:08:21.491859 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:08:21.491955 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:08:21.492025 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0903 00:08:21.492113 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:08:21.492198 140457530894336 dqn_agent.py:283] 	 seed: 1630627701491261
I0903 00:08:21.494049 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:08:21.494169 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:08:21.494241 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:08:21.494304 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:08:21.494362 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:08:21.494430 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:08:21.494508 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:08:21.494586 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:08:21.494648 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:08:21.514735 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:21.529363 140457530894336 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:08:21.529504 140457530894336 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 265.61
I0903 00:08:25.294520 140457530894336 replay_runner.py:36] Average training steps per second: 265.61
I0903 00:08:26.168065 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -446.98
Steps executed: 258 Episode length: 113 Return: -402.23770417012406
INFO:tensorflow:Starting iteration 1

Steps executed: 252 Episode length: 149 Return: -243.65268938645763
INFO:tensorflow:Average training steps per second: 323.87
I0903 00:08:32.388266 140457530894336 replay_runner.py:36] Average training steps per second: 323.87
I0903 00:08:32.545389 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.69
INFO:tensorflow:Starting iteration 2

Steps executed: 122 Episode length: 122 Return: -122.57347657256563
INFO:tensorflow:Average training steps per second: 335.69

Steps executed: 330 Episode length: 208 Return: -268.56952815743663
I0903 00:08:38.967468 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.57
INFO:tensorflow:Starting iteration 3

Steps executed: 608 Episode length: 432 Return: -242.94026829221793
INFO:tensorflow:Average training steps per second: 344.05
I0903 00:08:45.321138 140457530894336 replay_runner.py:36] Average training steps per second: 344.05
I0903 00:08:46.063724 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.05
INFO:tensorflow:Starting iteration 4
I0903 00:08:49.547059 140457530894336 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 344.48

Steps executed: 1000 Episode length: 1000 Return: -60.164360181047314
I0903 00:08:54.510131 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -60.16
INFO:tensorflow:Starting iteration 5
I0903 00:08:57.754639 140457530894336 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 357.82

Steps executed: 1000 Episode length: 1000 Return: -25.087386249336937
I0903 00:09:02.800835 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -25.09
INFO:tensorflow:Starting iteration 6
I0903 00:09:05.906920 140457530894336 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 331.28

Steps executed: 516 Episode length: 516 Return: -441.2830170605957437
I0903 00:09:09.784294 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -441.28
INFO:tensorflow:Starting iteration 7
I0903 00:09:13.163887 140457530894336 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 343.98

Steps executed: 1000 Episode length: 1000 Return: -160.45231131939173
I0903 00:09:17.827981 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.45
INFO:tensorflow:Starting iteration 8
I0903 00:09:21.222393 140457530894336 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 331.60

Steps executed: 954 Episode length: 954 Return: -308.4856341510798173
I0903 00:09:25.421717 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.49
INFO:tensorflow:Starting iteration 9

Steps executed: 805 Episode length: 805 Return: -352.4855921929223173
INFO:tensorflow:Average training steps per second: 331.81
I0903 00:09:31.818370 140457530894336 replay_runner.py:36] Average training steps per second: 331.81
I0903 00:09:32.913338 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.49
INFO:tensorflow:Starting iteration 10

Steps executed: 1000 Episode length: 1000 Return: -297.19892377421513
INFO:tensorflow:Average training steps per second: 335.32
I0903 00:09:39.280880 140457530894336 replay_runner.py:36] Average training steps per second: 335.32
I0903 00:09:40.636684 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -297.20
INFO:tensorflow:Starting iteration 11
I0903 00:09:43.924302 140457530894336 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 323.47

Steps executed: 1000 Episode length: 1000 Return: -21.567363472432906
I0903 00:09:48.675055 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -21.57
INFO:tensorflow:Starting iteration 12
I0903 00:09:51.865296 140457530894336 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 319.14

Steps executed: 1000 Episode length: 1000 Return: -82.388167913116676
I0903 00:09:56.680107 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.39
INFO:tensorflow:Starting iteration 13
I0903 00:10:00.056983 140457530894336 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 324.74

Steps executed: 1000 Episode length: 1000 Return: -85.906833613520876
I0903 00:10:05.237857 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.91
INFO:tensorflow:Starting iteration 14

Steps executed: 331 Episode length: 331 Return: -26.32010366505764476
INFO:tensorflow:Average training steps per second: 352.37
I0903 00:10:11.609395 140457530894336 replay_runner.py:36] Average training steps per second: 352.37
I0903 00:10:11.859304 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -26.32
INFO:tensorflow:Starting iteration 15

Steps executed: 446 Episode length: 247 Return: -524.4234392039691476
INFO:tensorflow:Average training steps per second: 334.80
I0903 00:10:18.311185 140457530894336 replay_runner.py:36] Average training steps per second: 334.80
I0903 00:10:18.635942 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.40
INFO:tensorflow:Starting iteration 16

Steps executed: 339 Episode length: 215 Return: -618.4702216416835476
INFO:tensorflow:Average training steps per second: 343.64
I0903 00:10:24.969738 140457530894336 replay_runner.py:36] Average training steps per second: 343.64
I0903 00:10:25.190372 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -492.38
INFO:tensorflow:Starting iteration 17
I0903 00:10:28.622541 140457530894336 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 349.74

Steps executed: 374 Episode length: 217 Return: -431.4262983511893676
I0903 00:10:31.724893 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -414.59
INFO:tensorflow:Starting iteration 18

Steps executed: 242 Episode length: 242 Return: -639.5778769778085676
INFO:tensorflow:Average training steps per second: 327.99
I0903 00:10:38.197789 140457530894336 replay_runner.py:36] Average training steps per second: 327.99
I0903 00:10:38.362657 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -639.58
INFO:tensorflow:Starting iteration 19

Steps executed: 210 Episode length: 210 Return: -480.7843822941509376
INFO:tensorflow:Average training steps per second: 308.83
I0903 00:10:44.830844 140457530894336 replay_runner.py:36] Average training steps per second: 308.83
I0903 00:10:44.958824 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -480.78
INFO:tensorflow:Starting iteration 20
I0903 00:10:48.125204 140457530894336 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 304.53

Steps executed: 415 Episode length: 283 Return: -208.6808891006052776
I0903 00:10:51.660809 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.16
INFO:tensorflow:Starting iteration 21

Steps executed: 241 Episode length: 87 Return: -364.85876467133886276
INFO:tensorflow:Average training steps per second: 309.48
I0903 00:10:58.035843 140457530894336 replay_runner.py:36] Average training steps per second: 309.48
I0903 00:10:58.153391 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -238.78
INFO:tensorflow:Starting iteration 22

Steps executed: 205 Episode length: 50 Return: -262.09396018077821276
INFO:tensorflow:Average training steps per second: 307.92
I0903 00:11:04.581825 140457530894336 replay_runner.py:36] Average training steps per second: 307.92
I0903 00:11:04.690612 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.39
INFO:tensorflow:Starting iteration 23

Steps executed: 345 Episode length: 182 Return: -458.2469518558524476
INFO:tensorflow:Average training steps per second: 296.11
I0903 00:11:11.317904 140457530894336 replay_runner.py:36] Average training steps per second: 296.11
I0903 00:11:11.518489 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.25
INFO:tensorflow:Starting iteration 24

Steps executed: 207 Episode length: 64 Return: -367.61390172505484476
INFO:tensorflow:Average training steps per second: 309.46
I0903 00:11:18.040838 140457530894336 replay_runner.py:36] Average training steps per second: 309.46
I0903 00:11:18.157553 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -494.30
INFO:tensorflow:Starting iteration 25

Steps executed: 228 Episode length: 66 Return: -457.22759348526654476
INFO:tensorflow:Average training steps per second: 309.98
I0903 00:11:24.618516 140457530894336 replay_runner.py:36] Average training steps per second: 309.98
I0903 00:11:24.752200 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -401.49
INFO:tensorflow:Starting iteration 26

Steps executed: 254 Episode length: 149 Return: -438.9921497708341476
INFO:tensorflow:Average training steps per second: 284.10
I0903 00:11:31.510674 140457530894336 replay_runner.py:36] Average training steps per second: 284.10
I0903 00:11:31.664625 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -560.88
INFO:tensorflow:Starting iteration 27

Steps executed: 305 Episode length: 109 Return: -679.9127240027732876
INFO:tensorflow:Average training steps per second: 315.44
I0903 00:11:38.110247 140457530894336 replay_runner.py:36] Average training steps per second: 315.44
I0903 00:11:38.276621 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -323.39
INFO:tensorflow:Starting iteration 28

Steps executed: 265 Episode length: 78 Return: -48.093431603077836876
INFO:tensorflow:Average training steps per second: 317.71
I0903 00:11:44.648384 140457530894336 replay_runner.py:36] Average training steps per second: 317.71
I0903 00:11:44.828975 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -317.27
INFO:tensorflow:Starting iteration 29

Steps executed: 290 Episode length: 126 Return: -308.3494510568156876
INFO:tensorflow:Average training steps per second: 321.27
I0903 00:11:51.178724 140457530894336 replay_runner.py:36] Average training steps per second: 321.27

Done fixed training!Episode length: 126 Return: -308.3494510568156876