I0905 16:38:20.754184 140275076675584 run_experiment.py:549] Creating TrainRunner ...
I0905 16:38:20.761934 140275076675584 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:38:20.762088 140275076675584 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:38:20.762172 140275076675584 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:38:20.762241 140275076675584 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:38:20.762304 140275076675584 dqn_agent.py:275] 	 update_period: 4
I0905 16:38:20.762370 140275076675584 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:38:20.762455 140275076675584 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:38:20.762559 140275076675584 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:38:20.762638 140275076675584 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:38:20.762715 140275076675584 dqn_agent.py:280] 	 optimizer: adam
I0905 16:38:20.762787 140275076675584 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:38:20.762868 140275076675584 dqn_agent.py:283] 	 seed: 1630859900761890
I0905 16:38:20.764755 140275076675584 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:38:20.764883 140275076675584 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:38:20.764969 140275076675584 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:38:20.765040 140275076675584 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:38:20.765105 140275076675584 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:38:20.765171 140275076675584 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:38:20.765276 140275076675584 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:38:20.765353 140275076675584 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:38:20.765413 140275076675584 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:38:22.260136 140275076675584 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0905 16:38:22.529219 140275076675584 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:38:22.537481 140275076675584 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:38:22.544256 140275076675584 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:38:22.544420 140275076675584 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:38:22.544499 140275076675584 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:38:22.544561 140275076675584 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:38:22.544617 140275076675584 dqn_agent.py:275] 	 update_period: 4
I0905 16:38:22.544690 140275076675584 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:38:22.544792 140275076675584 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:38:22.544850 140275076675584 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:38:22.544925 140275076675584 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:38:22.545001 140275076675584 dqn_agent.py:280] 	 optimizer: adam
I0905 16:38:22.545069 140275076675584 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:38:22.545141 140275076675584 dqn_agent.py:283] 	 seed: 1630859902544222
I0905 16:38:22.546502 140275076675584 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:38:22.546614 140275076675584 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:38:22.546687 140275076675584 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:38:22.546750 140275076675584 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:38:22.546807 140275076675584 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:38:22.546861 140275076675584 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:38:22.546933 140275076675584 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:38:22.547013 140275076675584 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:38:22.547082 140275076675584 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:38:22.570696 140275076675584 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:38:22.588892 140275076675584 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:38:22.589095 140275076675584 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 270.21
I0905 16:38:26.290101 140275076675584 replay_runner.py:36] Average training steps per second: 270.21
Steps executed: 313 Episode length: 132 Return: -408.00379129054477
I0905 16:38:27.067686 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -381.89
INFO:tensorflow:Starting iteration 1

Steps executed: 300 Episode length: 125 Return: -279.31177025816447
INFO:tensorflow:Average training steps per second: 335.15
I0905 16:38:33.553323 140275076675584 replay_runner.py:36] Average training steps per second: 335.15
I0905 16:38:33.727877 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.01
INFO:tensorflow:Starting iteration 2

Steps executed: 121 Episode length: 121 Return: -92.091963437443877
INFO:tensorflow:Average training steps per second: 321.40

Steps executed: 547 Episode length: 426 Return: -365.14285456749627
I0905 16:38:40.839225 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.62
INFO:tensorflow:Starting iteration 3
I0905 16:38:44.212514 140275076675584 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 325.18

Steps executed: 1000 Episode length: 1000 Return: -77.2040545516736
I0905 16:38:48.850506 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.20
INFO:tensorflow:Starting iteration 4
I0905 16:38:52.305834 140275076675584 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 345.79

Steps executed: 1000 Episode length: 1000 Return: -174.67254027022878
I0905 16:38:57.241360 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.67
INFO:tensorflow:Starting iteration 5

Steps executed: 747 Episode length: 747 Return: -407.7984650466256878
INFO:tensorflow:Average training steps per second: 348.78
I0905 16:39:03.547849 140275076675584 replay_runner.py:36] Average training steps per second: 348.78
I0905 16:39:04.464498 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -407.80
INFO:tensorflow:Starting iteration 6

Steps executed: 733 Episode length: 733 Return: -397.1047212851956878
INFO:tensorflow:Average training steps per second: 344.88
I0905 16:39:10.856774 140275076675584 replay_runner.py:36] Average training steps per second: 344.88
I0905 16:39:11.667146 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -397.10
INFO:tensorflow:Starting iteration 7

Steps executed: 404 Episode length: 404 Return: -459.6030587820349878
INFO:tensorflow:Average training steps per second: 330.79
I0905 16:39:18.174465 140275076675584 replay_runner.py:36] Average training steps per second: 330.79
I0905 16:39:18.613296 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -459.60
INFO:tensorflow:Starting iteration 8

Steps executed: 461 Episode length: 461 Return: -371.3561758331527578
INFO:tensorflow:Average training steps per second: 308.17
I0905 16:39:25.150017 140275076675584 replay_runner.py:36] Average training steps per second: 308.17
I0905 16:39:25.616677 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -371.36
INFO:tensorflow:Starting iteration 9
I0905 16:39:28.798964 140275076675584 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 313.28

Steps executed: 801 Episode length: 801 Return: -454.6198025821785578
I0905 16:39:33.767192 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -454.62
INFO:tensorflow:Starting iteration 10
I0905 16:39:36.991482 140275076675584 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 308.35

Steps executed: 639 Episode length: 639 Return: -365.3616077839323678
I0905 16:39:41.103988 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -365.36
INFO:tensorflow:Starting iteration 11

Steps executed: 261 Episode length: 261 Return: -454.5252078138962678
INFO:tensorflow:Average training steps per second: 314.94
I0905 16:39:47.523350 140275076675584 replay_runner.py:36] Average training steps per second: 314.94
I0905 16:39:47.726450 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -454.53
INFO:tensorflow:Starting iteration 12

Steps executed: 323 Episode length: 323 Return: -165.9786832011290678
INFO:tensorflow:Average training steps per second: 323.39
I0905 16:39:54.136473 140275076675584 replay_runner.py:36] Average training steps per second: 323.39
I0905 16:39:54.397556 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.98
INFO:tensorflow:Starting iteration 13
I0905 16:39:57.724785 140275076675584 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 324.48

Steps executed: 375 Episode length: 375 Return: -369.0568430643332478
I0905 16:40:01.209255 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -369.06
INFO:tensorflow:Starting iteration 14

Steps executed: 364 Episode length: 219 Return: -554.7039610647619478
INFO:tensorflow:Average training steps per second: 299.29
I0905 16:40:07.834917 140275076675584 replay_runner.py:36] Average training steps per second: 299.29
I0905 16:40:08.083355 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -739.30
INFO:tensorflow:Starting iteration 15
I0905 16:40:11.419514 140275076675584 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 324.99

Steps executed: 1000 Episode length: 1000 Return: -89.493829304739628
I0905 16:40:17.185338 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.49
INFO:tensorflow:Starting iteration 16

Steps executed: 403 Episode length: 403 Return: -384.1545036881957528
INFO:tensorflow:Average training steps per second: 331.06
I0905 16:40:23.647156 140275076675584 replay_runner.py:36] Average training steps per second: 331.06
I0905 16:40:24.055284 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -384.15
INFO:tensorflow:Starting iteration 17

Steps executed: 300 Episode length: 300 Return: -339.0498322399745328
INFO:tensorflow:Average training steps per second: 324.87
I0905 16:40:30.484651 140275076675584 replay_runner.py:36] Average training steps per second: 324.87
I0905 16:40:30.748428 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -339.05
INFO:tensorflow:Starting iteration 18

Steps executed: 202 Episode length: 202 Return: -327.8761441616846328
INFO:tensorflow:Average training steps per second: 325.32
I0905 16:40:37.232965 140275076675584 replay_runner.py:36] Average training steps per second: 325.32
I0905 16:40:37.366934 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.88
INFO:tensorflow:Starting iteration 19

Steps executed: 158 Episode length: 158 Return: -289.1717104457846328
INFO:tensorflow:Average training steps per second: 338.07

Steps executed: 1158 Episode length: 1000 Return: -148.48255428540118
I0905 16:40:45.995579 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.83
INFO:tensorflow:Starting iteration 20

Steps executed: 237 Episode length: 237 Return: -161.0621205619620118
INFO:tensorflow:Average training steps per second: 315.17
I0905 16:40:52.430891 140275076675584 replay_runner.py:36] Average training steps per second: 315.17
I0905 16:40:52.631381 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.06
INFO:tensorflow:Starting iteration 21
I0905 16:40:55.912087 140275076675584 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 305.44
I0905 16:40:59.186365 140275076675584 replay_runner.py:36] Average training steps per second: 305.44

Steps executed: 1000 Episode length: 1000 Return: -150.07599259361868
INFO:tensorflow:Starting iteration 22

Steps executed: 184 Episode length: 184 Return: 44.037312204388286868
INFO:tensorflow:Average training steps per second: 312.20
I0905 16:41:07.399565 140275076675584 replay_runner.py:36] Average training steps per second: 312.20

Steps executed: 949 Episode length: 765 Return: -542.1225750146698868
INFO:tensorflow:Starting iteration 23

Steps executed: 315 Episode length: 315 Return: -393.4017270581648868
INFO:tensorflow:Average training steps per second: 310.16
I0905 16:41:15.754625 140275076675584 replay_runner.py:36] Average training steps per second: 310.16
I0905 16:41:16.059162 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -393.40
INFO:tensorflow:Starting iteration 24

Steps executed: 295 Episode length: 295 Return: -170.6961107920228468
INFO:tensorflow:Average training steps per second: 319.94
I0905 16:41:22.511366 140275076675584 replay_runner.py:36] Average training steps per second: 319.94
I0905 16:41:22.760015 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.70
INFO:tensorflow:Starting iteration 25
I0905 16:41:26.146539 140275076675584 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 331.56

Steps executed: 1000 Episode length: 1000 Return: -89.498626710398148
I0905 16:41:31.819631 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.50
INFO:tensorflow:Starting iteration 26
I0905 16:41:35.157210 140275076675584 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 329.00

Steps executed: 1000 Episode length: 1000 Return: -25.708763263042038
I0905 16:41:41.139543 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -25.71
INFO:tensorflow:Starting iteration 27
I0905 16:41:44.630312 140275076675584 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 306.88

Steps executed: 1000 Episode length: 1000 Return: 18.6011902101363878
I0905 16:41:50.363757 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: 18.60
INFO:tensorflow:Starting iteration 28
I0905 16:41:54.167574 140275076675584 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 339.73

Steps executed: 213 Episode length: 213 Return: -346.6479912613840578
I0905 16:41:57.230522 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.65
INFO:tensorflow:Starting iteration 29

Steps executed: 204 Episode length: 204 Return: -222.1996920081118778
INFO:tensorflow:Average training steps per second: 298.04
I0905 16:42:04.409214 140275076675584 replay_runner.py:36] Average training steps per second: 298.04

Done fixed training!Episode length: 204 Return: -222.1996920081118778