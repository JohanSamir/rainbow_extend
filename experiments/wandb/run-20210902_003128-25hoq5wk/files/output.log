Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0902 00:31:34.002239 139929824643072 run_experiment.py:549] Creating TrainRunner ...
I0902 00:31:34.009774 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:31:34.009896 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:31:34.009970 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:31:34.010032 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:31:34.010088 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0902 00:31:34.010179 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:31:34.010263 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:31:34.010360 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:31:34.010471 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:31:34.010603 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0902 00:31:34.010738 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:31:34.010821 139929824643072 dqn_agent.py:283] 	 seed: 1630542694009742
I0902 00:31:34.013375 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:31:34.013523 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:31:34.013652 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:31:34.013728 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:31:34.013817 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:31:34.013874 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:31:34.013929 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:31:34.013981 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:31:34.014080 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:31:34.040527 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:31:34.300819 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:31:34.309592 139929824643072 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:31:34.316568 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:31:34.316711 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:31:34.316785 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:31:34.316867 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:31:34.316924 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0902 00:31:34.316978 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:31:34.317061 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:31:34.317136 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:31:34.317233 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:31:34.317307 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0902 00:31:34.317385 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:31:34.317454 139929824643072 dqn_agent.py:283] 	 seed: 1630542694316538
I0902 00:31:34.318844 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:31:34.318955 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:31:34.319025 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:31:34.319105 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:31:34.319161 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:31:34.319248 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:31:34.319347 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:31:34.319397 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:31:34.319460 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:31:34.342230 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:31:34.358143 139929824643072 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:31:34.358327 139929824643072 replay_runner.py:41] Starting iteration 0
Steps executed: 387 Episode length: 242 Return: -580.0784547331205
INFO:tensorflow:Average training steps per second: 256.86
I0902 00:31:38.251738 139929824643072 replay_runner.py:36] Average training steps per second: 256.86
I0902 00:31:39.238250 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -545.48
INFO:tensorflow:Starting iteration 1

Steps executed: 117 Episode length: 117 Return: -332.3044682776981
INFO:tensorflow:Average training steps per second: 354.76

Steps executed: 260 Episode length: 143 Return: -421.35905504370265
I0902 00:31:45.666253 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -376.83
INFO:tensorflow:Starting iteration 2

Steps executed: 239 Episode length: 126 Return: -457.28749060321013
INFO:tensorflow:Average training steps per second: 345.39
I0902 00:31:52.004222 139929824643072 replay_runner.py:36] Average training steps per second: 345.39
I0902 00:31:52.161942 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -466.90
INFO:tensorflow:Starting iteration 3
I0902 00:31:55.549736 139929824643072 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 337.08
I0902 00:31:58.516697 139929824643072 replay_runner.py:36] Average training steps per second: 337.08

Steps executed: 203 Episode length: 203 Return: -331.40568655161363
INFO:tensorflow:Starting iteration 4

Steps executed: 402 Episode length: 279 Return: -409.49938514485727
INFO:tensorflow:Average training steps per second: 343.43
I0902 00:32:04.883526 139929824643072 replay_runner.py:36] Average training steps per second: 343.43
I0902 00:32:05.171041 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -298.77
INFO:tensorflow:Starting iteration 5

Steps executed: 316 Episode length: 174 Return: -213.48239380968369
INFO:tensorflow:Average training steps per second: 363.92
I0902 00:32:11.300287 139929824643072 replay_runner.py:36] Average training steps per second: 363.92
I0902 00:32:11.538424 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.67
INFO:tensorflow:Starting iteration 6
I0902 00:32:15.044193 139929824643072 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 397.00

Steps executed: 294 Episode length: 294 Return: -447.16862397451246
I0902 00:32:17.845138 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -447.17
INFO:tensorflow:Starting iteration 7

Steps executed: 266 Episode length: 266 Return: -147.24949851593546
INFO:tensorflow:Average training steps per second: 367.60
I0902 00:32:24.118626 139929824643072 replay_runner.py:36] Average training steps per second: 367.60
I0902 00:32:24.319680 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.25
INFO:tensorflow:Starting iteration 8

Steps executed: 616 Episode length: 459 Return: -223.56417487189378
INFO:tensorflow:Average training steps per second: 345.01
I0902 00:32:30.626375 139929824643072 replay_runner.py:36] Average training steps per second: 345.01
I0902 00:32:31.172971 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.37
INFO:tensorflow:Starting iteration 9
I0902 00:32:34.569828 139929824643072 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 345.12

Steps executed: 1000 Episode length: 1000 Return: -259.8622475146896
I0902 00:32:38.799635 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.86
INFO:tensorflow:Starting iteration 10
I0902 00:32:42.245393 139929824643072 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 335.23

Steps executed: 918 Episode length: 918 Return: -362.075374614242296
I0902 00:32:46.570902 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -362.08
INFO:tensorflow:Starting iteration 11
I0902 00:32:49.983019 139929824643072 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 334.43

Steps executed: 1000 Episode length: 1000 Return: -165.28983664395187
I0902 00:32:54.442687 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.29
INFO:tensorflow:Starting iteration 12

Steps executed: 269 Episode length: 138 Return: -253.9042632972929487
INFO:tensorflow:Average training steps per second: 336.90
I0902 00:33:00.842782 139929824643072 replay_runner.py:36] Average training steps per second: 336.90
I0902 00:33:01.021126 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -286.37
INFO:tensorflow:Starting iteration 13
I0902 00:33:04.505338 139929824643072 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 354.89

Steps executed: 1000 Episode length: 1000 Return: -213.49147533287095
I0902 00:33:09.271944 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.49
INFO:tensorflow:Starting iteration 14
I0902 00:33:12.629350 139929824643072 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 338.14

Steps executed: 1000 Episode length: 1000 Return: -139.26152828218395
I0902 00:33:17.453212 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.26
INFO:tensorflow:Starting iteration 15

Steps executed: 337 Episode length: 337 Return: -124.6601847042505895
INFO:tensorflow:Average training steps per second: 331.44
I0902 00:33:23.870317 139929824643072 replay_runner.py:36] Average training steps per second: 331.44
I0902 00:33:24.224813 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.66
INFO:tensorflow:Starting iteration 16

Steps executed: 775 Episode length: 580 Return: -231.1998260232724895
INFO:tensorflow:Average training steps per second: 329.84
I0902 00:33:30.628265 139929824643072 replay_runner.py:36] Average training steps per second: 329.84
I0902 00:33:31.599241 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.86
INFO:tensorflow:Starting iteration 17
I0902 00:33:34.977003 139929824643072 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 332.98

Steps executed: 867 Episode length: 867 Return: -356.7461358149493895
I0902 00:33:39.483972 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -356.75
INFO:tensorflow:Starting iteration 18
I0902 00:33:42.935654 139929824643072 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 334.74
I0902 00:33:45.923369 139929824643072 replay_runner.py:36] Average training steps per second: 334.74

Steps executed: 270 Episode length: 130 Return: -391.3860136509753795
INFO:tensorflow:Starting iteration 19

Steps executed: 527 Episode length: 344 Return: -211.0493317783438895
INFO:tensorflow:Average training steps per second: 341.55
I0902 00:33:52.486630 139929824643072 replay_runner.py:36] Average training steps per second: 341.55
I0902 00:33:52.887960 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.00
INFO:tensorflow:Starting iteration 20

Steps executed: 271 Episode length: 171 Return: 1.7368811004027551895
INFO:tensorflow:Average training steps per second: 346.85
I0902 00:33:59.241795 139929824643072 replay_runner.py:36] Average training steps per second: 346.85
I0902 00:33:59.443027 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.46
INFO:tensorflow:Starting iteration 21

Steps executed: 272 Episode length: 91 Return: -61.024662328796134895
INFO:tensorflow:Average training steps per second: 343.33
I0902 00:34:05.795408 139929824643072 replay_runner.py:36] Average training steps per second: 343.33
I0902 00:34:05.960526 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.00
INFO:tensorflow:Starting iteration 22
I0902 00:34:09.394944 139929824643072 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 360.83
I0902 00:34:12.166611 139929824643072 replay_runner.py:36] Average training steps per second: 360.83

Steps executed: 289 Episode length: 106 Return: -201.2782665411113895
INFO:tensorflow:Starting iteration 23

Steps executed: 213 Episode length: 213 Return: -341.0314381163226595
INFO:tensorflow:Average training steps per second: 352.42
I0902 00:34:18.632757 139929824643072 replay_runner.py:36] Average training steps per second: 352.42
I0902 00:34:18.783679 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.03
INFO:tensorflow:Starting iteration 24

Steps executed: 295 Episode length: 295 Return: -642.6877134422218595
INFO:tensorflow:Average training steps per second: 343.81
I0902 00:34:25.080683 139929824643072 replay_runner.py:36] Average training steps per second: 343.81
I0902 00:34:25.294065 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -642.69
INFO:tensorflow:Starting iteration 25

Steps executed: 366 Episode length: 366 Return: -733.3313805103925595
INFO:tensorflow:Average training steps per second: 339.82
I0902 00:34:31.552539 139929824643072 replay_runner.py:36] Average training steps per second: 339.82
I0902 00:34:31.920274 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -733.33
INFO:tensorflow:Starting iteration 26


Steps executed: 406 Episode length: 218 Return: -136.4687071322884595
INFO:tensorflow:Average training steps per second: 354.33
I0902 00:34:38.130227 139929824643072 replay_runner.py:36] Average training steps per second: 354.33
I0902 00:34:38.351983 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.26
INFO:tensorflow:Starting iteration 27

Steps executed: 202 Episode length: 202 Return: -219.2041512655640695
INFO:tensorflow:Average training steps per second: 356.57
I0902 00:34:44.467911 139929824643072 replay_runner.py:36] Average training steps per second: 356.57
I0902 00:34:44.587941 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -219.20
INFO:tensorflow:Starting iteration 28

Steps executed: 339 Episode length: 177 Return: -156.3760634645457395
INFO:tensorflow:Average training steps per second: 363.89
I0902 00:34:50.447174 139929824643072 replay_runner.py:36] Average training steps per second: 363.89
I0902 00:34:50.692701 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.61
INFO:tensorflow:Starting iteration 29

Steps executed: 324 Episode length: 166 Return: -705.7615902426281395
INFO:tensorflow:Average training steps per second: 359.98
I0902 00:34:56.861833 139929824643072 replay_runner.py:36] Average training steps per second: 359.98

Done fixed training!Episode length: 166 Return: -705.7615902426281395