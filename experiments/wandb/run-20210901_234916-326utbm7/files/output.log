I0901 23:49:22.593857 140413705484288 run_experiment.py:549] Creating TrainRunner ...
I0901 23:49:22.604151 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:22.604328 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:22.604428 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:22.604495 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:22.604553 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:22.604647 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:22.604757 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:22.604817 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:22.604868 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:22.604931 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:22.605018 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:22.605098 140413705484288 dqn_agent.py:283] 	 seed: 1630540162604104
I0901 23:49:22.607634 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:22.607878 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:22.607994 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:22.608110 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:22.608462 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:22.608592 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:22.608744 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:22.608877 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:22.610311 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 23:49:24.606411 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:24.986631 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:24.998308 140413705484288 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:49:25.007373 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:25.007684 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:25.007811 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:25.007907 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:25.008050 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:25.008207 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:25.008295 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:25.008432 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:25.008524 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:25.008625 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:25.008728 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:25.008798 140413705484288 dqn_agent.py:283] 	 seed: 1630540165007314
I0901 23:49:25.010952 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:25.011080 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:25.011150 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:25.011220 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:25.011283 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:25.011375 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:25.011489 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:25.011566 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:25.011629 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:49:25.042323 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:25.262175 140413705484288 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:49:25.262411 140413705484288 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 167.03
I0901 23:49:31.250168 140413705484288 replay_runner.py:36] Average training steps per second: 167.03
Steps executed: 322 Episode length: 167 Return: -357.6387184540392
I0901 23:49:32.607021 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -384.50
INFO:tensorflow:Starting iteration 1

Steps executed: 410 Episode length: 270 Return: -300.88969128988748
INFO:tensorflow:Average training steps per second: 228.99
I0901 23:49:41.424686 140413705484288 replay_runner.py:36] Average training steps per second: 228.99
I0901 23:49:41.851276 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.16
INFO:tensorflow:Starting iteration 2

Steps executed: 501 Episode length: 345 Return: -136.51588817147036
INFO:tensorflow:Average training steps per second: 224.71
I0901 23:49:50.716387 140413705484288 replay_runner.py:36] Average training steps per second: 224.71
I0901 23:49:51.280196 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.09
INFO:tensorflow:Starting iteration 3
I0901 23:49:55.595628 140413705484288 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 232.44

Steps executed: 1000 Episode length: 1000 Return: -98.12275417464404
I0901 23:50:02.861340 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.12
INFO:tensorflow:Starting iteration 4

Steps executed: 160 Episode length: 160 Return: -84.0931895033577204
INFO:tensorflow:Average training steps per second: 237.43

Steps executed: 1160 Episode length: 1000 Return: -188.62501649061957
I0901 23:50:13.927949 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.36
INFO:tensorflow:Starting iteration 5
I0901 23:50:18.297966 140413705484288 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 234.40

Steps executed: 1000 Episode length: 1000 Return: -134.65979844796697
I0901 23:50:26.474153 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.66
INFO:tensorflow:Starting iteration 6
I0901 23:50:30.780729 140413705484288 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 237.81

Steps executed: 1000 Episode length: 1000 Return: -70.498191844482257
I0901 23:50:37.627676 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.50
INFO:tensorflow:Starting iteration 7
I0901 23:50:41.665645 140413705484288 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 234.64

Steps executed: 638 Episode length: 638 Return: -258.3472494806761757
I0901 23:50:47.717178 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.35
INFO:tensorflow:Starting iteration 8
I0901 23:50:51.941687 140413705484288 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 241.99

Steps executed: 970 Episode length: 970 Return: -481.5032139115936657
I0901 23:50:59.030464 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -481.50
INFO:tensorflow:Starting iteration 9
I0901 23:51:03.334338 140413705484288 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 240.47

Steps executed: 1000 Episode length: 1000 Return: -116.96126417900601
I0901 23:51:10.752606 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.96
INFO:tensorflow:Starting iteration 10
I0901 23:51:15.057126 140413705484288 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 231.09

Steps executed: 1000 Episode length: 1000 Return: -223.72478292854916
I0901 23:51:22.082734 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.72
INFO:tensorflow:Starting iteration 11
I0901 23:51:26.444909 140413705484288 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 223.93

Steps executed: 929 Episode length: 929 Return: -349.5606654967340316
I0901 23:51:34.264412 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -349.56
INFO:tensorflow:Starting iteration 12
I0901 23:51:38.585104 140413705484288 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 226.11

Steps executed: 1000 Episode length: 1000 Return: -182.95115172888616
I0901 23:51:46.426115 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.95
INFO:tensorflow:Starting iteration 13
I0901 23:51:50.687551 140413705484288 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 230.22

Steps executed: 1000 Episode length: 1000 Return: -165.86738864514996
I0901 23:51:57.844325 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.87
INFO:tensorflow:Starting iteration 14
I0901 23:52:02.206695 140413705484288 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 232.35

Steps executed: 1000 Episode length: 1000 Return: -76.803151422498236
I0901 23:52:09.764460 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.80
INFO:tensorflow:Starting iteration 15
I0901 23:52:14.141012 140413705484288 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 230.75

Steps executed: 1000 Episode length: 1000 Return: -122.14548818454082
I0901 23:52:23.440298 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.15
INFO:tensorflow:Starting iteration 16

Steps executed: 147 Episode length: 147 Return: -876.8197358746238082
INFO:tensorflow:Average training steps per second: 223.93
I0901 23:52:32.243638 140413705484288 replay_runner.py:36] Average training steps per second: 223.93

Steps executed: 625 Episode length: 478 Return: -117.7097406192559782
INFO:tensorflow:Starting iteration 17

Steps executed: 292 Episode length: 174 Return: -70.11040939713456682
INFO:tensorflow:Average training steps per second: 224.87
I0901 23:52:42.054695 140413705484288 replay_runner.py:36] Average training steps per second: 224.87
I0901 23:52:42.351432 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.21
INFO:tensorflow:Starting iteration 18
I0901 23:52:46.748014 140413705484288 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 232.01

Steps executed: 523 Episode length: 380 Return: -330.1123314916262682
I0901 23:52:51.736445 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -413.88
INFO:tensorflow:Starting iteration 19

Steps executed: 302 Episode length: 142 Return: -141.1058448583055582
INFO:tensorflow:Average training steps per second: 226.43
I0901 23:53:00.388485 140413705484288 replay_runner.py:36] Average training steps per second: 226.43
I0901 23:53:00.652333 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.68
INFO:tensorflow:Starting iteration 20

Steps executed: 276 Episode length: 276 Return: -62.45989781073582582
INFO:tensorflow:Average training steps per second: 224.97
I0901 23:53:09.320828 140413705484288 replay_runner.py:36] Average training steps per second: 224.97
I0901 23:53:09.638538 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -62.46
INFO:tensorflow:Starting iteration 21

Steps executed: 293 Episode length: 293 Return: 281.74955224069663582
INFO:tensorflow:Average training steps per second: 218.94
I0901 23:53:18.452660 140413705484288 replay_runner.py:36] Average training steps per second: 218.94
I0901 23:53:18.775537 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: 281.75
INFO:tensorflow:Starting iteration 22

Steps executed: 295 Episode length: 295 Return: -313.5843260393808782
INFO:tensorflow:Average training steps per second: 224.25
I0901 23:53:27.618369 140413705484288 replay_runner.py:36] Average training steps per second: 224.25
I0901 23:53:27.994700 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -313.58
INFO:tensorflow:Starting iteration 23
I0901 23:53:32.302842 140413705484288 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 237.10

Steps executed: 581 Episode length: 581 Return: -319.2827260741949782
I0901 23:53:37.729018 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -319.28
INFO:tensorflow:Starting iteration 24

Steps executed: 444 Episode length: 251 Return: -206.4278226361381782
INFO:tensorflow:Average training steps per second: 240.32
I0901 23:53:46.007490 140413705484288 replay_runner.py:36] Average training steps per second: 240.32
I0901 23:53:46.545362 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.31
INFO:tensorflow:Starting iteration 25
I0901 23:53:50.820699 140413705484288 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 234.24
I0901 23:53:55.090183 140413705484288 replay_runner.py:36] Average training steps per second: 234.24

Steps executed: 298 Episode length: 156 Return: -469.9944752923176682
INFO:tensorflow:Starting iteration 26

Steps executed: 330 Episode length: 330 Return: -54.18282680542875682
INFO:tensorflow:Average training steps per second: 238.16
I0901 23:54:03.802178 140413705484288 replay_runner.py:36] Average training steps per second: 238.16
I0901 23:54:04.240746 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.18
INFO:tensorflow:Starting iteration 27
I0901 23:54:08.556690 140413705484288 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 232.85
I0901 23:54:12.851899 140413705484288 replay_runner.py:36] Average training steps per second: 232.85

Steps executed: 299 Episode length: 299 Return: -16.34689306254388482
INFO:tensorflow:Starting iteration 28
I0901 23:54:17.628919 140413705484288 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 233.91
I0901 23:54:21.904465 140413705484288 replay_runner.py:36] Average training steps per second: 233.91

Steps executed: 568 Episode length: 568 Return: 185.14708720089442482
INFO:tensorflow:Starting iteration 29

Steps executed: 247 Episode length: 247 Return: -395.9715374925933782
INFO:tensorflow:Average training steps per second: 234.51
I0901 23:54:31.798913 140413705484288 replay_runner.py:36] Average training steps per second: 234.51

Done fixed training!Episode length: 247 Return: -395.9715374925933782