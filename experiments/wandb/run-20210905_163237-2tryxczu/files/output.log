I0905 16:32:44.410824 140202555004928 run_experiment.py:549] Creating TrainRunner ...
I0905 16:32:44.451619 140202555004928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:32:44.451925 140202555004928 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:32:44.452645 140202555004928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:32:44.453005 140202555004928 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:32:44.453161 140202555004928 dqn_agent.py:275] 	 update_period: 4
I0905 16:32:44.453283 140202555004928 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:32:44.453390 140202555004928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:32:44.453551 140202555004928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:32:44.454030 140202555004928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:32:44.454306 140202555004928 dqn_agent.py:280] 	 optimizer: adam
I0905 16:32:44.454421 140202555004928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:32:44.454622 140202555004928 dqn_agent.py:283] 	 seed: 1630859564451547
I0905 16:32:44.458015 140202555004928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:32:44.458253 140202555004928 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:32:44.458378 140202555004928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:32:44.458487 140202555004928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:32:44.458671 140202555004928 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:32:44.468494 140202555004928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:32:44.468763 140202555004928 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:32:44.469012 140202555004928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:32:44.469185 140202555004928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:32:47.423920 140202555004928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0905 16:32:48.355163 140202555004928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:32:48.390361 140202555004928 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:32:48.428638 140202555004928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:32:48.430317 140202555004928 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:32:48.431081 140202555004928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:32:48.431582 140202555004928 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:32:48.431920 140202555004928 dqn_agent.py:275] 	 update_period: 4
I0905 16:32:48.432622 140202555004928 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:32:48.432997 140202555004928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:32:48.434077 140202555004928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:32:48.434845 140202555004928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:32:48.435602 140202555004928 dqn_agent.py:280] 	 optimizer: adam
I0905 16:32:48.435942 140202555004928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:32:48.436101 140202555004928 dqn_agent.py:283] 	 seed: 1630859568428554
I0905 16:32:48.443981 140202555004928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:32:48.445331 140202555004928 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:32:48.445826 140202555004928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:32:48.447005 140202555004928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:32:48.447618 140202555004928 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:32:48.447857 140202555004928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:32:48.448636 140202555004928 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:32:48.449279 140202555004928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:32:48.449569 140202555004928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:32:48.508699 140202555004928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:32:48.561518 140202555004928 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:32:48.562518 140202555004928 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 103.87
I0905 16:32:58.191517 140202555004928 replay_runner.py:36] Average training steps per second: 103.87
Steps executed: 245 Episode length: 153 Return: -188.6971234638624
I0905 16:33:00.165014 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -321.83
INFO:tensorflow:Starting iteration 1

Steps executed: 275 Episode length: 108 Return: -362.4229432651789
INFO:tensorflow:Average training steps per second: 171.67
I0905 16:33:10.840296 140202555004928 replay_runner.py:36] Average training steps per second: 171.67
I0905 16:33:11.193785 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -238.80
INFO:tensorflow:Starting iteration 2

Steps executed: 315 Episode length: 315 Return: -213.21801471900693
INFO:tensorflow:Average training steps per second: 159.06
I0905 16:33:22.829385 140202555004928 replay_runner.py:36] Average training steps per second: 159.06
I0905 16:33:23.331621 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.22
INFO:tensorflow:Starting iteration 3

Steps executed: 252 Episode length: 140 Return: -255.59297223772765
INFO:tensorflow:Average training steps per second: 158.89
I0905 16:33:34.965691 140202555004928 replay_runner.py:36] Average training steps per second: 158.89
I0905 16:33:35.267719 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.66
INFO:tensorflow:Starting iteration 4

Steps executed: 252 Episode length: 109 Return: -347.93611009983342
INFO:tensorflow:Average training steps per second: 165.37
I0905 16:33:46.546200 140202555004928 replay_runner.py:36] Average training steps per second: 165.37
I0905 16:33:46.836810 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.35
INFO:tensorflow:Starting iteration 5
I0905 16:33:51.745534 140202555004928 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 185.69

Steps executed: 1000 Episode length: 1000 Return: -151.1143567670893
I0905 16:34:01.680838 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.11
INFO:tensorflow:Starting iteration 6

Steps executed: 448 Episode length: 448 Return: -377.816748623832793
INFO:tensorflow:Average training steps per second: 165.73
I0905 16:34:12.763715 140202555004928 replay_runner.py:36] Average training steps per second: 165.73
I0905 16:34:13.643956 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.82
INFO:tensorflow:Starting iteration 7

Steps executed: 439 Episode length: 439 Return: -258.398678903433493
INFO:tensorflow:Average training steps per second: 170.34
I0905 16:34:24.636049 140202555004928 replay_runner.py:36] Average training steps per second: 170.34
I0905 16:34:25.522467 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.40
INFO:tensorflow:Starting iteration 8
I0905 16:34:29.155799 140202555004928 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 159.37
I0905 16:34:35.431535 140202555004928 replay_runner.py:36] Average training steps per second: 159.37

Steps executed: 403 Episode length: 403 Return: -196.908024626560633
INFO:tensorflow:Starting iteration 9

Steps executed: 259 Episode length: 146 Return: -139.040574370261963
INFO:tensorflow:Average training steps per second: 164.25
I0905 16:34:47.568526 140202555004928 replay_runner.py:36] Average training steps per second: 164.25
I0905 16:34:47.946632 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.72
INFO:tensorflow:Starting iteration 10
I0905 16:34:53.170873 140202555004928 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 175.78

Steps executed: 741 Episode length: 741 Return: -2321.21932645007253
I0905 16:35:01.137987 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -2321.22
INFO:tensorflow:Starting iteration 11

Steps executed: 280 Episode length: 280 Return: -153.884163709302023
INFO:tensorflow:Average training steps per second: 161.61
I0905 16:35:12.457552 140202555004928 replay_runner.py:36] Average training steps per second: 161.61
I0905 16:35:12.941394 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.88
INFO:tensorflow:Starting iteration 12
I0905 16:35:18.158065 140202555004928 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 164.26

Steps executed: 671 Episode length: 528 Return: -384.228567264418263
I0905 16:35:25.617211 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -336.45
INFO:tensorflow:Starting iteration 13
I0905 16:35:30.250078 140202555004928 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 165.87

Steps executed: 606 Episode length: 606 Return: -726.263509835882263
I0905 16:35:37.519202 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -726.26
INFO:tensorflow:Starting iteration 14
I0905 16:35:41.977551 140202555004928 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 161.61

Steps executed: 249 Episode length: 249 Return: -111.248672517164343
I0905 16:35:48.522883 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.25
INFO:tensorflow:Starting iteration 15
I0905 16:35:53.260477 140202555004928 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 192.51

Steps executed: 383 Episode length: 383 Return: -334.891291526417743
I0905 16:35:59.161900 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -334.89
INFO:tensorflow:Starting iteration 16

Steps executed: 277 Episode length: 143 Return: -455.379692369138863
INFO:tensorflow:Average training steps per second: 193.15
I0905 16:36:09.127363 140202555004928 replay_runner.py:36] Average training steps per second: 193.15
I0905 16:36:09.421901 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -442.79
INFO:tensorflow:Starting iteration 17

Steps executed: 357 Episode length: 185 Return: -664.521563204621833
INFO:tensorflow:Average training steps per second: 211.12
I0905 16:36:18.799607 140202555004928 replay_runner.py:36] Average training steps per second: 211.12
I0905 16:36:19.145276 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -490.59
INFO:tensorflow:Starting iteration 18

Steps executed: 241 Episode length: 128 Return: -355.219478444380343
INFO:tensorflow:Average training steps per second: 256.94
I0905 16:36:27.473614 140202555004928 replay_runner.py:36] Average training steps per second: 256.94
I0905 16:36:27.638355 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -356.29
INFO:tensorflow:Starting iteration 19

Steps executed: 275 Episode length: 150 Return: -336.197517632668453
INFO:tensorflow:Average training steps per second: 294.54
I0905 16:36:34.907899 140202555004928 replay_runner.py:36] Average training steps per second: 294.54
I0905 16:36:35.096431 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -409.86
INFO:tensorflow:Starting iteration 20

Steps executed: 233 Episode length: 233 Return: -336.995824898962273
INFO:tensorflow:Average training steps per second: 389.58
I0905 16:36:40.844439 140202555004928 replay_runner.py:36] Average training steps per second: 389.58
I0905 16:36:40.981974 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -337.00
INFO:tensorflow:Starting iteration 21
I0905 16:36:44.038683 140202555004928 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 385.98

Steps executed: 207 Episode length: 60 Return: -268.4456167334194873
I0905 16:36:46.742753 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.88
INFO:tensorflow:Starting iteration 22

Steps executed: 300 Episode length: 300 Return: -229.516303970625933
INFO:tensorflow:Average training steps per second: 409.96
I0905 16:36:52.259078 140202555004928 replay_runner.py:36] Average training steps per second: 409.96
I0905 16:36:52.510035 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.52
INFO:tensorflow:Starting iteration 23
I0905 16:36:55.613730 140202555004928 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 404.14
I0905 16:36:58.088462 140202555004928 replay_runner.py:36] Average training steps per second: 404.14

Steps executed: 479 Episode length: 479 Return: -139.289717311421013
INFO:tensorflow:Starting iteration 24
I0905 16:37:01.796481 140202555004928 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 398.15

Steps executed: 1000 Episode length: 1000 Return: -8.019853402195423
I0905 16:37:06.183095 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -8.02
INFO:tensorflow:Starting iteration 25
I0905 16:37:09.301057 140202555004928 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 387.98

Steps executed: 1000 Episode length: 1000 Return: -33.722100511746966
I0905 16:37:13.634746 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -33.72
INFO:tensorflow:Starting iteration 26

Steps executed: 258 Episode length: 258 Return: -61.53957893703216966
INFO:tensorflow:Average training steps per second: 400.70
I0905 16:37:19.258907 140202555004928 replay_runner.py:36] Average training steps per second: 400.70
I0905 16:37:19.458794 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.54
INFO:tensorflow:Starting iteration 27
I0905 16:37:22.598945 140202555004928 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 407.93

Steps executed: 1000 Episode length: 1000 Return: -30.026365210724226
I0905 16:37:27.345145 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -30.03
INFO:tensorflow:Starting iteration 28

Steps executed: 1171 Episode length: 1000 Return: -29.050813808067627
INFO:tensorflow:Average training steps per second: 406.36
I0905 16:37:32.997458 140202555004928 replay_runner.py:36] Average training steps per second: 406.36
I0905 16:37:34.739117 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.38
INFO:tensorflow:Starting iteration 29

Steps executed: 357 Episode length: 357 Return: -232.9977400324689527
INFO:tensorflow:Average training steps per second: 410.65
I0905 16:37:40.361446 140202555004928 replay_runner.py:36] Average training steps per second: 410.65

Done fixed training!Episode length: 357 Return: -232.9977400324689527