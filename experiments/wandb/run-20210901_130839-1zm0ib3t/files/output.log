I0901 13:08:45.689229 140536266098688 run_experiment.py:549] Creating TrainRunner ...
I0901 13:08:45.696227 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:08:45.696346 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:08:45.696419 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:08:45.696481 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:08:45.696541 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 13:08:45.696612 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:08:45.696672 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:08:45.696757 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:08:45.696825 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:08:45.696889 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 13:08:45.696963 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:08:45.697034 140536266098688 dqn_agent.py:283] 	 seed: 1630501725696197
I0901 13:08:45.698765 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:08:45.698877 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:08:45.698940 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:08:45.699032 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:08:45.699090 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:08:45.699146 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:08:45.699198 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:08:45.699275 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:08:45.699358 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:08:45.789438 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:46.022522 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:46.030910 140536266098688 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:08:46.037996 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:08:46.038139 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:08:46.038208 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:08:46.038266 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:08:46.038318 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 13:08:46.038391 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:08:46.038475 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:08:46.038566 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:08:46.038630 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:08:46.038693 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 13:08:46.038762 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:08:46.038827 140536266098688 dqn_agent.py:283] 	 seed: 1630501726037968
I0901 13:08:46.040146 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:08:46.040257 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:08:46.040326 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:08:46.040387 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:08:46.040441 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:08:46.040510 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:08:46.040595 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:08:46.040671 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:08:46.040756 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:08:46.060266 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:46.075098 140536266098688 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:08:46.075240 140536266098688 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 243.55
I0901 13:08:50.181333 140536266098688 replay_runner.py:36] Average training steps per second: 243.55
I0901 13:08:51.060265 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -588.77
Steps executed: 230 Episode length: 136 Return: -449.4341035020467
INFO:tensorflow:Starting iteration 1

Steps executed: 256 Episode length: 107 Return: -324.30312672732884
INFO:tensorflow:Average training steps per second: 326.13
I0901 13:08:57.404421 140536266098688 replay_runner.py:36] Average training steps per second: 326.13
I0901 13:08:57.543905 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -298.05
INFO:tensorflow:Starting iteration 2
I0901 13:09:00.801696 140536266098688 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 316.68
I0901 13:09:03.960451 140536266098688 replay_runner.py:36] Average training steps per second: 316.68

Steps executed: 246 Episode length: 81 Return: -302.766055961811054
INFO:tensorflow:Starting iteration 3

Steps executed: 264 Episode length: 91 Return: -697.683498625133254
INFO:tensorflow:Average training steps per second: 329.78
I0901 13:09:10.497480 140536266098688 replay_runner.py:36] Average training steps per second: 329.78
I0901 13:09:10.666786 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -534.63
INFO:tensorflow:Starting iteration 4

Steps executed: 244 Episode length: 122 Return: -418.02176217466246
INFO:tensorflow:Average training steps per second: 327.03
I0901 13:09:17.119820 140536266098688 replay_runner.py:36] Average training steps per second: 327.03
I0901 13:09:17.267117 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -393.90
INFO:tensorflow:Starting iteration 5

Steps executed: 207 Episode length: 123 Return: -50.388816438872516
INFO:tensorflow:Average training steps per second: 283.31
I0901 13:09:24.206638 140536266098688 replay_runner.py:36] Average training steps per second: 283.31
I0901 13:09:24.321178 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.47
INFO:tensorflow:Starting iteration 6

Steps executed: 235 Episode length: 110 Return: -405.53397257397226
INFO:tensorflow:Average training steps per second: 324.73
I0901 13:09:30.809835 140536266098688 replay_runner.py:36] Average training steps per second: 324.73
I0901 13:09:30.941494 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.42
INFO:tensorflow:Starting iteration 7

Steps executed: 251 Episode length: 129 Return: -33.921041109301626
INFO:tensorflow:Average training steps per second: 332.12
I0901 13:09:37.366360 140536266098688 replay_runner.py:36] Average training steps per second: 332.12
I0901 13:09:37.507984 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -59.61
INFO:tensorflow:Starting iteration 8
I0901 13:09:40.925560 140536266098688 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 342.75

Steps executed: 246 Episode length: 128 Return: 11.4953252474130786
I0901 13:09:43.997496 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.19
INFO:tensorflow:Starting iteration 9

Steps executed: 264 Episode length: 145 Return: -7.5851204966503766
INFO:tensorflow:Average training steps per second: 336.96
I0901 13:09:50.414654 140536266098688 replay_runner.py:36] Average training steps per second: 336.96
I0901 13:09:50.599884 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -13.23
INFO:tensorflow:Starting iteration 10

Steps executed: 277 Episode length: 140 Return: -117.03250191774251
INFO:tensorflow:Average training steps per second: 337.15
I0901 13:09:56.995286 140536266098688 replay_runner.py:36] Average training steps per second: 337.15
I0901 13:09:57.157970 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.69
INFO:tensorflow:Starting iteration 11

Steps executed: 256 Episode length: 120 Return: -99.504752500391433
INFO:tensorflow:Average training steps per second: 338.47
I0901 13:10:03.525960 140536266098688 replay_runner.py:36] Average training steps per second: 338.47
I0901 13:10:03.688770 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.72
INFO:tensorflow:Starting iteration 12

Steps executed: 363 Episode length: 243 Return: 146.733312904904073
INFO:tensorflow:Average training steps per second: 342.06
I0901 13:10:10.075407 140536266098688 replay_runner.py:36] Average training steps per second: 342.06
I0901 13:10:10.350634 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: 51.97
INFO:tensorflow:Starting iteration 13

Steps executed: 611 Episode length: 611 Return: 195.846000219837783
INFO:tensorflow:Average training steps per second: 347.89
I0901 13:10:16.590066 140536266098688 replay_runner.py:36] Average training steps per second: 347.89
I0901 13:10:17.497622 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: 195.85
INFO:tensorflow:Starting iteration 14
I0901 13:10:20.849938 140536266098688 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 335.45

Steps executed: 1000 Episode length: 1000 Return: -55.74041287760257
I0901 13:10:26.205740 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -55.74
INFO:tensorflow:Starting iteration 15

Steps executed: 233 Episode length: 114 Return: -124.464123081020067
INFO:tensorflow:Average training steps per second: 330.38
I0901 13:10:32.613196 140536266098688 replay_runner.py:36] Average training steps per second: 330.38
I0901 13:10:32.734912 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.74
INFO:tensorflow:Starting iteration 16

Steps executed: 204 Episode length: 88 Return: -173.6594554434289567
INFO:tensorflow:Average training steps per second: 314.58
I0901 13:10:39.220322 140536266098688 replay_runner.py:36] Average training steps per second: 314.58
I0901 13:10:39.321659 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.77
INFO:tensorflow:Starting iteration 17
I0901 13:10:42.611238 140536266098688 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 327.64

Steps executed: 450 Episode length: 450 Return: -150.376075087179567
I0901 13:10:46.087612 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -150.38
INFO:tensorflow:Starting iteration 18

Steps executed: 501 Episode length: 384 Return: -184.047658329603187
INFO:tensorflow:Average training steps per second: 333.83
I0901 13:10:52.431634 140536266098688 replay_runner.py:36] Average training steps per second: 333.83
I0901 13:10:52.782238 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.36
INFO:tensorflow:Starting iteration 19

Steps executed: 241 Episode length: 131 Return: -15.4880909519783077
INFO:tensorflow:Average training steps per second: 320.61
I0901 13:10:59.156058 140536266098688 replay_runner.py:36] Average training steps per second: 320.61
I0901 13:10:59.274417 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -39.20
INFO:tensorflow:Starting iteration 20

Steps executed: 189 Episode length: 189 Return: -140.862121386963477
INFO:tensorflow:Average training steps per second: 314.14
I0901 13:11:05.642739 140536266098688 replay_runner.py:36] Average training steps per second: 314.14

Steps executed: 294 Episode length: 105 Return: -74.7174091959694877
INFO:tensorflow:Starting iteration 21

Steps executed: 277 Episode length: 162 Return: -144.940924456530927
INFO:tensorflow:Average training steps per second: 314.39
I0901 13:11:12.066095 140536266098688 replay_runner.py:36] Average training steps per second: 314.39
I0901 13:11:12.237953 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.90
INFO:tensorflow:Starting iteration 22

Steps executed: 216 Episode length: 113 Return: -11.4093634725822287
INFO:tensorflow:Average training steps per second: 324.15
I0901 13:11:18.361496 140536266098688 replay_runner.py:36] Average training steps per second: 324.15
I0901 13:11:18.503978 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -38.79
INFO:tensorflow:Starting iteration 23

Steps executed: 230 Episode length: 107 Return: -127.503010962766867
INFO:tensorflow:Average training steps per second: 341.02
I0901 13:11:24.678531 140536266098688 replay_runner.py:36] Average training steps per second: 341.02
I0901 13:11:24.816246 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.36
INFO:tensorflow:Starting iteration 24

Steps executed: 284 Episode length: 284 Return: -447.162504284009167
INFO:tensorflow:Average training steps per second: 366.60
I0901 13:11:30.752809 140536266098688 replay_runner.py:36] Average training steps per second: 366.60
I0901 13:11:30.982219 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -447.16
INFO:tensorflow:Starting iteration 25
I0901 13:11:34.398187 140536266098688 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 365.87

Steps executed: 1000 Episode length: 1000 Return: -135.80941375052748
I0901 13:11:39.921678 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.81
INFO:tensorflow:Starting iteration 26
I0901 13:11:43.226832 140536266098688 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 355.81

Steps executed: 296 Episode length: 150 Return: -255.5250662807291648
I0901 13:11:46.218682 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.52
INFO:tensorflow:Starting iteration 27

Steps executed: 219 Episode length: 107 Return: -74.70560589801844648
INFO:tensorflow:Average training steps per second: 365.88
I0901 13:11:52.265233 140536266098688 replay_runner.py:36] Average training steps per second: 365.88
I0901 13:11:52.388792 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.22
INFO:tensorflow:Starting iteration 28

Steps executed: 416 Episode length: 416 Return: -109.3238093861192748
INFO:tensorflow:Average training steps per second: 347.11
I0901 13:11:58.684151 140536266098688 replay_runner.py:36] Average training steps per second: 347.11
I0901 13:11:59.111037 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.32
INFO:tensorflow:Starting iteration 29
I0901 13:12:02.478397 140536266098688 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 361.74

Steps executed: 1000 Episode length: 1000 Return: -59.112668869263736

Done fixed training! Episode length: 1000 Return: -59.112668869263736