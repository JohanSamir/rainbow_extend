Loaded trained dqn in cartpole
Training fixed agent 7, please be patient, may be a while...
I0901 12:52:37.844557 140540456830976 run_experiment.py:549] Creating TrainRunner ...
I0901 12:52:37.853958 140540456830976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:52:37.854280 140540456830976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:52:37.854401 140540456830976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:52:37.854546 140540456830976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:52:37.854740 140540456830976 dqn_agent.py:275] 	 update_period: 4
I0901 12:52:37.855275 140540456830976 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:52:37.855536 140540456830976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:52:37.855847 140540456830976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:52:37.856119 140540456830976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:52:37.856226 140540456830976 dqn_agent.py:280] 	 optimizer: adam
I0901 12:52:37.856327 140540456830976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:52:37.856444 140540456830976 dqn_agent.py:283] 	 seed: 1630500757853870
I0901 12:52:37.859955 140540456830976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:52:37.860193 140540456830976 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:52:37.860316 140540456830976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:52:37.860403 140540456830976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:52:37.860491 140540456830976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:52:37.860579 140540456830976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:52:37.860838 140540456830976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:52:37.860991 140540456830976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:52:37.861095 140540456830976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:52:37.907141 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:52:38.445970 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:52:38.458245 140540456830976 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:52:38.466819 140540456830976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:52:38.467050 140540456830976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:52:38.467208 140540456830976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:52:38.467310 140540456830976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:52:38.467401 140540456830976 dqn_agent.py:275] 	 update_period: 4
I0901 12:52:38.467500 140540456830976 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:52:38.467580 140540456830976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:52:38.467662 140540456830976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:52:38.467741 140540456830976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:52:38.467826 140540456830976 dqn_agent.py:280] 	 optimizer: adam
I0901 12:52:38.468003 140540456830976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:52:38.468126 140540456830976 dqn_agent.py:283] 	 seed: 1630500758466768
I0901 12:52:38.470417 140540456830976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:52:38.470590 140540456830976 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:52:38.470694 140540456830976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:52:38.470784 140540456830976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:52:38.470867 140540456830976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:52:38.470947 140540456830976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:52:38.471030 140540456830976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:52:38.471110 140540456830976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:52:38.471214 140540456830976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:52:38.501599 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:52:38.524307 140540456830976 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:52:38.524640 140540456830976 replay_runner.py:41] Starting iteration 0
Steps executed: 200 Episode length: 9 Return: 9.0.0
INFO:tensorflow:Average training steps per second: 140.26
I0901 12:52:45.654727 140540456830976 replay_runner.py:36] Average training steps per second: 140.26
I0901 12:52:46.906394 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 10.53
INFO:tensorflow:Starting iteration 1

Steps executed: 206 Episode length: 11 Return: 11.0
INFO:tensorflow:Average training steps per second: 192.03
I0901 12:52:52.309376 140540456830976 replay_runner.py:36] Average training steps per second: 192.03
I0901 12:52:52.459403 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 10.84
INFO:tensorflow:Starting iteration 2

Steps executed: 212 Episode length: 116 Return: 116.0
INFO:tensorflow:Average training steps per second: 192.19
I0901 12:52:57.856466 140540456830976 replay_runner.py:36] Average training steps per second: 192.19
I0901 12:52:58.004589 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 106.00
INFO:tensorflow:Starting iteration 3

Steps executed: 259 Episode length: 88 Return: 88.0.0
INFO:tensorflow:Average training steps per second: 194.43
I0901 12:53:03.339926 140540456830976 replay_runner.py:36] Average training steps per second: 194.43
I0901 12:53:03.515903 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 86.33
INFO:tensorflow:Starting iteration 4

Steps executed: 263 Episode length: 87 Return: 87.0.0
INFO:tensorflow:Average training steps per second: 191.97
I0901 12:53:08.920098 140540456830976 replay_runner.py:36] Average training steps per second: 191.97
I0901 12:53:09.104617 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 87.67
INFO:tensorflow:Starting iteration 5

Steps executed: 226 Episode length: 105 Return: 105.0
INFO:tensorflow:Average training steps per second: 190.97
I0901 12:53:14.535056 140540456830976 replay_runner.py:36] Average training steps per second: 190.97
I0901 12:53:14.698184 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 113.00
INFO:tensorflow:Starting iteration 6

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 190.58
I0901 12:53:20.141077 140540456830976 replay_runner.py:36] Average training steps per second: 190.58
I0901 12:53:20.283172 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 7
I0901 12:53:20.471743 140540456830976 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 191.16
I0901 12:53:25.703233 140540456830976 replay_runner.py:36] Average training steps per second: 191.16
I0901 12:53:25.851941 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 8

Steps executed: 338 Episode length: 177 Return: 177.0
INFO:tensorflow:Average training steps per second: 189.86
I0901 12:53:31.319129 140540456830976 replay_runner.py:36] Average training steps per second: 189.86
I0901 12:53:31.574239 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 169.00
INFO:tensorflow:Starting iteration 9

Steps executed: 318 Episode length: 151 Return: 151.0
INFO:tensorflow:Average training steps per second: 193.38
I0901 12:53:36.952911 140540456830976 replay_runner.py:36] Average training steps per second: 193.38
I0901 12:53:37.176192 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 159.00
INFO:tensorflow:Starting iteration 10

Steps executed: 312 Episode length: 120 Return: 120.0
INFO:tensorflow:Average training steps per second: 197.68
I0901 12:53:42.423760 140540456830976 replay_runner.py:36] Average training steps per second: 197.68
I0901 12:53:42.650621 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 104.00
INFO:tensorflow:Starting iteration 11
I0901 12:53:42.843262 140540456830976 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 198.79

Steps executed: 255 Episode length: 85 Return: 85.0.0
I0901 12:53:48.052340 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 85.00
INFO:tensorflow:Starting iteration 12

Steps executed: 257 Episode length: 85 Return: 85.0.0
INFO:tensorflow:Average training steps per second: 191.39
I0901 12:53:53.465900 140540456830976 replay_runner.py:36] Average training steps per second: 191.39
I0901 12:53:53.643493 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 85.67
INFO:tensorflow:Starting iteration 13

Steps executed: 251 Episode length: 120 Return: 120.0
INFO:tensorflow:Average training steps per second: 192.27
I0901 12:53:59.029736 140540456830976 replay_runner.py:36] Average training steps per second: 192.27
I0901 12:53:59.201151 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 125.50
INFO:tensorflow:Starting iteration 14

Steps executed: 268 Episode length: 85 Return: 85.0.0
INFO:tensorflow:Average training steps per second: 190.24
I0901 12:54:04.642487 140540456830976 replay_runner.py:36] Average training steps per second: 190.24
I0901 12:54:04.835455 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 89.33
INFO:tensorflow:Starting iteration 15

Steps executed: 205 Episode length: 99 Return: 99.0.0
INFO:tensorflow:Average training steps per second: 190.66
I0901 12:54:10.275498 140540456830976 replay_runner.py:36] Average training steps per second: 190.66
I0901 12:54:10.427382 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 102.50
INFO:tensorflow:Starting iteration 16
I0901 12:54:10.597151 140540456830976 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 192.56
I0901 12:54:15.790590 140540456830976 replay_runner.py:36] Average training steps per second: 192.56
I0901 12:54:15.930876 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 17


Steps executed: 378 Episode length: 195 Return: 195.0
INFO:tensorflow:Average training steps per second: 189.42
I0901 12:54:21.390384 140540456830976 replay_runner.py:36] Average training steps per second: 189.42
I0901 12:54:21.648582 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 189.00
INFO:tensorflow:Starting iteration 18

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 193.31
I0901 12:54:26.994481 140540456830976 replay_runner.py:36] Average training steps per second: 193.31
I0901 12:54:27.138951 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 19

Steps executed: 261 Episode length: 138 Return: 138.0
INFO:tensorflow:Average training steps per second: 187.96
I0901 12:54:32.648221 140540456830976 replay_runner.py:36] Average training steps per second: 187.96
I0901 12:54:32.826146 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 130.50
INFO:tensorflow:Starting iteration 20

Steps executed: 261 Episode length: 130 Return: 130.0
INFO:tensorflow:Average training steps per second: 191.55
I0901 12:54:38.239607 140540456830976 replay_runner.py:36] Average training steps per second: 191.55
I0901 12:54:38.434063 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 130.50
INFO:tensorflow:Starting iteration 21

Steps executed: 134 Episode length: 134 Return: 134.0
INFO:tensorflow:Average training steps per second: 191.81

Steps executed: 265 Episode length: 131 Return: 131.0
I0901 12:54:44.028877 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 132.50
INFO:tensorflow:Starting iteration 22

Steps executed: 301 Episode length: 149 Return: 149.0
INFO:tensorflow:Average training steps per second: 193.65
I0901 12:54:49.387384 140540456830976 replay_runner.py:36] Average training steps per second: 193.65
I0901 12:54:49.604979 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 150.50
INFO:tensorflow:Starting iteration 23

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 194.46
I0901 12:54:54.937736 140540456830976 replay_runner.py:36] Average training steps per second: 194.46
I0901 12:54:55.078279 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 24
I0901 12:54:55.268683 140540456830976 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 192.60
I0901 12:55:00.461083 140540456830976 replay_runner.py:36] Average training steps per second: 192.60
I0901 12:55:00.611117 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 25
I0901 12:55:00.809631 140540456830976 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 187.59
I0901 12:55:06.140750 140540456830976 replay_runner.py:36] Average training steps per second: 187.59
I0901 12:55:06.285689 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26

Steps executed: 342 Episode length: 173 Return: 173.0
INFO:tensorflow:Average training steps per second: 194.32
I0901 12:55:11.609785 140540456830976 replay_runner.py:36] Average training steps per second: 194.32
I0901 12:55:11.857769 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 171.00
INFO:tensorflow:Starting iteration 27

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 185.83
I0901 12:55:17.442514 140540456830976 replay_runner.py:36] Average training steps per second: 185.83
I0901 12:55:17.584985 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 28
I0901 12:55:17.770286 140540456830976 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 199.77
I0901 12:55:22.776341 140540456830976 replay_runner.py:36] Average training steps per second: 199.77
I0901 12:55:22.911811 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 29
I0901 12:55:23.098242 140540456830976 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 200.00
I0901 12:55:28.098695 140540456830976 replay_runner.py:36] Average training steps per second: 200.00

Done fixed training!Episode length: 200 Return: 200.0