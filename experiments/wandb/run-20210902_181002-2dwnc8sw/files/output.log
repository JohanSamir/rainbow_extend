Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0902 18:10:08.914948 140216164177920 run_experiment.py:549] Creating TrainRunner ...
I0902 18:10:08.926270 140216164177920 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:10:08.926566 140216164177920 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:10:08.926701 140216164177920 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:10:08.927149 140216164177920 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:10:08.927313 140216164177920 dqn_agent.py:275] 	 update_period: 4
I0902 18:10:08.927440 140216164177920 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:10:08.927661 140216164177920 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:10:08.927800 140216164177920 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:10:08.927931 140216164177920 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:10:08.928052 140216164177920 dqn_agent.py:280] 	 optimizer: adam
I0902 18:10:08.928192 140216164177920 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:10:08.928350 140216164177920 dqn_agent.py:283] 	 seed: 1630606208926204
I0902 18:10:08.931567 140216164177920 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:10:08.931744 140216164177920 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:10:08.931918 140216164177920 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:10:08.932085 140216164177920 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:10:08.932233 140216164177920 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:10:08.932390 140216164177920 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:10:08.932520 140216164177920 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:10:08.932639 140216164177920 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:10:08.932753 140216164177920 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:10:08.971377 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.031250
I0902 18:10:09.361449 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.031250
I0902 18:10:09.373817 140216164177920 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:10:09.381726 140216164177920 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:10:09.381952 140216164177920 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:10:09.382055 140216164177920 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:10:09.382237 140216164177920 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:10:09.382386 140216164177920 dqn_agent.py:275] 	 update_period: 4
I0902 18:10:09.382530 140216164177920 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:10:09.382625 140216164177920 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:10:09.382808 140216164177920 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:10:09.382900 140216164177920 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:10:09.382988 140216164177920 dqn_agent.py:280] 	 optimizer: adam
I0902 18:10:09.383119 140216164177920 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:10:09.383214 140216164177920 dqn_agent.py:283] 	 seed: 1630606209381675
I0902 18:10:09.385570 140216164177920 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:10:09.385736 140216164177920 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:10:09.385858 140216164177920 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:10:09.385988 140216164177920 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:10:09.386136 140216164177920 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:10:09.386232 140216164177920 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:10:09.386319 140216164177920 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:10:09.386405 140216164177920 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:10:09.386484 140216164177920 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:10:09.457293 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.031250
I0902 18:10:09.480742 140216164177920 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:10:09.481021 140216164177920 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 161.91
I0902 18:10:15.658030 140216164177920 replay_runner.py:36] Average training steps per second: 161.91
Steps executed: 420 Episode length: 223 Return: -306.5995958870426
I0902 18:10:17.040154 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -443.62
INFO:tensorflow:Starting iteration 1
I0902 18:10:21.505835 140216164177920 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 223.23
I0902 18:10:25.986257 140216164177920 replay_runner.py:36] Average training steps per second: 223.23

Steps executed: 309 Episode length: 154 Return: -545.86397587936845
INFO:tensorflow:Starting iteration 2

Steps executed: 286 Episode length: 177 Return: -80.958354645588465
INFO:tensorflow:Average training steps per second: 227.06
I0902 18:10:35.093062 140216164177920 replay_runner.py:36] Average training steps per second: 227.06
I0902 18:10:35.343489 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.60
INFO:tensorflow:Starting iteration 3

Steps executed: 267 Episode length: 155 Return: -283.74533311445083
INFO:tensorflow:Average training steps per second: 221.15
I0902 18:10:44.304398 140216164177920 replay_runner.py:36] Average training steps per second: 221.15
I0902 18:10:44.556108 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.61
INFO:tensorflow:Starting iteration 4

Steps executed: 308 Episode length: 117 Return: -250.71385344908484
INFO:tensorflow:Average training steps per second: 224.61
I0902 18:10:53.340685 140216164177920 replay_runner.py:36] Average training steps per second: 224.61
I0902 18:10:53.582814 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -367.51
INFO:tensorflow:Starting iteration 5

Steps executed: 252 Episode length: 112 Return: -315.56530696606546
INFO:tensorflow:Average training steps per second: 238.68
I0902 18:11:02.043851 140216164177920 replay_runner.py:36] Average training steps per second: 238.68
I0902 18:11:02.267590 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.91
INFO:tensorflow:Starting iteration 6

Steps executed: 220 Episode length: 131 Return: -302.82753734285116
INFO:tensorflow:Average training steps per second: 249.77
I0902 18:11:10.415011 140216164177920 replay_runner.py:36] Average training steps per second: 249.77
I0902 18:11:10.579191 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -371.37
INFO:tensorflow:Starting iteration 7

Steps executed: 268 Episode length: 73 Return: -384.922322747603964
INFO:tensorflow:Average training steps per second: 254.39
I0902 18:11:18.604037 140216164177920 replay_runner.py:36] Average training steps per second: 254.39
I0902 18:11:18.784989 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.34
INFO:tensorflow:Starting iteration 8

Steps executed: 238 Episode length: 142 Return: -578.81661862973834
INFO:tensorflow:Average training steps per second: 265.47
I0902 18:11:26.512287 140216164177920 replay_runner.py:36] Average training steps per second: 265.47
I0902 18:11:26.691579 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -563.02
INFO:tensorflow:Starting iteration 9

Steps executed: 312 Episode length: 137 Return: -442.48927854948434
INFO:tensorflow:Average training steps per second: 263.83
I0902 18:11:34.410630 140216164177920 replay_runner.py:36] Average training steps per second: 263.83
I0902 18:11:34.637046 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -405.33
INFO:tensorflow:Starting iteration 10

Steps executed: 311 Episode length: 120 Return: -241.78601389592254
INFO:tensorflow:Average training steps per second: 260.11
I0902 18:11:42.375106 140216164177920 replay_runner.py:36] Average training steps per second: 260.11
I0902 18:11:42.577720 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.22
INFO:tensorflow:Starting iteration 11

Steps executed: 269 Episode length: 128 Return: -330.15135149009047
INFO:tensorflow:Average training steps per second: 273.65
I0902 18:11:50.099774 140216164177920 replay_runner.py:36] Average training steps per second: 273.65
I0902 18:11:50.299095 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -357.82
INFO:tensorflow:Starting iteration 12

Steps executed: 283 Episode length: 134 Return: -175.73671249741187
INFO:tensorflow:Average training steps per second: 296.01
I0902 18:11:57.418907 140216164177920 replay_runner.py:36] Average training steps per second: 296.01
I0902 18:11:57.612517 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.65
INFO:tensorflow:Starting iteration 13

Steps executed: 259 Episode length: 86 Return: -252.951321285556287
INFO:tensorflow:Average training steps per second: 315.91
I0902 18:12:04.380844 140216164177920 replay_runner.py:36] Average training steps per second: 315.91
I0902 18:12:04.516271 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -312.77
INFO:tensorflow:Starting iteration 14
I0902 18:12:07.995167 140216164177920 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 321.44

Steps executed: 309 Episode length: 177 Return: -136.04230141440053
I0902 18:12:11.310683 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.73
INFO:tensorflow:Starting iteration 15

Steps executed: 528 Episode length: 342 Return: -1891.5323353588487
INFO:tensorflow:Average training steps per second: 328.67
I0902 18:12:17.782047 140216164177920 replay_runner.py:36] Average training steps per second: 328.67
I0902 18:12:18.260958 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -855.08
INFO:tensorflow:Starting iteration 16
I0902 18:12:21.696086 140216164177920 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 328.14

Steps executed: 233 Episode length: 80 Return: -358.129275040081487
I0902 18:12:24.872433 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.40
INFO:tensorflow:Starting iteration 17

Steps executed: 238 Episode length: 96 Return: -28.1105074258336957
INFO:tensorflow:Average training steps per second: 346.56
I0902 18:12:31.184861 140216164177920 replay_runner.py:36] Average training steps per second: 346.56
I0902 18:12:31.306047 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -45.49
INFO:tensorflow:Starting iteration 18

Steps executed: 259 Episode length: 169 Return: -333.40299388234937
INFO:tensorflow:Average training steps per second: 351.20
I0902 18:12:37.636429 140216164177920 replay_runner.py:36] Average training steps per second: 351.20
I0902 18:12:37.786043 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.23
INFO:tensorflow:Starting iteration 19

Steps executed: 139 Episode length: 75 Return: -284.054960792540447
INFO:tensorflow:Average training steps per second: 340.32

Steps executed: 682 Episode length: 543 Return: -168.33746657592155
I0902 18:12:45.049738 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.54
INFO:tensorflow:Starting iteration 20

Steps executed: 226 Episode length: 53 Return: -63.9890786399431165
INFO:tensorflow:Average training steps per second: 343.47
I0902 18:12:51.398704 140216164177920 replay_runner.py:36] Average training steps per second: 343.47
I0902 18:12:51.503862 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.96
INFO:tensorflow:Starting iteration 21

Steps executed: 289 Episode length: 90 Return: -73.5795504773830878
INFO:tensorflow:Average training steps per second: 343.69
I0902 18:12:57.850345 140216164177920 replay_runner.py:36] Average training steps per second: 343.69
I0902 18:12:57.996925 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.75
INFO:tensorflow:Starting iteration 22

Steps executed: 179 Episode length: 90 Return: -96.3136407963977878
INFO:tensorflow:Average training steps per second: 348.02

Steps executed: 1179 Episode length: 1000 Return: -68.21917792903119
I0902 18:13:06.626052 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.77
INFO:tensorflow:Starting iteration 23

Steps executed: 253 Episode length: 108 Return: -179.806848224050589
INFO:tensorflow:Average training steps per second: 330.63
I0902 18:13:12.889749 140216164177920 replay_runner.py:36] Average training steps per second: 330.63
I0902 18:13:13.041871 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -241.88
INFO:tensorflow:Starting iteration 24

Steps executed: 388 Episode length: 244 Return: -274.924973541932849
INFO:tensorflow:Average training steps per second: 340.90
I0902 18:13:19.402988 140216164177920 replay_runner.py:36] Average training steps per second: 340.90
I0902 18:13:19.692001 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.97
INFO:tensorflow:Starting iteration 25

Steps executed: 218 Episode length: 218 Return: -420.986498680718549
INFO:tensorflow:Average training steps per second: 348.78
I0902 18:13:26.012596 140216164177920 replay_runner.py:36] Average training steps per second: 348.78
I0902 18:13:26.158238 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -420.99
INFO:tensorflow:Starting iteration 26

Steps executed: 185 Episode length: 185 Return: -244.091268255246549
INFO:tensorflow:Average training steps per second: 337.74

Steps executed: 929 Episode length: 744 Return: -97.1574475888565749
I0902 18:13:33.573988 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.62
INFO:tensorflow:Starting iteration 27

Steps executed: 200 Episode length: 98 Return: -304.4947279739362629
INFO:tensorflow:Average training steps per second: 347.23
I0902 18:13:39.942172 140216164177920 replay_runner.py:36] Average training steps per second: 347.23
I0902 18:13:40.048381 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.67
INFO:tensorflow:Starting iteration 28

Steps executed: 597 Episode length: 465 Return: -420.603516819956529
INFO:tensorflow:Average training steps per second: 345.07
I0902 18:13:46.200010 140216164177920 replay_runner.py:36] Average training steps per second: 345.07
I0902 18:13:46.868410 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.01
INFO:tensorflow:Starting iteration 29
I0902 18:13:49.872306 140216164177920 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 359.10
I0902 18:13:52.657328 140216164177920 replay_runner.py:36] Average training steps per second: 359.10


Done fixed training!Episode length: 267 Return: -319.670848818304929