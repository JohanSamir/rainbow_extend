Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0902 18:21:14.892602 140110082734080 run_experiment.py:549] Creating TrainRunner ...
I0902 18:21:14.899907 140110082734080 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:21:14.900037 140110082734080 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:21:14.900109 140110082734080 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:21:14.900170 140110082734080 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:21:14.900225 140110082734080 dqn_agent.py:275] 	 update_period: 4
I0902 18:21:14.900300 140110082734080 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:21:14.900369 140110082734080 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:21:14.900453 140110082734080 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:21:14.900517 140110082734080 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:21:14.900600 140110082734080 dqn_agent.py:280] 	 optimizer: adam
I0902 18:21:14.900682 140110082734080 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:21:14.900784 140110082734080 dqn_agent.py:283] 	 seed: 1630606874899872
I0902 18:21:14.903350 140110082734080 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:21:14.903470 140110082734080 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:21:14.903568 140110082734080 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:21:14.903685 140110082734080 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:21:14.903745 140110082734080 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:21:14.903812 140110082734080 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:21:14.903889 140110082734080 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:21:14.903957 140110082734080 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:21:14.904014 140110082734080 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:21:14.930625 140110082734080 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:15.181016 140110082734080 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:15.190414 140110082734080 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:21:15.196846 140110082734080 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:21:15.197008 140110082734080 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:21:15.197105 140110082734080 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:21:15.197222 140110082734080 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:21:15.197329 140110082734080 dqn_agent.py:275] 	 update_period: 4
I0902 18:21:15.197408 140110082734080 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:21:15.197485 140110082734080 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:21:15.197570 140110082734080 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:21:15.197638 140110082734080 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:21:15.197737 140110082734080 dqn_agent.py:280] 	 optimizer: adam
I0902 18:21:15.197910 140110082734080 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:21:15.197994 140110082734080 dqn_agent.py:283] 	 seed: 1630606875196809
I0902 18:21:15.199511 140110082734080 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:21:15.199625 140110082734080 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:21:15.199699 140110082734080 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:21:15.199764 140110082734080 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:21:15.199823 140110082734080 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:21:15.199881 140110082734080 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:21:15.199961 140110082734080 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:21:15.200033 140110082734080 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:21:15.200117 140110082734080 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:21:15.219208 140110082734080 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:15.233926 140110082734080 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:21:15.234079 140110082734080 replay_runner.py:41] Starting iteration 0
Steps executed: 316 Episode length: 127 Return: -483.2090216281832
INFO:tensorflow:Average training steps per second: 254.75
I0902 18:21:19.159814 140110082734080 replay_runner.py:36] Average training steps per second: 254.75
I0902 18:21:20.042491 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -394.00
INFO:tensorflow:Starting iteration 1

Steps executed: 327 Episode length: 151 Return: -130.47761397576326
INFO:tensorflow:Average training steps per second: 354.76
I0902 18:21:26.103918 140110082734080 replay_runner.py:36] Average training steps per second: 354.76
I0902 18:21:26.320627 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.54
INFO:tensorflow:Starting iteration 2

Steps executed: 362 Episode length: 189 Return: -424.14569547611694
INFO:tensorflow:Average training steps per second: 344.30
I0902 18:21:32.572594 140110082734080 replay_runner.py:36] Average training steps per second: 344.30
I0902 18:21:32.800095 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.09
INFO:tensorflow:Starting iteration 3

Steps executed: 206 Episode length: 206 Return: -172.70243845066742
INFO:tensorflow:Average training steps per second: 348.73
I0902 18:21:38.823608 140110082734080 replay_runner.py:36] Average training steps per second: 348.73
I0902 18:21:38.956820 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -172.70
INFO:tensorflow:Starting iteration 4

Steps executed: 1000 Episode length: 1000 Return: -135.6328434137292
INFO:tensorflow:Average training steps per second: 355.19
I0902 18:21:44.959784 140110082734080 replay_runner.py:36] Average training steps per second: 355.19
I0902 18:21:46.567986 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.63
INFO:tensorflow:Starting iteration 5

Steps executed: 1000 Episode length: 1000 Return: -250.53104245424666
INFO:tensorflow:Average training steps per second: 345.02
I0902 18:21:52.809993 140110082734080 replay_runner.py:36] Average training steps per second: 345.02
I0902 18:21:54.567267 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -250.53
INFO:tensorflow:Starting iteration 6
I0902 18:21:57.963580 140110082734080 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 342.88

Steps executed: 1000 Episode length: 1000 Return: -185.93724797823736
I0902 18:22:03.878046 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.94
INFO:tensorflow:Starting iteration 7
I0902 18:22:07.312146 140110082734080 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 343.26

Steps executed: 1000 Episode length: 1000 Return: -334.12250182131526
I0902 18:22:12.555272 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -334.12
INFO:tensorflow:Starting iteration 8
I0902 18:22:15.990245 140110082734080 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 351.12

Steps executed: 1000 Episode length: 1000 Return: -228.20638886584243
I0902 18:22:20.544981 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.21
INFO:tensorflow:Starting iteration 9
I0902 18:22:23.920262 140110082734080 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 350.54

Steps executed: 1000 Episode length: 1000 Return: -281.59060187817353
I0902 18:22:27.823269 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.59
INFO:tensorflow:Starting iteration 10
I0902 18:22:31.145098 140110082734080 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 346.04

Steps executed: 1000 Episode length: 1000 Return: -53.766999382350754
I0902 18:22:36.225945 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -53.77
INFO:tensorflow:Starting iteration 11
I0902 18:22:39.528804 140110082734080 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 338.40

Steps executed: 1000 Episode length: 1000 Return: -214.80756072322414
I0902 18:22:43.857225 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -214.81
INFO:tensorflow:Starting iteration 12
I0902 18:22:47.184204 140110082734080 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 343.85

Steps executed: 1000 Episode length: 1000 Return: -123.79287764574444
I0902 18:22:52.029863 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.79
INFO:tensorflow:Starting iteration 13
I0902 18:22:55.333467 140110082734080 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 348.67

Steps executed: 1000 Episode length: 1000 Return: -54.724472742093274
I0902 18:23:00.018601 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.72
INFO:tensorflow:Starting iteration 14
I0902 18:23:03.397066 140110082734080 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 350.32

Steps executed: 1000 Episode length: 1000 Return: -203.67179906909884
I0902 18:23:08.747483 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.67
INFO:tensorflow:Starting iteration 15
I0902 18:23:12.153388 140110082734080 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 347.08

Steps executed: 932 Episode length: 932 Return: -273.0983202265377484
I0902 18:23:17.050424 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.10
INFO:tensorflow:Starting iteration 16
I0902 18:23:20.389477 140110082734080 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 352.20

Steps executed: 1000 Episode length: 1000 Return: -77.436135877110224
I0902 18:23:25.494251 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.44
INFO:tensorflow:Starting iteration 17
I0902 18:23:28.850463 140110082734080 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 361.95

Steps executed: 1000 Episode length: 1000 Return: -82.105338299233354
I0902 18:23:34.096413 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.11
INFO:tensorflow:Starting iteration 18
I0902 18:23:37.439014 140110082734080 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 368.86

Steps executed: 1000 Episode length: 1000 Return: -49.450797651598384
I0902 18:23:42.135271 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -49.45
INFO:tensorflow:Starting iteration 19
I0902 18:23:45.445120 140110082734080 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 341.88

Steps executed: 823 Episode length: 823 Return: -624.6129997396342384
I0902 18:23:49.924886 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -624.61
INFO:tensorflow:Starting iteration 20
I0902 18:23:53.140817 140110082734080 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 344.39

Steps executed: 1000 Episode length: 1000 Return: -30.139413639035137
I0902 18:23:58.095792 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -30.14
INFO:tensorflow:Starting iteration 21
I0902 18:24:01.331087 140110082734080 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 333.11

Steps executed: 1000 Episode length: 1000 Return: -64.778351730743727
I0902 18:24:05.930202 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -64.78
INFO:tensorflow:Starting iteration 22

Steps executed: 489 Episode length: 489 Return: -367.9282445012374727
INFO:tensorflow:Average training steps per second: 356.39
I0902 18:24:12.099117 140110082734080 replay_runner.py:36] Average training steps per second: 356.39
I0902 18:24:12.704804 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -367.93
INFO:tensorflow:Starting iteration 23
I0902 18:24:16.210593 140110082734080 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 371.15

Steps executed: 379 Episode length: 242 Return: -120.7864607527999327
I0902 18:24:19.128948 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.82
INFO:tensorflow:Starting iteration 24

Steps executed: 525 Episode length: 525 Return: -573.7350059726645327
INFO:tensorflow:Average training steps per second: 361.81
I0902 18:24:25.395775 140110082734080 replay_runner.py:36] Average training steps per second: 361.81
I0902 18:24:26.205631 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -573.74
INFO:tensorflow:Starting iteration 25
I0902 18:24:29.705482 140110082734080 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 362.45

Steps executed: 1000 Episode length: 1000 Return: 109.231271270541927
I0902 18:24:35.344522 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: 109.23
INFO:tensorflow:Starting iteration 26

Steps executed: 239 Episode length: 79 Return: -440.29401523480551927
INFO:tensorflow:Average training steps per second: 386.09
I0902 18:24:41.337216 140110082734080 replay_runner.py:36] Average training steps per second: 386.09
I0902 18:24:41.469411 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -420.76
INFO:tensorflow:Starting iteration 27

Steps executed: 1000 Episode length: 1000 Return: 126.714920465416827
INFO:tensorflow:Average training steps per second: 356.56
I0902 18:24:47.739180 140110082734080 replay_runner.py:36] Average training steps per second: 356.56
I0902 18:24:48.983042 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: 126.71
INFO:tensorflow:Starting iteration 28

Steps executed: 299 Episode length: 200 Return: -104.6822525959535927
INFO:tensorflow:Average training steps per second: 348.27
I0902 18:24:55.277442 140110082734080 replay_runner.py:36] Average training steps per second: 348.27
I0902 18:24:55.411323 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.33
INFO:tensorflow:Starting iteration 29

Steps executed: 286 Episode length: 184 Return: -250.5038038086572327
INFO:tensorflow:Average training steps per second: 320.03
I0902 18:25:01.578321 140110082734080 replay_runner.py:36] Average training steps per second: 320.03

Done fixed training!Episode length: 184 Return: -250.5038038086572327