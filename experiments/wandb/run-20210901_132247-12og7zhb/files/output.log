I0901 13:22:53.692665 140298343233536 run_experiment.py:549] Creating TrainRunner ...
I0901 13:22:53.701984 140298343233536 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:22:53.702167 140298343233536 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:22:53.702277 140298343233536 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:22:53.702341 140298343233536 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:22:53.702400 140298343233536 dqn_agent.py:275] 	 update_period: 4
I0901 13:22:53.702500 140298343233536 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:22:53.702586 140298343233536 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:22:53.702657 140298343233536 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:22:53.702738 140298343233536 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:22:53.702805 140298343233536 dqn_agent.py:280] 	 optimizer: adam
I0901 13:22:53.702861 140298343233536 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:22:53.702937 140298343233536 dqn_agent.py:283] 	 seed: 1630502573701941
I0901 13:22:53.704770 140298343233536 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:22:53.704892 140298343233536 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:22:53.704970 140298343233536 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:22:53.705041 140298343233536 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:22:53.705114 140298343233536 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:22:53.705191 140298343233536 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:22:53.705270 140298343233536 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:22:53.705334 140298343233536 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:22:53.705396 140298343233536 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:22:53.828233 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:22:54.095027 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:22:54.106180 140298343233536 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:22:54.112832 140298343233536 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:22:54.112978 140298343233536 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:22:54.113077 140298343233536 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:22:54.113146 140298343233536 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:22:54.113204 140298343233536 dqn_agent.py:275] 	 update_period: 4
I0901 13:22:54.113273 140298343233536 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:22:54.113364 140298343233536 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:22:54.113501 140298343233536 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:22:54.113732 140298343233536 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:22:54.113830 140298343233536 dqn_agent.py:280] 	 optimizer: adam
I0901 13:22:54.113904 140298343233536 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:22:54.113975 140298343233536 dqn_agent.py:283] 	 seed: 1630502574112794
I0901 13:22:54.115682 140298343233536 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:22:54.115809 140298343233536 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:22:54.115944 140298343233536 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:22:54.116016 140298343233536 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:22:54.116122 140298343233536 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:22:54.116194 140298343233536 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:22:54.116261 140298343233536 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:22:54.116335 140298343233536 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:22:54.116388 140298343233536 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:22:54.141164 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:22:54.156797 140298343233536 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:22:54.156985 140298343233536 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 235.36
I0901 13:22:58.406150 140298343233536 replay_runner.py:36] Average training steps per second: 235.36
Steps executed: 193 Episode length: 193 Return: -116.03878989473176

Steps executed: 421 Episode length: 228 Return: -324.77077659501826
INFO:tensorflow:Starting iteration 1

Steps executed: 249 Episode length: 92 Return: -411.917925536844616
INFO:tensorflow:Average training steps per second: 352.32
I0901 13:23:05.655714 140298343233536 replay_runner.py:36] Average training steps per second: 352.32
I0901 13:23:05.806746 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.29
INFO:tensorflow:Starting iteration 2

Steps executed: 220 Episode length: 85 Return: -357.156242032520686
INFO:tensorflow:Average training steps per second: 346.11
I0901 13:23:12.226640 140298343233536 replay_runner.py:36] Average training steps per second: 346.11
I0901 13:23:12.379735 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.95
INFO:tensorflow:Starting iteration 3

Steps executed: 280 Episode length: 88 Return: -477.741406539587252
INFO:tensorflow:Average training steps per second: 352.50
I0901 13:23:18.814388 140298343233536 replay_runner.py:36] Average training steps per second: 352.50
I0901 13:23:18.981092 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -271.42
INFO:tensorflow:Starting iteration 4

Steps executed: 341 Episode length: 166 Return: -199.76985437917256
INFO:tensorflow:Average training steps per second: 342.67
I0901 13:23:25.519613 140298343233536 replay_runner.py:36] Average training steps per second: 342.67
I0901 13:23:25.740605 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.23
INFO:tensorflow:Starting iteration 5

Steps executed: 269 Episode length: 145 Return: -207.58808195245672
INFO:tensorflow:Average training steps per second: 347.79
I0901 13:23:32.192348 140298343233536 replay_runner.py:36] Average training steps per second: 347.79
I0901 13:23:32.369978 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.79
INFO:tensorflow:Starting iteration 6

Steps executed: 693 Episode length: 532 Return: -356.06984362682476
INFO:tensorflow:Average training steps per second: 345.90
I0901 13:23:38.856692 140298343233536 replay_runner.py:36] Average training steps per second: 345.90
I0901 13:23:39.596727 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -246.15
INFO:tensorflow:Starting iteration 7

Steps executed: 207 Episode length: 104 Return: -813.31875919289184
INFO:tensorflow:Average training steps per second: 333.74
I0901 13:23:46.116228 140298343233536 replay_runner.py:36] Average training steps per second: 333.74
I0901 13:23:46.244049 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -608.70
INFO:tensorflow:Starting iteration 8

Steps executed: 402 Episode length: 402 Return: -1796.5485571065324
INFO:tensorflow:Average training steps per second: 332.94
I0901 13:23:52.764038 140298343233536 replay_runner.py:36] Average training steps per second: 332.94
I0901 13:23:53.350695 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -1796.55
INFO:tensorflow:Starting iteration 9

Steps executed: 274 Episode length: 97 Return: -103.594970175438124
INFO:tensorflow:Average training steps per second: 323.63
I0901 13:24:00.003740 140298343233536 replay_runner.py:36] Average training steps per second: 323.63
I0901 13:24:00.154271 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.20
INFO:tensorflow:Starting iteration 10
I0901 13:24:03.741079 140298343233536 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 337.90

Steps executed: 1000 Episode length: 1000 Return: -130.79463546882175
I0901 13:24:08.320364 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.79
INFO:tensorflow:Starting iteration 11

Steps executed: 375 Episode length: 375 Return: -286.0860757416537675
INFO:tensorflow:Average training steps per second: 349.91
I0901 13:24:14.775631 140298343233536 replay_runner.py:36] Average training steps per second: 349.91
I0901 13:24:15.181315 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -286.09
INFO:tensorflow:Starting iteration 12

Steps executed: 149 Episode length: 66 Return: -220.37719975428537675
INFO:tensorflow:Average training steps per second: 338.90

Steps executed: 490 Episode length: 341 Return: -166.8533996301255875
I0901 13:24:22.215293 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -380.80
INFO:tensorflow:Starting iteration 13

Steps executed: 206 Episode length: 142 Return: -124.2719637700062175
INFO:tensorflow:Average training steps per second: 336.79
I0901 13:24:28.754781 140298343233536 replay_runner.py:36] Average training steps per second: 336.79
I0901 13:24:28.867402 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.61
INFO:tensorflow:Starting iteration 14
I0901 13:24:32.407161 140298343233536 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 321.89
I0901 13:24:35.514148 140298343233536 replay_runner.py:36] Average training steps per second: 321.89

Steps executed: 240 Episode length: 80 Return: -705.13888585826632175
INFO:tensorflow:Starting iteration 15

Steps executed: 241 Episode length: 81 Return: -672.15188183454222175
INFO:tensorflow:Average training steps per second: 321.87
I0901 13:24:42.288654 140298343233536 replay_runner.py:36] Average training steps per second: 321.87
I0901 13:24:42.432237 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -664.80
INFO:tensorflow:Starting iteration 16

Steps executed: 261 Episode length: 83 Return: -608.45776843718122175
INFO:tensorflow:Average training steps per second: 317.91
I0901 13:24:49.068676 140298343233536 replay_runner.py:36] Average training steps per second: 317.91
I0901 13:24:49.225084 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -630.94
INFO:tensorflow:Starting iteration 17
I0901 13:24:52.695272 140298343233536 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 309.75
I0901 13:24:55.924071 140298343233536 replay_runner.py:36] Average training steps per second: 309.75

Steps executed: 207 Episode length: 59 Return: -570.01765355986412175
INFO:tensorflow:Starting iteration 18

Steps executed: 260 Episode length: 84 Return: -662.82145944755295175
INFO:tensorflow:Average training steps per second: 311.95
I0901 13:25:02.697643 140298343233536 replay_runner.py:36] Average training steps per second: 311.95
I0901 13:25:02.839400 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -562.42
INFO:tensorflow:Starting iteration 19

Steps executed: 231 Episode length: 76 Return: -715.44103755274025175
INFO:tensorflow:Average training steps per second: 311.48
I0901 13:25:09.527410 140298343233536 replay_runner.py:36] Average training steps per second: 311.48
I0901 13:25:09.662802 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -628.71
INFO:tensorflow:Starting iteration 20

Steps executed: 244 Episode length: 74 Return: -561.62385595240635175
INFO:tensorflow:Average training steps per second: 310.59
I0901 13:25:16.333526 140298343233536 replay_runner.py:36] Average training steps per second: 310.59
I0901 13:25:16.482519 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -566.00
INFO:tensorflow:Starting iteration 21

Steps executed: 201 Episode length: 65 Return: -524.26574078696335175
INFO:tensorflow:Average training steps per second: 310.29
I0901 13:25:23.158212 140298343233536 replay_runner.py:36] Average training steps per second: 310.29
I0901 13:25:23.282041 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -594.00
INFO:tensorflow:Starting iteration 22

Steps executed: 250 Episode length: 88 Return: -581.18251745535855175
INFO:tensorflow:Average training steps per second: 313.07
I0901 13:25:29.925510 140298343233536 replay_runner.py:36] Average training steps per second: 313.07
I0901 13:25:30.071132 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -529.85
INFO:tensorflow:Starting iteration 23

Steps executed: 206 Episode length: 65 Return: -184.44534134207294175
INFO:tensorflow:Average training steps per second: 312.68
I0901 13:25:36.745186 140298343233536 replay_runner.py:36] Average training steps per second: 312.68
I0901 13:25:36.865657 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -518.94
INFO:tensorflow:Starting iteration 24

Steps executed: 240 Episode length: 71 Return: -716.53090624403065175
INFO:tensorflow:Average training steps per second: 306.45
I0901 13:25:43.597583 140298343233536 replay_runner.py:36] Average training steps per second: 306.45
I0901 13:25:43.741572 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.37
INFO:tensorflow:Starting iteration 25

Steps executed: 232 Episode length: 58 Return: -540.71482457602635175
INFO:tensorflow:Average training steps per second: 319.54
I0901 13:25:50.314522 140298343233536 replay_runner.py:36] Average training steps per second: 319.54
I0901 13:25:50.453318 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -479.97
INFO:tensorflow:Starting iteration 26

Steps executed: 246 Episode length: 117 Return: -790.4032460345276175
INFO:tensorflow:Average training steps per second: 318.56
I0901 13:25:57.008676 140298343233536 replay_runner.py:36] Average training steps per second: 318.56
I0901 13:25:57.184032 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -765.91
INFO:tensorflow:Starting iteration 27

Steps executed: 283 Episode length: 101 Return: -692.3044065196525775
INFO:tensorflow:Average training steps per second: 337.50
I0901 13:26:03.560158 140298343233536 replay_runner.py:36] Average training steps per second: 337.50
I0901 13:26:03.737972 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -569.06
INFO:tensorflow:Starting iteration 28

Steps executed: 258 Episode length: 84 Return: -895.99792538066955775
INFO:tensorflow:Average training steps per second: 317.77
I0901 13:26:10.266761 140298343233536 replay_runner.py:36] Average training steps per second: 317.77
I0901 13:26:10.429379 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -827.90
INFO:tensorflow:Starting iteration 29

Steps executed: 219 Episode length: 111 Return: -1020.662413799213375
INFO:tensorflow:Average training steps per second: 324.22
I0901 13:26:16.839556 140298343233536 replay_runner.py:36] Average training steps per second: 324.22

Done fixed training!Episode length: 111 Return: -1020.662413799213375