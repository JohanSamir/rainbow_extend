Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0902 17:51:01.347187 140451420674048 run_experiment.py:549] Creating TrainRunner ...
I0902 17:51:01.358757 140451420674048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:51:01.359153 140451420674048 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:51:01.359531 140451420674048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:51:01.359704 140451420674048 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:51:01.359854 140451420674048 dqn_agent.py:275] 	 update_period: 4
I0902 17:51:01.359976 140451420674048 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:51:01.360104 140451420674048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:51:01.360328 140451420674048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:51:01.360443 140451420674048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:51:01.360544 140451420674048 dqn_agent.py:280] 	 optimizer: adam
I0902 17:51:01.360672 140451420674048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:51:01.361215 140451420674048 dqn_agent.py:283] 	 seed: 1630605061358694
I0902 17:51:01.363962 140451420674048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:51:01.364091 140451420674048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:51:01.364168 140451420674048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:51:01.364225 140451420674048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:51:01.364277 140451420674048 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:51:01.364341 140451420674048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:51:01.364389 140451420674048 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:51:01.364449 140451420674048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:51:01.364540 140451420674048 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:51:01.400023 140451420674048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:51:01.801014 140451420674048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:51:01.816530 140451420674048 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 17:51:01.826029 140451420674048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:51:01.826353 140451420674048 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:51:01.826536 140451420674048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:51:01.826772 140451420674048 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:51:01.826920 140451420674048 dqn_agent.py:275] 	 update_period: 4
I0902 17:51:01.827060 140451420674048 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:51:01.827284 140451420674048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:51:01.827532 140451420674048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:51:01.827816 140451420674048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:51:01.827991 140451420674048 dqn_agent.py:280] 	 optimizer: adam
I0902 17:51:01.828140 140451420674048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:51:01.828289 140451420674048 dqn_agent.py:283] 	 seed: 1630605061825964
I0902 17:51:01.831283 140451420674048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:51:01.831765 140451420674048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:51:01.831852 140451420674048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:51:01.831928 140451420674048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:51:01.832073 140451420674048 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:51:01.832199 140451420674048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:51:01.832279 140451420674048 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:51:01.832376 140451420674048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:51:01.832713 140451420674048 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:51:01.909043 140451420674048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:51:01.932445 140451420674048 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 17:51:01.932709 140451420674048 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.86
I0902 17:51:08.073519 140451420674048 replay_runner.py:36] Average training steps per second: 162.86
Steps executed: 293 Episode length: 121 Return: -821.3015017652519
I0902 17:51:09.377325 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -546.25
INFO:tensorflow:Starting iteration 1

Steps executed: 244 Episode length: 128 Return: -387.9084707446703
INFO:tensorflow:Average training steps per second: 223.63
I0902 17:51:18.190734 140451420674048 replay_runner.py:36] Average training steps per second: 223.63
I0902 17:51:18.370350 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.70
INFO:tensorflow:Starting iteration 2

Steps executed: 217 Episode length: 72 Return: -216.89548464595642
INFO:tensorflow:Average training steps per second: 223.21
I0902 17:51:27.229136 140451420674048 replay_runner.py:36] Average training steps per second: 223.21
I0902 17:51:27.372884 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.73
INFO:tensorflow:Starting iteration 3

Steps executed: 263 Episode length: 67 Return: -175.548357040732725
INFO:tensorflow:Average training steps per second: 219.87
I0902 17:51:36.325793 140451420674048 replay_runner.py:36] Average training steps per second: 219.87
I0902 17:51:36.516982 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.93
INFO:tensorflow:Starting iteration 4

Steps executed: 261 Episode length: 128 Return: -298.25539382418665
INFO:tensorflow:Average training steps per second: 219.85
I0902 17:51:45.453755 140451420674048 replay_runner.py:36] Average training steps per second: 219.85
I0902 17:51:45.653957 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.98
INFO:tensorflow:Starting iteration 5

Steps executed: 290 Episode length: 108 Return: -328.57201894522046
INFO:tensorflow:Average training steps per second: 218.04
I0902 17:51:54.659582 140451420674048 replay_runner.py:36] Average training steps per second: 218.04
I0902 17:51:54.884468 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.23
INFO:tensorflow:Starting iteration 6

Steps executed: 301 Episode length: 205 Return: -254.31819673814716
INFO:tensorflow:Average training steps per second: 220.51
I0902 17:52:03.845260 140451420674048 replay_runner.py:36] Average training steps per second: 220.51
I0902 17:52:04.132279 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.73
INFO:tensorflow:Starting iteration 7

Steps executed: 261 Episode length: 139 Return: -510.50211764866056
INFO:tensorflow:Average training steps per second: 220.52
I0902 17:52:13.004015 140451420674048 replay_runner.py:36] Average training steps per second: 220.52
I0902 17:52:13.242645 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -398.33
INFO:tensorflow:Starting iteration 8

Steps executed: 226 Episode length: 133 Return: -584.84067592626966
INFO:tensorflow:Average training steps per second: 221.87
I0902 17:52:22.174626 140451420674048 replay_runner.py:36] Average training steps per second: 221.87
I0902 17:52:22.380025 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -528.35
INFO:tensorflow:Starting iteration 9
I0902 17:52:26.781162 140451420674048 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 221.24

Steps executed: 277 Episode length: 172 Return: -204.49363913269917
I0902 17:52:31.561095 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.49
INFO:tensorflow:Starting iteration 10

Steps executed: 328 Episode length: 241 Return: -82.505375750687397
INFO:tensorflow:Average training steps per second: 218.88
I0902 17:52:40.528046 140451420674048 replay_runner.py:36] Average training steps per second: 218.88
I0902 17:52:40.855120 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -222.22
INFO:tensorflow:Starting iteration 11

Steps executed: 314 Episode length: 198 Return: -504.72608290142267
INFO:tensorflow:Average training steps per second: 221.01
I0902 17:52:49.747917 140451420674048 replay_runner.py:36] Average training steps per second: 221.01
I0902 17:52:50.077474 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -583.63
INFO:tensorflow:Starting iteration 12

Steps executed: 206 Episode length: 206 Return: -509.99609761822813
INFO:tensorflow:Average training steps per second: 221.73
I0902 17:52:58.923101 140451420674048 replay_runner.py:36] Average training steps per second: 221.73
I0902 17:52:59.129969 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -510.00
INFO:tensorflow:Starting iteration 13

Steps executed: 218 Episode length: 130 Return: -446.38619185504814
INFO:tensorflow:Average training steps per second: 235.60
I0902 17:53:07.824865 140451420674048 replay_runner.py:36] Average training steps per second: 235.60
I0902 17:53:07.996264 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -401.93
INFO:tensorflow:Starting iteration 14

Steps executed: 221 Episode length: 112 Return: -277.27772372448774
INFO:tensorflow:Average training steps per second: 229.72
I0902 17:53:16.597760 140451420674048 replay_runner.py:36] Average training steps per second: 229.72
I0902 17:53:16.808355 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -483.73
INFO:tensorflow:Starting iteration 15

Steps executed: 225 Episode length: 120 Return: -478.03521066334834
INFO:tensorflow:Average training steps per second: 226.00
I0902 17:53:25.595166 140451420674048 replay_runner.py:36] Average training steps per second: 226.00
I0902 17:53:25.812072 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -424.08
INFO:tensorflow:Starting iteration 16

Steps executed: 297 Episode length: 184 Return: -738.72665307015944
INFO:tensorflow:Average training steps per second: 224.63
I0902 17:53:34.752102 140451420674048 replay_runner.py:36] Average training steps per second: 224.63
I0902 17:53:35.025741 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -599.97
INFO:tensorflow:Starting iteration 17

Steps executed: 253 Episode length: 128 Return: -379.19124809751366
INFO:tensorflow:Average training steps per second: 225.31
I0902 17:53:43.722620 140451420674048 replay_runner.py:36] Average training steps per second: 225.31
I0902 17:53:43.960093 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.44
INFO:tensorflow:Starting iteration 18

Steps executed: 273 Episode length: 87 Return: -401.365266087766876
INFO:tensorflow:Average training steps per second: 229.65
I0902 17:53:52.524895 140451420674048 replay_runner.py:36] Average training steps per second: 229.65
I0902 17:53:52.782526 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -564.22
INFO:tensorflow:Starting iteration 19
I0902 17:53:57.039160 140451420674048 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 227.30

Steps executed: 236 Episode length: 236 Return: -641.87058604327756
I0902 17:54:01.735971 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -641.87
INFO:tensorflow:Starting iteration 20

Steps executed: 418 Episode length: 418 Return: -628.88871135121296
INFO:tensorflow:Average training steps per second: 220.82
I0902 17:54:10.724149 140451420674048 replay_runner.py:36] Average training steps per second: 220.82
I0902 17:54:11.384356 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -628.89
INFO:tensorflow:Starting iteration 21

Steps executed: 387 Episode length: 220 Return: -693.20176082935596
INFO:tensorflow:Average training steps per second: 220.23
I0902 17:54:20.331355 140451420674048 replay_runner.py:36] Average training steps per second: 220.23
I0902 17:54:20.741135 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.50
INFO:tensorflow:Starting iteration 22

Steps executed: 363 Episode length: 278 Return: -374.84199692333436
INFO:tensorflow:Average training steps per second: 216.43
I0902 17:54:29.701331 140451420674048 replay_runner.py:36] Average training steps per second: 216.43
I0902 17:54:30.102881 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -360.47
INFO:tensorflow:Starting iteration 23

Steps executed: 342 Episode length: 245 Return: -782.41112420676046
INFO:tensorflow:Average training steps per second: 219.19
I0902 17:54:39.051946 140451420674048 replay_runner.py:36] Average training steps per second: 219.19
I0902 17:54:39.422004 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -572.45
INFO:tensorflow:Starting iteration 24

Steps executed: 326 Episode length: 241 Return: -807.83387421870136
INFO:tensorflow:Average training steps per second: 220.40
I0902 17:54:48.370480 140451420674048 replay_runner.py:36] Average training steps per second: 220.40
I0902 17:54:48.737435 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -573.51
INFO:tensorflow:Starting iteration 25
I0902 17:54:53.164024 140451420674048 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 219.64

Steps executed: 263 Episode length: 263 Return: -255.67868214449882
I0902 17:54:58.019940 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.68
INFO:tensorflow:Starting iteration 26

Steps executed: 273 Episode length: 198 Return: -320.77574227490142
INFO:tensorflow:Average training steps per second: 221.42
I0902 17:55:06.972020 140451420674048 replay_runner.py:36] Average training steps per second: 221.42
I0902 17:55:07.221912 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -379.35
INFO:tensorflow:Starting iteration 27

Steps executed: 206 Episode length: 83 Return: -406.380032981210306
INFO:tensorflow:Average training steps per second: 225.06
I0902 17:55:16.040275 140451420674048 replay_runner.py:36] Average training steps per second: 225.06
I0902 17:55:16.219437 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -428.49
INFO:tensorflow:Starting iteration 28

Steps executed: 218 Episode length: 136 Return: -322.18651727473856
INFO:tensorflow:Average training steps per second: 224.89
I0902 17:55:25.019679 140451420674048 replay_runner.py:36] Average training steps per second: 224.89
I0902 17:55:25.194293 140451420674048 run_experiment.py:428] Average undiscounted return per evaluation episode: -404.89
INFO:tensorflow:Starting iteration 29
I0902 17:55:29.503508 140451420674048 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 225.58

Steps executed: 263 Episode length: 83 Return: -373.654005842997956

Done fixed training!Episode length: 83 Return: -373.654005842997956