I0901 13:08:27.435550 140240877414400 run_experiment.py:549] Creating TrainRunner ...
I0901 13:08:27.442407 140240877414400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:08:27.442652 140240877414400 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:08:27.442764 140240877414400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:08:27.442858 140240877414400 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:08:27.442990 140240877414400 dqn_agent.py:275] 	 update_period: 4
I0901 13:08:27.443117 140240877414400 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:08:27.443195 140240877414400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:08:27.443267 140240877414400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:08:27.443340 140240877414400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:08:27.443436 140240877414400 dqn_agent.py:280] 	 optimizer: adam
I0901 13:08:27.443555 140240877414400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:08:27.443656 140240877414400 dqn_agent.py:283] 	 seed: 1630501707442365
I0901 13:08:27.446003 140240877414400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:08:27.446137 140240877414400 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:08:27.446238 140240877414400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:08:27.446311 140240877414400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:08:27.446388 140240877414400 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:08:27.446476 140240877414400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:08:27.446554 140240877414400 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:08:27.446627 140240877414400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:08:27.446684 140240877414400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:08:27.541004 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:27.783821 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:27.792413 140240877414400 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:08:27.798616 140240877414400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:08:27.798740 140240877414400 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:08:27.798825 140240877414400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:08:27.798884 140240877414400 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:08:27.798945 140240877414400 dqn_agent.py:275] 	 update_period: 4
I0901 13:08:27.799017 140240877414400 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:08:27.799098 140240877414400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:08:27.799162 140240877414400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:08:27.799214 140240877414400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:08:27.799283 140240877414400 dqn_agent.py:280] 	 optimizer: adam
I0901 13:08:27.799348 140240877414400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:08:27.799413 140240877414400 dqn_agent.py:283] 	 seed: 1630501707798585
I0901 13:08:27.800936 140240877414400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:08:27.801057 140240877414400 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:08:27.801137 140240877414400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:08:27.801210 140240877414400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:08:27.801283 140240877414400 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:08:27.801386 140240877414400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:08:27.801451 140240877414400 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:08:27.801513 140240877414400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:08:27.801599 140240877414400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:08:27.821817 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:27.836425 140240877414400 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:08:27.836639 140240877414400 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 244.32
I0901 13:08:31.929888 140240877414400 replay_runner.py:36] Average training steps per second: 244.32
I0901 13:08:32.654569 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -514.76
Steps executed: 213 Episode length: 119 Return: -324.0321619473395
INFO:tensorflow:Starting iteration 1
I0901 13:08:35.705819 140240877414400 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 335.93


Steps executed: 542 Episode length: 369 Return: 180.31435976857245
I0901 13:08:39.132393 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.06
INFO:tensorflow:Starting iteration 2

Steps executed: 210 Episode length: 81 Return: -316.98820390139184
INFO:tensorflow:Average training steps per second: 336.68
I0901 13:08:45.309707 140240877414400 replay_runner.py:36] Average training steps per second: 336.68
I0901 13:08:45.429835 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.61
INFO:tensorflow:Starting iteration 3
I0901 13:08:48.781753 140240877414400 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 328.93
I0901 13:08:51.822263 140240877414400 replay_runner.py:36] Average training steps per second: 328.93

Steps executed: 323 Episode length: 213 Return: -100.3816320975373
INFO:tensorflow:Starting iteration 4

Steps executed: 295 Episode length: 169 Return: -209.08085522352957
INFO:tensorflow:Average training steps per second: 338.33
I0901 13:08:58.302563 140240877414400 replay_runner.py:36] Average training steps per second: 338.33
I0901 13:08:58.450202 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.85
INFO:tensorflow:Starting iteration 5

Steps executed: 397 Episode length: 208 Return: -3.1190231817267033
INFO:tensorflow:Average training steps per second: 323.76
I0901 13:09:04.872023 140240877414400 replay_runner.py:36] Average training steps per second: 323.76
I0901 13:09:05.076465 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.78
INFO:tensorflow:Starting iteration 6

Steps executed: 230 Episode length: 139 Return: -206.68679403155583
INFO:tensorflow:Average training steps per second: 330.40
I0901 13:09:11.503493 140240877414400 replay_runner.py:36] Average training steps per second: 330.40
I0901 13:09:11.633131 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.74
INFO:tensorflow:Starting iteration 7

Steps executed: 635 Episode length: 506 Return: 127.977342678977988
INFO:tensorflow:Average training steps per second: 335.51
I0901 13:09:17.999258 140240877414400 replay_runner.py:36] Average training steps per second: 335.51
I0901 13:09:18.670991 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -44.55
INFO:tensorflow:Starting iteration 8

Steps executed: 210 Episode length: 107 Return: -100.89631105092343
INFO:tensorflow:Average training steps per second: 331.94
I0901 13:09:25.063897 140240877414400 replay_runner.py:36] Average training steps per second: 331.94
I0901 13:09:25.186444 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.55
INFO:tensorflow:Starting iteration 9

Steps executed: 363 Episode length: 182 Return: -82.161525834241433
INFO:tensorflow:Average training steps per second: 324.09
I0901 13:09:31.661206 140240877414400 replay_runner.py:36] Average training steps per second: 324.09
I0901 13:09:31.927314 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.79
INFO:tensorflow:Starting iteration 10

Steps executed: 215 Episode length: 111 Return: -142.83264308169245
INFO:tensorflow:Average training steps per second: 329.97
I0901 13:09:38.333993 140240877414400 replay_runner.py:36] Average training steps per second: 329.97
I0901 13:09:38.465778 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.93
INFO:tensorflow:Starting iteration 11

Steps executed: 288 Episode length: 115 Return: -78.961687164194523
INFO:tensorflow:Average training steps per second: 312.13
I0901 13:09:45.002540 140240877414400 replay_runner.py:36] Average training steps per second: 312.13
I0901 13:09:45.184409 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.17
INFO:tensorflow:Starting iteration 12

Steps executed: 244 Episode length: 143 Return: -75.600772870739962
INFO:tensorflow:Average training steps per second: 325.90
I0901 13:09:51.582901 140240877414400 replay_runner.py:36] Average training steps per second: 325.90
I0901 13:09:51.735042 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.41
INFO:tensorflow:Starting iteration 13

Steps executed: 230 Episode length: 123 Return: -28.356277923639794
INFO:tensorflow:Average training steps per second: 323.62
I0901 13:09:58.151981 140240877414400 replay_runner.py:36] Average training steps per second: 323.62
I0901 13:09:58.285871 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.72
INFO:tensorflow:Starting iteration 14

Steps executed: 439 Episode length: 314 Return: -122.15478997308036
INFO:tensorflow:Average training steps per second: 325.16
I0901 13:10:04.710361 140240877414400 replay_runner.py:36] Average training steps per second: 325.16
I0901 13:10:05.061102 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.30
INFO:tensorflow:Starting iteration 15
I0901 13:10:08.408588 140240877414400 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 327.87

Steps executed: 402 Episode length: 402 Return: -149.75207392717536
I0901 13:10:11.766499 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.75
INFO:tensorflow:Starting iteration 16
I0901 13:10:15.169894 140240877414400 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 331.26

Steps executed: 1000 Episode length: 1000 Return: -184.52271949796582
I0901 13:10:20.352041 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.52
INFO:tensorflow:Starting iteration 17

Steps executed: 786 Episode length: 673 Return: 101.00509958637649582
INFO:tensorflow:Average training steps per second: 343.05
I0901 13:10:26.723776 140240877414400 replay_runner.py:36] Average training steps per second: 343.05
I0901 13:10:27.614937 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: 63.80
INFO:tensorflow:Starting iteration 18

Steps executed: 295 Episode length: 170 Return: -5.690582231772396582
INFO:tensorflow:Average training steps per second: 360.70
I0901 13:10:33.851191 140240877414400 replay_runner.py:36] Average training steps per second: 360.70
I0901 13:10:34.008993 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -26.85
INFO:tensorflow:Starting iteration 19
I0901 13:10:37.509933 140240877414400 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 349.55

Steps executed: 1000 Episode length: 1000 Return: 16.8543025104150852
I0901 13:10:42.352883 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: 16.85
INFO:tensorflow:Starting iteration 20

Steps executed: 248 Episode length: 81 Return: -70.620243178686026852
INFO:tensorflow:Average training steps per second: 357.24
I0901 13:10:48.653751 140240877414400 replay_runner.py:36] Average training steps per second: 357.24
I0901 13:10:48.806695 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -51.06
INFO:tensorflow:Starting iteration 21
I0901 13:10:52.303226 140240877414400 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 384.02

Steps executed: 958 Episode length: 958 Return: -173.1454080512002852
I0901 13:10:56.481374 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.15
INFO:tensorflow:Starting iteration 22
I0901 13:10:59.851356 140240877414400 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 368.54

Steps executed: 1000 Episode length: 1000 Return: -42.469148142631774
I0901 13:11:04.456031 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -42.47
INFO:tensorflow:Starting iteration 23
I0901 13:11:07.596378 140240877414400 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 333.08

Steps executed: 1000 Episode length: 1000 Return: -126.20832962925806
I0901 13:11:13.387366 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.21
INFO:tensorflow:Starting iteration 24
I0901 13:11:16.405264 140240877414400 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 314.31
I0901 13:11:19.587301 140240877414400 replay_runner.py:36] Average training steps per second: 314.31

Steps executed: 305 Episode length: 130 Return: -99.63064024206938706
INFO:tensorflow:Starting iteration 25

Steps executed: 398 Episode length: 289 Return: 238.84469355158875706
INFO:tensorflow:Average training steps per second: 321.53
I0901 13:11:25.988551 140240877414400 replay_runner.py:36] Average training steps per second: 321.53
I0901 13:11:26.297605 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: 53.76
INFO:tensorflow:Starting iteration 26

Steps executed: 154 Episode length: 154 Return: -12.65045735954957706
INFO:tensorflow:Average training steps per second: 321.32

Steps executed: 1154 Episode length: 1000 Return: -58.184432591352466
I0901 13:11:34.551182 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -35.42
INFO:tensorflow:Starting iteration 27
I0901 13:11:37.874634 140240877414400 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 334.37

Steps executed: 784 Episode length: 784 Return: 108.45228454288441466
I0901 13:11:42.290329 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: 108.45
INFO:tensorflow:Starting iteration 28

Steps executed: 579 Episode length: 422 Return: -118.5719407912483566
INFO:tensorflow:Average training steps per second: 357.08
I0901 13:11:48.447488 140240877414400 replay_runner.py:36] Average training steps per second: 357.08
I0901 13:11:48.887476 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.09
INFO:tensorflow:Starting iteration 29
I0901 13:11:52.156378 140240877414400 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 342.31

Steps executed: 983 Episode length: 983 Return: 42.122674693844983566

Done fixed training!Episode length: 983 Return: 42.122674693844983566