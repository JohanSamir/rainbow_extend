I0901 23:29:06.511049 139752435963904 run_experiment.py:549] Creating TrainRunner ...
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0901 23:29:06.511831 139752435963904 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0901 23:29:06.597869 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:29:06.599080 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:29:06.599161 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:29:06.599224 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:29:06.599280 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0901 23:29:06.599361 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:29:06.599461 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:29:06.599518 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:29:06.599592 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:29:06.599668 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0901 23:29:06.599738 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:29:06.599810 139752435963904 dqn_agent.py:283] 	 seed: 1630538946597808
I0901 23:29:06.601602 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:29:06.601762 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:29:06.601834 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:29:06.601896 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:29:06.601954 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:29:06.602028 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:29:06.602145 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:29:06.602233 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:29:06.602310 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:29:13.438195 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0901 23:29:15.138575 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:29:15.217184 139752435963904 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:29:15.263078 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:29:15.265588 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:29:15.266554 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:29:15.267449 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:29:15.268141 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0901 23:29:15.268804 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:29:15.269474 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:29:15.270158 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:29:15.270999 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:29:15.271668 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0901 23:29:15.272316 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:29:15.272977 139752435963904 dqn_agent.py:283] 	 seed: 1630538955263023
I0901 23:29:15.286890 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:29:15.288552 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:29:15.289362 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:29:15.290217 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:29:15.291118 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:29:15.291999 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:29:15.292771 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:29:15.293554 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:29:15.294336 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:29:16.033969 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:29:16.150884 139752435963904 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:29:16.151251 139752435963904 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 141.16
I0901 23:29:23.236500 139752435963904 replay_runner.py:36] Average training steps per second: 141.16
Steps executed: 264 Episode length: 124 Return: -569.9463752108086
I0901 23:29:24.255876 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -557.63
INFO:tensorflow:Starting iteration 1

Steps executed: 269 Episode length: 142 Return: -284.32820408921515
INFO:tensorflow:Average training steps per second: 203.85
I0901 23:29:33.534042 139752435963904 replay_runner.py:36] Average training steps per second: 203.85
I0901 23:29:33.780680 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -297.03
INFO:tensorflow:Starting iteration 2

Steps executed: 329 Episode length: 173 Return: -198.99813740529285
INFO:tensorflow:Average training steps per second: 203.90
I0901 23:29:42.940588 139752435963904 replay_runner.py:36] Average training steps per second: 203.90
I0901 23:29:43.277127 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.92
INFO:tensorflow:Starting iteration 3
I0901 23:29:47.474004 139752435963904 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 208.18

Steps executed: 1000 Episode length: 1000 Return: -244.17800710853746
I0901 23:29:54.483967 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.18
INFO:tensorflow:Starting iteration 4
I0901 23:29:58.785831 139752435963904 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 212.45

Steps executed: 1000 Episode length: 1000 Return: -290.68512624107314
I0901 23:30:06.682162 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.69
INFO:tensorflow:Starting iteration 5
I0901 23:30:10.778586 139752435963904 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 213.76

Steps executed: 567 Episode length: 567 Return: -338.2523934816504314
I0901 23:30:16.604118 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.25
INFO:tensorflow:Starting iteration 6
I0901 23:30:20.776332 139752435963904 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 217.18

Steps executed: 1000 Episode length: 1000 Return: -635.69791042932294
I0901 23:30:27.993557 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -635.70
INFO:tensorflow:Starting iteration 7

Steps executed: 811 Episode length: 811 Return: -428.3919673141678294
INFO:tensorflow:Average training steps per second: 232.89
I0901 23:30:36.625615 139752435963904 replay_runner.py:36] Average training steps per second: 232.89
I0901 23:30:38.348531 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -428.39
INFO:tensorflow:Starting iteration 8

Steps executed: 365 Episode length: 365 Return: -1033.482391237189294
INFO:tensorflow:Average training steps per second: 222.98
I0901 23:30:47.119068 139752435963904 replay_runner.py:36] Average training steps per second: 222.98
I0901 23:30:47.767109 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -1033.48
INFO:tensorflow:Starting iteration 9
I0901 23:30:52.293673 139752435963904 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 233.35

Steps executed: 233 Episode length: 233 Return: -528.6801216847288294
I0901 23:30:56.827790 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -528.68
INFO:tensorflow:Starting iteration 10

Steps executed: 326 Episode length: 326 Return: -480.8997763625426494
INFO:tensorflow:Average training steps per second: 220.88
I0901 23:31:05.338014 139752435963904 replay_runner.py:36] Average training steps per second: 220.88
I0901 23:31:05.745541 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -480.90
INFO:tensorflow:Starting iteration 11
I0901 23:31:09.946387 139752435963904 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 222.48

Steps executed: 674 Episode length: 487 Return: -38.07657308440628494
I0901 23:31:15.512927 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -354.79
INFO:tensorflow:Starting iteration 12
I0901 23:31:19.736205 139752435963904 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 209.26

Steps executed: 452 Episode length: 452 Return: -456.1552322642791494
I0901 23:31:25.317509 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -456.16
INFO:tensorflow:Starting iteration 13

Steps executed: 204 Episode length: 204 Return: 48.147560703378421494
INFO:tensorflow:Average training steps per second: 232.19
I0901 23:31:33.919741 139752435963904 replay_runner.py:36] Average training steps per second: 232.19
I0901 23:31:34.142570 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: 48.15
INFO:tensorflow:Starting iteration 14
I0901 23:31:38.533002 139752435963904 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 220.44

Steps executed: 1000 Episode length: 1000 Return: -120.63747893439877
I0901 23:31:46.007758 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.64
INFO:tensorflow:Starting iteration 15
I0901 23:31:50.256347 139752435963904 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 223.78

Steps executed: 571 Episode length: 571 Return: -297.6879959325778877
I0901 23:31:55.943001 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -297.69
INFO:tensorflow:Starting iteration 16
I0901 23:31:59.963577 139752435963904 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 231.04

Steps executed: 742 Episode length: 742 Return: -85.01167647256248877
I0901 23:32:06.391833 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.01
INFO:tensorflow:Starting iteration 17

Steps executed: 262 Episode length: 139 Return: -145.4580124788320777
INFO:tensorflow:Average training steps per second: 250.55
I0901 23:32:14.443059 139752435963904 replay_runner.py:36] Average training steps per second: 250.55
I0901 23:32:14.680214 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.27
INFO:tensorflow:Starting iteration 18
I0901 23:32:18.728594 139752435963904 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 258.69

Steps executed: 476 Episode length: 476 Return: -17.90152601374221377
I0901 23:32:23.539553 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -17.90
INFO:tensorflow:Starting iteration 19
I0901 23:32:27.889239 139752435963904 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 226.59

Steps executed: 729 Episode length: 729 Return: -115.7354466462891577
I0901 23:32:34.998275 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.74
INFO:tensorflow:Starting iteration 20
I0901 23:32:39.335500 139752435963904 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 227.30

Steps executed: 677 Episode length: 677 Return: -226.4643952457761677
I0901 23:32:45.274864 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.46
INFO:tensorflow:Starting iteration 21

Steps executed: 400 Episode length: 285 Return: -354.6620420280277677
INFO:tensorflow:Average training steps per second: 236.65
I0901 23:32:53.872686 139752435963904 replay_runner.py:36] Average training steps per second: 236.65
I0901 23:32:54.308592 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.62
INFO:tensorflow:Starting iteration 22
I0901 23:32:58.713900 139752435963904 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 231.49

Steps executed: 579 Episode length: 579 Return: 173.34444282303775677
I0901 23:33:04.145900 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: 173.34
INFO:tensorflow:Starting iteration 23
I0901 23:33:08.297054 139752435963904 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 229.87
I0901 23:33:12.647689 139752435963904 replay_runner.py:36] Average training steps per second: 229.87

Steps executed: 312 Episode length: 202 Return: -275.5828526398417577
INFO:tensorflow:Starting iteration 24

Steps executed: 308 Episode length: 140 Return: -85.17697850548875577
INFO:tensorflow:Average training steps per second: 225.54
I0901 23:33:21.733804 139752435963904 replay_runner.py:36] Average training steps per second: 225.54
I0901 23:33:22.036118 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.94
INFO:tensorflow:Starting iteration 25
I0901 23:33:26.307532 139752435963904 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 225.56

Steps executed: 1000 Episode length: 1000 Return: -19.462228220165304
I0901 23:33:34.643595 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -19.46
INFO:tensorflow:Starting iteration 26

Steps executed: 315 Episode length: 155 Return: -99.87771444977942304
INFO:tensorflow:Average training steps per second: 225.29
I0901 23:33:43.341923 139752435963904 replay_runner.py:36] Average training steps per second: 225.29
I0901 23:33:43.633950 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -48.05
INFO:tensorflow:Starting iteration 27

Steps executed: 223 Episode length: 223 Return: -213.5710236454199804
INFO:tensorflow:Average training steps per second: 229.26
I0901 23:33:52.390400 139752435963904 replay_runner.py:36] Average training steps per second: 229.26
I0901 23:33:52.650212 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.57
INFO:tensorflow:Starting iteration 28

Steps executed: 261 Episode length: 261 Return: 0.8321250634116959804
INFO:tensorflow:Average training steps per second: 225.39
I0901 23:34:01.465889 139752435963904 replay_runner.py:36] Average training steps per second: 225.39
I0901 23:34:01.783612 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: 0.83
INFO:tensorflow:Starting iteration 29

Steps executed: 385 Episode length: 201 Return: -104.0694674454092604
INFO:tensorflow:Average training steps per second: 226.88
I0901 23:34:10.487498 139752435963904 replay_runner.py:36] Average training steps per second: 226.88

Done fixed training!Episode length: 201 Return: -104.0694674454092604