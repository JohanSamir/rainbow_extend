I0902 23:30:21.792687 139900407642112 run_experiment.py:549] Creating TrainRunner ...
I0902 23:30:21.805319 139900407642112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:30:21.805711 139900407642112 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:30:21.805889 139900407642112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:30:21.805993 139900407642112 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:30:21.806139 139900407642112 dqn_agent.py:275] 	 update_period: 4
I0902 23:30:21.806233 139900407642112 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:30:21.806313 139900407642112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:30:21.806387 139900407642112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:30:21.806566 139900407642112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:30:21.806674 139900407642112 dqn_agent.py:280] 	 optimizer: adam
I0902 23:30:21.806772 139900407642112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:30:21.806886 139900407642112 dqn_agent.py:283] 	 seed: 1630625421805228
I0902 23:30:21.810320 139900407642112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:30:21.810473 139900407642112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:30:21.810562 139900407642112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:30:21.810648 139900407642112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:30:21.810708 139900407642112 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:30:21.810777 139900407642112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:30:21.810857 139900407642112 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:30:21.810955 139900407642112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:30:21.811050 139900407642112 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0902 23:30:23.697753 139900407642112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:24.098990 139900407642112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:24.115766 139900407642112 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:30:24.123834 139900407642112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:30:24.124054 139900407642112 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:30:24.124123 139900407642112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:30:24.124219 139900407642112 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:30:24.124281 139900407642112 dqn_agent.py:275] 	 update_period: 4
I0902 23:30:24.124391 139900407642112 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:30:24.124533 139900407642112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:30:24.124608 139900407642112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:30:24.124667 139900407642112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:30:24.124727 139900407642112 dqn_agent.py:280] 	 optimizer: adam
I0902 23:30:24.124784 139900407642112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:30:24.124877 139900407642112 dqn_agent.py:283] 	 seed: 1630625424123781
I0902 23:30:24.127523 139900407642112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:30:24.127846 139900407642112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:30:24.128030 139900407642112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:30:24.128178 139900407642112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:30:24.128289 139900407642112 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:30:24.128389 139900407642112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:30:24.128466 139900407642112 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:30:24.128838 139900407642112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:30:24.128993 139900407642112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:30:24.161155 139900407642112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:24.185128 139900407642112 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:30:24.185549 139900407642112 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 159.94
I0902 23:30:30.438832 139900407642112 replay_runner.py:36] Average training steps per second: 159.94
Steps executed: 325 Episode length: 134 Return: -414.5765492843593
I0902 23:30:31.749598 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -396.43
INFO:tensorflow:Starting iteration 1

Steps executed: 298 Episode length: 151 Return: -264.5273644554868
INFO:tensorflow:Average training steps per second: 219.65
I0902 23:30:40.625139 139900407642112 replay_runner.py:36] Average training steps per second: 219.65
I0902 23:30:40.912268 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -278.37
INFO:tensorflow:Starting iteration 2
I0902 23:30:45.139871 139900407642112 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 229.99

Steps executed: 513 Episode length: 380 Return: -342.69971775477942
I0902 23:30:50.129375 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.20
INFO:tensorflow:Starting iteration 3

Steps executed: 241 Episode length: 241 Return: -303.82926385929943
INFO:tensorflow:Average training steps per second: 236.70
I0902 23:30:58.637727 139900407642112 replay_runner.py:36] Average training steps per second: 236.70
I0902 23:30:58.913421 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.83
INFO:tensorflow:Starting iteration 4

Steps executed: 336 Episode length: 336 Return: -307.47931788833813
INFO:tensorflow:Average training steps per second: 229.39
I0902 23:31:07.647076 139900407642112 replay_runner.py:36] Average training steps per second: 229.39
I0902 23:31:08.099578 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.48
INFO:tensorflow:Starting iteration 5
I0902 23:31:12.390521 139900407642112 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 225.14

Steps executed: 570 Episode length: 570 Return: -573.78580866687963
I0902 23:31:18.235760 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -573.79
INFO:tensorflow:Starting iteration 6
I0902 23:31:22.335437 139900407642112 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 225.42

Steps executed: 621 Episode length: 621 Return: -576.93834444959913
I0902 23:31:27.880637 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -576.94
INFO:tensorflow:Starting iteration 7
I0902 23:31:31.992141 139900407642112 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 231.25

Steps executed: 587 Episode length: 587 Return: -174.13396053323592
I0902 23:31:37.799476 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.13
INFO:tensorflow:Starting iteration 8
I0902 23:31:42.041631 139900407642112 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 226.16

Steps executed: 1000 Episode length: 1000 Return: -246.91223978335375
I0902 23:31:50.360185 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -246.91
INFO:tensorflow:Starting iteration 9
I0902 23:31:54.618906 139900407642112 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 227.92

Steps executed: 1000 Episode length: 1000 Return: -294.92108892997385
I0902 23:32:03.163304 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -294.92
INFO:tensorflow:Starting iteration 10

Steps executed: 493 Episode length: 305 Return: -188.4006713562720885
INFO:tensorflow:Average training steps per second: 223.27
I0902 23:32:12.016417 139900407642112 replay_runner.py:36] Average training steps per second: 223.27
I0902 23:32:12.696500 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.89
INFO:tensorflow:Starting iteration 11
I0902 23:32:16.951321 139900407642112 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 225.16

Steps executed: 1000 Episode length: 1000 Return: -188.82271539148329
I0902 23:32:24.688863 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.82
INFO:tensorflow:Starting iteration 12
I0902 23:32:29.031773 139900407642112 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 219.61

Steps executed: 1000 Episode length: 1000 Return: -244.91466132803154
I0902 23:32:36.214974 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.91
INFO:tensorflow:Starting iteration 13
I0902 23:32:40.459573 139900407642112 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 223.39

Steps executed: 1000 Episode length: 1000 Return: -140.59371519440114
I0902 23:32:47.852802 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.59
INFO:tensorflow:Starting iteration 14
I0902 23:32:52.137288 139900407642112 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 222.38

Steps executed: 1000 Episode length: 1000 Return: -133.70837269439193
I0902 23:33:00.933141 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.71
INFO:tensorflow:Starting iteration 15
I0902 23:33:05.263537 139900407642112 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 226.77
I0902 23:33:09.673764 139900407642112 replay_runner.py:36] Average training steps per second: 226.77

Steps executed: 239 Episode length: 68 Return: -196.24264563699109893
INFO:tensorflow:Starting iteration 16
I0902 23:33:14.169385 139900407642112 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 230.27
I0902 23:33:18.512487 139900407642112 replay_runner.py:36] Average training steps per second: 230.27

Steps executed: 1000 Episode length: 1000 Return: -84.202053449618773
INFO:tensorflow:Starting iteration 17

Steps executed: 305 Episode length: 164 Return: -99.36313970964132773
INFO:tensorflow:Average training steps per second: 228.03
I0902 23:33:30.375796 139900407642112 replay_runner.py:36] Average training steps per second: 228.03
I0902 23:33:30.665835 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.62
INFO:tensorflow:Starting iteration 18

Steps executed: 70 Episode length: 70 Return: -123.599506719000732773
INFO:tensorflow:Average training steps per second: 223.48
I0902 23:33:39.564787 139900407642112 replay_runner.py:36] Average training steps per second: 223.48

Steps executed: 1070 Episode length: 1000 Return: -89.884702828440643
INFO:tensorflow:Starting iteration 19
I0902 23:33:48.490968 139900407642112 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 233.61

Steps executed: 1000 Episode length: 1000 Return: -162.63656988826233
I0902 23:33:56.045351 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.64
INFO:tensorflow:Starting iteration 20

Steps executed: 487 Episode length: 331 Return: -44.72500527052818333
INFO:tensorflow:Average training steps per second: 234.76
I0902 23:34:04.712945 139900407642112 replay_runner.py:36] Average training steps per second: 234.76
I0902 23:34:05.331731 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.35
INFO:tensorflow:Starting iteration 21

Steps executed: 148 Episode length: 148 Return: -271.9957495616908333
INFO:tensorflow:Average training steps per second: 227.79

Steps executed: 1148 Episode length: 1000 Return: -119.33909241015793
I0902 23:34:17.191262 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.67
INFO:tensorflow:Starting iteration 22

Steps executed: 137 Episode length: 137 Return: -69.90987755406093793
INFO:tensorflow:Average training steps per second: 237.07
I0902 23:34:25.717949 139900407642112 replay_runner.py:36] Average training steps per second: 237.07

Steps executed: 319 Episode length: 182 Return: -124.8742604329557793
INFO:tensorflow:Starting iteration 23

Steps executed: 292 Episode length: 148 Return: -105.4092469215703393
INFO:tensorflow:Average training steps per second: 234.99
I0902 23:34:34.636404 139900407642112 replay_runner.py:36] Average training steps per second: 234.99
I0902 23:34:34.875921 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.04
INFO:tensorflow:Starting iteration 24
I0902 23:34:39.100339 139900407642112 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 231.36
I0902 23:34:43.422921 139900407642112 replay_runner.py:36] Average training steps per second: 231.36

Steps executed: 1000 Episode length: 1000 Return: -50.859833976792693
INFO:tensorflow:Starting iteration 25

Steps executed: 343 Episode length: 343 Return: -364.1503018263632693
INFO:tensorflow:Average training steps per second: 226.46
I0902 23:34:55.107102 139900407642112 replay_runner.py:36] Average training steps per second: 226.46
I0902 23:34:55.537625 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.15
INFO:tensorflow:Starting iteration 26
I0902 23:34:59.899853 139900407642112 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 226.99

Steps executed: 316 Episode length: 316 Return: 243.90988078562562693
I0902 23:35:04.687490 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: 243.91
INFO:tensorflow:Starting iteration 27
I0902 23:35:09.000271 139900407642112 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 228.09

Steps executed: 1000 Episode length: 1000 Return: -47.937986379274136
I0902 23:35:16.674511 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -47.94
INFO:tensorflow:Starting iteration 28

Steps executed: 201 Episode length: 201 Return: 31.605636493169158136
INFO:tensorflow:Average training steps per second: 221.55
I0902 23:35:25.466048 139900407642112 replay_runner.py:36] Average training steps per second: 221.55
I0902 23:35:25.660258 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: 31.61
INFO:tensorflow:Starting iteration 29
I0902 23:35:29.972251 139900407642112 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 229.70

Steps executed: 1000 Episode length: 1000 Return: 41.0940863462861766

Done fixed training! Episode length: 1000 Return: 41.0940863462861766