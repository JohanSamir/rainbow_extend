I0828 10:46:46.938683 140455557396480 run_experiment.py:549] Creating TrainRunner ...
I0828 10:46:46.946201 140455557396480 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:46:46.946331 140455557396480 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:46:46.946411 140455557396480 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:46:46.946472 140455557396480 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:46:46.946526 140455557396480 dqn_agent.py:275] 	 update_period: 4
I0828 10:46:46.946608 140455557396480 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:46:46.946696 140455557396480 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:46:46.946768 140455557396480 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:46:46.946836 140455557396480 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:46:46.946888 140455557396480 dqn_agent.py:280] 	 optimizer: adam
I0828 10:46:46.946959 140455557396480 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:46:46.947022 140455557396480 dqn_agent.py:283] 	 seed: 1630147606946167
I0828 10:46:46.948672 140455557396480 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:46:46.948793 140455557396480 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:46:46.948868 140455557396480 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:46:46.948929 140455557396480 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:46:46.948984 140455557396480 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:46:46.949061 140455557396480 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:46:46.949140 140455557396480 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:46:46.949196 140455557396480 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:46:46.949267 140455557396480 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:46:46.973561 140455557396480 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:47.219968 140455557396480 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:47.227982 140455557396480 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:46:47.234196 140455557396480 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:46:47.234317 140455557396480 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:46:47.234394 140455557396480 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:46:47.234460 140455557396480 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:46:47.234524 140455557396480 dqn_agent.py:275] 	 update_period: 4
I0828 10:46:47.234605 140455557396480 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:46:47.234666 140455557396480 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:46:47.234781 140455557396480 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:46:47.234858 140455557396480 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:46:47.234925 140455557396480 dqn_agent.py:280] 	 optimizer: adam
I0828 10:46:47.234997 140455557396480 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:46:47.235070 140455557396480 dqn_agent.py:283] 	 seed: 1630147607234171
I0828 10:46:47.237154 140455557396480 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:46:47.237315 140455557396480 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:46:47.237410 140455557396480 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:46:47.237499 140455557396480 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:46:47.237629 140455557396480 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:46:47.237761 140455557396480 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:46:47.237904 140455557396480 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:46:47.237987 140455557396480 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:46:47.238107 140455557396480 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:46:47.257246 140455557396480 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:47.271525 140455557396480 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:46:47.271749 140455557396480 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 251.58
I0828 10:46:51.246860 140455557396480 replay_runner.py:36] Average training steps per second: 251.58
I0828 10:46:52.302567 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -419.20
Steps executed: 238 Episode length: 92 Return: -411.93942083293739
INFO:tensorflow:Starting iteration 1

Steps executed: 309 Episode length: 140 Return: 60.9171673224121264
INFO:tensorflow:Average training steps per second: 343.68
I0828 10:46:58.227050 140455557396480 replay_runner.py:36] Average training steps per second: 343.68
I0828 10:46:58.394997 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.57
INFO:tensorflow:Starting iteration 2

Steps executed: 306 Episode length: 306 Return: -387.34732356197867
INFO:tensorflow:Average training steps per second: 361.16
I0828 10:47:04.346151 140455557396480 replay_runner.py:36] Average training steps per second: 361.16
I0828 10:47:04.644054 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -387.35
INFO:tensorflow:Starting iteration 3

Steps executed: 633 Episode length: 633 Return: -423.40567464266617
INFO:tensorflow:Average training steps per second: 340.36
I0828 10:47:10.958446 140455557396480 replay_runner.py:36] Average training steps per second: 340.36
I0828 10:47:11.800261 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -423.41
INFO:tensorflow:Starting iteration 4

Steps executed: 551 Episode length: 551 Return: -334.13648906318036
INFO:tensorflow:Average training steps per second: 338.18
I0828 10:47:18.163511 140455557396480 replay_runner.py:36] Average training steps per second: 338.18
I0828 10:47:18.772006 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -334.14
INFO:tensorflow:Starting iteration 5
I0828 10:47:22.184608 140455557396480 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 350.93

Steps executed: 1000 Episode length: 1000 Return: -260.38172787943927
I0828 10:47:26.947986 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.38
INFO:tensorflow:Starting iteration 6

Steps executed: 379 Episode length: 379 Return: -282.0350873426191427
INFO:tensorflow:Average training steps per second: 344.81
I0828 10:47:33.210753 140455557396480 replay_runner.py:36] Average training steps per second: 344.81
I0828 10:47:33.556058 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -282.04
INFO:tensorflow:Starting iteration 7
I0828 10:47:36.957152 140455557396480 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 344.41

Steps executed: 889 Episode length: 889 Return: -1296.820422077437427
I0828 10:47:41.212235 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -1296.82
INFO:tensorflow:Starting iteration 8
I0828 10:47:44.584594 140455557396480 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 342.91

Steps executed: 1000 Episode length: 1000 Return: -200.39530018692432
I0828 10:47:49.920550 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.40
INFO:tensorflow:Starting iteration 9
I0828 10:47:53.369569 140455557396480 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 359.99

Steps executed: 911 Episode length: 911 Return: -445.1304203931465532
I0828 10:47:57.125275 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -445.13
INFO:tensorflow:Starting iteration 10

Steps executed: 347 Episode length: 347 Return: -744.7360252472711532
INFO:tensorflow:Average training steps per second: 350.83
I0828 10:48:03.429792 140455557396480 replay_runner.py:36] Average training steps per second: 350.83
I0828 10:48:03.779656 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -744.74
INFO:tensorflow:Starting iteration 11

Steps executed: 316 Episode length: 144 Return: -718.3242019157367632
INFO:tensorflow:Average training steps per second: 329.48
I0828 10:48:10.193911 140455557396480 replay_runner.py:36] Average training steps per second: 329.48
I0828 10:48:10.393851 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -860.02
INFO:tensorflow:Starting iteration 12
I0828 10:48:13.558514 140455557396480 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 322.58
I0828 10:48:16.658824 140455557396480 replay_runner.py:36] Average training steps per second: 322.58

Steps executed: 216 Episode length: 216 Return: -534.5406890558373632
INFO:tensorflow:Starting iteration 13
I0828 10:48:20.057164 140455557396480 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 335.23

Steps executed: 379 Episode length: 379 Return: -280.2051744881612632
I0828 10:48:23.496058 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.21
INFO:tensorflow:Starting iteration 14

Steps executed: 66 Episode length: 66 Return: -68.7839759593297512632
INFO:tensorflow:Average training steps per second: 341.86

Steps executed: 1066 Episode length: 1000 Return: -107.35386679143534
I0828 10:48:31.330387 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.07
INFO:tensorflow:Starting iteration 15
I0828 10:48:34.670773 140455557396480 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 347.60

Steps executed: 1000 Episode length: 1000 Return: -166.10250619799052
I0828 10:48:39.097280 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.10
INFO:tensorflow:Starting iteration 16

Steps executed: 432 Episode length: 432 Return: -479.5783322442145552
INFO:tensorflow:Average training steps per second: 340.43
I0828 10:48:45.414504 140455557396480 replay_runner.py:36] Average training steps per second: 340.43
I0828 10:48:45.920040 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -479.58
INFO:tensorflow:Starting iteration 17
I0828 10:48:49.298153 140455557396480 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 363.77

Steps executed: 1000 Episode length: 1000 Return: -127.56737551058562
I0828 10:48:54.668761 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.57
INFO:tensorflow:Starting iteration 18

Steps executed: 84 Episode length: 84 Return: -101.715590540462148562
INFO:tensorflow:Average training steps per second: 325.91

Steps executed: 221 Episode length: 137 Return: -128.7233829202713562
I0828 10:49:01.015001 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.22
INFO:tensorflow:Starting iteration 19
I0828 10:49:04.221731 140455557396480 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 381.05

Steps executed: 1000 Episode length: 1000 Return: 21.0465296042352962
I0828 10:49:09.934494 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: 21.05
INFO:tensorflow:Starting iteration 20
I0828 10:49:12.902607 140455557396480 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 323.60

Steps executed: 779 Episode length: 779 Return: -128.6008362689180262
I0828 10:49:17.132612 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.60
INFO:tensorflow:Starting iteration 21

Steps executed: 206 Episode length: 206 Return: 2.2996877681872830262
INFO:tensorflow:Average training steps per second: 325.09
I0828 10:49:23.278481 140455557396480 replay_runner.py:36] Average training steps per second: 325.09
I0828 10:49:23.458332 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: 2.30
INFO:tensorflow:Starting iteration 22

Steps executed: 401 Episode length: 401 Return: -30.86580258170624862
INFO:tensorflow:Average training steps per second: 332.08
I0828 10:49:29.672873 140455557396480 replay_runner.py:36] Average training steps per second: 332.08
I0828 10:49:30.202562 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -30.87
INFO:tensorflow:Starting iteration 23

Steps executed: 291 Episode length: 291 Return: -69.72351750137767862
INFO:tensorflow:Average training steps per second: 323.65
I0828 10:49:36.576354 140455557396480 replay_runner.py:36] Average training steps per second: 323.65
I0828 10:49:36.830137 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.72
INFO:tensorflow:Starting iteration 24

Steps executed: 123 Episode length: 123 Return: -768.1868915022839862
INFO:tensorflow:Average training steps per second: 333.17

Steps executed: 328 Episode length: 205 Return: -33.07854484815523862
I0828 10:49:43.282102 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.63
INFO:tensorflow:Starting iteration 25

Steps executed: 578 Episode length: 578 Return: 198.17095212027093862
INFO:tensorflow:Average training steps per second: 341.01
I0828 10:49:49.543625 140455557396480 replay_runner.py:36] Average training steps per second: 341.01
I0828 10:49:50.492131 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: 198.17
INFO:tensorflow:Starting iteration 26

Steps executed: 340 Episode length: 340 Return: 273.14284680006074862
INFO:tensorflow:Average training steps per second: 328.41
I0828 10:49:56.832234 140455557396480 replay_runner.py:36] Average training steps per second: 328.41
I0828 10:49:57.174816 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: 273.14
INFO:tensorflow:Starting iteration 27

Steps executed: 326 Episode length: 187 Return: 259.04305031260883862
INFO:tensorflow:Average training steps per second: 320.95
I0828 10:50:03.465569 140455557396480 replay_runner.py:36] Average training steps per second: 320.95
I0828 10:50:03.690655 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: 105.51
INFO:tensorflow:Starting iteration 28

Steps executed: 277 Episode length: 87 Return: -171.05948392291566862
INFO:tensorflow:Average training steps per second: 326.24
I0828 10:50:09.969113 140455557396480 replay_runner.py:36] Average training steps per second: 326.24
I0828 10:50:10.149386 140455557396480 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.71
INFO:tensorflow:Starting iteration 29
I0828 10:50:13.468036 140455557396480 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 338.75

Steps executed: 1000 Episode length: 1000 Return: 14.6777989185621982

Done fixed training! Episode length: 1000 Return: 14.6777989185621982