Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0905 16:37:54.130778 140202555004928 run_experiment.py:549] Creating TrainRunner ...
I0905 16:37:54.138843 140202555004928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:37:54.138967 140202555004928 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:37:54.139042 140202555004928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:37:54.139102 140202555004928 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:37:54.139158 140202555004928 dqn_agent.py:275] 	 update_period: 4
I0905 16:37:54.139232 140202555004928 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:37:54.139366 140202555004928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:37:54.139469 140202555004928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:37:54.139552 140202555004928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:37:54.139642 140202555004928 dqn_agent.py:280] 	 optimizer: adam
I0905 16:37:54.139717 140202555004928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:37:54.139808 140202555004928 dqn_agent.py:283] 	 seed: 1630859874138813
I0905 16:37:54.141664 140202555004928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:37:54.141778 140202555004928 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:37:54.141857 140202555004928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:37:54.141920 140202555004928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:37:54.141974 140202555004928 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:37:54.142048 140202555004928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:37:54.142143 140202555004928 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:37:54.142244 140202555004928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:37:54.142357 140202555004928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:37:55.322714 140202555004928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:37:55.548746 140202555004928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:37:55.557507 140202555004928 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:37:55.564877 140202555004928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:37:55.565007 140202555004928 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:37:55.565169 140202555004928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:37:55.565343 140202555004928 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:37:55.565429 140202555004928 dqn_agent.py:275] 	 update_period: 4
I0905 16:37:55.565585 140202555004928 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:37:55.565678 140202555004928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:37:55.565806 140202555004928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:37:55.565897 140202555004928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:37:55.565976 140202555004928 dqn_agent.py:280] 	 optimizer: adam
I0905 16:37:55.566064 140202555004928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:37:55.566175 140202555004928 dqn_agent.py:283] 	 seed: 1630859875564836
I0905 16:37:55.568072 140202555004928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:37:55.568187 140202555004928 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:37:55.568261 140202555004928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:37:55.568338 140202555004928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:37:55.568397 140202555004928 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:37:55.568469 140202555004928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:37:55.568530 140202555004928 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:37:55.568609 140202555004928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:37:55.568672 140202555004928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:37:55.588234 140202555004928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:37:55.601143 140202555004928 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:37:55.601286 140202555004928 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 293.94
I0905 16:37:59.003536 140202555004928 replay_runner.py:36] Average training steps per second: 293.94
I0905 16:37:59.668321 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.70
Steps executed: 210 Episode length: 86 Return: -431.3305207135108
INFO:tensorflow:Starting iteration 1

Steps executed: 271 Episode length: 107 Return: -334.71725905829805
INFO:tensorflow:Average training steps per second: 388.51
I0905 16:38:05.315672 140202555004928 replay_runner.py:36] Average training steps per second: 388.51
I0905 16:38:05.449225 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -372.21
INFO:tensorflow:Starting iteration 2

Steps executed: 245 Episode length: 122 Return: -414.68178314219836
INFO:tensorflow:Average training steps per second: 368.42
I0905 16:38:11.257738 140202555004928 replay_runner.py:36] Average training steps per second: 368.42
I0905 16:38:11.382961 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.93
INFO:tensorflow:Starting iteration 3

Steps executed: 421 Episode length: 421 Return: 231.565041118074026
INFO:tensorflow:Average training steps per second: 356.01
I0905 16:38:17.164835 140202555004928 replay_runner.py:36] Average training steps per second: 356.01
I0905 16:38:17.713802 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: 231.57
INFO:tensorflow:Starting iteration 4
I0905 16:38:20.674943 140202555004928 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 339.28

Steps executed: 1000 Episode length: 1000 Return: -230.98272926679653
I0905 16:38:25.503904 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.98
INFO:tensorflow:Starting iteration 5
I0905 16:38:28.808681 140202555004928 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 335.04

Steps executed: 1000 Episode length: 1000 Return: -101.70188585185423
I0905 16:38:33.299031 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.70
INFO:tensorflow:Starting iteration 6

Steps executed: 311 Episode length: 311 Return: -348.3243937604860323
INFO:tensorflow:Average training steps per second: 331.26
I0905 16:38:39.665688 140202555004928 replay_runner.py:36] Average training steps per second: 331.26
I0905 16:38:39.905158 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -348.32
INFO:tensorflow:Starting iteration 7

Steps executed: 1000 Episode length: 1000 Return: -73.250376389182533
INFO:tensorflow:Average training steps per second: 342.92
I0905 16:38:46.151153 140202555004928 replay_runner.py:36] Average training steps per second: 342.92
I0905 16:38:47.571202 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.25
INFO:tensorflow:Starting iteration 8
I0905 16:38:50.954380 140202555004928 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 344.99

Steps executed: 1000 Episode length: 1000 Return: -119.82318715540733
I0905 16:38:55.755696 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.82
INFO:tensorflow:Starting iteration 9
I0905 16:38:59.260051 140202555004928 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 371.96
I0905 16:39:01.948818 140202555004928 replay_runner.py:36] Average training steps per second: 371.96

Steps executed: 1000 Episode length: 1000 Return: -136.14028575070213
INFO:tensorflow:Starting iteration 10

Steps executed: 1000 Episode length: 1000 Return: -118.00086036601138
INFO:tensorflow:Average training steps per second: 359.26
I0905 16:39:10.290255 140202555004928 replay_runner.py:36] Average training steps per second: 359.26
I0905 16:39:12.073203 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.00
INFO:tensorflow:Starting iteration 11

Steps executed: 642 Episode length: 642 Return: -237.3943172223834238
INFO:tensorflow:Average training steps per second: 355.01
I0905 16:39:18.333593 140202555004928 replay_runner.py:36] Average training steps per second: 355.01
I0905 16:39:19.084623 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.39
INFO:tensorflow:Starting iteration 12
I0905 16:39:22.421432 140202555004928 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 331.83

Steps executed: 1000 Episode length: 1000 Return: -98.953639586049628
I0905 16:39:26.772945 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.95
INFO:tensorflow:Starting iteration 13
I0905 16:39:30.053063 140202555004928 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 327.13

Steps executed: 1000 Episode length: 1000 Return: -91.734519969479788
I0905 16:39:34.791061 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.73
INFO:tensorflow:Starting iteration 14
I0905 16:39:38.152719 140202555004928 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 338.75

Steps executed: 1000 Episode length: 1000 Return: -213.59226099464456
I0905 16:39:42.834245 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.59
INFO:tensorflow:Starting iteration 15

Steps executed: 494 Episode length: 494 Return: -70.33010273878477456
INFO:tensorflow:Average training steps per second: 351.53
I0905 16:39:49.063554 140202555004928 replay_runner.py:36] Average training steps per second: 351.53
I0905 16:39:49.660454 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.33
INFO:tensorflow:Starting iteration 16

Steps executed: 274 Episode length: 274 Return: -268.4509507521725656
INFO:tensorflow:Average training steps per second: 340.98
I0905 16:39:55.979017 140202555004928 replay_runner.py:36] Average training steps per second: 340.98
I0905 16:39:56.182532 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.45
INFO:tensorflow:Starting iteration 17

Steps executed: 337 Episode length: 220 Return: -122.6448700040101756
INFO:tensorflow:Average training steps per second: 337.49
I0905 16:40:02.469356 140202555004928 replay_runner.py:36] Average training steps per second: 337.49
I0905 16:40:02.700205 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -321.87
INFO:tensorflow:Starting iteration 18

Steps executed: 348 Episode length: 176 Return: 13.973156672352331756
INFO:tensorflow:Average training steps per second: 339.94
I0905 16:40:08.962454 140202555004928 replay_runner.py:36] Average training steps per second: 339.94
I0905 16:40:09.173129 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.29
INFO:tensorflow:Starting iteration 19

Steps executed: 243 Episode length: 243 Return: -276.0490368642147756
INFO:tensorflow:Average training steps per second: 349.75
I0905 16:40:15.398849 140202555004928 replay_runner.py:36] Average training steps per second: 349.75
I0905 16:40:15.591234 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.05
INFO:tensorflow:Starting iteration 20

Steps executed: 216 Episode length: 216 Return: -130.7908121188457456
INFO:tensorflow:Average training steps per second: 352.36
I0905 16:40:21.721620 140202555004928 replay_runner.py:36] Average training steps per second: 352.36
I0905 16:40:21.887192 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.79
INFO:tensorflow:Starting iteration 21
I0905 16:40:25.283775 140202555004928 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 358.01
I0905 16:40:28.077567 140202555004928 replay_runner.py:36] Average training steps per second: 358.01

Steps executed: 354 Episode length: 354 Return: 249.13914500482847456
INFO:tensorflow:Starting iteration 22

Steps executed: 334 Episode length: 147 Return: -106.0423794471658156
INFO:tensorflow:Average training steps per second: 351.38
I0905 16:40:34.813059 140202555004928 replay_runner.py:36] Average training steps per second: 351.38
I0905 16:40:35.012364 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.15
INFO:tensorflow:Starting iteration 23

Steps executed: 503 Episode length: 353 Return: -319.9482777896484156
INFO:tensorflow:Average training steps per second: 348.12
I0905 16:40:41.420964 140202555004928 replay_runner.py:36] Average training steps per second: 348.12
I0905 16:40:41.899445 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.21
INFO:tensorflow:Starting iteration 24
I0905 16:40:45.378973 140202555004928 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 354.18

Steps executed: 134 Episode length: 134 Return: -354.0110159718708556

Steps executed: 1134 Episode length: 1000 Return: -28.836316655947012
INFO:tensorflow:Starting iteration 25
I0905 16:40:54.024980 140202555004928 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 375.69

Steps executed: 270 Episode length: 146 Return: -161.0004012027163212
I0905 16:40:56.888009 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.72
INFO:tensorflow:Starting iteration 26

Steps executed: 312 Episode length: 151 Return: -259.8249710648415212
INFO:tensorflow:Average training steps per second: 390.60
I0905 16:41:02.976376 140202555004928 replay_runner.py:36] Average training steps per second: 390.60
I0905 16:41:03.136908 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.74
INFO:tensorflow:Starting iteration 27

Steps executed: 230 Episode length: 107 Return: -150.5072960905016212
INFO:tensorflow:Average training steps per second: 360.71
I0905 16:41:09.386218 140202555004928 replay_runner.py:36] Average training steps per second: 360.71
I0905 16:41:09.508692 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.15
INFO:tensorflow:Starting iteration 28

Steps executed: 214 Episode length: 214 Return: -51.03661879165256212
INFO:tensorflow:Average training steps per second: 331.08
I0905 16:41:15.880037 140202555004928 replay_runner.py:36] Average training steps per second: 331.08
I0905 16:41:16.038803 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -51.04
INFO:tensorflow:Starting iteration 29
I0905 16:41:19.321155 140202555004928 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 339.73

Steps executed: 215 Episode length: 81 Return: -184.90000314703963512

Done fixed training!Episode length: 81 Return: -184.90000314703963512