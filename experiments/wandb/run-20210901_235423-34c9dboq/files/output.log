Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0901 23:54:29.590007 139752435963904 run_experiment.py:549] Creating TrainRunner ...
I0901 23:54:29.602434 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:54:29.602745 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:54:29.602904 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:54:29.603054 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:54:29.603199 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0901 23:54:29.603291 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:54:29.603416 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:54:29.603539 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:54:29.603621 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:54:29.603687 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0901 23:54:29.603750 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:54:29.603813 139752435963904 dqn_agent.py:283] 	 seed: 1630540469602353
I0901 23:54:29.606331 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:54:29.606565 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:54:29.606747 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:54:29.606988 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:54:29.607099 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:54:29.607433 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:54:29.607583 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:54:29.607666 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:54:29.607738 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:54:29.647992 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:30.031119 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:30.046046 139752435963904 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:54:30.055034 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:54:30.055283 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:54:30.055395 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:54:30.055478 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:54:30.055611 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0901 23:54:30.055742 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:54:30.055933 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:54:30.056030 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:54:30.056111 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:54:30.056231 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0901 23:54:30.056415 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:54:30.056518 139752435963904 dqn_agent.py:283] 	 seed: 1630540470054961
I0901 23:54:30.058950 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:54:30.059149 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:54:30.059474 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:54:30.059663 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:54:30.059849 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:54:30.060006 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:54:30.060225 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:54:30.060444 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:54:30.060581 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:54:30.133117 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:30.157296 139752435963904 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:54:30.157595 139752435963904 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 163.39
I0901 23:54:36.278674 139752435963904 replay_runner.py:36] Average training steps per second: 163.39
Steps executed: 325 Episode length: 325 Return: -79.52029457549621
I0901 23:54:37.666984 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.52
INFO:tensorflow:Starting iteration 1

Steps executed: 304 Episode length: 144 Return: -257.63539990734745
INFO:tensorflow:Average training steps per second: 224.08
I0901 23:54:46.381274 139752435963904 replay_runner.py:36] Average training steps per second: 224.08
I0901 23:54:46.651060 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.85
INFO:tensorflow:Starting iteration 2

Steps executed: 231 Episode length: 121 Return: -217.20337469831926
INFO:tensorflow:Average training steps per second: 225.36
I0901 23:54:55.386292 139752435963904 replay_runner.py:36] Average training steps per second: 225.36
I0901 23:54:55.570255 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -267.41
INFO:tensorflow:Starting iteration 3
I0901 23:54:59.935628 139752435963904 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 223.14

Steps executed: 776 Episode length: 776 Return: -360.96746993332624
I0901 23:55:06.277565 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -360.97
INFO:tensorflow:Starting iteration 4
I0901 23:55:10.811936 139752435963904 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 223.93

Steps executed: 1000 Episode length: 1000 Return: -151.1777251008836
I0901 23:55:18.064671 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.18
INFO:tensorflow:Starting iteration 5
I0901 23:55:22.438833 139752435963904 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 222.48
I0901 23:55:26.933984 139752435963904 replay_runner.py:36] Average training steps per second: 222.48

Steps executed: 1000 Episode length: 1000 Return: -65.25965789408953
INFO:tensorflow:Starting iteration 6
I0901 23:55:33.826164 139752435963904 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 216.30

Steps executed: 421 Episode length: 421 Return: -228.611785899349973
I0901 23:55:39.077421 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.61
INFO:tensorflow:Starting iteration 7

Steps executed: 522 Episode length: 522 Return: -348.349272316318873
INFO:tensorflow:Average training steps per second: 223.31
I0901 23:55:47.978515 139752435963904 replay_runner.py:36] Average training steps per second: 223.31
I0901 23:55:48.740668 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -348.35
INFO:tensorflow:Starting iteration 8
I0901 23:55:52.996002 139752435963904 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 222.81

Steps executed: 673 Episode length: 673 Return: -410.183964031801053
I0901 23:55:59.357958 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -410.18
INFO:tensorflow:Starting iteration 9

Steps executed: 497 Episode length: 343 Return: -489.823843121486853
INFO:tensorflow:Average training steps per second: 222.61
I0901 23:56:07.994286 139752435963904 replay_runner.py:36] Average training steps per second: 222.61
I0901 23:56:08.676605 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -679.76
INFO:tensorflow:Starting iteration 10
I0901 23:56:12.897865 139752435963904 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 233.31

Steps executed: 1000 Episode length: 1000 Return: -154.16462413427777
I0901 23:56:21.399080 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.16
INFO:tensorflow:Starting iteration 11
I0901 23:56:25.748733 139752435963904 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 224.00

Steps executed: 1000 Episode length: 1000 Return: -209.42340942186723
I0901 23:56:33.978440 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.42
INFO:tensorflow:Starting iteration 12
I0901 23:56:38.331790 139752435963904 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 231.03

Steps executed: 1000 Episode length: 1000 Return: -117.44052747501291
I0901 23:56:45.070618 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.44
INFO:tensorflow:Starting iteration 13
I0901 23:56:49.299841 139752435963904 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 228.79

Steps executed: 347 Episode length: 347 Return: -229.4445529512108591
I0901 23:56:54.099631 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.44
INFO:tensorflow:Starting iteration 14

Steps executed: 247 Episode length: 247 Return: -198.2911288302608591
INFO:tensorflow:Average training steps per second: 224.47
I0901 23:57:02.791845 139752435963904 replay_runner.py:36] Average training steps per second: 224.47
I0901 23:57:03.078686 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.29
INFO:tensorflow:Starting iteration 15
I0901 23:57:07.258275 139752435963904 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 222.19
I0901 23:57:11.759453 139752435963904 replay_runner.py:36] Average training steps per second: 222.19

Steps executed: 235 Episode length: 235 Return: -145.0765241540185591
INFO:tensorflow:Starting iteration 16

Steps executed: 311 Episode length: 158 Return: -142.7845067302276891
INFO:tensorflow:Average training steps per second: 232.50
I0901 23:57:20.512369 139752435963904 replay_runner.py:36] Average training steps per second: 232.50
I0901 23:57:20.784799 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.76
INFO:tensorflow:Starting iteration 17

Steps executed: 208 Episode length: 208 Return: -505.3195082197084891
INFO:tensorflow:Average training steps per second: 237.58
I0901 23:57:29.410478 139752435963904 replay_runner.py:36] Average training steps per second: 237.58
I0901 23:57:29.627714 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -505.32
INFO:tensorflow:Starting iteration 18

Steps executed: 394 Episode length: 206 Return: -483.2489595018089891
INFO:tensorflow:Average training steps per second: 222.62
I0901 23:57:38.511095 139752435963904 replay_runner.py:36] Average training steps per second: 222.62
I0901 23:57:38.877614 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.01
INFO:tensorflow:Starting iteration 19

Steps executed: 441 Episode length: 253 Return: -240.4132685453285591
INFO:tensorflow:Average training steps per second: 229.22
I0901 23:57:47.611037 139752435963904 replay_runner.py:36] Average training steps per second: 229.22
I0901 23:57:48.036869 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.66
INFO:tensorflow:Starting iteration 20

Steps executed: 387 Episode length: 205 Return: -248.9825562176288891
INFO:tensorflow:Average training steps per second: 235.36
I0901 23:57:56.683911 139752435963904 replay_runner.py:36] Average training steps per second: 235.36
I0901 23:57:57.131137 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.08
INFO:tensorflow:Starting iteration 21

Steps executed: 99 Episode length: 99 Return: -530.590997240431188891
INFO:tensorflow:Average training steps per second: 222.06
I0901 23:58:06.036429 139752435963904 replay_runner.py:36] Average training steps per second: 222.06

Steps executed: 279 Episode length: 180 Return: -407.5317748798117891
INFO:tensorflow:Starting iteration 22

Steps executed: 217 Episode length: 154 Return: -135.0716034998213891
INFO:tensorflow:Average training steps per second: 230.52
I0901 23:58:15.095885 139752435963904 replay_runner.py:36] Average training steps per second: 230.52
I0901 23:58:15.272948 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.43
INFO:tensorflow:Starting iteration 23

Steps executed: 205 Episode length: 63 Return: -130.72990066733473291
INFO:tensorflow:Average training steps per second: 226.32
I0901 23:58:24.050307 139752435963904 replay_runner.py:36] Average training steps per second: 226.32
I0901 23:58:24.213253 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.89
INFO:tensorflow:Starting iteration 24

Steps executed: 208 Episode length: 103 Return: -282.0406838329761691
INFO:tensorflow:Average training steps per second: 232.15
I0901 23:58:32.966699 139752435963904 replay_runner.py:36] Average training steps per second: 232.15
I0901 23:58:33.143626 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.12
INFO:tensorflow:Starting iteration 25
I0901 23:58:37.600014 139752435963904 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 223.40
I0901 23:58:42.076672 139752435963904 replay_runner.py:36] Average training steps per second: 223.40

Steps executed: 252 Episode length: 118 Return: -186.9244604792753691
INFO:tensorflow:Starting iteration 26

Steps executed: 229 Episode length: 89 Return: -445.30783031238473691
INFO:tensorflow:Average training steps per second: 227.89
I0901 23:58:50.964616 139752435963904 replay_runner.py:36] Average training steps per second: 227.89
I0901 23:58:51.144327 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -241.69
INFO:tensorflow:Starting iteration 27

Steps executed: 129 Episode length: 129 Return: -535.6084668015776691
INFO:tensorflow:Average training steps per second: 225.63
I0901 23:58:59.827595 139752435963904 replay_runner.py:36] Average training steps per second: 225.63

Steps executed: 302 Episode length: 173 Return: -138.4228442384980491
INFO:tensorflow:Starting iteration 28

Steps executed: 359 Episode length: 163 Return: -586.6688065088866491
INFO:tensorflow:Average training steps per second: 228.45
I0901 23:59:08.830583 139752435963904 replay_runner.py:36] Average training steps per second: 228.45
I0901 23:59:09.164872 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -595.48
INFO:tensorflow:Starting iteration 29
I0901 23:59:13.489187 139752435963904 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 225.03

Steps executed: 277 Episode length: 104 Return: -473.6723472743506491

Done fixed training!Episode length: 104 Return: -473.6723472743506491