I0901 23:49:30.262037 140053067847680 run_experiment.py:549] Creating TrainRunner ...
I0901 23:49:30.273777 140053067847680 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:30.274072 140053067847680 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:30.274246 140053067847680 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:30.274392 140053067847680 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:30.274506 140053067847680 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:30.274822 140053067847680 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:30.275004 140053067847680 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:30.275150 140053067847680 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:30.275489 140053067847680 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:30.275645 140053067847680 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:30.275789 140053067847680 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:30.275937 140053067847680 dqn_agent.py:283] 	 seed: 1630540170273707
I0901 23:49:30.279218 140053067847680 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:30.279415 140053067847680 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:30.279611 140053067847680 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:30.279754 140053067847680 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:30.279885 140053067847680 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:30.280054 140053067847680 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:30.280177 140053067847680 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:30.280291 140053067847680 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:30.280408 140053067847680 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0901 23:49:32.160786 140053067847680 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:32.574070 140053067847680 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:32.589643 140053067847680 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:49:32.599375 140053067847680 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:32.599637 140053067847680 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:32.599795 140053067847680 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:32.599935 140053067847680 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:32.600053 140053067847680 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:32.600204 140053067847680 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:32.600341 140053067847680 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:32.600588 140053067847680 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:32.600901 140053067847680 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:32.601204 140053067847680 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:32.601359 140053067847680 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:32.601588 140053067847680 dqn_agent.py:283] 	 seed: 1630540172599317
I0901 23:49:32.604279 140053067847680 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:32.604493 140053067847680 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:32.604675 140053067847680 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:32.604847 140053067847680 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:32.604990 140053067847680 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:32.605154 140053067847680 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:32.605356 140053067847680 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:32.605492 140053067847680 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:32.605721 140053067847680 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:49:32.637832 140053067847680 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:32.661405 140053067847680 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:49:32.661754 140053067847680 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 160.97
I0901 23:49:38.874433 140053067847680 replay_runner.py:36] Average training steps per second: 160.97
Steps executed: 209 Episode length: 88 Return: -495.38095260282415
I0901 23:49:40.084883 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -520.56
INFO:tensorflow:Starting iteration 1

Steps executed: 228 Episode length: 103 Return: -391.5182232669584
INFO:tensorflow:Average training steps per second: 218.83
I0901 23:49:48.945905 140053067847680 replay_runner.py:36] Average training steps per second: 218.83
I0901 23:49:49.146162 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -347.83
INFO:tensorflow:Starting iteration 2

Steps executed: 201 Episode length: 201 Return: -198.23704626386564
INFO:tensorflow:Average training steps per second: 225.14
I0901 23:49:58.044041 140053067847680 replay_runner.py:36] Average training steps per second: 225.14
I0901 23:49:58.261878 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.24
INFO:tensorflow:Starting iteration 3
I0901 23:50:02.552660 140053067847680 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 224.09

Steps executed: 1000 Episode length: 1000 Return: -260.87973254391517
I0901 23:50:09.970876 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.88
INFO:tensorflow:Starting iteration 4
I0901 23:50:14.099388 140053067847680 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 222.36

Steps executed: 778 Episode length: 778 Return: -351.6984579902467717
I0901 23:50:20.949362 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -351.70
INFO:tensorflow:Starting iteration 5
I0901 23:50:25.305614 140053067847680 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 223.29

Steps executed: 1000 Episode length: 1000 Return: -177.58030066093257
I0901 23:50:33.272444 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.58
INFO:tensorflow:Starting iteration 6
I0901 23:50:37.566880 140053067847680 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 244.34

Steps executed: 1000 Episode length: 1000 Return: -130.81510044614527
I0901 23:50:46.052240 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.82
INFO:tensorflow:Starting iteration 7
I0901 23:50:50.124886 140053067847680 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 239.84

Steps executed: 742 Episode length: 742 Return: -201.5477457241792427
I0901 23:50:55.715831 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.55
INFO:tensorflow:Starting iteration 8
I0901 23:51:00.042088 140053067847680 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 231.86

Steps executed: 434 Episode length: 434 Return: -642.3280763624728427
I0901 23:51:04.899075 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -642.33
INFO:tensorflow:Starting iteration 9
I0901 23:51:09.341653 140053067847680 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 228.95

Steps executed: 819 Episode length: 819 Return: -539.4751175152209427
I0901 23:51:16.076461 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -539.48
INFO:tensorflow:Starting iteration 10
I0901 23:51:20.482378 140053067847680 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 221.47

Steps executed: 1000 Episode length: 1000 Return: -228.23084913868013
I0901 23:51:27.924000 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.23
INFO:tensorflow:Starting iteration 11

Steps executed: 421 Episode length: 421 Return: -521.1379468874334013
INFO:tensorflow:Average training steps per second: 218.21
I0901 23:51:36.969873 140053067847680 replay_runner.py:36] Average training steps per second: 218.21
I0901 23:51:37.747910 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -521.14
INFO:tensorflow:Starting iteration 12

Steps executed: 130 Episode length: 130 Return: -100.7511089786279013
INFO:tensorflow:Average training steps per second: 223.74

Steps executed: 1130 Episode length: 1000 Return: -120.48749086211464
I0901 23:51:49.981707 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.62
INFO:tensorflow:Starting iteration 13
I0901 23:51:54.193621 140053067847680 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 219.20

Steps executed: 1000 Episode length: 1000 Return: -129.05906009313097
I0901 23:52:01.454274 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.06
INFO:tensorflow:Starting iteration 14
I0901 23:52:05.743603 140053067847680 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 216.75

Steps executed: 1000 Episode length: 1000 Return: -115.82775707764897
I0901 23:52:13.439310 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.83
INFO:tensorflow:Starting iteration 15
I0901 23:52:17.789245 140053067847680 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 215.57
I0901 23:52:22.428712 140053067847680 replay_runner.py:36] Average training steps per second: 215.57

Steps executed: 1000 Episode length: 1000 Return: -73.081492272652387
INFO:tensorflow:Starting iteration 16

Steps executed: 314 Episode length: 314 Return: -305.8223306358574487
INFO:tensorflow:Average training steps per second: 221.25
I0901 23:52:35.530918 140053067847680 replay_runner.py:36] Average training steps per second: 221.25
I0901 23:52:35.921625 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -305.82
INFO:tensorflow:Starting iteration 17

Steps executed: 274 Episode length: 274 Return: -442.0270268078674487
INFO:tensorflow:Average training steps per second: 217.92
I0901 23:52:44.913172 140053067847680 replay_runner.py:36] Average training steps per second: 217.92
I0901 23:52:45.245505 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -442.03
INFO:tensorflow:Starting iteration 18
I0901 23:52:49.535361 140053067847680 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 230.05

Steps executed: 544 Episode length: 544 Return: -570.9511019361289487
I0901 23:52:55.006389 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -570.95
INFO:tensorflow:Starting iteration 19
I0901 23:52:59.415358 140053067847680 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 236.70

Steps executed: 633 Episode length: 633 Return: 194.77483560333215487
I0901 23:53:05.091643 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: 194.77
INFO:tensorflow:Starting iteration 20

Steps executed: 324 Episode length: 324 Return: -40.60044908229329487
INFO:tensorflow:Average training steps per second: 234.20
I0901 23:53:13.765650 140053067847680 replay_runner.py:36] Average training steps per second: 234.20
I0901 23:53:14.280212 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -40.60
INFO:tensorflow:Starting iteration 21

Steps executed: 354 Episode length: 172 Return: -41.00855202072863487
INFO:tensorflow:Average training steps per second: 226.00
I0901 23:53:23.052881 140053067847680 replay_runner.py:36] Average training steps per second: 226.00
I0901 23:53:23.445625 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.74
INFO:tensorflow:Starting iteration 22
I0901 23:53:27.911758 140053067847680 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 235.37

Steps executed: 1000 Episode length: 1000 Return: -11.256156267799696
I0901 23:53:36.763204 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -11.26
INFO:tensorflow:Starting iteration 23

Steps executed: 269 Episode length: 269 Return: -693.6336121211135696
INFO:tensorflow:Average training steps per second: 232.64
I0901 23:53:45.284347 140053067847680 replay_runner.py:36] Average training steps per second: 232.64
I0901 23:53:45.589445 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -693.63
INFO:tensorflow:Starting iteration 24
I0901 23:53:49.904561 140053067847680 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 227.36

Steps executed: 922 Episode length: 922 Return: 137.59333859181967696
I0901 23:53:56.969130 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: 137.59
INFO:tensorflow:Starting iteration 25
I0901 23:54:00.993873 140053067847680 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 218.31

Steps executed: 1000 Episode length: 1000 Return: -16.621794826493556
I0901 23:54:08.450431 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -16.62
INFO:tensorflow:Starting iteration 26

Steps executed: 317 Episode length: 317 Return: -523.5958859997174556
INFO:tensorflow:Average training steps per second: 230.53
I0901 23:54:16.966444 140053067847680 replay_runner.py:36] Average training steps per second: 230.53
I0901 23:54:17.411209 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -523.60
INFO:tensorflow:Starting iteration 27
I0901 23:54:21.664548 140053067847680 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 218.26
I0901 23:54:26.246588 140053067847680 replay_runner.py:36] Average training steps per second: 218.26

Steps executed: 212 Episode length: 212 Return: -238.1299127953875556
INFO:tensorflow:Starting iteration 28

Steps executed: 268 Episode length: 268 Return: -649.9151278496558556
INFO:tensorflow:Average training steps per second: 220.13
I0901 23:54:35.415455 140053067847680 replay_runner.py:36] Average training steps per second: 220.13
I0901 23:54:35.727887 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -649.92
INFO:tensorflow:Starting iteration 29
I0901 23:54:39.997483 140053067847680 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 219.78
I0901 23:54:44.548092 140053067847680 replay_runner.py:36] Average training steps per second: 219.78


Done fixed training!Episode length: 263 Return: -312.7243410802078656