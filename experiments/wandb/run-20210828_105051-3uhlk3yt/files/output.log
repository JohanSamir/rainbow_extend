Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0828 10:50:56.693676 140251198892032 run_experiment.py:549] Creating TrainRunner ...
I0828 10:50:56.701375 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:50:56.701499 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:50:56.701568 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:50:56.701669 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:50:56.701725 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:50:56.701840 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:50:56.701920 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:50:56.701992 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:50:56.702104 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:50:56.702171 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:50:56.702263 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:50:56.702340 140251198892032 dqn_agent.py:283] 	 seed: 1630147856701343
I0828 10:50:56.704886 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:50:56.705024 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:50:56.705178 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:50:56.705345 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:50:56.705482 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:50:56.705647 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:50:56.705765 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:50:56.705933 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:50:56.706065 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:50:56.733754 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:50:56.993143 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:50:57.002769 140251198892032 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:50:57.009011 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:50:57.009172 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:50:57.009237 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:50:57.009291 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:50:57.009348 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:50:57.009400 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:50:57.009452 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:50:57.009526 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:50:57.009613 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:50:57.009706 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:50:57.009766 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:50:57.009827 140251198892032 dqn_agent.py:283] 	 seed: 1630147857008978
I0828 10:50:57.011226 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:50:57.011339 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:50:57.011407 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:50:57.011467 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:50:57.011561 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:50:57.011625 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:50:57.011698 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:50:57.011761 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:50:57.011829 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:50:57.032734 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:50:57.049388 140251198892032 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:50:57.049787 140251198892032 replay_runner.py:41] Starting iteration 0
Steps executed: 408 Episode length: 240 Return: -651.4948352109727
INFO:tensorflow:Average training steps per second: 248.99
I0828 10:51:01.066228 140251198892032 replay_runner.py:36] Average training steps per second: 248.99
I0828 10:51:01.992049 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -613.21
INFO:tensorflow:Starting iteration 1

Steps executed: 232 Episode length: 122 Return: -292.82808443603165
INFO:tensorflow:Average training steps per second: 330.23
I0828 10:51:08.393633 140251198892032 replay_runner.py:36] Average training steps per second: 330.23
I0828 10:51:08.540830 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.36
INFO:tensorflow:Starting iteration 2

Steps executed: 243 Episode length: 114 Return: -275.78642771755635
INFO:tensorflow:Average training steps per second: 351.43
I0828 10:51:14.785056 140251198892032 replay_runner.py:36] Average training steps per second: 351.43
I0828 10:51:14.938212 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.46
INFO:tensorflow:Starting iteration 3

Steps executed: 328 Episode length: 135 Return: -312.75671728092385
INFO:tensorflow:Average training steps per second: 350.63
I0828 10:51:21.218243 140251198892032 replay_runner.py:36] Average training steps per second: 350.63
I0828 10:51:21.430632 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -348.00
INFO:tensorflow:Starting iteration 4

Steps executed: 242 Episode length: 111 Return: -380.57474872552115
INFO:tensorflow:Average training steps per second: 344.92
I0828 10:51:27.755120 140251198892032 replay_runner.py:36] Average training steps per second: 344.92
I0828 10:51:27.905950 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.94
INFO:tensorflow:Starting iteration 5

Steps executed: 277 Episode length: 117 Return: -561.27673248935685
INFO:tensorflow:Average training steps per second: 353.25
I0828 10:51:34.205126 140251198892032 replay_runner.py:36] Average training steps per second: 353.25
I0828 10:51:34.383686 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -460.07
INFO:tensorflow:Starting iteration 6

Steps executed: 229 Episode length: 93 Return: -445.230541643623553
INFO:tensorflow:Average training steps per second: 357.11
I0828 10:51:40.663684 140251198892032 replay_runner.py:36] Average training steps per second: 357.11
I0828 10:51:40.807906 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -438.12
INFO:tensorflow:Starting iteration 7

Steps executed: 232 Episode length: 139 Return: -106.52848136992613
INFO:tensorflow:Average training steps per second: 358.06
I0828 10:51:47.082960 140251198892032 replay_runner.py:36] Average training steps per second: 358.06
I0828 10:51:47.206089 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.81
INFO:tensorflow:Starting iteration 8

Steps executed: 293 Episode length: 188 Return: -622.39282867908064
INFO:tensorflow:Average training steps per second: 363.19
I0828 10:51:53.450170 140251198892032 replay_runner.py:36] Average training steps per second: 363.19
I0828 10:51:53.617573 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -534.49
INFO:tensorflow:Starting iteration 9

Steps executed: 245 Episode length: 160 Return: -498.51300279549754
INFO:tensorflow:Average training steps per second: 355.49
I0828 10:51:59.940357 140251198892032 replay_runner.py:36] Average training steps per second: 355.49
I0828 10:52:00.084624 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -358.87
INFO:tensorflow:Starting iteration 10

Steps executed: 200 Episode length: 122 Return: -277.87860086965754
INFO:tensorflow:Average training steps per second: 351.27
I0828 10:52:06.421959 140251198892032 replay_runner.py:36] Average training steps per second: 351.27
I0828 10:52:06.536301 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -249.36
INFO:tensorflow:Starting iteration 11

Steps executed: 236 Episode length: 68 Return: -183.367500233521333
INFO:tensorflow:Average training steps per second: 346.13
I0828 10:52:12.896973 140251198892032 replay_runner.py:36] Average training steps per second: 346.13
I0828 10:52:13.035067 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.92
INFO:tensorflow:Starting iteration 12

Steps executed: 203 Episode length: 81 Return: -229.632161634187415
INFO:tensorflow:Average training steps per second: 352.45
I0828 10:52:19.331966 140251198892032 replay_runner.py:36] Average training steps per second: 352.45
I0828 10:52:19.444816 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -275.53
INFO:tensorflow:Starting iteration 13

Steps executed: 234 Episode length: 67 Return: -163.175814717700755
INFO:tensorflow:Average training steps per second: 331.65
I0828 10:52:25.889666 140251198892032 replay_runner.py:36] Average training steps per second: 331.65
I0828 10:52:26.001370 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -315.79
INFO:tensorflow:Starting iteration 14

Steps executed: 281 Episode length: 133 Return: -147.02235329718258
INFO:tensorflow:Average training steps per second: 334.00
I0828 10:52:32.446941 140251198892032 replay_runner.py:36] Average training steps per second: 334.00
I0828 10:52:32.595503 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.40
INFO:tensorflow:Starting iteration 15

Steps executed: 377 Episode length: 198 Return: -442.23734330204815
INFO:tensorflow:Average training steps per second: 339.63
I0828 10:52:38.978593 140251198892032 replay_runner.py:36] Average training steps per second: 339.63
I0828 10:52:39.211572 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -462.83
INFO:tensorflow:Starting iteration 16

Steps executed: 271 Episode length: 144 Return: -284.67295938948394
INFO:tensorflow:Average training steps per second: 342.46
I0828 10:52:45.568417 140251198892032 replay_runner.py:36] Average training steps per second: 342.46
I0828 10:52:45.721293 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -249.56
INFO:tensorflow:Starting iteration 17

Steps executed: 276 Episode length: 276 Return: -481.50715993769194
INFO:tensorflow:Average training steps per second: 335.14
I0828 10:52:52.148608 140251198892032 replay_runner.py:36] Average training steps per second: 335.14
I0828 10:52:52.400318 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -481.51
INFO:tensorflow:Starting iteration 18

Steps executed: 214 Episode length: 122 Return: -258.24978627800254
INFO:tensorflow:Average training steps per second: 333.53
I0828 10:52:58.827708 140251198892032 replay_runner.py:36] Average training steps per second: 333.53
I0828 10:52:58.969863 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.67
INFO:tensorflow:Starting iteration 19

Steps executed: 207 Episode length: 207 Return: -75.015100407919294
INFO:tensorflow:Average training steps per second: 343.31
I0828 10:53:05.310022 140251198892032 replay_runner.py:36] Average training steps per second: 343.31
I0828 10:53:05.468179 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.02
INFO:tensorflow:Starting iteration 20

Steps executed: 281 Episode length: 127 Return: -171.86845637503558
INFO:tensorflow:Average training steps per second: 350.31
I0828 10:53:11.757777 140251198892032 replay_runner.py:36] Average training steps per second: 350.31
I0828 10:53:11.939875 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -298.72
INFO:tensorflow:Starting iteration 21

Steps executed: 272 Episode length: 115 Return: -86.498808142961178
INFO:tensorflow:Average training steps per second: 339.12
I0828 10:53:18.337415 140251198892032 replay_runner.py:36] Average training steps per second: 339.12
I0828 10:53:18.512059 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.66
INFO:tensorflow:Starting iteration 22

Steps executed: 272 Episode length: 142 Return: -525.80280750409597
INFO:tensorflow:Average training steps per second: 347.55
I0828 10:53:24.834051 140251198892032 replay_runner.py:36] Average training steps per second: 347.55
I0828 10:53:25.023915 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.19
INFO:tensorflow:Starting iteration 23

Steps executed: 276 Episode length: 276 Return: -338.18779307940927
INFO:tensorflow:Average training steps per second: 354.27
I0828 10:53:31.314532 140251198892032 replay_runner.py:36] Average training steps per second: 354.27
I0828 10:53:31.593140 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.19
INFO:tensorflow:Starting iteration 24

Steps executed: 257 Episode length: 164 Return: -108.59546907495843
INFO:tensorflow:Average training steps per second: 347.67
I0828 10:53:37.916311 140251198892032 replay_runner.py:36] Average training steps per second: 347.67
I0828 10:53:38.085318 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.55
INFO:tensorflow:Starting iteration 25

Steps executed: 338 Episode length: 141 Return: -689.18744994698453
INFO:tensorflow:Average training steps per second: 344.77
I0828 10:53:44.461099 140251198892032 replay_runner.py:36] Average training steps per second: 344.77
I0828 10:53:44.650427 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -554.56
INFO:tensorflow:Starting iteration 26

Steps executed: 511 Episode length: 312 Return: -39.941206690518843
INFO:tensorflow:Average training steps per second: 344.03
I0828 10:53:51.009581 140251198892032 replay_runner.py:36] Average training steps per second: 344.03
I0828 10:53:51.400493 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.19
INFO:tensorflow:Starting iteration 27

Steps executed: 241 Episode length: 113 Return: -107.38323610889918
INFO:tensorflow:Average training steps per second: 346.35
I0828 10:53:57.710028 140251198892032 replay_runner.py:36] Average training steps per second: 346.35
I0828 10:53:57.829285 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.63
INFO:tensorflow:Starting iteration 28

Steps executed: 200 Episode length: 92 Return: -80.0809634983925258
INFO:tensorflow:Average training steps per second: 335.60
I0828 10:54:04.096638 140251198892032 replay_runner.py:36] Average training steps per second: 335.60
I0828 10:54:04.210673 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -411.48
INFO:tensorflow:Starting iteration 29

Steps executed: 218 Episode length: 106 Return: -526.90270078871916
INFO:tensorflow:Average training steps per second: 332.50
I0828 10:54:10.273823 140251198892032 replay_runner.py:36] Average training steps per second: 332.50

Done fixed training!Episode length: 106 Return: -526.90270078871916