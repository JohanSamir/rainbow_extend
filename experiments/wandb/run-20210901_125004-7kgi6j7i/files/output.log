Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0901 12:50:11.231677 140265790818304 run_experiment.py:549] Creating TrainRunner ...
I0901 12:50:11.243350 140265790818304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:50:11.243647 140265790818304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:50:11.243839 140265790818304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:50:11.243956 140265790818304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:50:11.244082 140265790818304 dqn_agent.py:275] 	 update_period: 4
I0901 12:50:11.244338 140265790818304 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:50:11.244453 140265790818304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:50:11.244565 140265790818304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:50:11.244669 140265790818304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:50:11.244778 140265790818304 dqn_agent.py:280] 	 optimizer: adam
I0901 12:50:11.244880 140265790818304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:50:11.244981 140265790818304 dqn_agent.py:283] 	 seed: 1630500611243284
I0901 12:50:11.247727 140265790818304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:50:11.247963 140265790818304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:50:11.248264 140265790818304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:50:11.248401 140265790818304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:50:11.248511 140265790818304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:50:11.248612 140265790818304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:50:11.248713 140265790818304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:50:11.248902 140265790818304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:50:11.249137 140265790818304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:50:11.292954 140265790818304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:11.703457 140265790818304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:11.743839 140265790818304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:50:11.756006 140265790818304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:50:11.756653 140265790818304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:50:11.756877 140265790818304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:50:11.757114 140265790818304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:50:11.757260 140265790818304 dqn_agent.py:275] 	 update_period: 4
I0901 12:50:11.757474 140265790818304 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:50:11.757632 140265790818304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:50:11.757838 140265790818304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:50:11.758309 140265790818304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:50:11.758512 140265790818304 dqn_agent.py:280] 	 optimizer: adam
I0901 12:50:11.758696 140265790818304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:50:11.758886 140265790818304 dqn_agent.py:283] 	 seed: 1630500611755943
I0901 12:50:11.761940 140265790818304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:50:11.762160 140265790818304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:50:11.762349 140265790818304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:50:11.762491 140265790818304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:50:11.762672 140265790818304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:50:11.762793 140265790818304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:50:11.762905 140265790818304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:50:11.763014 140265790818304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:50:11.763119 140265790818304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:50:11.800446 140265790818304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:11.822296 140265790818304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:50:11.822617 140265790818304 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 157.04
I0901 12:50:18.190887 140265790818304 replay_runner.py:36] Average training steps per second: 157.04
Steps executed: 275 Episode length: 97 Return: -128.12335489435986
I0901 12:50:19.467659 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.68
INFO:tensorflow:Starting iteration 1

Steps executed: 258 Episode length: 108 Return: -632.6132134911229
INFO:tensorflow:Average training steps per second: 226.16
I0901 12:50:28.229489 140265790818304 replay_runner.py:36] Average training steps per second: 226.16
I0901 12:50:28.480966 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -560.88
INFO:tensorflow:Starting iteration 2

Steps executed: 222 Episode length: 93 Return: -266.84027717139025
INFO:tensorflow:Average training steps per second: 236.51
I0901 12:50:37.067584 140265790818304 replay_runner.py:36] Average training steps per second: 236.51
I0901 12:50:37.284183 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -417.39
INFO:tensorflow:Starting iteration 3

Steps executed: 259 Episode length: 102 Return: -334.9643492073551
INFO:tensorflow:Average training steps per second: 227.34
I0901 12:50:45.842102 140265790818304 replay_runner.py:36] Average training steps per second: 227.34
I0901 12:50:46.103807 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -504.79
INFO:tensorflow:Starting iteration 4

Steps executed: 104 Episode length: 104 Return: -668.1497951676818
INFO:tensorflow:Average training steps per second: 227.67
I0901 12:50:54.790031 140265790818304 replay_runner.py:36] Average training steps per second: 227.67

Steps executed: 251 Episode length: 147 Return: -258.95036769845456
INFO:tensorflow:Starting iteration 5

Steps executed: 296 Episode length: 98 Return: -220.572504048912786
INFO:tensorflow:Average training steps per second: 238.09
I0901 12:51:03.605061 140265790818304 replay_runner.py:36] Average training steps per second: 238.09
I0901 12:51:03.877452 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -373.47
INFO:tensorflow:Starting iteration 6

Steps executed: 223 Episode length: 83 Return: -180.119991667263727
INFO:tensorflow:Average training steps per second: 222.39
I0901 12:51:12.822334 140265790818304 replay_runner.py:36] Average training steps per second: 222.39
I0901 12:51:13.022623 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.72
INFO:tensorflow:Starting iteration 7

Steps executed: 261 Episode length: 118 Return: -208.09136515286394
INFO:tensorflow:Average training steps per second: 222.25
I0901 12:51:21.947361 140265790818304 replay_runner.py:36] Average training steps per second: 222.25
I0901 12:51:22.205339 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.52
INFO:tensorflow:Starting iteration 8

Steps executed: 83 Episode length: 83 Return: -343.2525069485019394
INFO:tensorflow:Average training steps per second: 226.01

Steps executed: 317 Episode length: 158 Return: -33.202466678075414
I0901 12:51:31.278076 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.89
INFO:tensorflow:Starting iteration 9

Steps executed: 383 Episode length: 199 Return: -105.79609247359855
INFO:tensorflow:Average training steps per second: 223.76
I0901 12:51:40.090924 140265790818304 replay_runner.py:36] Average training steps per second: 223.76
I0901 12:51:40.533067 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -316.31
INFO:tensorflow:Starting iteration 10

Steps executed: 247 Episode length: 121 Return: -306.68402189847643
INFO:tensorflow:Average training steps per second: 223.28
I0901 12:51:49.499179 140265790818304 replay_runner.py:36] Average training steps per second: 223.28
I0901 12:51:49.732036 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.71
INFO:tensorflow:Starting iteration 11

Steps executed: 215 Episode length: 70 Return: -224.327228606022063
INFO:tensorflow:Average training steps per second: 217.69
I0901 12:51:58.754368 140265790818304 replay_runner.py:36] Average training steps per second: 217.69
I0901 12:51:58.933071 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.86
INFO:tensorflow:Starting iteration 12

Steps executed: 291 Episode length: 113 Return: -133.51724796696737
INFO:tensorflow:Average training steps per second: 224.63
I0901 12:52:07.729136 140265790818304 replay_runner.py:36] Average training steps per second: 224.63
I0901 12:52:07.977424 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.26
INFO:tensorflow:Starting iteration 13

Steps executed: 209 Episode length: 64 Return: -297.642275416565937
INFO:tensorflow:Average training steps per second: 218.70
I0901 12:52:16.989507 140265790818304 replay_runner.py:36] Average training steps per second: 218.70
I0901 12:52:17.151202 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.80
INFO:tensorflow:Starting iteration 14

Steps executed: 223 Episode length: 65 Return: -133.421923566797917
INFO:tensorflow:Average training steps per second: 221.68
I0901 12:52:25.979706 140265790818304 replay_runner.py:36] Average training steps per second: 221.68
I0901 12:52:26.130577 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.46
INFO:tensorflow:Starting iteration 15

Steps executed: 260 Episode length: 71 Return: -256.926472756067377
INFO:tensorflow:Average training steps per second: 227.52
I0901 12:52:34.884891 140265790818304 replay_runner.py:36] Average training steps per second: 227.52
I0901 12:52:35.085158 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.67
INFO:tensorflow:Starting iteration 16

Steps executed: 226 Episode length: 83 Return: -152.326040978323877
INFO:tensorflow:Average training steps per second: 223.91
I0901 12:52:43.820294 140265790818304 replay_runner.py:36] Average training steps per second: 223.91
I0901 12:52:44.017987 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.87
INFO:tensorflow:Starting iteration 17

Steps executed: 251 Episode length: 88 Return: -316.417380782285144
INFO:tensorflow:Average training steps per second: 226.10
I0901 12:52:52.736546 140265790818304 replay_runner.py:36] Average training steps per second: 226.10
I0901 12:52:52.925536 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.22
INFO:tensorflow:Starting iteration 18

Steps executed: 312 Episode length: 117 Return: -303.86915199527394
INFO:tensorflow:Average training steps per second: 221.70
I0901 12:53:01.889985 140265790818304 replay_runner.py:36] Average training steps per second: 221.70
I0901 12:53:02.215518 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -302.55
INFO:tensorflow:Starting iteration 19

Steps executed: 134 Episode length: 56 Return: -140.143787400619794
INFO:tensorflow:Average training steps per second: 222.14
I0901 12:53:11.017343 140265790818304 replay_runner.py:36] Average training steps per second: 222.14

Steps executed: 238 Episode length: 104 Return: -123.26406809493444
INFO:tensorflow:Starting iteration 20

Steps executed: 380 Episode length: 280 Return: -343.56912015779537
INFO:tensorflow:Average training steps per second: 229.72
I0901 12:53:19.899405 140265790818304 replay_runner.py:36] Average training steps per second: 229.72
I0901 12:53:20.295888 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.09
INFO:tensorflow:Starting iteration 21

Steps executed: 104 Episode length: 104 Return: -278.87855363320165
INFO:tensorflow:Average training steps per second: 223.76
I0901 12:53:29.062889 140265790818304 replay_runner.py:36] Average training steps per second: 223.76

Steps executed: 247 Episode length: 143 Return: -370.05735913036307
INFO:tensorflow:Starting iteration 22

Steps executed: 210 Episode length: 104 Return: -421.53009782764263
INFO:tensorflow:Average training steps per second: 227.61
I0901 12:53:38.152615 140265790818304 replay_runner.py:36] Average training steps per second: 227.61
I0901 12:53:38.347535 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -330.85
INFO:tensorflow:Starting iteration 23

Steps executed: 105 Episode length: 105 Return: -374.21452554638033
INFO:tensorflow:Average training steps per second: 227.20

Steps executed: 379 Episode length: 274 Return: -704.40027837237563
I0901 12:53:47.440921 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -539.31
INFO:tensorflow:Starting iteration 24

Steps executed: 317 Episode length: 140 Return: -387.11357795335687
INFO:tensorflow:Average training steps per second: 224.23
I0901 12:53:56.362965 140265790818304 replay_runner.py:36] Average training steps per second: 224.23
I0901 12:53:56.655029 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -316.34
INFO:tensorflow:Starting iteration 25

Steps executed: 269 Episode length: 269 Return: -1003.9815531658937
INFO:tensorflow:Average training steps per second: 220.83
I0901 12:54:05.538372 140265790818304 replay_runner.py:36] Average training steps per second: 220.83
I0901 12:54:05.893297 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -1003.98
INFO:tensorflow:Starting iteration 26

Steps executed: 285 Episode length: 90 Return: -703.648134024964337
INFO:tensorflow:Average training steps per second: 226.56
I0901 12:54:14.590595 140265790818304 replay_runner.py:36] Average training steps per second: 226.56
I0901 12:54:14.881297 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -505.11
INFO:tensorflow:Starting iteration 27
I0901 12:54:19.107352 140265790818304 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 223.74

Steps executed: 280 Episode length: 84 Return: -584.210648980026537
I0901 12:54:23.831968 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -541.22
INFO:tensorflow:Starting iteration 28

Steps executed: 340 Episode length: 340 Return: -681.64903206431597
INFO:tensorflow:Average training steps per second: 219.52
I0901 12:54:32.579698 140265790818304 replay_runner.py:36] Average training steps per second: 219.52
I0901 12:54:33.008418 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -681.65
INFO:tensorflow:Starting iteration 29
I0901 12:54:37.216484 140265790818304 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 225.75

Steps executed: 248 Episode length: 55 Return: -476.174165395086567

Done fixed training!Episode length: 55 Return: -476.174165395086567