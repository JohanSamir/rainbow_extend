Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0828 10:23:21.740819 140053337282560 run_experiment.py:549] Creating TrainRunner ...
I0828 10:23:21.751193 140053337282560 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:23:21.751438 140053337282560 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:23:21.751578 140053337282560 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:23:21.751667 140053337282560 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:23:21.751744 140053337282560 dqn_agent.py:275] 	 update_period: 4
I0828 10:23:21.751823 140053337282560 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:23:21.751898 140053337282560 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:23:21.752005 140053337282560 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:23:21.752131 140053337282560 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:23:21.752205 140053337282560 dqn_agent.py:280] 	 optimizer: adam
I0828 10:23:21.752411 140053337282560 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:23:21.752596 140053337282560 dqn_agent.py:283] 	 seed: 1630146201751142
I0828 10:23:21.754661 140053337282560 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:23:21.754793 140053337282560 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:23:21.754873 140053337282560 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:23:21.754938 140053337282560 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:23:21.754996 140053337282560 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:23:21.755068 140053337282560 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:23:21.755138 140053337282560 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:23:21.755222 140053337282560 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:23:21.755302 140053337282560 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:23:21.788936 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:22.172120 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:22.186989 140053337282560 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:23:22.195794 140053337282560 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:23:22.196000 140053337282560 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:23:22.196099 140053337282560 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:23:22.196188 140053337282560 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:23:22.196273 140053337282560 dqn_agent.py:275] 	 update_period: 4
I0828 10:23:22.196328 140053337282560 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:23:22.196404 140053337282560 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:23:22.196520 140053337282560 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:23:22.196591 140053337282560 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:23:22.196646 140053337282560 dqn_agent.py:280] 	 optimizer: adam
I0828 10:23:22.196713 140053337282560 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:23:22.196769 140053337282560 dqn_agent.py:283] 	 seed: 1630146202195747
I0828 10:23:22.199053 140053337282560 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:23:22.199244 140053337282560 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:23:22.199370 140053337282560 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:23:22.199479 140053337282560 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:23:22.199577 140053337282560 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:23:22.199692 140053337282560 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:23:22.199784 140053337282560 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:23:22.199891 140053337282560 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:23:22.200215 140053337282560 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:23:22.503924 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:22.525784 140053337282560 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:23:22.526078 140053337282560 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 165.63
I0828 10:23:28.564360 140053337282560 replay_runner.py:36] Average training steps per second: 165.63
Steps executed: 208 Episode length: 68 Return: -678.9098522611174
I0828 10:23:29.827674 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -679.94
INFO:tensorflow:Starting iteration 1

Steps executed: 216 Episode length: 72 Return: -280.4979503494567
INFO:tensorflow:Average training steps per second: 218.34
I0828 10:23:38.765670 140053337282560 replay_runner.py:36] Average training steps per second: 218.34
I0828 10:23:38.929206 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.07
INFO:tensorflow:Starting iteration 2

Steps executed: 255 Episode length: 255 Return: -732.7979887865438
INFO:tensorflow:Average training steps per second: 219.01
I0828 10:23:47.776936 140053337282560 replay_runner.py:36] Average training steps per second: 219.01
I0828 10:23:48.055927 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -732.80
INFO:tensorflow:Starting iteration 3

Steps executed: 285 Episode length: 101 Return: -215.53457169893005
INFO:tensorflow:Average training steps per second: 219.90
I0828 10:23:56.889978 140053337282560 replay_runner.py:36] Average training steps per second: 219.90
I0828 10:23:57.096529 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.52
INFO:tensorflow:Starting iteration 4

Steps executed: 316 Episode length: 134 Return: -352.77454517425474
INFO:tensorflow:Average training steps per second: 223.89
I0828 10:24:05.867551 140053337282560 replay_runner.py:36] Average training steps per second: 223.89
I0828 10:24:06.126906 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -378.81
INFO:tensorflow:Starting iteration 5

Steps executed: 208 Episode length: 60 Return: -449.246091576088974
INFO:tensorflow:Average training steps per second: 222.69
I0828 10:24:14.822965 140053337282560 replay_runner.py:36] Average training steps per second: 222.69
I0828 10:24:15.010929 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -584.17
INFO:tensorflow:Starting iteration 6
I0828 10:24:19.353518 140053337282560 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 232.75

Steps executed: 214 Episode length: 87 Return: -877.820599039335474
I0828 10:24:23.823879 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -679.20
INFO:tensorflow:Starting iteration 7

Steps executed: 211 Episode length: 77 Return: -563.126777143307274
INFO:tensorflow:Average training steps per second: 233.28
I0828 10:24:32.252780 140053337282560 replay_runner.py:36] Average training steps per second: 233.28
I0828 10:24:32.407974 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -514.37
INFO:tensorflow:Starting iteration 8

Steps executed: 245 Episode length: 54 Return: -425.405386739939444
INFO:tensorflow:Average training steps per second: 245.05
I0828 10:24:40.597866 140053337282560 replay_runner.py:36] Average training steps per second: 245.05
I0828 10:24:40.749876 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -460.33
INFO:tensorflow:Starting iteration 9

Steps executed: 227 Episode length: 111 Return: -796.45074654553124
INFO:tensorflow:Average training steps per second: 235.46
I0828 10:24:49.084964 140053337282560 replay_runner.py:36] Average training steps per second: 235.46
I0828 10:24:49.299247 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -680.55
INFO:tensorflow:Starting iteration 10

Steps executed: 225 Episode length: 65 Return: -104.887897305776454
INFO:tensorflow:Average training steps per second: 221.97
I0828 10:24:57.982687 140053337282560 replay_runner.py:36] Average training steps per second: 221.97
I0828 10:24:58.144122 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.71
INFO:tensorflow:Starting iteration 11

Steps executed: 201 Episode length: 68 Return: -634.069472634444754
INFO:tensorflow:Average training steps per second: 223.13
I0828 10:25:07.012710 140053337282560 replay_runner.py:36] Average training steps per second: 223.13
I0828 10:25:07.192590 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -614.53
INFO:tensorflow:Starting iteration 12

Steps executed: 290 Episode length: 290 Return: -2379.7415906662724
INFO:tensorflow:Average training steps per second: 222.36
I0828 10:25:16.085191 140053337282560 replay_runner.py:36] Average training steps per second: 222.36
I0828 10:25:16.511700 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -2379.74
INFO:tensorflow:Starting iteration 13

Steps executed: 265 Episode length: 265 Return: -2314.5460467635367
INFO:tensorflow:Average training steps per second: 217.92
I0828 10:25:25.293945 140053337282560 replay_runner.py:36] Average training steps per second: 217.92
I0828 10:25:25.650576 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -2314.55
INFO:tensorflow:Starting iteration 14

Steps executed: 269 Episode length: 173 Return: -1292.1892623492747
INFO:tensorflow:Average training steps per second: 215.85
I0828 10:25:34.616092 140053337282560 replay_runner.py:36] Average training steps per second: 215.85
I0828 10:25:34.873707 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -802.35
INFO:tensorflow:Starting iteration 15


Steps executed: 259 Episode length: 70 Return: -480.616913295067947
INFO:tensorflow:Average training steps per second: 221.73
I0828 10:25:43.798148 140053337282560 replay_runner.py:36] Average training steps per second: 221.73
I0828 10:25:44.029097 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -482.33
INFO:tensorflow:Starting iteration 16

Steps executed: 225 Episode length: 84 Return: -740.507930195090547
INFO:tensorflow:Average training steps per second: 225.09
I0828 10:25:52.865234 140053337282560 replay_runner.py:36] Average training steps per second: 225.09
I0828 10:25:53.064839 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -692.98
INFO:tensorflow:Starting iteration 17

Steps executed: 272 Episode length: 73 Return: -243.615389080530237
INFO:tensorflow:Average training steps per second: 223.53
I0828 10:26:01.972382 140053337282560 replay_runner.py:36] Average training steps per second: 223.53
I0828 10:26:02.233500 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.21
INFO:tensorflow:Starting iteration 18

Steps executed: 248 Episode length: 59 Return: -627.076748977313637
INFO:tensorflow:Average training steps per second: 218.75
I0828 10:26:11.231929 140053337282560 replay_runner.py:36] Average training steps per second: 218.75
I0828 10:26:11.456920 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -589.24
INFO:tensorflow:Starting iteration 19

Steps executed: 203 Episode length: 64 Return: -553.749567695008237
INFO:tensorflow:Average training steps per second: 221.46
I0828 10:26:20.356950 140053337282560 replay_runner.py:36] Average training steps per second: 221.46
I0828 10:26:20.539421 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -649.08
INFO:tensorflow:Starting iteration 20
I0828 10:26:24.972136 140053337282560 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 219.39

Steps executed: 405 Episode length: 250 Return: -1685.2980834226792
I0828 10:26:30.061819 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -1342.98
INFO:tensorflow:Starting iteration 21

Steps executed: 226 Episode length: 65 Return: -556.040432440726692
INFO:tensorflow:Average training steps per second: 222.55
I0828 10:26:38.960004 140053337282560 replay_runner.py:36] Average training steps per second: 222.55
I0828 10:26:39.172863 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -522.51
INFO:tensorflow:Starting iteration 22
I0828 10:26:43.577167 140053337282560 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 223.05

Steps executed: 230 Episode length: 54 Return: -468.102748174325372
I0828 10:26:48.279388 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -452.91
INFO:tensorflow:Starting iteration 23

Steps executed: 267 Episode length: 75 Return: -668.013343886763162
INFO:tensorflow:Average training steps per second: 222.63
I0828 10:26:57.087494 140053337282560 replay_runner.py:36] Average training steps per second: 222.63
I0828 10:26:57.346425 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -635.07
INFO:tensorflow:Starting iteration 24
I0828 10:27:01.641186 140053337282560 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 226.46

Steps executed: 227 Episode length: 75 Return: -108.775742032235342
I0828 10:27:06.220945 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.74
INFO:tensorflow:Starting iteration 25

Steps executed: 304 Episode length: 218 Return: -1655.8822304399642
INFO:tensorflow:Average training steps per second: 233.07
I0828 10:27:14.939695 140053337282560 replay_runner.py:36] Average training steps per second: 233.07
I0828 10:27:15.295015 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -1045.07
INFO:tensorflow:Starting iteration 26

Steps executed: 212 Episode length: 82 Return: -738.887316156507342
INFO:tensorflow:Average training steps per second: 241.09
I0828 10:27:23.748324 140053337282560 replay_runner.py:36] Average training steps per second: 241.09
I0828 10:27:23.927173 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -616.23
INFO:tensorflow:Starting iteration 27
I0828 10:27:28.171494 140053337282560 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 248.39

Steps executed: 262 Episode length: 75 Return: -691.797466186281342
I0828 10:27:32.408921 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -628.19
INFO:tensorflow:Starting iteration 28

Steps executed: 309 Episode length: 115 Return: -416.00007391934462
INFO:tensorflow:Average training steps per second: 236.40
I0828 10:27:41.091897 140053337282560 replay_runner.py:36] Average training steps per second: 236.40
I0828 10:27:41.353565 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -507.95
INFO:tensorflow:Starting iteration 29

Steps executed: 221 Episode length: 221 Return: -1952.4860980967958
INFO:tensorflow:Average training steps per second: 252.77
I0828 10:27:49.593698 140053337282560 replay_runner.py:36] Average training steps per second: 252.77

Done fixed training!Episode length: 221 Return: -1952.4860980967958