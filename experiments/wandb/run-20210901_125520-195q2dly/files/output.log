Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 12:55:26.800688 140315766171648 run_experiment.py:549] Creating TrainRunner ...
I0901 12:55:26.812956 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:55:26.813362 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:55:26.813601 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:55:26.813781 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:55:26.813920 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 12:55:26.814066 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:55:26.814311 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:55:26.814436 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:55:26.814820 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:55:26.815011 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 12:55:26.815168 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:55:26.815330 140315766171648 dqn_agent.py:283] 	 seed: 1630500926812883
I0901 12:55:26.818762 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:55:26.818969 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:55:26.819145 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:55:26.819321 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:55:26.819442 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:55:26.819560 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:55:26.819670 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:55:26.819793 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:55:26.819910 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:55:26.927857 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:55:27.357894 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:55:27.377770 140315766171648 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:55:27.388949 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:55:27.389313 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:55:27.389451 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:55:27.389530 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:55:27.389601 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 12:55:27.389674 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:55:27.389781 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:55:27.389959 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:55:27.390346 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:55:27.390590 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 12:55:27.390825 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:55:27.390993 140315766171648 dqn_agent.py:283] 	 seed: 1630500927388891
I0901 12:55:27.393864 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:55:27.394078 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:55:27.394285 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:55:27.394384 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:55:27.394500 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:55:27.394721 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:55:27.395028 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:55:27.395222 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:55:27.395480 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:55:27.433407 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:55:27.458362 140315766171648 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:55:27.458611 140315766171648 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 164.26
I0901 12:55:33.546954 140315766171648 replay_runner.py:36] Average training steps per second: 164.26
Steps executed: 234 Episode length: 56 Return: -10.867497263389197
I0901 12:55:35.106612 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.65
INFO:tensorflow:Starting iteration 1

Steps executed: 205 Episode length: 110 Return: -620.1209818036355
INFO:tensorflow:Average training steps per second: 221.38
I0901 12:55:44.063061 140315766171648 replay_runner.py:36] Average training steps per second: 221.38
I0901 12:55:44.265842 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -643.59
INFO:tensorflow:Starting iteration 2

Steps executed: 252 Episode length: 168 Return: -281.0745280584308
INFO:tensorflow:Average training steps per second: 218.29
I0901 12:55:53.278751 140315766171648 replay_runner.py:36] Average training steps per second: 218.29
I0901 12:55:53.504321 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.24
INFO:tensorflow:Starting iteration 3

Steps executed: 200 Episode length: 102 Return: -270.0426652451994
INFO:tensorflow:Average training steps per second: 213.17
I0901 12:56:02.606892 140315766171648 replay_runner.py:36] Average training steps per second: 213.17
I0901 12:56:02.783571 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -465.82
INFO:tensorflow:Starting iteration 4

Steps executed: 260 Episode length: 96 Return: -285.68336476443674
INFO:tensorflow:Average training steps per second: 212.79
I0901 12:56:11.832379 140315766171648 replay_runner.py:36] Average training steps per second: 212.79
I0901 12:56:12.059279 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.05
INFO:tensorflow:Starting iteration 5

Steps executed: 310 Episode length: 155 Return: -327.9225469636258
INFO:tensorflow:Average training steps per second: 216.42
I0901 12:56:21.093153 140315766171648 replay_runner.py:36] Average training steps per second: 216.42
I0901 12:56:21.383626 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.33
INFO:tensorflow:Starting iteration 6

Steps executed: 159 Episode length: 159 Return: -503.1802343417478
INFO:tensorflow:Average training steps per second: 217.56

Steps executed: 288 Episode length: 129 Return: -648.5149061529145
I0901 12:56:30.756141 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -575.85
INFO:tensorflow:Starting iteration 7

Steps executed: 269 Episode length: 88 Return: -418.48686917335355
INFO:tensorflow:Average training steps per second: 216.81
I0901 12:56:39.820600 140315766171648 replay_runner.py:36] Average training steps per second: 216.81
I0901 12:56:40.056176 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -598.23
INFO:tensorflow:Starting iteration 8

Steps executed: 242 Episode length: 109 Return: -69.84297836109702
INFO:tensorflow:Average training steps per second: 220.44
I0901 12:56:48.874656 140315766171648 replay_runner.py:36] Average training steps per second: 220.44
I0901 12:56:49.072027 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.72
INFO:tensorflow:Starting iteration 9

Steps executed: 284 Episode length: 120 Return: -366.6997522358091
INFO:tensorflow:Average training steps per second: 222.07
I0901 12:56:57.995160 140315766171648 replay_runner.py:36] Average training steps per second: 222.07
I0901 12:56:58.243061 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -368.52
INFO:tensorflow:Starting iteration 10

Steps executed: 234 Episode length: 129 Return: -204.95588014029393
INFO:tensorflow:Average training steps per second: 217.48
I0901 12:57:07.276156 140315766171648 replay_runner.py:36] Average training steps per second: 217.48
I0901 12:57:07.485195 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.24
INFO:tensorflow:Starting iteration 11

Steps executed: 293 Episode length: 109 Return: -305.81691521988506
INFO:tensorflow:Average training steps per second: 215.58
I0901 12:57:16.513856 140315766171648 replay_runner.py:36] Average training steps per second: 215.58
I0901 12:57:16.777747 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -578.16
INFO:tensorflow:Starting iteration 12

Steps executed: 241 Episode length: 125 Return: -157.74299137865972
INFO:tensorflow:Average training steps per second: 222.46
I0901 12:57:25.678018 140315766171648 replay_runner.py:36] Average training steps per second: 222.46
I0901 12:57:25.887393 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.22
INFO:tensorflow:Starting iteration 13
I0901 12:57:30.385419 140315766171648 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 214.15

Steps executed: 215 Episode length: 215 Return: -275.49324161435203
I0901 12:57:35.275652 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -275.49
INFO:tensorflow:Starting iteration 14

Steps executed: 201 Episode length: 84 Return: -712.226991126960653
INFO:tensorflow:Average training steps per second: 213.60
I0901 12:57:44.195414 140315766171648 replay_runner.py:36] Average training steps per second: 213.60
I0901 12:57:44.413648 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -521.77
INFO:tensorflow:Starting iteration 15

Steps executed: 344 Episode length: 198 Return: -424.11416690204015
INFO:tensorflow:Average training steps per second: 213.59
I0901 12:57:53.363731 140315766171648 replay_runner.py:36] Average training steps per second: 213.59
I0901 12:57:53.727190 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -466.37
INFO:tensorflow:Starting iteration 16
I0901 12:57:58.197558 140315766171648 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 212.41
I0901 12:58:02.905788 140315766171648 replay_runner.py:36] Average training steps per second: 212.41

Steps executed: 220 Episode length: 109 Return: -240.40140665396416
INFO:tensorflow:Starting iteration 17

Steps executed: 224 Episode length: 91 Return: -292.640202359046666
INFO:tensorflow:Average training steps per second: 213.39
I0901 12:58:12.283134 140315766171648 replay_runner.py:36] Average training steps per second: 213.39
I0901 12:58:12.480224 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.80
INFO:tensorflow:Starting iteration 18

Steps executed: 201 Episode length: 77 Return: -85.4576337253044256
INFO:tensorflow:Average training steps per second: 212.98
I0901 12:58:21.655871 140315766171648 replay_runner.py:36] Average training steps per second: 212.98
I0901 12:58:21.825463 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.30
INFO:tensorflow:Starting iteration 19
I0901 12:58:26.266283 140315766171648 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 224.42

Steps executed: 202 Episode length: 202 Return: -237.52856041993368
I0901 12:58:30.927653 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.53
INFO:tensorflow:Starting iteration 20

Steps executed: 238 Episode length: 61 Return: -460.791265054382975
INFO:tensorflow:Average training steps per second: 217.11
I0901 12:58:39.867768 140315766171648 replay_runner.py:36] Average training steps per second: 217.11
I0901 12:58:40.097803 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -362.59
INFO:tensorflow:Starting iteration 21

Steps executed: 265 Episode length: 75 Return: -601.195317986197775
INFO:tensorflow:Average training steps per second: 213.31
I0901 12:58:49.181141 140315766171648 replay_runner.py:36] Average training steps per second: 213.31
I0901 12:58:49.463940 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -610.79
INFO:tensorflow:Starting iteration 22
I0901 12:58:53.911064 140315766171648 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 215.69

Steps executed: 407 Episode length: 407 Return: -145.83413348425345
I0901 12:58:59.159504 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.83
INFO:tensorflow:Starting iteration 23

Steps executed: 211 Episode length: 113 Return: -249.49117842946754
INFO:tensorflow:Average training steps per second: 216.41
I0901 12:59:08.322277 140315766171648 replay_runner.py:36] Average training steps per second: 216.41
I0901 12:59:08.515560 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.39
INFO:tensorflow:Starting iteration 24

Steps executed: 248 Episode length: 75 Return: -550.138364857424954
INFO:tensorflow:Average training steps per second: 213.45
I0901 12:59:17.782808 140315766171648 replay_runner.py:36] Average training steps per second: 213.45
I0901 12:59:17.995081 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.36
INFO:tensorflow:Starting iteration 25

Steps executed: 179 Episode length: 86 Return: -173.916670041254354
INFO:tensorflow:Average training steps per second: 221.03
I0901 12:59:26.879722 140315766171648 replay_runner.py:36] Average training steps per second: 221.03

Steps executed: 271 Episode length: 92 Return: -308.364469736256254
INFO:tensorflow:Starting iteration 26

Steps executed: 309 Episode length: 144 Return: 6.53344887197225424
INFO:tensorflow:Average training steps per second: 214.28
I0901 12:59:36.263382 140315766171648 replay_runner.py:36] Average training steps per second: 214.28
I0901 12:59:36.535820 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -264.49
INFO:tensorflow:Starting iteration 27

Steps executed: 216 Episode length: 87 Return: -327.243025451767664
INFO:tensorflow:Average training steps per second: 213.50
I0901 12:59:45.638006 140315766171648 replay_runner.py:36] Average training steps per second: 213.50
I0901 12:59:45.828690 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -405.51
INFO:tensorflow:Starting iteration 28

Steps executed: 210 Episode length: 76 Return: -696.291973348124154
INFO:tensorflow:Average training steps per second: 220.83
I0901 12:59:54.849728 140315766171648 replay_runner.py:36] Average training steps per second: 220.83
I0901 12:59:55.080717 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -415.54
INFO:tensorflow:Starting iteration 29

Steps executed: 268 Episode length: 138 Return: -286.42511142302465
INFO:tensorflow:Average training steps per second: 221.92
I0901 13:00:03.958342 140315766171648 replay_runner.py:36] Average training steps per second: 221.92

Done fixed training!Episode length: 138 Return: -286.42511142302465