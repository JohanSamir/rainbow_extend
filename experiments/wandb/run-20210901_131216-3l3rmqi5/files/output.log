I0901 13:12:22.388333 140315766171648 run_experiment.py:549] Creating TrainRunner ...
I0901 13:12:22.397480 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:12:22.397629 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:12:22.397712 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:12:22.397773 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:12:22.397834 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 13:12:22.397909 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:12:22.397996 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:12:22.398055 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:12:22.398134 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:12:22.398213 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 13:12:22.398292 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:12:22.398366 140315766171648 dqn_agent.py:283] 	 seed: 1630501942397438
I0901 13:12:22.400015 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:12:22.400134 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:12:22.400212 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:12:22.400273 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:12:22.400329 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:12:22.400384 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:12:22.400454 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:12:22.400524 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:12:22.400578 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:12:22.506793 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:12:22.770141 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:12:22.779908 140315766171648 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:12:22.785769 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:12:22.785902 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:12:22.785992 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:12:22.786056 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:12:22.786122 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 13:12:22.786178 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:12:22.786269 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:12:22.786401 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:12:22.786528 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:12:22.786686 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 13:12:22.786790 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:12:22.786862 140315766171648 dqn_agent.py:283] 	 seed: 1630501942785739
I0901 13:12:22.789088 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:12:22.789229 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:12:22.789340 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:12:22.789422 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:12:22.789497 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:12:22.789570 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:12:22.789646 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:12:22.789733 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:12:22.789800 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:12:22.811895 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:12:22.826942 140315766171648 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:12:22.827110 140315766171648 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 250.66
I0901 13:12:26.816891 140315766171648 replay_runner.py:36] Average training steps per second: 250.66
I0901 13:12:27.685449 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.75
Steps executed: 218 Episode length: 133 Return: -26.988900545575703
INFO:tensorflow:Starting iteration 1
I0901 13:12:30.961528 140315766171648 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 332.35

Steps executed: 328 Episode length: 163 Return: -62.380162558023787
I0901 13:12:34.190136 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -43.34
INFO:tensorflow:Starting iteration 2

Steps executed: 227 Episode length: 75 Return: -85.6962796929550387
INFO:tensorflow:Average training steps per second: 328.75
I0901 13:12:40.509213 140315766171648 replay_runner.py:36] Average training steps per second: 328.75
I0901 13:12:40.649519 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.92
INFO:tensorflow:Starting iteration 3

Steps executed: 210 Episode length: 120 Return: -451.36983030635025
INFO:tensorflow:Average training steps per second: 337.71
I0901 13:12:46.923517 140315766171648 replay_runner.py:36] Average training steps per second: 337.71
I0901 13:12:47.049815 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -376.24
INFO:tensorflow:Starting iteration 4

Steps executed: 208 Episode length: 122 Return: -52.998562776127145
INFO:tensorflow:Average training steps per second: 333.79
I0901 13:12:53.478794 140315766171648 replay_runner.py:36] Average training steps per second: 333.79
I0901 13:12:53.597604 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.44
INFO:tensorflow:Starting iteration 5

Steps executed: 79 Episode length: 79 Return: -334.2266914161953145
INFO:tensorflow:Average training steps per second: 339.26
I0901 13:13:00.011262 140315766171648 replay_runner.py:36] Average training steps per second: 339.26

Steps executed: 203 Episode length: 124 Return: -332.80977649793825
INFO:tensorflow:Starting iteration 6

Steps executed: 213 Episode length: 65 Return: -17.3780040992625545
INFO:tensorflow:Average training steps per second: 346.40
I0901 13:13:06.465538 140315766171648 replay_runner.py:36] Average training steps per second: 346.40
I0901 13:13:06.577376 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.72
INFO:tensorflow:Starting iteration 7

Steps executed: 288 Episode length: 217 Return: -267.86832203912125
INFO:tensorflow:Average training steps per second: 347.78
I0901 13:13:12.940531 140315766171648 replay_runner.py:36] Average training steps per second: 347.78
I0901 13:13:13.129232 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -264.48
INFO:tensorflow:Starting iteration 8

Steps executed: 218 Episode length: 130 Return: -176.78165713951017
INFO:tensorflow:Average training steps per second: 347.11
I0901 13:13:19.514260 140315766171648 replay_runner.py:36] Average training steps per second: 347.11
I0901 13:13:19.651059 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -294.85
INFO:tensorflow:Starting iteration 9

Steps executed: 221 Episode length: 78 Return: -430.576873906010217
INFO:tensorflow:Average training steps per second: 346.21
I0901 13:13:26.067009 140315766171648 replay_runner.py:36] Average training steps per second: 346.21
I0901 13:13:26.182454 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.23
INFO:tensorflow:Starting iteration 10

Steps executed: 249 Episode length: 87 Return: -134.341126567350077
INFO:tensorflow:Average training steps per second: 357.31
I0901 13:13:32.480285 140315766171648 replay_runner.py:36] Average training steps per second: 357.31
I0901 13:13:32.624449 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.58
INFO:tensorflow:Starting iteration 11
I0901 13:13:36.186215 140315766171648 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 359.10
I0901 13:13:38.971193 140315766171648 replay_runner.py:36] Average training steps per second: 359.10

Steps executed: 291 Episode length: 146 Return: -364.38885879104095
INFO:tensorflow:Starting iteration 12

Steps executed: 260 Episode length: 177 Return: 6.23388558215744195
INFO:tensorflow:Average training steps per second: 364.58
I0901 13:13:45.460754 140315766171648 replay_runner.py:36] Average training steps per second: 364.58
I0901 13:13:45.632471 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -391.66
INFO:tensorflow:Starting iteration 13

Steps executed: 202 Episode length: 98 Return: -116.439213877881683
INFO:tensorflow:Average training steps per second: 367.67
I0901 13:13:51.936183 140315766171648 replay_runner.py:36] Average training steps per second: 367.67
I0901 13:13:52.087935 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.44
INFO:tensorflow:Starting iteration 14
I0901 13:13:55.675483 140315766171648 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 354.38

Steps executed: 248 Episode length: 74 Return: -144.960002791379983
I0901 13:13:58.658900 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -214.04
INFO:tensorflow:Starting iteration 15

Steps executed: 238 Episode length: 102 Return: -210.59788433381226
INFO:tensorflow:Average training steps per second: 342.22
I0901 13:14:05.112355 140315766171648 replay_runner.py:36] Average training steps per second: 342.22
I0901 13:14:05.250365 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.52
INFO:tensorflow:Starting iteration 16

Steps executed: 463 Episode length: 295 Return: -178.46029858531224
INFO:tensorflow:Average training steps per second: 346.28
I0901 13:14:11.674304 140315766171648 replay_runner.py:36] Average training steps per second: 346.28
I0901 13:14:12.079438 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -354.24
INFO:tensorflow:Starting iteration 17

Steps executed: 267 Episode length: 108 Return: -915.14738488635094
INFO:tensorflow:Average training steps per second: 343.63
I0901 13:14:18.533106 140315766171648 replay_runner.py:36] Average training steps per second: 343.63
I0901 13:14:18.706787 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -654.94
INFO:tensorflow:Starting iteration 18

Steps executed: 236 Episode length: 77 Return: -525.185521923635214
INFO:tensorflow:Average training steps per second: 329.79
I0901 13:14:25.181313 140315766171648 replay_runner.py:36] Average training steps per second: 329.79
I0901 13:14:25.338296 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -648.31
INFO:tensorflow:Starting iteration 19

Steps executed: 213 Episode length: 84 Return: -416.738064986142944
INFO:tensorflow:Average training steps per second: 329.55
I0901 13:14:31.821635 140315766171648 replay_runner.py:36] Average training steps per second: 329.55
I0901 13:14:31.939363 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.43
INFO:tensorflow:Starting iteration 20

Steps executed: 234 Episode length: 89 Return: -68.3963600440173144
INFO:tensorflow:Average training steps per second: 331.85
I0901 13:14:38.370526 140315766171648 replay_runner.py:36] Average training steps per second: 331.85
I0901 13:14:38.486262 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.72
INFO:tensorflow:Starting iteration 21

Steps executed: 226 Episode length: 83 Return: -345.455599220583644
INFO:tensorflow:Average training steps per second: 328.85
I0901 13:14:45.017140 140315766171648 replay_runner.py:36] Average training steps per second: 328.85
I0901 13:14:45.125293 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.59
INFO:tensorflow:Starting iteration 22

Steps executed: 227 Episode length: 148 Return: -216.82559115969175
INFO:tensorflow:Average training steps per second: 332.50
I0901 13:14:51.692332 140315766171648 replay_runner.py:36] Average training steps per second: 332.50
I0901 13:14:51.835314 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -251.81
INFO:tensorflow:Starting iteration 23
I0901 13:14:55.307025 140315766171648 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 323.12

Steps executed: 299 Episode length: 220 Return: -281.72289955386775
I0901 13:14:58.583647 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.93
INFO:tensorflow:Starting iteration 24

Steps executed: 260 Episode length: 111 Return: -461.90480334182206
INFO:tensorflow:Average training steps per second: 327.22
I0901 13:15:05.012945 140315766171648 replay_runner.py:36] Average training steps per second: 327.22
I0901 13:15:05.182200 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -499.83
INFO:tensorflow:Starting iteration 25

Steps executed: 256 Episode length: 256 Return: -59.487389224155516
INFO:tensorflow:Average training steps per second: 330.04
I0901 13:15:11.647162 140315766171648 replay_runner.py:36] Average training steps per second: 330.04
I0901 13:15:11.815297 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -59.49
INFO:tensorflow:Starting iteration 26

Steps executed: 237 Episode length: 66 Return: -179.119322132234636
INFO:tensorflow:Average training steps per second: 337.60
I0901 13:15:18.185478 140315766171648 replay_runner.py:36] Average training steps per second: 337.60
I0901 13:15:18.324952 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -387.92
INFO:tensorflow:Starting iteration 27
I0901 13:15:21.652591 140315766171648 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 345.45

Steps executed: 207 Episode length: 74 Return: -125.519308846072626
I0901 13:15:24.668436 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.44
INFO:tensorflow:Starting iteration 28

Steps executed: 293 Episode length: 115 Return: -447.66668902337156
INFO:tensorflow:Average training steps per second: 325.04
I0901 13:15:31.106769 140315766171648 replay_runner.py:36] Average training steps per second: 325.04
I0901 13:15:31.275023 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -358.94
INFO:tensorflow:Starting iteration 29

Steps executed: 266 Episode length: 137 Return: -138.94934653539508
INFO:tensorflow:Average training steps per second: 340.44
I0901 13:15:37.563191 140315766171648 replay_runner.py:36] Average training steps per second: 340.44

Done fixed training!Episode length: 137 Return: -138.94934653539508