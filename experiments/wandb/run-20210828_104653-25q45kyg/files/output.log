I0828 10:46:59.176955 140214119393280 run_experiment.py:549] Creating TrainRunner ...
I0828 10:46:59.184601 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:46:59.184709 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:46:59.184765 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:46:59.184843 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:46:59.184916 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:46:59.185026 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:46:59.185083 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:46:59.185152 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:46:59.185228 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:46:59.185285 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:46:59.185359 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:46:59.185426 140214119393280 dqn_agent.py:283] 	 seed: 1630147619184575
I0828 10:46:59.187233 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:46:59.187353 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:46:59.187435 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:46:59.187505 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:46:59.187579 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:46:59.187633 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:46:59.187712 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:46:59.187771 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:46:59.187828 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:46:59.211267 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:59.514500 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:59.521721 140214119393280 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:46:59.526858 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:46:59.526969 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:46:59.527021 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:46:59.527094 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:46:59.527137 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:46:59.527192 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:46:59.527238 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:46:59.527282 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:46:59.527348 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:46:59.527429 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:46:59.527494 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:46:59.527558 140214119393280 dqn_agent.py:283] 	 seed: 1630147619526837
I0828 10:46:59.528755 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:46:59.528851 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:46:59.528911 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:46:59.528970 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:46:59.529019 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:46:59.529078 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:46:59.529139 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:46:59.529197 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:46:59.529254 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:46:59.545787 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:59.569988 140214119393280 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:46:59.570123 140214119393280 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 266.18
I0828 10:47:03.327115 140214119393280 replay_runner.py:36] Average training steps per second: 266.18
I0828 10:47:04.122407 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -476.22
Steps executed: 256 Episode length: 98 Return: -569.1113721356887
INFO:tensorflow:Starting iteration 1

Steps executed: 247 Episode length: 100 Return: -315.59370853316227
INFO:tensorflow:Average training steps per second: 350.25
I0828 10:47:10.349360 140214119393280 replay_runner.py:36] Average training steps per second: 350.25
I0828 10:47:10.480649 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.68
INFO:tensorflow:Starting iteration 2
I0828 10:47:13.857756 140214119393280 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 336.22

Steps executed: 347 Episode length: 347 Return: -268.95867190678977
I0828 10:47:17.185489 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.96
INFO:tensorflow:Starting iteration 3
I0828 10:47:20.567149 140214119393280 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 345.69

Steps executed: 1000 Episode length: 1000 Return: -143.6879197419622
I0828 10:47:25.781003 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.69
INFO:tensorflow:Starting iteration 4
I0828 10:47:29.180496 140214119393280 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 356.96

Steps executed: 1000 Episode length: 1000 Return: -138.16949566119376
I0828 10:47:34.186017 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.17
INFO:tensorflow:Starting iteration 5
I0828 10:47:37.593781 140214119393280 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 344.06

Steps executed: 1000 Episode length: 1000 Return: -107.72780393226756
I0828 10:47:41.575597 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.73
INFO:tensorflow:Starting iteration 6
I0828 10:47:44.962902 140214119393280 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 342.88

Steps executed: 1000 Episode length: 1000 Return: -202.01838232615996
I0828 10:47:50.258409 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.02
INFO:tensorflow:Starting iteration 7

Steps executed: 285 Episode length: 285 Return: -398.3132012008702996
INFO:tensorflow:Average training steps per second: 364.84
I0828 10:47:56.422057 140214119393280 replay_runner.py:36] Average training steps per second: 364.84
I0828 10:47:56.636188 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -398.31
INFO:tensorflow:Starting iteration 8
I0828 10:48:00.049175 140214119393280 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 340.99
I0828 10:48:02.982068 140214119393280 replay_runner.py:36] Average training steps per second: 340.99

Steps executed: 1000 Episode length: 1000 Return: -197.01247129142084
INFO:tensorflow:Starting iteration 9

Steps executed: 1000 Episode length: 1000 Return: -176.28642758442535
INFO:tensorflow:Average training steps per second: 371.43
I0828 10:48:11.288661 140214119393280 replay_runner.py:36] Average training steps per second: 371.43
I0828 10:48:13.001104 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.29
INFO:tensorflow:Starting iteration 10
I0828 10:48:16.568832 140214119393280 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 381.55

Steps executed: 1000 Episode length: 1000 Return: -195.97780008341664
I0828 10:48:21.632887 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.98
INFO:tensorflow:Starting iteration 11

Steps executed: 448 Episode length: 448 Return: -423.0370987183640664
INFO:tensorflow:Average training steps per second: 361.03
I0828 10:48:27.798785 140214119393280 replay_runner.py:36] Average training steps per second: 361.03
I0828 10:48:28.303161 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -423.04
INFO:tensorflow:Starting iteration 12

Steps executed: 161 Episode length: 161 Return: -102.6139325239059364
INFO:tensorflow:Average training steps per second: 365.61

Steps executed: 1161 Episode length: 1000 Return: -145.11464141779553
I0828 10:48:36.340343 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.86
INFO:tensorflow:Starting iteration 13

Steps executed: 439 Episode length: 270 Return: -49.97393657268344353
INFO:tensorflow:Average training steps per second: 360.77
I0828 10:48:42.573966 140214119393280 replay_runner.py:36] Average training steps per second: 360.77
I0828 10:48:42.890495 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.99
INFO:tensorflow:Starting iteration 14

Steps executed: 142 Episode length: 142 Return: -726.4161307219938353
INFO:tensorflow:Average training steps per second: 361.88
I0828 10:48:49.140563 140214119393280 replay_runner.py:36] Average training steps per second: 361.88

Steps executed: 282 Episode length: 140 Return: -29.79058400098088653
INFO:tensorflow:Starting iteration 15

Steps executed: 264 Episode length: 110 Return: -172.2927364343370353
INFO:tensorflow:Average training steps per second: 341.33
I0828 10:48:55.643203 140214119393280 replay_runner.py:36] Average training steps per second: 341.33
I0828 10:48:55.765498 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.92
INFO:tensorflow:Starting iteration 16
I0828 10:48:58.922995 140214119393280 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 311.85

Steps executed: 1000 Episode length: 1000 Return: -83.241349302642583
I0828 10:49:04.577521 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.24
INFO:tensorflow:Starting iteration 17
I0828 10:49:07.960957 140214119393280 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 322.83
I0828 10:49:11.058862 140214119393280 replay_runner.py:36] Average training steps per second: 322.83

Steps executed: 424 Episode length: 424 Return: -27.00760518975831583
INFO:tensorflow:Starting iteration 18

Steps executed: 820 Episode length: 628 Return: -79.73574760376325583
INFO:tensorflow:Average training steps per second: 326.65
I0828 10:49:17.675928 140214119393280 replay_runner.py:36] Average training steps per second: 326.65
I0828 10:49:18.549683 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -48.73
INFO:tensorflow:Starting iteration 19
I0828 10:49:21.761298 140214119393280 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 321.02

Steps executed: 529 Episode length: 529 Return: -203.5111080866638883
I0828 10:49:25.583328 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.51
INFO:tensorflow:Starting iteration 20

Steps executed: 310 Episode length: 310 Return: -365.2060792552645783
INFO:tensorflow:Average training steps per second: 346.48
I0828 10:49:31.781888 140214119393280 replay_runner.py:36] Average training steps per second: 346.48
I0828 10:49:32.020492 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -365.21
INFO:tensorflow:Starting iteration 21

Steps executed: 369 Episode length: 193 Return: -307.4971955527808583
INFO:tensorflow:Average training steps per second: 338.43
I0828 10:49:38.378499 140214119393280 replay_runner.py:36] Average training steps per second: 338.43
I0828 10:49:38.583769 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.71
INFO:tensorflow:Starting iteration 22
I0828 10:49:41.871994 140214119393280 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 336.40

Steps executed: 650 Episode length: 650 Return: -526.7591155728895583
I0828 10:49:46.004595 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -526.76
INFO:tensorflow:Starting iteration 23

Steps executed: 213 Episode length: 213 Return: 16.409255559063855583
INFO:tensorflow:Average training steps per second: 353.24
I0828 10:49:52.288533 140214119393280 replay_runner.py:36] Average training steps per second: 353.24
I0828 10:49:52.424470 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: 16.41
INFO:tensorflow:Starting iteration 24

Steps executed: 313 Episode length: 125 Return: -33.41192010072817583
INFO:tensorflow:Average training steps per second: 344.38
I0828 10:49:58.680275 140214119393280 replay_runner.py:36] Average training steps per second: 344.38
I0828 10:49:58.866098 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.20
INFO:tensorflow:Starting iteration 25
I0828 10:50:02.176481 140214119393280 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 333.94

Steps executed: 428 Episode length: 428 Return: -72.89832751307209583
I0828 10:50:05.558285 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.90
INFO:tensorflow:Starting iteration 26

Steps executed: 552 Episode length: 552 Return: -612.0021765210681583
INFO:tensorflow:Average training steps per second: 346.07
I0828 10:50:11.804683 140214119393280 replay_runner.py:36] Average training steps per second: 346.07
I0828 10:50:12.540646 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -612.00
INFO:tensorflow:Starting iteration 27

Steps executed: 96 Episode length: 96 Return: -688.346893620171481583
INFO:tensorflow:Average training steps per second: 355.87

Steps executed: 679 Episode length: 583 Return: -506.8374647980775583
I0828 10:50:19.640428 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -597.59
INFO:tensorflow:Starting iteration 28

Steps executed: 399 Episode length: 232 Return: -329.0261448547173383
INFO:tensorflow:Average training steps per second: 359.50
I0828 10:50:25.832938 140214119393280 replay_runner.py:36] Average training steps per second: 359.50
I0828 10:50:26.058055 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.65
INFO:tensorflow:Starting iteration 29

Steps executed: 232 Episode length: 144 Return: -711.0864232464882383
INFO:tensorflow:Average training steps per second: 347.75
I0828 10:50:32.194811 140214119393280 replay_runner.py:36] Average training steps per second: 347.75

Done fixed training!Episode length: 144 Return: -711.0864232464882383