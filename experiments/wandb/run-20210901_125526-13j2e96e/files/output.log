Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0901 12:55:32.963154 139982171817984 run_experiment.py:549] Creating TrainRunner ...
I0901 12:55:32.973982 139982171817984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:55:32.974342 139982171817984 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:55:32.974512 139982171817984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:55:32.974598 139982171817984 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:55:32.974747 139982171817984 dqn_agent.py:275] 	 update_period: 4
I0901 12:55:32.975073 139982171817984 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:55:32.975227 139982171817984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:55:32.975414 139982171817984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:55:32.975513 139982171817984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:55:32.975671 139982171817984 dqn_agent.py:280] 	 optimizer: adam
I0901 12:55:32.975780 139982171817984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:55:32.975857 139982171817984 dqn_agent.py:283] 	 seed: 1630500932973909
I0901 12:55:32.979287 139982171817984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:55:32.979510 139982171817984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:55:32.979702 139982171817984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:55:32.979817 139982171817984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:55:32.979888 139982171817984 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:55:32.980009 139982171817984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:55:32.980109 139982171817984 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:55:32.980191 139982171817984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:55:32.980291 139982171817984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:55:33.045719 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:55:33.430836 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:55:33.445642 139982171817984 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:55:33.475694 139982171817984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:55:33.475935 139982171817984 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:55:33.476062 139982171817984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:55:33.476140 139982171817984 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:55:33.476197 139982171817984 dqn_agent.py:275] 	 update_period: 4
I0901 12:55:33.476253 139982171817984 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:55:33.476372 139982171817984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:55:33.476470 139982171817984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:55:33.476598 139982171817984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:55:33.476794 139982171817984 dqn_agent.py:280] 	 optimizer: adam
I0901 12:55:33.476888 139982171817984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:55:33.477203 139982171817984 dqn_agent.py:283] 	 seed: 1630500933475629
I0901 12:55:33.480269 139982171817984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:55:33.480436 139982171817984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:55:33.480548 139982171817984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:55:33.480626 139982171817984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:55:33.480702 139982171817984 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:55:33.480806 139982171817984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:55:33.480922 139982171817984 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:55:33.481036 139982171817984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:55:33.481126 139982171817984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:55:33.518325 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:55:33.540468 139982171817984 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:55:33.540802 139982171817984 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 155.77
I0901 12:55:39.960890 139982171817984 replay_runner.py:36] Average training steps per second: 155.77
Steps executed: 210 Episode length: 68 Return: -693.8493080643003
I0901 12:55:41.157495 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -664.02
INFO:tensorflow:Starting iteration 1

Steps executed: 226 Episode length: 81 Return: -678.8676197738628
INFO:tensorflow:Average training steps per second: 228.28
I0901 12:55:49.972009 139982171817984 replay_runner.py:36] Average training steps per second: 228.28
I0901 12:55:50.196700 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -641.22
INFO:tensorflow:Starting iteration 2

Steps executed: 272 Episode length: 97 Return: -268.36699459484464
INFO:tensorflow:Average training steps per second: 227.19
I0901 12:55:58.907054 139982171817984 replay_runner.py:36] Average training steps per second: 227.19
I0901 12:55:59.151671 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.12
INFO:tensorflow:Starting iteration 3

Steps executed: 266 Episode length: 175 Return: -384.9607118816368
INFO:tensorflow:Average training steps per second: 228.09
I0901 12:56:07.937259 139982171817984 replay_runner.py:36] Average training steps per second: 228.09
I0901 12:56:08.184026 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.82
INFO:tensorflow:Starting iteration 4

Steps executed: 263 Episode length: 87 Return: -478.366679609017878
INFO:tensorflow:Average training steps per second: 226.65
I0901 12:56:17.056244 139982171817984 replay_runner.py:36] Average training steps per second: 226.65
I0901 12:56:17.291252 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -444.63
INFO:tensorflow:Starting iteration 5

Steps executed: 211 Episode length: 211 Return: -153.25203874291435
INFO:tensorflow:Average training steps per second: 221.78
I0901 12:56:26.205371 139982171817984 replay_runner.py:36] Average training steps per second: 221.78
I0901 12:56:26.415727 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.25
INFO:tensorflow:Starting iteration 6

Steps executed: 227 Episode length: 129 Return: -276.36701011676785
INFO:tensorflow:Average training steps per second: 225.05
I0901 12:56:35.243995 139982171817984 replay_runner.py:36] Average training steps per second: 225.05
I0901 12:56:35.464450 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -483.85
INFO:tensorflow:Starting iteration 7

Steps executed: 233 Episode length: 233 Return: -601.07225042182925
INFO:tensorflow:Average training steps per second: 240.08
I0901 12:56:43.855742 139982171817984 replay_runner.py:36] Average training steps per second: 240.08
I0901 12:56:44.090855 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -601.07
INFO:tensorflow:Starting iteration 8

Steps executed: 201 Episode length: 201 Return: -398.76877880716445
INFO:tensorflow:Average training steps per second: 226.41
I0901 12:56:52.949574 139982171817984 replay_runner.py:36] Average training steps per second: 226.41
I0901 12:56:53.150569 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -398.77
INFO:tensorflow:Starting iteration 9

Steps executed: 302 Episode length: 165 Return: -158.26238589664456
INFO:tensorflow:Average training steps per second: 223.50
I0901 12:57:01.919912 139982171817984 replay_runner.py:36] Average training steps per second: 223.50
I0901 12:57:02.177492 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.51
INFO:tensorflow:Starting iteration 10
I0901 12:57:06.618781 139982171817984 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 225.63

Steps executed: 244 Episode length: 117 Return: -206.95628146681804
I0901 12:57:11.272466 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.61
INFO:tensorflow:Starting iteration 11

Steps executed: 291 Episode length: 127 Return: -299.87315432045136
INFO:tensorflow:Average training steps per second: 221.82
I0901 12:57:20.162347 139982171817984 replay_runner.py:36] Average training steps per second: 221.82
I0901 12:57:20.428547 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.00
INFO:tensorflow:Starting iteration 12

Steps executed: 352 Episode length: 161 Return: -83.285409541877396
INFO:tensorflow:Average training steps per second: 220.86
I0901 12:57:29.225664 139982171817984 replay_runner.py:36] Average training steps per second: 220.86
I0901 12:57:29.531986 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -286.24
INFO:tensorflow:Starting iteration 13

Steps executed: 207 Episode length: 90 Return: -199.810178703454486
INFO:tensorflow:Average training steps per second: 218.65
I0901 12:57:38.429002 139982171817984 replay_runner.py:36] Average training steps per second: 218.65
I0901 12:57:38.609565 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.85
INFO:tensorflow:Starting iteration 14

Steps executed: 260 Episode length: 111 Return: -295.82910670654275
INFO:tensorflow:Average training steps per second: 212.10
I0901 12:57:47.719232 139982171817984 replay_runner.py:36] Average training steps per second: 212.10
I0901 12:57:47.966683 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.14
INFO:tensorflow:Starting iteration 15

Steps executed: 258 Episode length: 93 Return: -235.780594472669807
INFO:tensorflow:Average training steps per second: 220.17
I0901 12:57:56.822427 139982171817984 replay_runner.py:36] Average training steps per second: 220.17
I0901 12:57:57.039835 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -295.74
INFO:tensorflow:Starting iteration 16

Steps executed: 340 Episode length: 217 Return: -128.92004017453652
INFO:tensorflow:Average training steps per second: 220.29
I0901 12:58:05.838909 139982171817984 replay_runner.py:36] Average training steps per second: 220.29
I0901 12:58:06.165729 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.95
INFO:tensorflow:Starting iteration 17

Steps executed: 263 Episode length: 81 Return: -361.977924770183852
INFO:tensorflow:Average training steps per second: 222.69
I0901 12:58:14.831133 139982171817984 replay_runner.py:36] Average training steps per second: 222.69
I0901 12:58:15.045330 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.71
INFO:tensorflow:Starting iteration 18

Steps executed: 218 Episode length: 131 Return: -239.52376487076642
INFO:tensorflow:Average training steps per second: 217.10
I0901 12:58:24.143052 139982171817984 replay_runner.py:36] Average training steps per second: 217.10
I0901 12:58:24.343638 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.42
INFO:tensorflow:Starting iteration 19
I0901 12:58:28.785417 139982171817984 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 224.51

Steps executed: 347 Episode length: 258 Return: -286.09257851540592
I0901 12:58:33.662754 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.57
INFO:tensorflow:Starting iteration 20

Steps executed: 422 Episode length: 261 Return: -393.51239716531154
INFO:tensorflow:Average training steps per second: 225.50
I0901 12:58:42.434371 139982171817984 replay_runner.py:36] Average training steps per second: 225.50
I0901 12:58:42.896057 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -435.67
INFO:tensorflow:Starting iteration 21

Steps executed: 148 Episode length: 148 Return: -256.51075324558985
INFO:tensorflow:Average training steps per second: 217.86

Steps executed: 1148 Episode length: 1000 Return: 36.21047835404044
I0901 12:58:54.267505 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.15
INFO:tensorflow:Starting iteration 22
I0901 12:58:58.343436 139982171817984 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 216.20

Steps executed: 209 Episode length: 110 Return: -361.93278930415397
I0901 12:59:03.139439 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -295.68
INFO:tensorflow:Starting iteration 23

Steps executed: 304 Episode length: 107 Return: -104.68368335627547
INFO:tensorflow:Average training steps per second: 220.29
I0901 12:59:12.120117 139982171817984 replay_runner.py:36] Average training steps per second: 220.29
I0901 12:59:12.399061 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.47
INFO:tensorflow:Starting iteration 24

Steps executed: 320 Episode length: 192 Return: -250.34644438082165
INFO:tensorflow:Average training steps per second: 223.86
I0901 12:59:21.330106 139982171817984 replay_runner.py:36] Average training steps per second: 223.86
I0901 12:59:21.654114 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -294.23
INFO:tensorflow:Starting iteration 25

Steps executed: 171 Episode length: 171 Return: -141.66560913644065
INFO:tensorflow:Average training steps per second: 215.06
I0901 12:59:30.849504 139982171817984 replay_runner.py:36] Average training steps per second: 215.06

Steps executed: 287 Episode length: 116 Return: -154.37756838383797
INFO:tensorflow:Starting iteration 26

Steps executed: 203 Episode length: 111 Return: -289.87744480358515
INFO:tensorflow:Average training steps per second: 222.65
I0901 12:59:39.999911 139982171817984 replay_runner.py:36] Average training steps per second: 222.65
I0901 12:59:40.195622 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -323.34
INFO:tensorflow:Starting iteration 27
I0901 12:59:44.667495 139982171817984 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 220.17

Steps executed: 326 Episode length: 167 Return: -15.962164451392056
I0901 12:59:49.497879 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.44
INFO:tensorflow:Starting iteration 28

Steps executed: 294 Episode length: 294 Return: -449.04085689671024
INFO:tensorflow:Average training steps per second: 222.65
I0901 12:59:58.280923 139982171817984 replay_runner.py:36] Average training steps per second: 222.65
I0901 12:59:58.719430 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -449.04
INFO:tensorflow:Starting iteration 29

Steps executed: 272 Episode length: 169 Return: -69.426601661887676
INFO:tensorflow:Average training steps per second: 224.16
I0901 13:00:07.463285 139982171817984 replay_runner.py:36] Average training steps per second: 224.16

Done fixed training!Episode length: 169 Return: -69.426601661887676