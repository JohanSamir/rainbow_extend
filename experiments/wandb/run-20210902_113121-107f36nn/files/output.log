Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0902 11:31:27.241849 140427886061568 run_experiment.py:549] Creating TrainRunner ...
I0902 11:31:27.255130 140427886061568 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 11:31:27.255359 140427886061568 dqn_agent.py:272] 	 gamma: 0.990000
I0902 11:31:27.255465 140427886061568 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 11:31:27.255577 140427886061568 dqn_agent.py:274] 	 min_replay_history: 500
I0902 11:31:27.255652 140427886061568 dqn_agent.py:275] 	 update_period: 4
I0902 11:31:27.255824 140427886061568 dqn_agent.py:276] 	 target_update_period: 300
I0902 11:31:27.256109 140427886061568 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 11:31:27.256220 140427886061568 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 11:31:27.256301 140427886061568 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 11:31:27.256383 140427886061568 dqn_agent.py:280] 	 optimizer: adam
I0902 11:31:27.256457 140427886061568 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 11:31:27.256528 140427886061568 dqn_agent.py:283] 	 seed: 1630582287255063
I0902 11:31:27.259131 140427886061568 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 11:31:27.259289 140427886061568 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 11:31:27.259439 140427886061568 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 11:31:27.259595 140427886061568 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 11:31:27.259767 140427886061568 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 11:31:27.259846 140427886061568 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 11:31:27.259920 140427886061568 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 11:31:27.260033 140427886061568 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 11:31:27.260107 140427886061568 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 11:31:27.455569 140427886061568 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:27.706582 140427886061568 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:27.716166 140427886061568 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 11:31:27.734388 140427886061568 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 11:31:27.734549 140427886061568 dqn_agent.py:272] 	 gamma: 0.990000
I0902 11:31:27.734639 140427886061568 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 11:31:27.734704 140427886061568 dqn_agent.py:274] 	 min_replay_history: 500
I0902 11:31:27.735032 140427886061568 dqn_agent.py:275] 	 update_period: 4
I0902 11:31:27.735143 140427886061568 dqn_agent.py:276] 	 target_update_period: 300
I0902 11:31:27.735262 140427886061568 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 11:31:27.735327 140427886061568 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 11:31:27.735388 140427886061568 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 11:31:27.735540 140427886061568 dqn_agent.py:280] 	 optimizer: adam
I0902 11:31:27.735631 140427886061568 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 11:31:27.735722 140427886061568 dqn_agent.py:283] 	 seed: 1630582287734345
I0902 11:31:27.737962 140427886061568 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 11:31:27.738133 140427886061568 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 11:31:27.738244 140427886061568 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 11:31:27.738342 140427886061568 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 11:31:27.738422 140427886061568 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 11:31:27.738500 140427886061568 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 11:31:27.738598 140427886061568 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 11:31:27.738722 140427886061568 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 11:31:27.738809 140427886061568 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 11:31:27.776405 140427886061568 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:27.796742 140427886061568 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 11:31:27.796953 140427886061568 replay_runner.py:41] Starting iteration 0
Steps executed: 254 Episode length: 118 Return: -203.01879541273905
INFO:tensorflow:Average training steps per second: 199.08
I0902 11:31:32.820237 140427886061568 replay_runner.py:36] Average training steps per second: 199.08
I0902 11:31:33.801450 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.48
INFO:tensorflow:Starting iteration 1

Steps executed: 206 Episode length: 206 Return: -307.23299870967265
INFO:tensorflow:Average training steps per second: 336.95
I0902 11:31:40.187194 140427886061568 replay_runner.py:36] Average training steps per second: 336.95
I0902 11:31:40.330001 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.23
INFO:tensorflow:Starting iteration 2
I0902 11:31:43.822615 140427886061568 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 346.50

Steps executed: 1000 Episode length: 1000 Return: -44.00417036256418
I0902 11:31:49.139237 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -44.00
INFO:tensorflow:Starting iteration 3
I0902 11:31:52.569505 140427886061568 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 348.33

Steps executed: 1000 Episode length: 1000 Return: -80.70791400080178
I0902 11:31:57.206863 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.71
INFO:tensorflow:Starting iteration 4

Steps executed: 186 Episode length: 186 Return: -138.878246273959328
INFO:tensorflow:Average training steps per second: 360.19

Steps executed: 1186 Episode length: 1000 Return: -202.89455106233623
I0902 11:32:05.436846 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.89
INFO:tensorflow:Starting iteration 5

Steps executed: 224 Episode length: 224 Return: -19.03139700636727623
INFO:tensorflow:Average training steps per second: 347.32
I0902 11:32:11.754262 140427886061568 replay_runner.py:36] Average training steps per second: 347.32
I0902 11:32:11.904633 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -19.03
INFO:tensorflow:Starting iteration 6
I0902 11:32:15.418938 140427886061568 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 355.98

Steps executed: 1000 Episode length: 1000 Return: -238.10984944909788
I0902 11:32:19.696853 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -238.11
INFO:tensorflow:Starting iteration 7
I0902 11:32:23.143518 140427886061568 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 338.75

Steps executed: 1000 Episode length: 1000 Return: -178.08594832650996
I0902 11:32:28.232274 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.09
INFO:tensorflow:Starting iteration 8
I0902 11:32:31.673949 140427886061568 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 334.13

Steps executed: 467 Episode length: 467 Return: -105.8416450403928996
I0902 11:32:35.231775 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.84
INFO:tensorflow:Starting iteration 9

Steps executed: 590 Episode length: 590 Return: -315.4659668910401996
INFO:tensorflow:Average training steps per second: 326.89
I0902 11:32:41.659967 140427886061568 replay_runner.py:36] Average training steps per second: 326.89
I0902 11:32:42.449016 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -315.47
INFO:tensorflow:Starting iteration 10
I0902 11:32:45.818679 140427886061568 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 330.33

Steps executed: 1000 Episode length: 1000 Return: -91.847727678293986
I0902 11:32:50.779633 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.85
INFO:tensorflow:Starting iteration 11
I0902 11:32:54.179748 140427886061568 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 334.59

Steps executed: 1000 Episode length: 1000 Return: -351.94153655523656
I0902 11:32:59.087400 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -351.94
INFO:tensorflow:Starting iteration 12

Steps executed: 476 Episode length: 476 Return: -74.11865020642583656
INFO:tensorflow:Average training steps per second: 357.41
I0902 11:33:05.359357 140427886061568 replay_runner.py:36] Average training steps per second: 357.41
I0902 11:33:05.978409 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.12
INFO:tensorflow:Starting iteration 13
I0902 11:33:09.365467 140427886061568 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 328.20

Steps executed: 1000 Episode length: 1000 Return: -75.175117136738156
I0902 11:33:13.772685 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.18
INFO:tensorflow:Starting iteration 14

Steps executed: 422 Episode length: 422 Return: -270.1215520636895356
INFO:tensorflow:Average training steps per second: 339.95
I0902 11:33:20.178612 140427886061568 replay_runner.py:36] Average training steps per second: 339.95
I0902 11:33:20.523626 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.12
INFO:tensorflow:Starting iteration 15
I0902 11:33:23.935770 140427886061568 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 331.50

Steps executed: 545 Episode length: 545 Return: 211.20716988909456356
I0902 11:33:27.482597 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: 211.21
INFO:tensorflow:Starting iteration 16

Steps executed: 704 Episode length: 704 Return: -339.5411106576141356
INFO:tensorflow:Average training steps per second: 322.03
I0902 11:33:33.900217 140427886061568 replay_runner.py:36] Average training steps per second: 322.03
I0902 11:33:34.829090 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -339.54
INFO:tensorflow:Starting iteration 17
I0902 11:33:38.110398 140427886061568 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 321.58
I0902 11:33:41.220393 140427886061568 replay_runner.py:36] Average training steps per second: 321.58

Steps executed: 389 Episode length: 389 Return: -63.84998538246258356
INFO:tensorflow:Starting iteration 18
I0902 11:33:44.919618 140427886061568 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 305.02

Steps executed: 1000 Episode length: 1000 Return: -199.04284216637282
I0902 11:33:50.221572 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.04
INFO:tensorflow:Starting iteration 19

Steps executed: 147 Episode length: 147 Return: -59.00761904126474682
INFO:tensorflow:Average training steps per second: 326.37
I0902 11:33:56.694032 140427886061568 replay_runner.py:36] Average training steps per second: 326.37

Steps executed: 658 Episode length: 511 Return: 245.67805236013922682
INFO:tensorflow:Starting iteration 20

Steps executed: 581 Episode length: 581 Return: -174.5605419532846682
INFO:tensorflow:Average training steps per second: 319.29
I0902 11:34:03.925049 140427886061568 replay_runner.py:36] Average training steps per second: 319.29
I0902 11:34:04.605952 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.56
INFO:tensorflow:Starting iteration 21
I0902 11:34:07.973672 140427886061568 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 332.58

Steps executed: 1000 Episode length: 1000 Return: 49.7306281589514382
I0902 11:34:12.485834 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: 49.73
INFO:tensorflow:Starting iteration 22
I0902 11:34:15.825548 140427886061568 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 322.43

Steps executed: 1000 Episode length: 1000 Return: -54.706214809587492
I0902 11:34:21.020445 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.71
INFO:tensorflow:Starting iteration 23
I0902 11:34:24.352787 140427886061568 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 313.28

Steps executed: 1000 Episode length: 1000 Return: 55.3570776672841492
I0902 11:34:29.488685 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: 55.36
INFO:tensorflow:Starting iteration 24

Steps executed: 221 Episode length: 221 Return: -16.64469274958151492
INFO:tensorflow:Average training steps per second: 326.29
I0902 11:34:35.965663 140427886061568 replay_runner.py:36] Average training steps per second: 326.29
I0902 11:34:36.128720 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -16.64
INFO:tensorflow:Starting iteration 25

Steps executed: 345 Episode length: 345 Return: -198.7731607855187792
INFO:tensorflow:Average training steps per second: 312.69
I0902 11:34:42.301562 140427886061568 replay_runner.py:36] Average training steps per second: 312.69
I0902 11:34:42.616085 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.77
INFO:tensorflow:Starting iteration 26
I0902 11:34:45.714176 140427886061568 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 310.91

Steps executed: 1000 Episode length: 1000 Return: 154.958294249860442
I0902 11:34:50.538754 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: 154.96
INFO:tensorflow:Starting iteration 27

Steps executed: 457 Episode length: 457 Return: -434.5509085736882442
INFO:tensorflow:Average training steps per second: 332.42
I0902 11:34:56.818120 140427886061568 replay_runner.py:36] Average training steps per second: 332.42
I0902 11:34:57.318085 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -434.55
INFO:tensorflow:Starting iteration 28
I0902 11:35:00.608594 140427886061568 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 348.05

Steps executed: 359 Episode length: 359 Return: -190.0572199522927742
I0902 11:35:03.786719 140427886061568 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.06
INFO:tensorflow:Starting iteration 29

Steps executed: 524 Episode length: 524 Return: -126.0852065136102642
INFO:tensorflow:Average training steps per second: 351.68
I0902 11:35:09.821054 140427886061568 replay_runner.py:36] Average training steps per second: 351.68

Done fixed training!Episode length: 524 Return: -126.0852065136102642