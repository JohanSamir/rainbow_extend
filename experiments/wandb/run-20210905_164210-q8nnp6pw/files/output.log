I0905 16:42:17.083903 140035672414208 run_experiment.py:549] Creating TrainRunner ...
I0905 16:42:17.100195 140035672414208 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:42:17.100423 140035672414208 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:42:17.100565 140035672414208 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:42:17.100692 140035672414208 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:42:17.100779 140035672414208 dqn_agent.py:275] 	 update_period: 4
I0905 16:42:17.100906 140035672414208 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:42:17.101062 140035672414208 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:42:17.101145 140035672414208 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:42:17.101251 140035672414208 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:42:17.101348 140035672414208 dqn_agent.py:280] 	 optimizer: adam
I0905 16:42:17.101432 140035672414208 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:42:17.101512 140035672414208 dqn_agent.py:283] 	 seed: 1630860137100148
I0905 16:42:17.104788 140035672414208 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:42:17.105066 140035672414208 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:42:17.105246 140035672414208 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:42:17.105376 140035672414208 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:42:17.105462 140035672414208 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:42:17.105564 140035672414208 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:42:17.105649 140035672414208 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:42:17.105739 140035672414208 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:42:17.105811 140035672414208 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0905 16:42:18.753840 140035672414208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:42:19.646334 140035672414208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:42:19.661055 140035672414208 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:42:19.669582 140035672414208 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:42:19.669774 140035672414208 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:42:19.669878 140035672414208 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:42:19.669962 140035672414208 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:42:19.670249 140035672414208 dqn_agent.py:275] 	 update_period: 4
I0905 16:42:19.670364 140035672414208 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:42:19.670439 140035672414208 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:42:19.670511 140035672414208 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:42:19.670586 140035672414208 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:42:19.670681 140035672414208 dqn_agent.py:280] 	 optimizer: adam
I0905 16:42:19.670789 140035672414208 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:42:19.670873 140035672414208 dqn_agent.py:283] 	 seed: 1630860139669535
I0905 16:42:19.673991 140035672414208 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:42:19.674149 140035672414208 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:42:19.674252 140035672414208 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:42:19.674335 140035672414208 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:42:19.674414 140035672414208 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:42:19.674765 140035672414208 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:42:19.674909 140035672414208 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:42:19.675102 140035672414208 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:42:19.675337 140035672414208 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:42:19.706265 140035672414208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:42:19.730314 140035672414208 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:42:19.730805 140035672414208 replay_runner.py:41] Starting iteration 0
Steps executed: 285 Episode length: 143 Return: -272.12768346555826
INFO:tensorflow:Average training steps per second: 180.00
I0905 16:42:25.286654 140035672414208 replay_runner.py:36] Average training steps per second: 180.00
I0905 16:42:26.506114 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.57
INFO:tensorflow:Starting iteration 1

Steps executed: 288 Episode length: 157 Return: -397.87634435334644
INFO:tensorflow:Average training steps per second: 218.25
I0905 16:42:35.310392 140035672414208 replay_runner.py:36] Average training steps per second: 218.25
I0905 16:42:35.651865 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.05
INFO:tensorflow:Starting iteration 2

Steps executed: 391 Episode length: 241 Return: -517.06191532580244
INFO:tensorflow:Average training steps per second: 271.99
I0905 16:42:43.507782 140035672414208 replay_runner.py:36] Average training steps per second: 271.99
I0905 16:42:44.005682 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.41
INFO:tensorflow:Starting iteration 3
I0905 16:42:48.279382 140035672414208 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 263.49

Steps executed: 1000 Episode length: 1000 Return: -146.3502687658359
I0905 16:42:55.799523 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.35
INFO:tensorflow:Starting iteration 4
I0905 16:43:00.062581 140035672414208 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 253.77
I0905 16:43:04.003841 140035672414208 replay_runner.py:36] Average training steps per second: 253.77

Steps executed: 1000 Episode length: 1000 Return: -285.16101476005116
INFO:tensorflow:Starting iteration 5
I0905 16:43:10.956256 140035672414208 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 244.01

Steps executed: 1000 Episode length: 1000 Return: -195.37328021026585
I0905 16:43:18.469496 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.37
INFO:tensorflow:Starting iteration 6
I0905 16:43:22.506640 140035672414208 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 241.50

Steps executed: 1000 Episode length: 1000 Return: -107.76772087196595
I0905 16:43:29.360471 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.77
INFO:tensorflow:Starting iteration 7
I0905 16:43:33.336990 140035672414208 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 256.23

Steps executed: 345 Episode length: 345 Return: -248.4272692968200795
I0905 16:43:37.794916 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.43
INFO:tensorflow:Starting iteration 8
I0905 16:43:41.918115 140035672414208 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 260.80

Steps executed: 810 Episode length: 810 Return: -363.9661788652602595
I0905 16:43:48.457637 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -363.97
INFO:tensorflow:Starting iteration 9
I0905 16:43:52.465192 140035672414208 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 253.16

Steps executed: 1000 Episode length: 1000 Return: -178.32167786442165
I0905 16:44:00.190336 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.32
INFO:tensorflow:Starting iteration 10
I0905 16:44:04.117123 140035672414208 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 237.16

Steps executed: 1000 Episode length: 1000 Return: -140.77436366067704
I0905 16:44:11.047908 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.77
INFO:tensorflow:Starting iteration 11
I0905 16:44:14.882677 140035672414208 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 225.67

Steps executed: 1000 Episode length: 1000 Return: -153.41840746225724
I0905 16:44:23.232879 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.42
INFO:tensorflow:Starting iteration 12
I0905 16:44:27.488546 140035672414208 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 254.31

Steps executed: 979 Episode length: 979 Return: -393.5137939776348724
I0905 16:44:33.320846 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -393.51
INFO:tensorflow:Starting iteration 13

Steps executed: 211 Episode length: 211 Return: -167.2692940661804424
INFO:tensorflow:Average training steps per second: 262.91
I0905 16:44:41.374473 140035672414208 replay_runner.py:36] Average training steps per second: 262.91
I0905 16:44:41.580417 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.27
INFO:tensorflow:Starting iteration 14

Steps executed: 300 Episode length: 300 Return: -94.06882192591323424
INFO:tensorflow:Average training steps per second: 232.29
I0905 16:44:49.585606 140035672414208 replay_runner.py:36] Average training steps per second: 232.29
I0905 16:44:49.934355 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.07
INFO:tensorflow:Starting iteration 15

Steps executed: 223 Episode length: 223 Return: -12.08026238822046124
INFO:tensorflow:Average training steps per second: 235.21
I0905 16:44:58.157705 140035672414208 replay_runner.py:36] Average training steps per second: 235.21
I0905 16:44:58.445365 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -12.08
INFO:tensorflow:Starting iteration 16

Steps executed: 233 Episode length: 116 Return: -609.2589636758191124
INFO:tensorflow:Average training steps per second: 243.61
I0905 16:45:06.493714 140035672414208 replay_runner.py:36] Average training steps per second: 243.61
I0905 16:45:06.722585 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -619.53
INFO:tensorflow:Starting iteration 17

Steps executed: 262 Episode length: 161 Return: 47.443461999781451124
INFO:tensorflow:Average training steps per second: 260.09
I0905 16:45:14.751965 140035672414208 replay_runner.py:36] Average training steps per second: 260.09
I0905 16:45:15.037938 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: 27.49
INFO:tensorflow:Starting iteration 18
I0905 16:45:19.223837 140035672414208 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 248.32

Steps executed: 418 Episode length: 265 Return: -72.07724355335377124
I0905 16:45:23.786165 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.68
INFO:tensorflow:Starting iteration 19

Steps executed: 201 Episode length: 201 Return: -57.66241315516922124
INFO:tensorflow:Average training steps per second: 255.24
I0905 16:45:31.789328 140035672414208 replay_runner.py:36] Average training steps per second: 255.24
I0905 16:45:32.040656 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.66
INFO:tensorflow:Starting iteration 20

Steps executed: 241 Episode length: 119 Return: -123.2143482423141324
INFO:tensorflow:Average training steps per second: 236.84
I0905 16:45:40.395387 140035672414208 replay_runner.py:36] Average training steps per second: 236.84
I0905 16:45:40.638960 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.62
INFO:tensorflow:Starting iteration 21

Steps executed: 223 Episode length: 223 Return: -473.5122581572968324
INFO:tensorflow:Average training steps per second: 233.02
I0905 16:45:48.996081 140035672414208 replay_runner.py:36] Average training steps per second: 233.02
I0905 16:45:49.237772 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -473.51
INFO:tensorflow:Starting iteration 22

Steps executed: 295 Episode length: 163 Return: -177.3834394129220324
INFO:tensorflow:Average training steps per second: 222.29
I0905 16:45:57.495781 140035672414208 replay_runner.py:36] Average training steps per second: 222.29
I0905 16:45:57.786875 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.64
INFO:tensorflow:Starting iteration 23

Steps executed: 288 Episode length: 162 Return: -659.0848056237191724
INFO:tensorflow:Average training steps per second: 227.73
I0905 16:46:05.924290 140035672414208 replay_runner.py:36] Average training steps per second: 227.73
I0905 16:46:06.329164 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -560.01
INFO:tensorflow:Starting iteration 24

Steps executed: 272 Episode length: 125 Return: -800.1911447041006724
INFO:tensorflow:Average training steps per second: 249.45
I0905 16:46:14.245680 140035672414208 replay_runner.py:36] Average training steps per second: 249.45
I0905 16:46:14.607587 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -555.70
INFO:tensorflow:Starting iteration 25

Steps executed: 226 Episode length: 118 Return: -709.2145772707116724
INFO:tensorflow:Average training steps per second: 263.97
I0905 16:46:22.555981 140035672414208 replay_runner.py:36] Average training steps per second: 263.97
I0905 16:46:22.795463 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -675.86
INFO:tensorflow:Starting iteration 26

Steps executed: 296 Episode length: 122 Return: -367.7497149836416424
INFO:tensorflow:Average training steps per second: 246.26
I0905 16:46:30.905881 140035672414208 replay_runner.py:36] Average training steps per second: 246.26
I0905 16:46:31.185025 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -343.94
INFO:tensorflow:Starting iteration 27
I0905 16:46:34.964035 140035672414208 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 231.18
I0905 16:46:39.290234 140035672414208 replay_runner.py:36] Average training steps per second: 231.18

Steps executed: 296 Episode length: 137 Return: -527.4527972252915424
INFO:tensorflow:Starting iteration 28
I0905 16:46:43.279320 140035672414208 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 246.98
I0905 16:46:47.328534 140035672414208 replay_runner.py:36] Average training steps per second: 246.98

Steps executed: 300 Episode length: 186 Return: -49.22505825753588224
INFO:tensorflow:Starting iteration 29

Steps executed: 68 Episode length: 68 Return: -314.216535028627858224
INFO:tensorflow:Average training steps per second: 274.57
I0905 16:46:55.130377 140035672414208 replay_runner.py:36] Average training steps per second: 274.57


Done fixed training!Episode length: 120 Return: -589.1746604483425224