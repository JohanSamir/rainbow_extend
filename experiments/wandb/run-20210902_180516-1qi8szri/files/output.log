Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0902 18:05:23.025919 140216164177920 run_experiment.py:549] Creating TrainRunner ...
I0902 18:05:23.036980 140216164177920 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:05:23.037214 140216164177920 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:05:23.037408 140216164177920 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:05:23.037517 140216164177920 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:05:23.037631 140216164177920 dqn_agent.py:275] 	 update_period: 4
I0902 18:05:23.037770 140216164177920 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:05:23.037926 140216164177920 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:05:23.038065 140216164177920 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:05:23.038142 140216164177920 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:05:23.038228 140216164177920 dqn_agent.py:280] 	 optimizer: adam
I0902 18:05:23.038414 140216164177920 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:05:23.038574 140216164177920 dqn_agent.py:283] 	 seed: 1630605923036907
I0902 18:05:23.041588 140216164177920 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:05:23.041745 140216164177920 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:05:23.041880 140216164177920 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:05:23.041986 140216164177920 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:05:23.042149 140216164177920 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:05:23.042274 140216164177920 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:05:23.042376 140216164177920 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:05:23.042511 140216164177920 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:05:23.042603 140216164177920 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:05:23.078002 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.312500
I0902 18:05:23.469761 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.312500
I0902 18:05:23.482266 140216164177920 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:05:23.491547 140216164177920 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:05:23.491739 140216164177920 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:05:23.491816 140216164177920 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:05:23.491879 140216164177920 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:05:23.491935 140216164177920 dqn_agent.py:275] 	 update_period: 4
I0902 18:05:23.492013 140216164177920 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:05:23.492103 140216164177920 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:05:23.492159 140216164177920 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:05:23.492223 140216164177920 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:05:23.492303 140216164177920 dqn_agent.py:280] 	 optimizer: adam
I0902 18:05:23.492384 140216164177920 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:05:23.492459 140216164177920 dqn_agent.py:283] 	 seed: 1630605923491497
I0902 18:05:23.494758 140216164177920 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:05:23.494989 140216164177920 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:05:23.495528 140216164177920 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:05:23.495713 140216164177920 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:05:23.495826 140216164177920 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:05:23.495939 140216164177920 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:05:23.496048 140216164177920 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:05:23.496155 140216164177920 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:05:23.496279 140216164177920 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:05:23.566144 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.312500
I0902 18:05:23.588195 140216164177920 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:05:23.588442 140216164177920 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 163.85
I0902 18:05:29.691948 140216164177920 replay_runner.py:36] Average training steps per second: 163.85
I0902 18:05:30.969835 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -654.44
Steps executed: 308 Episode length: 146 Return: -771.211688995374
INFO:tensorflow:Starting iteration 1

Steps executed: 239 Episode length: 93 Return: -579.28601859433555
INFO:tensorflow:Average training steps per second: 225.78
I0902 18:05:39.689333 140216164177920 replay_runner.py:36] Average training steps per second: 225.78
I0902 18:05:39.903079 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -634.33
INFO:tensorflow:Starting iteration 2
I0902 18:05:44.261110 140216164177920 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 230.67

Steps executed: 275 Episode length: 148 Return: -577.92733563057036
I0902 18:05:48.843147 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -383.36
INFO:tensorflow:Starting iteration 3

Steps executed: 285 Episode length: 104 Return: -280.66176842041943
INFO:tensorflow:Average training steps per second: 232.54
I0902 18:05:57.441260 140216164177920 replay_runner.py:36] Average training steps per second: 232.54
I0902 18:05:57.706942 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.82
INFO:tensorflow:Starting iteration 4

Steps executed: 209 Episode length: 209 Return: -350.52077245736383
INFO:tensorflow:Average training steps per second: 231.03
I0902 18:06:06.342538 140216164177920 replay_runner.py:36] Average training steps per second: 231.03
I0902 18:06:06.535291 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -350.52
INFO:tensorflow:Starting iteration 5

Steps executed: 292 Episode length: 157 Return: -360.70812491782512
INFO:tensorflow:Average training steps per second: 220.82
I0902 18:06:15.158325 140216164177920 replay_runner.py:36] Average training steps per second: 220.82
I0902 18:06:15.398506 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.91
INFO:tensorflow:Starting iteration 6

Steps executed: 202 Episode length: 202 Return: -585.86415242329912
INFO:tensorflow:Average training steps per second: 217.67
I0902 18:06:24.332433 140216164177920 replay_runner.py:36] Average training steps per second: 217.67
I0902 18:06:24.514651 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -585.86
INFO:tensorflow:Starting iteration 7

Steps executed: 258 Episode length: 158 Return: -322.04591648289322
INFO:tensorflow:Average training steps per second: 224.71
I0902 18:06:33.324644 140216164177920 replay_runner.py:36] Average training steps per second: 224.71
I0902 18:06:33.554524 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -478.42
INFO:tensorflow:Starting iteration 8

Steps executed: 324 Episode length: 226 Return: -147.68569951412803
INFO:tensorflow:Average training steps per second: 218.11
I0902 18:06:42.225802 140216164177920 replay_runner.py:36] Average training steps per second: 218.11
I0902 18:06:42.546058 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -410.68
INFO:tensorflow:Starting iteration 9

Steps executed: 271 Episode length: 113 Return: -194.13427635292353
INFO:tensorflow:Average training steps per second: 217.08
I0902 18:06:51.465650 140216164177920 replay_runner.py:36] Average training steps per second: 217.08
I0902 18:06:51.713348 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -393.14
INFO:tensorflow:Starting iteration 10

Steps executed: 226 Episode length: 122 Return: -287.36838711639046
INFO:tensorflow:Average training steps per second: 214.89
I0902 18:07:00.720928 140216164177920 replay_runner.py:36] Average training steps per second: 214.89
I0902 18:07:00.918838 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.68
INFO:tensorflow:Starting iteration 11
I0902 18:07:05.219716 140216164177920 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 218.04
I0902 18:07:09.806474 140216164177920 replay_runner.py:36] Average training steps per second: 218.04

Steps executed: 241 Episode length: 109 Return: -181.63437642934258
INFO:tensorflow:Starting iteration 12

Steps executed: 204 Episode length: 110 Return: -546.59352964203448
INFO:tensorflow:Average training steps per second: 220.00
I0902 18:07:18.940197 140216164177920 replay_runner.py:36] Average training steps per second: 220.00
I0902 18:07:19.118061 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -578.12
INFO:tensorflow:Starting iteration 13

Steps executed: 220 Episode length: 117 Return: -346.50782450813478
INFO:tensorflow:Average training steps per second: 219.92
I0902 18:07:28.027228 140216164177920 replay_runner.py:36] Average training steps per second: 219.92
I0902 18:07:28.225887 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -379.57
INFO:tensorflow:Starting iteration 14

Steps executed: 115 Episode length: 115 Return: -251.10724241915288
INFO:tensorflow:Average training steps per second: 225.60
I0902 18:07:37.032561 140216164177920 replay_runner.py:36] Average training steps per second: 225.60

Steps executed: 245 Episode length: 130 Return: -125.40769493515472
INFO:tensorflow:Starting iteration 15

Steps executed: 257 Episode length: 160 Return: -265.00977388726994
INFO:tensorflow:Average training steps per second: 222.96
I0902 18:07:46.035394 140216164177920 replay_runner.py:36] Average training steps per second: 222.96
I0902 18:07:46.244392 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.34
INFO:tensorflow:Starting iteration 16

Steps executed: 248 Episode length: 115 Return: -427.04533928562046
INFO:tensorflow:Average training steps per second: 221.81
I0902 18:07:55.039223 140216164177920 replay_runner.py:36] Average training steps per second: 221.81
I0902 18:07:55.263099 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.50
INFO:tensorflow:Starting iteration 17

Steps executed: 222 Episode length: 117 Return: -353.13761670660554
INFO:tensorflow:Average training steps per second: 230.25
I0902 18:08:03.827451 140216164177920 replay_runner.py:36] Average training steps per second: 230.25
I0902 18:08:04.009302 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -350.50
INFO:tensorflow:Starting iteration 18

Steps executed: 228 Episode length: 134 Return: -382.22286757974244
INFO:tensorflow:Average training steps per second: 225.23
I0902 18:08:12.481924 140216164177920 replay_runner.py:36] Average training steps per second: 225.23
I0902 18:08:12.681008 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -508.49
INFO:tensorflow:Starting iteration 19

Steps executed: 331 Episode length: 250 Return: 138.772167182186544
INFO:tensorflow:Average training steps per second: 226.53
I0902 18:08:21.432645 140216164177920 replay_runner.py:36] Average training steps per second: 226.53
I0902 18:08:21.773455 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.89
INFO:tensorflow:Starting iteration 20

Steps executed: 349 Episode length: 211 Return: -59.760957949095154
INFO:tensorflow:Average training steps per second: 227.20
I0902 18:08:30.545617 140216164177920 replay_runner.py:36] Average training steps per second: 227.20
I0902 18:08:30.883372 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -194.18
INFO:tensorflow:Starting iteration 21

Steps executed: 250 Episode length: 136 Return: -250.07245948646167
INFO:tensorflow:Average training steps per second: 224.82
I0902 18:08:39.758795 140216164177920 replay_runner.py:36] Average training steps per second: 224.82
I0902 18:08:39.970861 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.11
INFO:tensorflow:Starting iteration 22

Steps executed: 250 Episode length: 82 Return: -473.850207182701657
INFO:tensorflow:Average training steps per second: 226.51
I0902 18:08:48.625734 140216164177920 replay_runner.py:36] Average training steps per second: 226.51
I0902 18:08:48.839334 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.60
INFO:tensorflow:Starting iteration 23

Steps executed: 255 Episode length: 150 Return: -267.87236042616746
INFO:tensorflow:Average training steps per second: 223.69
I0902 18:08:57.647188 140216164177920 replay_runner.py:36] Average training steps per second: 223.69
I0902 18:08:57.858680 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.19
INFO:tensorflow:Starting iteration 24

Steps executed: 357 Episode length: 174 Return: -215.30570124104286
INFO:tensorflow:Average training steps per second: 224.79
I0902 18:09:06.580875 140216164177920 replay_runner.py:36] Average training steps per second: 224.79
I0902 18:09:06.904787 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.83
INFO:tensorflow:Starting iteration 25

Steps executed: 318 Episode length: 142 Return: -284.71143064175567
INFO:tensorflow:Average training steps per second: 229.20
I0902 18:09:15.594123 140216164177920 replay_runner.py:36] Average training steps per second: 229.20
I0902 18:09:15.916756 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.03
INFO:tensorflow:Starting iteration 26

Steps executed: 248 Episode length: 87 Return: -392.526880963120567
INFO:tensorflow:Average training steps per second: 227.38
I0902 18:09:24.536058 140216164177920 replay_runner.py:36] Average training steps per second: 227.38
I0902 18:09:24.740400 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -495.68
INFO:tensorflow:Starting iteration 27

Steps executed: 230 Episode length: 90 Return: -512.065101255557917
INFO:tensorflow:Average training steps per second: 224.54
I0902 18:09:33.599793 140216164177920 replay_runner.py:36] Average training steps per second: 224.54
I0902 18:09:33.817409 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -453.71
INFO:tensorflow:Starting iteration 28

Steps executed: 293 Episode length: 98 Return: -334.630810103978347
INFO:tensorflow:Average training steps per second: 224.59
I0902 18:09:42.658262 140216164177920 replay_runner.py:36] Average training steps per second: 224.59
I0902 18:09:42.927611 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.15
INFO:tensorflow:Starting iteration 29

Steps executed: 301 Episode length: 119 Return: -251.21905449240347
INFO:tensorflow:Average training steps per second: 229.13
I0902 18:09:51.775658 140216164177920 replay_runner.py:36] Average training steps per second: 229.13

Done fixed training!Episode length: 119 Return: -251.21905449240347