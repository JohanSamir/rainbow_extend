Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0901 23:39:31.245165 139929824643072 run_experiment.py:549] Creating TrainRunner ...
I0901 23:39:31.257015 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:39:31.257341 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:39:31.257542 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:39:31.257733 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:39:31.257980 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0901 23:39:31.258216 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:39:31.258355 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:39:31.258435 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:39:31.258517 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:39:31.258611 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0901 23:39:31.258666 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:39:31.258747 139929824643072 dqn_agent.py:283] 	 seed: 1630539571256956
I0901 23:39:31.261458 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:39:31.261705 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:39:31.261875 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:39:31.262037 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:39:31.262231 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:39:31.262365 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:39:31.262722 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:39:31.262880 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:39:31.263033 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:39:31.297825 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:31.702984 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:31.718222 139929824643072 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:39:31.728328 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:39:31.728551 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:39:31.728934 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:39:31.729156 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:39:31.729313 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0901 23:39:31.729460 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:39:31.729587 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:39:31.729698 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:39:31.735123 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:39:31.740583 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0901 23:39:31.740840 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:39:31.740951 139929824643072 dqn_agent.py:283] 	 seed: 1630539571728273
I0901 23:39:31.761686 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:39:31.761982 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:39:31.762162 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:39:31.762284 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:39:31.762475 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:39:31.762625 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:39:31.762752 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:39:31.762914 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:39:31.763050 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:39:31.792281 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:31.813605 139929824643072 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:39:31.813836 139929824643072 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 159.61
I0901 23:39:38.079524 139929824643072 replay_runner.py:36] Average training steps per second: 159.61
Steps executed: 218 Episode length: 78 Return: -782.1868492012414
I0901 23:39:39.213062 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -720.89
INFO:tensorflow:Starting iteration 1

Steps executed: 225 Episode length: 89 Return: -1090.228078728336
INFO:tensorflow:Average training steps per second: 224.85
I0901 23:39:48.054767 139929824643072 replay_runner.py:36] Average training steps per second: 224.85
I0901 23:39:48.252589 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -780.33
INFO:tensorflow:Starting iteration 2

Steps executed: 219 Episode length: 53 Return: -437.15169347454565
INFO:tensorflow:Average training steps per second: 225.43
I0901 23:39:57.051575 139929824643072 replay_runner.py:36] Average training steps per second: 225.43
I0901 23:39:57.233596 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -761.15
INFO:tensorflow:Starting iteration 3

Steps executed: 212 Episode length: 65 Return: -608.04630630644995
INFO:tensorflow:Average training steps per second: 227.90
I0901 23:40:05.867988 139929824643072 replay_runner.py:36] Average training steps per second: 227.90
I0901 23:40:06.066081 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -696.37
INFO:tensorflow:Starting iteration 4
I0901 23:40:10.532709 139929824643072 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 224.88

Steps executed: 230 Episode length: 79 Return: -753.42067431780675
I0901 23:40:15.187630 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -691.38
INFO:tensorflow:Starting iteration 5

Steps executed: 219 Episode length: 63 Return: -503.45033945123175
INFO:tensorflow:Average training steps per second: 222.36
I0901 23:40:23.992115 139929824643072 replay_runner.py:36] Average training steps per second: 222.36
I0901 23:40:24.188293 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -661.78
INFO:tensorflow:Starting iteration 6
I0901 23:40:28.595776 139929824643072 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 222.96

Steps executed: 222 Episode length: 81 Return: -785.67996062107045
I0901 23:40:33.276437 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -680.84
INFO:tensorflow:Starting iteration 7

Steps executed: 204 Episode length: 104 Return: -665.04772456975093
INFO:tensorflow:Average training steps per second: 219.59
I0901 23:40:42.227542 139929824643072 replay_runner.py:36] Average training steps per second: 219.59
I0901 23:40:42.427028 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -576.99
INFO:tensorflow:Starting iteration 8

Steps executed: 313 Episode length: 168 Return: -1171.2769227315478
INFO:tensorflow:Average training steps per second: 221.69
I0901 23:40:51.342370 139929824643072 replay_runner.py:36] Average training steps per second: 221.69
I0901 23:40:51.672498 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -953.63
INFO:tensorflow:Starting iteration 9

Steps executed: 238 Episode length: 108 Return: -516.51961816348438
INFO:tensorflow:Average training steps per second: 228.33
I0901 23:41:00.263045 139929824643072 replay_runner.py:36] Average training steps per second: 228.33
I0901 23:41:00.495335 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -544.48
INFO:tensorflow:Starting iteration 10

Steps executed: 87 Episode length: 87 Return: -633.9955981879476438
INFO:tensorflow:Average training steps per second: 230.87

Steps executed: 327 Episode length: 240 Return: -1590.2643734837459
I0901 23:41:09.408414 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -1112.13
INFO:tensorflow:Starting iteration 11

Steps executed: 364 Episode length: 269 Return: -2554.2762488573317
INFO:tensorflow:Average training steps per second: 232.64
I0901 23:41:17.904093 139929824643072 replay_runner.py:36] Average training steps per second: 232.64
I0901 23:41:18.334551 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -1548.09
INFO:tensorflow:Starting iteration 12

Steps executed: 377 Episode length: 191 Return: -1327.4759037468361
INFO:tensorflow:Average training steps per second: 238.27
I0901 23:41:26.763037 139929824643072 replay_runner.py:36] Average training steps per second: 238.27
I0901 23:41:27.103307 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -809.85
INFO:tensorflow:Starting iteration 13

Steps executed: 208 Episode length: 120 Return: -684.54626952857361
INFO:tensorflow:Average training steps per second: 231.63
I0901 23:41:35.568062 139929824643072 replay_runner.py:36] Average training steps per second: 231.63
I0901 23:41:35.749230 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -699.95
INFO:tensorflow:Starting iteration 14

Steps executed: 286 Episode length: 99 Return: -717.298884084271418
INFO:tensorflow:Average training steps per second: 226.85
I0901 23:41:44.346215 139929824643072 replay_runner.py:36] Average training steps per second: 226.85
I0901 23:41:44.630384 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -1057.38
INFO:tensorflow:Starting iteration 15
I0901 23:41:48.955247 139929824643072 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 221.89

Steps executed: 532 Episode length: 532 Return: -6814.5911444740818
I0901 23:41:54.544023 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -6814.59
INFO:tensorflow:Starting iteration 16

Steps executed: 98 Episode length: 98 Return: -783.3838296426478818
INFO:tensorflow:Average training steps per second: 221.07

Steps executed: 251 Episode length: 153 Return: -1140.3337170397335
I0901 23:42:03.633161 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -961.86
INFO:tensorflow:Starting iteration 17

Steps executed: 200 Episode length: 76 Return: -374.906544509851365
INFO:tensorflow:Average training steps per second: 218.63
I0901 23:42:12.610052 139929824643072 replay_runner.py:36] Average training steps per second: 218.63
I0901 23:42:12.800207 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -603.04
INFO:tensorflow:Starting iteration 18

Steps executed: 469 Episode length: 283 Return: -2520.9490916081836
INFO:tensorflow:Average training steps per second: 219.87
I0901 23:42:21.940071 139929824643072 replay_runner.py:36] Average training steps per second: 219.87
I0901 23:42:22.483456 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -1177.44
INFO:tensorflow:Starting iteration 19

Steps executed: 193 Episode length: 193 Return: -1364.1736264054136
INFO:tensorflow:Average training steps per second: 222.19

Steps executed: 381 Episode length: 188 Return: -1059.7866649101497
I0901 23:42:31.744482 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -1211.98
INFO:tensorflow:Starting iteration 20

Steps executed: 285 Episode length: 98 Return: -746.586890687324687
INFO:tensorflow:Average training steps per second: 226.56
I0901 23:42:40.518216 139929824643072 replay_runner.py:36] Average training steps per second: 226.56
I0901 23:42:40.780006 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -673.30
INFO:tensorflow:Starting iteration 21

Steps executed: 279 Episode length: 109 Return: -478.75912296803077
INFO:tensorflow:Average training steps per second: 218.54
I0901 23:42:49.650073 139929824643072 replay_runner.py:36] Average training steps per second: 218.54
I0901 23:42:49.909850 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -567.34
INFO:tensorflow:Starting iteration 22
I0901 23:42:54.311024 139929824643072 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 223.57

Steps executed: 569 Episode length: 569 Return: -8770.1047986050427
I0901 23:42:59.963721 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -8770.10
INFO:tensorflow:Starting iteration 23

Steps executed: 352 Episode length: 267 Return: -1712.3727952311153
INFO:tensorflow:Average training steps per second: 222.69
I0901 23:43:08.789807 139929824643072 replay_runner.py:36] Average training steps per second: 222.69
I0901 23:43:09.273497 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -1137.56
INFO:tensorflow:Starting iteration 24

Steps executed: 230 Episode length: 76 Return: -482.598143473487266
INFO:tensorflow:Average training steps per second: 225.54
I0901 23:43:18.116381 139929824643072 replay_runner.py:36] Average training steps per second: 225.54
I0901 23:43:18.369358 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -791.25
INFO:tensorflow:Starting iteration 25

Steps executed: 206 Episode length: 125 Return: -728.95054863060376
INFO:tensorflow:Average training steps per second: 226.84
I0901 23:43:26.646362 139929824643072 replay_runner.py:36] Average training steps per second: 226.84
I0901 23:43:26.847636 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -656.00
INFO:tensorflow:Starting iteration 26
I0901 23:43:31.144204 139929824643072 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 226.25

Steps executed: 233 Episode length: 233 Return: -1979.0734467323686
I0901 23:43:35.843114 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -1979.07
INFO:tensorflow:Starting iteration 27

Steps executed: 331 Episode length: 133 Return: -902.90067435311216
INFO:tensorflow:Average training steps per second: 221.40
I0901 23:43:44.668870 139929824643072 replay_runner.py:36] Average training steps per second: 221.40
I0901 23:43:44.996915 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -770.19
INFO:tensorflow:Starting iteration 28

Steps executed: 278 Episode length: 102 Return: -671.41909859691016
INFO:tensorflow:Average training steps per second: 222.37
I0901 23:43:53.959093 139929824643072 replay_runner.py:36] Average training steps per second: 222.37
I0901 23:43:54.222957 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -606.14
INFO:tensorflow:Starting iteration 29

Steps executed: 284 Episode length: 142 Return: -1110.3552110060186
INFO:tensorflow:Average training steps per second: 241.72
I0901 23:44:02.588264 139929824643072 replay_runner.py:36] Average training steps per second: 241.72

Done fixed training!Episode length: 142 Return: -1110.3552110060186