I0901 23:29:06.477305 139825600018432 run_experiment.py:549] Creating TrainRunner ...
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0901 23:29:06.478211 139825600018432 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0901 23:29:06.557266 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:29:06.558655 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:29:06.558751 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:29:06.558820 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:29:06.558881 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0901 23:29:06.558935 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:29:06.558979 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:29:06.559077 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:29:06.559306 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:29:06.559441 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0901 23:29:06.559681 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:29:06.559814 139825600018432 dqn_agent.py:283] 	 seed: 1630538946557196
I0901 23:29:06.562443 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:29:06.562601 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:29:06.562791 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:29:06.562897 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:29:06.563034 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:29:06.563186 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:29:06.564115 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:29:06.564224 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:29:06.564294 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:29:14.550027 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0901 23:29:16.207482 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:29:16.240174 139825600018432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:29:16.260401 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:29:16.261370 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:29:16.261871 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:29:16.262278 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:29:16.262657 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0901 23:29:16.263023 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:29:16.263363 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:29:16.263689 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:29:16.264044 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:29:16.264404 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0901 23:29:16.264739 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:29:16.265058 139825600018432 dqn_agent.py:283] 	 seed: 1630538956260348
I0901 23:29:16.271438 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:29:16.272047 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:29:16.272463 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:29:16.272851 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:29:16.273196 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:29:16.273545 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:29:16.273887 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:29:16.274236 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:29:16.274597 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:29:17.132910 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:29:17.167377 139825600018432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:29:17.168215 139825600018432 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 160.52
I0901 23:29:23.398665 139825600018432 replay_runner.py:36] Average training steps per second: 160.52
Steps executed: 292 Episode length: 160 Return: -351.76853820806974
I0901 23:29:24.369641 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.90
INFO:tensorflow:Starting iteration 1

Steps executed: 298 Episode length: 173 Return: -368.90876179954284
INFO:tensorflow:Average training steps per second: 207.39
I0901 23:29:33.388375 139825600018432 replay_runner.py:36] Average training steps per second: 207.39
I0901 23:29:33.698843 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.91
INFO:tensorflow:Starting iteration 2

Steps executed: 240 Episode length: 240 Return: -367.49085356091314
INFO:tensorflow:Average training steps per second: 205.58
I0901 23:29:42.615738 139825600018432 replay_runner.py:36] Average training steps per second: 205.58
I0901 23:29:42.908836 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -367.49
INFO:tensorflow:Starting iteration 3
I0901 23:29:47.220217 139825600018432 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 203.14

Steps executed: 419 Episode length: 362 Return: -159.69098533686375
I0901 23:29:52.808679 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.74
INFO:tensorflow:Starting iteration 4
I0901 23:29:57.005217 139825600018432 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 216.03

Steps executed: 780 Episode length: 780 Return: -264.91576951588263
I0901 23:30:03.241849 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -264.92
INFO:tensorflow:Starting iteration 5
I0901 23:30:07.480850 139825600018432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 222.68

Steps executed: 758 Episode length: 758 Return: -262.45838299395813
I0901 23:30:13.937930 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.46
INFO:tensorflow:Starting iteration 6

Steps executed: 68 Episode length: 68 Return: -58.59292215156793813
INFO:tensorflow:Average training steps per second: 232.80

Steps executed: 1068 Episode length: 1000 Return: -316.48203857638885
I0901 23:30:25.075282 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.54
INFO:tensorflow:Starting iteration 7
I0901 23:30:29.218249 139825600018432 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 231.38

Steps executed: 545 Episode length: 545 Return: -285.0599888717338885
I0901 23:30:34.547738 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.06
INFO:tensorflow:Starting iteration 8

Steps executed: 450 Episode length: 450 Return: -425.4433334429939585
INFO:tensorflow:Average training steps per second: 233.09
I0901 23:30:42.819833 139825600018432 replay_runner.py:36] Average training steps per second: 233.09
I0901 23:30:43.498216 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -425.44
INFO:tensorflow:Starting iteration 9
I0901 23:30:47.826757 139825600018432 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 222.46

Steps executed: 774 Episode length: 774 Return: -313.7849610477405585
I0901 23:30:54.713553 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -313.78
INFO:tensorflow:Starting iteration 10
I0901 23:30:58.898761 139825600018432 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 221.74

Steps executed: 836 Episode length: 836 Return: -430.9497250459341585
I0901 23:31:06.018413 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -430.95
INFO:tensorflow:Starting iteration 11
I0901 23:31:10.272778 139825600018432 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 217.98

Steps executed: 1000 Episode length: 1000 Return: -155.10255888774565
I0901 23:31:17.137697 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.10
INFO:tensorflow:Starting iteration 12
I0901 23:31:21.393860 139825600018432 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 218.10

Steps executed: 1000 Episode length: 1000 Return: -208.64757773759925
I0901 23:31:28.882261 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.65
INFO:tensorflow:Starting iteration 13
I0901 23:31:33.257093 139825600018432 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 224.39

Steps executed: 1000 Episode length: 1000 Return: -71.710049823048525
I0901 23:31:40.781748 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.71
INFO:tensorflow:Starting iteration 14
I0901 23:31:45.713884 139825600018432 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 216.77

Steps executed: 1000 Episode length: 1000 Return: -67.965145158107625
I0901 23:31:53.627786 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -67.97
INFO:tensorflow:Starting iteration 15
I0901 23:31:57.983684 139825600018432 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 221.94

Steps executed: 1000 Episode length: 1000 Return: -84.056179167296825
I0901 23:32:04.950049 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.06
INFO:tensorflow:Starting iteration 16

Steps executed: 120 Episode length: 120 Return: -134.1712953397075825
INFO:tensorflow:Average training steps per second: 268.89
I0901 23:32:12.418945 139825600018432 replay_runner.py:36] Average training steps per second: 268.89

Steps executed: 293 Episode length: 173 Return: -224.6483438672525825
INFO:tensorflow:Starting iteration 17

Steps executed: 156 Episode length: 156 Return: -63.53993055016152825
INFO:tensorflow:Average training steps per second: 249.76
I0901 23:32:20.352561 139825600018432 replay_runner.py:36] Average training steps per second: 249.76

Steps executed: 317 Episode length: 161 Return: -114.9890508300507325
INFO:tensorflow:Starting iteration 18
I0901 23:32:24.637047 139825600018432 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 226.58

Steps executed: 240 Episode length: 133 Return: -315.4473095947077325
I0901 23:32:29.272088 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.27
INFO:tensorflow:Starting iteration 19
I0901 23:32:34.027255 139825600018432 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 214.04

Steps executed: 540 Episode length: 540 Return: 207.88202275679186325
I0901 23:32:39.831459 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: 207.88
INFO:tensorflow:Starting iteration 20
I0901 23:32:44.214096 139825600018432 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 223.05

Steps executed: 620 Episode length: 620 Return: 208.95060990872798325
I0901 23:32:50.483762 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: 208.95
INFO:tensorflow:Starting iteration 21
I0901 23:32:54.782699 139825600018432 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 223.77

Steps executed: 295 Episode length: 156 Return: -9.933098979285703325
I0901 23:32:59.535854 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -6.80
INFO:tensorflow:Starting iteration 22
I0901 23:33:03.875819 139825600018432 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 227.00

Steps executed: 1000 Episode length: 1000 Return: -54.987293585702875
I0901 23:33:13.558348 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.99
INFO:tensorflow:Starting iteration 23

Steps executed: 174 Episode length: 174 Return: -231.8409065327960575
INFO:tensorflow:Average training steps per second: 223.35
I0901 23:33:22.349740 139825600018432 replay_runner.py:36] Average training steps per second: 223.35

Steps executed: 1174 Episode length: 1000 Return: -27.888616385174416
INFO:tensorflow:Starting iteration 24
I0901 23:33:31.720802 139825600018432 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 227.04
I0901 23:33:36.125800 139825600018432 replay_runner.py:36] Average training steps per second: 227.04

Steps executed: 1000 Episode length: 1000 Return: -32.430389233657486
INFO:tensorflow:Starting iteration 25

Steps executed: 355 Episode length: 192 Return: -254.1298612928523386
INFO:tensorflow:Average training steps per second: 229.03
I0901 23:33:48.000045 139825600018432 replay_runner.py:36] Average training steps per second: 229.03
I0901 23:33:48.394444 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -204.13
INFO:tensorflow:Starting iteration 26
I0901 23:33:52.634824 139825600018432 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 227.69
I0901 23:33:57.027360 139825600018432 replay_runner.py:36] Average training steps per second: 227.69

Steps executed: 203 Episode length: 203 Return: -87.89098401379353386
INFO:tensorflow:Starting iteration 27
I0901 23:34:01.665611 139825600018432 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 230.05
I0901 23:34:06.013457 139825600018432 replay_runner.py:36] Average training steps per second: 230.05

Steps executed: 485 Episode length: 485 Return: -94.96176916390723386
INFO:tensorflow:Starting iteration 28
I0901 23:34:11.246766 139825600018432 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 228.26

Steps executed: 163 Episode length: 163 Return: -109.2931391718851786

Steps executed: 1163 Episode length: 1000 Return: -67.822529012171326
INFO:tensorflow:Starting iteration 29

Steps executed: 286 Episode length: 143 Return: -25.42530645030788626
INFO:tensorflow:Average training steps per second: 226.03
I0901 23:34:27.882447 139825600018432 replay_runner.py:36] Average training steps per second: 226.03

Done fixed training!Episode length: 143 Return: -25.42530645030788626