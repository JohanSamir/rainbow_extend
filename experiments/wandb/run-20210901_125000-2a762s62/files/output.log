Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0901 12:50:06.612364 140298343233536 run_experiment.py:549] Creating TrainRunner ...
I0901 12:50:06.623959 140298343233536 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:50:06.624249 140298343233536 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:50:06.624365 140298343233536 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:50:06.624509 140298343233536 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:50:06.624590 140298343233536 dqn_agent.py:275] 	 update_period: 4
I0901 12:50:06.624664 140298343233536 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:50:06.624814 140298343233536 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:50:06.624881 140298343233536 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:50:06.624941 140298343233536 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:50:06.625001 140298343233536 dqn_agent.py:280] 	 optimizer: adam
I0901 12:50:06.625073 140298343233536 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:50:06.625176 140298343233536 dqn_agent.py:283] 	 seed: 1630500606623870
I0901 12:50:06.627948 140298343233536 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:50:06.628154 140298343233536 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:50:06.628305 140298343233536 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:50:06.628497 140298343233536 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:50:06.628641 140298343233536 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:50:06.628728 140298343233536 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:50:06.628797 140298343233536 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:50:06.628964 140298343233536 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:50:06.629092 140298343233536 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:50:06.671564 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:07.080769 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:07.095662 140298343233536 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:50:07.123681 140298343233536 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:50:07.123955 140298343233536 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:50:07.124102 140298343233536 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:50:07.124225 140298343233536 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:50:07.124337 140298343233536 dqn_agent.py:275] 	 update_period: 4
I0901 12:50:07.124460 140298343233536 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:50:07.124611 140298343233536 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:50:07.124728 140298343233536 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:50:07.124834 140298343233536 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:50:07.124913 140298343233536 dqn_agent.py:280] 	 optimizer: adam
I0901 12:50:07.124997 140298343233536 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:50:07.125204 140298343233536 dqn_agent.py:283] 	 seed: 1630500607123627
I0901 12:50:07.127879 140298343233536 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:50:07.128102 140298343233536 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:50:07.128231 140298343233536 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:50:07.128349 140298343233536 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:50:07.128475 140298343233536 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:50:07.128591 140298343233536 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:50:07.128692 140298343233536 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:50:07.128793 140298343233536 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:50:07.128954 140298343233536 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:50:07.167360 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:07.190174 140298343233536 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:50:07.190456 140298343233536 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 157.09
I0901 12:50:13.556668 140298343233536 replay_runner.py:36] Average training steps per second: 157.09
Steps executed: 223 Episode length: 83 Return: -557.76384266237782
I0901 12:50:14.876829 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -629.20
INFO:tensorflow:Starting iteration 1

Steps executed: 242 Episode length: 69 Return: -603.58710301583198
INFO:tensorflow:Average training steps per second: 229.15
I0901 12:50:23.339163 140298343233536 replay_runner.py:36] Average training steps per second: 229.15
I0901 12:50:23.584287 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -601.31
INFO:tensorflow:Starting iteration 2
I0901 12:50:27.953965 140298343233536 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 232.12

Steps executed: 374 Episode length: 178 Return: -119.95127296432256
I0901 12:50:32.592468 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.49
INFO:tensorflow:Starting iteration 3

Steps executed: 238 Episode length: 154 Return: 15.7950391981731436
INFO:tensorflow:Average training steps per second: 230.21
I0901 12:50:41.180005 140298343233536 replay_runner.py:36] Average training steps per second: 230.21
I0901 12:50:41.374735 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.04
INFO:tensorflow:Starting iteration 4
I0901 12:50:45.668706 140298343233536 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 219.09

Steps executed: 243 Episode length: 144 Return: -365.94456383464156
I0901 12:50:50.459928 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -535.36
INFO:tensorflow:Starting iteration 5

Steps executed: 294 Episode length: 100 Return: -143.44778897703554
INFO:tensorflow:Average training steps per second: 220.57
I0901 12:50:59.331945 140298343233536 replay_runner.py:36] Average training steps per second: 220.57
I0901 12:50:59.590744 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -485.44
INFO:tensorflow:Starting iteration 6

Steps executed: 131 Episode length: 131 Return: -196.19125579286724
INFO:tensorflow:Average training steps per second: 220.70
I0901 12:51:08.214636 140298343233536 replay_runner.py:36] Average training steps per second: 220.70

Steps executed: 243 Episode length: 112 Return: -80.680517697709484
INFO:tensorflow:Starting iteration 7

Steps executed: 257 Episode length: 117 Return: -22.205817293572423
INFO:tensorflow:Average training steps per second: 223.06
I0901 12:51:17.381695 140298343233536 replay_runner.py:36] Average training steps per second: 223.06
I0901 12:51:17.616863 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -33.43
INFO:tensorflow:Starting iteration 8

Steps executed: 236 Episode length: 86 Return: -295.066914091957763
INFO:tensorflow:Average training steps per second: 216.78
I0901 12:51:26.637757 140298343233536 replay_runner.py:36] Average training steps per second: 216.78
I0901 12:51:26.856579 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -347.12
INFO:tensorflow:Starting iteration 9

Steps executed: 278 Episode length: 161 Return: -21.593399089557124
INFO:tensorflow:Average training steps per second: 218.19
I0901 12:51:35.688874 140298343233536 replay_runner.py:36] Average training steps per second: 218.19
I0901 12:51:35.948224 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.78
INFO:tensorflow:Starting iteration 10

Steps executed: 309 Episode length: 111 Return: -246.12510203495708
INFO:tensorflow:Average training steps per second: 217.30
I0901 12:51:44.898244 140298343233536 replay_runner.py:36] Average training steps per second: 217.30
I0901 12:51:45.177153 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -297.98
INFO:tensorflow:Starting iteration 11

Steps executed: 254 Episode length: 75 Return: -215.360016462436168
INFO:tensorflow:Average training steps per second: 221.37
I0901 12:51:54.079679 140298343233536 replay_runner.py:36] Average training steps per second: 221.37
I0901 12:51:54.292928 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.00
INFO:tensorflow:Starting iteration 12

Steps executed: 224 Episode length: 141 Return: -381.10112681213738
INFO:tensorflow:Average training steps per second: 214.73
I0901 12:52:03.445276 140298343233536 replay_runner.py:36] Average training steps per second: 214.73
I0901 12:52:03.640006 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -368.70
INFO:tensorflow:Starting iteration 13

Steps executed: 71 Episode length: 71 Return: -153.3867534016467938
INFO:tensorflow:Average training steps per second: 220.67
I0901 12:52:12.627112 140298343233536 replay_runner.py:36] Average training steps per second: 220.67

Steps executed: 214 Episode length: 64 Return: -162.306085875574528
INFO:tensorflow:Starting iteration 14

Steps executed: 239 Episode length: 76 Return: -151.887618438723178
INFO:tensorflow:Average training steps per second: 229.52
I0901 12:52:21.509531 140298343233536 replay_runner.py:36] Average training steps per second: 229.52
I0901 12:52:21.674011 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.77
INFO:tensorflow:Starting iteration 15

Steps executed: 219 Episode length: 85 Return: -371.582182676726538
INFO:tensorflow:Average training steps per second: 230.66
I0901 12:52:30.319129 140298343233536 replay_runner.py:36] Average training steps per second: 230.66
I0901 12:52:30.455974 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.21
INFO:tensorflow:Starting iteration 16

Steps executed: 228 Episode length: 65 Return: -329.368359979055248
INFO:tensorflow:Average training steps per second: 235.04
I0901 12:52:39.098098 140298343233536 replay_runner.py:36] Average training steps per second: 235.04
I0901 12:52:39.271548 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -390.85
INFO:tensorflow:Starting iteration 17

Steps executed: 230 Episode length: 73 Return: -142.798789746334058
INFO:tensorflow:Average training steps per second: 220.20
I0901 12:52:48.118775 140298343233536 replay_runner.py:36] Average training steps per second: 220.20
I0901 12:52:48.302670 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.86
INFO:tensorflow:Starting iteration 18

Steps executed: 272 Episode length: 129 Return: -194.03248278914646
INFO:tensorflow:Average training steps per second: 222.33
I0901 12:52:57.059426 140298343233536 replay_runner.py:36] Average training steps per second: 222.33
I0901 12:52:57.274599 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.58
INFO:tensorflow:Starting iteration 19

Steps executed: 241 Episode length: 60 Return: -359.461237157712843
INFO:tensorflow:Average training steps per second: 219.98
I0901 12:53:06.007228 140298343233536 replay_runner.py:36] Average training steps per second: 219.98
I0901 12:53:06.209093 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.88
INFO:tensorflow:Starting iteration 20

Steps executed: 244 Episode length: 113 Return: -341.00801479198996
INFO:tensorflow:Average training steps per second: 223.76
I0901 12:53:14.875619 140298343233536 replay_runner.py:36] Average training steps per second: 223.76
I0901 12:53:15.099282 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.06
INFO:tensorflow:Starting iteration 21

Steps executed: 245 Episode length: 62 Return: -388.604159170435656
INFO:tensorflow:Average training steps per second: 222.45
I0901 12:53:24.009635 140298343233536 replay_runner.py:36] Average training steps per second: 222.45
I0901 12:53:24.219119 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.73
INFO:tensorflow:Starting iteration 22

Steps executed: 239 Episode length: 83 Return: -456.192355793892656
INFO:tensorflow:Average training steps per second: 217.93
I0901 12:53:33.149415 140298343233536 replay_runner.py:36] Average training steps per second: 217.93
I0901 12:53:33.341385 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -411.49
INFO:tensorflow:Starting iteration 23

Steps executed: 206 Episode length: 129 Return: -319.97146551752707
INFO:tensorflow:Average training steps per second: 223.34
I0901 12:53:41.952675 140298343233536 replay_runner.py:36] Average training steps per second: 223.34
I0901 12:53:42.118897 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.77
INFO:tensorflow:Starting iteration 24

Steps executed: 228 Episode length: 228 Return: -221.08081761746327
INFO:tensorflow:Average training steps per second: 222.75
I0901 12:53:50.914605 140298343233536 replay_runner.py:36] Average training steps per second: 222.75
I0901 12:53:51.220362 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.08
INFO:tensorflow:Starting iteration 25

Steps executed: 351 Episode length: 183 Return: -376.06967050339824
INFO:tensorflow:Average training steps per second: 218.82
I0901 12:54:00.139525 140298343233536 replay_runner.py:36] Average training steps per second: 218.82
I0901 12:54:00.523941 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.80
INFO:tensorflow:Starting iteration 26

Steps executed: 242 Episode length: 84 Return: -56.2150008031143364
INFO:tensorflow:Average training steps per second: 222.64
I0901 12:54:09.474855 140298343233536 replay_runner.py:36] Average training steps per second: 222.64
I0901 12:54:09.685524 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -427.94
INFO:tensorflow:Starting iteration 27
I0901 12:54:14.155695 140298343233536 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 216.28

Steps executed: 310 Episode length: 142 Return: -600.21156650881224
I0901 12:54:19.089568 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -594.66
INFO:tensorflow:Starting iteration 28

Steps executed: 239 Episode length: 95 Return: -745.701017226119324
INFO:tensorflow:Average training steps per second: 224.49
I0901 12:54:27.873473 140298343233536 replay_runner.py:36] Average training steps per second: 224.49
I0901 12:54:28.146927 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -577.09
INFO:tensorflow:Starting iteration 29

Steps executed: 174 Episode length: 85 Return: -352.690002723274824
INFO:tensorflow:Average training steps per second: 223.41
I0901 12:54:36.628080 140298343233536 replay_runner.py:36] Average training steps per second: 223.41


Done fixed training!Episode length: 207 Return: -388.66625302818784