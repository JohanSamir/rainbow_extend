Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0901 23:34:28.612838 139752435963904 run_experiment.py:549] Creating TrainRunner ...
I0901 23:34:28.624567 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:34:28.625104 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:34:28.625338 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:34:28.625510 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:34:28.625770 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0901 23:34:28.625918 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:34:28.626259 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:34:28.626417 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:34:28.626654 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:34:28.626883 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0901 23:34:28.627058 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:34:28.627195 139752435963904 dqn_agent.py:283] 	 seed: 1630539268624490
I0901 23:34:28.631105 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:34:28.631331 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:34:28.631743 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:34:28.631935 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:34:28.632100 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:34:28.632247 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:34:28.632396 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:34:28.632544 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:34:28.632665 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:34:28.667198 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:29.051041 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:29.065060 139752435963904 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:34:29.074953 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:34:29.075264 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:34:29.075411 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:34:29.075579 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:34:29.075830 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0901 23:34:29.076073 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:34:29.076278 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:34:29.076471 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:34:29.076688 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:34:29.077280 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0901 23:34:29.077489 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:34:29.077670 139752435963904 dqn_agent.py:283] 	 seed: 1630539269074882
I0901 23:34:29.080056 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:34:29.080275 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:34:29.080442 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:34:29.080564 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:34:29.080644 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:34:29.080721 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:34:29.080824 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:34:29.080959 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:34:29.081084 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:34:29.147402 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:29.214021 139752435963904 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:34:29.214314 139752435963904 replay_runner.py:41] Starting iteration 0
Steps executed: 233 Episode length: 81 Return: -164.55181841298042
INFO:tensorflow:Average training steps per second: 171.69
I0901 23:34:35.039142 139752435963904 replay_runner.py:36] Average training steps per second: 171.69
I0901 23:34:36.124824 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.01
INFO:tensorflow:Starting iteration 1

Steps executed: 221 Episode length: 66 Return: -154.47986491320398
INFO:tensorflow:Average training steps per second: 222.95
I0901 23:34:44.898892 139752435963904 replay_runner.py:36] Average training steps per second: 222.95
I0901 23:34:45.044809 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.08
INFO:tensorflow:Starting iteration 2

Steps executed: 282 Episode length: 88 Return: -84.822355375254268
INFO:tensorflow:Average training steps per second: 222.95
I0901 23:34:53.903761 139752435963904 replay_runner.py:36] Average training steps per second: 222.95
I0901 23:34:54.113851 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.17
INFO:tensorflow:Starting iteration 3

Steps executed: 264 Episode length: 73 Return: -8.0565362208780875
INFO:tensorflow:Average training steps per second: 232.59
I0901 23:35:02.863733 139752435963904 replay_runner.py:36] Average training steps per second: 232.59
I0901 23:35:03.028744 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.66
INFO:tensorflow:Starting iteration 4

Steps executed: 261 Episode length: 71 Return: -162.63713727776165
INFO:tensorflow:Average training steps per second: 231.93
I0901 23:35:11.502444 139752435963904 replay_runner.py:36] Average training steps per second: 231.93
I0901 23:35:11.653225 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.55
INFO:tensorflow:Starting iteration 5

Steps executed: 281 Episode length: 82 Return: -160.06387612996284
INFO:tensorflow:Average training steps per second: 245.51
I0901 23:35:19.664032 139752435963904 replay_runner.py:36] Average training steps per second: 245.51
I0901 23:35:19.811181 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.58
INFO:tensorflow:Starting iteration 6

Steps executed: 50 Episode length: 50 Return: -111.404288446686984
INFO:tensorflow:Average training steps per second: 226.04

Steps executed: 202 Episode length: 57 Return: -122.84230725194067
I0901 23:35:28.521064 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.88
INFO:tensorflow:Starting iteration 7

Steps executed: 268 Episode length: 88 Return: -119.02671941937058
INFO:tensorflow:Average training steps per second: 226.69
I0901 23:35:37.097149 139752435963904 replay_runner.py:36] Average training steps per second: 226.69
I0901 23:35:37.272597 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.21
INFO:tensorflow:Starting iteration 8

Steps executed: 203 Episode length: 63 Return: -138.41844511706915
INFO:tensorflow:Average training steps per second: 220.81
I0901 23:35:46.185786 139752435963904 replay_runner.py:36] Average training steps per second: 220.81
I0901 23:35:46.317915 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.76
INFO:tensorflow:Starting iteration 9

Steps executed: 204 Episode length: 66 Return: -143.74567103712764
INFO:tensorflow:Average training steps per second: 221.81
I0901 23:35:55.202961 139752435963904 replay_runner.py:36] Average training steps per second: 221.81
I0901 23:35:55.338044 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.21
INFO:tensorflow:Starting iteration 10

Steps executed: 276 Episode length: 89 Return: -110.16882009492159
INFO:tensorflow:Average training steps per second: 224.90
I0901 23:36:04.072107 139752435963904 replay_runner.py:36] Average training steps per second: 224.90
I0901 23:36:04.273866 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.45
INFO:tensorflow:Starting iteration 11

Steps executed: 249 Episode length: 76 Return: -139.59126009115025
INFO:tensorflow:Average training steps per second: 221.79
I0901 23:36:13.101677 139752435963904 replay_runner.py:36] Average training steps per second: 221.79
I0901 23:36:13.270457 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.22
INFO:tensorflow:Starting iteration 12

Steps executed: 201 Episode length: 74 Return: -167.18077155250162
INFO:tensorflow:Average training steps per second: 224.50
I0901 23:36:21.877033 139752435963904 replay_runner.py:36] Average training steps per second: 224.50
I0901 23:36:22.015743 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.50
INFO:tensorflow:Starting iteration 13
I0901 23:36:26.305382 139752435963904 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 222.74

Steps executed: 246 Episode length: 55 Return: -88.432180384358652
I0901 23:36:30.965848 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.87
INFO:tensorflow:Starting iteration 14

Steps executed: 268 Episode length: 69 Return: -149.05606243404845
INFO:tensorflow:Average training steps per second: 220.88
I0901 23:36:39.899359 139752435963904 replay_runner.py:36] Average training steps per second: 220.88
I0901 23:36:40.090318 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.61
INFO:tensorflow:Starting iteration 15

Steps executed: 228 Episode length: 91 Return: 15.6144865171803125
INFO:tensorflow:Average training steps per second: 219.53
I0901 23:36:49.040510 139752435963904 replay_runner.py:36] Average training steps per second: 219.53
I0901 23:36:49.199656 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.89
INFO:tensorflow:Starting iteration 16

Steps executed: 224 Episode length: 85 Return: -102.77631633083018
INFO:tensorflow:Average training steps per second: 220.78
I0901 23:36:57.923399 139752435963904 replay_runner.py:36] Average training steps per second: 220.78
I0901 23:36:58.080248 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.77
INFO:tensorflow:Starting iteration 17
I0901 23:37:02.190715 139752435963904 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 215.50
I0901 23:37:06.831551 139752435963904 replay_runner.py:36] Average training steps per second: 215.50

Steps executed: 255 Episode length: 60 Return: -108.64763466078836
INFO:tensorflow:Starting iteration 18

Steps executed: 235 Episode length: 70 Return: -150.09687995338504
INFO:tensorflow:Average training steps per second: 221.36
I0901 23:37:15.843733 139752435963904 replay_runner.py:36] Average training steps per second: 221.36
I0901 23:37:16.001757 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.32
INFO:tensorflow:Starting iteration 19
I0901 23:37:20.261219 139752435963904 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 221.71
I0901 23:37:24.772184 139752435963904 replay_runner.py:36] Average training steps per second: 221.71

Steps executed: 225 Episode length: 79 Return: -54.066647346095834
INFO:tensorflow:Starting iteration 20

Steps executed: 204 Episode length: 56 Return: -146.88293868037964
INFO:tensorflow:Average training steps per second: 221.80
I0901 23:37:33.671107 139752435963904 replay_runner.py:36] Average training steps per second: 221.80
I0901 23:37:33.805425 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.72
INFO:tensorflow:Starting iteration 21
I0901 23:37:38.153190 139752435963904 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 221.16

Steps executed: 220 Episode length: 59 Return: -33.398841751053595
I0901 23:37:42.826248 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.30
INFO:tensorflow:Starting iteration 22

Steps executed: 212 Episode length: 72 Return: -121.85947953611449
INFO:tensorflow:Average training steps per second: 226.91
I0901 23:37:51.362434 139752435963904 replay_runner.py:36] Average training steps per second: 226.91
I0901 23:37:51.509963 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.35
INFO:tensorflow:Starting iteration 23

Steps executed: 230 Episode length: 81 Return: -108.83733610813198
INFO:tensorflow:Average training steps per second: 233.79
I0901 23:38:00.118287 139752435963904 replay_runner.py:36] Average training steps per second: 233.79
I0901 23:38:00.275691 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.06
INFO:tensorflow:Starting iteration 24

Steps executed: 235 Episode length: 80 Return: -146.64597799267693
INFO:tensorflow:Average training steps per second: 233.33
I0901 23:38:08.918091 139752435963904 replay_runner.py:36] Average training steps per second: 233.33
I0901 23:38:09.072076 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.76
INFO:tensorflow:Starting iteration 25

Steps executed: 235 Episode length: 64 Return: -149.61278659512425
INFO:tensorflow:Average training steps per second: 228.90
I0901 23:38:17.595016 139752435963904 replay_runner.py:36] Average training steps per second: 228.90
I0901 23:38:17.744019 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.25
INFO:tensorflow:Starting iteration 26

Steps executed: 246 Episode length: 55 Return: -115.36285432836092
INFO:tensorflow:Average training steps per second: 239.60
I0901 23:38:26.093786 139752435963904 replay_runner.py:36] Average training steps per second: 239.60
I0901 23:38:26.242717 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.30
INFO:tensorflow:Starting iteration 27

Steps executed: 207 Episode length: 53 Return: -127.26390246600323
INFO:tensorflow:Average training steps per second: 244.03
I0901 23:38:34.471100 139752435963904 replay_runner.py:36] Average training steps per second: 244.03
I0901 23:38:34.600668 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.25
INFO:tensorflow:Starting iteration 28

Steps executed: 223 Episode length: 63 Return: -108.34048091658147
INFO:tensorflow:Average training steps per second: 224.88
I0901 23:38:43.334727 139752435963904 replay_runner.py:36] Average training steps per second: 224.88
I0901 23:38:43.486790 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.49
INFO:tensorflow:Starting iteration 29

Steps executed: 272 Episode length: 89 Return: -92.148380948954721
INFO:tensorflow:Average training steps per second: 228.41
I0901 23:38:52.185486 139752435963904 replay_runner.py:36] Average training steps per second: 228.41

Done fixed training!Episode length: 89 Return: -92.148380948954721