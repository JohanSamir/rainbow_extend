Loaded trained dqn in acrobot
Training fixed agent 6, please be patient, may be a while...
I0901 23:54:08.351519 140490221283328 run_experiment.py:549] Creating TrainRunner ...
I0901 23:54:08.361614 140490221283328 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:54:08.361924 140490221283328 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:54:08.362079 140490221283328 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:54:08.362254 140490221283328 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:54:08.362391 140490221283328 dqn_agent.py:275] 	 update_period: 4
I0901 23:54:08.362851 140490221283328 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:54:08.363093 140490221283328 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:54:08.363261 140490221283328 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:54:08.363418 140490221283328 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:54:08.363610 140490221283328 dqn_agent.py:280] 	 optimizer: adam
I0901 23:54:08.363741 140490221283328 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:54:08.363894 140490221283328 dqn_agent.py:283] 	 seed: 1630540448361542
I0901 23:54:08.366984 140490221283328 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:54:08.367191 140490221283328 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 23:54:08.367321 140490221283328 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:54:08.367436 140490221283328 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:54:08.367543 140490221283328 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:54:08.367647 140490221283328 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:54:08.367747 140490221283328 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:54:08.367851 140490221283328 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:54:08.367945 140490221283328 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:54:08.408280 140490221283328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:08.894206 140490221283328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:08.909147 140490221283328 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:54:08.918463 140490221283328 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:54:08.918728 140490221283328 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:54:08.918901 140490221283328 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:54:08.919033 140490221283328 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:54:08.919144 140490221283328 dqn_agent.py:275] 	 update_period: 4
I0901 23:54:08.919351 140490221283328 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:54:08.919526 140490221283328 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:54:08.919667 140490221283328 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:54:08.919784 140490221283328 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:54:08.919893 140490221283328 dqn_agent.py:280] 	 optimizer: adam
I0901 23:54:08.919997 140490221283328 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:54:08.920109 140490221283328 dqn_agent.py:283] 	 seed: 1630540448918406
I0901 23:54:08.922850 140490221283328 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:54:08.923026 140490221283328 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 23:54:08.923159 140490221283328 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:54:08.923258 140490221283328 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:54:08.923394 140490221283328 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:54:08.923490 140490221283328 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:54:08.923614 140490221283328 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:54:08.923742 140490221283328 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:54:08.923945 140490221283328 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:54:08.958649 140490221283328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:08.985293 140490221283328 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:54:08.985615 140490221283328 replay_runner.py:41] Starting iteration 0
Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 143.63
I0901 23:54:15.948758 140490221283328 replay_runner.py:36] Average training steps per second: 143.63
I0901 23:54:17.425079 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1
I0901 23:54:17.656098 140490221283328 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 194.92
I0901 23:54:22.786967 140490221283328 replay_runner.py:36] Average training steps per second: 194.92
I0901 23:54:23.227522 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 2

Steps executed: 312 Episode length: 312 Return: -311.0
INFO:tensorflow:Average training steps per second: 196.02
I0901 23:54:28.587819 140490221283328 replay_runner.py:36] Average training steps per second: 196.02
I0901 23:54:28.842954 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.00
INFO:tensorflow:Starting iteration 3

Steps executed: 206 Episode length: 98 Return: -97.0.0
INFO:tensorflow:Average training steps per second: 193.09
I0901 23:54:34.260718 140490221283328 replay_runner.py:36] Average training steps per second: 193.09
I0901 23:54:34.442688 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.00
INFO:tensorflow:Starting iteration 4

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 201.76
I0901 23:54:39.630605 140490221283328 replay_runner.py:36] Average training steps per second: 201.76
I0901 23:54:40.041305 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 5

Steps executed: 237 Episode length: 119 Return: -118.0
INFO:tensorflow:Average training steps per second: 192.46
I0901 23:54:45.463124 140490221283328 replay_runner.py:36] Average training steps per second: 192.46
I0901 23:54:45.660107 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.50
INFO:tensorflow:Starting iteration 6

Steps executed: 224 Episode length: 86 Return: -85.0.0
INFO:tensorflow:Average training steps per second: 201.34
I0901 23:54:50.851814 140490221283328 replay_runner.py:36] Average training steps per second: 201.34
I0901 23:54:51.030269 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.00
INFO:tensorflow:Starting iteration 7
I0901 23:54:51.283792 140490221283328 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 192.85
I0901 23:54:56.469693 140490221283328 replay_runner.py:36] Average training steps per second: 192.85
I0901 23:54:56.643469 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.33
INFO:tensorflow:Starting iteration 8

Steps executed: 220 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Average training steps per second: 200.46
I0901 23:55:01.872039 140490221283328 replay_runner.py:36] Average training steps per second: 200.46

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Starting iteration 9
I0901 23:55:02.523551 140490221283328 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 190.48
I0901 23:55:07.773865 140490221283328 replay_runner.py:36] Average training steps per second: 190.48
I0901 23:55:08.020985 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.67
INFO:tensorflow:Starting iteration 10

Steps executed: 305 Episode length: 117 Return: -116.0
INFO:tensorflow:Average training steps per second: 191.92
I0901 23:55:13.638128 140490221283328 replay_runner.py:36] Average training steps per second: 191.92
I0901 23:55:13.861938 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.00
INFO:tensorflow:Starting iteration 11


Steps executed: 272 Episode length: 86 Return: -85.0.0
INFO:tensorflow:Average training steps per second: 193.73
I0901 23:55:19.263787 140490221283328 replay_runner.py:36] Average training steps per second: 193.73
I0901 23:55:19.485701 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.67
INFO:tensorflow:Starting iteration 12

Steps executed: 275 Episode length: 94 Return: -93.000
INFO:tensorflow:Average training steps per second: 191.78
I0901 23:55:24.938619 140490221283328 replay_runner.py:36] Average training steps per second: 191.78
I0901 23:55:25.189605 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.67
INFO:tensorflow:Starting iteration 13
I0901 23:55:25.436744 140490221283328 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 198.75

Steps executed: 322 Episode length: 138 Return: -137.0
I0901 23:55:30.731890 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.00
INFO:tensorflow:Starting iteration 14
I0901 23:55:30.982146 140490221283328 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 185.65

Steps executed: 500 Episode length: 500 Return: -500.0
I0901 23:55:36.834451 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 15

Steps executed: 638 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 196.95
I0901 23:55:42.160229 140490221283328 replay_runner.py:36] Average training steps per second: 196.95
I0901 23:55:42.692392 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -318.50
INFO:tensorflow:Starting iteration 16
I0901 23:55:42.935390 140490221283328 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 194.30

Steps executed: 500 Episode length: 500 Return: -500.0
I0901 23:55:48.476418 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 17

Steps executed: 250 Episode length: 77 Return: -76.0.0
INFO:tensorflow:Average training steps per second: 204.04
I0901 23:55:53.613505 140490221283328 replay_runner.py:36] Average training steps per second: 204.04
I0901 23:55:53.822612 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.33
INFO:tensorflow:Starting iteration 18

Steps executed: 269 Episode length: 73 Return: -72.0.0
INFO:tensorflow:Average training steps per second: 198.35
I0901 23:55:59.105308 140490221283328 replay_runner.py:36] Average training steps per second: 198.35
I0901 23:55:59.320158 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.67
INFO:tensorflow:Starting iteration 19

Steps executed: 88 Episode length: 88 Return: -87.00.0
INFO:tensorflow:Average training steps per second: 208.56

Steps executed: 236 Episode length: 76 Return: -75.0.0
I0901 23:56:04.577658 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.67
INFO:tensorflow:Starting iteration 20

Steps executed: 214 Episode length: 86 Return: -85.0.0
INFO:tensorflow:Average training steps per second: 192.54
I0901 23:56:10.023073 140490221283328 replay_runner.py:36] Average training steps per second: 192.54
I0901 23:56:10.199663 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.00
INFO:tensorflow:Starting iteration 21

Steps executed: 309 Episode length: 137 Return: -136.0
INFO:tensorflow:Average training steps per second: 201.31
I0901 23:56:15.402617 140490221283328 replay_runner.py:36] Average training steps per second: 201.31
I0901 23:56:15.672339 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.00
INFO:tensorflow:Starting iteration 22

Steps executed: 292 Episode length: 107 Return: -106.0
INFO:tensorflow:Average training steps per second: 194.69
I0901 23:56:21.053622 140490221283328 replay_runner.py:36] Average training steps per second: 194.69
I0901 23:56:21.284649 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.33
INFO:tensorflow:Starting iteration 23

Steps executed: 94 Episode length: 94 Return: -93.06.0
INFO:tensorflow:Average training steps per second: 197.14

Steps executed: 280 Episode length: 100 Return: -99.00
I0901 23:56:26.828509 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.33
INFO:tensorflow:Starting iteration 24

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 194.95
I0901 23:56:32.198546 140490221283328 replay_runner.py:36] Average training steps per second: 194.95
I0901 23:56:32.590879 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 25

Steps executed: 280 Episode length: 99 Return: -98.0.0
INFO:tensorflow:Average training steps per second: 207.20
I0901 23:56:37.648780 140490221283328 replay_runner.py:36] Average training steps per second: 207.20
I0901 23:56:37.874161 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.33
INFO:tensorflow:Starting iteration 26

Steps executed: 301 Episode length: 105 Return: -104.0
INFO:tensorflow:Average training steps per second: 197.66
I0901 23:56:43.167809 140490221283328 replay_runner.py:36] Average training steps per second: 197.66
I0901 23:56:43.385272 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.33
INFO:tensorflow:Starting iteration 27

Steps executed: 254 Episode length: 113 Return: -112.0
INFO:tensorflow:Average training steps per second: 213.86
I0901 23:56:48.276470 140490221283328 replay_runner.py:36] Average training steps per second: 213.86
I0901 23:56:48.475900 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.67
INFO:tensorflow:Starting iteration 28

Steps executed: 675 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 199.50
I0901 23:56:53.714011 140490221283328 replay_runner.py:36] Average training steps per second: 199.50
I0901 23:56:54.239756 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.33
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 100 Return: -99.00
INFO:tensorflow:Average training steps per second: 205.61
I0901 23:56:59.332456 140490221283328 replay_runner.py:36] Average training steps per second: 205.61
I0901 23:56:59.558492 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.67