Loaded trained dqn in acrobot
Training fixed agent 1, please be patient, may be a while...
I0901 12:56:53.472389 140583573075968 run_experiment.py:549] Creating TrainRunner ...
I0901 12:56:53.482915 140583573075968 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:56:53.483165 140583573075968 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:56:53.483306 140583573075968 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:56:53.483441 140583573075968 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:56:53.483559 140583573075968 dqn_agent.py:275] 	 update_period: 4
I0901 12:56:53.483670 140583573075968 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:56:53.483835 140583573075968 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:56:53.483962 140583573075968 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:56:53.484324 140583573075968 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:56:53.484506 140583573075968 dqn_agent.py:280] 	 optimizer: adam
I0901 12:56:53.484653 140583573075968 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:56:53.484803 140583573075968 dqn_agent.py:283] 	 seed: 1630501013482853
I0901 12:56:53.488049 140583573075968 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:56:53.488249 140583573075968 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 12:56:53.488389 140583573075968 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:56:53.488536 140583573075968 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:56:53.488656 140583573075968 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:56:53.489029 140583573075968 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:56:53.489557 140583573075968 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:56:53.489753 140583573075968 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:56:53.489938 140583573075968 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:56:53.535950 140583573075968 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:56:54.026598 140583573075968 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:56:54.041216 140583573075968 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:56:54.050225 140583573075968 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:56:54.050477 140583573075968 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:56:54.050596 140583573075968 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:56:54.050694 140583573075968 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:56:54.050844 140583573075968 dqn_agent.py:275] 	 update_period: 4
I0901 12:56:54.050968 140583573075968 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:56:54.051076 140583573075968 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:56:54.051197 140583573075968 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:56:54.051296 140583573075968 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:56:54.051493 140583573075968 dqn_agent.py:280] 	 optimizer: adam
I0901 12:56:54.051609 140583573075968 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:56:54.051711 140583573075968 dqn_agent.py:283] 	 seed: 1630501014050166
I0901 12:56:54.054877 140583573075968 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:56:54.055139 140583573075968 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 12:56:54.055292 140583573075968 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:56:54.055457 140583573075968 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:56:54.055597 140583573075968 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:56:54.055710 140583573075968 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:56:54.055822 140583573075968 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:56:54.055943 140583573075968 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:56:54.056060 140583573075968 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:56:54.093575 140583573075968 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:56:54.117146 140583573075968 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:56:54.117961 140583573075968 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 134.93
I0901 12:57:01.529521 140583573075968 replay_runner.py:36] Average training steps per second: 134.93
I0901 12:57:03.119004 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1
I0901 12:57:03.362468 140583573075968 replay_runner.py:41] Starting iteration 1
Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 194.70
I0901 12:57:08.499057 140583573075968 replay_runner.py:36] Average training steps per second: 194.70
I0901 12:57:08.966344 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 2
I0901 12:57:09.211876 140583573075968 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 191.71
I0901 12:57:14.428542 140583573075968 replay_runner.py:36] Average training steps per second: 191.71
I0901 12:57:14.876109 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 3
I0901 12:57:15.126383 140583573075968 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 202.68
I0901 12:57:20.060668 140583573075968 replay_runner.py:36] Average training steps per second: 202.68
I0901 12:57:20.496535 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 4
I0901 12:57:20.728537 140583573075968 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 193.39
I0901 12:57:25.899946 140583573075968 replay_runner.py:36] Average training steps per second: 193.39
I0901 12:57:26.347584 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 5
I0901 12:57:26.595349 140583573075968 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 193.77
I0901 12:57:31.756635 140583573075968 replay_runner.py:36] Average training steps per second: 193.77
I0901 12:57:32.203478 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6
I0901 12:57:32.434644 140583573075968 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 188.21
I0901 12:57:37.748561 140583573075968 replay_runner.py:36] Average training steps per second: 188.21
I0901 12:57:38.179170 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7

Steps executed: 306 Episode length: 109 Return: -108.0
INFO:tensorflow:Average training steps per second: 188.87
I0901 12:57:43.714990 140583573075968 replay_runner.py:36] Average training steps per second: 188.87
I0901 12:57:43.985688 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.00
INFO:tensorflow:Starting iteration 8

Steps executed: 647 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 186.11
I0901 12:57:49.615474 140583573075968 replay_runner.py:36] Average training steps per second: 186.11
I0901 12:57:50.166371 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -323.00
INFO:tensorflow:Starting iteration 9

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 189.25
I0901 12:57:55.706294 140583573075968 replay_runner.py:36] Average training steps per second: 189.25
I0901 12:57:56.125812 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 10

Steps executed: 584 Episode length: 390 Return: -389.0
INFO:tensorflow:Average training steps per second: 188.02
I0901 12:58:01.672185 140583573075968 replay_runner.py:36] Average training steps per second: 188.02
I0901 12:58:02.203950 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -291.00
INFO:tensorflow:Starting iteration 11
I0901 12:58:02.430247 140583573075968 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 190.65

Steps executed: 243 Episode length: 79 Return: -78.000
I0901 12:58:07.893538 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.00
INFO:tensorflow:Starting iteration 12
I0901 12:58:08.130109 140583573075968 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 187.25
I0901 12:58:13.471063 140583573075968 replay_runner.py:36] Average training steps per second: 187.25


Steps executed: 269 Episode length: 88 Return: -87.0.0
INFO:tensorflow:Starting iteration 13
I0901 12:58:13.963818 140583573075968 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 188.28
I0901 12:58:19.275500 140583573075968 replay_runner.py:36] Average training steps per second: 188.28
I0901 12:58:19.556024 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.00
INFO:tensorflow:Starting iteration 14

Steps executed: 294 Episode length: 111 Return: -110.0
INFO:tensorflow:Average training steps per second: 190.14
I0901 12:58:25.043407 140583573075968 replay_runner.py:36] Average training steps per second: 190.14

Steps executed: 222 Episode length: 132 Return: -131.0
INFO:tensorflow:Starting iteration 15
I0901 12:58:25.474588 140583573075968 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 192.24
I0901 12:58:30.677239 140583573075968 replay_runner.py:36] Average training steps per second: 192.24

Steps executed: 627 Episode length: 500 Return: -500.0
INFO:tensorflow:Starting iteration 16
I0901 12:58:31.494152 140583573075968 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 200.05
I0901 12:58:36.493393 140583573075968 replay_runner.py:36] Average training steps per second: 200.05
I0901 12:58:36.681458 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.50
INFO:tensorflow:Starting iteration 17


Steps executed: 262 Episode length: 115 Return: -114.0
INFO:tensorflow:Average training steps per second: 193.18
I0901 12:58:42.107369 140583573075968 replay_runner.py:36] Average training steps per second: 193.18
I0901 12:58:42.341119 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.33
INFO:tensorflow:Starting iteration 18

Steps executed: 309 Episode length: 117 Return: -116.0
INFO:tensorflow:Average training steps per second: 185.85
I0901 12:58:47.968515 140583573075968 replay_runner.py:36] Average training steps per second: 185.85
I0901 12:58:48.255749 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.00
INFO:tensorflow:Starting iteration 19

Steps executed: 95 Episode length: 95 Return: -94.06.0
INFO:tensorflow:Average training steps per second: 189.13
I0901 12:58:53.791397 140583573075968 replay_runner.py:36] Average training steps per second: 189.13
I0901 12:58:54.044775 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.67
INFO:tensorflow:Starting iteration 20

Steps executed: 272 Episode length: 96 Return: -95.0.0
INFO:tensorflow:Average training steps per second: 193.07

Steps executed: 328 Episode length: 134 Return: -133.0
I0901 12:58:59.793647 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.33
INFO:tensorflow:Starting iteration 21

Steps executed: 246 Episode length: 135 Return: -134.0
INFO:tensorflow:Average training steps per second: 197.29
I0901 12:59:05.116233 140583573075968 replay_runner.py:36] Average training steps per second: 197.29
I0901 12:59:05.337278 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.00
INFO:tensorflow:Starting iteration 22

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 190.12
I0901 12:59:10.844959 140583573075968 replay_runner.py:36] Average training steps per second: 190.12
I0901 12:59:11.293031 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 23

Steps executed: 209 Episode length: 110 Return: -109.0
INFO:tensorflow:Average training steps per second: 192.35
I0901 12:59:16.725614 140583573075968 replay_runner.py:36] Average training steps per second: 192.35
I0901 12:59:16.910622 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.50
INFO:tensorflow:Starting iteration 24

Steps executed: 272 Episode length: 94 Return: -93.0.0
INFO:tensorflow:Average training steps per second: 188.50
I0901 12:59:22.461550 140583573075968 replay_runner.py:36] Average training steps per second: 188.50
I0901 12:59:22.705960 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.67
INFO:tensorflow:Starting iteration 25

Steps executed: 254 Episode length: 95 Return: -94.0.0
INFO:tensorflow:Average training steps per second: 184.27
I0901 12:59:28.385109 140583573075968 replay_runner.py:36] Average training steps per second: 184.27
I0901 12:59:28.609703 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.67
INFO:tensorflow:Starting iteration 26

Steps executed: 235 Episode length: 96 Return: -95.0.0
INFO:tensorflow:Average training steps per second: 183.82
I0901 12:59:34.293540 140583573075968 replay_runner.py:36] Average training steps per second: 183.82
I0901 12:59:34.506186 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.50
INFO:tensorflow:Starting iteration 27
I0901 12:59:34.734988 140583573075968 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 195.22
I0901 12:59:39.857709 140583573075968 replay_runner.py:36] Average training steps per second: 195.22

Steps executed: 259 Episode length: 96 Return: -95.0.0
INFO:tensorflow:Starting iteration 28

Steps executed: 178 Episode length: 87 Return: -86.0.0
INFO:tensorflow:Average training steps per second: 191.85
I0901 12:59:45.605129 140583573075968 replay_runner.py:36] Average training steps per second: 191.85
I0901 12:59:45.861607 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.33
INFO:tensorflow:Starting iteration 29


Done fixed training!Episode length: 64 Return: -63.0.0
INFO:tensorflow:Average training steps per second: 194.30
I0901 12:59:51.247308 140583573075968 replay_runner.py:36] Average training steps per second: 194.30
I0901 12:59:51.445236 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.67