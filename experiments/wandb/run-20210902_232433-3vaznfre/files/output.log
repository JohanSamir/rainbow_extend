I0902 23:24:40.267703 139803223304192 run_experiment.py:549] Creating TrainRunner ...
I0902 23:24:40.279969 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:24:40.280227 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:24:40.280416 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:24:40.280548 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:24:40.280664 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0902 23:24:40.280768 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:24:40.280842 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:24:40.281001 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:24:40.281107 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:24:40.281233 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0902 23:24:40.281320 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:24:40.281428 139803223304192 dqn_agent.py:283] 	 seed: 1630625080279900
I0902 23:24:40.284933 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:24:40.285158 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:24:40.285320 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:24:40.285462 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:24:40.285595 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:24:40.285728 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:24:40.285855 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:24:40.285974 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:24:40.286098 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0902 23:24:41.817770 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:24:42.277903 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:24:42.290408 139803223304192 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:24:42.300406 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:24:42.300732 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:24:42.300873 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:24:42.300991 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:24:42.301097 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0902 23:24:42.301174 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:24:42.301250 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:24:42.301343 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:24:42.301657 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:24:42.302032 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0902 23:24:42.302211 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:24:42.302362 139803223304192 dqn_agent.py:283] 	 seed: 1630625082300348
I0902 23:24:42.305207 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:24:42.305361 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:24:42.305449 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:24:42.305514 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:24:42.305572 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:24:42.305716 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:24:42.305787 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:24:42.305916 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:24:42.306023 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:24:42.336405 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:24:42.358783 139803223304192 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:24:42.359103 139803223304192 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 176.00
I0902 23:24:48.041506 139803223304192 replay_runner.py:36] Average training steps per second: 176.00
I0902 23:24:49.558917 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.41
Steps executed: 293 Episode length: 136 Return: -311.0012718615082
INFO:tensorflow:Starting iteration 1

Steps executed: 276 Episode length: 142 Return: -292.41612937033426
INFO:tensorflow:Average training steps per second: 229.21
I0902 23:24:58.144936 139803223304192 replay_runner.py:36] Average training steps per second: 229.21
I0902 23:24:58.366643 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.36
INFO:tensorflow:Starting iteration 2

Steps executed: 264 Episode length: 264 Return: -325.31700637214716
INFO:tensorflow:Average training steps per second: 226.68
I0902 23:25:07.007148 139803223304192 replay_runner.py:36] Average training steps per second: 226.68
I0902 23:25:07.348461 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.32
INFO:tensorflow:Starting iteration 3
I0902 23:25:11.565519 139803223304192 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 230.34

Steps executed: 318 Episode length: 318 Return: -102.29922222165817
I0902 23:25:16.403473 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.30
INFO:tensorflow:Starting iteration 4
I0902 23:25:20.532204 139803223304192 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 225.76

Steps executed: 1000 Episode length: 1000 Return: -112.18663050300721
I0902 23:25:29.626600 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.19
INFO:tensorflow:Starting iteration 5
I0902 23:25:33.852530 139803223304192 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 221.92

Steps executed: 1000 Episode length: 1000 Return: -56.950067358840341
I0902 23:25:40.806381 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -56.95
INFO:tensorflow:Starting iteration 6
I0902 23:25:45.102883 139803223304192 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 227.99

Steps executed: 1000 Episode length: 1000 Return: -186.72835382017078
I0902 23:25:52.903604 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.73
INFO:tensorflow:Starting iteration 7
I0902 23:25:57.298961 139803223304192 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 226.46

Steps executed: 1000 Episode length: 1000 Return: -247.52836592639503
I0902 23:26:04.176880 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -247.53
INFO:tensorflow:Starting iteration 8
I0902 23:26:08.477082 139803223304192 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 222.92

Steps executed: 1000 Episode length: 1000 Return: -109.25453862085075
I0902 23:26:15.831566 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.25
INFO:tensorflow:Starting iteration 9
I0902 23:26:20.244153 139803223304192 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 220.68

Steps executed: 1000 Episode length: 1000 Return: -324.80749532152976
I0902 23:26:27.281694 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -324.81
INFO:tensorflow:Starting iteration 10

Steps executed: 206 Episode length: 75 Return: -39.021461921831393676
INFO:tensorflow:Average training steps per second: 227.43
I0902 23:26:36.062119 139803223304192 replay_runner.py:36] Average training steps per second: 227.43
I0902 23:26:36.239082 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.35
INFO:tensorflow:Starting iteration 11
I0902 23:26:40.462694 139803223304192 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 219.31

Steps executed: 1000 Episode length: 1000 Return: -154.80225863696616
I0902 23:26:48.421420 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.80
INFO:tensorflow:Starting iteration 12

Steps executed: 583 Episode length: 583 Return: -404.0281357393879516
INFO:tensorflow:Average training steps per second: 218.21
I0902 23:26:57.398304 139803223304192 replay_runner.py:36] Average training steps per second: 218.21
I0902 23:26:58.446521 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -404.03
INFO:tensorflow:Starting iteration 13
I0902 23:27:02.745858 139803223304192 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 216.65

Steps executed: 1000 Episode length: 1000 Return: -125.02725577279284
I0902 23:27:10.210737 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.03
INFO:tensorflow:Starting iteration 14
I0902 23:27:14.222912 139803223304192 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 219.92

Steps executed: 1000 Episode length: 1000 Return: -87.028142513394494
I0902 23:27:21.964406 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.03
INFO:tensorflow:Starting iteration 15
I0902 23:27:26.224529 139803223304192 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 221.78

Steps executed: 1000 Episode length: 1000 Return: -71.324894630620074
I0902 23:27:33.943379 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.32
INFO:tensorflow:Starting iteration 16
I0902 23:27:38.189354 139803223304192 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 217.99

Steps executed: 244 Episode length: 154 Return: -72.75946596306898074
I0902 23:27:43.011968 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.04
INFO:tensorflow:Starting iteration 17

Steps executed: 269 Episode length: 269 Return: -250.2841448730058974
INFO:tensorflow:Average training steps per second: 229.55
I0902 23:27:51.498683 139803223304192 replay_runner.py:36] Average training steps per second: 229.55
I0902 23:27:51.818350 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -250.28
INFO:tensorflow:Starting iteration 18

Steps executed: 69 Episode length: 69 Return: -33.8926281273265258974
INFO:tensorflow:Average training steps per second: 229.44

Steps executed: 502 Episode length: 433 Return: -5.459806624784832974
I0902 23:28:01.112156 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -19.68
INFO:tensorflow:Starting iteration 19
I0902 23:28:05.477029 139803223304192 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 222.00

Steps executed: 679 Episode length: 679 Return: -93.57659043998179974
I0902 23:28:11.016506 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.58
INFO:tensorflow:Starting iteration 20

Steps executed: 337 Episode length: 337 Return: -269.3818601743393974
INFO:tensorflow:Average training steps per second: 236.97
I0902 23:28:19.634592 139803223304192 replay_runner.py:36] Average training steps per second: 236.97
I0902 23:28:20.113643 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.38
INFO:tensorflow:Starting iteration 21

Steps executed: 117 Episode length: 117 Return: -220.3302789020444874
INFO:tensorflow:Average training steps per second: 240.13
I0902 23:28:28.495395 139803223304192 replay_runner.py:36] Average training steps per second: 240.13

Steps executed: 238 Episode length: 121 Return: -244.9168064057447274
INFO:tensorflow:Starting iteration 22

Steps executed: 583 Episode length: 583 Return: -91.66847353365154274
INFO:tensorflow:Average training steps per second: 230.47
I0902 23:28:37.442024 139803223304192 replay_runner.py:36] Average training steps per second: 230.47
I0902 23:28:38.603442 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.67
INFO:tensorflow:Starting iteration 23

Steps executed: 246 Episode length: 246 Return: -342.5629662539851774
INFO:tensorflow:Average training steps per second: 216.74
I0902 23:28:47.471108 139803223304192 replay_runner.py:36] Average training steps per second: 216.74
I0902 23:28:47.761228 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.56
INFO:tensorflow:Starting iteration 24
I0902 23:28:52.085911 139803223304192 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 216.73

Steps executed: 875 Episode length: 875 Return: 154.45787634853491774
I0902 23:28:59.388410 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: 154.46
INFO:tensorflow:Starting iteration 25

Steps executed: 230 Episode length: 51 Return: -133.71840689104362774
INFO:tensorflow:Average training steps per second: 219.44
I0902 23:29:08.299658 139803223304192 replay_runner.py:36] Average training steps per second: 219.44
I0902 23:29:08.483886 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.78
INFO:tensorflow:Starting iteration 26

Steps executed: 258 Episode length: 258 Return: -137.7696346537882274
INFO:tensorflow:Average training steps per second: 220.92
I0902 23:29:17.431883 139803223304192 replay_runner.py:36] Average training steps per second: 220.92
I0902 23:29:17.721227 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.77
INFO:tensorflow:Starting iteration 27

Steps executed: 160 Episode length: 160 Return: -72.96811246273153274
INFO:tensorflow:Average training steps per second: 220.42
I0902 23:29:26.634137 139803223304192 replay_runner.py:36] Average training steps per second: 220.42

Steps executed: 331 Episode length: 171 Return: -260.5331150918400574
INFO:tensorflow:Starting iteration 28

Steps executed: 264 Episode length: 264 Return: -616.0528660839644574
INFO:tensorflow:Average training steps per second: 221.62
I0902 23:29:35.454052 139803223304192 replay_runner.py:36] Average training steps per second: 221.62
I0902 23:29:35.838191 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -616.05
INFO:tensorflow:Starting iteration 29
I0902 23:29:40.141972 139803223304192 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 221.63

Steps executed: 850 Episode length: 850 Return: -474.6841177754305474

Done fixed training!Episode length: 850 Return: -474.6841177754305474