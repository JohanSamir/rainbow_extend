I0902 18:13:58.078847 140016423897088 run_experiment.py:549] Creating TrainRunner ...
I0902 18:13:58.085267 140016423897088 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:13:58.085381 140016423897088 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:13:58.085442 140016423897088 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:13:58.085522 140016423897088 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:13:58.085585 140016423897088 dqn_agent.py:275] 	 update_period: 4
I0902 18:13:58.085638 140016423897088 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:13:58.085682 140016423897088 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:13:58.085753 140016423897088 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:13:58.085809 140016423897088 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:13:58.085875 140016423897088 dqn_agent.py:280] 	 optimizer: adam
I0902 18:13:58.085940 140016423897088 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:13:58.085997 140016423897088 dqn_agent.py:283] 	 seed: 1630606438085239
I0902 18:13:58.087406 140016423897088 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:13:58.087501 140016423897088 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:13:58.087564 140016423897088 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:13:58.087618 140016423897088 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:13:58.087666 140016423897088 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:13:58.087717 140016423897088 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:13:58.087788 140016423897088 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:13:58.087852 140016423897088 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:13:58.087916 140016423897088 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:13:58.106955 140016423897088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.003125
I0902 18:13:58.310869 140016423897088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.003125
I0902 18:13:58.318629 140016423897088 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:13:58.324331 140016423897088 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:13:58.324468 140016423897088 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:13:58.324540 140016423897088 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:13:58.324614 140016423897088 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:13:58.324667 140016423897088 dqn_agent.py:275] 	 update_period: 4
I0902 18:13:58.324736 140016423897088 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:13:58.324833 140016423897088 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:13:58.324898 140016423897088 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:13:58.324969 140016423897088 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:13:58.325031 140016423897088 dqn_agent.py:280] 	 optimizer: adam
I0902 18:13:58.325092 140016423897088 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:13:58.325153 140016423897088 dqn_agent.py:283] 	 seed: 1630606438324286
I0902 18:13:58.326466 140016423897088 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:13:58.326567 140016423897088 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:13:58.326620 140016423897088 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:13:58.326691 140016423897088 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:13:58.326744 140016423897088 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:13:58.326820 140016423897088 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:13:58.326868 140016423897088 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:13:58.326941 140016423897088 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:13:58.327004 140016423897088 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:13:58.343873 140016423897088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.003125
I0902 18:13:58.356179 140016423897088 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:13:58.356331 140016423897088 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 268.48
I0902 18:14:02.081175 140016423897088 replay_runner.py:36] Average training steps per second: 268.48
I0902 18:14:02.867653 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -250.37
Steps executed: 266 Episode length: 121 Return: -284.5800466591314
INFO:tensorflow:Starting iteration 1

Steps executed: 333 Episode length: 138 Return: -326.42948187620874
INFO:tensorflow:Average training steps per second: 347.77
I0902 18:14:09.018030 140016423897088 replay_runner.py:36] Average training steps per second: 347.77
I0902 18:14:09.234449 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -322.10
INFO:tensorflow:Starting iteration 2

Steps executed: 134 Episode length: 134 Return: -306.23721420320034
INFO:tensorflow:Average training steps per second: 337.36

Steps executed: 267 Episode length: 133 Return: -387.44671838354014
I0902 18:14:15.750990 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.84
INFO:tensorflow:Starting iteration 3

Steps executed: 298 Episode length: 133 Return: -285.03310198733224
INFO:tensorflow:Average training steps per second: 335.09
I0902 18:14:22.166345 140016423897088 replay_runner.py:36] Average training steps per second: 335.09
I0902 18:14:22.322676 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.67
INFO:tensorflow:Starting iteration 4

Steps executed: 223 Episode length: 223 Return: -227.00661374988554
INFO:tensorflow:Average training steps per second: 334.28
I0902 18:14:28.741511 140016423897088 replay_runner.py:36] Average training steps per second: 334.28
I0902 18:14:28.882432 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.01
INFO:tensorflow:Starting iteration 5

Steps executed: 145 Episode length: 145 Return: -181.59035902898262
INFO:tensorflow:Average training steps per second: 336.01

Steps executed: 782 Episode length: 637 Return: -180.19083557741465
I0902 18:14:36.178552 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.89
INFO:tensorflow:Starting iteration 6
I0902 18:14:39.594523 140016423897088 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 334.54

Steps executed: 917 Episode length: 917 Return: -259.96717105016245
I0902 18:14:44.147491 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.97
INFO:tensorflow:Starting iteration 7

Steps executed: 463 Episode length: 463 Return: -1311.9794901091295
INFO:tensorflow:Average training steps per second: 336.46
I0902 18:14:50.487232 140016423897088 replay_runner.py:36] Average training steps per second: 336.46
I0902 18:14:51.019744 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -1311.98
INFO:tensorflow:Starting iteration 8
I0902 18:14:54.347345 140016423897088 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 362.05

Steps executed: 1000 Episode length: 1000 Return: -121.54268282354488
I0902 18:14:58.973917 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.54
INFO:tensorflow:Starting iteration 9
I0902 18:15:02.315370 140016423897088 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 351.07

Steps executed: 1000 Episode length: 1000 Return: -83.799489459462588
I0902 18:15:07.003605 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.80
INFO:tensorflow:Starting iteration 10
I0902 18:15:10.258249 140016423897088 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 338.66

Steps executed: 798 Episode length: 798 Return: -461.6206023441098488
I0902 18:15:14.188555 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -461.62
INFO:tensorflow:Starting iteration 11

Steps executed: 362 Episode length: 362 Return: -579.8207084156677488
INFO:tensorflow:Average training steps per second: 337.77
I0902 18:15:20.382751 140016423897088 replay_runner.py:36] Average training steps per second: 337.77
I0902 18:15:20.727600 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -579.82
INFO:tensorflow:Starting iteration 12
I0902 18:15:24.103043 140016423897088 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 353.35

Steps executed: 879 Episode length: 879 Return: -505.1116429859831488
I0902 18:15:28.489165 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -505.11
INFO:tensorflow:Starting iteration 13
I0902 18:15:31.740759 140016423897088 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 342.28

Steps executed: 1000 Episode length: 1000 Return: -678.08866264667598
I0902 18:15:37.152122 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -678.09
INFO:tensorflow:Starting iteration 14
I0902 18:15:40.335292 140016423897088 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 329.30

Steps executed: 712 Episode length: 712 Return: -865.8969944552881598
I0902 18:15:44.510844 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -865.90
INFO:tensorflow:Starting iteration 15

Steps executed: 644 Episode length: 517 Return: -376.9829472445816598
INFO:tensorflow:Average training steps per second: 342.90
I0902 18:15:50.771401 140016423897088 replay_runner.py:36] Average training steps per second: 342.90
I0902 18:15:51.484494 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -321.55
INFO:tensorflow:Starting iteration 16
I0902 18:15:54.785988 140016423897088 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 359.22

Steps executed: 1000 Episode length: 1000 Return: -190.54079590701628
I0902 18:15:59.976251 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.54
INFO:tensorflow:Starting iteration 17
I0902 18:16:03.177832 140016423897088 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 333.85

Steps executed: 1000 Episode length: 1000 Return: -148.19823309015186
I0902 18:16:08.510776 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.20
INFO:tensorflow:Starting iteration 18
I0902 18:16:11.811339 140016423897088 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 337.47

Steps executed: 1000 Episode length: 1000 Return: -151.06161880627027
I0902 18:16:16.599267 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.06
INFO:tensorflow:Starting iteration 19

Steps executed: 631 Episode length: 631 Return: -404.3296664683884027
INFO:tensorflow:Average training steps per second: 364.41
I0902 18:16:22.722436 140016423897088 replay_runner.py:36] Average training steps per second: 364.41
I0902 18:16:23.848357 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -404.33
INFO:tensorflow:Starting iteration 20
I0902 18:16:27.316462 140016423897088 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 380.11

Steps executed: 653 Episode length: 653 Return: -539.9277954032458027
I0902 18:16:31.351018 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -539.93
INFO:tensorflow:Starting iteration 21

Steps executed: 272 Episode length: 147 Return: -287.5845596534733427
INFO:tensorflow:Average training steps per second: 357.46
I0902 18:16:37.558875 140016423897088 replay_runner.py:36] Average training steps per second: 357.46
I0902 18:16:37.737826 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -354.97
INFO:tensorflow:Starting iteration 22
I0902 18:16:41.160179 140016423897088 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 354.69
I0902 18:16:43.979923 140016423897088 replay_runner.py:36] Average training steps per second: 354.69

Steps executed: 372 Episode length: 372 Return: 222.54402136824496427
INFO:tensorflow:Starting iteration 23

Steps executed: 309 Episode length: 309 Return: -358.5619279328552727
INFO:tensorflow:Average training steps per second: 357.55
I0902 18:16:50.577816 140016423897088 replay_runner.py:36] Average training steps per second: 357.55
I0902 18:16:50.822100 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -358.56
INFO:tensorflow:Starting iteration 24

Steps executed: 269 Episode length: 142 Return: -341.8844030891640427
INFO:tensorflow:Average training steps per second: 334.79
I0902 18:16:57.207622 140016423897088 replay_runner.py:36] Average training steps per second: 334.79
I0902 18:16:57.358228 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -382.11
INFO:tensorflow:Starting iteration 25
I0902 18:17:00.694564 140016423897088 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 337.96

Steps executed: 1000 Episode length: 1000 Return: -76.259851006421877
I0902 18:17:06.470891 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.26
INFO:tensorflow:Starting iteration 26

Steps executed: 270 Episode length: 139 Return: -95.55482285913561277
INFO:tensorflow:Average training steps per second: 333.30
I0902 18:17:12.899043 140016423897088 replay_runner.py:36] Average training steps per second: 333.30
I0902 18:17:13.036201 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.23
INFO:tensorflow:Starting iteration 27

Steps executed: 488 Episode length: 488 Return: -272.4882183793545277
INFO:tensorflow:Average training steps per second: 354.61
I0902 18:17:19.272085 140016423897088 replay_runner.py:36] Average training steps per second: 354.61
I0902 18:17:19.897134 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -272.49
INFO:tensorflow:Starting iteration 28
I0902 18:17:23.276968 140016423897088 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 349.62

Steps executed: 1000 Episode length: 1000 Return: -39.867462508488617
I0902 18:17:29.271110 140016423897088 run_experiment.py:428] Average undiscounted return per evaluation episode: -39.87
INFO:tensorflow:Starting iteration 29

Steps executed: 225 Episode length: 225 Return: -178.7009429354337717
INFO:tensorflow:Average training steps per second: 338.17
I0902 18:17:35.507196 140016423897088 replay_runner.py:36] Average training steps per second: 338.17

Done fixed training!Episode length: 225 Return: -178.7009429354337717