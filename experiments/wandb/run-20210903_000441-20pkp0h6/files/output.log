Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0903 00:04:47.048393 140006414895104 run_experiment.py:549] Creating TrainRunner ...
I0903 00:04:47.055944 140006414895104 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:04:47.056096 140006414895104 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:04:47.056177 140006414895104 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:04:47.056253 140006414895104 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:04:47.056329 140006414895104 dqn_agent.py:275] 	 update_period: 4
I0903 00:04:47.056393 140006414895104 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:04:47.056503 140006414895104 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:04:47.056651 140006414895104 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:04:47.056890 140006414895104 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:04:47.057018 140006414895104 dqn_agent.py:280] 	 optimizer: adam
I0903 00:04:47.057123 140006414895104 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:04:47.057222 140006414895104 dqn_agent.py:283] 	 seed: 1630627487055892
I0903 00:04:47.060005 140006414895104 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:04:47.060150 140006414895104 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:04:47.060245 140006414895104 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:04:47.060355 140006414895104 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:04:47.060419 140006414895104 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:04:47.060528 140006414895104 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:04:47.060613 140006414895104 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:04:47.060684 140006414895104 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:04:47.060751 140006414895104 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:04:47.087392 140006414895104 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:04:47.392090 140006414895104 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:04:47.400862 140006414895104 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:04:47.408445 140006414895104 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:04:47.408591 140006414895104 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:04:47.408674 140006414895104 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:04:47.408736 140006414895104 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:04:47.408793 140006414895104 dqn_agent.py:275] 	 update_period: 4
I0903 00:04:47.408874 140006414895104 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:04:47.409030 140006414895104 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:04:47.409087 140006414895104 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:04:47.409152 140006414895104 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:04:47.409237 140006414895104 dqn_agent.py:280] 	 optimizer: adam
I0903 00:04:47.409315 140006414895104 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:04:47.409384 140006414895104 dqn_agent.py:283] 	 seed: 1630627487408413
I0903 00:04:47.410835 140006414895104 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:04:47.410944 140006414895104 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:04:47.411023 140006414895104 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:04:47.411077 140006414895104 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:04:47.411135 140006414895104 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:04:47.411198 140006414895104 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:04:47.411253 140006414895104 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:04:47.411322 140006414895104 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:04:47.411380 140006414895104 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:04:47.432978 140006414895104 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:04:47.451544 140006414895104 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:04:47.451762 140006414895104 replay_runner.py:41] Starting iteration 0
Steps executed: 208 Episode length: 79 Return: -339.1286613941293
INFO:tensorflow:Average training steps per second: 242.52
I0903 00:04:51.575296 140006414895104 replay_runner.py:36] Average training steps per second: 242.52
I0903 00:04:52.363630 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -322.88
INFO:tensorflow:Starting iteration 1

Steps executed: 401 Episode length: 259 Return: -92.46562685380738
INFO:tensorflow:Average training steps per second: 320.15
I0903 00:04:58.934949 140006414895104 replay_runner.py:36] Average training steps per second: 320.15
I0903 00:04:59.204695 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.26
INFO:tensorflow:Starting iteration 2

Steps executed: 269 Episode length: 149 Return: -399.33026096314053
INFO:tensorflow:Average training steps per second: 331.18
I0903 00:05:05.562842 140006414895104 replay_runner.py:36] Average training steps per second: 331.18
I0903 00:05:05.739255 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.81
INFO:tensorflow:Starting iteration 3

Steps executed: 323 Episode length: 323 Return: -50.723867401372833
INFO:tensorflow:Average training steps per second: 335.30
I0903 00:05:12.120714 140006414895104 replay_runner.py:36] Average training steps per second: 335.30
I0903 00:05:12.421533 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -50.72
INFO:tensorflow:Starting iteration 4

Steps executed: 1000 Episode length: 1000 Return: -37.874861590738924
INFO:tensorflow:Average training steps per second: 330.04
I0903 00:05:18.881279 140006414895104 replay_runner.py:36] Average training steps per second: 330.04
I0903 00:05:20.391599 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.87
INFO:tensorflow:Starting iteration 5
I0903 00:05:23.835412 140006414895104 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 323.00

Steps executed: 1000 Episode length: 1000 Return: -127.04808439584173
I0903 00:05:29.720033 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.05
INFO:tensorflow:Starting iteration 6
I0903 00:05:33.285015 140006414895104 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 321.40

Steps executed: 1000 Episode length: 1000 Return: -157.06078870786843
I0903 00:05:38.839996 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -157.06
INFO:tensorflow:Starting iteration 7
I0903 00:05:42.181697 140006414895104 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 333.46

Steps executed: 1000 Episode length: 1000 Return: -138.45211593675876
I0903 00:05:47.584854 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.45
INFO:tensorflow:Starting iteration 8
I0903 00:05:50.884841 140006414895104 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 320.01

Steps executed: 1000 Episode length: 1000 Return: -70.999085273935986
I0903 00:05:55.886202 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.00
INFO:tensorflow:Starting iteration 9
I0903 00:05:59.222186 140006414895104 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 328.54

Steps executed: 867 Episode length: 867 Return: -284.2652873964238986
I0903 00:06:03.575769 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.27
INFO:tensorflow:Starting iteration 10
I0903 00:06:07.016326 140006414895104 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 335.78
I0903 00:06:09.994729 140006414895104 replay_runner.py:36] Average training steps per second: 335.78

Steps executed: 714 Episode length: 714 Return: -271.6809168996492986
INFO:tensorflow:Starting iteration 11

Steps executed: 667 Episode length: 667 Return: -415.9983838095951786
INFO:tensorflow:Average training steps per second: 332.64
I0903 00:06:17.592156 140006414895104 replay_runner.py:36] Average training steps per second: 332.64
I0903 00:06:18.418122 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -416.00
INFO:tensorflow:Starting iteration 12

Steps executed: 341 Episode length: 341 Return: -236.3374592270792786
INFO:tensorflow:Average training steps per second: 350.60
I0903 00:06:24.740196 140006414895104 replay_runner.py:36] Average training steps per second: 350.60
I0903 00:06:25.068088 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.34
INFO:tensorflow:Starting iteration 13

Steps executed: 312 Episode length: 312 Return: -296.5518313104476786
INFO:tensorflow:Average training steps per second: 330.85
I0903 00:06:31.541153 140006414895104 replay_runner.py:36] Average training steps per second: 330.85
I0903 00:06:31.777836 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.55
INFO:tensorflow:Starting iteration 14

Steps executed: 534 Episode length: 534 Return: 211.34509944164688786
INFO:tensorflow:Average training steps per second: 336.70
I0903 00:06:38.246677 140006414895104 replay_runner.py:36] Average training steps per second: 336.70
I0903 00:06:38.944733 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: 211.35
INFO:tensorflow:Starting iteration 15
I0903 00:06:42.441127 140006414895104 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 323.93
I0903 00:06:45.528495 140006414895104 replay_runner.py:36] Average training steps per second: 323.93

Steps executed: 827 Episode length: 827 Return: -171.4609472173845386
INFO:tensorflow:Starting iteration 16

Steps executed: 241 Episode length: 241 Return: -540.4034615511509386
INFO:tensorflow:Average training steps per second: 318.09
I0903 00:06:53.903102 140006414895104 replay_runner.py:36] Average training steps per second: 318.09
I0903 00:06:54.094717 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -540.40
INFO:tensorflow:Starting iteration 17

Steps executed: 263 Episode length: 263 Return: -51.17619179990517386
INFO:tensorflow:Average training steps per second: 317.25
I0903 00:07:00.663676 140006414895104 replay_runner.py:36] Average training steps per second: 317.25
I0903 00:07:00.878786 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -51.18
INFO:tensorflow:Starting iteration 18
I0903 00:07:04.313868 140006414895104 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 315.86

Steps executed: 376 Episode length: 376 Return: -367.4092898146342386
I0903 00:07:07.824161 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -367.41
INFO:tensorflow:Starting iteration 19

Steps executed: 410 Episode length: 410 Return: -251.0532528188323386
INFO:tensorflow:Average training steps per second: 315.04
I0903 00:07:14.392000 140006414895104 replay_runner.py:36] Average training steps per second: 315.04
I0903 00:07:14.768337 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -251.05
INFO:tensorflow:Starting iteration 20
I0903 00:07:18.172494 140006414895104 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 313.38

Steps executed: 445 Episode length: 445 Return: 182.35712985916638386
I0903 00:07:21.872008 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: 182.36
INFO:tensorflow:Starting iteration 21

Steps executed: 268 Episode length: 80 Return: -89.725550132968965386
INFO:tensorflow:Average training steps per second: 326.35
I0903 00:07:28.358490 140006414895104 replay_runner.py:36] Average training steps per second: 326.35
I0903 00:07:28.539541 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.72
INFO:tensorflow:Starting iteration 22

Steps executed: 107 Episode length: 107 Return: -253.7485604448110386
INFO:tensorflow:Average training steps per second: 327.34
I0903 00:07:35.069794 140006414895104 replay_runner.py:36] Average training steps per second: 327.34

Steps executed: 512 Episode length: 313 Return: -180.6346657800646786
INFO:tensorflow:Starting iteration 23

Steps executed: 256 Episode length: 127 Return: -264.3297173174898486
INFO:tensorflow:Average training steps per second: 320.45
I0903 00:07:42.062150 140006414895104 replay_runner.py:36] Average training steps per second: 320.45
I0903 00:07:42.208647 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.56
INFO:tensorflow:Starting iteration 24

Steps executed: 511 Episode length: 329 Return: -71.13436016977923486
INFO:tensorflow:Average training steps per second: 332.59
I0903 00:07:48.612297 140006414895104 replay_runner.py:36] Average training steps per second: 332.59
I0903 00:07:48.971748 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -52.36
INFO:tensorflow:Starting iteration 25
I0903 00:07:52.416513 140006414895104 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 336.92
I0903 00:07:55.384928 140006414895104 replay_runner.py:36] Average training steps per second: 336.92

Steps executed: 312 Episode length: 186 Return: -25.44171785188953586
INFO:tensorflow:Starting iteration 26

Steps executed: 317 Episode length: 143 Return: -192.8998307960395486
INFO:tensorflow:Average training steps per second: 323.56
I0903 00:08:01.929515 140006414895104 replay_runner.py:36] Average training steps per second: 323.56
I0903 00:08:02.172168 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.73
INFO:tensorflow:Starting iteration 27

Steps executed: 351 Episode length: 351 Return: -36.87099027004795586
INFO:tensorflow:Average training steps per second: 338.23
I0903 00:08:08.364028 140006414895104 replay_runner.py:36] Average training steps per second: 338.23
I0903 00:08:08.666214 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -36.87
INFO:tensorflow:Starting iteration 28

Steps executed: 218 Episode length: 218 Return: -343.5626347406034786
INFO:tensorflow:Average training steps per second: 328.13
I0903 00:08:15.100948 140006414895104 replay_runner.py:36] Average training steps per second: 328.13
I0903 00:08:15.256513 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -343.56
INFO:tensorflow:Starting iteration 29
I0903 00:08:18.556672 140006414895104 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 330.65

Steps executed: 401 Episode length: 224 Return: -1376.358667886580686

Done fixed training!Episode length: 224 Return: -1376.358667886580686