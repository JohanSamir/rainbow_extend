Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0902 23:56:02.979956 139900407642112 run_experiment.py:549] Creating TrainRunner ...
I0902 23:56:02.991476 139900407642112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:56:02.991789 139900407642112 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:56:02.991907 139900407642112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:56:02.992012 139900407642112 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:56:02.992143 139900407642112 dqn_agent.py:275] 	 update_period: 4
I0902 23:56:02.992359 139900407642112 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:56:02.992474 139900407642112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:56:02.992579 139900407642112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:56:02.992729 139900407642112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:56:02.992855 139900407642112 dqn_agent.py:280] 	 optimizer: adam
I0902 23:56:02.993004 139900407642112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:56:02.993114 139900407642112 dqn_agent.py:283] 	 seed: 1630626962991393
I0902 23:56:02.996169 139900407642112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:56:02.996401 139900407642112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:56:02.996561 139900407642112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:56:02.996823 139900407642112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:56:02.996945 139900407642112 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:56:02.997023 139900407642112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:56:02.997096 139900407642112 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:56:02.997205 139900407642112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:56:02.997366 139900407642112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:56:03.036515 139900407642112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:56:03.399044 139900407642112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:56:03.413181 139900407642112 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:56:03.421662 139900407642112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:56:03.421884 139900407642112 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:56:03.422053 139900407642112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:56:03.422129 139900407642112 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:56:03.422198 139900407642112 dqn_agent.py:275] 	 update_period: 4
I0902 23:56:03.422281 139900407642112 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:56:03.422401 139900407642112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:56:03.422501 139900407642112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:56:03.422613 139900407642112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:56:03.422902 139900407642112 dqn_agent.py:280] 	 optimizer: adam
I0902 23:56:03.423194 139900407642112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:56:03.423379 139900407642112 dqn_agent.py:283] 	 seed: 1630626963421609
I0902 23:56:03.426795 139900407642112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:56:03.427076 139900407642112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:56:03.427265 139900407642112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:56:03.427419 139900407642112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:56:03.427552 139900407642112 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:56:03.427837 139900407642112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:56:03.427992 139900407642112 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:56:03.428127 139900407642112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:56:03.428285 139900407642112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:56:03.456799 139900407642112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:56:03.519553 139900407642112 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:56:03.519867 139900407642112 replay_runner.py:41] Starting iteration 0
Steps executed: 169 Episode length: 85 Return: -340.90149922892334
INFO:tensorflow:Average training steps per second: 170.57

Steps executed: 306 Episode length: 137 Return: -383.9741337262174
I0902 23:56:10.613090 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -376.25
INFO:tensorflow:Starting iteration 1

Steps executed: 265 Episode length: 110 Return: -339.65133007459553
INFO:tensorflow:Average training steps per second: 221.99
I0902 23:56:19.382365 139900407642112 replay_runner.py:36] Average training steps per second: 221.99
I0902 23:56:19.611291 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -353.15
INFO:tensorflow:Starting iteration 2

Steps executed: 133 Episode length: 133 Return: -243.16483351710497
INFO:tensorflow:Average training steps per second: 225.13

Steps executed: 291 Episode length: 158 Return: -253.60970750508724
I0902 23:56:28.666897 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.39
INFO:tensorflow:Starting iteration 3

Steps executed: 227 Episode length: 227 Return: -312.78114746470123
INFO:tensorflow:Average training steps per second: 216.03
I0902 23:56:37.569278 139900407642112 replay_runner.py:36] Average training steps per second: 216.03
I0902 23:56:37.822949 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -312.78
INFO:tensorflow:Starting iteration 4

Steps executed: 728 Episode length: 728 Return: -480.53594608914966
INFO:tensorflow:Average training steps per second: 216.15
I0902 23:56:46.815712 139900407642112 replay_runner.py:36] Average training steps per second: 216.15
I0902 23:56:48.359198 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -480.54
INFO:tensorflow:Starting iteration 5
I0902 23:56:52.709821 139900407642112 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 228.48

Steps executed: 1000 Episode length: 1000 Return: -69.71152594797613
I0902 23:57:00.190389 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.71
INFO:tensorflow:Starting iteration 6

Steps executed: 1000 Episode length: 1000 Return: -85.81254659081095
INFO:tensorflow:Average training steps per second: 219.62
I0902 23:57:09.014985 139900407642112 replay_runner.py:36] Average training steps per second: 219.62
I0902 23:57:10.775820 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.81
INFO:tensorflow:Starting iteration 7
I0902 23:57:14.918161 139900407642112 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 222.22

Steps executed: 1000 Episode length: 1000 Return: -352.45892568531485
I0902 23:57:21.593490 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.46
INFO:tensorflow:Starting iteration 8
I0902 23:57:25.887399 139900407642112 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 226.90

Steps executed: 1000 Episode length: 1000 Return: -95.932806324227545
I0902 23:57:32.326389 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.93
INFO:tensorflow:Starting iteration 9
I0902 23:57:36.603436 139900407642112 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 230.72

Steps executed: 1000 Episode length: 1000 Return: -564.60355053469955
I0902 23:57:43.856121 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -564.60
INFO:tensorflow:Starting iteration 10
I0902 23:57:48.043074 139900407642112 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 237.22

Steps executed: 1000 Episode length: 1000 Return: -103.40929227429787
I0902 23:57:56.319889 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.41
INFO:tensorflow:Starting iteration 11
I0902 23:58:00.462659 139900407642112 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 250.52

Steps executed: 1000 Episode length: 1000 Return: -224.19784248694188
I0902 23:58:06.672114 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.20
INFO:tensorflow:Starting iteration 12

Steps executed: 396 Episode length: 396 Return: -343.3626646789189188
INFO:tensorflow:Average training steps per second: 259.82
I0902 23:58:14.598148 139900407642112 replay_runner.py:36] Average training steps per second: 259.82
I0902 23:58:15.113520 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -343.36
INFO:tensorflow:Starting iteration 13
I0902 23:58:19.223652 139900407642112 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 251.79

Steps executed: 374 Episode length: 374 Return: -66.51778680215499188
I0902 23:58:23.639453 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -66.52
INFO:tensorflow:Starting iteration 14
I0902 23:58:27.748755 139900407642112 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 255.16

Steps executed: 1000 Episode length: 1000 Return: -63.872912335390865
I0902 23:58:35.163933 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -63.87
INFO:tensorflow:Starting iteration 15

Steps executed: 361 Episode length: 188 Return: -129.8621957486339865
INFO:tensorflow:Average training steps per second: 260.88
I0902 23:58:43.001043 139900407642112 replay_runner.py:36] Average training steps per second: 260.88
I0902 23:58:43.262670 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.16
INFO:tensorflow:Starting iteration 16

Steps executed: 339 Episode length: 174 Return: -73.54363953804153865
INFO:tensorflow:Average training steps per second: 278.39
I0902 23:58:50.808396 139900407642112 replay_runner.py:36] Average training steps per second: 278.39
I0902 23:58:51.086811 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -49.71
INFO:tensorflow:Starting iteration 17

Steps executed: 243 Episode length: 124 Return: -844.2806364210801465
INFO:tensorflow:Average training steps per second: 290.69
I0902 23:58:58.413103 139900407642112 replay_runner.py:36] Average training steps per second: 290.69
I0902 23:58:58.587865 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -526.33
INFO:tensorflow:Starting iteration 18

Steps executed: 265 Episode length: 148 Return: -388.6432171660030765
INFO:tensorflow:Average training steps per second: 306.37
I0902 23:59:05.637964 139900407642112 replay_runner.py:36] Average training steps per second: 306.37
I0902 23:59:05.818655 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -422.13
INFO:tensorflow:Starting iteration 19

Steps executed: 149 Episode length: 149 Return: -224.0245713576730765
INFO:tensorflow:Average training steps per second: 290.76
I0902 23:59:12.887940 139900407642112 replay_runner.py:36] Average training steps per second: 290.76

Steps executed: 251 Episode length: 102 Return: -194.4320244480827965
INFO:tensorflow:Starting iteration 20

Steps executed: 325 Episode length: 148 Return: -294.1691429882830665
INFO:tensorflow:Average training steps per second: 298.56
I0902 23:59:19.889535 139900407642112 replay_runner.py:36] Average training steps per second: 298.56
I0902 23:59:20.065117 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.11
INFO:tensorflow:Starting iteration 21

Steps executed: 322 Episode length: 176 Return: -116.2729809415456365
INFO:tensorflow:Average training steps per second: 300.43
I0902 23:59:26.877450 139900407642112 replay_runner.py:36] Average training steps per second: 300.43
I0902 23:59:27.078677 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.73
INFO:tensorflow:Starting iteration 22

Steps executed: 277 Episode length: 170 Return: -239.9507117632058265
INFO:tensorflow:Average training steps per second: 302.97
I0902 23:59:33.832062 139900407642112 replay_runner.py:36] Average training steps per second: 302.97
I0902 23:59:34.005547 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -527.71
INFO:tensorflow:Starting iteration 23

Steps executed: 239 Episode length: 131 Return: -567.5960392572069265
INFO:tensorflow:Average training steps per second: 295.64
I0902 23:59:40.765769 139900407642112 replay_runner.py:36] Average training steps per second: 295.64
I0902 23:59:40.902524 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -770.52
INFO:tensorflow:Starting iteration 24

Steps executed: 282 Episode length: 93 Return: -23.284757451786499265
INFO:tensorflow:Average training steps per second: 311.14
I0902 23:59:47.506246 139900407642112 replay_runner.py:36] Average training steps per second: 311.14
I0902 23:59:47.666125 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -34.60
INFO:tensorflow:Starting iteration 25

Steps executed: 247 Episode length: 83 Return: -165.15210533126879265
INFO:tensorflow:Average training steps per second: 311.76
I0902 23:59:54.236665 139900407642112 replay_runner.py:36] Average training steps per second: 311.76
I0902 23:59:54.354796 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.99
INFO:tensorflow:Starting iteration 26

Steps executed: 270 Episode length: 81 Return: -213.40565055320124265
INFO:tensorflow:Average training steps per second: 302.86
I0903 00:00:00.837252 139900407642112 replay_runner.py:36] Average training steps per second: 302.86
I0903 00:00:00.995497 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -461.37
INFO:tensorflow:Starting iteration 27

Steps executed: 304 Episode length: 134 Return: -131.0953340362373865
INFO:tensorflow:Average training steps per second: 294.40
I0903 00:00:07.541521 139900407642112 replay_runner.py:36] Average training steps per second: 294.40
I0903 00:00:07.738333 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.37
INFO:tensorflow:Starting iteration 28

Steps executed: 257 Episode length: 121 Return: -80.67418796631692265
INFO:tensorflow:Average training steps per second: 308.53
I0903 00:00:14.108498 139900407642112 replay_runner.py:36] Average training steps per second: 308.53
I0903 00:00:14.257308 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.95
INFO:tensorflow:Starting iteration 29

Steps executed: 258 Episode length: 138 Return: -152.3728606520438565
INFO:tensorflow:Average training steps per second: 299.51
I0903 00:00:20.703850 139900407642112 replay_runner.py:36] Average training steps per second: 299.51

Done fixed training!Episode length: 138 Return: -152.3728606520438565