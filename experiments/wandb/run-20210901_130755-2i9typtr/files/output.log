Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0901 13:08:01.618639 139803418769408 run_experiment.py:549] Creating TrainRunner ...
I0901 13:08:01.627283 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:08:01.627419 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:08:01.627494 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:08:01.627601 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:08:01.627820 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 13:08:01.627987 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:08:01.628140 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:08:01.628237 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:08:01.628397 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:08:01.628503 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 13:08:01.628663 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:08:01.628769 139803418769408 dqn_agent.py:283] 	 seed: 1630501681627247
I0901 13:08:01.631571 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:08:01.631693 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:08:01.631782 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:08:01.631856 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:08:01.631920 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:08:01.631987 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:08:01.632063 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:08:01.632207 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:08:01.632326 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:08:01.744452 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:02.010093 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:02.018453 139803418769408 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:08:02.026050 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:08:02.026211 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:08:02.026397 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:08:02.026494 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:08:02.026822 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 13:08:02.027022 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:08:02.027185 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:08:02.027314 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:08:02.027436 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:08:02.027565 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 13:08:02.027695 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:08:02.027819 139803418769408 dqn_agent.py:283] 	 seed: 1630501682026014
I0901 13:08:02.030816 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:08:02.031004 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:08:02.031143 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:08:02.031332 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:08:02.031485 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:08:02.031638 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:08:02.031801 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:08:02.031923 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:08:02.032069 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:08:02.066271 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:02.090268 139803418769408 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:08:02.090574 139803418769408 replay_runner.py:41] Starting iteration 0
Steps executed: 110 Episode length: 110 Return: -35.62262941447675
INFO:tensorflow:Average training steps per second: 222.71

Steps executed: 259 Episode length: 149 Return: -102.5361418375002
I0901 13:08:07.327812 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.08
INFO:tensorflow:Starting iteration 1

Steps executed: 269 Episode length: 93 Return: -613.873281113510419
INFO:tensorflow:Average training steps per second: 345.42
I0901 13:08:13.551875 139803418769408 replay_runner.py:36] Average training steps per second: 345.42
I0901 13:08:13.712410 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.06
INFO:tensorflow:Starting iteration 2

Steps executed: 230 Episode length: 129 Return: -169.46373949133999
INFO:tensorflow:Average training steps per second: 355.93
I0901 13:08:19.941140 139803418769408 replay_runner.py:36] Average training steps per second: 355.93
I0901 13:08:20.072010 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -376.17
INFO:tensorflow:Starting iteration 3

Steps executed: 209 Episode length: 102 Return: -665.00873456858536
INFO:tensorflow:Average training steps per second: 341.87
I0901 13:08:26.523050 139803418769408 replay_runner.py:36] Average training steps per second: 341.87
I0901 13:08:26.639233 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -343.05
INFO:tensorflow:Starting iteration 4

Steps executed: 280 Episode length: 168 Return: 17.3888286328272736
INFO:tensorflow:Average training steps per second: 345.80
I0901 13:08:32.867088 139803418769408 replay_runner.py:36] Average training steps per second: 345.80
I0901 13:08:32.990056 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -40.40
INFO:tensorflow:Starting iteration 5

Steps executed: 265 Episode length: 126 Return: 10.0769499253482736
INFO:tensorflow:Average training steps per second: 331.65
I0901 13:08:39.066485 139803418769408 replay_runner.py:36] Average training steps per second: 331.65
I0901 13:08:39.172145 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -13.16
INFO:tensorflow:Starting iteration 6

Steps executed: 261 Episode length: 139 Return: -190.87627139554877
INFO:tensorflow:Average training steps per second: 335.02
I0901 13:08:45.347496 139803418769408 replay_runner.py:36] Average training steps per second: 335.02
I0901 13:08:45.495482 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.83
INFO:tensorflow:Starting iteration 7

Steps executed: 338 Episode length: 221 Return: -128.93634912395424
INFO:tensorflow:Average training steps per second: 325.85
I0901 13:08:51.931359 139803418769408 replay_runner.py:36] Average training steps per second: 325.85
I0901 13:08:52.109715 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.28
INFO:tensorflow:Starting iteration 8

Steps executed: 209 Episode length: 113 Return: -230.15793784185524
INFO:tensorflow:Average training steps per second: 342.74
I0901 13:08:58.419651 139803418769408 replay_runner.py:36] Average training steps per second: 342.74
I0901 13:08:58.499119 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.28
INFO:tensorflow:Starting iteration 9
I0901 13:09:01.853960 139803418769408 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 329.99

Steps executed: 698 Episode length: 698 Return: 190.053063426933564
I0901 13:09:05.737824 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: 190.05
INFO:tensorflow:Starting iteration 10

Steps executed: 254 Episode length: 140 Return: -162.70706678612726
INFO:tensorflow:Average training steps per second: 340.09
I0901 13:09:12.108071 139803418769408 replay_runner.py:36] Average training steps per second: 340.09
I0901 13:09:12.254851 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.99
INFO:tensorflow:Starting iteration 11

Steps executed: 304 Episode length: 128 Return: -14.273837334384325
INFO:tensorflow:Average training steps per second: 333.50
I0901 13:09:18.664325 139803418769408 replay_runner.py:36] Average training steps per second: 333.50
I0901 13:09:18.846592 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -36.07
INFO:tensorflow:Starting iteration 12

Steps executed: 201 Episode length: 122 Return: -165.33276306417696
INFO:tensorflow:Average training steps per second: 328.53
I0901 13:09:25.304255 139803418769408 replay_runner.py:36] Average training steps per second: 328.53
I0901 13:09:25.411779 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.84
INFO:tensorflow:Starting iteration 13
I0901 13:09:28.841685 139803418769408 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 336.35

Steps executed: 292 Episode length: 160 Return: -35.629756458744816
I0901 13:09:31.993922 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.78
INFO:tensorflow:Starting iteration 14

Steps executed: 297 Episode length: 123 Return: -108.97294155138758
INFO:tensorflow:Average training steps per second: 333.74
I0901 13:09:38.400964 139803418769408 replay_runner.py:36] Average training steps per second: 333.74
I0901 13:09:38.560198 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.84
INFO:tensorflow:Starting iteration 15

Steps executed: 246 Episode length: 71 Return: -122.396740421936098
INFO:tensorflow:Average training steps per second: 320.79
I0901 13:09:45.024391 139803418769408 replay_runner.py:36] Average training steps per second: 320.79
I0901 13:09:45.150087 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.87
INFO:tensorflow:Starting iteration 16
I0901 13:09:48.500056 139803418769408 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 324.37
I0901 13:09:51.583418 139803418769408 replay_runner.py:36] Average training steps per second: 324.37

Steps executed: 245 Episode length: 91 Return: -244.744376460659778
INFO:tensorflow:Starting iteration 17

Steps executed: 263 Episode length: 119 Return: -330.93472881375528
INFO:tensorflow:Average training steps per second: 322.24
I0901 13:09:58.157091 139803418769408 replay_runner.py:36] Average training steps per second: 322.24
I0901 13:09:58.308912 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.26
INFO:tensorflow:Starting iteration 18

Steps executed: 256 Episode length: 119 Return: -124.90767208494644
INFO:tensorflow:Average training steps per second: 324.09
I0901 13:10:04.756956 139803418769408 replay_runner.py:36] Average training steps per second: 324.09
I0901 13:10:04.909908 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.71
INFO:tensorflow:Starting iteration 19

Steps executed: 291 Episode length: 193 Return: -102.80825302705303
INFO:tensorflow:Average training steps per second: 327.22
I0901 13:10:11.304255 139803418769408 replay_runner.py:36] Average training steps per second: 327.22
I0901 13:10:11.472412 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -53.52
INFO:tensorflow:Starting iteration 20

Steps executed: 207 Episode length: 103 Return: -159.03383532608163
INFO:tensorflow:Average training steps per second: 338.37
I0901 13:10:17.779282 139803418769408 replay_runner.py:36] Average training steps per second: 338.37
I0901 13:10:17.882252 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.76
INFO:tensorflow:Starting iteration 21

Steps executed: 205 Episode length: 104 Return: -107.34042063633117
INFO:tensorflow:Average training steps per second: 336.04
I0901 13:10:24.182983 139803418769408 replay_runner.py:36] Average training steps per second: 336.04
I0901 13:10:24.284626 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.55
INFO:tensorflow:Starting iteration 22
I0901 13:10:27.653719 139803418769408 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 340.23

Steps executed: 653 Episode length: 653 Return: -570.88538889663377
I0901 13:10:31.874708 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -570.89
INFO:tensorflow:Starting iteration 23

Steps executed: 277 Episode length: 117 Return: -102.61730026498213
INFO:tensorflow:Average training steps per second: 328.20
I0901 13:10:38.228195 139803418769408 replay_runner.py:36] Average training steps per second: 328.20
I0901 13:10:38.406444 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.13
INFO:tensorflow:Starting iteration 24

Steps executed: 404 Episode length: 270 Return: 114.154857401230983
INFO:tensorflow:Average training steps per second: 331.24
I0901 13:10:44.716776 139803418769408 replay_runner.py:36] Average training steps per second: 331.24
I0901 13:10:45.032923 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: 5.53
INFO:tensorflow:Starting iteration 25

Steps executed: 208 Episode length: 208 Return: -69.143932897990423
INFO:tensorflow:Average training steps per second: 328.48
I0901 13:10:51.369697 139803418769408 replay_runner.py:36] Average training steps per second: 328.48
I0901 13:10:51.524089 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.14
INFO:tensorflow:Starting iteration 26
I0901 13:10:54.738086 139803418769408 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 329.25

Steps executed: 676 Episode length: 676 Return: 163.929030339138343
I0901 13:10:58.672390 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: 163.93
INFO:tensorflow:Starting iteration 27

Steps executed: 285 Episode length: 156 Return: -163.33299659125144
INFO:tensorflow:Average training steps per second: 316.15
I0901 13:11:04.980801 139803418769408 replay_runner.py:36] Average training steps per second: 316.15
I0901 13:11:05.160053 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.80
INFO:tensorflow:Starting iteration 28
I0901 13:11:08.197040 139803418769408 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 313.18

Steps executed: 1000 Episode length: 1000 Return: -8.132841177235203
I0901 13:11:13.540551 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -8.13
INFO:tensorflow:Starting iteration 29
I0901 13:11:16.642541 139803418769408 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 317.19

Steps executed: 1000 Episode length: 1000 Return: -85.98936564929946

Done fixed training! Episode length: 1000 Return: -85.98936564929946