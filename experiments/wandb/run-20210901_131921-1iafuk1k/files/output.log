Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0901 13:19:27.118039 139982171817984 run_experiment.py:549] Creating TrainRunner ...
I0901 13:19:27.125293 139982171817984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:19:27.125437 139982171817984 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:19:27.125613 139982171817984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:19:27.125724 139982171817984 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:19:27.125834 139982171817984 dqn_agent.py:275] 	 update_period: 4
I0901 13:19:27.125942 139982171817984 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:19:27.126016 139982171817984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:19:27.126194 139982171817984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:19:27.126377 139982171817984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:19:27.126527 139982171817984 dqn_agent.py:280] 	 optimizer: adam
I0901 13:19:27.126672 139982171817984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:19:27.126765 139982171817984 dqn_agent.py:283] 	 seed: 1630502367125240
I0901 13:19:27.129252 139982171817984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:19:27.129364 139982171817984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:19:27.129443 139982171817984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:19:27.129506 139982171817984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:19:27.129583 139982171817984 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:19:27.129663 139982171817984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:19:27.129742 139982171817984 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:19:27.129845 139982171817984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:19:27.129901 139982171817984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:19:27.159793 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:27.422894 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:27.432873 139982171817984 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:19:27.440444 139982171817984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:19:27.440602 139982171817984 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:19:27.440747 139982171817984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:19:27.440823 139982171817984 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:19:27.440910 139982171817984 dqn_agent.py:275] 	 update_period: 4
I0901 13:19:27.440983 139982171817984 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:19:27.441258 139982171817984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:19:27.441365 139982171817984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:19:27.441447 139982171817984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:19:27.441521 139982171817984 dqn_agent.py:280] 	 optimizer: adam
I0901 13:19:27.441593 139982171817984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:19:27.441663 139982171817984 dqn_agent.py:283] 	 seed: 1630502367440389
I0901 13:19:27.443210 139982171817984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:19:27.443320 139982171817984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:19:27.443425 139982171817984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:19:27.443493 139982171817984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:19:27.443550 139982171817984 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:19:27.443624 139982171817984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:19:27.443707 139982171817984 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:19:27.443769 139982171817984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:19:27.443837 139982171817984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:19:27.470818 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:27.486100 139982171817984 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:19:27.486288 139982171817984 replay_runner.py:41] Starting iteration 0
Steps executed: 278 Episode length: 132 Return: -211.0229602635289
INFO:tensorflow:Average training steps per second: 236.10
I0901 13:19:31.722083 139982171817984 replay_runner.py:36] Average training steps per second: 236.10
I0901 13:19:32.595692 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -204.54
INFO:tensorflow:Starting iteration 1

Steps executed: 288 Episode length: 138 Return: -416.57952747518886
INFO:tensorflow:Average training steps per second: 320.34
I0901 13:19:39.087324 139982171817984 replay_runner.py:36] Average training steps per second: 320.34
I0901 13:19:39.304721 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -365.16
INFO:tensorflow:Starting iteration 2

Steps executed: 396 Episode length: 396 Return: -20.600688782086735
INFO:tensorflow:Average training steps per second: 345.87
I0901 13:19:45.570951 139982171817984 replay_runner.py:36] Average training steps per second: 345.87
I0901 13:19:45.983723 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -20.60
INFO:tensorflow:Starting iteration 3

Steps executed: 256 Episode length: 188 Return: -273.45563591849657
INFO:tensorflow:Average training steps per second: 336.40
I0901 13:19:52.376318 139982171817984 replay_runner.py:36] Average training steps per second: 336.40
I0901 13:19:52.544229 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.77
INFO:tensorflow:Starting iteration 4
I0901 13:19:55.916182 139982171817984 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 320.99

Steps executed: 1000 Episode length: 1000 Return: -192.27146042415043
I0901 13:20:01.581207 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.27
INFO:tensorflow:Starting iteration 5

Steps executed: 231 Episode length: 65 Return: -247.15678425000266843
INFO:tensorflow:Average training steps per second: 332.35
I0901 13:20:07.997480 139982171817984 replay_runner.py:36] Average training steps per second: 332.35
I0901 13:20:08.131438 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.79
INFO:tensorflow:Starting iteration 6

Steps executed: 283 Episode length: 283 Return: -24.99641891340043343
INFO:tensorflow:Average training steps per second: 338.08
I0901 13:20:14.497356 139982171817984 replay_runner.py:36] Average training steps per second: 338.08
I0901 13:20:14.743673 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -25.00
INFO:tensorflow:Starting iteration 7

Steps executed: 212 Episode length: 212 Return: -157.0540328132756343
INFO:tensorflow:Average training steps per second: 338.79
I0901 13:20:21.130266 139982171817984 replay_runner.py:36] Average training steps per second: 338.79
I0901 13:20:21.296235 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -157.05
INFO:tensorflow:Starting iteration 8
I0901 13:20:24.699354 139982171817984 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 327.56

Steps executed: 1000 Episode length: 1000 Return: -292.49443802184343
I0901 13:20:29.780726 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -292.49
INFO:tensorflow:Starting iteration 9

Steps executed: 542 Episode length: 405 Return: -248.6836831038405343
INFO:tensorflow:Average training steps per second: 348.88
I0901 13:20:36.114709 139982171817984 replay_runner.py:36] Average training steps per second: 348.88
I0901 13:20:36.474355 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.80
INFO:tensorflow:Starting iteration 10
I0901 13:20:39.964497 139982171817984 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 341.19

Steps executed: 451 Episode length: 451 Return: -452.7135588384196343
I0901 13:20:43.304182 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -452.71
INFO:tensorflow:Starting iteration 11

Steps executed: 485 Episode length: 356 Return: -280.0115491323388843
INFO:tensorflow:Average training steps per second: 339.44
I0901 13:20:49.715010 139982171817984 replay_runner.py:36] Average training steps per second: 339.44
I0901 13:20:50.085841 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.72
INFO:tensorflow:Starting iteration 12
I0901 13:20:53.518573 139982171817984 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 334.85

Steps executed: 570 Episode length: 570 Return: -279.1080164706653543
I0901 13:20:57.307910 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.11
INFO:tensorflow:Starting iteration 13

Steps executed: 248 Episode length: 126 Return: -344.9535641750300743
INFO:tensorflow:Average training steps per second: 338.08
I0901 13:21:03.672235 139982171817984 replay_runner.py:36] Average training steps per second: 338.08
I0901 13:21:03.812322 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.96
INFO:tensorflow:Starting iteration 14

Steps executed: 211 Episode length: 152 Return: -188.5920203003834743
INFO:tensorflow:Average training steps per second: 322.25
I0901 13:21:10.167445 139982171817984 replay_runner.py:36] Average training steps per second: 322.25
I0901 13:21:10.308922 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.15
INFO:tensorflow:Starting iteration 15

Steps executed: 231 Episode length: 110 Return: -176.8860535102001843
INFO:tensorflow:Average training steps per second: 317.20
I0901 13:21:16.695071 139982171817984 replay_runner.py:36] Average training steps per second: 317.20
I0901 13:21:16.835611 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.66
INFO:tensorflow:Starting iteration 16

Steps executed: 172 Episode length: 172 Return: -85.95524808721034843
INFO:tensorflow:Average training steps per second: 325.81
I0901 13:21:23.232053 139982171817984 replay_runner.py:36] Average training steps per second: 325.81

Steps executed: 278 Episode length: 106 Return: -99.13720873183074843
INFO:tensorflow:Starting iteration 17

Steps executed: 206 Episode length: 81 Return: -347.94453451899284843
INFO:tensorflow:Average training steps per second: 329.74
I0901 13:21:29.804822 139982171817984 replay_runner.py:36] Average training steps per second: 329.74
I0901 13:21:29.929728 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -383.60
INFO:tensorflow:Starting iteration 18

Steps executed: 230 Episode length: 87 Return: -163.63406351999848843
INFO:tensorflow:Average training steps per second: 333.86
I0901 13:21:36.321307 139982171817984 replay_runner.py:36] Average training steps per second: 333.86
I0901 13:21:36.452664 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.26
INFO:tensorflow:Starting iteration 19

Steps executed: 282 Episode length: 148 Return: -182.0677419469596743
INFO:tensorflow:Average training steps per second: 334.67
I0901 13:21:42.882514 139982171817984 replay_runner.py:36] Average training steps per second: 334.67
I0901 13:21:43.047131 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.43
INFO:tensorflow:Starting iteration 20

Steps executed: 287 Episode length: 174 Return: -302.7512885795707743
INFO:tensorflow:Average training steps per second: 342.44
I0901 13:21:49.406432 139982171817984 replay_runner.py:36] Average training steps per second: 342.44
I0901 13:21:49.570853 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.11
INFO:tensorflow:Starting iteration 21

Steps executed: 318 Episode length: 244 Return: -248.3548456260874443
INFO:tensorflow:Average training steps per second: 356.33
I0901 13:21:55.902598 139982171817984 replay_runner.py:36] Average training steps per second: 356.33
I0901 13:21:56.134538 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -444.61
INFO:tensorflow:Starting iteration 22

Steps executed: 491 Episode length: 491 Return: -377.5500147599007443
INFO:tensorflow:Average training steps per second: 364.89
I0901 13:22:02.463729 139982171817984 replay_runner.py:36] Average training steps per second: 364.89
I0901 13:22:02.947839 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.55
INFO:tensorflow:Starting iteration 23

Steps executed: 348 Episode length: 179 Return: -107.7422932086814643
INFO:tensorflow:Average training steps per second: 368.10
I0901 13:22:09.274198 139982171817984 replay_runner.py:36] Average training steps per second: 368.10
I0901 13:22:09.459178 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.35
INFO:tensorflow:Starting iteration 24

Steps executed: 241 Episode length: 93 Return: -703.21536731185614643
INFO:tensorflow:Average training steps per second: 340.73
I0901 13:22:15.837904 139982171817984 replay_runner.py:36] Average training steps per second: 340.73
I0901 13:22:15.977139 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -408.33
INFO:tensorflow:Starting iteration 25
I0901 13:22:19.323768 139982171817984 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 331.85

Steps executed: 1000 Episode length: 1000 Return: -92.017711313166643
I0901 13:22:25.037910 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.02
INFO:tensorflow:Starting iteration 26
I0901 13:22:28.456061 139982171817984 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 343.24

Steps executed: 245 Episode length: 70 Return: -208.58550671529576643
I0901 13:22:31.500885 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -247.71
INFO:tensorflow:Starting iteration 27

Steps executed: 291 Episode length: 95 Return: -287.55452624711516643
INFO:tensorflow:Average training steps per second: 351.66
I0901 13:22:37.719507 139982171817984 replay_runner.py:36] Average training steps per second: 351.66
I0901 13:22:37.861835 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.23
INFO:tensorflow:Starting iteration 28

Steps executed: 223 Episode length: 75 Return: -38.493862717853574643
INFO:tensorflow:Average training steps per second: 373.92
I0901 13:22:44.099475 139982171817984 replay_runner.py:36] Average training steps per second: 373.92
I0901 13:22:44.233358 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -44.60
INFO:tensorflow:Starting iteration 29

Steps executed: 402 Episode length: 402 Return: -30.39366080863054343
INFO:tensorflow:Average training steps per second: 360.68
I0901 13:22:50.336947 139982171817984 replay_runner.py:36] Average training steps per second: 360.68

Done fixed training!Episode length: 402 Return: -30.39366080863054343