Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0902 23:56:02.568227 140369919707136 run_experiment.py:549] Creating TrainRunner ...
I0902 23:56:02.580402 140369919707136 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:56:02.580766 140369919707136 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:56:02.580946 140369919707136 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:56:02.581053 140369919707136 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:56:02.581214 140369919707136 dqn_agent.py:275] 	 update_period: 4
I0902 23:56:02.581393 140369919707136 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:56:02.581612 140369919707136 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:56:02.581774 140369919707136 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:56:02.581919 140369919707136 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:56:02.582036 140369919707136 dqn_agent.py:280] 	 optimizer: adam
I0902 23:56:02.582206 140369919707136 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:56:02.582311 140369919707136 dqn_agent.py:283] 	 seed: 1630626962580336
I0902 23:56:02.585582 140369919707136 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:56:02.585753 140369919707136 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:56:02.585865 140369919707136 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:56:02.585956 140369919707136 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:56:02.586063 140369919707136 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:56:02.586164 140369919707136 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:56:02.586279 140369919707136 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:56:02.586396 140369919707136 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:56:02.586518 140369919707136 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:56:02.624459 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:56:02.975097 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:56:02.991564 140369919707136 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:56:03.001267 140369919707136 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:56:03.001519 140369919707136 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:56:03.001654 140369919707136 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:56:03.001755 140369919707136 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:56:03.001858 140369919707136 dqn_agent.py:275] 	 update_period: 4
I0902 23:56:03.002078 140369919707136 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:56:03.002199 140369919707136 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:56:03.002305 140369919707136 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:56:03.002417 140369919707136 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:56:03.002614 140369919707136 dqn_agent.py:280] 	 optimizer: adam
I0902 23:56:03.002744 140369919707136 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:56:03.002854 140369919707136 dqn_agent.py:283] 	 seed: 1630626963001207
I0902 23:56:03.005284 140369919707136 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:56:03.005466 140369919707136 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:56:03.005565 140369919707136 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:56:03.005699 140369919707136 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:56:03.005817 140369919707136 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:56:03.005920 140369919707136 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:56:03.006017 140369919707136 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:56:03.006113 140369919707136 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:56:03.006203 140369919707136 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:56:03.037834 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:56:03.099702 140369919707136 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:56:03.099937 140369919707136 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 168.45
I0902 23:56:09.036518 140369919707136 replay_runner.py:36] Average training steps per second: 168.45
Steps executed: 246 Episode length: 103 Return: -415.8531431186718
I0902 23:56:10.223662 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -484.45
INFO:tensorflow:Starting iteration 1

Steps executed: 293 Episode length: 156 Return: -290.5942760450083
INFO:tensorflow:Average training steps per second: 235.12
I0902 23:56:18.895845 140369919707136 replay_runner.py:36] Average training steps per second: 235.12
I0902 23:56:19.172339 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -403.34
INFO:tensorflow:Starting iteration 2

Steps executed: 298 Episode length: 120 Return: -98.14769247116343
INFO:tensorflow:Average training steps per second: 225.09
I0902 23:56:27.919869 140369919707136 replay_runner.py:36] Average training steps per second: 225.09
I0902 23:56:28.178267 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.52
INFO:tensorflow:Starting iteration 3

Steps executed: 281 Episode length: 281 Return: -253.52235168383817
INFO:tensorflow:Average training steps per second: 217.91
I0902 23:56:37.089812 140369919707136 replay_runner.py:36] Average training steps per second: 217.91
I0902 23:56:37.454953 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.52
INFO:tensorflow:Starting iteration 4
I0902 23:56:41.661481 140369919707136 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 212.84

Steps executed: 1000 Episode length: 1000 Return: -134.23836332671348
I0902 23:56:49.211317 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.24
INFO:tensorflow:Starting iteration 5
I0902 23:56:53.389168 140369919707136 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 226.85

Steps executed: 999 Episode length: 999 Return: -567.7527109933104348
I0902 23:56:59.872015 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -567.75
INFO:tensorflow:Starting iteration 6
I0902 23:57:04.152338 140369919707136 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 223.97

Steps executed: 1000 Episode length: 1000 Return: -61.575653435849134
I0902 23:57:11.952169 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.58
INFO:tensorflow:Starting iteration 7

Steps executed: 380 Episode length: 237 Return: -264.7478352222741534
INFO:tensorflow:Average training steps per second: 226.28
I0902 23:57:20.652904 140369919707136 replay_runner.py:36] Average training steps per second: 226.28
I0902 23:57:21.042988 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -391.70
INFO:tensorflow:Starting iteration 8
I0902 23:57:25.301149 140369919707136 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 227.10

Steps executed: 1000 Episode length: 1000 Return: -400.65548653982394
I0902 23:57:32.733784 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.66
INFO:tensorflow:Starting iteration 9

Steps executed: 353 Episode length: 353 Return: -325.7498554204825394
INFO:tensorflow:Average training steps per second: 230.56
I0902 23:57:41.346761 140369919707136 replay_runner.py:36] Average training steps per second: 230.56
I0902 23:57:41.943560 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.75
INFO:tensorflow:Starting iteration 10
I0902 23:57:46.184221 140369919707136 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 231.36

Steps executed: 381 Episode length: 381 Return: -285.3753546765024794
I0902 23:57:51.119205 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.38
INFO:tensorflow:Starting iteration 11

Steps executed: 336 Episode length: 336 Return: -283.2370864128353794
INFO:tensorflow:Average training steps per second: 242.38
I0902 23:57:59.444408 140369919707136 replay_runner.py:36] Average training steps per second: 242.38
I0902 23:57:59.878712 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.24
INFO:tensorflow:Starting iteration 12
I0902 23:58:03.905393 140369919707136 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 248.11

Steps executed: 1000 Episode length: 1000 Return: -229.67904362656793
I0902 23:58:11.393031 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.68
INFO:tensorflow:Starting iteration 13
I0902 23:58:15.434994 140369919707136 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 249.55

Steps executed: 1000 Episode length: 1000 Return: -141.00874748404263
I0902 23:58:21.809267 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.01
INFO:tensorflow:Starting iteration 14
I0902 23:58:25.909715 140369919707136 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 254.78

Steps executed: 1000 Episode length: 1000 Return: -162.19377698495583
I0902 23:58:31.539416 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.19
INFO:tensorflow:Starting iteration 15

Steps executed: 296 Episode length: 296 Return: -233.8180732955813483
INFO:tensorflow:Average training steps per second: 259.98
I0902 23:58:39.470667 140369919707136 replay_runner.py:36] Average training steps per second: 259.98
I0902 23:58:39.809255 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.82
INFO:tensorflow:Starting iteration 16

Steps executed: 297 Episode length: 157 Return: -570.9520022597011483
INFO:tensorflow:Average training steps per second: 267.54
I0902 23:58:47.545770 140369919707136 replay_runner.py:36] Average training steps per second: 267.54
I0902 23:58:47.785316 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -607.49
INFO:tensorflow:Starting iteration 17

Steps executed: 333 Episode length: 333 Return: -173.3058110073001883
INFO:tensorflow:Average training steps per second: 270.82
I0902 23:58:55.336941 140369919707136 replay_runner.py:36] Average training steps per second: 270.82
I0902 23:58:55.750807 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.31
INFO:tensorflow:Starting iteration 18
I0902 23:58:59.482522 140369919707136 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 284.04
I0902 23:59:03.003548 140369919707136 replay_runner.py:36] Average training steps per second: 284.04

Steps executed: 1000 Episode length: 1000 Return: -39.084879002021143
INFO:tensorflow:Starting iteration 19

Steps executed: 262 Episode length: 262 Return: -90.39671579225032143
INFO:tensorflow:Average training steps per second: 282.96
I0902 23:59:11.914783 140369919707136 replay_runner.py:36] Average training steps per second: 282.96
I0902 23:59:12.151613 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.40
INFO:tensorflow:Starting iteration 20
I0902 23:59:15.598029 140369919707136 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 292.29
I0902 23:59:19.019658 140369919707136 replay_runner.py:36] Average training steps per second: 292.29

Steps executed: 212 Episode length: 212 Return: -204.4471978203030543
INFO:tensorflow:Starting iteration 21

Steps executed: 365 Episode length: 223 Return: -306.3679958753017443
INFO:tensorflow:Average training steps per second: 295.99
I0902 23:59:25.973040 140369919707136 replay_runner.py:36] Average training steps per second: 295.99
I0902 23:59:26.269221 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.35
INFO:tensorflow:Starting iteration 22

Steps executed: 327 Episode length: 327 Return: -366.0281964152149443
INFO:tensorflow:Average training steps per second: 298.68
I0902 23:59:32.981665 140369919707136 replay_runner.py:36] Average training steps per second: 298.68
I0902 23:59:33.331000 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -366.03
INFO:tensorflow:Starting iteration 23

Steps executed: 207 Episode length: 82 Return: -492.85913648579675443
INFO:tensorflow:Average training steps per second: 302.70
I0902 23:59:39.958414 140369919707136 replay_runner.py:36] Average training steps per second: 302.70
I0902 23:59:40.106085 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -467.34
INFO:tensorflow:Starting iteration 24

Steps executed: 182 Episode length: 182 Return: -68.63829572116201443
INFO:tensorflow:Average training steps per second: 304.67

Steps executed: 331 Episode length: 149 Return: -131.2442915758851443
I0902 23:59:47.019500 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.94
INFO:tensorflow:Starting iteration 25

Steps executed: 394 Episode length: 394 Return: -12.52941104410834343
INFO:tensorflow:Average training steps per second: 311.63
I0902 23:59:53.567994 140369919707136 replay_runner.py:36] Average training steps per second: 311.63
I0902 23:59:54.091780 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -12.53
INFO:tensorflow:Starting iteration 26

Steps executed: 295 Episode length: 151 Return: -148.3546344810103443
INFO:tensorflow:Average training steps per second: 301.85
I0903 00:00:00.593953 140369919707136 replay_runner.py:36] Average training steps per second: 301.85
I0903 00:00:00.787440 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.79
INFO:tensorflow:Starting iteration 27

Steps executed: 403 Episode length: 275 Return: -8.515355765998606443
INFO:tensorflow:Average training steps per second: 297.84
I0903 00:00:07.284760 140369919707136 replay_runner.py:36] Average training steps per second: 297.84
I0903 00:00:07.607028 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.00
INFO:tensorflow:Starting iteration 28

Steps executed: 275 Episode length: 144 Return: -292.1740810032221643
INFO:tensorflow:Average training steps per second: 319.69
I0903 00:00:13.840908 140369919707136 replay_runner.py:36] Average training steps per second: 319.69
I0903 00:00:14.003937 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.81
INFO:tensorflow:Starting iteration 29

Steps executed: 301 Episode length: 124 Return: -137.1597248935737843
INFO:tensorflow:Average training steps per second: 302.77
I0903 00:00:20.423235 140369919707136 replay_runner.py:36] Average training steps per second: 302.77

Done fixed training!Episode length: 124 Return: -137.1597248935737843