I0902 23:24:57.010809 140457530894336 run_experiment.py:549] Creating TrainRunner ...
I0902 23:24:57.022687 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:24:57.023142 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:24:57.023318 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:24:57.023443 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:24:57.023568 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0902 23:24:57.023683 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:24:57.023854 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:24:57.023976 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:24:57.024096 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:24:57.024388 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0902 23:24:57.024550 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:24:57.024705 140457530894336 dqn_agent.py:283] 	 seed: 1630625097022616
I0902 23:24:57.028089 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:24:57.028305 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:24:57.028485 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:24:57.028618 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:24:57.028753 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:24:57.028877 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:24:57.029035 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:24:57.029186 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:24:57.029296 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0902 23:24:58.599566 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:24:58.946502 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:24:58.959550 140457530894336 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:24:58.969100 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:24:58.969336 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:24:58.969463 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:24:58.969570 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:24:58.969747 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0902 23:24:58.969834 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:24:58.969985 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:24:58.970061 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:24:58.970209 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:24:58.970352 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0902 23:24:58.970456 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:24:58.970556 140457530894336 dqn_agent.py:283] 	 seed: 1630625098969038
I0902 23:24:58.972154 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:24:58.972283 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:24:58.972370 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:24:58.972436 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:24:58.972494 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:24:58.972565 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:24:58.972638 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:24:58.972714 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:24:58.972776 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:24:59.015275 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:24:59.060337 140457530894336 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:24:59.060603 140457530894336 replay_runner.py:41] Starting iteration 0
Steps executed: 225 Episode length: 92 Return: -245.175116616586765
INFO:tensorflow:Average training steps per second: 161.39
I0902 23:25:05.257191 140457530894336 replay_runner.py:36] Average training steps per second: 161.39
I0902 23:25:06.470560 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.70
INFO:tensorflow:Starting iteration 1

Steps executed: 329 Episode length: 149 Return: -388.45797117774725
INFO:tensorflow:Average training steps per second: 231.92
I0902 23:25:15.054916 140457530894336 replay_runner.py:36] Average training steps per second: 231.92
I0902 23:25:15.356971 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -403.54
INFO:tensorflow:Starting iteration 2

Steps executed: 302 Episode length: 128 Return: -269.18651652221345
INFO:tensorflow:Average training steps per second: 230.23
I0902 23:25:24.083389 140457530894336 replay_runner.py:36] Average training steps per second: 230.23
I0902 23:25:24.355984 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.31
INFO:tensorflow:Starting iteration 3

Steps executed: 265 Episode length: 265 Return: -259.04552753055003
INFO:tensorflow:Average training steps per second: 226.31
I0902 23:25:33.055743 140457530894336 replay_runner.py:36] Average training steps per second: 226.31
I0902 23:25:33.392204 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.05
INFO:tensorflow:Starting iteration 4
I0902 23:25:37.711865 140457530894336 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 236.37

Steps executed: 1000 Episode length: 1000 Return: -107.36321072691702
I0902 23:25:45.982882 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.36
INFO:tensorflow:Starting iteration 5
I0902 23:25:50.191308 140457530894336 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 224.49

Steps executed: 1000 Episode length: 1000 Return: -185.39616010203994
I0902 23:25:57.591197 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.40
INFO:tensorflow:Starting iteration 6
I0902 23:26:01.950796 140457530894336 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 225.02

Steps executed: 1000 Episode length: 1000 Return: -125.81548879246864
I0902 23:26:09.205898 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.82
INFO:tensorflow:Starting iteration 7

Steps executed: 534 Episode length: 534 Return: -1448.499965116129564
INFO:tensorflow:Average training steps per second: 224.58
I0902 23:26:18.067748 140457530894336 replay_runner.py:36] Average training steps per second: 224.58
I0902 23:26:18.922948 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -1448.50
INFO:tensorflow:Starting iteration 8
I0902 23:26:23.314736 140457530894336 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 233.13

Steps executed: 1000 Episode length: 1000 Return: -264.00577091775564
I0902 23:26:30.099755 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -264.01
INFO:tensorflow:Starting iteration 9

Steps executed: 249 Episode length: 249 Return: -234.6376329251346864
INFO:tensorflow:Average training steps per second: 227.44
I0902 23:26:38.920399 140457530894336 replay_runner.py:36] Average training steps per second: 227.44
I0902 23:26:39.191562 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.64
INFO:tensorflow:Starting iteration 10
I0902 23:26:43.618364 140457530894336 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 224.42

Steps executed: 1000 Episode length: 1000 Return: -321.00903496926884
I0902 23:26:50.173398 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -321.01
INFO:tensorflow:Starting iteration 11
I0902 23:26:54.603739 140457530894336 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 220.97

Steps executed: 383 Episode length: 383 Return: -496.4167408907165884
I0902 23:26:59.750351 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -496.42
INFO:tensorflow:Starting iteration 12

Steps executed: 106 Episode length: 106 Return: -166.8328007794569684
INFO:tensorflow:Average training steps per second: 216.33
I0902 23:27:08.705491 140457530894336 replay_runner.py:36] Average training steps per second: 216.33

Steps executed: 409 Episode length: 303 Return: -104.6090787099351884
INFO:tensorflow:Starting iteration 13
I0902 23:27:13.452599 140457530894336 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 215.61

Steps executed: 1000 Episode length: 1000 Return: -199.08153830652924
I0902 23:27:20.666496 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.08
INFO:tensorflow:Starting iteration 14
I0902 23:27:24.995426 140457530894336 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 221.98

Steps executed: 1000 Episode length: 1000 Return: -192.01738248436976
I0902 23:27:32.594407 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.02
INFO:tensorflow:Starting iteration 15

Steps executed: 347 Episode length: 347 Return: -231.2185775927886276
INFO:tensorflow:Average training steps per second: 214.79
I0902 23:27:41.581555 140457530894336 replay_runner.py:36] Average training steps per second: 214.79
I0902 23:27:42.013753 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.22
INFO:tensorflow:Starting iteration 16
I0902 23:27:46.255809 140457530894336 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 235.02

Steps executed: 1000 Episode length: 1000 Return: -112.70688451940792
I0902 23:27:52.889879 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.71
INFO:tensorflow:Starting iteration 17
I0902 23:27:57.188502 140457530894336 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 230.98

Steps executed: 284 Episode length: 201 Return: -260.8253170649734392
I0902 23:28:01.779340 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.01
INFO:tensorflow:Starting iteration 18

Steps executed: 259 Episode length: 259 Return: -554.5277070832567392
INFO:tensorflow:Average training steps per second: 226.13
I0902 23:28:10.556936 140457530894336 replay_runner.py:36] Average training steps per second: 226.13
I0902 23:28:10.840205 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -554.53
INFO:tensorflow:Starting iteration 19

Steps executed: 417 Episode length: 292 Return: -210.5456583298353692
INFO:tensorflow:Average training steps per second: 238.25
I0902 23:28:19.416341 140457530894336 replay_runner.py:36] Average training steps per second: 238.25
I0902 23:28:19.823439 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.65
INFO:tensorflow:Starting iteration 20

Steps executed: 96 Episode length: 96 Return: -51.7848877961727353692
INFO:tensorflow:Average training steps per second: 235.01

Steps executed: 654 Episode length: 558 Return: -27.46329005494034492
I0902 23:28:30.082995 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -39.62
INFO:tensorflow:Starting iteration 21

Steps executed: 286 Episode length: 101 Return: -102.0862472905111292
INFO:tensorflow:Average training steps per second: 227.54
I0902 23:28:38.878174 140457530894336 replay_runner.py:36] Average training steps per second: 227.54
I0902 23:28:39.139860 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.09
INFO:tensorflow:Starting iteration 22

Steps executed: 329 Episode length: 136 Return: -21.44590173833459892
INFO:tensorflow:Average training steps per second: 221.13
I0902 23:28:48.104604 140457530894336 replay_runner.py:36] Average training steps per second: 221.13
I0902 23:28:48.387169 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.60
INFO:tensorflow:Starting iteration 23

Steps executed: 134 Episode length: 134 Return: -97.06175532987497892
INFO:tensorflow:Average training steps per second: 219.05

Steps executed: 248 Episode length: 114 Return: -147.3030241022088492
I0902 23:28:57.430902 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.18
INFO:tensorflow:Starting iteration 24
I0902 23:29:01.756853 140457530894336 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 219.76

Steps executed: 1000 Episode length: 1000 Return: 67.7035483054265292
I0902 23:29:10.391702 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: 67.70
INFO:tensorflow:Starting iteration 25

Steps executed: 61 Episode length: 61 Return: -150.316500027027965292
INFO:tensorflow:Average training steps per second: 221.35

Steps executed: 284 Episode length: 135 Return: -73.81084462656571292
I0902 23:29:19.585479 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.59
INFO:tensorflow:Starting iteration 26

Steps executed: 308 Episode length: 308 Return: -325.8683717830273292
INFO:tensorflow:Average training steps per second: 220.35
I0902 23:29:28.508766 140457530894336 replay_runner.py:36] Average training steps per second: 220.35
I0902 23:29:28.943888 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.87
INFO:tensorflow:Starting iteration 27

Steps executed: 305 Episode length: 305 Return: -67.49380962703104292
INFO:tensorflow:Average training steps per second: 220.52
I0902 23:29:37.850006 140457530894336 replay_runner.py:36] Average training steps per second: 220.52
I0902 23:29:38.201378 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -67.49
INFO:tensorflow:Starting iteration 28

Steps executed: 261 Episode length: 123 Return: -102.7431551747608992
INFO:tensorflow:Average training steps per second: 226.27
I0902 23:29:47.033695 140457530894336 replay_runner.py:36] Average training steps per second: 226.27
I0902 23:29:47.255238 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.47
INFO:tensorflow:Starting iteration 29

Steps executed: 299 Episode length: 140 Return: -162.3640409610226592
INFO:tensorflow:Average training steps per second: 230.71
I0902 23:29:55.957674 140457530894336 replay_runner.py:36] Average training steps per second: 230.71

Done fixed training!Episode length: 140 Return: -162.3640409610226592