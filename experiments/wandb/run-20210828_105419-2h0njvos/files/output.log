I0828 10:54:25.436879 140251198892032 run_experiment.py:549] Creating TrainRunner ...
I0828 10:54:25.444433 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:54:25.444572 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:54:25.444646 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:54:25.444709 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:54:25.444787 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:54:25.444880 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:54:25.444972 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:54:25.445038 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:54:25.445103 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:54:25.445176 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:54:25.445249 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:54:25.445300 140251198892032 dqn_agent.py:283] 	 seed: 1630148065444398
I0828 10:54:25.447124 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:54:25.447254 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:54:25.447347 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:54:25.447417 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:54:25.447480 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:54:25.447565 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:54:25.447696 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:54:25.447823 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:54:25.447896 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:54:25.472840 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:25.728990 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:25.738506 140251198892032 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:54:25.745447 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:54:25.745598 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:54:25.745703 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:54:25.745785 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:54:25.745860 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:54:25.745938 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:54:25.745994 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:54:25.746045 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:54:25.746096 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:54:25.746160 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:54:25.746211 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:54:25.746262 140251198892032 dqn_agent.py:283] 	 seed: 1630148065745415
I0828 10:54:25.748547 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:54:25.748729 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:54:25.748862 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:54:25.748987 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:54:25.749141 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:54:25.749310 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:54:25.749509 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:54:25.749672 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:54:25.749758 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:54:25.770809 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:25.786088 140251198892032 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:54:25.786237 140251198892032 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 242.57
I0828 10:54:29.908880 140251198892032 replay_runner.py:36] Average training steps per second: 242.57
I0828 10:54:30.698908 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -602.06
Steps executed: 242 Episode length: 70 Return: -642.0255160296149
INFO:tensorflow:Starting iteration 1

Steps executed: 256 Episode length: 83 Return: -459.18980786449931
INFO:tensorflow:Average training steps per second: 320.29
I0828 10:54:37.105813 140251198892032 replay_runner.py:36] Average training steps per second: 320.29
I0828 10:54:37.251154 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -575.14
INFO:tensorflow:Starting iteration 2

Steps executed: 229 Episode length: 121 Return: -342.68047984341786
INFO:tensorflow:Average training steps per second: 313.60
I0828 10:54:43.696355 140251198892032 replay_runner.py:36] Average training steps per second: 313.60
I0828 10:54:43.839460 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -489.26
INFO:tensorflow:Starting iteration 3

Steps executed: 279 Episode length: 103 Return: -297.62103780185896
INFO:tensorflow:Average training steps per second: 325.60
I0828 10:54:50.066314 140251198892032 replay_runner.py:36] Average training steps per second: 325.60
I0828 10:54:50.250555 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -530.92
INFO:tensorflow:Starting iteration 4

Steps executed: 295 Episode length: 144 Return: -382.44075138273723
INFO:tensorflow:Average training steps per second: 317.36
I0828 10:54:56.600425 140251198892032 replay_runner.py:36] Average training steps per second: 317.36
I0828 10:54:56.791277 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -446.58
INFO:tensorflow:Starting iteration 5
I0828 10:55:00.055795 140251198892032 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 312.52

Steps executed: 208 Episode length: 208 Return: -651.37657498578933
I0828 10:55:03.415792 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -651.38
INFO:tensorflow:Starting iteration 6

Steps executed: 303 Episode length: 202 Return: -154.59741191127665
INFO:tensorflow:Average training steps per second: 318.82
I0828 10:55:09.769395 140251198892032 replay_runner.py:36] Average training steps per second: 318.82
I0828 10:55:09.992217 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -431.48
INFO:tensorflow:Starting iteration 7

Steps executed: 278 Episode length: 183 Return: -486.96171893818535
INFO:tensorflow:Average training steps per second: 314.52
I0828 10:55:16.393849 140251198892032 replay_runner.py:36] Average training steps per second: 314.52
I0828 10:55:16.575349 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -354.06
INFO:tensorflow:Starting iteration 8

Steps executed: 437 Episode length: 252 Return: -447.65236563994915
INFO:tensorflow:Average training steps per second: 314.10
I0828 10:55:22.949257 140251198892032 replay_runner.py:36] Average training steps per second: 314.10
I0828 10:55:23.280080 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -373.21
INFO:tensorflow:Starting iteration 9

Steps executed: 390 Episode length: 191 Return: -81.085038567294535
INFO:tensorflow:Average training steps per second: 309.10
I0828 10:55:29.707760 140251198892032 replay_runner.py:36] Average training steps per second: 309.10
I0828 10:55:30.024427 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.43
INFO:tensorflow:Starting iteration 10

Steps executed: 238 Episode length: 238 Return: -16.232110645996997
INFO:tensorflow:Average training steps per second: 308.38
I0828 10:55:36.448017 140251198892032 replay_runner.py:36] Average training steps per second: 308.38
I0828 10:55:36.631335 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -16.23
INFO:tensorflow:Starting iteration 11

Steps executed: 357 Episode length: 167 Return: -360.12088534656997
INFO:tensorflow:Average training steps per second: 313.14
I0828 10:55:42.992937 140251198892032 replay_runner.py:36] Average training steps per second: 313.14
I0828 10:55:43.211786 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.86
INFO:tensorflow:Starting iteration 12

Steps executed: 240 Episode length: 240 Return: -51.676827662827647
INFO:tensorflow:Average training steps per second: 307.65
I0828 10:55:49.621942 140251198892032 replay_runner.py:36] Average training steps per second: 307.65
I0828 10:55:49.794492 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -51.68
INFO:tensorflow:Starting iteration 13

Steps executed: 372 Episode length: 194 Return: -111.56751014275402
INFO:tensorflow:Average training steps per second: 310.19
I0828 10:55:56.195948 140251198892032 replay_runner.py:36] Average training steps per second: 310.19
I0828 10:55:56.432265 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.11
INFO:tensorflow:Starting iteration 14

Steps executed: 278 Episode length: 142 Return: -19.947990241771862
INFO:tensorflow:Average training steps per second: 304.86
I0828 10:56:02.928295 140251198892032 replay_runner.py:36] Average training steps per second: 304.86
I0828 10:56:03.092905 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.70
INFO:tensorflow:Starting iteration 15

Steps executed: 302 Episode length: 157 Return: -233.60579694466352
INFO:tensorflow:Average training steps per second: 306.48
I0828 10:56:09.513592 140251198892032 replay_runner.py:36] Average training steps per second: 306.48
I0828 10:56:09.690865 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.03
INFO:tensorflow:Starting iteration 16

Steps executed: 326 Episode length: 151 Return: -13.388638957183844
INFO:tensorflow:Average training steps per second: 312.89
I0828 10:56:16.074858 140251198892032 replay_runner.py:36] Average training steps per second: 312.89
I0828 10:56:16.288075 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -28.55
INFO:tensorflow:Starting iteration 17

Steps executed: 300 Episode length: 130 Return: -70.916015725027254
INFO:tensorflow:Average training steps per second: 298.17
I0828 10:56:22.886294 140251198892032 replay_runner.py:36] Average training steps per second: 298.17
I0828 10:56:23.061512 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.98
INFO:tensorflow:Starting iteration 18

Steps executed: 269 Episode length: 134 Return: -223.64943237034953
INFO:tensorflow:Average training steps per second: 316.71
I0828 10:56:29.425502 140251198892032 replay_runner.py:36] Average training steps per second: 316.71
I0828 10:56:29.584155 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.91
INFO:tensorflow:Starting iteration 19

Steps executed: 255 Episode length: 118 Return: -105.82674322382167
INFO:tensorflow:Average training steps per second: 318.77
I0828 10:56:35.913504 140251198892032 replay_runner.py:36] Average training steps per second: 318.77
I0828 10:56:36.058445 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.73
INFO:tensorflow:Starting iteration 20

Steps executed: 324 Episode length: 204 Return: -18.421075162991613
INFO:tensorflow:Average training steps per second: 316.33
I0828 10:56:42.545588 140251198892032 replay_runner.py:36] Average training steps per second: 316.33
I0828 10:56:42.734890 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.30
INFO:tensorflow:Starting iteration 21

Steps executed: 340 Episode length: 236 Return: -1.4991360070087438
INFO:tensorflow:Average training steps per second: 310.18
I0828 10:56:49.176292 140251198892032 replay_runner.py:36] Average training steps per second: 310.18
I0828 10:56:49.404119 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.44
INFO:tensorflow:Starting iteration 22

Steps executed: 350 Episode length: 176 Return: -44.215584869093924
INFO:tensorflow:Average training steps per second: 322.44
I0828 10:56:55.775371 140251198892032 replay_runner.py:36] Average training steps per second: 322.44
I0828 10:56:55.993900 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.11
INFO:tensorflow:Starting iteration 23

Steps executed: 325 Episode length: 194 Return: -43.650288862821586
INFO:tensorflow:Average training steps per second: 316.95
I0828 10:57:02.414279 140251198892032 replay_runner.py:36] Average training steps per second: 316.95
I0828 10:57:02.604724 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.13
INFO:tensorflow:Starting iteration 24

Steps executed: 258 Episode length: 132 Return: -174.48331280973014
INFO:tensorflow:Average training steps per second: 322.46
I0828 10:57:08.994993 140251198892032 replay_runner.py:36] Average training steps per second: 322.46
I0828 10:57:09.132347 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.41
INFO:tensorflow:Starting iteration 25

Steps executed: 201 Episode length: 201 Return: -107.27085917474888
INFO:tensorflow:Average training steps per second: 322.17
I0828 10:57:15.540673 140251198892032 replay_runner.py:36] Average training steps per second: 322.17
I0828 10:57:15.658051 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.27
INFO:tensorflow:Starting iteration 26

Steps executed: 253 Episode length: 129 Return: -203.57401849405264
INFO:tensorflow:Average training steps per second: 326.68
I0828 10:57:21.997421 140251198892032 replay_runner.py:36] Average training steps per second: 326.68
I0828 10:57:22.131361 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.04
INFO:tensorflow:Starting iteration 27

Steps executed: 248 Episode length: 144 Return: -260.16434465622837
INFO:tensorflow:Average training steps per second: 340.49
I0828 10:57:28.207203 140251198892032 replay_runner.py:36] Average training steps per second: 340.49
I0828 10:57:28.345517 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.26
INFO:tensorflow:Starting iteration 28

Steps executed: 213 Episode length: 84 Return: -424.169157265714945
INFO:tensorflow:Average training steps per second: 358.01
I0828 10:57:34.298058 140251198892032 replay_runner.py:36] Average training steps per second: 358.01
I0828 10:57:34.409482 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -350.30
INFO:tensorflow:Starting iteration 29

Steps executed: 361 Episode length: 232 Return: -273.00302389019795
INFO:tensorflow:Average training steps per second: 354.28
I0828 10:57:40.250372 140251198892032 replay_runner.py:36] Average training steps per second: 354.28

Done fixed training!Episode length: 232 Return: -273.00302389019795