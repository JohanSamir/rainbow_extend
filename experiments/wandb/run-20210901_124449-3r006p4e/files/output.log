Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0901 12:44:56.647583 139803418769408 run_experiment.py:549] Creating TrainRunner ...
I0901 12:44:56.659079 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:44:56.659450 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:44:56.659692 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:44:56.659819 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:44:56.659946 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 12:44:56.660209 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:44:56.660385 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:44:56.660536 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:44:56.660661 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:44:56.660848 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 12:44:56.660936 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:44:56.661005 139803418769408 dqn_agent.py:283] 	 seed: 1630500296659018
I0901 12:44:56.664395 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:44:56.664591 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:44:56.664734 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:44:56.664866 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:44:56.665008 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:44:56.665157 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:44:56.665302 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:44:56.665378 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:44:56.665508 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:44:56.707106 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:44:57.121123 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:44:57.158092 139803418769408 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:44:57.168582 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:44:57.168905 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:44:57.169054 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:44:57.169352 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:44:57.169829 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 12:44:57.170026 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:44:57.170213 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:44:57.170450 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:44:57.170577 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:44:57.170784 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 12:44:57.170910 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:44:57.171021 139803418769408 dqn_agent.py:283] 	 seed: 1630500297168515
I0901 12:44:57.174133 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:44:57.174360 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:44:57.174645 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:44:57.174846 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:44:57.174975 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:44:57.175150 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:44:57.175389 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:44:57.175571 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:44:57.175817 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:44:57.211850 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:44:57.233675 139803418769408 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:44:57.233948 139803418769408 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 153.86
I0901 12:45:03.733983 139803418769408 replay_runner.py:36] Average training steps per second: 153.86
Steps executed: 220 Episode length: 91 Return: -338.15342883533395
I0901 12:45:04.962986 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.62
INFO:tensorflow:Starting iteration 1

Steps executed: 254 Episode length: 160 Return: -57.63084985261206
INFO:tensorflow:Average training steps per second: 217.98
I0901 12:45:13.938396 139803418769408 replay_runner.py:36] Average training steps per second: 217.98
I0901 12:45:14.164144 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.93
INFO:tensorflow:Starting iteration 2

Steps executed: 251 Episode length: 113 Return: -317.13202413538636
INFO:tensorflow:Average training steps per second: 207.79
I0901 12:45:23.339175 139803418769408 replay_runner.py:36] Average training steps per second: 207.79
I0901 12:45:23.582758 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.99
INFO:tensorflow:Starting iteration 3

Steps executed: 205 Episode length: 118 Return: -283.75017810339236
INFO:tensorflow:Average training steps per second: 216.44
I0901 12:45:32.457775 139803418769408 replay_runner.py:36] Average training steps per second: 216.44
I0901 12:45:32.634498 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.48
INFO:tensorflow:Starting iteration 4

Steps executed: 253 Episode length: 126 Return: -177.03541917808997
INFO:tensorflow:Average training steps per second: 223.02
I0901 12:45:41.573059 139803418769408 replay_runner.py:36] Average training steps per second: 223.02
I0901 12:45:41.790879 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.47
INFO:tensorflow:Starting iteration 5

Steps executed: 222 Episode length: 133 Return: -25.131828888429317
INFO:tensorflow:Average training steps per second: 211.79
I0901 12:45:50.915987 139803418769408 replay_runner.py:36] Average training steps per second: 211.79
I0901 12:45:51.105564 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -157.90
INFO:tensorflow:Starting iteration 6

Steps executed: 180 Episode length: 180 Return: -270.68466462137277
INFO:tensorflow:Average training steps per second: 212.09
I0901 12:46:00.226927 139803418769408 replay_runner.py:36] Average training steps per second: 212.09

Steps executed: 322 Episode length: 142 Return: -240.04590854155377
INFO:tensorflow:Starting iteration 7

Steps executed: 316 Episode length: 164 Return: -310.59303612740456
INFO:tensorflow:Average training steps per second: 216.88
I0901 12:46:09.584699 139803418769408 replay_runner.py:36] Average training steps per second: 216.88
I0901 12:46:09.898141 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.07
INFO:tensorflow:Starting iteration 8

Steps executed: 299 Episode length: 118 Return: -143.07794799180356
INFO:tensorflow:Average training steps per second: 223.13
I0901 12:46:18.817153 139803418769408 replay_runner.py:36] Average training steps per second: 223.13
I0901 12:46:19.065397 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.85
INFO:tensorflow:Starting iteration 9

Steps executed: 309 Episode length: 218 Return: -240.50904653529687
INFO:tensorflow:Average training steps per second: 220.94
I0901 12:46:27.897489 139803418769408 replay_runner.py:36] Average training steps per second: 220.94
I0901 12:46:28.185063 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -286.55
INFO:tensorflow:Starting iteration 10

Steps executed: 268 Episode length: 268 Return: -199.50814237356267
INFO:tensorflow:Average training steps per second: 223.49
I0901 12:46:37.115389 139803418769408 replay_runner.py:36] Average training steps per second: 223.49
I0901 12:46:37.456618 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.51
INFO:tensorflow:Starting iteration 11

Steps executed: 110 Episode length: 110 Return: -476.20454157137267
INFO:tensorflow:Average training steps per second: 217.61

Steps executed: 510 Episode length: 400 Return: -424.55100693427477
I0901 12:46:47.066084 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -450.38
INFO:tensorflow:Starting iteration 12

Steps executed: 213 Episode length: 107 Return: -149.35170462323938
INFO:tensorflow:Average training steps per second: 218.06
I0901 12:46:56.057079 139803418769408 replay_runner.py:36] Average training steps per second: 218.06
I0901 12:46:56.223028 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.71
INFO:tensorflow:Starting iteration 13

Steps executed: 203 Episode length: 133 Return: -98.493496223883978
INFO:tensorflow:Average training steps per second: 219.25
I0901 12:47:05.060300 139803418769408 replay_runner.py:36] Average training steps per second: 219.25
I0901 12:47:05.220676 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.33
INFO:tensorflow:Starting iteration 14

Steps executed: 290 Episode length: 164 Return: -368.25603098589077
INFO:tensorflow:Average training steps per second: 227.72
I0901 12:47:14.007112 139803418769408 replay_runner.py:36] Average training steps per second: 227.72
I0901 12:47:14.251250 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -251.53
INFO:tensorflow:Starting iteration 15
I0901 12:47:18.442306 139803418769408 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 226.28

Steps executed: 326 Episode length: 141 Return: -876.15805678525742
I0901 12:47:23.166569 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -999.66
INFO:tensorflow:Starting iteration 16

Steps executed: 259 Episode length: 66 Return: -493.418140359517652
INFO:tensorflow:Average training steps per second: 229.05
I0901 12:47:31.524464 139803418769408 replay_runner.py:36] Average training steps per second: 229.05
I0901 12:47:31.745087 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -485.79
INFO:tensorflow:Starting iteration 17

Steps executed: 215 Episode length: 215 Return: -637.31362994442322
INFO:tensorflow:Average training steps per second: 224.61
I0901 12:47:40.472723 139803418769408 replay_runner.py:36] Average training steps per second: 224.61
I0901 12:47:40.682934 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -637.31
INFO:tensorflow:Starting iteration 18

Steps executed: 208 Episode length: 105 Return: -704.90269723878962
INFO:tensorflow:Average training steps per second: 222.94
I0901 12:47:49.406377 139803418769408 replay_runner.py:36] Average training steps per second: 222.94
I0901 12:47:49.587185 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -498.04
INFO:tensorflow:Starting iteration 19

Steps executed: 247 Episode length: 117 Return: -699.93453155375772
INFO:tensorflow:Average training steps per second: 224.47
I0901 12:47:58.266497 139803418769408 replay_runner.py:36] Average training steps per second: 224.47
I0901 12:47:58.498674 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -702.52
INFO:tensorflow:Starting iteration 20

Steps executed: 202 Episode length: 56 Return: -366.165693804564172
INFO:tensorflow:Average training steps per second: 219.45
I0901 12:48:07.342780 139803418769408 replay_runner.py:36] Average training steps per second: 219.45
I0901 12:48:07.525085 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -542.68
INFO:tensorflow:Starting iteration 21

Steps executed: 270 Episode length: 73 Return: -640.575337280641972
INFO:tensorflow:Average training steps per second: 220.62
I0901 12:48:16.341685 139803418769408 replay_runner.py:36] Average training steps per second: 220.62
I0901 12:48:16.571691 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -506.10
INFO:tensorflow:Starting iteration 22

Steps executed: 207 Episode length: 74 Return: -363.826538582995772
INFO:tensorflow:Average training steps per second: 223.93
I0901 12:48:25.326319 139803418769408 replay_runner.py:36] Average training steps per second: 223.93
I0901 12:48:25.498215 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -413.50
INFO:tensorflow:Starting iteration 23

Steps executed: 218 Episode length: 67 Return: -641.277307580611172
INFO:tensorflow:Average training steps per second: 224.48
I0901 12:48:34.232564 139803418769408 replay_runner.py:36] Average training steps per second: 224.48
I0901 12:48:34.434582 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -605.47
INFO:tensorflow:Starting iteration 24

Steps executed: 243 Episode length: 55 Return: -478.696431559577382
INFO:tensorflow:Average training steps per second: 228.80
I0901 12:48:43.277405 139803418769408 replay_runner.py:36] Average training steps per second: 228.80
I0901 12:48:43.477248 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.59
INFO:tensorflow:Starting iteration 25

Steps executed: 287 Episode length: 93 Return: -415.694262742879972
INFO:tensorflow:Average training steps per second: 229.75
I0901 12:48:52.350922 139803418769408 replay_runner.py:36] Average training steps per second: 229.75
I0901 12:48:52.609884 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -457.44
INFO:tensorflow:Starting iteration 26

Steps executed: 230 Episode length: 69 Return: -63.5045366502103272
INFO:tensorflow:Average training steps per second: 225.49
I0901 12:49:01.445154 139803418769408 replay_runner.py:36] Average training steps per second: 225.49
I0901 12:49:01.645329 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.50
INFO:tensorflow:Starting iteration 27

Steps executed: 230 Episode length: 74 Return: -587.538541044752372
INFO:tensorflow:Average training steps per second: 227.91
I0901 12:49:10.433274 139803418769408 replay_runner.py:36] Average training steps per second: 227.91
I0901 12:49:10.644057 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -627.93
INFO:tensorflow:Starting iteration 28

Steps executed: 231 Episode length: 72 Return: -738.390306275237272
INFO:tensorflow:Average training steps per second: 236.98
I0901 12:49:19.348532 139803418769408 replay_runner.py:36] Average training steps per second: 236.98
I0901 12:49:19.552244 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -674.98
INFO:tensorflow:Starting iteration 29

Steps executed: 241 Episode length: 79 Return: -434.539989879251152
INFO:tensorflow:Average training steps per second: 228.16
I0901 12:49:28.229876 139803418769408 replay_runner.py:36] Average training steps per second: 228.16

Done fixed training!Episode length: 79 Return: -434.539989879251152