I0903 00:20:10.820457 140099460519936 run_experiment.py:549] Creating TrainRunner ...
I0903 00:20:10.830092 140099460519936 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:20:10.830279 140099460519936 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:20:10.830386 140099460519936 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:20:10.830479 140099460519936 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:20:10.830557 140099460519936 dqn_agent.py:275] 	 update_period: 4
I0903 00:20:10.830639 140099460519936 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:20:10.830713 140099460519936 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:20:10.830786 140099460519936 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:20:10.830886 140099460519936 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:20:10.831006 140099460519936 dqn_agent.py:280] 	 optimizer: adam
I0903 00:20:10.831115 140099460519936 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:20:10.831197 140099460519936 dqn_agent.py:283] 	 seed: 1630628410830046
I0903 00:20:10.833514 140099460519936 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:20:10.833674 140099460519936 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:20:10.833776 140099460519936 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:20:10.833864 140099460519936 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:20:10.833943 140099460519936 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:20:10.834019 140099460519936 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:20:10.834118 140099460519936 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:20:10.834233 140099460519936 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:20:10.834324 140099460519936 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:20:10.863389 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:20:11.214735 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:20:11.226277 140099460519936 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:20:11.234427 140099460519936 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:20:11.234643 140099460519936 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:20:11.234776 140099460519936 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:20:11.234958 140099460519936 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:20:11.235108 140099460519936 dqn_agent.py:275] 	 update_period: 4
I0903 00:20:11.235229 140099460519936 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:20:11.235368 140099460519936 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:20:11.235504 140099460519936 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:20:11.235768 140099460519936 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:20:11.235928 140099460519936 dqn_agent.py:280] 	 optimizer: adam
I0903 00:20:11.236028 140099460519936 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:20:11.236110 140099460519936 dqn_agent.py:283] 	 seed: 1630628411234383
I0903 00:20:11.237689 140099460519936 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:20:11.237805 140099460519936 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:20:11.237897 140099460519936 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:20:11.237954 140099460519936 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:20:11.238005 140099460519936 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:20:11.238065 140099460519936 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:20:11.238130 140099460519936 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:20:11.238210 140099460519936 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:20:11.238279 140099460519936 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:20:11.261392 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:20:11.277971 140099460519936 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:20:11.278270 140099460519936 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
Steps executed: 118 Episode length: 118 Return: -370.40137395682973
INFO:tensorflow:Average training steps per second: 229.15

Steps executed: 291 Episode length: 93 Return: -311.304027235728473
I0903 00:20:16.474704 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.63
INFO:tensorflow:Starting iteration 1
I0903 00:20:19.928214 140099460519936 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 338.36
I0903 00:20:22.883937 140099460519936 replay_runner.py:36] Average training steps per second: 338.36

Steps executed: 239 Episode length: 84 Return: -622.260771366676653
INFO:tensorflow:Starting iteration 2

Steps executed: 288 Episode length: 185 Return: -339.19214668605863
INFO:tensorflow:Average training steps per second: 335.07
I0903 00:20:29.467815 140099460519936 replay_runner.py:36] Average training steps per second: 335.07
I0903 00:20:29.648757 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -297.18
INFO:tensorflow:Starting iteration 3

Steps executed: 239 Episode length: 102 Return: -423.36351141005733
INFO:tensorflow:Average training steps per second: 339.30
I0903 00:20:36.035861 140099460519936 replay_runner.py:36] Average training steps per second: 339.30
I0903 00:20:36.157276 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -412.35
INFO:tensorflow:Starting iteration 4
I0903 00:20:39.628127 140099460519936 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 339.11

Steps executed: 227 Episode length: 79 Return: -696.438554908358133
I0903 00:20:42.707849 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -570.07
INFO:tensorflow:Starting iteration 5

Steps executed: 250 Episode length: 250 Return: -543.48310942607993
INFO:tensorflow:Average training steps per second: 334.71
I0903 00:20:49.162999 140099460519936 replay_runner.py:36] Average training steps per second: 334.71
I0903 00:20:49.351784 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -543.48
INFO:tensorflow:Starting iteration 6

Steps executed: 239 Episode length: 55 Return: -336.767085094082393
INFO:tensorflow:Average training steps per second: 345.80
I0903 00:20:55.737972 140099460519936 replay_runner.py:36] Average training steps per second: 345.80
I0903 00:20:55.869549 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.13
INFO:tensorflow:Starting iteration 7

Steps executed: 300 Episode length: 121 Return: -636.17713707519843
INFO:tensorflow:Average training steps per second: 343.20
I0903 00:21:02.272800 140099460519936 replay_runner.py:36] Average training steps per second: 343.20
I0903 00:21:02.458108 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -569.69
INFO:tensorflow:Starting iteration 8

Steps executed: 270 Episode length: 97 Return: -598.873693783637743
INFO:tensorflow:Average training steps per second: 340.81
I0903 00:21:08.882970 140099460519936 replay_runner.py:36] Average training steps per second: 340.81
I0903 00:21:09.034736 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -435.87
INFO:tensorflow:Starting iteration 9

Steps executed: 234 Episode length: 124 Return: -100.98206385849168
INFO:tensorflow:Average training steps per second: 336.12
I0903 00:21:15.490964 140099460519936 replay_runner.py:36] Average training steps per second: 336.12
I0903 00:21:15.623530 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.01
INFO:tensorflow:Starting iteration 10

Steps executed: 278 Episode length: 117 Return: -786.99788412838898
INFO:tensorflow:Average training steps per second: 331.55
I0903 00:21:22.134253 140099460519936 replay_runner.py:36] Average training steps per second: 331.55
I0903 00:21:22.297919 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -701.30
INFO:tensorflow:Starting iteration 11

Steps executed: 232 Episode length: 82 Return: -618.082016250286198
INFO:tensorflow:Average training steps per second: 346.47
I0903 00:21:28.658193 140099460519936 replay_runner.py:36] Average training steps per second: 346.47
I0903 00:21:28.780842 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -518.40
INFO:tensorflow:Starting iteration 12

Steps executed: 208 Episode length: 60 Return: -620.212306243665198
INFO:tensorflow:Average training steps per second: 335.85
I0903 00:21:35.218060 140099460519936 replay_runner.py:36] Average training steps per second: 335.85
I0903 00:21:35.333472 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -642.42
INFO:tensorflow:Starting iteration 13

Steps executed: 243 Episode length: 97 Return: -562.665920625575298
INFO:tensorflow:Average training steps per second: 328.74
I0903 00:21:41.819817 140099460519936 replay_runner.py:36] Average training steps per second: 328.74
I0903 00:21:41.942562 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -690.56
INFO:tensorflow:Starting iteration 14

Steps executed: 225 Episode length: 69 Return: -680.073385864460298
INFO:tensorflow:Average training steps per second: 331.17
I0903 00:21:48.410949 140099460519936 replay_runner.py:36] Average training steps per second: 331.17
I0903 00:21:48.535209 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.55
INFO:tensorflow:Starting iteration 15
I0903 00:21:52.008679 140099460519936 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 327.71

Steps executed: 205 Episode length: 69 Return: -544.958233508807898
I0903 00:21:55.174642 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -381.39
INFO:tensorflow:Starting iteration 16

Steps executed: 212 Episode length: 212 Return: -806.66881246017178
INFO:tensorflow:Average training steps per second: 322.67
I0903 00:22:01.692983 140099460519936 replay_runner.py:36] Average training steps per second: 322.67
I0903 00:22:01.877279 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -806.67
INFO:tensorflow:Starting iteration 17

Steps executed: 342 Episode length: 224 Return: -654.56480766561928
INFO:tensorflow:Average training steps per second: 326.60
I0903 00:22:08.356425 140099460519936 replay_runner.py:36] Average training steps per second: 326.60
I0903 00:22:08.568396 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -513.01
INFO:tensorflow:Starting iteration 18

Steps executed: 244 Episode length: 52 Return: -192.892787559920468
INFO:tensorflow:Average training steps per second: 323.49
I0903 00:22:15.085815 140099460519936 replay_runner.py:36] Average training steps per second: 323.49
I0903 00:22:15.206700 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.65
INFO:tensorflow:Starting iteration 19

Steps executed: 253 Episode length: 57 Return: -389.677751483935378
INFO:tensorflow:Average training steps per second: 328.33
I0903 00:22:21.611575 140099460519936 replay_runner.py:36] Average training steps per second: 328.33
I0903 00:22:21.738387 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.12
INFO:tensorflow:Starting iteration 20

Steps executed: 243 Episode length: 84 Return: -106.451085920230988
INFO:tensorflow:Average training steps per second: 337.30
I0903 00:22:28.041930 140099460519936 replay_runner.py:36] Average training steps per second: 337.30
I0903 00:22:28.156535 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.64
INFO:tensorflow:Starting iteration 21

Steps executed: 267 Episode length: 74 Return: -335.140714497854358
INFO:tensorflow:Average training steps per second: 355.00
I0903 00:22:34.305318 140099460519936 replay_runner.py:36] Average training steps per second: 355.00
I0903 00:22:34.441226 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -370.38
INFO:tensorflow:Starting iteration 22

Steps executed: 221 Episode length: 105 Return: -290.70169547910274
INFO:tensorflow:Average training steps per second: 359.50
I0903 00:22:40.542110 140099460519936 replay_runner.py:36] Average training steps per second: 359.50
I0903 00:22:40.627689 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.42
INFO:tensorflow:Starting iteration 23

Steps executed: 271 Episode length: 75 Return: -286.543975453226664
INFO:tensorflow:Average training steps per second: 372.45
I0903 00:22:46.552567 140099460519936 replay_runner.py:36] Average training steps per second: 372.45
I0903 00:22:46.652395 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -381.74
INFO:tensorflow:Starting iteration 24

Steps executed: 272 Episode length: 74 Return: -330.538555224810764
INFO:tensorflow:Average training steps per second: 373.75
I0903 00:22:52.400842 140099460519936 replay_runner.py:36] Average training steps per second: 373.75
I0903 00:22:52.505304 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.95
INFO:tensorflow:Starting iteration 25

Steps executed: 245 Episode length: 57 Return: -188.962770141314544
INFO:tensorflow:Average training steps per second: 398.50
I0903 00:22:58.047688 140099460519936 replay_runner.py:36] Average training steps per second: 398.50
I0903 00:22:58.146873 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -355.27
INFO:tensorflow:Starting iteration 26

Steps executed: 229 Episode length: 53 Return: -475.555363387786844
INFO:tensorflow:Average training steps per second: 399.52
I0903 00:23:03.489800 140099460519936 replay_runner.py:36] Average training steps per second: 399.52
I0903 00:23:03.591340 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -506.19
INFO:tensorflow:Starting iteration 27

Steps executed: 248 Episode length: 62 Return: -581.001758950016464
INFO:tensorflow:Average training steps per second: 405.03
I0903 00:23:08.910592 140099460519936 replay_runner.py:36] Average training steps per second: 405.03
I0903 00:23:09.021054 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -594.61
INFO:tensorflow:Starting iteration 28

Steps executed: 275 Episode length: 79 Return: -808.408238494822164
INFO:tensorflow:Average training steps per second: 409.76
I0903 00:23:14.190953 140099460519936 replay_runner.py:36] Average training steps per second: 409.76
I0903 00:23:14.307856 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -607.14
INFO:tensorflow:Starting iteration 29

Steps executed: 235 Episode length: 56 Return: -342.959770976602044
INFO:tensorflow:Average training steps per second: 412.68
I0903 00:23:19.451856 140099460519936 replay_runner.py:36] Average training steps per second: 412.68

Done fixed training!Episode length: 56 Return: -342.959770976602044