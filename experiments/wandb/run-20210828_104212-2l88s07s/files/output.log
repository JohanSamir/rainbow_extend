Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0828 10:42:19.397113 140214119393280 run_experiment.py:549] Creating TrainRunner ...
I0828 10:42:19.409438 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:19.409657 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:19.409842 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:19.409943 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:19.410095 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:19.410218 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:19.410386 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:19.410653 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:19.410767 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:19.410903 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:19.411078 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:19.411195 140214119393280 dqn_agent.py:283] 	 seed: 1630147339409382
I0828 10:42:19.413828 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:19.413977 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:19.414057 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:19.414141 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:19.414201 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:19.414290 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:19.414382 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:19.414455 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:19.414528 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:19.448540 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:19.787178 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:19.798197 140214119393280 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:42:19.807098 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:19.807266 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:19.807348 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:19.807427 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:19.807489 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:19.807568 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:19.807701 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:19.807759 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:19.807818 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:19.807890 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:19.807967 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:19.808036 140214119393280 dqn_agent.py:283] 	 seed: 1630147339807059
I0828 10:42:19.810022 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:19.810202 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:19.810291 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:19.810367 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:19.810472 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:19.810551 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:19.810623 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:19.810682 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:19.810826 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:19.841258 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:19.861045 140214119393280 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:42:19.861392 140214119393280 replay_runner.py:41] Starting iteration 0
Steps executed: 216 Episode length: 118 Return: -502.31429369570645
INFO:tensorflow:Average training steps per second: 176.57
I0828 10:42:25.525364 140214119393280 replay_runner.py:36] Average training steps per second: 176.57
I0828 10:42:26.677756 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -576.68
INFO:tensorflow:Starting iteration 1

Steps executed: 140 Episode length: 140 Return: -539.32896969395965
INFO:tensorflow:Average training steps per second: 238.33

Steps executed: 1140 Episode length: 1000 Return: -124.86425127734735
I0828 10:42:37.347080 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.10
INFO:tensorflow:Starting iteration 2
I0828 10:42:41.518882 140214119393280 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 235.15

Steps executed: 1000 Episode length: 1000 Return: -53.588841184503555
I0828 10:42:49.542277 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -53.59
INFO:tensorflow:Starting iteration 3

Steps executed: 218 Episode length: 218 Return: 46.993736959649683555
INFO:tensorflow:Average training steps per second: 221.25
I0828 10:42:58.320544 140214119393280 replay_runner.py:36] Average training steps per second: 221.25
I0828 10:42:58.551020 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: 46.99
INFO:tensorflow:Starting iteration 4
I0828 10:43:02.833236 140214119393280 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 232.57

Steps executed: 786 Episode length: 786 Return: -174.5274123969818555
I0828 10:43:09.101719 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.53
INFO:tensorflow:Starting iteration 5

Steps executed: 143 Episode length: 143 Return: -87.47481927039829555
INFO:tensorflow:Average training steps per second: 238.51

Steps executed: 1143 Episode length: 1000 Return: -109.63744428640825
I0828 10:43:19.957608 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.56
INFO:tensorflow:Starting iteration 6
I0828 10:43:24.164080 140214119393280 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 246.88

Steps executed: 1000 Episode length: 1000 Return: -101.58989134351197
I0828 10:43:31.061200 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.59
INFO:tensorflow:Starting iteration 7

Steps executed: 674 Episode length: 577 Return: -239.2629053885604397
INFO:tensorflow:Average training steps per second: 230.00
I0828 10:43:39.619033 140214119393280 replay_runner.py:36] Average training steps per second: 230.00
I0828 10:43:40.710902 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.79
INFO:tensorflow:Starting iteration 8
I0828 10:43:45.067649 140214119393280 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 222.66

Steps executed: 1000 Episode length: 1000 Return: -139.63473611498427
I0828 10:43:51.549461 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.63
INFO:tensorflow:Starting iteration 9

Steps executed: 84 Episode length: 84 Return: -211.368236512156898427
INFO:tensorflow:Average training steps per second: 226.14

Steps executed: 1084 Episode length: 1000 Return: -224.92511527173744
I0828 10:44:02.816120 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.15
INFO:tensorflow:Starting iteration 10
I0828 10:44:07.108434 140214119393280 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 229.11

Steps executed: 491 Episode length: 491 Return: -386.1065770175335444
I0828 10:44:12.322086 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -386.11
INFO:tensorflow:Starting iteration 11

Steps executed: 245 Episode length: 94 Return: -278.39671040824152444
INFO:tensorflow:Average training steps per second: 227.74
I0828 10:44:21.211743 140214119393280 replay_runner.py:36] Average training steps per second: 227.74
I0828 10:44:21.417144 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -414.17
INFO:tensorflow:Starting iteration 12

Steps executed: 270 Episode length: 108 Return: -123.6785352521689444
INFO:tensorflow:Average training steps per second: 231.33
I0828 10:44:30.106385 140214119393280 replay_runner.py:36] Average training steps per second: 231.33
I0828 10:44:30.329591 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.08
INFO:tensorflow:Starting iteration 13

Steps executed: 223 Episode length: 223 Return: -390.6180580060071444
INFO:tensorflow:Average training steps per second: 238.27
I0828 10:44:38.907555 140214119393280 replay_runner.py:36] Average training steps per second: 238.27
I0828 10:44:39.125862 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -390.62
INFO:tensorflow:Starting iteration 14
I0828 10:44:43.444264 140214119393280 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 236.10

Steps executed: 205 Episode length: 68 Return: -110.77486975407575444
I0828 10:44:47.828574 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.96
INFO:tensorflow:Starting iteration 15

Steps executed: 247 Episode length: 124 Return: -443.7217467179019844
INFO:tensorflow:Average training steps per second: 232.14
I0828 10:44:56.396711 140214119393280 replay_runner.py:36] Average training steps per second: 232.14
I0828 10:44:56.627876 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -348.52
INFO:tensorflow:Starting iteration 16
I0828 10:45:00.873351 140214119393280 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 233.48
I0828 10:45:05.157117 140214119393280 replay_runner.py:36] Average training steps per second: 233.48

Steps executed: 306 Episode length: 306 Return: -420.3141439430381844
INFO:tensorflow:Starting iteration 17

Steps executed: 229 Episode length: 93 Return: -716.44810755248971844
INFO:tensorflow:Average training steps per second: 237.93
I0828 10:45:13.897990 140214119393280 replay_runner.py:36] Average training steps per second: 237.93
I0828 10:45:14.082898 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.89
INFO:tensorflow:Starting iteration 18

Steps executed: 271 Episode length: 271 Return: -73.27558259277154844
INFO:tensorflow:Average training steps per second: 241.61
I0828 10:45:22.314805 140214119393280 replay_runner.py:36] Average training steps per second: 241.61
I0828 10:45:22.540072 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.28
INFO:tensorflow:Starting iteration 19

Steps executed: 254 Episode length: 122 Return: -1203.576328683609744
INFO:tensorflow:Average training steps per second: 259.20
I0828 10:45:30.432395 140214119393280 replay_runner.py:36] Average training steps per second: 259.20
I0828 10:45:30.652218 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -1231.89
INFO:tensorflow:Starting iteration 20

Steps executed: 441 Episode length: 284 Return: -236.1049681353992544
INFO:tensorflow:Average training steps per second: 261.80
I0828 10:45:38.445052 140214119393280 replay_runner.py:36] Average training steps per second: 261.80
I0828 10:45:38.848015 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.41
INFO:tensorflow:Starting iteration 21

Steps executed: 166 Episode length: 166 Return: -366.1313754660266744
INFO:tensorflow:Average training steps per second: 264.72

Steps executed: 1040 Episode length: 874 Return: -399.683263820122934
I0828 10:45:48.533091 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -382.91
INFO:tensorflow:Starting iteration 22

Steps executed: 300 Episode length: 126 Return: -665.6801131215029734
INFO:tensorflow:Average training steps per second: 269.81
I0828 10:45:56.188726 140214119393280 replay_runner.py:36] Average training steps per second: 269.81
I0828 10:45:56.423329 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -409.23
INFO:tensorflow:Starting iteration 23

Steps executed: 235 Episode length: 74 Return: -281.33338360649446734
INFO:tensorflow:Average training steps per second: 276.04
I0828 10:46:03.891844 140214119393280 replay_runner.py:36] Average training steps per second: 276.04
I0828 10:46:04.062450 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.02
INFO:tensorflow:Starting iteration 24

Steps executed: 249 Episode length: 97 Return: -547.00346615958144734
INFO:tensorflow:Average training steps per second: 285.41
I0828 10:46:11.211974 140214119393280 replay_runner.py:36] Average training steps per second: 285.41
I0828 10:46:11.367850 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -238.01
INFO:tensorflow:Starting iteration 25

Steps executed: 279 Episode length: 106 Return: -288.3973122008883534
INFO:tensorflow:Average training steps per second: 308.21
I0828 10:46:18.283900 140214119393280 replay_runner.py:36] Average training steps per second: 308.21
I0828 10:46:18.496419 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -316.41
INFO:tensorflow:Starting iteration 26

Steps executed: 225 Episode length: 59 Return: -173.52558592619963534
INFO:tensorflow:Average training steps per second: 323.47
I0828 10:46:24.942007 140214119393280 replay_runner.py:36] Average training steps per second: 323.47
I0828 10:46:25.085858 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.90
INFO:tensorflow:Starting iteration 27

Steps executed: 200 Episode length: 66 Return: -566.58428907597193534
INFO:tensorflow:Average training steps per second: 318.24
I0828 10:46:31.545969 140214119393280 replay_runner.py:36] Average training steps per second: 318.24
I0828 10:46:31.664048 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -579.88
INFO:tensorflow:Starting iteration 28
I0828 10:46:34.914250 140214119393280 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 332.34
I0828 10:46:37.923711 140214119393280 replay_runner.py:36] Average training steps per second: 332.34

Steps executed: 220 Episode length: 87 Return: -225.92326839365222534
INFO:tensorflow:Starting iteration 29

Steps executed: 300 Episode length: 131 Return: -304.6320876899897634
INFO:tensorflow:Average training steps per second: 332.19
I0828 10:46:44.280285 140214119393280 replay_runner.py:36] Average training steps per second: 332.19

Done fixed training!Episode length: 131 Return: -304.6320876899897634