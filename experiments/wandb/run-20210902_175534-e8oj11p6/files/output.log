Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0902 17:55:40.879226 140613433649152 run_experiment.py:549] Creating TrainRunner ...
I0902 17:55:40.890772 140613433649152 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:55:40.891069 140613433649152 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:55:40.891227 140613433649152 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:55:40.891357 140613433649152 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:55:40.891482 140613433649152 dqn_agent.py:275] 	 update_period: 4
I0902 17:55:40.891601 140613433649152 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:55:40.891854 140613433649152 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:55:40.891997 140613433649152 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:55:40.892121 140613433649152 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:55:40.892246 140613433649152 dqn_agent.py:280] 	 optimizer: adam
I0902 17:55:40.892438 140613433649152 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:55:40.892561 140613433649152 dqn_agent.py:283] 	 seed: 1630605340890702
I0902 17:55:40.895778 140613433649152 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:55:40.896003 140613433649152 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:55:40.896159 140613433649152 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:55:40.896348 140613433649152 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:55:40.896482 140613433649152 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:55:40.896921 140613433649152 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:55:40.897109 140613433649152 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:55:40.897300 140613433649152 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:55:40.897426 140613433649152 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:55:40.935266 140613433649152 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=1.000000
I0902 17:55:41.301276 140613433649152 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=1.000000
I0902 17:55:41.315530 140613433649152 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 17:55:41.323431 140613433649152 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:55:41.323735 140613433649152 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:55:41.323901 140613433649152 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:55:41.324013 140613433649152 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:55:41.324132 140613433649152 dqn_agent.py:275] 	 update_period: 4
I0902 17:55:41.324248 140613433649152 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:55:41.324367 140613433649152 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:55:41.324495 140613433649152 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:55:41.324632 140613433649152 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:55:41.324748 140613433649152 dqn_agent.py:280] 	 optimizer: adam
I0902 17:55:41.325007 140613433649152 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:55:41.325452 140613433649152 dqn_agent.py:283] 	 seed: 1630605341323362
I0902 17:55:41.328658 140613433649152 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:55:41.328892 140613433649152 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:55:41.329088 140613433649152 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:55:41.329217 140613433649152 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:55:41.329339 140613433649152 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:55:41.329562 140613433649152 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:55:41.329711 140613433649152 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:55:41.329811 140613433649152 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:55:41.329916 140613433649152 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:55:41.358416 140613433649152 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=1.000000
I0902 17:55:41.422368 140613433649152 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 17:55:41.422721 140613433649152 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 167.03
I0902 17:55:47.410121 140613433649152 replay_runner.py:36] Average training steps per second: 167.03
Steps executed: 266 Episode length: 92 Return: -155.094663791717565
I0902 17:55:48.883283 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.45
INFO:tensorflow:Starting iteration 1

Steps executed: 242 Episode length: 62 Return: -130.668096396049155
INFO:tensorflow:Average training steps per second: 227.41
I0902 17:55:57.490117 140613433649152 replay_runner.py:36] Average training steps per second: 227.41
I0902 17:55:57.705528 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -62.04
INFO:tensorflow:Starting iteration 2

Steps executed: 253 Episode length: 120 Return: -115.67246891366287
INFO:tensorflow:Average training steps per second: 248.35
I0902 17:56:06.108932 140613433649152 replay_runner.py:36] Average training steps per second: 248.35
I0902 17:56:06.282641 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.48
INFO:tensorflow:Starting iteration 3

Steps executed: 345 Episode length: 192 Return: -652.92715191222927
INFO:tensorflow:Average training steps per second: 239.17
I0902 17:56:14.733007 140613433649152 replay_runner.py:36] Average training steps per second: 239.17
I0902 17:56:14.988696 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -374.78
INFO:tensorflow:Starting iteration 4

Steps executed: 237 Episode length: 237 Return: -60.392210563073937
INFO:tensorflow:Average training steps per second: 230.73
I0902 17:56:23.562942 140613433649152 replay_runner.py:36] Average training steps per second: 230.73
I0902 17:56:23.840884 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -60.39
INFO:tensorflow:Starting iteration 5
I0902 17:56:28.151262 140613433649152 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 222.21

Steps executed: 246 Episode length: 82 Return: -221.502807433270337
I0902 17:56:32.873801 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -386.45
INFO:tensorflow:Starting iteration 6

Steps executed: 213 Episode length: 118 Return: -312.40099148553554
INFO:tensorflow:Average training steps per second: 234.19
I0902 17:56:41.487283 140613433649152 replay_runner.py:36] Average training steps per second: 234.19
I0902 17:56:41.649803 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.55
INFO:tensorflow:Starting iteration 7

Steps executed: 419 Episode length: 287 Return: -123.17303525279219
INFO:tensorflow:Average training steps per second: 225.59
I0902 17:56:50.289457 140613433649152 replay_runner.py:36] Average training steps per second: 225.59
I0902 17:56:50.692611 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.67
INFO:tensorflow:Starting iteration 8

Steps executed: 291 Episode length: 97 Return: -473.744794025852069
INFO:tensorflow:Average training steps per second: 234.95
I0902 17:56:59.107892 140613433649152 replay_runner.py:36] Average training steps per second: 234.95
I0902 17:56:59.349706 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -412.62
INFO:tensorflow:Starting iteration 9

Steps executed: 255 Episode length: 100 Return: -425.41837083562076
INFO:tensorflow:Average training steps per second: 232.97
I0902 17:57:08.117245 140613433649152 replay_runner.py:36] Average training steps per second: 232.97
I0902 17:57:08.332683 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -336.41
INFO:tensorflow:Starting iteration 10

Steps executed: 320 Episode length: 203 Return: -430.19806020068346
INFO:tensorflow:Average training steps per second: 227.76
I0902 17:57:17.120436 140613433649152 replay_runner.py:36] Average training steps per second: 227.76
I0902 17:57:17.421288 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -368.72
INFO:tensorflow:Starting iteration 11

Steps executed: 262 Episode length: 171 Return: -594.19309685118386
INFO:tensorflow:Average training steps per second: 226.95
I0902 17:57:26.178916 140613433649152 replay_runner.py:36] Average training steps per second: 226.95
I0902 17:57:26.395572 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -438.10
INFO:tensorflow:Starting iteration 12
I0902 17:57:30.518413 140613433649152 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 223.43

Steps executed: 349 Episode length: 180 Return: -242.78085925722917
I0902 17:57:35.343173 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -367.25
INFO:tensorflow:Starting iteration 13

Steps executed: 261 Episode length: 106 Return: -274.46765152326606
INFO:tensorflow:Average training steps per second: 223.27
I0902 17:57:44.088352 140613433649152 replay_runner.py:36] Average training steps per second: 223.27
I0902 17:57:44.297064 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.49
INFO:tensorflow:Starting iteration 14

Steps executed: 97 Episode length: 97 Return: -278.0757338585624406
INFO:tensorflow:Average training steps per second: 225.53

Steps executed: 261 Episode length: 88 Return: -391.368614588154906
I0902 17:57:53.286025 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -363.46
INFO:tensorflow:Starting iteration 15

Steps executed: 247 Episode length: 155 Return: -258.52620429153217
INFO:tensorflow:Average training steps per second: 223.88
I0902 17:58:02.022554 140613433649152 replay_runner.py:36] Average training steps per second: 223.88
I0902 17:58:02.231814 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.84
INFO:tensorflow:Starting iteration 16
I0902 17:58:06.662672 140613433649152 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 223.62

Steps executed: 484 Episode length: 368 Return: -173.96220787938963
I0902 17:58:11.775787 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.45
INFO:tensorflow:Starting iteration 17
I0902 17:58:16.077043 140613433649152 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 221.44
I0902 17:58:20.593626 140613433649152 replay_runner.py:36] Average training steps per second: 221.44

Steps executed: 250 Episode length: 250 Return: -294.03436750016215
INFO:tensorflow:Starting iteration 18

Steps executed: 292 Episode length: 97 Return: -294.200671109953315
INFO:tensorflow:Average training steps per second: 227.89
I0902 17:58:29.646380 140613433649152 replay_runner.py:36] Average training steps per second: 227.89
I0902 17:58:29.891453 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -387.38
INFO:tensorflow:Starting iteration 19

Steps executed: 145 Episode length: 145 Return: -128.94631921148914
INFO:tensorflow:Average training steps per second: 223.66

Steps executed: 347 Episode length: 202 Return: -409.41753064271864
I0902 17:58:39.019374 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.18
INFO:tensorflow:Starting iteration 20

Steps executed: 284 Episode length: 183 Return: -307.99276494335974
INFO:tensorflow:Average training steps per second: 223.06
I0902 17:58:47.635131 140613433649152 replay_runner.py:36] Average training steps per second: 223.06
I0902 17:58:47.875822 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.29
INFO:tensorflow:Starting iteration 21

Steps executed: 155 Episode length: 155 Return: -452.17139616042854
INFO:tensorflow:Average training steps per second: 224.03
I0902 17:58:56.692764 140613433649152 replay_runner.py:36] Average training steps per second: 224.03

Steps executed: 346 Episode length: 191 Return: -165.90491709243418
INFO:tensorflow:Starting iteration 22

Steps executed: 229 Episode length: 127 Return: -77.470083865075143
INFO:tensorflow:Average training steps per second: 240.25
I0902 17:59:05.255733 140613433649152 replay_runner.py:36] Average training steps per second: 240.25
I0902 17:59:05.421159 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.49
INFO:tensorflow:Starting iteration 23

Steps executed: 374 Episode length: 188 Return: -331.81614512880793
INFO:tensorflow:Average training steps per second: 235.80
I0902 17:59:14.031796 140613433649152 replay_runner.py:36] Average training steps per second: 235.80
I0902 17:59:14.331982 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.45
INFO:tensorflow:Starting iteration 24

Steps executed: 167 Episode length: 167 Return: -353.25459068654544
INFO:tensorflow:Average training steps per second: 225.88

Steps executed: 317 Episode length: 150 Return: -291.86124782910944
I0902 17:59:23.228780 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -322.56
INFO:tensorflow:Starting iteration 25

Steps executed: 269 Episode length: 155 Return: -345.33268784777524
INFO:tensorflow:Average training steps per second: 224.91
I0902 17:59:31.930605 140613433649152 replay_runner.py:36] Average training steps per second: 224.91
I0902 17:59:32.138867 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.60
INFO:tensorflow:Starting iteration 26

Steps executed: 334 Episode length: 185 Return: -330.41939416658914
INFO:tensorflow:Average training steps per second: 228.80
I0902 17:59:40.887129 140613433649152 replay_runner.py:36] Average training steps per second: 228.80
I0902 17:59:41.157932 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.80
INFO:tensorflow:Starting iteration 27

Steps executed: 200 Episode length: 200 Return: -102.40704704897811
INFO:tensorflow:Average training steps per second: 236.32
I0902 17:59:49.729232 140613433649152 replay_runner.py:36] Average training steps per second: 236.32
I0902 17:59:49.894059 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.41
INFO:tensorflow:Starting iteration 28

Steps executed: 218 Episode length: 218 Return: -22.169999210555491
INFO:tensorflow:Average training steps per second: 228.97
I0902 17:59:58.590963 140613433649152 replay_runner.py:36] Average training steps per second: 228.97
I0902 17:59:58.777631 140613433649152 run_experiment.py:428] Average undiscounted return per evaluation episode: -22.17
INFO:tensorflow:Starting iteration 29
I0902 18:00:02.997500 140613433649152 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 227.39

Steps executed: 291 Episode length: 184 Return: -29.646719673461163

Done fixed training!Episode length: 184 Return: -29.646719673461163