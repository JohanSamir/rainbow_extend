Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0902 00:10:09.446445 139825600018432 run_experiment.py:549] Creating TrainRunner ...
I0902 00:10:09.456383 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:10:09.456727 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:10:09.456921 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:10:09.457074 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:10:09.457481 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0902 00:10:09.457900 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:10:09.458223 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:10:09.458369 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:10:09.458573 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:10:09.458722 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:10:09.458838 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:10:09.458927 139825600018432 dqn_agent.py:283] 	 seed: 1630541409456303
I0902 00:10:09.462541 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:10:09.462922 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:10:09.463230 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:10:09.463392 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:10:09.463576 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:10:09.463651 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:10:09.464159 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:10:09.464323 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:10:09.464493 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:10:09.505604 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:10:09.896710 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:10:09.909700 139825600018432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:10:09.917995 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:10:09.918252 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:10:09.918431 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:10:09.918537 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:10:09.918668 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0902 00:10:09.918803 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:10:09.918887 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:10:09.918973 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:10:09.919053 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:10:09.919248 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:10:09.919395 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:10:09.919491 139825600018432 dqn_agent.py:283] 	 seed: 1630541409917941
I0902 00:10:09.921750 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:10:09.921945 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:10:09.922042 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:10:09.922194 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:10:09.922326 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:10:09.922427 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:10:09.922516 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:10:09.922678 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:10:09.922798 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:10:09.996937 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:10:10.021139 139825600018432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:10:10.021640 139825600018432 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 160.59
I0902 00:10:16.248885 139825600018432 replay_runner.py:36] Average training steps per second: 160.59
Steps executed: 309 Episode length: 131 Return: -447.5259025116448
I0902 00:10:17.986444 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -457.84
INFO:tensorflow:Starting iteration 1

Steps executed: 153 Episode length: 153 Return: 25.398968121429128
INFO:tensorflow:Average training steps per second: 213.88

Steps executed: 307 Episode length: 154 Return: -126.92333516470143
I0902 00:10:27.279964 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -50.76
INFO:tensorflow:Starting iteration 2

Steps executed: 274 Episode length: 274 Return: -111.90282643884072
INFO:tensorflow:Average training steps per second: 218.96
I0902 00:10:36.109920 139825600018432 replay_runner.py:36] Average training steps per second: 218.96
I0902 00:10:36.400936 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.90
INFO:tensorflow:Starting iteration 3
I0902 00:10:40.635931 139825600018432 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 223.20

Steps executed: 252 Episode length: 252 Return: -198.22757788588032
I0902 00:10:45.401088 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.23
INFO:tensorflow:Starting iteration 4

Steps executed: 153 Episode length: 153 Return: -682.92117947594112
INFO:tensorflow:Average training steps per second: 213.49

Steps executed: 793 Episode length: 640 Return: -466.55342750175882
I0902 00:10:56.233937 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -574.74
INFO:tensorflow:Starting iteration 5
I0902 00:11:00.559561 139825600018432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 221.11

Steps executed: 1000 Episode length: 1000 Return: -13.755005380960302
I0902 00:11:07.484213 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -13.76
INFO:tensorflow:Starting iteration 6
I0902 00:11:11.942834 139825600018432 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 221.61

Steps executed: 1000 Episode length: 1000 Return: 9.05765164298935602
I0902 00:11:19.740159 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.06
INFO:tensorflow:Starting iteration 7
I0902 00:11:24.089121 139825600018432 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 220.06

Steps executed: 1000 Episode length: 1000 Return: -232.97992601609621
I0902 00:11:30.432375 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.98
INFO:tensorflow:Starting iteration 8
I0902 00:11:34.809709 139825600018432 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 219.44

Steps executed: 1000 Episode length: 1000 Return: -12.117744222812634
I0902 00:11:42.257336 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -12.12
INFO:tensorflow:Starting iteration 9
I0902 00:11:46.623154 139825600018432 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 224.09
I0902 00:11:51.086033 139825600018432 replay_runner.py:36] Average training steps per second: 224.09

Steps executed: 1000 Episode length: 1000 Return: -85.604407223736434
INFO:tensorflow:Starting iteration 10

Steps executed: 489 Episode length: 489 Return: -340.3611644320576534
INFO:tensorflow:Average training steps per second: 233.95
I0902 00:12:02.261056 139825600018432 replay_runner.py:36] Average training steps per second: 233.95
I0902 00:12:02.970991 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -340.36
INFO:tensorflow:Starting iteration 11
I0902 00:12:07.282542 139825600018432 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 233.51
I0902 00:12:11.565554 139825600018432 replay_runner.py:36] Average training steps per second: 233.51

Steps executed: 749 Episode length: 749 Return: -218.0417770145761534
INFO:tensorflow:Starting iteration 12
I0902 00:12:17.719879 139825600018432 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 227.40
I0902 00:12:22.117770 139825600018432 replay_runner.py:36] Average training steps per second: 227.40

Steps executed: 794 Episode length: 794 Return: -316.2277311066402534
INFO:tensorflow:Starting iteration 13
I0902 00:12:28.200882 139825600018432 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 224.15

Steps executed: 618 Episode length: 618 Return: -406.6946753799043734
I0902 00:12:33.974672 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.69
INFO:tensorflow:Starting iteration 14

Steps executed: 53 Episode length: 53 Return: -157.032593541029343734
INFO:tensorflow:Average training steps per second: 221.15

Steps executed: 1053 Episode length: 1000 Return: -27.763264500673056
I0902 00:12:45.829635 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.40
INFO:tensorflow:Starting iteration 15

Steps executed: 360 Episode length: 360 Return: -152.2898334602993056
INFO:tensorflow:Average training steps per second: 227.21
I0902 00:12:54.635323 139825600018432 replay_runner.py:36] Average training steps per second: 227.21
I0902 00:12:55.149915 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.29
INFO:tensorflow:Starting iteration 16

Steps executed: 201 Episode length: 201 Return: -114.5010421838493156
INFO:tensorflow:Average training steps per second: 223.48
I0902 00:13:04.054597 139825600018432 replay_runner.py:36] Average training steps per second: 223.48
I0902 00:13:04.279840 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.50
INFO:tensorflow:Starting iteration 17

Steps executed: 374 Episode length: 213 Return: -561.3740962667008756
INFO:tensorflow:Average training steps per second: 227.35
I0902 00:13:13.100435 139825600018432 replay_runner.py:36] Average training steps per second: 227.35
I0902 00:13:13.481737 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -374.56
INFO:tensorflow:Starting iteration 18

Steps executed: 285 Episode length: 155 Return: -98.01486601834918556
INFO:tensorflow:Average training steps per second: 224.43
I0902 00:13:22.310960 139825600018432 replay_runner.py:36] Average training steps per second: 224.43
I0902 00:13:22.562590 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.85
INFO:tensorflow:Starting iteration 19

Steps executed: 52 Episode length: 52 Return: -152.188403170656918556
INFO:tensorflow:Average training steps per second: 223.04

Steps executed: 280 Episode length: 228 Return: -261.8498132515937556
I0902 00:13:31.762420 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.02
INFO:tensorflow:Starting iteration 20

Steps executed: 259 Episode length: 259 Return: -215.1437741050683656
INFO:tensorflow:Average training steps per second: 234.04
I0902 00:13:40.408321 139825600018432 replay_runner.py:36] Average training steps per second: 234.04
I0902 00:13:40.748661 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.14
INFO:tensorflow:Starting iteration 21

Steps executed: 164 Episode length: 164 Return: -142.6292331029047556
INFO:tensorflow:Average training steps per second: 227.65
I0902 00:13:49.469129 139825600018432 replay_runner.py:36] Average training steps per second: 227.65

Steps executed: 342 Episode length: 178 Return: -741.9602616425493556
INFO:tensorflow:Starting iteration 22

Steps executed: 548 Episode length: 373 Return: -117.7386460594421556
INFO:tensorflow:Average training steps per second: 224.48
I0902 00:13:58.621551 139825600018432 replay_runner.py:36] Average training steps per second: 224.48
I0902 00:13:59.409927 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.55
INFO:tensorflow:Starting iteration 23

Steps executed: 301 Episode length: 113 Return: -44.26229929011433556
INFO:tensorflow:Average training steps per second: 225.03
I0902 00:14:08.206536 139825600018432 replay_runner.py:36] Average training steps per second: 225.03
I0902 00:14:08.429710 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.75
INFO:tensorflow:Starting iteration 24

Steps executed: 227 Episode length: 66 Return: -230.48190950894178556
INFO:tensorflow:Average training steps per second: 225.27
I0902 00:14:17.208922 139825600018432 replay_runner.py:36] Average training steps per second: 225.27
I0902 00:14:17.378230 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -219.26
INFO:tensorflow:Starting iteration 25

Steps executed: 271 Episode length: 116 Return: 11.229057689726022556
INFO:tensorflow:Average training steps per second: 222.36
I0902 00:14:26.320977 139825600018432 replay_runner.py:36] Average training steps per second: 222.36
I0902 00:14:26.579073 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: 20.07
INFO:tensorflow:Starting iteration 26

Steps executed: 308 Episode length: 308 Return: 231.75674303922221556
INFO:tensorflow:Average training steps per second: 222.38
I0902 00:14:35.493921 139825600018432 replay_runner.py:36] Average training steps per second: 222.38
I0902 00:14:35.899264 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: 231.76
INFO:tensorflow:Starting iteration 27

Steps executed: 362 Episode length: 362 Return: -549.9286669561625556
INFO:tensorflow:Average training steps per second: 227.12
I0902 00:14:44.660166 139825600018432 replay_runner.py:36] Average training steps per second: 227.12
I0902 00:14:45.301682 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -549.93
INFO:tensorflow:Starting iteration 28
I0902 00:14:49.608074 139825600018432 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 229.39

Steps executed: 203 Episode length: 203 Return: -127.5467600115437256
I0902 00:14:54.151881 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.55
INFO:tensorflow:Starting iteration 29

Steps executed: 367 Episode length: 252 Return: -571.0080733573819256
INFO:tensorflow:Average training steps per second: 225.25
I0902 00:15:02.843652 139825600018432 replay_runner.py:36] Average training steps per second: 225.25

Done fixed training!Episode length: 252 Return: -571.0080733573819256