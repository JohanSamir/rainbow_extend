Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0828 10:46:55.139161 140220309850112 run_experiment.py:549] Creating TrainRunner ...
I0828 10:46:55.146951 140220309850112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:46:55.147069 140220309850112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:46:55.147150 140220309850112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:46:55.147211 140220309850112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:46:55.147294 140220309850112 dqn_agent.py:275] 	 update_period: 4
I0828 10:46:55.147438 140220309850112 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:46:55.147520 140220309850112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:46:55.147618 140220309850112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:46:55.147677 140220309850112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:46:55.147732 140220309850112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:46:55.147816 140220309850112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:46:55.147894 140220309850112 dqn_agent.py:283] 	 seed: 1630147615146919
I0828 10:46:55.149566 140220309850112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:46:55.149673 140220309850112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:46:55.149752 140220309850112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:46:55.149814 140220309850112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:46:55.149871 140220309850112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:46:55.149971 140220309850112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:46:55.150038 140220309850112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:46:55.150104 140220309850112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:46:55.150189 140220309850112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:46:55.175721 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:55.447116 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:55.460296 140220309850112 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:46:55.469577 140220309850112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:46:55.469762 140220309850112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:46:55.469878 140220309850112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:46:55.469982 140220309850112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:46:55.470079 140220309850112 dqn_agent.py:275] 	 update_period: 4
I0828 10:46:55.470193 140220309850112 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:46:55.470289 140220309850112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:46:55.470382 140220309850112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:46:55.470484 140220309850112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:46:55.470585 140220309850112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:46:55.470665 140220309850112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:46:55.470748 140220309850112 dqn_agent.py:283] 	 seed: 1630147615469538
I0828 10:46:55.473698 140220309850112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:46:55.473884 140220309850112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:46:55.474002 140220309850112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:46:55.474127 140220309850112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:46:55.474234 140220309850112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:46:55.474329 140220309850112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:46:55.474431 140220309850112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:46:55.474525 140220309850112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:46:55.474617 140220309850112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:46:55.511320 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:55.527209 140220309850112 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:46:55.527342 140220309850112 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 243.64
I0828 10:46:59.631831 140220309850112 replay_runner.py:36] Average training steps per second: 243.64
I0828 10:47:00.252290 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.48
Steps executed: 237 Episode length: 148 Return: -248.86942552506713
INFO:tensorflow:Starting iteration 1

Steps executed: 213 Episode length: 98 Return: -467.684028613083805
INFO:tensorflow:Average training steps per second: 353.45
I0828 10:47:06.351029 140220309850112 replay_runner.py:36] Average training steps per second: 353.45
I0828 10:47:06.450407 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -371.31
INFO:tensorflow:Starting iteration 2
I0828 10:47:09.832256 140220309850112 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 355.11
I0828 10:47:12.648593 140220309850112 replay_runner.py:36] Average training steps per second: 355.11

Steps executed: 263 Episode length: 263 Return: -139.21401485082195
INFO:tensorflow:Starting iteration 3

Steps executed: 736 Episode length: 600 Return: -258.83889687142107
INFO:tensorflow:Average training steps per second: 350.70
I0828 10:47:19.166063 140220309850112 replay_runner.py:36] Average training steps per second: 350.70
I0828 10:47:19.937520 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.03
INFO:tensorflow:Starting iteration 4

Steps executed: 460 Episode length: 460 Return: -290.22895351374867
INFO:tensorflow:Average training steps per second: 349.49
I0828 10:47:26.241401 140220309850112 replay_runner.py:36] Average training steps per second: 349.49
I0828 10:47:26.747331 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.23
INFO:tensorflow:Starting iteration 5
I0828 10:47:30.121365 140220309850112 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 353.73

Steps executed: 632 Episode length: 632 Return: -413.46794752961027
I0828 10:47:33.893798 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -413.47
INFO:tensorflow:Starting iteration 6
I0828 10:47:37.301323 140220309850112 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 351.98
I0828 10:47:40.143011 140220309850112 replay_runner.py:36] Average training steps per second: 351.98

Steps executed: 686 Episode length: 686 Return: -282.07501443417877
INFO:tensorflow:Starting iteration 7

Steps executed: 649 Episode length: 649 Return: -726.65647567365227
INFO:tensorflow:Average training steps per second: 340.10
I0828 10:47:47.329372 140220309850112 replay_runner.py:36] Average training steps per second: 340.10
I0828 10:47:48.290295 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -726.66
INFO:tensorflow:Starting iteration 8
I0828 10:47:51.630067 140220309850112 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 350.21

Steps executed: 687 Episode length: 687 Return: -361.03670214943685
I0828 10:47:55.546545 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.04
INFO:tensorflow:Starting iteration 9

Steps executed: 435 Episode length: 435 Return: -401.67409090479835
INFO:tensorflow:Average training steps per second: 336.84
I0828 10:48:01.824957 140220309850112 replay_runner.py:36] Average training steps per second: 336.84
I0828 10:48:02.280560 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -401.67
INFO:tensorflow:Starting iteration 10
I0828 10:48:05.498347 140220309850112 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 334.61

Steps executed: 885 Episode length: 885 Return: -380.95683463436325
I0828 10:48:10.440553 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -380.96
INFO:tensorflow:Starting iteration 11
I0828 10:48:13.632636 140220309850112 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 310.64

Steps executed: 951 Episode length: 951 Return: -280.71386540812296
I0828 10:48:17.971840 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.71
INFO:tensorflow:Starting iteration 12
I0828 10:48:21.258060 140220309850112 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 341.29

Steps executed: 1000 Episode length: 1000 Return: -110.599206863165
I0828 10:48:26.181521 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.60
INFO:tensorflow:Starting iteration 13
I0828 10:48:29.614367 140220309850112 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 342.93

Steps executed: 1000 Episode length: 1000 Return: -269.94752300747643
I0828 10:48:34.283662 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.95
INFO:tensorflow:Starting iteration 14
I0828 10:48:37.687415 140220309850112 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 349.76

Steps executed: 1000 Episode length: 1000 Return: -81.501188643103183
I0828 10:48:42.359070 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.50
INFO:tensorflow:Starting iteration 15

Steps executed: 430 Episode length: 430 Return: -295.8829983463034183
INFO:tensorflow:Average training steps per second: 353.89
I0828 10:48:48.646584 140220309850112 replay_runner.py:36] Average training steps per second: 353.89
I0828 10:48:49.140848 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -295.88
INFO:tensorflow:Starting iteration 16

Steps executed: 247 Episode length: 247 Return: -221.1156502174811783
INFO:tensorflow:Average training steps per second: 326.78
I0828 10:48:55.580777 140220309850112 replay_runner.py:36] Average training steps per second: 326.78
I0828 10:48:55.747683 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.12
INFO:tensorflow:Starting iteration 17
I0828 10:48:58.904562 140220309850112 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 310.32

Steps executed: 1000 Episode length: 1000 Return: -75.661615678681573
I0828 10:49:03.701513 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.66
INFO:tensorflow:Starting iteration 18

Steps executed: 337 Episode length: 152 Return: -260.6811375648195573
INFO:tensorflow:Average training steps per second: 320.04
I0828 10:49:10.069398 140220309850112 replay_runner.py:36] Average training steps per second: 320.04
I0828 10:49:10.276194 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.73
INFO:tensorflow:Starting iteration 19
I0828 10:49:13.229542 140220309850112 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 317.49

Steps executed: 633 Episode length: 633 Return: 229.06526519895295573
I0828 10:49:17.447819 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: 229.07
INFO:tensorflow:Starting iteration 20

Steps executed: 252 Episode length: 108 Return: -302.8346185960984573
INFO:tensorflow:Average training steps per second: 312.60
I0828 10:49:23.710460 140220309850112 replay_runner.py:36] Average training steps per second: 312.60
I0828 10:49:23.875777 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.97
INFO:tensorflow:Starting iteration 21

Steps executed: 718 Episode length: 563 Return: -75.08096870952707573
INFO:tensorflow:Average training steps per second: 335.24
I0828 10:49:30.027234 140220309850112 replay_runner.py:36] Average training steps per second: 335.24
I0828 10:49:30.985301 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -67.29
INFO:tensorflow:Starting iteration 22
I0828 10:49:34.304111 140220309850112 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 321.82

Steps executed: 737 Episode length: 596 Return: -286.7014292694863573
I0828 10:49:38.211409 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.27
INFO:tensorflow:Starting iteration 23

Steps executed: 653 Episode length: 505 Return: -367.3819286515939573
INFO:tensorflow:Average training steps per second: 331.99
I0828 10:49:44.443990 140220309850112 replay_runner.py:36] Average training steps per second: 331.99
I0828 10:49:45.113804 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.45
INFO:tensorflow:Starting iteration 24
I0828 10:49:48.474767 140220309850112 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 343.94

Steps executed: 244 Episode length: 75 Return: -337.76766550201194273
I0828 10:49:51.524520 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -275.15
INFO:tensorflow:Starting iteration 25

Steps executed: 262 Episode length: 262 Return: 266.61963292636955273
INFO:tensorflow:Average training steps per second: 333.42
I0828 10:49:57.802137 140220309850112 replay_runner.py:36] Average training steps per second: 333.42
I0828 10:49:58.013812 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: 266.62
INFO:tensorflow:Starting iteration 26

Steps executed: 212 Episode length: 212 Return: -260.2333441494124273
INFO:tensorflow:Average training steps per second: 320.14
I0828 10:50:04.347872 140220309850112 replay_runner.py:36] Average training steps per second: 320.14
I0828 10:50:04.489182 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.23
INFO:tensorflow:Starting iteration 27

Steps executed: 262 Episode length: 104 Return: -59.77573518021986273
INFO:tensorflow:Average training steps per second: 332.70
I0828 10:50:10.723199 140220309850112 replay_runner.py:36] Average training steps per second: 332.70
I0828 10:50:10.850996 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -25.95
INFO:tensorflow:Starting iteration 28

Steps executed: 326 Episode length: 172 Return: 15.205051500292413273
INFO:tensorflow:Average training steps per second: 334.73
I0828 10:50:17.181792 140220309850112 replay_runner.py:36] Average training steps per second: 334.73
I0828 10:50:17.391861 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -39.30
INFO:tensorflow:Starting iteration 29
I0828 10:50:20.660310 140220309850112 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 347.40

Steps executed: 269 Episode length: 269 Return: -15.77157698165235973

Done fixed training!Episode length: 269 Return: -15.77157698165235973