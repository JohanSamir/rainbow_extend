Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0901 12:59:28.326618 139803418769408 run_experiment.py:549] Creating TrainRunner ...
I0901 12:59:28.339093 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:59:28.339338 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:59:28.339496 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:59:28.339630 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:59:28.339757 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 12:59:28.339908 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:59:28.340258 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:59:28.340476 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:59:28.340688 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:59:28.340985 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 12:59:28.341199 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:59:28.341304 139803418769408 dqn_agent.py:283] 	 seed: 1630501168339033
I0901 12:59:28.344104 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:59:28.344443 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:59:28.344836 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:59:28.344961 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:59:28.345240 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:59:28.345463 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:59:28.345854 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:59:28.345994 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:59:28.346309 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:59:28.389355 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:59:28.808552 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:59:28.844903 139803418769408 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:59:28.853771 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:59:28.854123 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:59:28.854286 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:59:28.854402 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:59:28.854545 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 12:59:28.854720 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:59:28.854900 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:59:28.855013 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:59:28.855128 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:59:28.855307 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 12:59:28.855489 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:59:28.855591 139803418769408 dqn_agent.py:283] 	 seed: 1630501168853714
I0901 12:59:28.858419 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:59:28.858626 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:59:28.858807 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:59:28.858926 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:59:28.859303 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:59:28.859460 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:59:28.859628 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:59:28.859952 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:59:28.860134 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:59:28.896382 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:59:28.920004 139803418769408 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:59:28.920275 139803418769408 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 155.39
I0901 12:59:35.355931 139803418769408 replay_runner.py:36] Average training steps per second: 155.39
Steps executed: 217 Episode length: 101 Return: -296.6448294970772
I0901 12:59:36.591181 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -313.25
INFO:tensorflow:Starting iteration 1

Steps executed: 217 Episode length: 120 Return: -50.36945703881154
INFO:tensorflow:Average training steps per second: 219.84
I0901 12:59:45.602641 139803418769408 replay_runner.py:36] Average training steps per second: 219.84
I0901 12:59:45.777692 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.60
INFO:tensorflow:Starting iteration 2

Steps executed: 221 Episode length: 114 Return: -292.76766624089832
INFO:tensorflow:Average training steps per second: 217.14
I0901 12:59:54.654828 139803418769408 replay_runner.py:36] Average training steps per second: 217.14
I0901 12:59:54.867797 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -271.42
INFO:tensorflow:Starting iteration 3

Steps executed: 247 Episode length: 91 Return: -157.688168638719562
INFO:tensorflow:Average training steps per second: 228.36
I0901 13:00:03.699391 139803418769408 replay_runner.py:36] Average training steps per second: 228.36
I0901 13:00:03.899284 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.95
INFO:tensorflow:Starting iteration 4

Steps executed: 313 Episode length: 131 Return: -301.43369302087666
INFO:tensorflow:Average training steps per second: 216.60
I0901 13:00:13.004590 139803418769408 replay_runner.py:36] Average training steps per second: 216.60
I0901 13:00:13.304969 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.70
INFO:tensorflow:Starting iteration 5

Steps executed: 266 Episode length: 177 Return: -84.755221910805676
INFO:tensorflow:Average training steps per second: 214.93
I0901 13:00:22.265009 139803418769408 replay_runner.py:36] Average training steps per second: 214.93
I0901 13:00:22.496687 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -222.53
INFO:tensorflow:Starting iteration 6

Steps executed: 208 Episode length: 87 Return: -294.243921510635236
INFO:tensorflow:Average training steps per second: 211.90
I0901 13:00:31.619616 139803418769408 replay_runner.py:36] Average training steps per second: 211.90
I0901 13:00:31.811685 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.63
INFO:tensorflow:Starting iteration 7

Steps executed: 259 Episode length: 65 Return: -124.820669081757256
INFO:tensorflow:Average training steps per second: 211.79
I0901 13:00:40.781824 139803418769408 replay_runner.py:36] Average training steps per second: 211.79
I0901 13:00:40.961271 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.76
INFO:tensorflow:Starting iteration 8

Steps executed: 277 Episode length: 150 Return: -10.126499463381379
INFO:tensorflow:Average training steps per second: 216.60
I0901 13:00:49.707014 139803418769408 replay_runner.py:36] Average training steps per second: 216.60
I0901 13:00:50.012002 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.39
INFO:tensorflow:Starting iteration 9

Steps executed: 223 Episode length: 57 Return: -332.868806115646639
INFO:tensorflow:Average training steps per second: 212.79
I0901 13:00:59.156533 139803418769408 replay_runner.py:36] Average training steps per second: 212.79
I0901 13:00:59.369230 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -436.57
INFO:tensorflow:Starting iteration 10

Steps executed: 232 Episode length: 87 Return: -362.041741369055969
INFO:tensorflow:Average training steps per second: 206.90
I0901 13:01:08.540038 139803418769408 replay_runner.py:36] Average training steps per second: 206.90
I0901 13:01:08.776506 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.49
INFO:tensorflow:Starting iteration 11

Steps executed: 232 Episode length: 80 Return: -221.817613923998189
INFO:tensorflow:Average training steps per second: 211.97
I0901 13:01:17.778764 139803418769408 replay_runner.py:36] Average training steps per second: 211.97
I0901 13:01:17.965250 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.73
INFO:tensorflow:Starting iteration 12

Steps executed: 256 Episode length: 91 Return: -797.708976946072189
INFO:tensorflow:Average training steps per second: 214.62
I0901 13:01:27.106936 139803418769408 replay_runner.py:36] Average training steps per second: 214.62
I0901 13:01:27.338458 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -490.29
INFO:tensorflow:Starting iteration 13
I0901 13:01:31.788262 139803418769408 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 214.48

Steps executed: 203 Episode length: 115 Return: -52.966092203623329
I0901 13:01:36.620448 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.43
INFO:tensorflow:Starting iteration 14

Steps executed: 230 Episode length: 82 Return: -362.720292671744975
INFO:tensorflow:Average training steps per second: 222.16
I0901 13:01:45.428811 139803418769408 replay_runner.py:36] Average training steps per second: 222.16
I0901 13:01:45.653834 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -405.78
INFO:tensorflow:Starting iteration 15
I0901 13:01:49.972221 139803418769408 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 220.21

Steps executed: 284 Episode length: 86 Return: -575.811481421365885
I0901 13:01:54.746566 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -568.77
INFO:tensorflow:Starting iteration 16

Steps executed: 281 Episode length: 88 Return: -322.326381155509685
INFO:tensorflow:Average training steps per second: 220.55
I0901 13:02:03.622630 139803418769408 replay_runner.py:36] Average training steps per second: 220.55
I0901 13:02:03.850781 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -398.77
INFO:tensorflow:Starting iteration 17
I0901 13:02:08.142085 139803418769408 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 217.42

Steps executed: 370 Episode length: 186 Return: -255.90564855321853
I0901 13:02:13.060615 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.55
INFO:tensorflow:Starting iteration 18

Steps executed: 241 Episode length: 56 Return: -346.767256820593253
INFO:tensorflow:Average training steps per second: 218.02
I0901 13:02:21.921533 139803418769408 replay_runner.py:36] Average training steps per second: 218.02
I0901 13:02:22.149150 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -43.65
INFO:tensorflow:Starting iteration 19

Steps executed: 240 Episode length: 67 Return: -123.962964369562293
INFO:tensorflow:Average training steps per second: 225.06
I0901 13:02:30.798597 139803418769408 replay_runner.py:36] Average training steps per second: 225.06
I0901 13:02:30.959158 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.54
INFO:tensorflow:Starting iteration 20

Steps executed: 258 Episode length: 65 Return: -528.417369143172543
INFO:tensorflow:Average training steps per second: 223.48
I0901 13:02:39.699880 139803418769408 replay_runner.py:36] Average training steps per second: 223.48
I0901 13:02:39.918026 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -446.03
INFO:tensorflow:Starting iteration 21

Steps executed: 248 Episode length: 95 Return: -401.870721371947143
INFO:tensorflow:Average training steps per second: 219.97
I0901 13:02:48.813285 139803418769408 replay_runner.py:36] Average training steps per second: 219.97
I0901 13:02:49.014275 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -434.89
INFO:tensorflow:Starting iteration 22

Steps executed: 208 Episode length: 80 Return: -339.851992619701046
INFO:tensorflow:Average training steps per second: 229.09
I0901 13:02:57.642830 139803418769408 replay_runner.py:36] Average training steps per second: 229.09
I0901 13:02:57.797098 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.50
INFO:tensorflow:Starting iteration 23

Steps executed: 79 Episode length: 79 Return: -357.1548214123196046
INFO:tensorflow:Average training steps per second: 229.34

Steps executed: 268 Episode length: 78 Return: -329.971840974667036
I0901 13:03:06.634707 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -354.66
INFO:tensorflow:Starting iteration 24

Steps executed: 230 Episode length: 87 Return: -118.192430242452086
INFO:tensorflow:Average training steps per second: 238.45
I0901 13:03:14.962892 139803418769408 replay_runner.py:36] Average training steps per second: 238.45
I0901 13:03:15.101799 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.12
INFO:tensorflow:Starting iteration 25

Steps executed: 206 Episode length: 62 Return: -492.911549939310286
INFO:tensorflow:Average training steps per second: 241.35
I0901 13:03:23.363428 139803418769408 replay_runner.py:36] Average training steps per second: 241.35
I0901 13:03:23.530178 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -513.45
INFO:tensorflow:Starting iteration 26

Steps executed: 215 Episode length: 63 Return: -186.314085257977336
INFO:tensorflow:Average training steps per second: 239.35
I0901 13:03:31.882788 139803418769408 replay_runner.py:36] Average training steps per second: 239.35
I0901 13:03:32.036531 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.66
INFO:tensorflow:Starting iteration 27

Steps executed: 225 Episode length: 72 Return: -486.838880050790866
INFO:tensorflow:Average training steps per second: 240.06
I0901 13:03:40.349084 139803418769408 replay_runner.py:36] Average training steps per second: 240.06
I0901 13:03:40.498740 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.91
INFO:tensorflow:Starting iteration 28

Steps executed: 132 Episode length: 78 Return: -99.3062674449099966
INFO:tensorflow:Average training steps per second: 250.53
I0901 13:03:48.653878 139803418769408 replay_runner.py:36] Average training steps per second: 250.53

Steps executed: 267 Episode length: 75 Return: -135.529982393648086
INFO:tensorflow:Starting iteration 29

Steps executed: 220 Episode length: 53 Return: -390.366077080333246
INFO:tensorflow:Average training steps per second: 250.50
I0901 13:03:57.040817 139803418769408 replay_runner.py:36] Average training steps per second: 250.50

Done fixed training!Episode length: 53 Return: -390.366077080333246