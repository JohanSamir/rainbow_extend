I0828 10:47:17.970107 140078257940480 run_experiment.py:549] Creating TrainRunner ...
I0828 10:47:17.978507 140078257940480 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:47:17.978639 140078257940480 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:47:17.978714 140078257940480 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:47:17.978791 140078257940480 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:47:17.978879 140078257940480 dqn_agent.py:275] 	 update_period: 4
I0828 10:47:17.978950 140078257940480 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:47:17.979004 140078257940480 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:47:17.979151 140078257940480 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:47:17.979288 140078257940480 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:47:17.979415 140078257940480 dqn_agent.py:280] 	 optimizer: adam
I0828 10:47:17.979552 140078257940480 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:47:17.979696 140078257940480 dqn_agent.py:283] 	 seed: 1630147637978470
I0828 10:47:17.981615 140078257940480 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:47:17.981726 140078257940480 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:47:17.981916 140078257940480 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:47:17.982026 140078257940480 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:47:17.982160 140078257940480 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:47:17.982234 140078257940480 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:47:17.982316 140078257940480 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:47:17.982375 140078257940480 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:47:17.982476 140078257940480 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:47:18.008642 140078257940480 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:18.256679 140078257940480 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:18.266029 140078257940480 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:47:18.272779 140078257940480 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:47:18.272919 140078257940480 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:47:18.272995 140078257940480 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:47:18.273063 140078257940480 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:47:18.273119 140078257940480 dqn_agent.py:275] 	 update_period: 4
I0828 10:47:18.273197 140078257940480 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:47:18.273260 140078257940480 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:47:18.273377 140078257940480 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:47:18.273473 140078257940480 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:47:18.273578 140078257940480 dqn_agent.py:280] 	 optimizer: adam
I0828 10:47:18.273654 140078257940480 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:47:18.273743 140078257940480 dqn_agent.py:283] 	 seed: 1630147638272748
I0828 10:47:18.275750 140078257940480 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:47:18.275874 140078257940480 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:47:18.275953 140078257940480 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:47:18.276022 140078257940480 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:47:18.276093 140078257940480 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:47:18.276173 140078257940480 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:47:18.276254 140078257940480 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:47:18.276354 140078257940480 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:47:18.276429 140078257940480 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:47:18.296635 140078257940480 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:18.310566 140078257940480 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:47:18.310724 140078257940480 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 236.27
I0828 10:47:22.543420 140078257940480 replay_runner.py:36] Average training steps per second: 236.27
I0828 10:47:23.405065 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -451.29
Steps executed: 353 Episode length: 159 Return: -426.1600990316125
INFO:tensorflow:Starting iteration 1

Steps executed: 264 Episode length: 116 Return: -235.96782935139984
INFO:tensorflow:Average training steps per second: 331.60
I0828 10:47:29.841269 140078257940480 replay_runner.py:36] Average training steps per second: 331.60
I0828 10:47:29.972270 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -267.92
INFO:tensorflow:Starting iteration 2

Steps executed: 296 Episode length: 180 Return: -452.24565720699854
INFO:tensorflow:Average training steps per second: 324.97
I0828 10:47:36.443233 140078257940480 replay_runner.py:36] Average training steps per second: 324.97
I0828 10:47:36.627923 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.81
INFO:tensorflow:Starting iteration 3
I0828 10:47:40.002058 140078257940480 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 326.66

Steps executed: 1000 Episode length: 1000 Return: -166.6004411097622
I0828 10:47:45.633449 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.60
INFO:tensorflow:Starting iteration 4

Steps executed: 1000 Episode length: 1000 Return: -205.37443343070493
INFO:tensorflow:Average training steps per second: 329.79
I0828 10:47:51.987293 140078257940480 replay_runner.py:36] Average training steps per second: 329.79
I0828 10:47:53.401981 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.37
INFO:tensorflow:Starting iteration 5
I0828 10:47:56.713063 140078257940480 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 332.19

Steps executed: 1000 Episode length: 1000 Return: -218.15227232807655
I0828 10:48:02.265429 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.15
INFO:tensorflow:Starting iteration 6
I0828 10:48:05.429402 140078257940480 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 318.72

Steps executed: 1000 Episode length: 1000 Return: -291.14802274118335
I0828 10:48:10.281293 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -291.15
INFO:tensorflow:Starting iteration 7
I0828 10:48:13.439722 140078257940480 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 311.67

Steps executed: 1000 Episode length: 1000 Return: -189.49939160660827
I0828 10:48:19.566809 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.50
INFO:tensorflow:Starting iteration 8

Steps executed: 348 Episode length: 348 Return: -439.1374439242767827
INFO:tensorflow:Average training steps per second: 336.28
I0828 10:48:26.030223 140078257940480 replay_runner.py:36] Average training steps per second: 336.28
I0828 10:48:26.286652 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -439.14
INFO:tensorflow:Starting iteration 9
I0828 10:48:29.722588 140078257940480 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 326.65

Steps executed: 1000 Episode length: 1000 Return: -180.20347218743692
I0828 10:48:34.991547 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.20
INFO:tensorflow:Starting iteration 10

Steps executed: 463 Episode length: 463 Return: -300.7257084292065692
INFO:tensorflow:Average training steps per second: 340.65
I0828 10:48:41.352867 140078257940480 replay_runner.py:36] Average training steps per second: 340.65
I0828 10:48:41.925405 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.73
INFO:tensorflow:Starting iteration 11

Steps executed: 326 Episode length: 326 Return: -282.5621819685227492
INFO:tensorflow:Average training steps per second: 333.69
I0828 10:48:48.376193 140078257940480 replay_runner.py:36] Average training steps per second: 333.69
I0828 10:48:48.652353 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -282.56
INFO:tensorflow:Starting iteration 12

Steps executed: 493 Episode length: 493 Return: -311.9212537735143792
INFO:tensorflow:Average training steps per second: 315.69
I0828 10:48:55.187852 140078257940480 replay_runner.py:36] Average training steps per second: 315.69
I0828 10:48:55.728818 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.92
INFO:tensorflow:Starting iteration 13
I0828 10:48:58.879238 140078257940480 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 303.39

Steps executed: 1000 Episode length: 1000 Return: -291.28264157059622
I0828 10:49:03.679729 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -291.28
INFO:tensorflow:Starting iteration 14
I0828 10:49:06.881985 140078257940480 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 305.31

Steps executed: 1000 Episode length: 1000 Return: -171.59444860559185
I0828 10:49:12.184345 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.59
INFO:tensorflow:Starting iteration 15

Steps executed: 498 Episode length: 498 Return: -191.2404849167824685
INFO:tensorflow:Average training steps per second: 332.17
I0828 10:49:18.594948 140078257940480 replay_runner.py:36] Average training steps per second: 332.17
I0828 10:49:19.077646 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.24
INFO:tensorflow:Starting iteration 16
I0828 10:49:22.405113 140078257940480 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 319.41
I0828 10:49:25.536157 140078257940480 replay_runner.py:36] Average training steps per second: 319.41

Steps executed: 1000 Episode length: 1000 Return: -103.27683710275564
INFO:tensorflow:Starting iteration 17
I0828 10:49:31.680953 140078257940480 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 345.79

Steps executed: 1000 Episode length: 1000 Return: -237.01211353853733
I0828 10:49:37.523699 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.01
INFO:tensorflow:Starting iteration 18
I0828 10:49:40.733725 140078257940480 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 312.61

Steps executed: 283 Episode length: 146 Return: -24.85446245955667333
I0828 10:49:44.091150 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -27.74
INFO:tensorflow:Starting iteration 19
I0828 10:49:47.376793 140078257940480 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 317.74

Steps executed: 1000 Episode length: 1000 Return: -119.72245452509183
I0828 10:49:52.311100 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.72
INFO:tensorflow:Starting iteration 20

Steps executed: 230 Episode length: 230 Return: -196.8909268526715683
INFO:tensorflow:Average training steps per second: 321.70
I0828 10:49:58.775027 140078257940480 replay_runner.py:36] Average training steps per second: 321.70
I0828 10:49:58.913656 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.89
INFO:tensorflow:Starting iteration 21
I0828 10:50:02.230247 140078257940480 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 322.60

Steps executed: 1000 Episode length: 1000 Return: 33.0760699048377283
I0828 10:50:07.889054 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: 33.08
INFO:tensorflow:Starting iteration 22
I0828 10:50:11.341069 140078257940480 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 343.73

Steps executed: 1000 Episode length: 1000 Return: 44.0521133596585843
I0828 10:50:16.584175 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: 44.05
INFO:tensorflow:Starting iteration 23

Steps executed: 244 Episode length: 90 Return: -2.1926791765934723843
INFO:tensorflow:Average training steps per second: 333.65
I0828 10:50:22.881752 140078257940480 replay_runner.py:36] Average training steps per second: 333.65
I0828 10:50:23.029366 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -27.09
INFO:tensorflow:Starting iteration 24

Steps executed: 256 Episode length: 117 Return: -100.2394848198291343
INFO:tensorflow:Average training steps per second: 350.99
I0828 10:50:29.142703 140078257940480 replay_runner.py:36] Average training steps per second: 350.99
I0828 10:50:29.289091 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.30
INFO:tensorflow:Starting iteration 25

Steps executed: 139 Episode length: 139 Return: -136.0615823477564343
INFO:tensorflow:Average training steps per second: 320.84

Steps executed: 796 Episode length: 657 Return: -56.64061918431155443
I0828 10:50:36.625399 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.35
INFO:tensorflow:Starting iteration 26
I0828 10:50:39.721082 140078257940480 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 327.70

Steps executed: 1000 Episode length: 1000 Return: -38.622908217028396
I0828 10:50:45.359634 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -38.62
INFO:tensorflow:Starting iteration 27
I0828 10:50:48.528205 140078257940480 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 327.42

Steps executed: 955 Episode length: 955 Return: -521.1670425179773396
I0828 10:50:53.823297 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -521.17
INFO:tensorflow:Starting iteration 28
I0828 10:50:57.220252 140078257940480 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 337.08

Steps executed: 1000 Episode length: 1000 Return: -114.35860933605868
I0828 10:51:01.953072 140078257940480 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.36
INFO:tensorflow:Starting iteration 29
I0828 10:51:05.351461 140078257940480 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 318.62

Steps executed: 334 Episode length: 334 Return: 2.6080646186521795868

Done fixed training!Episode length: 334 Return: 2.6080646186521795868