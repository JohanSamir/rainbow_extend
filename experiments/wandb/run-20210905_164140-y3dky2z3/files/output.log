I0905 16:41:46.426296 139803301922816 run_experiment.py:549] Creating TrainRunner ...
I0905 16:41:46.435841 139803301922816 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:41:46.435980 139803301922816 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:41:46.436055 139803301922816 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:41:46.436127 139803301922816 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:41:46.436190 139803301922816 dqn_agent.py:275] 	 update_period: 4
I0905 16:41:46.436274 139803301922816 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:41:46.436384 139803301922816 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:41:46.436470 139803301922816 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:41:46.436540 139803301922816 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:41:46.436630 139803301922816 dqn_agent.py:280] 	 optimizer: adam
I0905 16:41:46.436705 139803301922816 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:41:46.436796 139803301922816 dqn_agent.py:283] 	 seed: 1630860106435799
I0905 16:41:46.438543 139803301922816 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:41:46.438658 139803301922816 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:41:46.438733 139803301922816 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:41:46.438800 139803301922816 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:41:46.438858 139803301922816 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:41:46.438929 139803301922816 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:41:46.438986 139803301922816 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:41:46.439066 139803301922816 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:41:46.439150 139803301922816 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:41:47.629430 139803301922816 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0905 16:41:48.226413 139803301922816 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:41:48.235675 139803301922816 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:41:48.241239 139803301922816 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:41:48.241377 139803301922816 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:41:48.241481 139803301922816 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:41:48.241552 139803301922816 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:41:48.241608 139803301922816 dqn_agent.py:275] 	 update_period: 4
I0905 16:41:48.241689 139803301922816 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:41:48.241752 139803301922816 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:41:48.241830 139803301922816 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:41:48.241901 139803301922816 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:41:48.241968 139803301922816 dqn_agent.py:280] 	 optimizer: adam
I0905 16:41:48.242042 139803301922816 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:41:48.242116 139803301922816 dqn_agent.py:283] 	 seed: 1630860108241212
I0905 16:41:48.243518 139803301922816 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:41:48.243662 139803301922816 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:41:48.243740 139803301922816 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:41:48.243808 139803301922816 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:41:48.243864 139803301922816 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:41:48.243939 139803301922816 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:41:48.244024 139803301922816 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:41:48.244090 139803301922816 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:41:48.244169 139803301922816 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:41:48.263885 139803301922816 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:41:48.277228 139803301922816 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:41:48.277426 139803301922816 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 223.87
I0905 16:41:52.744539 139803301922816 replay_runner.py:36] Average training steps per second: 223.87
I0905 16:41:54.038986 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.91
Steps executed: 302 Episode length: 160 Return: -189.00060758538928
INFO:tensorflow:Starting iteration 1

Steps executed: 284 Episode length: 155 Return: -246.27100565355628
INFO:tensorflow:Average training steps per second: 275.40
I0905 16:42:01.052685 139803301922816 replay_runner.py:36] Average training steps per second: 275.40
I0905 16:42:01.331646 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.26
INFO:tensorflow:Starting iteration 2
I0905 16:42:04.872542 139803301922816 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 284.39

Steps executed: 295 Episode length: 152 Return: -264.68219366194285
I0905 16:42:08.656392 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.27
INFO:tensorflow:Starting iteration 3
I0905 16:42:12.450811 139803301922816 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 301.25

Steps executed: 834 Episode length: 834 Return: -279.02402787006735
I0905 16:42:17.126693 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.02
INFO:tensorflow:Starting iteration 4
I0905 16:42:21.339193 139803301922816 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 257.91

Steps executed: 1000 Episode length: 1000 Return: -151.62300046779092
I0905 16:42:27.370404 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.62
INFO:tensorflow:Starting iteration 5
I0905 16:42:31.528638 139803301922816 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 248.22

Steps executed: 1000 Episode length: 1000 Return: -126.84157784064656
I0905 16:42:39.159816 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.84
INFO:tensorflow:Starting iteration 6
I0905 16:42:43.159207 139803301922816 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 236.07
I0905 16:42:47.395764 139803301922816 replay_runner.py:36] Average training steps per second: 236.07

Steps executed: 1000 Episode length: 1000 Return: -445.75587637812686
INFO:tensorflow:Starting iteration 7
I0905 16:42:54.072169 139803301922816 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 235.52

Steps executed: 394 Episode length: 394 Return: -498.5333802712704686
I0905 16:42:58.907511 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -498.53
INFO:tensorflow:Starting iteration 8

Steps executed: 573 Episode length: 573 Return: -263.3263927125606686
INFO:tensorflow:Average training steps per second: 251.24
I0905 16:43:06.890213 139803301922816 replay_runner.py:36] Average training steps per second: 251.24
I0905 16:43:08.170695 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.33
INFO:tensorflow:Starting iteration 9

Steps executed: 274 Episode length: 274 Return: -193.0079357390566686
INFO:tensorflow:Average training steps per second: 236.96
I0905 16:43:16.452471 139803301922816 replay_runner.py:36] Average training steps per second: 236.96
I0905 16:43:16.820992 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.01
INFO:tensorflow:Starting iteration 10

Steps executed: 281 Episode length: 281 Return: -334.6237388757141686
INFO:tensorflow:Average training steps per second: 247.31
I0905 16:43:25.014336 139803301922816 replay_runner.py:36] Average training steps per second: 247.31
I0905 16:43:25.371163 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -334.62
INFO:tensorflow:Starting iteration 11
I0905 16:43:29.463283 139803301922816 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 261.74

Steps executed: 964 Episode length: 964 Return: -792.3442733118051686
I0905 16:43:35.976586 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -792.34
INFO:tensorflow:Starting iteration 12
I0905 16:43:40.250639 139803301922816 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 251.22

Steps executed: 1000 Episode length: 1000 Return: -169.34168756085586
I0905 16:43:47.055448 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.34
INFO:tensorflow:Starting iteration 13
I0905 16:43:51.260037 139803301922816 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 266.53

Steps executed: 1000 Episode length: 1000 Return: -213.62916147296283
I0905 16:43:57.735707 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.63
INFO:tensorflow:Starting iteration 14
I0905 16:44:01.752629 139803301922816 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 253.56

Steps executed: 1000 Episode length: 1000 Return: -163.99632524402253
I0905 16:44:07.983467 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.00
INFO:tensorflow:Starting iteration 15
I0905 16:44:12.026729 139803301922816 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 266.36

Steps executed: 1000 Episode length: 1000 Return: -180.21042410023773
I0905 16:44:19.155657 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.21
INFO:tensorflow:Starting iteration 16

Steps executed: 173 Episode length: 173 Return: 5.0124639987976853773
INFO:tensorflow:Average training steps per second: 243.15

Steps executed: 1173 Episode length: 1000 Return: -71.901363200854053
I0905 16:44:29.855743 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -33.44
INFO:tensorflow:Starting iteration 17
I0905 16:44:33.649325 139803301922816 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 226.52

Steps executed: 1000 Episode length: 1000 Return: -157.94820186256172
I0905 16:44:40.614524 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -157.95
INFO:tensorflow:Starting iteration 18

Steps executed: 373 Episode length: 373 Return: -538.3884203894368172
INFO:tensorflow:Average training steps per second: 226.29
I0905 16:44:48.835126 139803301922816 replay_runner.py:36] Average training steps per second: 226.29
I0905 16:44:49.389805 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -538.39
INFO:tensorflow:Starting iteration 19

Steps executed: 311 Episode length: 311 Return: -515.0534888549382172
INFO:tensorflow:Average training steps per second: 237.71
I0905 16:44:57.573401 139803301922816 replay_runner.py:36] Average training steps per second: 237.71
I0905 16:44:58.025429 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -515.05
INFO:tensorflow:Starting iteration 20
I0905 16:45:02.012106 139803301922816 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 246.61

Steps executed: 1000 Episode length: 1000 Return: 16.0389274143018132
I0905 16:45:09.736836 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: 16.04
INFO:tensorflow:Starting iteration 21

Steps executed: 143 Episode length: 143 Return: -20.23516630407040432
INFO:tensorflow:Average training steps per second: 244.25

Steps executed: 621 Episode length: 478 Return: -34.60887801374795532
I0905 16:45:19.044908 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -27.42
INFO:tensorflow:Starting iteration 22
I0905 16:45:23.277150 139803301922816 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 242.67

Steps executed: 1000 Episode length: 1000 Return: 60.9662295130544432
I0905 16:45:31.096796 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: 60.97
INFO:tensorflow:Starting iteration 23

Steps executed: 221 Episode length: 146 Return: -80.44743801455382432
INFO:tensorflow:Average training steps per second: 230.32
I0905 16:45:39.573482 139803301922816 replay_runner.py:36] Average training steps per second: 230.32
I0905 16:45:39.815997 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -6.99
INFO:tensorflow:Starting iteration 24
I0905 16:45:43.857751 139803301922816 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 230.36
I0905 16:45:48.199052 139803301922816 replay_runner.py:36] Average training steps per second: 230.36

Steps executed: 837 Episode length: 837 Return: 181.72465497201318432
INFO:tensorflow:Starting iteration 25
I0905 16:45:54.910392 139803301922816 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 237.93
I0905 16:45:59.113833 139803301922816 replay_runner.py:36] Average training steps per second: 237.93

Steps executed: 970 Episode length: 970 Return: 176.19632458966933432
INFO:tensorflow:Starting iteration 26

Steps executed: 298 Episode length: 147 Return: -483.8841631142771432
INFO:tensorflow:Average training steps per second: 239.40
I0905 16:46:09.242767 139803301922816 replay_runner.py:36] Average training steps per second: 239.40
I0905 16:46:09.483086 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -525.07
INFO:tensorflow:Starting iteration 27

Steps executed: 174 Episode length: 174 Return: -364.1579600047968432
INFO:tensorflow:Average training steps per second: 227.72

Steps executed: 1174 Episode length: 1000 Return: 7.85974223360226432
I0905 16:46:21.219414 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.15
INFO:tensorflow:Starting iteration 28
I0905 16:46:25.251715 139803301922816 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 239.81

Steps executed: 748 Episode length: 748 Return: -356.3062809952711532
I0905 16:46:31.201201 139803301922816 run_experiment.py:428] Average undiscounted return per evaluation episode: -356.31
INFO:tensorflow:Starting iteration 29

Steps executed: 293 Episode length: 293 Return: -478.2802720536735732
INFO:tensorflow:Average training steps per second: 224.44
I0905 16:46:39.403659 139803301922816 replay_runner.py:36] Average training steps per second: 224.44

Done fixed training!Episode length: 293 Return: -478.2802720536735732