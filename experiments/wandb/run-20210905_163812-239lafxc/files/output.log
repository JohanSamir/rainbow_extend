Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0905 16:38:17.371083 140439533856768 run_experiment.py:549] Creating TrainRunner ...
I0905 16:38:17.378194 140439533856768 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:38:17.378310 140439533856768 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:38:17.378371 140439533856768 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:38:17.378452 140439533856768 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:38:17.378549 140439533856768 dqn_agent.py:275] 	 update_period: 4
I0905 16:38:17.378645 140439533856768 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:38:17.378699 140439533856768 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:38:17.378776 140439533856768 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:38:17.378852 140439533856768 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:38:17.378908 140439533856768 dqn_agent.py:280] 	 optimizer: adam
I0905 16:38:17.378960 140439533856768 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:38:17.379032 140439533856768 dqn_agent.py:283] 	 seed: 1630859897378162
I0905 16:38:17.380599 140439533856768 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:38:17.380713 140439533856768 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:38:17.380774 140439533856768 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:38:17.380834 140439533856768 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:38:17.380891 140439533856768 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:38:17.380944 140439533856768 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:38:17.381011 140439533856768 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:38:17.381079 140439533856768 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:38:17.381144 140439533856768 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:38:18.447540 140439533856768 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:38:18.643757 140439533856768 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:38:18.650589 140439533856768 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:38:18.655695 140439533856768 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:38:18.655809 140439533856768 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:38:18.655865 140439533856768 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:38:18.655935 140439533856768 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:38:18.655985 140439533856768 dqn_agent.py:275] 	 update_period: 4
I0905 16:38:18.656031 140439533856768 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:38:18.656081 140439533856768 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:38:18.656166 140439533856768 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:38:18.656227 140439533856768 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:38:18.656283 140439533856768 dqn_agent.py:280] 	 optimizer: adam
I0905 16:38:18.656346 140439533856768 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:38:18.656415 140439533856768 dqn_agent.py:283] 	 seed: 1630859898655671
I0905 16:38:18.657787 140439533856768 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:38:18.657918 140439533856768 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:38:18.657979 140439533856768 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:38:18.658031 140439533856768 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:38:18.658085 140439533856768 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:38:18.658146 140439533856768 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:38:18.658213 140439533856768 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:38:18.658278 140439533856768 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:38:18.658338 140439533856768 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:38:18.674238 140439533856768 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:38:18.685434 140439533856768 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:38:18.685548 140439533856768 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 261.77
I0905 16:38:22.505866 140439533856768 replay_runner.py:36] Average training steps per second: 261.77
Steps executed: 267 Episode length: 147 Return: -446.60127010896616
I0905 16:38:23.393868 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -336.47
INFO:tensorflow:Starting iteration 1

Steps executed: 287 Episode length: 161 Return: -392.61675035090286
INFO:tensorflow:Average training steps per second: 324.75
I0905 16:38:29.624863 140439533856768 replay_runner.py:36] Average training steps per second: 324.75
I0905 16:38:29.802400 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -316.97
INFO:tensorflow:Starting iteration 2

Steps executed: 581 Episode length: 386 Return: -350.51758116609364
INFO:tensorflow:Average training steps per second: 354.98
I0905 16:38:35.999112 140439533856768 replay_runner.py:36] Average training steps per second: 354.98
I0905 16:38:36.484788 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -349.77
INFO:tensorflow:Starting iteration 3
I0905 16:38:39.998392 140439533856768 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 355.91

Steps executed: 833 Episode length: 833 Return: -270.19045162879286
I0905 16:38:43.795372 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.19
INFO:tensorflow:Starting iteration 4
I0905 16:38:47.210162 140439533856768 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 349.30

Steps executed: 1000 Episode length: 1000 Return: -114.39269663586843
I0905 16:38:52.758008 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.39
INFO:tensorflow:Starting iteration 5

Steps executed: 949 Episode length: 949 Return: -300.3845906078322543
INFO:tensorflow:Average training steps per second: 318.76
I0905 16:38:59.176428 140439533856768 replay_runner.py:36] Average training steps per second: 318.76
I0905 16:39:00.484492 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.38
INFO:tensorflow:Starting iteration 6
I0905 16:39:03.747228 140439533856768 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 335.59

Steps executed: 1000 Episode length: 1000 Return: -288.13714864905376
I0905 16:39:08.278399 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.14
INFO:tensorflow:Starting iteration 7

Steps executed: 688 Episode length: 546 Return: -581.4957557625277476
INFO:tensorflow:Average training steps per second: 340.51
I0905 16:39:14.488861 140439533856768 replay_runner.py:36] Average training steps per second: 340.51
I0905 16:39:15.111061 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -536.98
INFO:tensorflow:Starting iteration 8
I0905 16:39:18.516857 140439533856768 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 373.66

Steps executed: 517 Episode length: 517 Return: -334.5789245402669476
I0905 16:39:21.783658 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -334.58
INFO:tensorflow:Starting iteration 9

Steps executed: 276 Episode length: 276 Return: -440.1826892643827676
INFO:tensorflow:Average training steps per second: 381.37
I0905 16:39:27.949767 140439533856768 replay_runner.py:36] Average training steps per second: 381.37
I0905 16:39:28.155989 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -440.18
INFO:tensorflow:Starting iteration 10
I0905 16:39:31.684760 140439533856768 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 350.91

Steps executed: 887 Episode length: 887 Return: -300.6502246622312776
I0905 16:39:36.195803 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.65
INFO:tensorflow:Starting iteration 11
I0905 16:39:39.720177 140439533856768 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 347.34

Steps executed: 1000 Episode length: 1000 Return: -109.92296087810356
I0905 16:39:44.342269 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.92
INFO:tensorflow:Starting iteration 12
I0905 16:39:47.876196 140439533856768 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 357.83

Steps executed: 1000 Episode length: 1000 Return: -235.64952384075727
I0905 16:39:52.210279 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.65
INFO:tensorflow:Starting iteration 13
I0905 16:39:55.682819 140439533856768 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 353.26

Steps executed: 1000 Episode length: 1000 Return: -151.14068458789868
I0905 16:40:01.277291 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.14
INFO:tensorflow:Starting iteration 14

Steps executed: 729 Episode length: 729 Return: -438.6548704424256868
INFO:tensorflow:Average training steps per second: 317.49
I0905 16:40:07.697675 140439533856768 replay_runner.py:36] Average training steps per second: 317.49
I0905 16:40:08.508022 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -438.65
INFO:tensorflow:Starting iteration 15

Steps executed: 215 Episode length: 215 Return: -41.13547034511676868
INFO:tensorflow:Average training steps per second: 330.05
I0905 16:40:14.890260 140439533856768 replay_runner.py:36] Average training steps per second: 330.05
I0905 16:40:15.031209 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -41.14
INFO:tensorflow:Starting iteration 16
I0905 16:40:18.293563 140439533856768 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 338.40

Steps executed: 1000 Episode length: 1000 Return: -105.97083279400614
I0905 16:40:23.742141 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.97
INFO:tensorflow:Starting iteration 17

Steps executed: 283 Episode length: 153 Return: -93.37180677337521514
INFO:tensorflow:Average training steps per second: 333.93
I0905 16:40:30.074676 140439533856768 replay_runner.py:36] Average training steps per second: 333.93
I0905 16:40:30.254228 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.82
INFO:tensorflow:Starting iteration 18

Steps executed: 282 Episode length: 152 Return: -8.577930803385044314
INFO:tensorflow:Average training steps per second: 339.92
I0905 16:40:36.587010 140439533856768 replay_runner.py:36] Average training steps per second: 339.92
I0905 16:40:36.765353 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.15
INFO:tensorflow:Starting iteration 19

Steps executed: 150 Episode length: 82 Return: -138.78862680234604314
INFO:tensorflow:Average training steps per second: 343.16
I0905 16:40:43.134633 140439533856768 replay_runner.py:36] Average training steps per second: 343.16

Steps executed: 265 Episode length: 115 Return: -142.3426534593698414
INFO:tensorflow:Starting iteration 20
I0905 16:40:46.743103 140439533856768 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 377.89

Steps executed: 386 Episode length: 386 Return: -248.5556303284112414
I0905 16:40:49.879728 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.56
INFO:tensorflow:Starting iteration 21

Steps executed: 299 Episode length: 115 Return: -178.9707942798008314
INFO:tensorflow:Average training steps per second: 358.90
I0905 16:40:56.189616 140439533856768 replay_runner.py:36] Average training steps per second: 358.90
I0905 16:40:56.359955 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -50.66
INFO:tensorflow:Starting iteration 22

Steps executed: 207 Episode length: 207 Return: -126.7173574248932814
INFO:tensorflow:Average training steps per second: 366.71
I0905 16:41:02.663775 140439533856768 replay_runner.py:36] Average training steps per second: 366.71
I0905 16:41:02.791758 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.72
INFO:tensorflow:Starting iteration 23

Steps executed: 299 Episode length: 152 Return: -179.4323272450006514
INFO:tensorflow:Average training steps per second: 337.52
I0905 16:41:09.179675 140439533856768 replay_runner.py:36] Average training steps per second: 337.52
I0905 16:41:09.344295 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.88
INFO:tensorflow:Starting iteration 24

Steps executed: 150 Episode length: 150 Return: -107.3264966559703214
INFO:tensorflow:Average training steps per second: 319.78

Steps executed: 1126 Episode length: 976 Return: -89.6473104543931214
I0905 16:41:18.268985 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.49
INFO:tensorflow:Starting iteration 25

Steps executed: 211 Episode length: 211 Return: -257.9976558731372214
INFO:tensorflow:Average training steps per second: 348.54
I0905 16:41:24.644794 140439533856768 replay_runner.py:36] Average training steps per second: 348.54
I0905 16:41:24.780593 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.00
INFO:tensorflow:Starting iteration 26
I0905 16:41:28.159874 140439533856768 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 341.28

Steps executed: 958 Episode length: 958 Return: -99.25751359370662214
I0905 16:41:33.576220 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.26
INFO:tensorflow:Starting iteration 27

Steps executed: 209 Episode length: 209 Return: -110.8070981266285214
INFO:tensorflow:Average training steps per second: 336.89
I0905 16:41:39.907750 140439533856768 replay_runner.py:36] Average training steps per second: 336.89
I0905 16:41:40.046988 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.81
INFO:tensorflow:Starting iteration 28

Steps executed: 538 Episode length: 538 Return: -290.4979504015675514
INFO:tensorflow:Average training steps per second: 296.25
I0905 16:41:46.750785 140439533856768 replay_runner.py:36] Average training steps per second: 296.25
I0905 16:41:47.567848 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.50
INFO:tensorflow:Starting iteration 29

Steps executed: 126 Episode length: 126 Return: -115.5114065250220414
INFO:tensorflow:Average training steps per second: 287.41

Steps executed: 1126 Episode length: 1000 Return: 5.72400715715872614

Done fixed training! Episode length: 1000 Return: 5.72400715715872614