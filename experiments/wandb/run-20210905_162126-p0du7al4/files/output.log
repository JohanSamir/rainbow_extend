I0905 16:21:32.992144 140572166862848 run_experiment.py:549] Creating TrainRunner ...
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0905 16:21:32.992696 140572166862848 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0905 16:21:33.054816 140572166862848 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:21:33.055909 140572166862848 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:21:33.055980 140572166862848 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:21:33.056045 140572166862848 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:21:33.056104 140572166862848 dqn_agent.py:275] 	 update_period: 4
I0905 16:21:33.056160 140572166862848 dqn_agent.py:276] 	 target_update_period: 100
I0905 16:21:33.056213 140572166862848 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:21:33.056298 140572166862848 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:21:33.056450 140572166862848 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:21:33.056524 140572166862848 dqn_agent.py:280] 	 optimizer: adam
I0905 16:21:33.056594 140572166862848 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:21:33.056656 140572166862848 dqn_agent.py:283] 	 seed: 1630858893054753
I0905 16:21:33.058456 140572166862848 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:21:33.058599 140572166862848 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0905 16:21:33.058672 140572166862848 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:21:33.058734 140572166862848 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:21:33.058789 140572166862848 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:21:33.058861 140572166862848 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:21:33.058964 140572166862848 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:21:33.059046 140572166862848 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:21:33.059112 140572166862848 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in acrobot
Training fixed agent 10, please be patient, may be a while...
I0905 16:21:34.753697 140572166862848 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:21:35.083799 140572166862848 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:21:35.185745 140572166862848 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:21:35.190051 140572166862848 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:21:35.190196 140572166862848 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:21:35.190274 140572166862848 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:21:35.190338 140572166862848 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:21:35.190394 140572166862848 dqn_agent.py:275] 	 update_period: 4
I0905 16:21:35.190456 140572166862848 dqn_agent.py:276] 	 target_update_period: 100
I0905 16:21:35.190528 140572166862848 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:21:35.190613 140572166862848 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:21:35.190685 140572166862848 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:21:35.190738 140572166862848 dqn_agent.py:280] 	 optimizer: adam
I0905 16:21:35.190819 140572166862848 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:21:35.190890 140572166862848 dqn_agent.py:283] 	 seed: 1630858895190016
I0905 16:21:35.192287 140572166862848 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:21:35.192421 140572166862848 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0905 16:21:35.192494 140572166862848 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:21:35.192561 140572166862848 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:21:35.192620 140572166862848 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:21:35.192677 140572166862848 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:21:35.192747 140572166862848 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:21:35.192814 140572166862848 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:21:35.192868 140572166862848 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:21:35.213779 140572166862848 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:21:35.225025 140572166862848 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:21:35.225183 140572166862848 replay_runner.py:41] Starting iteration 0
Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 257.95
I0905 16:21:39.102072 140572166862848 replay_runner.py:36] Average training steps per second: 257.95
I0905 16:21:39.815529 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1

Steps executed: 285 Episode length: 136 Return: -135.0
INFO:tensorflow:Average training steps per second: 365.88
I0905 16:21:42.708162 140572166862848 replay_runner.py:36] Average training steps per second: 365.88
I0905 16:21:42.830414 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.50
INFO:tensorflow:Starting iteration 2

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 356.47
I0905 16:21:45.824863 140572166862848 replay_runner.py:36] Average training steps per second: 356.47
I0905 16:21:45.997667 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 3

Steps executed: 237 Episode length: 237 Return: -236.0
INFO:tensorflow:Average training steps per second: 361.92
I0905 16:21:48.920378 140572166862848 replay_runner.py:36] Average training steps per second: 361.92
I0905 16:21:49.005831 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.00
INFO:tensorflow:Starting iteration 4

Steps executed: 200 Episode length: 200 Return: -199.0
INFO:tensorflow:Average training steps per second: 361.98
I0905 16:21:51.927515 140572166862848 replay_runner.py:36] Average training steps per second: 361.98
I0905 16:21:51.995626 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.00
INFO:tensorflow:Starting iteration 5

Steps executed: 370 Episode length: 208 Return: -207.0
INFO:tensorflow:Average training steps per second: 362.69
I0905 16:21:54.910373 140572166862848 replay_runner.py:36] Average training steps per second: 362.69
I0905 16:21:55.043271 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.00
INFO:tensorflow:Starting iteration 6

Steps executed: 216 Episode length: 216 Return: -215.0
INFO:tensorflow:Average training steps per second: 363.84
I0905 16:21:57.951159 140572166862848 replay_runner.py:36] Average training steps per second: 363.84
I0905 16:21:58.028460 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.00
INFO:tensorflow:Starting iteration 7

Steps executed: 280 Episode length: 153 Return: -152.0
INFO:tensorflow:Average training steps per second: 365.31
I0905 16:22:00.930046 140572166862848 replay_runner.py:36] Average training steps per second: 365.31
I0905 16:22:01.029508 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.00
INFO:tensorflow:Starting iteration 8

Steps executed: 270 Episode length: 112 Return: -111.0
INFO:tensorflow:Average training steps per second: 366.38
I0905 16:22:03.919382 140572166862848 replay_runner.py:36] Average training steps per second: 366.38
I0905 16:22:04.011220 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.00
INFO:tensorflow:Starting iteration 9

Steps executed: 301 Episode length: 149 Return: -148.0
INFO:tensorflow:Average training steps per second: 362.96
I0905 16:22:06.925517 140572166862848 replay_runner.py:36] Average training steps per second: 362.96
I0905 16:22:07.028040 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.50
INFO:tensorflow:Starting iteration 10

Steps executed: 288 Episode length: 136 Return: -135.0
INFO:tensorflow:Average training steps per second: 366.79
I0905 16:22:09.912327 140572166862848 replay_runner.py:36] Average training steps per second: 366.79
I0905 16:22:10.009943 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.00
INFO:tensorflow:Starting iteration 11
I0905 16:22:10.166154 140572166862848 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 367.45

Steps executed: 271 Episode length: 130 Return: -129.0
I0905 16:22:12.983909 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.50
INFO:tensorflow:Starting iteration 12

Steps executed: 259 Episode length: 127 Return: -126.0
INFO:tensorflow:Average training steps per second: 366.35
I0905 16:22:15.873107 140572166862848 replay_runner.py:36] Average training steps per second: 366.35
I0905 16:22:15.963424 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.50
INFO:tensorflow:Starting iteration 13

Steps executed: 150 Episode length: 150 Return: -149.0
INFO:tensorflow:Average training steps per second: 360.41

Steps executed: 347 Episode length: 197 Return: -196.0
I0905 16:22:19.018010 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -172.50
INFO:tensorflow:Starting iteration 14

Steps executed: 290 Episode length: 140 Return: -139.0
INFO:tensorflow:Average training steps per second: 363.69
I0905 16:22:21.925885 140572166862848 replay_runner.py:36] Average training steps per second: 363.69
I0905 16:22:22.028954 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.00
INFO:tensorflow:Starting iteration 15

Steps executed: 244 Episode length: 110 Return: -109.0
INFO:tensorflow:Average training steps per second: 364.69
I0905 16:22:24.934422 140572166862848 replay_runner.py:36] Average training steps per second: 364.69
I0905 16:22:25.019736 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.00
INFO:tensorflow:Starting iteration 16

Steps executed: 260 Episode length: 168 Return: -167.0
INFO:tensorflow:Average training steps per second: 366.35
I0905 16:22:27.907966 140572166862848 replay_runner.py:36] Average training steps per second: 366.35
I0905 16:22:27.998309 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.00
INFO:tensorflow:Starting iteration 17

Steps executed: 229 Episode length: 111 Return: -110.0
INFO:tensorflow:Average training steps per second: 363.70
I0905 16:22:30.905730 140572166862848 replay_runner.py:36] Average training steps per second: 363.70
I0905 16:22:30.983869 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.50
INFO:tensorflow:Starting iteration 18

Steps executed: 289 Episode length: 144 Return: -143.0
INFO:tensorflow:Average training steps per second: 363.94
I0905 16:22:33.889887 140572166862848 replay_runner.py:36] Average training steps per second: 363.94
I0905 16:22:33.989399 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.50
INFO:tensorflow:Starting iteration 19

Steps executed: 302 Episode length: 155 Return: -154.0
INFO:tensorflow:Average training steps per second: 360.73
I0905 16:22:36.918977 140572166862848 replay_runner.py:36] Average training steps per second: 360.73
I0905 16:22:37.023489 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -150.00
INFO:tensorflow:Starting iteration 20

Steps executed: 289 Episode length: 171 Return: -170.0
INFO:tensorflow:Average training steps per second: 362.41
I0905 16:22:39.940844 140572166862848 replay_runner.py:36] Average training steps per second: 362.41
I0905 16:22:40.039281 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.50
INFO:tensorflow:Starting iteration 21
I0905 16:22:40.195783 140572166862848 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 366.08
I0905 16:22:42.927698 140572166862848 replay_runner.py:36] Average training steps per second: 366.08
I0905 16:22:43.014371 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.00
INFO:tensorflow:Starting iteration 22


Steps executed: 272 Episode length: 132 Return: -131.0
INFO:tensorflow:Average training steps per second: 368.46
I0905 16:22:45.885088 140572166862848 replay_runner.py:36] Average training steps per second: 368.46
I0905 16:22:45.980458 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.00
INFO:tensorflow:Starting iteration 23

Steps executed: 239 Episode length: 117 Return: -116.0
INFO:tensorflow:Average training steps per second: 364.21
I0905 16:22:48.882602 140572166862848 replay_runner.py:36] Average training steps per second: 364.21
I0905 16:22:48.966989 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.50
INFO:tensorflow:Starting iteration 24

Steps executed: 235 Episode length: 129 Return: -128.0
INFO:tensorflow:Average training steps per second: 364.98
I0905 16:22:51.868966 140572166862848 replay_runner.py:36] Average training steps per second: 364.98
I0905 16:22:51.947965 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.50
INFO:tensorflow:Starting iteration 25

Steps executed: 110 Episode length: 110 Return: -109.0
INFO:tensorflow:Average training steps per second: 368.18

Steps executed: 278 Episode length: 168 Return: -167.0
I0905 16:22:54.921689 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.00
INFO:tensorflow:Starting iteration 26

Steps executed: 304 Episode length: 112 Return: -111.0
INFO:tensorflow:Average training steps per second: 367.16
I0905 16:22:57.802307 140572166862848 replay_runner.py:36] Average training steps per second: 367.16
I0905 16:22:57.905923 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.33
INFO:tensorflow:Starting iteration 27

Steps executed: 177 Episode length: 82 Return: -81.0.0
INFO:tensorflow:Average training steps per second: 356.38

Steps executed: 286 Episode length: 109 Return: -108.0
I0905 16:23:00.973421 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.33
INFO:tensorflow:Starting iteration 28

Steps executed: 299 Episode length: 109 Return: -108.0
INFO:tensorflow:Average training steps per second: 352.39
I0905 16:23:03.972321 140572166862848 replay_runner.py:36] Average training steps per second: 352.39
I0905 16:23:04.078603 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.67
INFO:tensorflow:Starting iteration 29

Steps executed: 109 Episode length: 109 Return: -108.0
INFO:tensorflow:Average training steps per second: 368.72

Done fixed training!Episode length: 111 Return: -110.0
I0905 16:23:07.026039 140572166862848 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.00