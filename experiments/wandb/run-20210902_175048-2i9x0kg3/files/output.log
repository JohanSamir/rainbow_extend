Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0902 17:50:55.044387 140131099109376 run_experiment.py:549] Creating TrainRunner ...
I0902 17:50:55.058498 140131099109376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:50:55.058775 140131099109376 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:50:55.058977 140131099109376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:50:55.059125 140131099109376 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:50:55.059362 140131099109376 dqn_agent.py:275] 	 update_period: 4
I0902 17:50:55.059488 140131099109376 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:50:55.059598 140131099109376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:50:55.059693 140131099109376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:50:55.059795 140131099109376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:50:55.059927 140131099109376 dqn_agent.py:280] 	 optimizer: adam
I0902 17:50:55.059995 140131099109376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:50:55.060249 140131099109376 dqn_agent.py:283] 	 seed: 1630605055058426
I0902 17:50:55.063424 140131099109376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:50:55.063561 140131099109376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:50:55.063639 140131099109376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:50:55.063701 140131099109376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:50:55.063758 140131099109376 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:50:55.063813 140131099109376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:50:55.063868 140131099109376 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:50:55.063919 140131099109376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:50:55.063971 140131099109376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:50:55.102200 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:50:55.589221 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:50:55.603065 140131099109376 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 17:50:55.611059 140131099109376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:50:55.611291 140131099109376 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:50:55.611397 140131099109376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:50:55.611522 140131099109376 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:50:55.611633 140131099109376 dqn_agent.py:275] 	 update_period: 4
I0902 17:50:55.611707 140131099109376 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:50:55.611801 140131099109376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:50:55.611861 140131099109376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:50:55.611919 140131099109376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:50:55.611975 140131099109376 dqn_agent.py:280] 	 optimizer: adam
I0902 17:50:55.612093 140131099109376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:50:55.612205 140131099109376 dqn_agent.py:283] 	 seed: 1630605055611011
I0902 17:50:55.615266 140131099109376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:50:55.615493 140131099109376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:50:55.615700 140131099109376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:50:55.615810 140131099109376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:50:55.615888 140131099109376 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:50:55.616043 140131099109376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:50:55.616221 140131099109376 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:50:55.616351 140131099109376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:50:55.616461 140131099109376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:50:55.647769 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:50:55.667995 140131099109376 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 17:50:55.668211 140131099109376 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 167.79
I0902 17:51:01.628288 140131099109376 replay_runner.py:36] Average training steps per second: 167.79
Steps executed: 243 Episode length: 166 Return: -436.4861874987259
I0902 17:51:02.862441 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -440.10
INFO:tensorflow:Starting iteration 1

Steps executed: 414 Episode length: 264 Return: 257.97808752482184
INFO:tensorflow:Average training steps per second: 232.85
I0902 17:51:11.555718 140131099109376 replay_runner.py:36] Average training steps per second: 232.85
I0902 17:51:11.947695 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -55.05
INFO:tensorflow:Starting iteration 2
I0902 17:51:16.354614 140131099109376 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 227.15

Steps executed: 299 Episode length: 165 Return: -221.58257489181972
I0902 17:51:21.028220 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.67
INFO:tensorflow:Starting iteration 3

Steps executed: 222 Episode length: 222 Return: -89.278392234272352
INFO:tensorflow:Average training steps per second: 232.82
I0902 17:51:29.688847 140131099109376 replay_runner.py:36] Average training steps per second: 232.82
I0902 17:51:29.895127 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.28
INFO:tensorflow:Starting iteration 4
I0902 17:51:34.217558 140131099109376 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 227.89

Steps executed: 289 Episode length: 289 Return: -198.76895721882582
I0902 17:51:38.946166 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.77
INFO:tensorflow:Starting iteration 5

Steps executed: 344 Episode length: 260 Return: -112.28533930229272
INFO:tensorflow:Average training steps per second: 233.15
I0902 17:51:47.580195 140131099109376 replay_runner.py:36] Average training steps per second: 233.15
I0902 17:51:47.912072 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.15
INFO:tensorflow:Starting iteration 6
I0902 17:51:52.306848 140131099109376 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 231.63
I0902 17:51:56.624562 140131099109376 replay_runner.py:36] Average training steps per second: 231.63

Steps executed: 208 Episode length: 208 Return: -238.77574834882674
INFO:tensorflow:Starting iteration 7

Steps executed: 292 Episode length: 135 Return: -272.76029335610133
INFO:tensorflow:Average training steps per second: 234.79
I0902 17:52:05.403393 140131099109376 replay_runner.py:36] Average training steps per second: 234.79
I0902 17:52:05.661418 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.38
INFO:tensorflow:Starting iteration 8

Steps executed: 240 Episode length: 84 Return: -351.840353808240763
INFO:tensorflow:Average training steps per second: 226.17
I0902 17:52:14.486886 140131099109376 replay_runner.py:36] Average training steps per second: 226.17
I0902 17:52:14.716834 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -315.49
INFO:tensorflow:Starting iteration 9

Steps executed: 213 Episode length: 87 Return: -332.305368129970503
INFO:tensorflow:Average training steps per second: 228.78
I0902 17:52:23.097963 140131099109376 replay_runner.py:36] Average training steps per second: 228.78
I0902 17:52:23.280913 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.65
INFO:tensorflow:Starting iteration 10

Steps executed: 320 Episode length: 140 Return: -338.80904119877023
INFO:tensorflow:Average training steps per second: 229.13
I0902 17:52:32.062684 140131099109376 replay_runner.py:36] Average training steps per second: 229.13
I0902 17:52:32.327334 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.83
INFO:tensorflow:Starting iteration 11
I0902 17:52:36.745157 140131099109376 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 226.02

Steps executed: 339 Episode length: 171 Return: -835.60430182763093
I0902 17:52:41.489913 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -547.47
INFO:tensorflow:Starting iteration 12

Steps executed: 205 Episode length: 205 Return: -373.34280272922035
INFO:tensorflow:Average training steps per second: 224.59
I0902 17:52:50.282896 140131099109376 replay_runner.py:36] Average training steps per second: 224.59
I0902 17:52:50.473053 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -373.34
INFO:tensorflow:Starting iteration 13
I0902 17:52:54.793029 140131099109376 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 231.93

Steps executed: 277 Episode length: 182 Return: -801.63449846113415
I0902 17:52:59.361660 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -546.96
INFO:tensorflow:Starting iteration 14

Steps executed: 207 Episode length: 207 Return: -885.61466439469715
INFO:tensorflow:Average training steps per second: 244.86
I0902 17:53:07.692709 140131099109376 replay_runner.py:36] Average training steps per second: 244.86
I0902 17:53:07.892159 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -885.61
INFO:tensorflow:Starting iteration 15

Steps executed: 268 Episode length: 99 Return: -214.833737915669265
INFO:tensorflow:Average training steps per second: 233.36
I0902 17:53:16.465404 140131099109376 replay_runner.py:36] Average training steps per second: 233.36
I0902 17:53:16.702480 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -497.30
INFO:tensorflow:Starting iteration 16

Steps executed: 254 Episode length: 254 Return: -712.01565688742365
INFO:tensorflow:Average training steps per second: 234.94
I0902 17:53:25.047268 140131099109376 replay_runner.py:36] Average training steps per second: 234.94
I0902 17:53:25.343690 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -712.02
INFO:tensorflow:Starting iteration 17

Steps executed: 464 Episode length: 362 Return: -289.62110235285365
INFO:tensorflow:Average training steps per second: 230.74
I0902 17:53:34.001812 140131099109376 replay_runner.py:36] Average training steps per second: 230.74
I0902 17:53:34.521278 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.13
INFO:tensorflow:Starting iteration 18
I0902 17:53:38.818572 140131099109376 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 244.37
I0902 17:53:42.911014 140131099109376 replay_runner.py:36] Average training steps per second: 244.37

Steps executed: 395 Episode length: 218 Return: -887.97630313310225
INFO:tensorflow:Starting iteration 19

Steps executed: 266 Episode length: 84 Return: -475.796930423458585
INFO:tensorflow:Average training steps per second: 239.10
I0902 17:53:51.659985 140131099109376 replay_runner.py:36] Average training steps per second: 239.10
I0902 17:53:51.917238 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -367.33
INFO:tensorflow:Starting iteration 20

Steps executed: 206 Episode length: 206 Return: -854.64157563075225
INFO:tensorflow:Average training steps per second: 230.01
I0902 17:54:00.711534 140131099109376 replay_runner.py:36] Average training steps per second: 230.01
I0902 17:54:00.923163 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -854.64
INFO:tensorflow:Starting iteration 21

Steps executed: 502 Episode length: 314 Return: -795.11674539732425
INFO:tensorflow:Average training steps per second: 222.40
I0902 17:54:09.914182 140131099109376 replay_runner.py:36] Average training steps per second: 222.40
I0902 17:54:10.446035 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -532.71
INFO:tensorflow:Starting iteration 22
I0902 17:54:14.712157 140131099109376 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 226.24

Steps executed: 343 Episode length: 246 Return: -612.29198077844825
I0902 17:54:19.473162 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.93
INFO:tensorflow:Starting iteration 23

Steps executed: 310 Episode length: 199 Return: -227.63331688310421
INFO:tensorflow:Average training steps per second: 222.94
I0902 17:54:28.191087 140131099109376 replay_runner.py:36] Average training steps per second: 222.94
I0902 17:54:28.511247 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.66
INFO:tensorflow:Starting iteration 24

Steps executed: 162 Episode length: 162 Return: -281.33722382223226
INFO:tensorflow:Average training steps per second: 220.62
I0902 17:54:37.105949 140131099109376 replay_runner.py:36] Average training steps per second: 220.62

Steps executed: 266 Episode length: 104 Return: -218.03258605448566
INFO:tensorflow:Starting iteration 25

Steps executed: 241 Episode length: 131 Return: -233.54472150961874
INFO:tensorflow:Average training steps per second: 222.45
I0902 17:54:45.800336 140131099109376 replay_runner.py:36] Average training steps per second: 222.45
I0902 17:54:46.012418 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.24
INFO:tensorflow:Starting iteration 26

Steps executed: 248 Episode length: 248 Return: -146.89957583778874
INFO:tensorflow:Average training steps per second: 228.93
I0902 17:54:54.729196 140131099109376 replay_runner.py:36] Average training steps per second: 228.93
I0902 17:54:54.966464 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.90
INFO:tensorflow:Starting iteration 27

Steps executed: 289 Episode length: 102 Return: -304.38812299774134
INFO:tensorflow:Average training steps per second: 222.49
I0902 17:55:03.912751 140131099109376 replay_runner.py:36] Average training steps per second: 222.49
I0902 17:55:04.166873 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.87
INFO:tensorflow:Starting iteration 28

Steps executed: 232 Episode length: 232 Return: -608.09139947155794
INFO:tensorflow:Average training steps per second: 223.46
I0902 17:55:12.952528 140131099109376 replay_runner.py:36] Average training steps per second: 223.46
I0902 17:55:13.209142 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -608.09
INFO:tensorflow:Starting iteration 29

Steps executed: 280 Episode length: 280 Return: -184.83469941622556
INFO:tensorflow:Average training steps per second: 227.88
I0902 17:55:21.978129 140131099109376 replay_runner.py:36] Average training steps per second: 227.88

Done fixed training!Episode length: 280 Return: -184.83469941622556