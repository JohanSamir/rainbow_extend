I0901 23:43:54.441448 139752435963904 run_experiment.py:549] Creating TrainRunner ...
I0901 23:43:54.452972 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:43:54.453182 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:43:54.453348 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:43:54.453571 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:43:54.453731 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0901 23:43:54.454069 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:43:54.454203 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:43:54.454407 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:43:54.454651 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:43:54.454868 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0901 23:43:54.454982 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:43:54.455132 139752435963904 dqn_agent.py:283] 	 seed: 1630539834452920
I0901 23:43:54.458028 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:43:54.458196 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:43:54.458399 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:43:54.458489 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:43:54.458557 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:43:54.458620 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:43:54.458678 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:43:54.458738 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:43:54.459020 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:43:55.939922 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0901 23:43:56.442781 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:43:56.457896 139752435963904 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:43:56.469772 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:43:56.470027 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:43:56.470192 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:43:56.470382 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:43:56.470482 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0901 23:43:56.470573 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:43:56.470666 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:43:56.470772 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:43:56.470866 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:43:56.470952 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0901 23:43:56.471039 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:43:56.471126 139752435963904 dqn_agent.py:283] 	 seed: 1630539836469709
I0901 23:43:56.474047 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:43:56.474309 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:43:56.474467 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:43:56.474622 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:43:56.474783 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:43:56.474900 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:43:56.475001 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:43:56.475147 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:43:56.475257 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:43:56.506884 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:43:56.529136 139752435963904 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:43:56.529439 139752435963904 replay_runner.py:41] Starting iteration 0
Steps executed: 328 Episode length: 328 Return: -307.375611090603
INFO:tensorflow:Average training steps per second: 163.18
I0901 23:44:02.657987 139752435963904 replay_runner.py:36] Average training steps per second: 163.18
I0901 23:44:04.093202 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.38
INFO:tensorflow:Starting iteration 1

Steps executed: 320 Episode length: 160 Return: -218.77381233792382
INFO:tensorflow:Average training steps per second: 237.24
I0901 23:44:12.467469 139752435963904 replay_runner.py:36] Average training steps per second: 237.24
I0901 23:44:12.782474 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.11
INFO:tensorflow:Starting iteration 2

Steps executed: 340 Episode length: 173 Return: -458.12806944712077
INFO:tensorflow:Average training steps per second: 228.36
I0901 23:44:21.509060 139752435963904 replay_runner.py:36] Average training steps per second: 228.36
I0901 23:44:21.814337 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -423.92
INFO:tensorflow:Starting iteration 3

Steps executed: 272 Episode length: 123 Return: -415.56746186470977
INFO:tensorflow:Average training steps per second: 235.02
I0901 23:44:30.490876 139752435963904 replay_runner.py:36] Average training steps per second: 235.02
I0901 23:44:30.702783 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.42
INFO:tensorflow:Starting iteration 4
I0901 23:44:34.849490 139752435963904 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 230.72

Steps executed: 1000 Episode length: 1000 Return: -199.63255577462226
I0901 23:44:41.139246 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.63
INFO:tensorflow:Starting iteration 5
I0901 23:44:45.375059 139752435963904 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 229.86

Steps executed: 1000 Episode length: 1000 Return: -198.29320540870884
I0901 23:44:52.145752 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.29
INFO:tensorflow:Starting iteration 6
I0901 23:44:56.755369 139752435963904 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 221.01

Steps executed: 1000 Episode length: 1000 Return: -274.29907218127874
I0901 23:45:03.363897 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.30
INFO:tensorflow:Starting iteration 7
I0901 23:45:07.697073 139752435963904 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 220.56

Steps executed: 856 Episode length: 856 Return: -291.3451168073499874
I0901 23:45:14.241266 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -291.35
INFO:tensorflow:Starting iteration 8
I0901 23:45:18.458546 139752435963904 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 217.57

Steps executed: 858 Episode length: 858 Return: -329.7204352556422874
I0901 23:45:25.076093 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.72
INFO:tensorflow:Starting iteration 9
I0901 23:45:29.469291 139752435963904 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 217.25

Steps executed: 662 Episode length: 662 Return: -398.5486913550758574
I0901 23:45:35.836225 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -398.55
INFO:tensorflow:Starting iteration 10
I0901 23:45:39.871968 139752435963904 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 218.26

Steps executed: 611 Episode length: 611 Return: -578.1255132848296574
I0901 23:45:45.746402 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -578.13
INFO:tensorflow:Starting iteration 11
I0901 23:45:50.057531 139752435963904 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 217.43

Steps executed: 874 Episode length: 874 Return: -329.2571392491029574
I0901 23:45:57.016548 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.26
INFO:tensorflow:Starting iteration 12

Steps executed: 308 Episode length: 308 Return: -370.7594466620124574
INFO:tensorflow:Average training steps per second: 216.22
I0901 23:46:05.990104 139752435963904 replay_runner.py:36] Average training steps per second: 216.22
I0901 23:46:06.420235 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -370.76
INFO:tensorflow:Starting iteration 13
I0901 23:46:10.710794 139752435963904 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 222.28

Steps executed: 1000 Episode length: 1000 Return: -136.89627819248997
I0901 23:46:17.922990 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.90
INFO:tensorflow:Starting iteration 14
I0901 23:46:22.292325 139752435963904 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 221.18
I0901 23:46:26.814615 139752435963904 replay_runner.py:36] Average training steps per second: 221.18

Steps executed: 681 Episode length: 681 Return: -44.30216204323146997
INFO:tensorflow:Starting iteration 15

Steps executed: 289 Episode length: 210 Return: -12.05345042812750597
INFO:tensorflow:Average training steps per second: 223.89
I0901 23:46:37.378393 139752435963904 replay_runner.py:36] Average training steps per second: 223.89
I0901 23:46:37.668647 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -49.75
INFO:tensorflow:Starting iteration 16

Steps executed: 212 Episode length: 212 Return: -189.2441655048908797
INFO:tensorflow:Average training steps per second: 217.00
I0901 23:46:46.600101 139752435963904 replay_runner.py:36] Average training steps per second: 217.00
I0901 23:46:46.838284 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.24
INFO:tensorflow:Starting iteration 17

Steps executed: 325 Episode length: 159 Return: -112.6717387722879897
INFO:tensorflow:Average training steps per second: 225.44
I0901 23:46:55.625328 139752435963904 replay_runner.py:36] Average training steps per second: 225.44
I0901 23:46:55.909818 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.11
INFO:tensorflow:Starting iteration 18

Steps executed: 558 Episode length: 558 Return: 214.56851746226369897
INFO:tensorflow:Average training steps per second: 223.15
I0901 23:47:04.746491 139752435963904 replay_runner.py:36] Average training steps per second: 223.15
I0901 23:47:05.867394 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: 214.57
INFO:tensorflow:Starting iteration 19
I0901 23:47:09.881921 139752435963904 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 220.10

Steps executed: 304 Episode length: 141 Return: -49.75717288994682897
I0901 23:47:14.736056 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.41
INFO:tensorflow:Starting iteration 20

Steps executed: 402 Episode length: 281 Return: -49.00511827016323897
INFO:tensorflow:Average training steps per second: 226.94
I0901 23:47:23.181850 139752435963904 replay_runner.py:36] Average training steps per second: 226.94
I0901 23:47:23.655513 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.98
INFO:tensorflow:Starting iteration 21

Steps executed: 72 Episode length: 72 Return: -179.648536185115663897
INFO:tensorflow:Average training steps per second: 231.36

Steps executed: 623 Episode length: 551 Return: -21.37232373732503397
I0901 23:47:33.396751 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.51
INFO:tensorflow:Starting iteration 22

Steps executed: 319 Episode length: 131 Return: -35.12459874138943497
INFO:tensorflow:Average training steps per second: 238.47
I0901 23:47:41.756989 139752435963904 replay_runner.py:36] Average training steps per second: 238.47
I0901 23:47:42.070093 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -16.99
INFO:tensorflow:Starting iteration 23
I0901 23:47:46.326454 139752435963904 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 228.92

Steps executed: 359 Episode length: 359 Return: -0.838441179059344797
I0901 23:47:51.267961 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -0.84
INFO:tensorflow:Starting iteration 24
I0901 23:47:55.659877 139752435963904 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 222.09
I0901 23:48:00.163002 139752435963904 replay_runner.py:36] Average training steps per second: 222.09

Steps executed: 422 Episode length: 422 Return: -257.3476621100028397
INFO:tensorflow:Starting iteration 25
I0901 23:48:05.293284 139752435963904 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 223.59

Steps executed: 798 Episode length: 798 Return: -74.74538090380011397
I0901 23:48:11.875668 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.75
INFO:tensorflow:Starting iteration 26
I0901 23:48:16.089479 139752435963904 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 224.32

Steps executed: 1000 Episode length: 1000 Return: 44.8947841104273957
I0901 23:48:23.727509 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: 44.89
INFO:tensorflow:Starting iteration 27

Steps executed: 226 Episode length: 226 Return: 28.758229397711546957
INFO:tensorflow:Average training steps per second: 223.32
I0901 23:48:32.491698 139752435963904 replay_runner.py:36] Average training steps per second: 223.32
I0901 23:48:32.749034 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: 28.76
INFO:tensorflow:Starting iteration 28

Steps executed: 364 Episode length: 188 Return: -4.673628547174928657
INFO:tensorflow:Average training steps per second: 226.38
I0901 23:48:41.489991 139752435963904 replay_runner.py:36] Average training steps per second: 226.38
I0901 23:48:41.873715 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -27.29
INFO:tensorflow:Starting iteration 29

Steps executed: 358 Episode length: 358 Return: -58.97680617090727657
INFO:tensorflow:Average training steps per second: 232.54
I0901 23:48:50.453533 139752435963904 replay_runner.py:36] Average training steps per second: 232.54

Done fixed training!Episode length: 358 Return: -58.97680617090727657