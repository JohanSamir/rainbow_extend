Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0903 00:19:25.699667 140457530894336 run_experiment.py:549] Creating TrainRunner ...
I0903 00:19:25.707379 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:19:25.707531 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:19:25.707619 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:19:25.707690 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:19:25.707752 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0903 00:19:25.707842 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:19:25.707928 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:19:25.708026 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:19:25.708109 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:19:25.708186 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0903 00:19:25.708262 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:19:25.708361 140457530894336 dqn_agent.py:283] 	 seed: 1630628365707338
I0903 00:19:25.710249 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:19:25.710364 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:19:25.710434 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:19:25.710498 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:19:25.710555 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:19:25.710622 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:19:25.710702 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:19:25.710794 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:19:25.710870 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:19:25.734485 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:19:25.964275 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:19:25.972167 140457530894336 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:19:25.978211 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:19:25.978412 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:19:25.978516 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:19:25.978654 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:19:25.978796 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0903 00:19:25.978901 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:19:25.979052 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:19:25.979186 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:19:25.979316 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:19:25.979408 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0903 00:19:25.979492 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:19:25.979573 140457530894336 dqn_agent.py:283] 	 seed: 1630628365978162
I0903 00:19:25.981032 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:19:25.981151 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:19:25.981237 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:19:25.981312 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:19:25.981383 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:19:25.981462 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:19:25.981546 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:19:25.981645 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:19:25.981746 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:19:26.001430 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:19:26.016402 140457530894336 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:19:26.016561 140457530894336 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 228.48
I0903 00:19:30.393573 140457530894336 replay_runner.py:36] Average training steps per second: 228.48
I0903 00:19:31.207038 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.70
Steps executed: 256 Episode length: 124 Return: -74.18948235687714
INFO:tensorflow:Starting iteration 1

Steps executed: 253 Episode length: 113 Return: -345.6064794601452
INFO:tensorflow:Average training steps per second: 320.25
I0903 00:19:37.640814 140457530894336 replay_runner.py:36] Average training steps per second: 320.25
I0903 00:19:37.783135 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -510.24
INFO:tensorflow:Starting iteration 2

Steps executed: 205 Episode length: 96 Return: -455.95685185573378
INFO:tensorflow:Average training steps per second: 327.89
I0903 00:19:44.193531 140457530894336 replay_runner.py:36] Average training steps per second: 327.89
I0903 00:19:44.308298 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -517.48
INFO:tensorflow:Starting iteration 3

Steps executed: 251 Episode length: 61 Return: -632.61663767313458
INFO:tensorflow:Average training steps per second: 319.93
I0903 00:19:50.792377 140457530894336 replay_runner.py:36] Average training steps per second: 319.93
I0903 00:19:50.935710 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -489.76
INFO:tensorflow:Starting iteration 4
I0903 00:19:54.298135 140457530894336 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 312.95
I0903 00:19:57.494037 140457530894336 replay_runner.py:36] Average training steps per second: 312.95

Steps executed: 276 Episode length: 188 Return: -665.8796039863334
INFO:tensorflow:Starting iteration 5

Steps executed: 226 Episode length: 89 Return: -135.587964191144482
INFO:tensorflow:Average training steps per second: 330.97
I0903 00:20:04.052144 140457530894336 replay_runner.py:36] Average training steps per second: 330.97
I0903 00:20:04.189022 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.31
INFO:tensorflow:Starting iteration 6

Steps executed: 241 Episode length: 67 Return: -645.195371793903952
INFO:tensorflow:Average training steps per second: 334.65
I0903 00:20:10.637140 140457530894336 replay_runner.py:36] Average training steps per second: 334.65
I0903 00:20:10.776596 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -476.24
INFO:tensorflow:Starting iteration 7

Steps executed: 221 Episode length: 221 Return: -1689.6980126938942
INFO:tensorflow:Average training steps per second: 332.74
I0903 00:20:17.244074 140457530894336 replay_runner.py:36] Average training steps per second: 332.74
I0903 00:20:17.425764 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -1689.70
INFO:tensorflow:Starting iteration 8

Steps executed: 211 Episode length: 68 Return: -605.293173297014242
INFO:tensorflow:Average training steps per second: 329.50
I0903 00:20:23.905690 140457530894336 replay_runner.py:36] Average training steps per second: 329.50
I0903 00:20:24.036461 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -594.13
INFO:tensorflow:Starting iteration 9

Steps executed: 223 Episode length: 103 Return: -713.03891956179832
INFO:tensorflow:Average training steps per second: 326.31
I0903 00:20:30.541867 140457530894336 replay_runner.py:36] Average training steps per second: 326.31
I0903 00:20:30.687291 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -640.66
INFO:tensorflow:Starting iteration 10

Steps executed: 295 Episode length: 233 Return: -519.22666372283792
INFO:tensorflow:Average training steps per second: 319.91
I0903 00:20:37.276283 140457530894336 replay_runner.py:36] Average training steps per second: 319.91
I0903 00:20:37.469991 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -321.70
INFO:tensorflow:Starting iteration 11

Steps executed: 234 Episode length: 77 Return: -310.245317512644474
INFO:tensorflow:Average training steps per second: 329.28
I0903 00:20:43.974551 140457530894336 replay_runner.py:36] Average training steps per second: 329.28
I0903 00:20:44.120203 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.20
INFO:tensorflow:Starting iteration 12

Steps executed: 372 Episode length: 177 Return: -347.76218055093855
INFO:tensorflow:Average training steps per second: 334.30
I0903 00:20:50.587817 140457530894336 replay_runner.py:36] Average training steps per second: 334.30
I0903 00:20:50.806867 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -370.79
INFO:tensorflow:Starting iteration 13

Steps executed: 237 Episode length: 105 Return: -697.68735306135595
INFO:tensorflow:Average training steps per second: 335.05
I0903 00:20:57.269191 140457530894336 replay_runner.py:36] Average training steps per second: 335.05
I0903 00:20:57.420629 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -615.48
INFO:tensorflow:Starting iteration 14

Steps executed: 247 Episode length: 96 Return: -468.733617878382235
INFO:tensorflow:Average training steps per second: 337.35
I0903 00:21:03.864294 140457530894336 replay_runner.py:36] Average training steps per second: 337.35
I0903 00:21:04.007897 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -431.06
INFO:tensorflow:Starting iteration 15

Steps executed: 208 Episode length: 71 Return: -625.520516118537435
INFO:tensorflow:Average training steps per second: 340.46
I0903 00:21:10.448704 140457530894336 replay_runner.py:36] Average training steps per second: 340.46
I0903 00:21:10.575348 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -633.75
INFO:tensorflow:Starting iteration 16

Steps executed: 223 Episode length: 86 Return: -331.228499900646485
INFO:tensorflow:Average training steps per second: 342.93
I0903 00:21:17.009456 140457530894336 replay_runner.py:36] Average training steps per second: 342.93
I0903 00:21:17.121962 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -320.79
INFO:tensorflow:Starting iteration 17

Steps executed: 262 Episode length: 124 Return: -683.91492295659245
INFO:tensorflow:Average training steps per second: 337.92
I0903 00:21:23.607480 140457530894336 replay_runner.py:36] Average training steps per second: 337.92
I0903 00:21:23.778566 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -775.63
INFO:tensorflow:Starting iteration 18

Steps executed: 246 Episode length: 55 Return: -499.798275573295545
INFO:tensorflow:Average training steps per second: 343.46
I0903 00:21:30.217813 140457530894336 replay_runner.py:36] Average training steps per second: 343.46
I0903 00:21:30.358195 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -489.29
INFO:tensorflow:Starting iteration 19

Steps executed: 217 Episode length: 76 Return: -560.320898835158945
INFO:tensorflow:Average training steps per second: 337.29
I0903 00:21:36.826526 140457530894336 replay_runner.py:36] Average training steps per second: 337.29
I0903 00:21:36.950113 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -566.17
INFO:tensorflow:Starting iteration 20

Steps executed: 210 Episode length: 80 Return: -792.081306404293945
INFO:tensorflow:Average training steps per second: 339.42
I0903 00:21:43.386273 140457530894336 replay_runner.py:36] Average training steps per second: 339.42
I0903 00:21:43.507790 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -651.25
INFO:tensorflow:Starting iteration 21

Steps executed: 245 Episode length: 86 Return: -803.642461779673145
INFO:tensorflow:Average training steps per second: 337.75
I0903 00:21:49.996198 140457530894336 replay_runner.py:36] Average training steps per second: 337.75
I0903 00:21:50.148599 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -810.17
INFO:tensorflow:Starting iteration 22

Steps executed: 200 Episode length: 72 Return: -592.996038740926145
INFO:tensorflow:Average training steps per second: 344.86
I0903 00:21:56.547777 140457530894336 replay_runner.py:36] Average training steps per second: 344.86
I0903 00:21:56.676030 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -549.57
INFO:tensorflow:Starting iteration 23

Steps executed: 227 Episode length: 56 Return: -396.921876720079475
INFO:tensorflow:Average training steps per second: 341.85
I0903 00:22:03.125819 140457530894336 replay_runner.py:36] Average training steps per second: 341.85
I0903 00:22:03.265394 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -460.68
INFO:tensorflow:Starting iteration 24
I0903 00:22:06.761682 140457530894336 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 335.83
I0903 00:22:09.739643 140457530894336 replay_runner.py:36] Average training steps per second: 335.83

Steps executed: 238 Episode length: 55 Return: -386.744639258066235
INFO:tensorflow:Starting iteration 25

Steps executed: 214 Episode length: 61 Return: -486.743245077057175
INFO:tensorflow:Average training steps per second: 339.10
I0903 00:22:16.349595 140457530894336 replay_runner.py:36] Average training steps per second: 339.10
I0903 00:22:16.476150 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -649.17
INFO:tensorflow:Starting iteration 26

Steps executed: 253 Episode length: 63 Return: -581.559906822414975
INFO:tensorflow:Average training steps per second: 338.18
I0903 00:22:22.900477 140457530894336 replay_runner.py:36] Average training steps per second: 338.18
I0903 00:22:23.049907 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -533.83
INFO:tensorflow:Starting iteration 27

Steps executed: 257 Episode length: 74 Return: -609.132847996273875
INFO:tensorflow:Average training steps per second: 347.05
I0903 00:22:29.348973 140457530894336 replay_runner.py:36] Average training steps per second: 347.05
I0903 00:22:29.500632 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -521.95
INFO:tensorflow:Starting iteration 28

Steps executed: 230 Episode length: 50 Return: -327.722929776626535
INFO:tensorflow:Average training steps per second: 361.33
I0903 00:22:35.638937 140457530894336 replay_runner.py:36] Average training steps per second: 361.33
I0903 00:22:35.759736 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -423.28
INFO:tensorflow:Starting iteration 29

Steps executed: 200 Episode length: 75 Return: -700.151611753491735
INFO:tensorflow:Average training steps per second: 378.52
I0903 00:22:41.782946 140457530894336 replay_runner.py:36] Average training steps per second: 378.52

Done fixed training!Episode length: 75 Return: -700.151611753491735