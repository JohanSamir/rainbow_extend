Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0902 00:05:06.582593 139825600018432 run_experiment.py:549] Creating TrainRunner ...
I0902 00:05:06.596157 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:05:06.596553 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:05:06.596741 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:05:06.596856 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:05:06.596961 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0902 00:05:06.597309 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:05:06.597544 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:05:06.597649 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:05:06.597797 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:05:06.597928 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:05:06.598074 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:05:06.598385 139825600018432 dqn_agent.py:283] 	 seed: 1630541106596054
I0902 00:05:06.601001 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:05:06.601154 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:05:06.601328 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:05:06.601678 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:05:06.601909 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:05:06.602053 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:05:06.602296 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:05:06.602450 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:05:06.602573 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:05:06.646749 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:06.997977 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:07.012681 139825600018432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:05:07.035747 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:05:07.036091 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:05:07.036363 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:05:07.036693 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:05:07.036942 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0902 00:05:07.037186 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:05:07.037425 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:05:07.037670 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:05:07.037926 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:05:07.038191 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:05:07.038438 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:05:07.038689 139825600018432 dqn_agent.py:283] 	 seed: 1630541107035692
I0902 00:05:07.042054 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:05:07.042457 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:05:07.042820 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:05:07.043180 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:05:07.043669 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:05:07.044027 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:05:07.044346 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:05:07.044604 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:05:07.044833 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:05:07.144123 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:07.175708 139825600018432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:05:07.176055 139825600018432 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 161.40
I0902 00:05:13.372017 139825600018432 replay_runner.py:36] Average training steps per second: 161.40
Steps executed: 278 Episode length: 111 Return: -175.0791288151743
I0902 00:05:14.735743 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.19
INFO:tensorflow:Starting iteration 1

Steps executed: 293 Episode length: 293 Return: -256.7449765817353
INFO:tensorflow:Average training steps per second: 222.52
I0902 00:05:23.621737 139825600018432 replay_runner.py:36] Average training steps per second: 222.52
I0902 00:05:24.020854 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.74
INFO:tensorflow:Starting iteration 2

Steps executed: 258 Episode length: 153 Return: -405.13916937354185
INFO:tensorflow:Average training steps per second: 222.47
I0902 00:05:32.889972 139825600018432 replay_runner.py:36] Average training steps per second: 222.47
I0902 00:05:33.115003 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -426.57
INFO:tensorflow:Starting iteration 3

Steps executed: 171 Episode length: 171 Return: -435.04721806913885
INFO:tensorflow:Average training steps per second: 226.77
I0902 00:05:41.854415 139825600018432 replay_runner.py:36] Average training steps per second: 226.77

Steps executed: 392 Episode length: 221 Return: -263.49128239620665
INFO:tensorflow:Starting iteration 4

Steps executed: 437 Episode length: 437 Return: -294.07617445271734
INFO:tensorflow:Average training steps per second: 236.99
I0902 00:05:50.729915 139825600018432 replay_runner.py:36] Average training steps per second: 236.99
I0902 00:05:51.328001 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -294.08
INFO:tensorflow:Starting iteration 5
I0902 00:05:55.542828 139825600018432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 232.84

Steps executed: 1000 Episode length: 1000 Return: -47.81108917507436
I0902 00:06:03.485026 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -47.81
INFO:tensorflow:Starting iteration 6
I0902 00:06:07.759017 139825600018432 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 223.22

Steps executed: 1000 Episode length: 1000 Return: -187.05682375274367
I0902 00:06:13.979914 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.06
INFO:tensorflow:Starting iteration 7

Steps executed: 343 Episode length: 343 Return: -307.5886405652802367
INFO:tensorflow:Average training steps per second: 226.42
I0902 00:06:22.753840 139825600018432 replay_runner.py:36] Average training steps per second: 226.42
I0902 00:06:23.216872 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.59
INFO:tensorflow:Starting iteration 8
I0902 00:06:27.825679 139825600018432 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 228.24

Steps executed: 792 Episode length: 792 Return: -543.5974025278766367
I0902 00:06:34.295285 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -543.60
INFO:tensorflow:Starting iteration 9

Steps executed: 230 Episode length: 230 Return: -508.5127562803917367
INFO:tensorflow:Average training steps per second: 226.01
I0902 00:06:43.102808 139825600018432 replay_runner.py:36] Average training steps per second: 226.01
I0902 00:06:43.365208 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -508.51
INFO:tensorflow:Starting iteration 10
I0902 00:06:47.802344 139825600018432 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 227.86

Steps executed: 566 Episode length: 566 Return: -243.2639421725336367
I0902 00:06:53.301069 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.26
INFO:tensorflow:Starting iteration 11

Steps executed: 239 Episode length: 171 Return: -109.3927388298143367
INFO:tensorflow:Average training steps per second: 220.73
I0902 00:07:02.291896 139825600018432 replay_runner.py:36] Average training steps per second: 220.73
I0902 00:07:02.484409 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.51
INFO:tensorflow:Starting iteration 12

Steps executed: 375 Episode length: 375 Return: -132.5950606171075867
INFO:tensorflow:Average training steps per second: 221.64
I0902 00:07:11.428351 139825600018432 replay_runner.py:36] Average training steps per second: 221.64
I0902 00:07:11.946757 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.60
INFO:tensorflow:Starting iteration 13

Steps executed: 61 Episode length: 61 Return: -96.6777303029001475867
INFO:tensorflow:Average training steps per second: 231.80

Steps executed: 407 Episode length: 346 Return: -127.6651240594130667
I0902 00:07:21.208765 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.17
INFO:tensorflow:Starting iteration 14

Steps executed: 270 Episode length: 270 Return: -163.3185357947747667
INFO:tensorflow:Average training steps per second: 221.84
I0902 00:07:30.205382 139825600018432 replay_runner.py:36] Average training steps per second: 221.84
I0902 00:07:30.531859 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.32
INFO:tensorflow:Starting iteration 15

Steps executed: 333 Episode length: 333 Return: -231.2587106490514767
INFO:tensorflow:Average training steps per second: 223.66
I0902 00:07:39.455847 139825600018432 replay_runner.py:36] Average training steps per second: 223.66
I0902 00:07:39.966451 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.26
INFO:tensorflow:Starting iteration 16
I0902 00:07:44.292822 139825600018432 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 218.46

Steps executed: 214 Episode length: 62 Return: -109.35988167342256767
I0902 00:07:49.042502 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.36
INFO:tensorflow:Starting iteration 17
I0902 00:07:53.345727 139825600018432 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 221.80

Steps executed: 577 Episode length: 577 Return: -588.3822063358736767
I0902 00:07:59.146064 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -588.38
INFO:tensorflow:Starting iteration 18

Steps executed: 307 Episode length: 307 Return: -166.5674395347874767
INFO:tensorflow:Average training steps per second: 220.19
I0902 00:08:08.004074 139825600018432 replay_runner.py:36] Average training steps per second: 220.19
I0902 00:08:08.376880 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.57
INFO:tensorflow:Starting iteration 19
I0902 00:08:12.660626 139825600018432 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 226.50

Steps executed: 316 Episode length: 316 Return: -515.7908950529124767
I0902 00:08:17.529635 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -515.79
INFO:tensorflow:Starting iteration 20
I0902 00:08:21.962496 139825600018432 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 219.18
I0902 00:08:26.525628 139825600018432 replay_runner.py:36] Average training steps per second: 219.18

Steps executed: 387 Episode length: 214 Return: -126.2974149159521567
INFO:tensorflow:Starting iteration 21

Steps executed: 243 Episode length: 186 Return: -152.7937024731186367
INFO:tensorflow:Average training steps per second: 221.61
I0902 00:08:35.857675 139825600018432 replay_runner.py:36] Average training steps per second: 221.61
I0902 00:08:36.087768 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.26
INFO:tensorflow:Starting iteration 22
I0902 00:08:40.406214 139825600018432 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 224.60

Steps executed: 1000 Episode length: 1000 Return: -67.468193506331867
I0902 00:08:47.962861 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -67.47
INFO:tensorflow:Starting iteration 23
I0902 00:08:52.210391 139825600018432 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 229.94

Steps executed: 578 Episode length: 578 Return: -141.8235788752385267
I0902 00:08:57.965277 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.82
INFO:tensorflow:Starting iteration 24
I0902 00:09:02.371888 139825600018432 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 224.16

Steps executed: 319 Episode length: 319 Return: -198.5351808981876667
I0902 00:09:07.190725 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.54
INFO:tensorflow:Starting iteration 25

Steps executed: 295 Episode length: 295 Return: -72.73028494848111667
INFO:tensorflow:Average training steps per second: 229.03
I0902 00:09:15.895005 139825600018432 replay_runner.py:36] Average training steps per second: 229.03
I0902 00:09:16.263911 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.73
INFO:tensorflow:Starting iteration 26

Steps executed: 244 Episode length: 52 Return: -89.999937880334364767
INFO:tensorflow:Average training steps per second: 225.95
I0902 00:09:25.040898 139825600018432 replay_runner.py:36] Average training steps per second: 225.95
I0902 00:09:25.230919 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.56
INFO:tensorflow:Starting iteration 27

Steps executed: 246 Episode length: 137 Return: -120.9108039512986567
INFO:tensorflow:Average training steps per second: 220.31
I0902 00:09:34.152911 139825600018432 replay_runner.py:36] Average training steps per second: 220.31
I0902 00:09:34.359622 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.30
INFO:tensorflow:Starting iteration 28

Steps executed: 222 Episode length: 70 Return: -142.90925472126693567
INFO:tensorflow:Average training steps per second: 220.87
I0902 00:09:43.256542 139825600018432 replay_runner.py:36] Average training steps per second: 220.87
I0902 00:09:43.431241 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.16
INFO:tensorflow:Starting iteration 29

Steps executed: 243 Episode length: 63 Return: -161.67443821292668567
INFO:tensorflow:Average training steps per second: 221.50
I0902 00:09:52.227476 139825600018432 replay_runner.py:36] Average training steps per second: 221.50

Done fixed training!Episode length: 63 Return: -161.67443821292668567