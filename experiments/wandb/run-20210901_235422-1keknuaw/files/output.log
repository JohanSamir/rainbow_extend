Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0901 23:54:28.970582 140149719906304 run_experiment.py:549] Creating TrainRunner ...
I0901 23:54:28.982488 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:54:28.982747 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:54:28.983046 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:54:28.983149 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:54:28.983222 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0901 23:54:28.983311 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:54:28.983387 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:54:28.983494 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:54:28.983588 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:54:28.983708 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0901 23:54:28.983800 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:54:28.983871 140149719906304 dqn_agent.py:283] 	 seed: 1630540468982426
I0901 23:54:28.986757 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:54:28.986998 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:54:28.987179 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:54:28.987284 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:54:28.987582 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:54:28.987737 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:54:28.987883 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:54:28.987970 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:54:28.988060 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:54:29.027925 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:29.403726 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:29.420571 140149719906304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:54:29.429982 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:54:29.430349 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:54:29.430531 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:54:29.430680 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:54:29.430799 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0901 23:54:29.430915 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:54:29.431007 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:54:29.431086 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:54:29.431155 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:54:29.431258 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0901 23:54:29.431330 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:54:29.431562 140149719906304 dqn_agent.py:283] 	 seed: 1630540469429930
I0901 23:54:29.434443 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:54:29.434608 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:54:29.434777 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:54:29.434966 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:54:29.435119 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:54:29.435271 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:54:29.435533 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:54:29.435661 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:54:29.435897 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:54:29.505315 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:29.529118 140149719906304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:54:29.529378 140149719906304 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.13
I0901 23:54:35.697615 140149719906304 replay_runner.py:36] Average training steps per second: 162.13
Steps executed: 308 Episode length: 128 Return: -210.34216631378564
I0901 23:54:37.004579 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.32
INFO:tensorflow:Starting iteration 1

Steps executed: 207 Episode length: 86 Return: -401.245054957523856
INFO:tensorflow:Average training steps per second: 216.98
I0901 23:54:45.848544 140149719906304 replay_runner.py:36] Average training steps per second: 216.98
I0901 23:54:46.011929 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -353.96
INFO:tensorflow:Starting iteration 2

Steps executed: 225 Episode length: 143 Return: -365.61921514492315
INFO:tensorflow:Average training steps per second: 220.52
I0901 23:54:54.832773 140149719906304 replay_runner.py:36] Average training steps per second: 220.52
I0901 23:54:55.043859 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -438.82
INFO:tensorflow:Starting iteration 3

Steps executed: 336 Episode length: 336 Return: -285.07359902046315
INFO:tensorflow:Average training steps per second: 224.04
I0901 23:55:03.896783 140149719906304 replay_runner.py:36] Average training steps per second: 224.04
I0901 23:55:04.396040 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.07
INFO:tensorflow:Starting iteration 4
I0901 23:55:08.809615 140149719906304 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 221.74

Steps executed: 818 Episode length: 818 Return: -336.98330548619375
I0901 23:55:15.016369 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -336.98
INFO:tensorflow:Starting iteration 5

Steps executed: 174 Episode length: 174 Return: -446.10833467537315
INFO:tensorflow:Average training steps per second: 221.40

Steps executed: 1174 Episode length: 1000 Return: -168.9031403069241
I0901 23:55:26.940529 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.51
INFO:tensorflow:Starting iteration 6
I0901 23:55:31.221178 140149719906304 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 211.14

Steps executed: 1000 Episode length: 1000 Return: -80.11425577126079
I0901 23:55:39.680724 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.11
INFO:tensorflow:Starting iteration 7
I0901 23:55:44.075695 140149719906304 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 224.63

Steps executed: 1000 Episode length: 1000 Return: -126.8934053408739
I0901 23:55:50.603409 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.89
INFO:tensorflow:Starting iteration 8
I0901 23:55:54.795966 140149719906304 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 218.20

Steps executed: 1000 Episode length: 1000 Return: -201.19563121880958
I0901 23:56:01.417824 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.20
INFO:tensorflow:Starting iteration 9
I0901 23:56:05.810692 140149719906304 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 221.76

Steps executed: 646 Episode length: 646 Return: -203.4067085532249958
I0901 23:56:11.615786 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.41
INFO:tensorflow:Starting iteration 10
I0901 23:56:15.847509 140149719906304 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 222.72

Steps executed: 834 Episode length: 834 Return: -246.5676317218086258
I0901 23:56:22.837785 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -246.57
INFO:tensorflow:Starting iteration 11

Steps executed: 351 Episode length: 351 Return: -235.9272578888234858
INFO:tensorflow:Average training steps per second: 221.13
I0901 23:56:31.646590 140149719906304 replay_runner.py:36] Average training steps per second: 221.13
I0901 23:56:32.113712 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.93
INFO:tensorflow:Starting iteration 12
I0901 23:56:36.336441 140149719906304 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 230.65

Steps executed: 412 Episode length: 412 Return: -177.5347545937020858
I0901 23:56:41.502077 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.53
INFO:tensorflow:Starting iteration 13
I0901 23:56:45.653606 140149719906304 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 234.82

Steps executed: 1000 Episode length: 1000 Return: -30.404145723614466
I0901 23:56:53.322205 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -30.40
INFO:tensorflow:Starting iteration 14
I0901 23:56:57.301910 140149719906304 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 223.68

Steps executed: 757 Episode length: 757 Return: -160.5506729573608666
I0901 23:57:03.736102 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.55
INFO:tensorflow:Starting iteration 15

Steps executed: 217 Episode length: 217 Return: -494.6630281609963666
INFO:tensorflow:Average training steps per second: 220.64
I0901 23:57:12.462500 140149719906304 replay_runner.py:36] Average training steps per second: 220.64
I0901 23:57:12.708339 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -494.66
INFO:tensorflow:Starting iteration 16
I0901 23:57:16.819647 140149719906304 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 225.59

Steps executed: 751 Episode length: 644 Return: 211.19430612283634166
I0901 23:57:22.324693 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: 43.96
INFO:tensorflow:Starting iteration 17
I0901 23:57:26.679227 140149719906304 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 227.21
I0901 23:57:31.080911 140149719906304 replay_runner.py:36] Average training steps per second: 227.21

Steps executed: 284 Episode length: 128 Return: -813.9694592653632566
INFO:tensorflow:Starting iteration 18

Steps executed: 261 Episode length: 261 Return: -403.0622386448843566
INFO:tensorflow:Average training steps per second: 231.02
I0901 23:57:40.008860 140149719906304 replay_runner.py:36] Average training steps per second: 231.02
I0901 23:57:40.345867 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -403.06
INFO:tensorflow:Starting iteration 19
I0901 23:57:44.773855 140149719906304 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 220.50
I0901 23:57:49.309325 140149719906304 replay_runner.py:36] Average training steps per second: 220.50

Steps executed: 265 Episode length: 77 Return: -126.68566621168554366
INFO:tensorflow:Starting iteration 20

Steps executed: 259 Episode length: 123 Return: -155.4109762545333566
INFO:tensorflow:Average training steps per second: 225.10
I0901 23:57:58.261296 140149719906304 replay_runner.py:36] Average training steps per second: 225.10
I0901 23:57:58.496008 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.13
INFO:tensorflow:Starting iteration 21
I0901 23:58:02.795084 140149719906304 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 226.39

Steps executed: 362 Episode length: 181 Return: -457.4318811852770666
I0901 23:58:07.612318 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -297.92
INFO:tensorflow:Starting iteration 22

Steps executed: 201 Episode length: 134 Return: -575.2950808620004666
INFO:tensorflow:Average training steps per second: 229.32
I0901 23:58:16.223844 140149719906304 replay_runner.py:36] Average training steps per second: 229.32
I0901 23:58:16.430982 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -571.38
INFO:tensorflow:Starting iteration 23
I0901 23:58:20.795131 140149719906304 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 225.17
I0901 23:58:25.236740 140149719906304 replay_runner.py:36] Average training steps per second: 225.17

Steps executed: 292 Episode length: 206 Return: -462.7387143985817566
INFO:tensorflow:Starting iteration 24

Steps executed: 225 Episode length: 60 Return: -166.46315254018856566
INFO:tensorflow:Average training steps per second: 224.79
I0901 23:58:34.368517 140149719906304 replay_runner.py:36] Average training steps per second: 224.79
I0901 23:58:34.533935 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.43
INFO:tensorflow:Starting iteration 25

Steps executed: 209 Episode length: 209 Return: -15.78347717770245166
INFO:tensorflow:Average training steps per second: 224.49
I0901 23:58:43.395114 140149719906304 replay_runner.py:36] Average training steps per second: 224.49
I0901 23:58:43.637277 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -15.78
INFO:tensorflow:Starting iteration 26

Steps executed: 219 Episode length: 219 Return: -41.24847266637679166
INFO:tensorflow:Average training steps per second: 229.95
I0901 23:58:52.240539 140149719906304 replay_runner.py:36] Average training steps per second: 229.95
I0901 23:58:52.485847 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -41.25
INFO:tensorflow:Starting iteration 27
I0901 23:58:56.910641 140149719906304 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 225.53

Steps executed: 259 Episode length: 62 Return: -514.05012954759949166
I0901 23:59:01.581640 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -306.84
INFO:tensorflow:Starting iteration 28

Steps executed: 200 Episode length: 107 Return: -103.9087420945394166
INFO:tensorflow:Average training steps per second: 230.89
I0901 23:59:10.267987 140149719906304 replay_runner.py:36] Average training steps per second: 230.89
I0901 23:59:10.413033 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.59
INFO:tensorflow:Starting iteration 29

Steps executed: 231 Episode length: 94 Return: -146.41773943314033166
INFO:tensorflow:Average training steps per second: 228.78
I0901 23:59:19.214175 140149719906304 replay_runner.py:36] Average training steps per second: 228.78

Done fixed training!Episode length: 94 Return: -146.41773943314033166