I0901 23:49:08.486970 139752435963904 run_experiment.py:549] Creating TrainRunner ...
I0901 23:49:08.498914 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:08.499260 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:08.499418 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:08.499554 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:08.499687 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:08.499876 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:08.500027 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:08.500308 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:08.500461 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:08.500592 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:08.500747 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:08.500978 139752435963904 dqn_agent.py:283] 	 seed: 1630540148498825
I0901 23:49:08.504164 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:08.504384 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:08.504544 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:08.504720 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:08.504854 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:08.505005 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:08.505144 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:08.505269 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:08.505388 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0901 23:49:10.367850 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:10.775022 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:10.791731 139752435963904 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:49:10.800237 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:10.800485 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:10.800583 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:10.800742 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:10.800856 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:10.800960 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:10.801099 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:10.801173 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:10.801283 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:10.801417 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:10.801503 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:10.801693 139752435963904 dqn_agent.py:283] 	 seed: 1630540150800183
I0901 23:49:10.804630 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:10.804786 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:10.804886 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:10.804976 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:10.805082 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:10.805212 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:10.805308 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:10.805508 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:10.805620 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:49:10.835918 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:10.857272 139752435963904 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:49:10.857713 139752435963904 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.34
I0901 23:49:17.018215 139752435963904 replay_runner.py:36] Average training steps per second: 162.34
Steps executed: 267 Episode length: 123 Return: -276.01323046199333
I0901 23:49:18.258325 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.46
INFO:tensorflow:Starting iteration 1

Steps executed: 236 Episode length: 107 Return: -277.82222792790515
INFO:tensorflow:Average training steps per second: 229.85
I0901 23:49:26.877471 139752435963904 replay_runner.py:36] Average training steps per second: 229.85
I0901 23:49:27.070408 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.96
INFO:tensorflow:Starting iteration 2
I0901 23:49:31.406656 139752435963904 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 234.69
I0901 23:49:35.668266 139752435963904 replay_runner.py:36] Average training steps per second: 234.69

Steps executed: 305 Episode length: 305 Return: -404.45752964706965
INFO:tensorflow:Starting iteration 3

Steps executed: 258 Episode length: 258 Return: 21.6929508610434435
INFO:tensorflow:Average training steps per second: 229.59
I0901 23:49:44.718678 139752435963904 replay_runner.py:36] Average training steps per second: 229.59
I0901 23:49:45.041370 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: 21.69
INFO:tensorflow:Starting iteration 4
I0901 23:49:49.491067 139752435963904 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 231.46

Steps executed: 1000 Episode length: 1000 Return: -163.35351880483324
I0901 23:49:56.411550 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.35
INFO:tensorflow:Starting iteration 5
I0901 23:50:00.726654 139752435963904 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 230.99

Steps executed: 1000 Episode length: 1000 Return: -126.56783888370168
I0901 23:50:07.645801 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.57
INFO:tensorflow:Starting iteration 6
I0901 23:50:12.023494 139752435963904 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 224.41

Steps executed: 1000 Episode length: 1000 Return: -243.68531673721034
I0901 23:50:19.710801 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.69
INFO:tensorflow:Starting iteration 7
I0901 23:50:23.994289 139752435963904 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 230.38

Steps executed: 471 Episode length: 471 Return: -357.6547789762167034
I0901 23:50:29.001040 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -357.65
INFO:tensorflow:Starting iteration 8

Steps executed: 543 Episode length: 543 Return: -213.1476585555707934
INFO:tensorflow:Average training steps per second: 240.35
I0901 23:50:37.505678 139752435963904 replay_runner.py:36] Average training steps per second: 240.35
I0901 23:50:38.235278 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.15
INFO:tensorflow:Starting iteration 9

Steps executed: 767 Episode length: 767 Return: -407.4101199981254934
INFO:tensorflow:Average training steps per second: 237.34
I0901 23:50:46.714074 139752435963904 replay_runner.py:36] Average training steps per second: 237.34
I0901 23:50:48.382715 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -407.41
INFO:tensorflow:Starting iteration 10
I0901 23:50:52.427849 139752435963904 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 234.66

Steps executed: 1000 Episode length: 1000 Return: -162.97614310491406
I0901 23:50:59.740338 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.98
INFO:tensorflow:Starting iteration 11
I0901 23:51:03.892823 139752435963904 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 231.23

Steps executed: 1000 Episode length: 1000 Return: -241.75481219031326
I0901 23:51:10.110902 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -241.75
INFO:tensorflow:Starting iteration 12
I0901 23:51:14.453943 139752435963904 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 235.09

Steps executed: 483 Episode length: 483 Return: -289.5359935717169326
I0901 23:51:19.365600 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.54
INFO:tensorflow:Starting iteration 13
I0901 23:51:23.668217 139752435963904 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 229.45

Steps executed: 1000 Episode length: 1000 Return: -154.14400269908293
I0901 23:51:30.889808 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.14
INFO:tensorflow:Starting iteration 14
I0901 23:51:35.124710 139752435963904 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 226.04

Steps executed: 1000 Episode length: 1000 Return: -235.31263884526018
I0901 23:51:43.362133 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.31
INFO:tensorflow:Starting iteration 15
I0901 23:51:47.762663 139752435963904 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 226.25

Steps executed: 1000 Episode length: 1000 Return: -61.017204857852918
I0901 23:51:54.715883 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.02
INFO:tensorflow:Starting iteration 16

Steps executed: 200 Episode length: 200 Return: -181.8614782476252618
INFO:tensorflow:Average training steps per second: 227.03
I0901 23:52:03.472558 139752435963904 replay_runner.py:36] Average training steps per second: 227.03
I0901 23:52:03.678618 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -181.86
INFO:tensorflow:Starting iteration 17
I0901 23:52:08.017540 139752435963904 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 221.46

Steps executed: 1000 Episode length: 1000 Return: -78.239060183263088
I0901 23:52:15.067650 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.24
INFO:tensorflow:Starting iteration 18
I0901 23:52:19.505798 139752435963904 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 222.95
I0901 23:52:23.991550 139752435963904 replay_runner.py:36] Average training steps per second: 222.95

Steps executed: 1000 Episode length: 1000 Return: -112.17752222301766
INFO:tensorflow:Starting iteration 19

Steps executed: 242 Episode length: 242 Return: -33.17179090930142766
INFO:tensorflow:Average training steps per second: 223.19
I0901 23:52:35.457052 139752435963904 replay_runner.py:36] Average training steps per second: 223.19
I0901 23:52:35.748380 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -33.17
INFO:tensorflow:Starting iteration 20
I0901 23:52:40.180430 139752435963904 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 218.90

Steps executed: 1000 Episode length: 1000 Return: -20.692106045757246
I0901 23:52:48.242656 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -20.69
INFO:tensorflow:Starting iteration 21
I0901 23:52:52.605927 139752435963904 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 227.84

Steps executed: 829 Episode length: 829 Return: 130.38911384598018246
I0901 23:52:59.510678 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: 130.39
INFO:tensorflow:Starting iteration 22
I0901 23:53:03.764446 139752435963904 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 229.11

Steps executed: 452 Episode length: 452 Return: -364.7004867334489246
I0901 23:53:08.930186 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.70
INFO:tensorflow:Starting iteration 23

Steps executed: 319 Episode length: 121 Return: -40.94632989048814446
INFO:tensorflow:Average training steps per second: 215.93
I0901 23:53:17.806353 139752435963904 replay_runner.py:36] Average training steps per second: 215.93
I0901 23:53:18.123670 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.48
INFO:tensorflow:Starting iteration 24

Steps executed: 304 Episode length: 154 Return: -53.52920042588289546
INFO:tensorflow:Average training steps per second: 223.02
I0901 23:53:26.995850 139752435963904 replay_runner.py:36] Average training steps per second: 223.02
I0901 23:53:27.274830 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -51.64
INFO:tensorflow:Starting iteration 25

Steps executed: 372 Episode length: 231 Return: -5.340665032611184546
INFO:tensorflow:Average training steps per second: 228.89
I0901 23:53:35.903911 139752435963904 replay_runner.py:36] Average training steps per second: 228.89
I0901 23:53:36.258309 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -0.21
INFO:tensorflow:Starting iteration 26

Steps executed: 225 Episode length: 225 Return: -1062.385174838144846
INFO:tensorflow:Average training steps per second: 242.36
I0901 23:53:44.554150 139752435963904 replay_runner.py:36] Average training steps per second: 242.36
I0901 23:53:44.865285 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -1062.39
INFO:tensorflow:Starting iteration 27

Steps executed: 244 Episode length: 170 Return: -171.5111325747396846
INFO:tensorflow:Average training steps per second: 228.96
I0901 23:53:53.548627 139752435963904 replay_runner.py:36] Average training steps per second: 228.96
I0901 23:53:53.788784 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.92
INFO:tensorflow:Starting iteration 28

Steps executed: 275 Episode length: 275 Return: -281.7843368829036346
INFO:tensorflow:Average training steps per second: 228.14
I0901 23:54:02.358248 139752435963904 replay_runner.py:36] Average training steps per second: 228.14
I0901 23:54:02.637742 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.78
INFO:tensorflow:Starting iteration 29

Steps executed: 231 Episode length: 123 Return: -74.53528005675255346
INFO:tensorflow:Average training steps per second: 220.62
I0901 23:54:11.578340 139752435963904 replay_runner.py:36] Average training steps per second: 220.62

Done fixed training!Episode length: 123 Return: -74.53528005675255346