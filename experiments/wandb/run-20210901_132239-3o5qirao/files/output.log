Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0901 13:22:44.701928 140460307478528 run_experiment.py:549] Creating TrainRunner ...
I0901 13:22:44.709826 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:22:44.709952 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:22:44.710025 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:22:44.710086 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:22:44.710155 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 13:22:44.710231 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:22:44.710328 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:22:44.710407 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:22:44.710486 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:22:44.710561 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 13:22:44.710641 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:22:44.710709 140460307478528 dqn_agent.py:283] 	 seed: 1630502564709791
I0901 13:22:44.712519 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:22:44.712672 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:22:44.712772 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:22:44.712855 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:22:44.712931 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:22:44.713028 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:22:44.713124 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:22:44.713243 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:22:44.713310 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:22:44.827444 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:22:45.093983 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:22:45.101785 140460307478528 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:22:45.108366 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:22:45.108492 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:22:45.108564 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:22:45.108625 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:22:45.108686 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 13:22:45.108756 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:22:45.108822 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:22:45.108950 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:22:45.109040 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:22:45.109128 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 13:22:45.109190 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:22:45.109245 140460307478528 dqn_agent.py:283] 	 seed: 1630502565108338
I0901 13:22:45.110669 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:22:45.110780 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:22:45.110851 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:22:45.110914 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:22:45.110971 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:22:45.111027 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:22:45.111089 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:22:45.111158 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:22:45.111233 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:22:45.134571 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:22:45.151603 140460307478528 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:22:45.151785 140460307478528 replay_runner.py:41] Starting iteration 0
Steps executed: 258 Episode length: 141 Return: -132.75833922354332
INFO:tensorflow:Average training steps per second: 230.14
I0901 13:22:49.497107 140460307478528 replay_runner.py:36] Average training steps per second: 230.14
I0901 13:22:50.270449 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.56
INFO:tensorflow:Starting iteration 1

Steps executed: 276 Episode length: 134 Return: -51.271155587762252
INFO:tensorflow:Average training steps per second: 356.79
I0901 13:22:56.453634 140460307478528 replay_runner.py:36] Average training steps per second: 356.79
I0901 13:22:56.604711 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -53.45
INFO:tensorflow:Starting iteration 2

Steps executed: 242 Episode length: 140 Return: -207.27289840532535
INFO:tensorflow:Average training steps per second: 356.10
I0901 13:23:02.816808 140460307478528 replay_runner.py:36] Average training steps per second: 356.10
I0901 13:23:02.935490 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.03
INFO:tensorflow:Starting iteration 3

Steps executed: 225 Episode length: 69 Return: -280.728186953677155
INFO:tensorflow:Average training steps per second: 333.07
I0901 13:23:09.329622 140460307478528 replay_runner.py:36] Average training steps per second: 333.07
I0901 13:23:09.446033 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.95
INFO:tensorflow:Starting iteration 4

Steps executed: 243 Episode length: 146 Return: -356.96917956597815
INFO:tensorflow:Average training steps per second: 310.91
I0901 13:23:16.089994 140460307478528 replay_runner.py:36] Average training steps per second: 310.91
I0901 13:23:16.229765 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.36
INFO:tensorflow:Starting iteration 5

Steps executed: 234 Episode length: 147 Return: -301.99258237762425
INFO:tensorflow:Average training steps per second: 311.46
I0901 13:23:22.794358 140460307478528 replay_runner.py:36] Average training steps per second: 311.46
I0901 13:23:22.939095 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.38
INFO:tensorflow:Starting iteration 6

Steps executed: 297 Episode length: 113 Return: -46.694391057530936
INFO:tensorflow:Average training steps per second: 320.32
I0901 13:23:29.471021 140460307478528 replay_runner.py:36] Average training steps per second: 320.32
I0901 13:23:29.630801 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.72
INFO:tensorflow:Starting iteration 7
I0901 13:23:33.017713 140460307478528 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 313.89

Steps executed: 1000 Episode length: 1000 Return: -210.41987495310616
I0901 13:23:38.912902 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.42
INFO:tensorflow:Starting iteration 8
I0901 13:23:42.430437 140460307478528 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 331.73

Steps executed: 1000 Episode length: 1000 Return: -188.46775482627256
I0901 13:23:47.647612 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.47
INFO:tensorflow:Starting iteration 9
I0901 13:23:51.153143 140460307478528 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 337.88

Steps executed: 868 Episode length: 868 Return: -1073.483062321919556
I0901 13:23:55.996793 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -1073.48
INFO:tensorflow:Starting iteration 10
I0901 13:23:59.456952 140460307478528 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 318.59

Steps executed: 488 Episode length: 488 Return: -1184.585599098636756
I0901 13:24:03.141980 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -1184.59
INFO:tensorflow:Starting iteration 11
I0901 13:24:06.601052 140460307478528 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 324.25

Steps executed: 758 Episode length: 758 Return: -867.8543498004765756
I0901 13:24:11.727746 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -867.85
INFO:tensorflow:Starting iteration 12

Steps executed: 203 Episode length: 130 Return: -426.2493079822661556
INFO:tensorflow:Average training steps per second: 318.43
I0901 13:24:18.258742 140460307478528 replay_runner.py:36] Average training steps per second: 318.43
I0901 13:24:18.395801 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -384.79
INFO:tensorflow:Starting iteration 13

Steps executed: 58 Episode length: 58 Return: -261.153682801206741556
INFO:tensorflow:Average training steps per second: 329.01

Steps executed: 626 Episode length: 568 Return: -273.5752713819034556
I0901 13:24:25.802766 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -267.36
INFO:tensorflow:Starting iteration 14
I0901 13:24:29.212067 140460307478528 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 322.44

Steps executed: 600 Episode length: 600 Return: -1151.283044845631156
I0901 13:24:33.706067 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -1151.28
INFO:tensorflow:Starting iteration 15

Steps executed: 323 Episode length: 323 Return: -492.5264021018778156
INFO:tensorflow:Average training steps per second: 313.48
I0901 13:24:40.302430 140460307478528 replay_runner.py:36] Average training steps per second: 313.48
I0901 13:24:40.603369 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -492.53
INFO:tensorflow:Starting iteration 16

Steps executed: 439 Episode length: 242 Return: -171.3971499369142156
INFO:tensorflow:Average training steps per second: 308.21
I0901 13:24:47.266315 140460307478528 replay_runner.py:36] Average training steps per second: 308.21
I0901 13:24:47.558807 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.68
INFO:tensorflow:Starting iteration 17

Steps executed: 233 Episode length: 57 Return: -161.01946075970745156
INFO:tensorflow:Average training steps per second: 325.45
I0901 13:24:54.052798 140460307478528 replay_runner.py:36] Average training steps per second: 325.45
I0901 13:24:54.170501 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.72
INFO:tensorflow:Starting iteration 18
I0901 13:24:57.633045 140460307478528 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 329.59
I0901 13:25:00.667477 140460307478528 replay_runner.py:36] Average training steps per second: 329.59

Steps executed: 220 Episode length: 91 Return: -353.24091456934923156
INFO:tensorflow:Starting iteration 19

Steps executed: 237 Episode length: 67 Return: -313.02824239843966456
INFO:tensorflow:Average training steps per second: 325.54
I0901 13:25:07.396496 140460307478528 replay_runner.py:36] Average training steps per second: 325.54
I0901 13:25:07.552122 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -306.77
INFO:tensorflow:Starting iteration 20

Steps executed: 245 Episode length: 62 Return: -231.76134588055584456
INFO:tensorflow:Average training steps per second: 334.09
I0901 13:25:14.052007 140460307478528 replay_runner.py:36] Average training steps per second: 334.09
I0901 13:25:14.189175 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -379.37
INFO:tensorflow:Starting iteration 21
I0901 13:25:17.726006 140460307478528 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 337.23

Steps executed: 273 Episode length: 112 Return: -121.3028852378641956
I0901 13:25:20.854065 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.10
INFO:tensorflow:Starting iteration 22

Steps executed: 211 Episode length: 102 Return: -373.3491209539679956
INFO:tensorflow:Average training steps per second: 343.26
I0901 13:25:27.351925 140460307478528 replay_runner.py:36] Average training steps per second: 343.26
I0901 13:25:27.483895 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.41
INFO:tensorflow:Starting iteration 23

Steps executed: 213 Episode length: 111 Return: -497.3415957787609956
INFO:tensorflow:Average training steps per second: 341.18
I0901 13:25:33.970257 140460307478528 replay_runner.py:36] Average training steps per second: 341.18
I0901 13:25:34.104414 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -409.02
INFO:tensorflow:Starting iteration 24

Steps executed: 273 Episode length: 100 Return: -359.5612790918885556
INFO:tensorflow:Average training steps per second: 345.80
I0901 13:25:40.592770 140460307478528 replay_runner.py:36] Average training steps per second: 345.80
I0901 13:25:40.758326 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.03
INFO:tensorflow:Starting iteration 25

Steps executed: 300 Episode length: 110 Return: -841.7808432906974556
INFO:tensorflow:Average training steps per second: 347.12
I0901 13:25:47.220764 140460307478528 replay_runner.py:36] Average training steps per second: 347.12
I0901 13:25:47.407933 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -614.51
INFO:tensorflow:Starting iteration 26

Steps executed: 207 Episode length: 53 Return: -208.88613715659278556
INFO:tensorflow:Average training steps per second: 356.04
I0901 13:25:53.802297 140460307478528 replay_runner.py:36] Average training steps per second: 356.04
I0901 13:25:53.907223 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -172.66
INFO:tensorflow:Starting iteration 27

Steps executed: 226 Episode length: 62 Return: -582.66626197111277556
INFO:tensorflow:Average training steps per second: 346.29
I0901 13:26:00.330674 140460307478528 replay_runner.py:36] Average training steps per second: 346.29
I0901 13:26:00.455348 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -533.34
INFO:tensorflow:Starting iteration 28

Steps executed: 236 Episode length: 86 Return: -801.04711462179456556
INFO:tensorflow:Average training steps per second: 354.40
I0901 13:26:06.779236 140460307478528 replay_runner.py:36] Average training steps per second: 354.40
I0901 13:26:06.890328 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -582.26
INFO:tensorflow:Starting iteration 29

Steps executed: 225 Episode length: 79 Return: -799.61772380879696556
INFO:tensorflow:Average training steps per second: 342.92
I0901 13:26:13.328177 140460307478528 replay_runner.py:36] Average training steps per second: 342.92

Done fixed training!Episode length: 79 Return: -799.61772380879696556