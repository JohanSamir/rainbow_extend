Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0905 16:38:26.545717 140035672414208 run_experiment.py:549] Creating TrainRunner ...
I0905 16:38:26.553827 140035672414208 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:38:26.554021 140035672414208 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:38:26.554152 140035672414208 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:38:26.554254 140035672414208 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:38:26.554329 140035672414208 dqn_agent.py:275] 	 update_period: 4
I0905 16:38:26.554400 140035672414208 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:38:26.554500 140035672414208 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:38:26.554662 140035672414208 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:38:26.554804 140035672414208 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:38:26.554934 140035672414208 dqn_agent.py:280] 	 optimizer: adam
I0905 16:38:26.555033 140035672414208 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:38:26.555129 140035672414208 dqn_agent.py:283] 	 seed: 1630859906553788
I0905 16:38:26.557025 140035672414208 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:38:26.557201 140035672414208 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:38:26.557322 140035672414208 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:38:26.557415 140035672414208 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:38:26.557485 140035672414208 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:38:26.557575 140035672414208 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:38:26.557682 140035672414208 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:38:26.557823 140035672414208 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:38:26.557940 140035672414208 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:38:27.853649 140035672414208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:38:28.113808 140035672414208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:38:28.124293 140035672414208 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:38:28.130877 140035672414208 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:38:28.131056 140035672414208 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:38:28.131187 140035672414208 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:38:28.131259 140035672414208 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:38:28.131349 140035672414208 dqn_agent.py:275] 	 update_period: 4
I0905 16:38:28.131434 140035672414208 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:38:28.131497 140035672414208 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:38:28.131575 140035672414208 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:38:28.131633 140035672414208 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:38:28.131774 140035672414208 dqn_agent.py:280] 	 optimizer: adam
I0905 16:38:28.131845 140035672414208 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:38:28.131903 140035672414208 dqn_agent.py:283] 	 seed: 1630859908130842
I0905 16:38:28.134008 140035672414208 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:38:28.134131 140035672414208 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:38:28.134202 140035672414208 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:38:28.134263 140035672414208 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:38:28.134319 140035672414208 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:38:28.134388 140035672414208 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:38:28.134469 140035672414208 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:38:28.134540 140035672414208 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:38:28.134615 140035672414208 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:38:28.154836 140035672414208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:38:28.170913 140035672414208 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:38:28.171216 140035672414208 replay_runner.py:41] Starting iteration 0
Steps executed: 424 Episode length: 303 Return: -294.4728977432404
INFO:tensorflow:Average training steps per second: 245.41
I0905 16:38:32.246248 140035672414208 replay_runner.py:36] Average training steps per second: 245.41
I0905 16:38:33.171385 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.64
INFO:tensorflow:Starting iteration 1

Steps executed: 325 Episode length: 223 Return: -371.8945910675011
INFO:tensorflow:Average training steps per second: 326.43
I0905 16:38:39.600836 140035672414208 replay_runner.py:36] Average training steps per second: 326.43
I0905 16:38:39.804397 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -343.94
INFO:tensorflow:Starting iteration 2
I0905 16:38:43.159133 140035672414208 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 333.63

Steps executed: 266 Episode length: 266 Return: -226.48798597532434
I0905 16:38:46.333456 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.49
INFO:tensorflow:Starting iteration 3

Steps executed: 333 Episode length: 333 Return: -98.475755943483294
INFO:tensorflow:Average training steps per second: 338.78
I0905 16:38:52.622758 140035672414208 replay_runner.py:36] Average training steps per second: 338.78
I0905 16:38:52.923326 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.48
INFO:tensorflow:Starting iteration 4
I0905 16:38:56.185718 140035672414208 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 325.73

Steps executed: 1000 Episode length: 1000 Return: -37.887895178858216
I0905 16:39:01.150319 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.89
INFO:tensorflow:Starting iteration 5
I0905 16:39:04.482954 140035672414208 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 324.97

Steps executed: 1000 Episode length: 1000 Return: -69.016356114601176
I0905 16:39:09.567462 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.02
INFO:tensorflow:Starting iteration 6
I0905 16:39:12.827332 140035672414208 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 327.97

Steps executed: 1000 Episode length: 1000 Return: -103.20798130407539
I0905 16:39:18.025292 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.21
INFO:tensorflow:Starting iteration 7
I0905 16:39:21.253022 140035672414208 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 317.38

Steps executed: 1000 Episode length: 1000 Return: -96.524242511589299
I0905 16:39:26.289695 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.52
INFO:tensorflow:Starting iteration 8

Steps executed: 1000 Episode length: 1000 Return: -40.987630977791184
INFO:tensorflow:Average training steps per second: 323.04
I0905 16:39:32.615982 140035672414208 replay_runner.py:36] Average training steps per second: 323.04
I0905 16:39:33.862737 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -40.99
INFO:tensorflow:Starting iteration 9
I0905 16:39:37.094903 140035672414208 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 324.00

Steps executed: 1000 Episode length: 1000 Return: -256.25696607835636
I0905 16:39:41.811637 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.26
INFO:tensorflow:Starting iteration 10
I0905 16:39:45.081463 140035672414208 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 328.44

Steps executed: 1000 Episode length: 1000 Return: -69.921852089957166
I0905 16:39:49.843437 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.92
INFO:tensorflow:Starting iteration 11
I0905 16:39:53.247789 140035672414208 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 335.95

Steps executed: 1000 Episode length: 1000 Return: -193.88885128722447
I0905 16:39:57.305460 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.89
INFO:tensorflow:Starting iteration 12
I0905 16:40:00.736675 140035672414208 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 346.95

Steps executed: 1000 Episode length: 1000 Return: -88.094681642454767
I0905 16:40:05.430821 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.09
INFO:tensorflow:Starting iteration 13
I0905 16:40:08.916867 140035672414208 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 360.90

Steps executed: 1000 Episode length: 1000 Return: -65.336803249794747
I0905 16:40:13.543399 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.34
INFO:tensorflow:Starting iteration 14
I0905 16:40:16.882514 140035672414208 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 343.60

Steps executed: 1000 Episode length: 1000 Return: -125.57679535651685
I0905 16:40:21.372936 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.58
INFO:tensorflow:Starting iteration 15

Steps executed: 285 Episode length: 285 Return: 293.23752822278531685
INFO:tensorflow:Average training steps per second: 361.97
I0905 16:40:27.542331 140035672414208 replay_runner.py:36] Average training steps per second: 361.97
I0905 16:40:27.779379 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: 293.24
INFO:tensorflow:Starting iteration 16

Steps executed: 370 Episode length: 171 Return: -145.8865783236495385
INFO:tensorflow:Average training steps per second: 355.08
I0905 16:40:34.079199 140035672414208 replay_runner.py:36] Average training steps per second: 355.08
I0905 16:40:34.312695 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.07
INFO:tensorflow:Starting iteration 17

Steps executed: 191 Episode length: 191 Return: -55.21268287722714385
INFO:tensorflow:Average training steps per second: 351.88
I0905 16:40:40.634088 140035672414208 replay_runner.py:36] Average training steps per second: 351.88

Steps executed: 307 Episode length: 116 Return: -141.9743679861537785
INFO:tensorflow:Starting iteration 18

Steps executed: 458 Episode length: 296 Return: -244.3474606973642785
INFO:tensorflow:Average training steps per second: 329.68
I0905 16:40:47.289404 140035672414208 replay_runner.py:36] Average training steps per second: 329.68
I0905 16:40:47.626825 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.03
INFO:tensorflow:Starting iteration 19

Steps executed: 251 Episode length: 135 Return: -361.4973179921441685
INFO:tensorflow:Average training steps per second: 328.79
I0905 16:40:53.966300 140035672414208 replay_runner.py:36] Average training steps per second: 328.79
I0905 16:40:54.106113 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.30
INFO:tensorflow:Starting iteration 20
I0905 16:40:57.461900 140035672414208 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 330.18

Steps executed: 421 Episode length: 421 Return: -410.1374881194068485
I0905 16:41:00.992856 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -410.14
INFO:tensorflow:Starting iteration 21

Steps executed: 222 Episode length: 100 Return: -129.8083474071935485
INFO:tensorflow:Average training steps per second: 323.13
I0905 16:41:07.266831 140035672414208 replay_runner.py:36] Average training steps per second: 323.13
I0905 16:41:07.399559 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.61
INFO:tensorflow:Starting iteration 22

Steps executed: 207 Episode length: 144 Return: -58.44694837438420685
INFO:tensorflow:Average training steps per second: 337.50
I0905 16:41:13.611483 140035672414208 replay_runner.py:36] Average training steps per second: 337.50
I0905 16:41:13.745028 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.58
INFO:tensorflow:Starting iteration 23

Steps executed: 273 Episode length: 147 Return: -288.6889902337009685
INFO:tensorflow:Average training steps per second: 338.33
I0905 16:41:20.070357 140035672414208 replay_runner.py:36] Average training steps per second: 338.33
I0905 16:41:20.239612 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.12
INFO:tensorflow:Starting iteration 24

Steps executed: 110 Episode length: 110 Return: -552.3496519447372685
INFO:tensorflow:Average training steps per second: 349.71
I0905 16:41:26.533462 140035672414208 replay_runner.py:36] Average training steps per second: 349.71

Steps executed: 436 Episode length: 326 Return: -592.9405968506793685
INFO:tensorflow:Starting iteration 25
I0905 16:41:30.339828 140035672414208 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 356.79

Steps executed: 211 Episode length: 107 Return: -211.7349712884311885
I0905 16:41:33.250383 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -264.87
INFO:tensorflow:Starting iteration 26

Steps executed: 666 Episode length: 666 Return: -415.2282620871812485
INFO:tensorflow:Average training steps per second: 339.58
I0905 16:41:39.527886 140035672414208 replay_runner.py:36] Average training steps per second: 339.58
I0905 16:41:40.640466 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -415.23
INFO:tensorflow:Starting iteration 27

Steps executed: 276 Episode length: 106 Return: -191.7860869951179385
INFO:tensorflow:Average training steps per second: 302.41
I0905 16:41:47.346318 140035672414208 replay_runner.py:36] Average training steps per second: 302.41
I0905 16:41:47.519909 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -376.07
INFO:tensorflow:Starting iteration 28

Steps executed: 253 Episode length: 165 Return: -114.4017795732625485
INFO:tensorflow:Average training steps per second: 287.66
I0905 16:41:54.431448 140035672414208 replay_runner.py:36] Average training steps per second: 287.66
I0905 16:41:54.558306 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.58
INFO:tensorflow:Starting iteration 29

Steps executed: 268 Episode length: 141 Return: -10.95300244855724385
INFO:tensorflow:Average training steps per second: 281.32
I0905 16:42:01.486284 140035672414208 replay_runner.py:36] Average training steps per second: 281.32

Done fixed training!Episode length: 141 Return: -10.95300244855724385