Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0903 00:09:09.686121 140099460519936 run_experiment.py:549] Creating TrainRunner ...
I0903 00:09:09.696502 140099460519936 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:09:09.696725 140099460519936 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:09:09.696896 140099460519936 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:09:09.697019 140099460519936 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:09:09.697130 140099460519936 dqn_agent.py:275] 	 update_period: 4
I0903 00:09:09.697254 140099460519936 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:09:09.697364 140099460519936 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:09:09.697498 140099460519936 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:09:09.697646 140099460519936 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:09:09.697762 140099460519936 dqn_agent.py:280] 	 optimizer: adam
I0903 00:09:09.697873 140099460519936 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:09:09.698008 140099460519936 dqn_agent.py:283] 	 seed: 1630627749696449
I0903 00:09:09.700723 140099460519936 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:09:09.700887 140099460519936 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:09:09.701027 140099460519936 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:09:09.701154 140099460519936 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:09:09.701280 140099460519936 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:09:09.701390 140099460519936 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:09:09.701495 140099460519936 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:09:09.701596 140099460519936 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:09:09.701705 140099460519936 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:09:09.737740 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:09:10.027766 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:09:10.037771 140099460519936 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:09:10.044679 140099460519936 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:09:10.044833 140099460519936 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:09:10.044925 140099460519936 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:09:10.044986 140099460519936 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:09:10.045042 140099460519936 dqn_agent.py:275] 	 update_period: 4
I0903 00:09:10.045117 140099460519936 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:09:10.045203 140099460519936 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:09:10.045293 140099460519936 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:09:10.045356 140099460519936 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:09:10.045428 140099460519936 dqn_agent.py:280] 	 optimizer: adam
I0903 00:09:10.045495 140099460519936 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:09:10.045569 140099460519936 dqn_agent.py:283] 	 seed: 1630627750044643
I0903 00:09:10.046990 140099460519936 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:09:10.047105 140099460519936 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:09:10.047240 140099460519936 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:09:10.047382 140099460519936 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:09:10.047552 140099460519936 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:09:10.047675 140099460519936 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:09:10.047750 140099460519936 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:09:10.047855 140099460519936 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:09:10.047938 140099460519936 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:09:10.069614 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:09:10.085779 140099460519936 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:09:10.085995 140099460519936 replay_runner.py:41] Starting iteration 0
Steps executed: 294 Episode length: 115 Return: -448.35222339308825
INFO:tensorflow:Average training steps per second: 249.64
I0903 00:09:14.092163 140099460519936 replay_runner.py:36] Average training steps per second: 249.64
I0903 00:09:14.954876 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.94
INFO:tensorflow:Starting iteration 1
I0903 00:09:18.433115 140099460519936 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 348.17

Steps executed: 243 Episode length: 126 Return: -464.15426855924414
I0903 00:09:21.438693 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -414.22
INFO:tensorflow:Starting iteration 2

Steps executed: 285 Episode length: 116 Return: -527.84275500527314
INFO:tensorflow:Average training steps per second: 342.72
I0903 00:09:27.835176 140099460519936 replay_runner.py:36] Average training steps per second: 342.72
I0903 00:09:28.014760 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -539.17
INFO:tensorflow:Starting iteration 3

Steps executed: 722 Episode length: 722 Return: -405.86589082786696
INFO:tensorflow:Average training steps per second: 338.09
I0903 00:09:34.362026 140099460519936 replay_runner.py:36] Average training steps per second: 338.09
I0903 00:09:35.292410 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -405.87
INFO:tensorflow:Starting iteration 4

Steps executed: 738 Episode length: 738 Return: -488.66384245512976
INFO:tensorflow:Average training steps per second: 324.35
I0903 00:09:41.776166 140099460519936 replay_runner.py:36] Average training steps per second: 324.35
I0903 00:09:42.830738 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -488.66
INFO:tensorflow:Starting iteration 5
I0903 00:09:46.254701 140099460519936 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 339.82

Steps executed: 1000 Episode length: 1000 Return: -12.968488296747942
I0903 00:09:50.919219 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -12.97
INFO:tensorflow:Starting iteration 6
I0903 00:09:54.377451 140099460519936 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 339.35

Steps executed: 1000 Episode length: 1000 Return: -302.70615916100162
I0903 00:09:59.413190 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -302.71
INFO:tensorflow:Starting iteration 7

Steps executed: 1000 Episode length: 1000 Return: -190.50696044827642
INFO:tensorflow:Average training steps per second: 359.77
I0903 00:10:05.660112 140099460519936 replay_runner.py:36] Average training steps per second: 359.77
I0903 00:10:07.178200 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.51
INFO:tensorflow:Starting iteration 8
I0903 00:10:10.632186 140099460519936 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 353.44
I0903 00:10:13.461767 140099460519936 replay_runner.py:36] Average training steps per second: 353.44

Steps executed: 233 Episode length: 233 Return: -85.23897452742438642
INFO:tensorflow:Starting iteration 9
I0903 00:10:17.130118 140099460519936 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 353.62

Steps executed: 1000 Episode length: 1000 Return: -380.67014340243867
I0903 00:10:21.736522 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -380.67
INFO:tensorflow:Starting iteration 10
I0903 00:10:25.146185 140099460519936 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 349.24

Steps executed: 1000 Episode length: 1000 Return: -521.89566478761627
I0903 00:10:29.904401 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -521.90
INFO:tensorflow:Starting iteration 11

Steps executed: 392 Episode length: 294 Return: -295.7107851543253627
INFO:tensorflow:Average training steps per second: 319.15
I0903 00:10:36.350044 140099460519936 replay_runner.py:36] Average training steps per second: 319.15
I0903 00:10:36.651847 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.13
INFO:tensorflow:Starting iteration 12
I0903 00:10:39.846476 140099460519936 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 309.84

Steps executed: 1000 Episode length: 1000 Return: -410.42863127259324
I0903 00:10:44.598495 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -410.43
INFO:tensorflow:Starting iteration 13
I0903 00:10:47.704062 140099460519936 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 296.64

Steps executed: 1000 Episode length: 1000 Return: -409.66141806752074
I0903 00:10:52.418076 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -409.66
INFO:tensorflow:Starting iteration 14
I0903 00:10:55.767751 140099460519936 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 326.55

Steps executed: 1000 Episode length: 1000 Return: -312.22259167688334
I0903 00:11:00.265458 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -312.22
INFO:tensorflow:Starting iteration 15

Steps executed: 650 Episode length: 467 Return: -652.0184103167185334
INFO:tensorflow:Average training steps per second: 360.66
I0903 00:11:06.667364 140099460519936 replay_runner.py:36] Average training steps per second: 360.66
I0903 00:11:07.379802 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -477.61
INFO:tensorflow:Starting iteration 16

Steps executed: 224 Episode length: 60 Return: -422.89357402915711634
INFO:tensorflow:Average training steps per second: 381.05
I0903 00:11:13.634781 140099460519936 replay_runner.py:36] Average training steps per second: 381.05
I0903 00:11:13.754018 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -452.45
INFO:tensorflow:Starting iteration 17

Steps executed: 294 Episode length: 124 Return: -366.4657424558689634
INFO:tensorflow:Average training steps per second: 374.50
I0903 00:11:20.049679 140099460519936 replay_runner.py:36] Average training steps per second: 374.50
I0903 00:11:20.210305 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.49
INFO:tensorflow:Starting iteration 18

Steps executed: 314 Episode length: 179 Return: -36.80017316839004634
INFO:tensorflow:Average training steps per second: 347.09
I0903 00:11:26.634281 140099460519936 replay_runner.py:36] Average training steps per second: 347.09
I0903 00:11:26.802501 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.54
INFO:tensorflow:Starting iteration 19

Steps executed: 211 Episode length: 93 Return: -760.09948493692256634
INFO:tensorflow:Average training steps per second: 351.73
I0903 00:11:33.170446 140099460519936 replay_runner.py:36] Average training steps per second: 351.73
I0903 00:11:33.274173 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -490.19
INFO:tensorflow:Starting iteration 20
I0903 00:11:36.773220 140099460519936 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 351.63

Steps executed: 572 Episode length: 394 Return: -30.60622181839281834
I0903 00:11:40.063935 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.18
INFO:tensorflow:Starting iteration 21

Steps executed: 243 Episode length: 243 Return: -205.2208589599851534
INFO:tensorflow:Average training steps per second: 371.54
I0903 00:11:46.276899 140099460519936 replay_runner.py:36] Average training steps per second: 371.54
I0903 00:11:46.450096 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.22
INFO:tensorflow:Starting iteration 22

Steps executed: 233 Episode length: 53 Return: -474.21939091213891534
INFO:tensorflow:Average training steps per second: 358.86
I0903 00:11:52.730724 140099460519936 replay_runner.py:36] Average training steps per second: 358.86
I0903 00:11:52.838923 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -680.29
INFO:tensorflow:Starting iteration 23

Steps executed: 242 Episode length: 125 Return: -46.26592202460703634
INFO:tensorflow:Average training steps per second: 342.73
I0903 00:11:59.131840 140099460519936 replay_runner.py:36] Average training steps per second: 342.73
I0903 00:11:59.252933 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -56.14
INFO:tensorflow:Starting iteration 24

Steps executed: 257 Episode length: 110 Return: -832.9591230798989534
INFO:tensorflow:Average training steps per second: 345.78
I0903 00:12:05.423001 140099460519936 replay_runner.py:36] Average training steps per second: 345.78
I0903 00:12:05.579262 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -493.18
INFO:tensorflow:Starting iteration 25
I0903 00:12:08.866028 140099460519936 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 335.07
I0903 00:12:11.850779 140099460519936 replay_runner.py:36] Average training steps per second: 335.07

Steps executed: 200 Episode length: 56 Return: -94.942491322965271534
INFO:tensorflow:Starting iteration 26

Steps executed: 250 Episode length: 78 Return: -417.24856523109787534
INFO:tensorflow:Average training steps per second: 330.46
I0903 00:12:18.297346 140099460519936 replay_runner.py:36] Average training steps per second: 330.46
I0903 00:12:18.435249 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -455.22
INFO:tensorflow:Starting iteration 27

Steps executed: 416 Episode length: 254 Return: -270.3825394203678334
INFO:tensorflow:Average training steps per second: 333.51
I0903 00:12:24.724830 140099460519936 replay_runner.py:36] Average training steps per second: 333.51
I0903 00:12:24.989581 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.50
INFO:tensorflow:Starting iteration 28

Steps executed: 223 Episode length: 70 Return: -650.03282229382555334
INFO:tensorflow:Average training steps per second: 324.28
I0903 00:12:31.346256 140099460519936 replay_runner.py:36] Average training steps per second: 324.28
I0903 00:12:31.495885 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -467.74
INFO:tensorflow:Starting iteration 29

Steps executed: 69 Episode length: 69 Return: -484.792737547107555334
INFO:tensorflow:Average training steps per second: 311.83

Steps executed: 488 Episode length: 302 Return: -208.8046063113688134

Done fixed training!Episode length: 302 Return: -208.8046063113688134