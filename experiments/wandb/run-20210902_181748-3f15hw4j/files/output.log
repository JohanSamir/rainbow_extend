I0902 18:17:53.614093 139685444462592 run_experiment.py:549] Creating TrainRunner ...
I0902 18:17:53.621513 139685444462592 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:17:53.621629 139685444462592 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:17:53.621705 139685444462592 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:17:53.621774 139685444462592 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:17:53.621831 139685444462592 dqn_agent.py:275] 	 update_period: 4
I0902 18:17:53.621909 139685444462592 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:17:53.621963 139685444462592 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:17:53.622066 139685444462592 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:17:53.622144 139685444462592 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:17:53.622215 139685444462592 dqn_agent.py:280] 	 optimizer: adam
I0902 18:17:53.622267 139685444462592 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:17:53.622346 139685444462592 dqn_agent.py:283] 	 seed: 1630606673621483
I0902 18:17:53.623903 139685444462592 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:17:53.624012 139685444462592 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:17:53.624086 139685444462592 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:17:53.624149 139685444462592 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:17:53.624205 139685444462592 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:17:53.624275 139685444462592 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:17:53.624337 139685444462592 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:17:53.624430 139685444462592 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:17:53.624482 139685444462592 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:17:53.646854 139685444462592 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 18:17:53.881241 139685444462592 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 18:17:53.889455 139685444462592 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:17:53.896284 139685444462592 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:17:53.896467 139685444462592 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:17:53.896586 139685444462592 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:17:53.896692 139685444462592 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:17:53.896805 139685444462592 dqn_agent.py:275] 	 update_period: 4
I0902 18:17:53.896911 139685444462592 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:17:53.896970 139685444462592 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:17:53.897037 139685444462592 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:17:53.897098 139685444462592 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:17:53.897151 139685444462592 dqn_agent.py:280] 	 optimizer: adam
I0902 18:17:53.897202 139685444462592 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:17:53.897299 139685444462592 dqn_agent.py:283] 	 seed: 1630606673896249
I0902 18:17:53.898895 139685444462592 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:17:53.899016 139685444462592 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:17:53.899096 139685444462592 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:17:53.899166 139685444462592 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:17:53.899233 139685444462592 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:17:53.899297 139685444462592 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:17:53.899373 139685444462592 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:17:53.899461 139685444462592 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:17:53.899534 139685444462592 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:17:53.919312 139685444462592 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 18:17:53.934023 139685444462592 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:17:53.934187 139685444462592 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 243.63
I0902 18:17:58.038983 139685444462592 replay_runner.py:36] Average training steps per second: 243.63
I0902 18:17:58.844199 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -330.52
Steps executed: 286 Episode length: 100 Return: -321.65307408221133
INFO:tensorflow:Starting iteration 1

Steps executed: 115 Episode length: 115 Return: -308.11795482439673
INFO:tensorflow:Average training steps per second: 330.19

Steps executed: 357 Episode length: 242 Return: -457.70175503187833
I0902 18:18:05.368602 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -382.91
INFO:tensorflow:Starting iteration 2

Steps executed: 261 Episode length: 151 Return: -256.27434211262215
INFO:tensorflow:Average training steps per second: 351.92
I0902 18:18:11.585858 139685444462592 replay_runner.py:36] Average training steps per second: 351.92
I0902 18:18:11.743350 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.39
INFO:tensorflow:Starting iteration 3

Steps executed: 99 Episode length: 99 Return: -472.1473179431762315
INFO:tensorflow:Average training steps per second: 375.76

Steps executed: 1099 Episode length: 1000 Return: -139.1091877069847
I0902 18:18:20.118673 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -305.63
INFO:tensorflow:Starting iteration 4
I0902 18:18:23.392101 139685444462592 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 360.58

Steps executed: 1000 Episode length: 1000 Return: -127.64988480115575
I0902 18:18:29.259104 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.65
INFO:tensorflow:Starting iteration 5
I0902 18:18:32.424123 139685444462592 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 330.57

Steps executed: 1000 Episode length: 1000 Return: -228.13920495465675
I0902 18:18:37.772596 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.14
INFO:tensorflow:Starting iteration 6

Steps executed: 1000 Episode length: 1000 Return: -160.48612146381006
INFO:tensorflow:Average training steps per second: 321.34
I0902 18:18:44.079558 139685444462592 replay_runner.py:36] Average training steps per second: 321.34
I0902 18:18:45.342406 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.49
INFO:tensorflow:Starting iteration 7

Steps executed: 678 Episode length: 678 Return: -351.0086537643482506
INFO:tensorflow:Average training steps per second: 314.27
I0902 18:18:51.818190 139685444462592 replay_runner.py:36] Average training steps per second: 314.27
I0902 18:18:52.953440 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -351.01
INFO:tensorflow:Starting iteration 8
I0902 18:18:56.206629 139685444462592 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 324.18

Steps executed: 1000 Episode length: 1000 Return: -134.67184863500376
I0902 18:19:01.144025 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.67
INFO:tensorflow:Starting iteration 9
I0902 18:19:04.567517 139685444462592 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 345.56

Steps executed: 406 Episode length: 406 Return: -291.1337920670810376
I0902 18:19:07.882761 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -291.13
INFO:tensorflow:Starting iteration 10
I0902 18:19:11.329756 139685444462592 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 335.71

Steps executed: 1000 Episode length: 1000 Return: -388.68631685466835
I0902 18:19:16.551085 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -388.69
INFO:tensorflow:Starting iteration 11
I0902 18:19:19.972923 139685444462592 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 333.63

Steps executed: 1000 Episode length: 1000 Return: -263.38543224264745
I0902 18:19:24.832647 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.39
INFO:tensorflow:Starting iteration 12
I0902 18:19:28.209527 139685444462592 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 341.74

Steps executed: 1000 Episode length: 1000 Return: -96.409485481985735
I0902 18:19:33.535120 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.41
INFO:tensorflow:Starting iteration 13

Steps executed: 1152 Episode length: 1000 Return: -116.03455642807137
INFO:tensorflow:Average training steps per second: 343.29
I0902 18:19:39.845176 139685444462592 replay_runner.py:36] Average training steps per second: 343.29
I0902 18:19:41.768156 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.69
INFO:tensorflow:Starting iteration 14

Steps executed: 409 Episode length: 234 Return: -700.5622021914746537
INFO:tensorflow:Average training steps per second: 325.79
I0902 18:19:48.119629 139685444462592 replay_runner.py:36] Average training steps per second: 325.79
I0902 18:19:48.394928 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -503.17
INFO:tensorflow:Starting iteration 15

Steps executed: 272 Episode length: 272 Return: -478.2903307017885537
INFO:tensorflow:Average training steps per second: 327.80
I0902 18:19:54.737240 139685444462592 replay_runner.py:36] Average training steps per second: 327.80
I0902 18:19:54.968421 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -478.29
INFO:tensorflow:Starting iteration 16

Steps executed: 138 Episode length: 138 Return: -708.2078995290999537
INFO:tensorflow:Average training steps per second: 330.46

Steps executed: 675 Episode length: 537 Return: -438.6404768276426637
I0902 18:20:02.346215 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -573.42
INFO:tensorflow:Starting iteration 17
I0902 18:20:05.750363 139685444462592 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 327.61

Steps executed: 1000 Episode length: 1000 Return: -88.327674659600637
I0902 18:20:11.021249 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.33
INFO:tensorflow:Starting iteration 18
I0902 18:20:14.405041 139685444462592 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 329.51
I0902 18:20:17.440173 139685444462592 replay_runner.py:36] Average training steps per second: 329.51

Steps executed: 434 Episode length: 250 Return: -368.4373690066568737
INFO:tensorflow:Starting iteration 19

Steps executed: 596 Episode length: 461 Return: -59.36433296781487537
INFO:tensorflow:Average training steps per second: 327.90
I0902 18:20:24.270183 139685444462592 replay_runner.py:36] Average training steps per second: 327.90
I0902 18:20:24.920771 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.06
INFO:tensorflow:Starting iteration 20

Steps executed: 301 Episode length: 172 Return: -542.0823089297035537
INFO:tensorflow:Average training steps per second: 327.36
I0902 18:20:31.394249 139685444462592 replay_runner.py:36] Average training steps per second: 327.36
I0902 18:20:31.589017 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -517.36
INFO:tensorflow:Starting iteration 21
I0902 18:20:34.924351 139685444462592 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 324.80

Steps executed: 253 Episode length: 253 Return: -682.6185975345833537
I0902 18:20:38.227151 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -682.62
INFO:tensorflow:Starting iteration 22

Steps executed: 318 Episode length: 163 Return: -357.0688084109926337
INFO:tensorflow:Average training steps per second: 333.07
I0902 18:20:44.572783 139685444462592 replay_runner.py:36] Average training steps per second: 333.07
I0902 18:20:44.777964 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -417.73
INFO:tensorflow:Starting iteration 23

Steps executed: 387 Episode length: 245 Return: -383.3460151974099437
INFO:tensorflow:Average training steps per second: 329.08
I0902 18:20:51.188374 139685444462592 replay_runner.py:36] Average training steps per second: 329.08
I0902 18:20:51.466374 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -393.97
INFO:tensorflow:Starting iteration 24

Steps executed: 343 Episode length: 343 Return: 257.71413857779919437
INFO:tensorflow:Average training steps per second: 331.41
I0902 18:20:57.879617 139685444462592 replay_runner.py:36] Average training steps per second: 331.41
I0902 18:20:58.228107 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: 257.71
INFO:tensorflow:Starting iteration 25
I0902 18:21:01.537924 139685444462592 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 338.78

Steps executed: 1000 Episode length: 1000 Return: -14.254629602872187
I0902 18:21:06.463747 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -14.25
INFO:tensorflow:Starting iteration 26

Steps executed: 269 Episode length: 269 Return: -45.08635346854842187
INFO:tensorflow:Average training steps per second: 334.48
I0902 18:21:12.818948 139685444462592 replay_runner.py:36] Average training steps per second: 334.48
I0902 18:21:13.040390 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -45.09
INFO:tensorflow:Starting iteration 27
I0902 18:21:16.312472 139685444462592 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 331.26

Steps executed: 1000 Episode length: 1000 Return: -53.893059646876467
I0902 18:21:21.441773 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -53.89
INFO:tensorflow:Starting iteration 28
I0902 18:21:24.652328 139685444462592 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 348.39

Steps executed: 1000 Episode length: 1000 Return: -38.917856088270167
I0902 18:21:29.865148 139685444462592 run_experiment.py:428] Average undiscounted return per evaluation episode: -38.92
INFO:tensorflow:Starting iteration 29
I0902 18:21:33.237082 139685444462592 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 373.45

Steps executed: 679 Episode length: 679 Return: -133.4716536248680867

Done fixed training!Episode length: 679 Return: -133.4716536248680867