Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 13:00:21.427608 140315766171648 run_experiment.py:549] Creating TrainRunner ...
I0901 13:00:21.439320 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:00:21.439598 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:00:21.439757 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:00:21.439955 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:00:21.440089 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 13:00:21.440741 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:00:21.440952 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:00:21.441103 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:00:21.441220 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:00:21.441340 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 13:00:21.441438 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:00:21.441557 140315766171648 dqn_agent.py:283] 	 seed: 1630501221439260
I0901 13:00:21.445935 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:00:21.446213 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:00:21.446333 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:00:21.446456 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:00:21.446583 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:00:21.446853 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:00:21.446968 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:00:21.447118 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:00:21.447212 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:00:21.489646 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:00:21.986069 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:00:22.001853 140315766171648 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:00:22.012630 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:00:22.012933 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:00:22.013125 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:00:22.013396 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:00:22.013540 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 13:00:22.013654 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:00:22.013770 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:00:22.013872 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:00:22.013984 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:00:22.014250 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 13:00:22.014364 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:00:22.014522 140315766171648 dqn_agent.py:283] 	 seed: 1630501222012569
I0901 13:00:22.017387 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:00:22.017588 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:00:22.017705 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:00:22.017827 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:00:22.017949 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:00:22.018040 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:00:22.018133 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:00:22.018247 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:00:22.018409 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:00:22.054015 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:00:22.079166 140315766171648 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:00:22.079411 140315766171648 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 151.38
I0901 13:00:28.685346 140315766171648 replay_runner.py:36] Average training steps per second: 151.38
Steps executed: 306 Episode length: 128 Return: -263.67915462311953
I0901 13:00:30.029456 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.81
INFO:tensorflow:Starting iteration 1

Steps executed: 285 Episode length: 95 Return: -166.119662715151788
INFO:tensorflow:Average training steps per second: 214.83
I0901 13:00:39.102814 140315766171648 replay_runner.py:36] Average training steps per second: 214.83
I0901 13:00:39.353155 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.64
INFO:tensorflow:Starting iteration 2

Steps executed: 229 Episode length: 93 Return: -290.027153315074545
INFO:tensorflow:Average training steps per second: 211.19
I0901 13:00:48.597250 140315766171648 replay_runner.py:36] Average training steps per second: 211.19
I0901 13:00:48.819685 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.76
INFO:tensorflow:Starting iteration 3

Steps executed: 254 Episode length: 132 Return: -72.539061340637195
INFO:tensorflow:Average training steps per second: 207.46
I0901 13:00:58.114139 140315766171648 replay_runner.py:36] Average training steps per second: 207.46
I0901 13:00:58.356189 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.98
INFO:tensorflow:Starting iteration 4

Steps executed: 211 Episode length: 92 Return: -300.782077869855665
INFO:tensorflow:Average training steps per second: 208.25
I0901 13:01:07.590058 140315766171648 replay_runner.py:36] Average training steps per second: 208.25
I0901 13:01:07.783810 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.64
INFO:tensorflow:Starting iteration 5

Steps executed: 175 Episode length: 74 Return: -363.425226880727865
INFO:tensorflow:Average training steps per second: 211.93
I0901 13:01:16.965455 140315766171648 replay_runner.py:36] Average training steps per second: 211.93

Steps executed: 264 Episode length: 89 Return: -426.682803590177345
INFO:tensorflow:Starting iteration 6

Steps executed: 247 Episode length: 137 Return: -219.30030140996936
INFO:tensorflow:Average training steps per second: 210.33
I0901 13:01:26.345300 140315766171648 replay_runner.py:36] Average training steps per second: 210.33
I0901 13:01:26.564040 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.25
INFO:tensorflow:Starting iteration 7

Steps executed: 269 Episode length: 132 Return: -310.08104104951086
INFO:tensorflow:Average training steps per second: 211.33
I0901 13:01:35.659116 140315766171648 replay_runner.py:36] Average training steps per second: 211.33
I0901 13:01:35.889364 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.38
INFO:tensorflow:Starting iteration 8

Steps executed: 222 Episode length: 125 Return: -220.49889894429782
INFO:tensorflow:Average training steps per second: 219.49
I0901 13:01:44.870987 140315766171648 replay_runner.py:36] Average training steps per second: 219.49
I0901 13:01:45.045238 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -239.98
INFO:tensorflow:Starting iteration 9

Steps executed: 360 Episode length: 199 Return: -422.01213369367412
INFO:tensorflow:Average training steps per second: 220.17
I0901 13:01:53.996064 140315766171648 replay_runner.py:36] Average training steps per second: 220.17
I0901 13:01:54.286284 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -317.54
INFO:tensorflow:Starting iteration 10

Steps executed: 90 Episode length: 90 Return: -699.1295262428382412
INFO:tensorflow:Average training steps per second: 217.33

Steps executed: 332 Episode length: 156 Return: -258.22022860351024
I0901 13:02:03.536408 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -522.86
INFO:tensorflow:Starting iteration 11

Steps executed: 274 Episode length: 75 Return: -257.009255442434844
INFO:tensorflow:Average training steps per second: 217.62
I0901 13:02:12.488005 140315766171648 replay_runner.py:36] Average training steps per second: 217.62
I0901 13:02:12.694949 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.89
INFO:tensorflow:Starting iteration 12

Steps executed: 269 Episode length: 74 Return: -213.393217342630464
INFO:tensorflow:Average training steps per second: 214.78
I0901 13:02:21.651921 140315766171648 replay_runner.py:36] Average training steps per second: 214.78
I0901 13:02:21.871152 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.98
INFO:tensorflow:Starting iteration 13

Steps executed: 241 Episode length: 62 Return: -112.956894343423444
INFO:tensorflow:Average training steps per second: 220.13
I0901 13:02:30.550710 140315766171648 replay_runner.py:36] Average training steps per second: 220.13
I0901 13:02:30.737126 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.42
INFO:tensorflow:Starting iteration 14
I0901 13:02:35.016404 140315766171648 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 220.38

Steps executed: 220 Episode length: 67 Return: -1.52326198388612974
I0901 13:02:39.723306 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.53
INFO:tensorflow:Starting iteration 15

Steps executed: 244 Episode length: 84 Return: -142.401084734977276
INFO:tensorflow:Average training steps per second: 222.64
I0901 13:02:48.555331 140315766171648 replay_runner.py:36] Average training steps per second: 222.64
I0901 13:02:48.741722 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -62.22
INFO:tensorflow:Starting iteration 16

Steps executed: 248 Episode length: 75 Return: 24.92776846298601376
INFO:tensorflow:Average training steps per second: 222.88
I0901 13:02:57.463178 140315766171648 replay_runner.py:36] Average training steps per second: 222.88
I0901 13:02:57.665754 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.75
INFO:tensorflow:Starting iteration 17

Steps executed: 239 Episode length: 68 Return: -403.759722184140736
INFO:tensorflow:Average training steps per second: 230.74
I0901 13:03:06.305992 140315766171648 replay_runner.py:36] Average training steps per second: 230.74
I0901 13:03:06.481695 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.42
INFO:tensorflow:Starting iteration 18

Steps executed: 225 Episode length: 72 Return: -443.514217596270766
INFO:tensorflow:Average training steps per second: 237.01
I0901 13:03:14.997161 140315766171648 replay_runner.py:36] Average training steps per second: 237.01
I0901 13:03:15.165467 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -391.59
INFO:tensorflow:Starting iteration 19
I0901 13:03:19.369407 140315766171648 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 234.44
I0901 13:03:23.635346 140315766171648 replay_runner.py:36] Average training steps per second: 234.44

Steps executed: 236 Episode length: 66 Return: -261.074845882698166
INFO:tensorflow:Starting iteration 20

Steps executed: 256 Episode length: 68 Return: -113.851403373809776
INFO:tensorflow:Average training steps per second: 233.54
I0901 13:03:32.260790 140315766171648 replay_runner.py:36] Average training steps per second: 233.54
I0901 13:03:32.426295 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.20
INFO:tensorflow:Starting iteration 21

Steps executed: 244 Episode length: 84 Return: -218.649384195369926
INFO:tensorflow:Average training steps per second: 237.06
I0901 13:03:40.819104 140315766171648 replay_runner.py:36] Average training steps per second: 237.06
I0901 13:03:40.991594 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.75
INFO:tensorflow:Starting iteration 22

Steps executed: 201 Episode length: 116 Return: -96.526506214930686
INFO:tensorflow:Average training steps per second: 246.95
I0901 13:03:49.139818 140315766171648 replay_runner.py:36] Average training steps per second: 246.95
I0901 13:03:49.316974 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.77
INFO:tensorflow:Starting iteration 23
I0901 13:03:53.495396 140315766171648 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 244.80
I0901 13:03:57.581126 140315766171648 replay_runner.py:36] Average training steps per second: 244.80

Steps executed: 246 Episode length: 57 Return: -454.031362099422886
INFO:tensorflow:Starting iteration 24

Steps executed: 228 Episode length: 62 Return: -291.532483985263436
INFO:tensorflow:Average training steps per second: 247.97
I0901 13:04:05.954182 140315766171648 replay_runner.py:36] Average training steps per second: 247.97
I0901 13:04:06.120485 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.78
INFO:tensorflow:Starting iteration 25

Steps executed: 213 Episode length: 78 Return: -474.014045666023336
INFO:tensorflow:Average training steps per second: 251.49
I0901 13:04:14.275932 140315766171648 replay_runner.py:36] Average training steps per second: 251.49
I0901 13:04:14.462499 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -537.88
INFO:tensorflow:Starting iteration 26

Steps executed: 220 Episode length: 77 Return: -344.524969453076746
INFO:tensorflow:Average training steps per second: 257.57
I0901 13:04:22.509718 140315766171648 replay_runner.py:36] Average training steps per second: 257.57
I0901 13:04:22.650940 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.17
INFO:tensorflow:Starting iteration 27

Steps executed: 229 Episode length: 83 Return: -109.589619212007346
INFO:tensorflow:Average training steps per second: 252.31
I0901 13:04:30.595456 140315766171648 replay_runner.py:36] Average training steps per second: 252.31
I0901 13:04:30.745213 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.41
INFO:tensorflow:Starting iteration 28

Steps executed: 267 Episode length: 70 Return: -542.030110746794456
INFO:tensorflow:Average training steps per second: 257.69
I0901 13:04:38.582716 140315766171648 replay_runner.py:36] Average training steps per second: 257.69
I0901 13:04:38.785948 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -516.23
INFO:tensorflow:Starting iteration 29

Steps executed: 204 Episode length: 61 Return: -518.758812685645556
INFO:tensorflow:Average training steps per second: 278.22
I0901 13:04:46.252294 140315766171648 replay_runner.py:36] Average training steps per second: 278.22

Done fixed training!Episode length: 61 Return: -518.758812685645556