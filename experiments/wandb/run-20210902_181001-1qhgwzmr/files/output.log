Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0902 18:10:08.517487 140284730537984 run_experiment.py:549] Creating TrainRunner ...
I0902 18:10:08.528427 140284730537984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:10:08.528692 140284730537984 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:10:08.528830 140284730537984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:10:08.528994 140284730537984 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:10:08.529125 140284730537984 dqn_agent.py:275] 	 update_period: 4
I0902 18:10:08.529244 140284730537984 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:10:08.529351 140284730537984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:10:08.529461 140284730537984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:10:08.529583 140284730537984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:10:08.529684 140284730537984 dqn_agent.py:280] 	 optimizer: adam
I0902 18:10:08.529775 140284730537984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:10:08.529870 140284730537984 dqn_agent.py:283] 	 seed: 1630606208528361
I0902 18:10:08.533245 140284730537984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:10:08.533448 140284730537984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:10:08.533643 140284730537984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:10:08.533783 140284730537984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:10:08.533907 140284730537984 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:10:08.534031 140284730537984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:10:08.534149 140284730537984 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:10:08.534264 140284730537984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:10:08.534378 140284730537984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:10:08.573752 140284730537984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.031250
I0902 18:10:08.955450 140284730537984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.031250
I0902 18:10:08.969002 140284730537984 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:10:08.978381 140284730537984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:10:08.978700 140284730537984 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:10:08.978855 140284730537984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:10:08.978974 140284730537984 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:10:08.979053 140284730537984 dqn_agent.py:275] 	 update_period: 4
I0902 18:10:08.979150 140284730537984 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:10:08.979269 140284730537984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:10:08.979495 140284730537984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:10:08.979606 140284730537984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:10:08.979688 140284730537984 dqn_agent.py:280] 	 optimizer: adam
I0902 18:10:08.979819 140284730537984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:10:08.979919 140284730537984 dqn_agent.py:283] 	 seed: 1630606208978332
I0902 18:10:08.982771 140284730537984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:10:08.982943 140284730537984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:10:08.983097 140284730537984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:10:08.983234 140284730537984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:10:08.983329 140284730537984 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:10:08.983459 140284730537984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:10:08.983546 140284730537984 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:10:08.983835 140284730537984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:10:08.984105 140284730537984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:10:09.057192 140284730537984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.031250
I0902 18:10:09.077681 140284730537984 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:10:09.077996 140284730537984 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 164.81
I0902 18:10:15.145743 140284730537984 replay_runner.py:36] Average training steps per second: 164.81
Steps executed: 214 Episode length: 126 Return: -631.7256495414603
I0902 18:10:16.659212 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -538.76
INFO:tensorflow:Starting iteration 1

Steps executed: 231 Episode length: 117 Return: -445.98750350270444
INFO:tensorflow:Average training steps per second: 222.82
I0902 18:10:25.471204 140284730537984 replay_runner.py:36] Average training steps per second: 222.82
I0902 18:10:25.675201 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -416.86
INFO:tensorflow:Starting iteration 2

Steps executed: 318 Episode length: 222 Return: -165.71135491136224
INFO:tensorflow:Average training steps per second: 221.63
I0902 18:10:34.620268 140284730537984 replay_runner.py:36] Average training steps per second: 221.63
I0902 18:10:34.926393 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -384.25
INFO:tensorflow:Starting iteration 3

Steps executed: 238 Episode length: 133 Return: -79.607165993023564
INFO:tensorflow:Average training steps per second: 219.29
I0902 18:10:43.824450 140284730537984 replay_runner.py:36] Average training steps per second: 219.29
I0902 18:10:44.036792 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.95
INFO:tensorflow:Starting iteration 4

Steps executed: 219 Episode length: 123 Return: -177.08460648847444
INFO:tensorflow:Average training steps per second: 221.46
I0902 18:10:52.878214 140284730537984 replay_runner.py:36] Average training steps per second: 221.46
I0902 18:10:53.061196 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.70
INFO:tensorflow:Starting iteration 5

Steps executed: 349 Episode length: 171 Return: -146.83427050888275
INFO:tensorflow:Average training steps per second: 238.30
I0902 18:11:01.531897 140284730537984 replay_runner.py:36] Average training steps per second: 238.30
I0902 18:11:01.798090 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -286.96
INFO:tensorflow:Starting iteration 6

Steps executed: 257 Episode length: 116 Return: -123.17928271111747
INFO:tensorflow:Average training steps per second: 247.85
I0902 18:11:09.945209 140284730537984 replay_runner.py:36] Average training steps per second: 247.85
I0902 18:11:10.148588 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.25
INFO:tensorflow:Starting iteration 7

Steps executed: 237 Episode length: 237 Return: -295.38113955582427
INFO:tensorflow:Average training steps per second: 254.63
I0902 18:11:18.078696 140284730537984 replay_runner.py:36] Average training steps per second: 254.63
I0902 18:11:18.308073 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -295.38
INFO:tensorflow:Starting iteration 8

Steps executed: 280 Episode length: 121 Return: -148.76126496409644
INFO:tensorflow:Average training steps per second: 262.85
I0902 18:11:26.064393 140284730537984 replay_runner.py:36] Average training steps per second: 262.85
I0902 18:11:26.279173 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.25
INFO:tensorflow:Starting iteration 9

Steps executed: 219 Episode length: 120 Return: -266.25012236425346
INFO:tensorflow:Average training steps per second: 264.44
I0902 18:11:34.010726 140284730537984 replay_runner.py:36] Average training steps per second: 264.44
I0902 18:11:34.156903 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.23
INFO:tensorflow:Starting iteration 10

Steps executed: 205 Episode length: 205 Return: -115.22415649236203
INFO:tensorflow:Average training steps per second: 262.69
I0902 18:11:41.888912 140284730537984 replay_runner.py:36] Average training steps per second: 262.69
I0902 18:11:42.053635 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.22
INFO:tensorflow:Starting iteration 11

Steps executed: 267 Episode length: 76 Return: -29.8591310472389684
INFO:tensorflow:Average training steps per second: 272.94
I0902 18:11:49.536867 140284730537984 replay_runner.py:36] Average training steps per second: 272.94
I0902 18:11:49.708252 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.56
INFO:tensorflow:Starting iteration 12

Steps executed: 269 Episode length: 133 Return: -279.48268778415025
INFO:tensorflow:Average training steps per second: 293.95
I0902 18:11:56.836708 140284730537984 replay_runner.py:36] Average training steps per second: 293.95
I0902 18:11:57.016444 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -272.67
INFO:tensorflow:Starting iteration 13

Steps executed: 268 Episode length: 187 Return: -145.23249595814988
INFO:tensorflow:Average training steps per second: 312.87
I0902 18:12:03.751640 140284730537984 replay_runner.py:36] Average training steps per second: 312.87
I0902 18:12:03.917094 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -204.80
INFO:tensorflow:Starting iteration 14

Steps executed: 208 Episode length: 139 Return: -438.48783109541046
INFO:tensorflow:Average training steps per second: 313.47
I0902 18:12:10.583307 140284730537984 replay_runner.py:36] Average training steps per second: 313.47
I0902 18:12:10.697876 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.20
INFO:tensorflow:Starting iteration 15

Steps executed: 251 Episode length: 91 Return: -372.040473100013866
INFO:tensorflow:Average training steps per second: 329.19
I0902 18:12:17.149854 140284730537984 replay_runner.py:36] Average training steps per second: 329.19
I0902 18:12:17.275998 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -330.22
INFO:tensorflow:Starting iteration 16

Steps executed: 264 Episode length: 108 Return: -419.16721712830616
INFO:tensorflow:Average training steps per second: 322.50
I0902 18:12:23.769585 140284730537984 replay_runner.py:36] Average training steps per second: 322.50
I0902 18:12:23.913922 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -335.09
INFO:tensorflow:Starting iteration 17

Steps executed: 95 Episode length: 95 Return: -349.5354632897819616
INFO:tensorflow:Average training steps per second: 341.18
I0902 18:12:30.242464 140284730537984 replay_runner.py:36] Average training steps per second: 341.18

Steps executed: 308 Episode length: 213 Return: -171.47235120510476
INFO:tensorflow:Starting iteration 18
I0902 18:12:33.834946 140284730537984 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 337.18

Steps executed: 732 Episode length: 563 Return: 110.120382337419026
I0902 18:12:37.533414 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -6.02
INFO:tensorflow:Starting iteration 19

Steps executed: 358 Episode length: 358 Return: 138.667721706488446
INFO:tensorflow:Average training steps per second: 329.81
I0902 18:12:43.997286 140284730537984 replay_runner.py:36] Average training steps per second: 329.81
I0902 18:12:44.339898 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: 138.67
INFO:tensorflow:Starting iteration 20

Steps executed: 233 Episode length: 121 Return: -124.64805560178826
INFO:tensorflow:Average training steps per second: 338.39
I0902 18:12:50.707472 140284730537984 replay_runner.py:36] Average training steps per second: 338.39
I0902 18:12:50.822820 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.90
INFO:tensorflow:Starting iteration 21

Steps executed: 152 Episode length: 76 Return: -300.877580971469346
INFO:tensorflow:Average training steps per second: 341.08

Steps executed: 1152 Episode length: 1000 Return: -80.09346898375614
I0902 18:12:59.665459 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.52
INFO:tensorflow:Starting iteration 22

Steps executed: 192 Episode length: 192 Return: -213.888034099161614
INFO:tensorflow:Average training steps per second: 327.70

Steps executed: 1192 Episode length: 1000 Return: -54.16420709003798
I0902 18:13:07.527255 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.03
INFO:tensorflow:Starting iteration 23

Steps executed: 285 Episode length: 166 Return: -585.506715379657258
INFO:tensorflow:Average training steps per second: 325.64
I0902 18:13:13.843009 140284730537984 replay_runner.py:36] Average training steps per second: 325.64
I0902 18:13:14.014225 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -447.95
INFO:tensorflow:Starting iteration 24

Steps executed: 300 Episode length: 121 Return: 65.08639778161654638
INFO:tensorflow:Average training steps per second: 337.48
I0902 18:13:20.317541 140284730537984 replay_runner.py:36] Average training steps per second: 337.48
I0902 18:13:20.499883 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.10
INFO:tensorflow:Starting iteration 25

Steps executed: 275 Episode length: 126 Return: -980.754826789558938
INFO:tensorflow:Average training steps per second: 339.24
I0902 18:13:26.833665 140284730537984 replay_runner.py:36] Average training steps per second: 339.24
I0902 18:13:27.000990 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -541.09
INFO:tensorflow:Starting iteration 26

Steps executed: 318 Episode length: 318 Return: -64.2100318249691538
INFO:tensorflow:Average training steps per second: 344.48
I0902 18:13:33.349356 140284730537984 replay_runner.py:36] Average training steps per second: 344.48
I0902 18:13:33.609014 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -64.21
INFO:tensorflow:Starting iteration 27

Steps executed: 245 Episode length: 245 Return: -421.979546212233538
INFO:tensorflow:Average training steps per second: 340.63
I0902 18:13:39.972647 140284730537984 replay_runner.py:36] Average training steps per second: 340.63
I0902 18:13:40.142672 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -421.98
INFO:tensorflow:Starting iteration 28

Steps executed: 201 Episode length: 102 Return: -310.595695835057438
INFO:tensorflow:Average training steps per second: 338.08
I0902 18:13:46.310602 140284730537984 replay_runner.py:36] Average training steps per second: 338.08
I0902 18:13:46.427882 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -363.32
INFO:tensorflow:Starting iteration 29

Steps executed: 257 Episode length: 257 Return: -138.294568732256538
INFO:tensorflow:Average training steps per second: 364.18
I0902 18:13:52.229037 140284730537984 replay_runner.py:36] Average training steps per second: 364.18

Done fixed training!Episode length: 257 Return: -138.294568732256538