Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0902 11:31:32.650863 140176592435200 run_experiment.py:549] Creating TrainRunner ...
I0902 11:31:32.659082 140176592435200 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 11:31:32.659212 140176592435200 dqn_agent.py:272] 	 gamma: 0.990000
I0902 11:31:32.659289 140176592435200 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 11:31:32.659350 140176592435200 dqn_agent.py:274] 	 min_replay_history: 500
I0902 11:31:32.659408 140176592435200 dqn_agent.py:275] 	 update_period: 4
I0902 11:31:32.659475 140176592435200 dqn_agent.py:276] 	 target_update_period: 300
I0902 11:31:32.659532 140176592435200 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 11:31:32.659605 140176592435200 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 11:31:32.659658 140176592435200 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 11:31:32.659723 140176592435200 dqn_agent.py:280] 	 optimizer: adam
I0902 11:31:32.659774 140176592435200 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 11:31:32.659877 140176592435200 dqn_agent.py:283] 	 seed: 1630582292659047
I0902 11:31:32.661611 140176592435200 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 11:31:32.661732 140176592435200 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 11:31:32.661814 140176592435200 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 11:31:32.661887 140176592435200 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 11:31:32.661961 140176592435200 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 11:31:32.662014 140176592435200 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 11:31:32.662067 140176592435200 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 11:31:32.662175 140176592435200 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 11:31:32.662245 140176592435200 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 11:31:32.818979 140176592435200 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:33.093151 140176592435200 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:33.102464 140176592435200 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 11:31:33.109126 140176592435200 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 11:31:33.109261 140176592435200 dqn_agent.py:272] 	 gamma: 0.990000
I0902 11:31:33.109333 140176592435200 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 11:31:33.109395 140176592435200 dqn_agent.py:274] 	 min_replay_history: 500
I0902 11:31:33.109450 140176592435200 dqn_agent.py:275] 	 update_period: 4
I0902 11:31:33.109523 140176592435200 dqn_agent.py:276] 	 target_update_period: 300
I0902 11:31:33.109638 140176592435200 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 11:31:33.109691 140176592435200 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 11:31:33.109746 140176592435200 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 11:31:33.109842 140176592435200 dqn_agent.py:280] 	 optimizer: adam
I0902 11:31:33.109893 140176592435200 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 11:31:33.109955 140176592435200 dqn_agent.py:283] 	 seed: 1630582293109094
I0902 11:31:33.111370 140176592435200 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 11:31:33.111483 140176592435200 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 11:31:33.111560 140176592435200 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 11:31:33.111622 140176592435200 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 11:31:33.111678 140176592435200 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 11:31:33.111732 140176592435200 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 11:31:33.111812 140176592435200 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 11:31:33.111880 140176592435200 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 11:31:33.111957 140176592435200 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 11:31:33.169261 140176592435200 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:33.188787 140176592435200 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 11:31:33.188974 140176592435200 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 194.61
I0902 11:31:38.327681 140176592435200 replay_runner.py:36] Average training steps per second: 194.61
I0902 11:31:39.304369 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -22.19
Steps executed: 277 Episode length: 128 Return: 21.56263799198831
INFO:tensorflow:Starting iteration 1

Steps executed: 262 Episode length: 161 Return: -351.3025753818648
INFO:tensorflow:Average training steps per second: 340.84
I0902 11:31:45.749423 140176592435200 replay_runner.py:36] Average training steps per second: 340.84
I0902 11:31:45.894961 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -358.72
INFO:tensorflow:Starting iteration 2

Steps executed: 271 Episode length: 143 Return: -246.16910709949434
INFO:tensorflow:Average training steps per second: 337.40
I0902 11:31:52.294526 140176592435200 replay_runner.py:36] Average training steps per second: 337.40
I0902 11:31:52.441642 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.98
INFO:tensorflow:Starting iteration 3
I0902 11:31:55.850432 140176592435200 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 326.43

Steps executed: 1000 Episode length: 1000 Return: -112.05678927264829
I0902 11:32:00.418432 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.06
INFO:tensorflow:Starting iteration 4

Steps executed: 753 Episode length: 753 Return: -245.4185437338422329
INFO:tensorflow:Average training steps per second: 331.19
I0902 11:32:06.719542 140176592435200 replay_runner.py:36] Average training steps per second: 331.19
I0902 11:32:07.996302 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.42
INFO:tensorflow:Starting iteration 5
I0902 11:32:11.339717 140176592435200 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 325.78

Steps executed: 1000 Episode length: 1000 Return: -168.60087091628304
I0902 11:32:16.249799 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.60
INFO:tensorflow:Starting iteration 6
I0902 11:32:19.635958 140176592435200 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 343.55

Steps executed: 1000 Episode length: 1000 Return: -277.60624513717784
I0902 11:32:24.787230 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.61
INFO:tensorflow:Starting iteration 7

Steps executed: 590 Episode length: 460 Return: -195.2756144067756284
INFO:tensorflow:Average training steps per second: 345.96
I0902 11:32:31.088180 140176592435200 replay_runner.py:36] Average training steps per second: 345.96
I0902 11:32:31.618450 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.99
INFO:tensorflow:Starting iteration 8

Steps executed: 142 Episode length: 142 Return: -64.52051335420956284
INFO:tensorflow:Average training steps per second: 357.24

Steps executed: 1142 Episode length: 1000 Return: -462.43037053537404
I0902 11:32:39.478950 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.48
INFO:tensorflow:Starting iteration 9
I0902 11:32:42.852312 140176592435200 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 343.76

Steps executed: 1000 Episode length: 1000 Return: -423.58027909737734
I0902 11:32:47.516287 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -423.58
INFO:tensorflow:Starting iteration 10

Steps executed: 439 Episode length: 439 Return: -142.7727935553323734
INFO:tensorflow:Average training steps per second: 348.72
I0902 11:32:53.797595 140176592435200 replay_runner.py:36] Average training steps per second: 348.72
I0902 11:32:54.321618 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.77
INFO:tensorflow:Starting iteration 11
I0902 11:32:57.757062 140176592435200 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 353.21

Steps executed: 1000 Episode length: 1000 Return: -79.340163053075844
I0902 11:33:02.181256 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.34
INFO:tensorflow:Starting iteration 12
I0902 11:33:05.586011 140176592435200 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 361.35

Steps executed: 1000 Episode length: 1000 Return: -16.177984393559814
I0902 11:33:10.946457 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -16.18
INFO:tensorflow:Starting iteration 13

Steps executed: 1000 Episode length: 1000 Return: -165.82774129185364
INFO:tensorflow:Average training steps per second: 331.88
I0902 11:33:17.259313 140176592435200 replay_runner.py:36] Average training steps per second: 331.88
I0902 11:33:18.802663 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.83
INFO:tensorflow:Starting iteration 14
I0902 11:33:22.076063 140176592435200 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 315.07

Steps executed: 1000 Episode length: 1000 Return: -90.295015045418384
I0902 11:33:26.939275 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.30
INFO:tensorflow:Starting iteration 15

Steps executed: 280 Episode length: 280 Return: -138.6473703687360384
INFO:tensorflow:Average training steps per second: 316.70
I0902 11:33:33.328628 140176592435200 replay_runner.py:36] Average training steps per second: 316.70
I0902 11:33:33.568801 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.65
INFO:tensorflow:Starting iteration 16

Steps executed: 261 Episode length: 261 Return: -195.6187853132726384
INFO:tensorflow:Average training steps per second: 313.64
I0902 11:33:40.010346 140176592435200 replay_runner.py:36] Average training steps per second: 313.64
I0902 11:33:40.237480 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.62
INFO:tensorflow:Starting iteration 17
I0902 11:33:43.579485 140176592435200 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 320.57

Steps executed: 887 Episode length: 887 Return: 89.324562124523856384
I0902 11:33:48.361453 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: 89.32
INFO:tensorflow:Starting iteration 18
I0902 11:33:51.613399 140176592435200 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 327.39
I0902 11:33:54.668129 140176592435200 replay_runner.py:36] Average training steps per second: 327.39

Steps executed: 347 Episode length: 347 Return: -208.7932528945429384
INFO:tensorflow:Starting iteration 19

Steps executed: 407 Episode length: 221 Return: -202.2489433910977384
INFO:tensorflow:Average training steps per second: 335.92
I0902 11:34:01.348058 140176592435200 replay_runner.py:36] Average training steps per second: 335.92
I0902 11:34:01.619513 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -172.34
INFO:tensorflow:Starting iteration 20
I0902 11:34:05.174011 140176592435200 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 353.28
I0902 11:34:08.004881 140176592435200 replay_runner.py:36] Average training steps per second: 353.28

Steps executed: 400 Episode length: 400 Return: -251.6096384580763884
INFO:tensorflow:Starting iteration 21
I0902 11:34:12.244871 140176592435200 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 347.83

Steps executed: 342 Episode length: 201 Return: -262.2077247353752384
I0902 11:34:15.340812 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.39
INFO:tensorflow:Starting iteration 22

Steps executed: 344 Episode length: 344 Return: -508.3114233074836384
INFO:tensorflow:Average training steps per second: 337.97
I0902 11:34:21.758604 140176592435200 replay_runner.py:36] Average training steps per second: 337.97
I0902 11:34:22.036290 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -508.31
INFO:tensorflow:Starting iteration 23
I0902 11:34:25.479355 140176592435200 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 325.99

Steps executed: 495 Episode length: 495 Return: 168.03310725300807384
I0902 11:34:29.131190 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: 168.03
INFO:tensorflow:Starting iteration 24

Steps executed: 362 Episode length: 362 Return: -59.04349843570762384
INFO:tensorflow:Average training steps per second: 315.95
I0902 11:34:35.676708 140176592435200 replay_runner.py:36] Average training steps per second: 315.95
I0902 11:34:36.010822 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -59.04
INFO:tensorflow:Starting iteration 25

Steps executed: 241 Episode length: 241 Return: -127.6736831461593284
INFO:tensorflow:Average training steps per second: 315.25
I0902 11:34:42.149367 140176592435200 replay_runner.py:36] Average training steps per second: 315.25
I0902 11:34:42.355792 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.67
INFO:tensorflow:Starting iteration 26

Steps executed: 269 Episode length: 161 Return: -34.47337324343836484
INFO:tensorflow:Average training steps per second: 313.61
I0902 11:34:48.716955 140176592435200 replay_runner.py:36] Average training steps per second: 313.61
I0902 11:34:48.886399 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -36.42
INFO:tensorflow:Starting iteration 27

Steps executed: 929 Episode length: 929 Return: 221.97643359555758484
INFO:tensorflow:Average training steps per second: 339.82
I0902 11:34:54.962372 140176592435200 replay_runner.py:36] Average training steps per second: 339.82
I0902 11:34:56.364653 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: 221.98
INFO:tensorflow:Starting iteration 28

Steps executed: 451 Episode length: 317 Return: -304.3505223758319384
INFO:tensorflow:Average training steps per second: 335.01
I0902 11:35:02.577017 140176592435200 replay_runner.py:36] Average training steps per second: 335.01
I0902 11:35:02.942716 140176592435200 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.07
INFO:tensorflow:Starting iteration 29

Steps executed: 246 Episode length: 246 Return: -53.01486710404191384
INFO:tensorflow:Average training steps per second: 328.72
I0902 11:35:09.100753 140176592435200 replay_runner.py:36] Average training steps per second: 328.72

Done fixed training!Episode length: 246 Return: -53.01486710404191384