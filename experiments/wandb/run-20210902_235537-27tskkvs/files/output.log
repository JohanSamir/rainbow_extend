Loaded trained dqn in acrobot
Training fixed agent 7, please be patient, may be a while...
I0902 23:55:44.021536 140527680751616 run_experiment.py:549] Creating TrainRunner ...
I0902 23:55:44.032428 140527680751616 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:55:44.032748 140527680751616 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:55:44.032998 140527680751616 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:55:44.033183 140527680751616 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:55:44.033316 140527680751616 dqn_agent.py:275] 	 update_period: 4
I0902 23:55:44.033457 140527680751616 dqn_agent.py:276] 	 target_update_period: 100
I0902 23:55:44.033624 140527680751616 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:55:44.033747 140527680751616 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:55:44.033865 140527680751616 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:55:44.033986 140527680751616 dqn_agent.py:280] 	 optimizer: adam
I0902 23:55:44.034111 140527680751616 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:55:44.034232 140527680751616 dqn_agent.py:283] 	 seed: 1630626944032342
I0902 23:55:44.037699 140527680751616 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:55:44.037927 140527680751616 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0902 23:55:44.038096 140527680751616 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:55:44.038250 140527680751616 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:55:44.038752 140527680751616 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:55:44.038925 140527680751616 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:55:44.039062 140527680751616 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:55:44.039184 140527680751616 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:55:44.039311 140527680751616 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:55:44.083089 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:55:44.584486 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:55:44.599046 140527680751616 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:55:44.610034 140527680751616 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:55:44.610304 140527680751616 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:55:44.610420 140527680751616 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:55:44.610513 140527680751616 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:55:44.610593 140527680751616 dqn_agent.py:275] 	 update_period: 4
I0902 23:55:44.610684 140527680751616 dqn_agent.py:276] 	 target_update_period: 100
I0902 23:55:44.610804 140527680751616 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:55:44.610983 140527680751616 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:55:44.611128 140527680751616 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:55:44.611244 140527680751616 dqn_agent.py:280] 	 optimizer: adam
I0902 23:55:44.611381 140527680751616 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:55:44.611655 140527680751616 dqn_agent.py:283] 	 seed: 1630626944609960
I0902 23:55:44.614275 140527680751616 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:55:44.614440 140527680751616 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0902 23:55:44.614536 140527680751616 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:55:44.614655 140527680751616 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:55:44.614731 140527680751616 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:55:44.614787 140527680751616 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:55:44.614845 140527680751616 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:55:44.614898 140527680751616 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:55:44.614950 140527680751616 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:55:44.647523 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:55:44.673174 140527680751616 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:55:44.673418 140527680751616 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 148.10
I0902 23:55:51.425985 140527680751616 replay_runner.py:36] Average training steps per second: 148.10
Steps executed: 500 Episode length: 500 Return: -500.0
I0902 23:55:52.902437 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1

Steps executed: 355 Episode length: 213 Return: -212.0
INFO:tensorflow:Average training steps per second: 206.98
I0902 23:55:57.959882 140527680751616 replay_runner.py:36] Average training steps per second: 206.98
I0902 23:55:58.256517 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.50
INFO:tensorflow:Starting iteration 2
I0902 23:55:58.483610 140527680751616 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 207.04
I0902 23:56:03.313980 140527680751616 replay_runner.py:36] Average training steps per second: 207.04

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Starting iteration 3

Steps executed: 203 Episode length: 203 Return: -202.0
INFO:tensorflow:Average training steps per second: 202.52
I0902 23:56:08.884055 140527680751616 replay_runner.py:36] Average training steps per second: 202.52
I0902 23:56:09.047828 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.00
INFO:tensorflow:Starting iteration 4

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 201.36
I0902 23:56:14.248164 140527680751616 replay_runner.py:36] Average training steps per second: 201.36
I0902 23:56:14.653081 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 5
I0902 23:56:14.887685 140527680751616 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 199.79
I0902 23:56:19.893221 140527680751616 replay_runner.py:36] Average training steps per second: 199.79
I0902 23:56:20.289393 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6
I0902 23:56:20.517619 140527680751616 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 201.41
I0902 23:56:25.483017 140527680751616 replay_runner.py:36] Average training steps per second: 201.41
I0902 23:56:25.902403 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7

Steps executed: 203 Episode length: 203 Return: -202.0
INFO:tensorflow:Average training steps per second: 202.36
I0902 23:56:31.073130 140527680751616 replay_runner.py:36] Average training steps per second: 202.36
I0902 23:56:31.249972 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.00
INFO:tensorflow:Starting iteration 8

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 192.66
I0902 23:56:36.684433 140527680751616 replay_runner.py:36] Average training steps per second: 192.66
I0902 23:56:37.137740 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 9
I0902 23:56:37.383737 140527680751616 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 194.33
I0902 23:56:42.530199 140527680751616 replay_runner.py:36] Average training steps per second: 194.33
I0902 23:56:42.967850 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 10

Steps executed: 239 Episode length: 239 Return: -238.0
INFO:tensorflow:Average training steps per second: 192.92
I0902 23:56:48.402243 140527680751616 replay_runner.py:36] Average training steps per second: 192.92
I0902 23:56:48.602572 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -238.00
INFO:tensorflow:Starting iteration 11
I0902 23:56:48.832479 140527680751616 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 193.70

Steps executed: 631 Episode length: 452 Return: -451.0
I0902 23:56:54.524492 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.50
INFO:tensorflow:Starting iteration 12
I0902 23:56:54.759958 140527680751616 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 200.21
I0902 23:56:59.755236 140527680751616 replay_runner.py:36] Average training steps per second: 200.21

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Starting iteration 13

Steps executed: 351 Episode length: 351 Return: -350.0
INFO:tensorflow:Average training steps per second: 197.65
I0902 23:57:05.436679 140527680751616 replay_runner.py:36] Average training steps per second: 197.65
I0902 23:57:05.740992 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -350.00
INFO:tensorflow:Starting iteration 14

Steps executed: 285 Episode length: 166 Return: -165.0
INFO:tensorflow:Average training steps per second: 197.88
I0902 23:57:11.044510 140527680751616 replay_runner.py:36] Average training steps per second: 197.88
I0902 23:57:11.270118 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.50
INFO:tensorflow:Starting iteration 15

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 202.33
I0902 23:57:16.448354 140527680751616 replay_runner.py:36] Average training steps per second: 202.33
I0902 23:57:16.862537 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 16
I0902 23:57:17.108198 140527680751616 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 205.25
I0902 23:57:21.980735 140527680751616 replay_runner.py:36] Average training steps per second: 205.25
I0902 23:57:22.365274 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 17

Steps executed: 363 Episode length: 363 Return: -362.0
INFO:tensorflow:Average training steps per second: 201.86
I0902 23:57:27.554410 140527680751616 replay_runner.py:36] Average training steps per second: 201.86
I0902 23:57:27.843591 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -362.00
INFO:tensorflow:Starting iteration 18

Steps executed: 481 Episode length: 319 Return: -318.0
INFO:tensorflow:Average training steps per second: 204.91
I0902 23:57:32.972262 140527680751616 replay_runner.py:36] Average training steps per second: 204.91
I0902 23:57:33.350799 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -239.50
INFO:tensorflow:Starting iteration 19

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 205.05
I0902 23:57:38.467887 140527680751616 replay_runner.py:36] Average training steps per second: 205.05
I0902 23:57:38.876553 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 20
I0902 23:57:39.108013 140527680751616 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 204.75
I0902 23:57:43.992338 140527680751616 replay_runner.py:36] Average training steps per second: 204.75

Steps executed: 299 Episode length: 160 Return: -159.0
INFO:tensorflow:Starting iteration 21

Steps executed: 270 Episode length: 150 Return: -149.0
INFO:tensorflow:Average training steps per second: 208.91
I0902 23:57:49.243370 140527680751616 replay_runner.py:36] Average training steps per second: 208.91
I0902 23:57:49.456482 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.00
INFO:tensorflow:Starting iteration 22
I0902 23:57:49.694743 140527680751616 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 214.34

Steps executed: 323 Episode length: 166 Return: -165.0
I0902 23:57:54.604790 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.50
INFO:tensorflow:Starting iteration 23

Steps executed: 255 Episode length: 155 Return: -154.0
INFO:tensorflow:Average training steps per second: 212.60
I0902 23:57:59.534857 140527680751616 replay_runner.py:36] Average training steps per second: 212.60
I0902 23:57:59.724621 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.50
INFO:tensorflow:Starting iteration 24
I0902 23:57:59.942378 140527680751616 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 220.00

Steps executed: 305 Episode length: 305 Return: -304.0
I0902 23:58:04.725102 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.00
INFO:tensorflow:Starting iteration 25

Steps executed: 316 Episode length: 127 Return: -126.0
INFO:tensorflow:Average training steps per second: 220.99
I0902 23:58:09.471525 140527680751616 replay_runner.py:36] Average training steps per second: 220.99
I0902 23:58:09.713350 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.33
INFO:tensorflow:Starting iteration 26
I0902 23:58:09.944340 140527680751616 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 228.41
I0902 23:58:14.322935 140527680751616 replay_runner.py:36] Average training steps per second: 228.41

Steps executed: 286 Episode length: 122 Return: -121.0
INFO:tensorflow:Starting iteration 27

Steps executed: 210 Episode length: 111 Return: -110.0
INFO:tensorflow:Average training steps per second: 224.22
I0902 23:58:19.210809 140527680751616 replay_runner.py:36] Average training steps per second: 224.22
I0902 23:58:19.374696 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.00
INFO:tensorflow:Starting iteration 28

Steps executed: 437 Episode length: 254 Return: -253.0
INFO:tensorflow:Average training steps per second: 221.72
I0902 23:58:24.110657 140527680751616 replay_runner.py:36] Average training steps per second: 221.72
I0902 23:58:24.423331 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.50
INFO:tensorflow:Starting iteration 29
I0902 23:58:24.640696 140527680751616 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 222.09
I0902 23:58:29.143727 140527680751616 replay_runner.py:36] Average training steps per second: 222.09

Done fixed training!Episode length: 195 Return: -194.0