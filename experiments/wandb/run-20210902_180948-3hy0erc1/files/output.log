Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0902 18:09:55.210331 140131099109376 run_experiment.py:549] Creating TrainRunner ...
I0902 18:09:55.221318 140131099109376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:09:55.221572 140131099109376 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:09:55.221883 140131099109376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:09:55.222055 140131099109376 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:09:55.222205 140131099109376 dqn_agent.py:275] 	 update_period: 4
I0902 18:09:55.222319 140131099109376 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:09:55.222483 140131099109376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:09:55.222589 140131099109376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:09:55.222688 140131099109376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:09:55.222784 140131099109376 dqn_agent.py:280] 	 optimizer: adam
I0902 18:09:55.222930 140131099109376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:09:55.223109 140131099109376 dqn_agent.py:283] 	 seed: 1630606195221256
I0902 18:09:55.226288 140131099109376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:09:55.226494 140131099109376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:09:55.226604 140131099109376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:09:55.226694 140131099109376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:09:55.226837 140131099109376 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:09:55.227016 140131099109376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:09:55.227253 140131099109376 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:09:55.227454 140131099109376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:09:55.227673 140131099109376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:09:55.265157 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.031250
I0902 18:09:55.655942 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.031250
I0902 18:09:55.671394 140131099109376 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:09:55.681112 140131099109376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:09:55.681339 140131099109376 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:09:55.681437 140131099109376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:09:55.681515 140131099109376 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:09:55.681588 140131099109376 dqn_agent.py:275] 	 update_period: 4
I0902 18:09:55.681738 140131099109376 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:09:55.681927 140131099109376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:09:55.682033 140131099109376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:09:55.682127 140131099109376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:09:55.682219 140131099109376 dqn_agent.py:280] 	 optimizer: adam
I0902 18:09:55.682319 140131099109376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:09:55.682410 140131099109376 dqn_agent.py:283] 	 seed: 1630606195681044
I0902 18:09:55.683944 140131099109376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:09:55.684061 140131099109376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:09:55.684130 140131099109376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:09:55.684191 140131099109376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:09:55.684247 140131099109376 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:09:55.684325 140131099109376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:09:55.684385 140131099109376 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:09:55.684462 140131099109376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:09:55.684531 140131099109376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:09:55.766041 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.031250
I0902 18:09:55.790332 140131099109376 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:09:55.790548 140131099109376 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 158.35
I0902 18:10:02.106056 140131099109376 replay_runner.py:36] Average training steps per second: 158.35
Steps executed: 242 Episode length: 242 Return: -308.725733686871
I0902 18:10:03.510627 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.73
INFO:tensorflow:Starting iteration 1

Steps executed: 365 Episode length: 203 Return: -337.9103026093812
INFO:tensorflow:Average training steps per second: 229.17
I0902 18:10:12.194963 140131099109376 replay_runner.py:36] Average training steps per second: 229.17
I0902 18:10:12.588206 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -365.71
INFO:tensorflow:Starting iteration 2

Steps executed: 301 Episode length: 167 Return: -129.61853773660084
INFO:tensorflow:Average training steps per second: 224.35
I0902 18:10:21.443998 140131099109376 replay_runner.py:36] Average training steps per second: 224.35
I0902 18:10:21.742995 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.16
INFO:tensorflow:Starting iteration 3

Steps executed: 253 Episode length: 130 Return: -408.78332786697166
INFO:tensorflow:Average training steps per second: 222.66
I0902 18:10:30.608029 140131099109376 replay_runner.py:36] Average training steps per second: 222.66
I0902 18:10:30.865568 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.76
INFO:tensorflow:Starting iteration 4

Steps executed: 206 Episode length: 206 Return: -118.92298019119089
INFO:tensorflow:Average training steps per second: 226.51
I0902 18:10:39.445833 140131099109376 replay_runner.py:36] Average training steps per second: 226.51
I0902 18:10:39.645342 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.92
INFO:tensorflow:Starting iteration 5

Steps executed: 232 Episode length: 116 Return: -281.73098106086799
INFO:tensorflow:Average training steps per second: 233.24
I0902 18:10:48.288886 140131099109376 replay_runner.py:36] Average training steps per second: 233.24
I0902 18:10:48.500106 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.33
INFO:tensorflow:Starting iteration 6

Steps executed: 290 Episode length: 138 Return: -389.82082476790379
INFO:tensorflow:Average training steps per second: 239.75
I0902 18:10:56.929903 140131099109376 replay_runner.py:36] Average training steps per second: 239.75
I0902 18:10:57.198934 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.23
INFO:tensorflow:Starting iteration 7

Steps executed: 355 Episode length: 226 Return: -345.28253970805799
INFO:tensorflow:Average training steps per second: 253.54
I0902 18:11:05.448279 140131099109376 replay_runner.py:36] Average training steps per second: 253.54
I0902 18:11:05.795876 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.57
INFO:tensorflow:Starting iteration 8

Steps executed: 262 Episode length: 150 Return: -327.66608486820819
INFO:tensorflow:Average training steps per second: 260.46
I0902 18:11:13.797896 140131099109376 replay_runner.py:36] Average training steps per second: 260.46
I0902 18:11:14.018182 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -380.46
INFO:tensorflow:Starting iteration 9

Steps executed: 402 Episode length: 240 Return: -73.477637453590269
INFO:tensorflow:Average training steps per second: 268.60
I0902 18:11:21.887011 140131099109376 replay_runner.py:36] Average training steps per second: 268.60
I0902 18:11:22.225275 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.88
INFO:tensorflow:Starting iteration 10

Steps executed: 225 Episode length: 142 Return: -126.81560403711039
INFO:tensorflow:Average training steps per second: 270.01
I0902 18:11:29.933413 140131099109376 replay_runner.py:36] Average training steps per second: 270.01
I0902 18:11:30.094268 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.12
INFO:tensorflow:Starting iteration 11

Steps executed: 204 Episode length: 204 Return: -309.29691679508693
INFO:tensorflow:Average training steps per second: 279.56
I0902 18:11:37.730042 140131099109376 replay_runner.py:36] Average training steps per second: 279.56
I0902 18:11:37.896282 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.30
INFO:tensorflow:Starting iteration 12

Steps executed: 318 Episode length: 157 Return: -271.01135907078752
INFO:tensorflow:Average training steps per second: 274.33
I0902 18:11:45.623235 140131099109376 replay_runner.py:36] Average training steps per second: 274.33
I0902 18:11:45.877710 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.51
INFO:tensorflow:Starting iteration 13
I0902 18:11:49.844827 140131099109376 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 295.66

Steps executed: 307 Episode length: 113 Return: -331.60897800583103
I0902 18:11:53.422159 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.60
INFO:tensorflow:Starting iteration 14

Steps executed: 234 Episode length: 234 Return: -439.30949761997593
INFO:tensorflow:Average training steps per second: 316.87
I0902 18:12:00.353187 140131099109376 replay_runner.py:36] Average training steps per second: 316.87
I0902 18:12:00.550726 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -439.31
INFO:tensorflow:Starting iteration 15

Steps executed: 88 Episode length: 88 Return: -166.1925249480512793
INFO:tensorflow:Average training steps per second: 337.59
I0902 18:12:07.138345 140131099109376 replay_runner.py:36] Average training steps per second: 337.59

Steps executed: 288 Episode length: 200 Return: -737.11126167286483
INFO:tensorflow:Starting iteration 16

Steps executed: 239 Episode length: 79 Return: -108.424731015184183
INFO:tensorflow:Average training steps per second: 345.41
I0902 18:12:13.804634 140131099109376 replay_runner.py:36] Average training steps per second: 345.41
I0902 18:12:13.925575 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.86
INFO:tensorflow:Starting iteration 17

Steps executed: 426 Episode length: 329 Return: -271.61592611755566
INFO:tensorflow:Average training steps per second: 349.49
I0902 18:12:20.311729 140131099109376 replay_runner.py:36] Average training steps per second: 349.49
I0902 18:12:20.676855 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.14
INFO:tensorflow:Starting iteration 18

Steps executed: 320 Episode length: 320 Return: -337.59465773101635
INFO:tensorflow:Average training steps per second: 348.93
I0902 18:12:27.041021 140131099109376 replay_runner.py:36] Average training steps per second: 348.93
I0902 18:12:27.329877 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -337.59
INFO:tensorflow:Starting iteration 19

Steps executed: 313 Episode length: 154 Return: -103.15726321074816
INFO:tensorflow:Average training steps per second: 330.32
I0902 18:12:33.805094 140131099109376 replay_runner.py:36] Average training steps per second: 330.32
I0902 18:12:34.016590 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.54
INFO:tensorflow:Starting iteration 20

Steps executed: 244 Episode length: 82 Return: -165.747248634201696
INFO:tensorflow:Average training steps per second: 339.57
I0902 18:12:40.382934 140131099109376 replay_runner.py:36] Average training steps per second: 339.57
I0902 18:12:40.503208 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.71
INFO:tensorflow:Starting iteration 21
I0902 18:12:43.947207 140131099109376 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 341.70

Steps executed: 1000 Episode length: 1000 Return: -49.09646781111453
I0902 18:12:48.469032 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -49.10
INFO:tensorflow:Starting iteration 22

Steps executed: 242 Episode length: 120 Return: -265.903487791109853
INFO:tensorflow:Average training steps per second: 340.46
I0902 18:12:54.831855 140131099109376 replay_runner.py:36] Average training steps per second: 340.46
I0902 18:12:54.976238 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.01
INFO:tensorflow:Starting iteration 23

Steps executed: 253 Episode length: 128 Return: -98.2102739807744553
INFO:tensorflow:Average training steps per second: 353.90
I0902 18:13:01.274905 140131099109376 replay_runner.py:36] Average training steps per second: 353.90
I0902 18:13:01.407195 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.63
INFO:tensorflow:Starting iteration 24

Steps executed: 1013 Episode length: 963 Return: -187.13744537826955
INFO:tensorflow:Average training steps per second: 343.68
I0902 18:13:07.823228 140131099109376 replay_runner.py:36] Average training steps per second: 343.68
I0902 18:13:09.517459 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.95
INFO:tensorflow:Starting iteration 25

Steps executed: 264 Episode length: 102 Return: -242.549180358193955
INFO:tensorflow:Average training steps per second: 341.18
I0902 18:13:15.938688 140131099109376 replay_runner.py:36] Average training steps per second: 341.18
I0902 18:13:16.068834 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -222.71
INFO:tensorflow:Starting iteration 26

Steps executed: 100 Episode length: 100 Return: -302.496907957644855
INFO:tensorflow:Average training steps per second: 334.29

Steps executed: 1100 Episode length: 1000 Return: -54.88880502058395
I0902 18:13:24.287715 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.69
INFO:tensorflow:Starting iteration 27

Steps executed: 218 Episode length: 123 Return: -525.675446292058395
INFO:tensorflow:Average training steps per second: 337.20
I0902 18:13:30.701285 140131099109376 replay_runner.py:36] Average training steps per second: 337.20
I0902 18:13:30.827702 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -413.10
INFO:tensorflow:Starting iteration 28

Steps executed: 211 Episode length: 107 Return: -1009.47504959123745
INFO:tensorflow:Average training steps per second: 334.24
I0902 18:13:37.239615 140131099109376 replay_runner.py:36] Average training steps per second: 334.24
I0902 18:13:37.366012 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -594.90
INFO:tensorflow:Starting iteration 29

Steps executed: 281 Episode length: 169 Return: 19.00915751922443545
INFO:tensorflow:Average training steps per second: 381.43
I0902 18:13:43.405830 140131099109376 replay_runner.py:36] Average training steps per second: 381.43

Done fixed training!Episode length: 169 Return: 19.00915751922443545