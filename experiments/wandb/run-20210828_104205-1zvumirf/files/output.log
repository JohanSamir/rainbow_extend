Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0828 10:42:11.848472 140220309850112 run_experiment.py:549] Creating TrainRunner ...
I0828 10:42:11.858888 140220309850112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:11.859115 140220309850112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:11.859252 140220309850112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:11.859380 140220309850112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:11.859524 140220309850112 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:11.859726 140220309850112 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:11.859885 140220309850112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:11.860066 140220309850112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:11.860218 140220309850112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:11.860373 140220309850112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:11.860474 140220309850112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:11.860606 140220309850112 dqn_agent.py:283] 	 seed: 1630147331858819
I0828 10:42:11.862972 140220309850112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:11.863095 140220309850112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:11.863176 140220309850112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:11.863241 140220309850112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:11.863303 140220309850112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:11.863383 140220309850112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:11.863503 140220309850112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:11.863592 140220309850112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:11.863667 140220309850112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:11.899449 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:12.258307 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:12.273430 140220309850112 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:42:12.282316 140220309850112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:12.282598 140220309850112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:12.282719 140220309850112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:12.282835 140220309850112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:12.283095 140220309850112 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:12.283337 140220309850112 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:12.283555 140220309850112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:12.283715 140220309850112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:12.283881 140220309850112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:12.284036 140220309850112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:12.284126 140220309850112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:12.284228 140220309850112 dqn_agent.py:283] 	 seed: 1630147332282250
I0828 10:42:12.287018 140220309850112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:12.287251 140220309850112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:12.287360 140220309850112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:12.287467 140220309850112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:12.287644 140220309850112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:12.287763 140220309850112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:12.287873 140220309850112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:12.288002 140220309850112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:12.288115 140220309850112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:12.321125 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:12.376286 140220309850112 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:42:12.376663 140220309850112 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 177.84
I0828 10:42:18.000091 140220309850112 replay_runner.py:36] Average training steps per second: 177.84
I0828 10:42:19.179060 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.81
Steps executed: 241 Episode length: 130 Return: -628.3507783498663
INFO:tensorflow:Starting iteration 1
I0828 10:42:23.253642 140220309850112 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 239.85

Steps executed: 337 Episode length: 147 Return: -263.88573058417006
I0828 10:42:27.761633 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.07
INFO:tensorflow:Starting iteration 2
I0828 10:42:32.036719 140220309850112 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 234.73
I0828 10:42:36.297309 140220309850112 replay_runner.py:36] Average training steps per second: 234.73

Steps executed: 1000 Episode length: 1000 Return: -177.10111203311325
INFO:tensorflow:Starting iteration 3
I0828 10:42:44.104908 140220309850112 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 228.22

Steps executed: 114 Episode length: 114 Return: -508.9482784178779325

Steps executed: 1114 Episode length: 1000 Return: -133.28638765443545
INFO:tensorflow:Starting iteration 4
I0828 10:42:56.929876 140220309850112 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 233.06

Steps executed: 1000 Episode length: 1000 Return: -383.24935265402553
I0828 10:43:04.629750 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -383.25
INFO:tensorflow:Starting iteration 5
I0828 10:43:08.832637 140220309850112 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 235.30

Steps executed: 1000 Episode length: 1000 Return: -266.74527910297233
I0828 10:43:16.828553 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.75
INFO:tensorflow:Starting iteration 6
I0828 10:43:21.044643 140220309850112 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 245.77

Steps executed: 1000 Episode length: 1000 Return: -79.421563806001833
I0828 10:43:27.731594 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.42
INFO:tensorflow:Starting iteration 7
I0828 10:43:31.917788 140220309850112 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 243.20

Steps executed: 1000 Episode length: 1000 Return: -138.88856095206592
I0828 10:43:38.200310 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.89
INFO:tensorflow:Starting iteration 8

Steps executed: 570 Episode length: 570 Return: -209.6423598807514392
INFO:tensorflow:Average training steps per second: 231.44
I0828 10:43:46.680118 140220309850112 replay_runner.py:36] Average training steps per second: 231.44
I0828 10:43:47.890434 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.64
INFO:tensorflow:Starting iteration 9

Steps executed: 116 Episode length: 116 Return: 7.5005395277604384392
INFO:tensorflow:Average training steps per second: 234.08

Steps executed: 1116 Episode length: 1000 Return: -56.869487810752872
I0828 10:43:59.724987 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -24.68
INFO:tensorflow:Starting iteration 10

Steps executed: 217 Episode length: 217 Return: -44.08724099947318872
INFO:tensorflow:Average training steps per second: 230.87
I0828 10:44:08.267622 140220309850112 replay_runner.py:36] Average training steps per second: 230.87
I0828 10:44:08.488426 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -44.09
INFO:tensorflow:Starting iteration 11
I0828 10:44:12.882715 140220309850112 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 226.42

Steps executed: 666 Episode length: 666 Return: -107.4851278378983972
I0828 10:44:18.741607 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.49
INFO:tensorflow:Starting iteration 12

Steps executed: 230 Episode length: 151 Return: -465.1839267084209972
INFO:tensorflow:Average training steps per second: 226.93
I0828 10:44:27.505399 140220309850112 replay_runner.py:36] Average training steps per second: 226.93
I0828 10:44:27.708672 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -319.12
INFO:tensorflow:Starting iteration 13

Steps executed: 210 Episode length: 138 Return: -247.4479455883534672
INFO:tensorflow:Average training steps per second: 228.00
I0828 10:44:36.447921 140220309850112 replay_runner.py:36] Average training steps per second: 228.00
I0828 10:44:36.609473 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -150.28
INFO:tensorflow:Starting iteration 14

Steps executed: 447 Episode length: 289 Return: -144.0278929592351772
INFO:tensorflow:Average training steps per second: 229.53
I0828 10:44:45.247516 140220309850112 replay_runner.py:36] Average training steps per second: 229.53
I0828 10:44:45.792297 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.70
INFO:tensorflow:Starting iteration 15
I0828 10:44:49.980014 140220309850112 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 232.46

Steps executed: 273 Episode length: 149 Return: -217.3452718739672572
I0828 10:44:54.512963 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.21
INFO:tensorflow:Starting iteration 16

Steps executed: 200 Episode length: 62 Return: -30.801625024767134272
INFO:tensorflow:Average training steps per second: 234.39
I0828 10:45:02.993728 140220309850112 replay_runner.py:36] Average training steps per second: 234.39
I0828 10:45:03.153012 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.43
INFO:tensorflow:Starting iteration 17

Steps executed: 291 Episode length: 154 Return: -706.1750105467621272
INFO:tensorflow:Average training steps per second: 243.76
I0828 10:45:11.415068 140220309850112 replay_runner.py:36] Average training steps per second: 243.76
I0828 10:45:11.679553 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -667.53
INFO:tensorflow:Starting iteration 18

Steps executed: 270 Episode length: 71 Return: -289.78373006711786272
INFO:tensorflow:Average training steps per second: 249.48
I0828 10:45:19.865861 140220309850112 replay_runner.py:36] Average training steps per second: 249.48
I0828 10:45:20.103712 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.22
INFO:tensorflow:Starting iteration 19

Steps executed: 256 Episode length: 80 Return: -97.328611006318646272
INFO:tensorflow:Average training steps per second: 264.45
I0828 10:45:27.997131 140220309850112 replay_runner.py:36] Average training steps per second: 264.45
I0828 10:45:28.181697 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.29
INFO:tensorflow:Starting iteration 20

Steps executed: 53 Episode length: 53 Return: -128.991071967536336272
INFO:tensorflow:Average training steps per second: 271.38

Steps executed: 340 Episode length: 157 Return: -82.54769914242883772
I0828 10:45:36.157862 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.02
INFO:tensorflow:Starting iteration 21

Steps executed: 151 Episode length: 151 Return: -61.99347953815434772
INFO:tensorflow:Average training steps per second: 275.10
I0828 10:45:43.827857 140220309850112 replay_runner.py:36] Average training steps per second: 275.10

Steps executed: 269 Episode length: 118 Return: -10.53424297190102372
INFO:tensorflow:Starting iteration 22

Steps executed: 217 Episode length: 76 Return: -231.29108306340362372
INFO:tensorflow:Average training steps per second: 280.77
I0828 10:45:51.599629 140220309850112 replay_runner.py:36] Average training steps per second: 280.77
I0828 10:45:51.763369 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.61
INFO:tensorflow:Starting iteration 23

Steps executed: 255 Episode length: 161 Return: -176.1705575238022272
INFO:tensorflow:Average training steps per second: 289.31
I0828 10:45:59.203905 140220309850112 replay_runner.py:36] Average training steps per second: 289.31
I0828 10:45:59.404424 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.35
INFO:tensorflow:Starting iteration 24

Steps executed: 237 Episode length: 106 Return: -121.6402349499459872
INFO:tensorflow:Average training steps per second: 310.84
I0828 10:46:06.600795 140220309850112 replay_runner.py:36] Average training steps per second: 310.84
I0828 10:46:06.750619 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.31
INFO:tensorflow:Starting iteration 25

Steps executed: 242 Episode length: 123 Return: -389.6033734395437672
INFO:tensorflow:Average training steps per second: 311.94
I0828 10:46:13.807545 140220309850112 replay_runner.py:36] Average training steps per second: 311.94
I0828 10:46:13.975831 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -351.60
INFO:tensorflow:Starting iteration 26

Steps executed: 341 Episode length: 185 Return: -541.1909766245592672
INFO:tensorflow:Average training steps per second: 341.02
I0828 10:46:20.613399 140220309850112 replay_runner.py:36] Average training steps per second: 341.02
I0828 10:46:20.807562 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.87
INFO:tensorflow:Starting iteration 27

Steps executed: 288 Episode length: 152 Return: -296.6190840100641672
INFO:tensorflow:Average training steps per second: 353.04
I0828 10:46:27.131665 140220309850112 replay_runner.py:36] Average training steps per second: 353.04
I0828 10:46:27.304873 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.83
INFO:tensorflow:Starting iteration 28

Steps executed: 217 Episode length: 78 Return: -147.89177121883924672
INFO:tensorflow:Average training steps per second: 350.42
I0828 10:46:33.609242 140220309850112 replay_runner.py:36] Average training steps per second: 350.42
I0828 10:46:33.721006 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.06
INFO:tensorflow:Starting iteration 29

Steps executed: 210 Episode length: 210 Return: -132.1283080798429672
INFO:tensorflow:Average training steps per second: 353.92
I0828 10:46:39.925419 140220309850112 replay_runner.py:36] Average training steps per second: 353.92

Done fixed training!Episode length: 210 Return: -132.1283080798429672