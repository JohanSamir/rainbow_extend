I0905 16:33:34.601843 140235000764416 run_experiment.py:549] Creating TrainRunner ...
I0905 16:33:34.650829 140235000764416 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:33:34.651269 140235000764416 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:33:34.651607 140235000764416 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:33:34.651803 140235000764416 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:33:34.651952 140235000764416 dqn_agent.py:275] 	 update_period: 4
I0905 16:33:34.652122 140235000764416 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:33:34.652339 140235000764416 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:33:34.652504 140235000764416 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:33:34.652640 140235000764416 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:33:34.652774 140235000764416 dqn_agent.py:280] 	 optimizer: adam
I0905 16:33:34.652913 140235000764416 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:33:34.653036 140235000764416 dqn_agent.py:283] 	 seed: 1630859614650753
I0905 16:33:34.657690 140235000764416 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:33:34.658019 140235000764416 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:33:34.658243 140235000764416 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:33:34.672517 140235000764416 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:33:34.673192 140235000764416 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:33:34.673420 140235000764416 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:33:34.673574 140235000764416 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:33:34.673706 140235000764416 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:33:34.673839 140235000764416 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0905 16:33:36.988556 140235000764416 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:38.113369 140235000764416 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:38.144768 140235000764416 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:33:38.178636 140235000764416 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:33:38.180243 140235000764416 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:33:38.180522 140235000764416 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:33:38.180690 140235000764416 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:33:38.181636 140235000764416 dqn_agent.py:275] 	 update_period: 4
I0905 16:33:38.182531 140235000764416 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:33:38.182883 140235000764416 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:33:38.183112 140235000764416 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:33:38.183552 140235000764416 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:33:38.183959 140235000764416 dqn_agent.py:280] 	 optimizer: adam
I0905 16:33:38.184762 140235000764416 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:33:38.185044 140235000764416 dqn_agent.py:283] 	 seed: 1630859618178563
I0905 16:33:38.190117 140235000764416 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:33:38.190413 140235000764416 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:33:38.190848 140235000764416 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:33:38.191385 140235000764416 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:33:38.191706 140235000764416 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:33:38.192189 140235000764416 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:33:38.192668 140235000764416 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:33:38.192970 140235000764416 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:33:38.193728 140235000764416 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:33:38.270429 140235000764416 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:38.323898 140235000764416 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:33:38.324820 140235000764416 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 106.36
I0905 16:33:47.728414 140235000764416 replay_runner.py:36] Average training steps per second: 106.36
Steps executed: 310 Episode length: 221 Return: -89.7679830066446
I0905 16:33:49.454908 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.73
INFO:tensorflow:Starting iteration 1
I0905 16:33:54.116131 140235000764416 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 159.01

Steps executed: 223 Episode length: 104 Return: -283.4885776360313
I0905 16:34:00.622149 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -351.11
INFO:tensorflow:Starting iteration 2

Steps executed: 262 Episode length: 162 Return: -421.51413089586163
INFO:tensorflow:Average training steps per second: 159.45
I0905 16:34:11.856105 140235000764416 replay_runner.py:36] Average training steps per second: 159.45
I0905 16:34:12.137205 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -431.17
INFO:tensorflow:Starting iteration 3

Steps executed: 204 Episode length: 204 Return: -49.174488880429043
INFO:tensorflow:Average training steps per second: 157.49
I0905 16:34:22.823930 140235000764416 replay_runner.py:36] Average training steps per second: 157.49
I0905 16:34:23.055084 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -49.17
INFO:tensorflow:Starting iteration 4

Steps executed: 400 Episode length: 274 Return: -457.17695051583826
INFO:tensorflow:Average training steps per second: 185.72
I0905 16:34:32.814685 140235000764416 replay_runner.py:36] Average training steps per second: 185.72
I0905 16:34:33.395132 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.56
INFO:tensorflow:Starting iteration 5
I0905 16:34:38.497251 140235000764416 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 158.43

Steps executed: 1000 Episode length: 1000 Return: -114.87633123608194
I0905 16:34:48.190864 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.88
INFO:tensorflow:Starting iteration 6
I0905 16:34:53.428655 140235000764416 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 171.79

Steps executed: 1000 Episode length: 1000 Return: -170.89328953376997
I0905 16:35:01.511255 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.89
INFO:tensorflow:Starting iteration 7
I0905 16:35:06.623631 140235000764416 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 169.39

Steps executed: 1000 Episode length: 1000 Return: -158.48288821127815
I0905 16:35:17.602926 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.48
INFO:tensorflow:Starting iteration 8
I0905 16:35:22.290058 140235000764416 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 155.11

Steps executed: 1000 Episode length: 1000 Return: -319.36698393018605
I0905 16:35:31.669524 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -319.37
INFO:tensorflow:Starting iteration 9
I0905 16:35:36.602042 140235000764416 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 168.28

Steps executed: 1000 Episode length: 1000 Return: -222.39215688225994
I0905 16:35:45.928905 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -222.39
INFO:tensorflow:Starting iteration 10
I0905 16:35:50.997694 140235000764416 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 189.18

Steps executed: 1000 Episode length: 1000 Return: -128.81579662018494
I0905 16:35:59.879325 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.82
INFO:tensorflow:Starting iteration 11

Steps executed: 167 Episode length: 95 Return: -19.222147399156512494
INFO:tensorflow:Average training steps per second: 189.54

Steps executed: 1167 Episode length: 1000 Return: -164.01664827440634
I0905 16:36:13.376186 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.98
INFO:tensorflow:Starting iteration 12
I0905 16:36:17.938054 140235000764416 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 223.41

Steps executed: 1000 Episode length: 1000 Return: -186.37519518867438
I0905 16:36:24.352528 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.38
INFO:tensorflow:Starting iteration 13
I0905 16:36:28.380305 140235000764416 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 286.54
I0905 16:36:31.871089 140235000764416 replay_runner.py:36] Average training steps per second: 286.54

Steps executed: 1000 Episode length: 1000 Return: -203.54735175352317
INFO:tensorflow:Starting iteration 14

Steps executed: 407 Episode length: 232 Return: -38.61424302464502317
INFO:tensorflow:Average training steps per second: 408.04
I0905 16:36:40.169495 140235000764416 replay_runner.py:36] Average training steps per second: 408.04
I0905 16:36:40.406851 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.84
INFO:tensorflow:Starting iteration 15
I0905 16:36:43.510094 140235000764416 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 394.58

Steps executed: 1000 Episode length: 1000 Return: -133.63941116372797
I0905 16:36:47.638501 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.64
INFO:tensorflow:Starting iteration 16

Steps executed: 501 Episode length: 319 Return: 32.678941868641743597
INFO:tensorflow:Average training steps per second: 385.18
I0905 16:36:53.265692 140235000764416 replay_runner.py:36] Average training steps per second: 385.18
I0905 16:36:53.629963 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.91
INFO:tensorflow:Starting iteration 17

Steps executed: 284 Episode length: 165 Return: -123.6871129283104797
INFO:tensorflow:Average training steps per second: 393.42
I0905 16:36:59.283212 140235000764416 replay_runner.py:36] Average training steps per second: 393.42
I0905 16:36:59.413192 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.85
INFO:tensorflow:Starting iteration 18
I0905 16:37:02.575886 140235000764416 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 387.75

Steps executed: 583 Episode length: 583 Return: -326.5148857590614797
I0905 16:37:05.822021 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.51
INFO:tensorflow:Starting iteration 19

Steps executed: 120 Episode length: 120 Return: -475.6391478256273397
INFO:tensorflow:Average training steps per second: 384.28
I0905 16:37:11.468824 140235000764416 replay_runner.py:36] Average training steps per second: 384.28

Steps executed: 1120 Episode length: 1000 Return: -139.47353711000127
INFO:tensorflow:Starting iteration 20
I0905 16:37:16.203015 140235000764416 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 383.74
I0905 16:37:18.809244 140235000764416 replay_runner.py:36] Average training steps per second: 383.74

Steps executed: 345 Episode length: 154 Return: -80.29572044073498127
INFO:tensorflow:Starting iteration 21
I0905 16:37:22.051569 140235000764416 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 392.92

Steps executed: 1000 Episode length: 1000 Return: 126.202403321538587
I0905 16:37:25.872978 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: 126.20
INFO:tensorflow:Starting iteration 22

Steps executed: 268 Episode length: 84 Return: -450.51021534713999787
INFO:tensorflow:Average training steps per second: 399.82
I0905 16:37:31.501382 140235000764416 replay_runner.py:36] Average training steps per second: 399.82
I0905 16:37:31.613875 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.48
INFO:tensorflow:Starting iteration 23
I0905 16:37:34.714895 140235000764416 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 394.13

Steps executed: 387 Episode length: 228 Return: 239.46799257083183787
I0905 16:37:37.461309 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -204.57
INFO:tensorflow:Starting iteration 24

Steps executed: 306 Episode length: 115 Return: -44.90488577346809787
INFO:tensorflow:Average training steps per second: 390.99
I0905 16:37:43.165292 140235000764416 replay_runner.py:36] Average training steps per second: 390.99
I0905 16:37:43.319028 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.11
INFO:tensorflow:Starting iteration 25
I0905 16:37:46.453873 140235000764416 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 397.20

Steps executed: 262 Episode length: 131 Return: -295.5892883876057787
I0905 16:37:49.088504 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.73
INFO:tensorflow:Starting iteration 26

Steps executed: 155 Episode length: 155 Return: -309.8864809935259787
INFO:tensorflow:Average training steps per second: 402.87
I0905 16:37:54.751968 140235000764416 replay_runner.py:36] Average training steps per second: 402.87

Steps executed: 342 Episode length: 187 Return: -280.9465918535759787
INFO:tensorflow:Starting iteration 27

Steps executed: 238 Episode length: 96 Return: 55.9327487885266564387
INFO:tensorflow:Average training steps per second: 401.13
I0905 16:38:00.560646 140235000764416 replay_runner.py:36] Average training steps per second: 401.13
I0905 16:38:00.661490 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.37
INFO:tensorflow:Starting iteration 28

Steps executed: 204 Episode length: 144 Return: -121.1783906493056387
INFO:tensorflow:Average training steps per second: 380.65
I0905 16:38:06.402338 140235000764416 replay_runner.py:36] Average training steps per second: 380.65
I0905 16:38:06.469321 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.00
INFO:tensorflow:Starting iteration 29

Steps executed: 354 Episode length: 162 Return: -387.6748178842269787
INFO:tensorflow:Average training steps per second: 394.04
I0905 16:38:12.164276 140235000764416 replay_runner.py:36] Average training steps per second: 394.04

Done fixed training!Episode length: 162 Return: -387.6748178842269787