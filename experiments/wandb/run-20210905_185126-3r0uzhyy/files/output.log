Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0905 18:51:33.225461 139980086712320 run_experiment.py:549] Creating TrainRunner ...
I0905 18:51:33.237715 139980086712320 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 18:51:33.238004 139980086712320 dqn_agent.py:272] 	 gamma: 0.990000
I0905 18:51:33.238140 139980086712320 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 18:51:33.238263 139980086712320 dqn_agent.py:274] 	 min_replay_history: 500
I0905 18:51:33.238336 139980086712320 dqn_agent.py:275] 	 update_period: 4
I0905 18:51:33.238405 139980086712320 dqn_agent.py:276] 	 target_update_period: 300
I0905 18:51:33.238468 139980086712320 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 18:51:33.238537 139980086712320 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 18:51:33.238601 139980086712320 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 18:51:33.238667 139980086712320 dqn_agent.py:280] 	 optimizer: adam
I0905 18:51:33.238740 139980086712320 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 18:51:33.238826 139980086712320 dqn_agent.py:283] 	 seed: 1630867893237639
I0905 18:51:33.241421 139980086712320 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 18:51:33.241649 139980086712320 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 18:51:33.241817 139980086712320 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 18:51:33.241923 139980086712320 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 18:51:33.242010 139980086712320 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 18:51:33.242087 139980086712320 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 18:51:33.242211 139980086712320 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 18:51:33.242380 139980086712320 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 18:51:33.242520 139980086712320 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 18:51:33.743026 139980086712320 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:51:34.100288 139980086712320 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:51:34.112386 139980086712320 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 18:51:34.123123 139980086712320 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 18:51:34.123317 139980086712320 dqn_agent.py:272] 	 gamma: 0.990000
I0905 18:51:34.123385 139980086712320 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 18:51:34.123447 139980086712320 dqn_agent.py:274] 	 min_replay_history: 500
I0905 18:51:34.123508 139980086712320 dqn_agent.py:275] 	 update_period: 4
I0905 18:51:34.123562 139980086712320 dqn_agent.py:276] 	 target_update_period: 300
I0905 18:51:34.123751 139980086712320 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 18:51:34.123826 139980086712320 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 18:51:34.123898 139980086712320 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 18:51:34.123971 139980086712320 dqn_agent.py:280] 	 optimizer: adam
I0905 18:51:34.124040 139980086712320 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 18:51:34.124108 139980086712320 dqn_agent.py:283] 	 seed: 1630867894123035
I0905 18:51:34.125756 139980086712320 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 18:51:34.125898 139980086712320 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 18:51:34.125982 139980086712320 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 18:51:34.126052 139980086712320 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 18:51:34.126111 139980086712320 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 18:51:34.126225 139980086712320 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 18:51:34.126304 139980086712320 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 18:51:34.126383 139980086712320 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 18:51:34.126470 139980086712320 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 18:51:34.160682 139980086712320 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:51:34.180152 139980086712320 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 18:51:34.180366 139980086712320 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 156.57
I0905 18:51:40.567291 139980086712320 replay_runner.py:36] Average training steps per second: 156.57
Steps executed: 265 Episode length: 158 Return: -393.90139284221355
I0905 18:51:41.828108 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -380.85
INFO:tensorflow:Starting iteration 1
I0905 18:51:46.098104 139980086712320 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 214.09
I0905 18:51:50.769355 139980086712320 replay_runner.py:36] Average training steps per second: 214.09

Steps executed: 301 Episode length: 143 Return: -335.21255459270367
INFO:tensorflow:Starting iteration 2

Steps executed: 360 Episode length: 180 Return: -244.80359388362797
INFO:tensorflow:Average training steps per second: 226.68
I0905 18:51:59.808179 139980086712320 replay_runner.py:36] Average training steps per second: 226.68
I0905 18:52:00.200713 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.98
INFO:tensorflow:Starting iteration 3
I0905 18:52:04.430388 139980086712320 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 219.27

Steps executed: 1000 Episode length: 1000 Return: -120.09806549061511
I0905 18:52:12.858043 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.10
INFO:tensorflow:Starting iteration 4
I0905 18:52:17.077795 139980086712320 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 253.94

Steps executed: 1000 Episode length: 1000 Return: -137.96859434174631
I0905 18:52:24.260447 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.97
INFO:tensorflow:Starting iteration 5
I0905 18:52:28.339767 139980086712320 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 245.00
I0905 18:52:32.424364 139980086712320 replay_runner.py:36] Average training steps per second: 245.00

Steps executed: 1000 Episode length: 1000 Return: -540.78085347473771
INFO:tensorflow:Starting iteration 6
I0905 18:52:39.562000 139980086712320 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 203.77

Steps executed: 1000 Episode length: 1000 Return: -89.439390155413971
I0905 18:52:47.039207 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.44
INFO:tensorflow:Starting iteration 7
I0905 18:52:51.612726 139980086712320 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 201.79

Steps executed: 362 Episode length: 362 Return: -269.7876028278324971
I0905 18:52:57.169941 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.79
INFO:tensorflow:Starting iteration 8
I0905 18:53:01.716398 139980086712320 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 201.20

Steps executed: 1000 Episode length: 1000 Return: -170.75612859190147
I0905 18:53:10.027902 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.76
INFO:tensorflow:Starting iteration 9
I0905 18:53:14.673830 139980086712320 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 201.00

Steps executed: 1000 Episode length: 1000 Return: -143.73023545740992
I0905 18:53:23.419440 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.73
INFO:tensorflow:Starting iteration 10

Steps executed: 83 Episode length: 83 Return: -658.229855114936440992
INFO:tensorflow:Average training steps per second: 200.30

Steps executed: 252 Episode length: 169 Return: -538.7946527557550992
I0905 18:53:33.239303 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -598.51
INFO:tensorflow:Starting iteration 11
I0905 18:53:37.842912 139980086712320 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 195.75

Steps executed: 1000 Episode length: 1000 Return: -101.80964114862704
I0905 18:53:45.312928 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.81
INFO:tensorflow:Starting iteration 12
I0905 18:53:49.956163 139980086712320 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 205.32

Steps executed: 1000 Episode length: 1000 Return: -176.09718167170053
I0905 18:53:58.344755 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.10
INFO:tensorflow:Starting iteration 13

Steps executed: 208 Episode length: 208 Return: -31.08024687901263453
INFO:tensorflow:Average training steps per second: 196.35
I0905 18:54:07.796293 139980086712320 replay_runner.py:36] Average training steps per second: 196.35
I0905 18:54:08.035893 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -31.08
INFO:tensorflow:Starting iteration 14

Steps executed: 166 Episode length: 166 Return: -100.1003113159515653
INFO:tensorflow:Average training steps per second: 204.14

Steps executed: 364 Episode length: 198 Return: -119.9215798784384253
I0905 18:54:17.626180 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.01
INFO:tensorflow:Starting iteration 15

Steps executed: 218 Episode length: 93 Return: -112.10393918691187253
INFO:tensorflow:Average training steps per second: 201.37
I0905 18:54:27.205007 139980086712320 replay_runner.py:36] Average training steps per second: 201.37
I0905 18:54:27.430705 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.86
INFO:tensorflow:Starting iteration 16

Steps executed: 64 Episode length: 64 Return: -175.222565021366827253
INFO:tensorflow:Average training steps per second: 198.10

Steps executed: 1064 Episode length: 1000 Return: -28.530110156032016
I0905 18:54:39.967761 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.88
INFO:tensorflow:Starting iteration 17

Steps executed: 232 Episode length: 62 Return: -28.613606491405235016
INFO:tensorflow:Average training steps per second: 199.88
I0905 18:54:49.444632 139980086712320 replay_runner.py:36] Average training steps per second: 199.88
I0905 18:54:49.685364 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -10.59
INFO:tensorflow:Starting iteration 18

Steps executed: 214 Episode length: 49 Return: -123.68856709782943316
INFO:tensorflow:Average training steps per second: 197.29
I0905 18:54:59.094736 139980086712320 replay_runner.py:36] Average training steps per second: 197.29
I0905 18:54:59.304740 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.52
INFO:tensorflow:Starting iteration 19

Steps executed: 232 Episode length: 164 Return: 22.041980706267953316
INFO:tensorflow:Average training steps per second: 198.12
I0905 18:55:08.651558 139980086712320 replay_runner.py:36] Average training steps per second: 198.12
I0905 18:55:08.897273 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -1.17
INFO:tensorflow:Starting iteration 20

Steps executed: 251 Episode length: 77 Return: -19.292483377982308316
INFO:tensorflow:Average training steps per second: 202.23
I0905 18:55:18.354640 139980086712320 replay_runner.py:36] Average training steps per second: 202.23
I0905 18:55:18.607450 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.85
INFO:tensorflow:Starting iteration 21

Steps executed: 261 Episode length: 261 Return: -121.9897747087821416
INFO:tensorflow:Average training steps per second: 197.45
I0905 18:55:28.166002 139980086712320 replay_runner.py:36] Average training steps per second: 197.45
I0905 18:55:28.546350 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.99
INFO:tensorflow:Starting iteration 22

Steps executed: 266 Episode length: 68 Return: -147.07136343753234616
INFO:tensorflow:Average training steps per second: 209.55
I0905 18:55:37.757939 139980086712320 replay_runner.py:36] Average training steps per second: 209.55
I0905 18:55:37.993370 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.56
INFO:tensorflow:Starting iteration 23

Steps executed: 223 Episode length: 51 Return: -117.04665818287708616
INFO:tensorflow:Average training steps per second: 226.40
I0905 18:55:46.814304 139980086712320 replay_runner.py:36] Average training steps per second: 226.40
I0905 18:55:47.028525 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.12
INFO:tensorflow:Starting iteration 24

Steps executed: 377 Episode length: 218 Return: 23.281145265222776616
INFO:tensorflow:Average training steps per second: 222.56
I0905 18:55:56.089775 139980086712320 replay_runner.py:36] Average training steps per second: 222.56
I0905 18:55:56.487366 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -19.10
INFO:tensorflow:Starting iteration 25

Steps executed: 379 Episode length: 234 Return: -79.36892683298522616
INFO:tensorflow:Average training steps per second: 201.71
I0905 18:56:06.085067 139980086712320 replay_runner.py:36] Average training steps per second: 201.71
I0905 18:56:06.600487 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -58.57
INFO:tensorflow:Starting iteration 26

Steps executed: 328 Episode length: 182 Return: -182.7253126534572616
INFO:tensorflow:Average training steps per second: 192.83
I0905 18:56:16.209827 139980086712320 replay_runner.py:36] Average training steps per second: 192.83
I0905 18:56:16.591981 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.16
INFO:tensorflow:Starting iteration 27

Steps executed: 53 Episode length: 53 Return: -98.0274909947773572616
INFO:tensorflow:Average training steps per second: 183.45

Steps executed: 1053 Episode length: 1000 Return: -65.326758285407616
I0905 18:56:30.443567 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.68
INFO:tensorflow:Starting iteration 28
I0905 18:56:34.253453 139980086712320 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 185.75

Steps executed: 258 Episode length: 125 Return: -54.06188227037538616
I0905 18:56:39.935167 139980086712320 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.97
INFO:tensorflow:Starting iteration 29

Steps executed: 278 Episode length: 113 Return: -74.25314368178121616
INFO:tensorflow:Average training steps per second: 193.95
I0905 18:56:49.942444 139980086712320 replay_runner.py:36] Average training steps per second: 193.95

Done fixed training!Episode length: 113 Return: -74.25314368178121616