I0902 23:30:06.284104 140310902786048 run_experiment.py:549] Creating TrainRunner ...
I0902 23:30:06.296204 140310902786048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:30:06.296537 140310902786048 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:30:06.296747 140310902786048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:30:06.296887 140310902786048 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:30:06.296980 140310902786048 dqn_agent.py:275] 	 update_period: 4
I0902 23:30:06.297070 140310902786048 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:30:06.297203 140310902786048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:30:06.297317 140310902786048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:30:06.297403 140310902786048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:30:06.297509 140310902786048 dqn_agent.py:280] 	 optimizer: adam
I0902 23:30:06.297584 140310902786048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:30:06.297653 140310902786048 dqn_agent.py:283] 	 seed: 1630625406296142
I0902 23:30:06.301429 140310902786048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:30:06.301704 140310902786048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:30:06.302025 140310902786048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:30:06.302210 140310902786048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:30:06.302328 140310902786048 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:30:06.302412 140310902786048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:30:06.302498 140310902786048 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:30:06.302732 140310902786048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:30:06.302973 140310902786048 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0902 23:30:08.178064 140310902786048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:08.683403 140310902786048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:08.702452 140310902786048 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:30:08.711897 140310902786048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:30:08.712193 140310902786048 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:30:08.712385 140310902786048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:30:08.712499 140310902786048 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:30:08.712634 140310902786048 dqn_agent.py:275] 	 update_period: 4
I0902 23:30:08.712748 140310902786048 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:30:08.712926 140310902786048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:30:08.713044 140310902786048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:30:08.713128 140310902786048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:30:08.713213 140310902786048 dqn_agent.py:280] 	 optimizer: adam
I0902 23:30:08.713277 140310902786048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:30:08.713382 140310902786048 dqn_agent.py:283] 	 seed: 1630625408711834
I0902 23:30:08.715554 140310902786048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:30:08.715792 140310902786048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:30:08.715914 140310902786048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:30:08.716021 140310902786048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:30:08.716123 140310902786048 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:30:08.716236 140310902786048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:30:08.716414 140310902786048 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:30:08.716530 140310902786048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:30:08.716619 140310902786048 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:30:08.745338 140310902786048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:08.768131 140310902786048 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:30:08.768544 140310902786048 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.82
I0902 23:30:14.910779 140310902786048 replay_runner.py:36] Average training steps per second: 162.82
Steps executed: 240 Episode length: 240 Return: -120.41524190298044
I0902 23:30:16.239056 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.42
INFO:tensorflow:Starting iteration 1

Steps executed: 255 Episode length: 107 Return: -268.58949482413385
INFO:tensorflow:Average training steps per second: 226.16
I0902 23:30:25.063573 140310902786048 replay_runner.py:36] Average training steps per second: 226.16
I0902 23:30:25.270084 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.29
INFO:tensorflow:Starting iteration 2

Steps executed: 481 Episode length: 331 Return: -257.77213880576036
INFO:tensorflow:Average training steps per second: 227.20
I0902 23:30:34.093611 140310902786048 replay_runner.py:36] Average training steps per second: 227.20
I0902 23:30:34.703354 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.33
INFO:tensorflow:Starting iteration 3

Steps executed: 254 Episode length: 111 Return: -204.86475968238694
INFO:tensorflow:Average training steps per second: 221.19
I0902 23:30:43.579842 140310902786048 replay_runner.py:36] Average training steps per second: 221.19
I0902 23:30:43.796293 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -194.46
INFO:tensorflow:Starting iteration 4
I0902 23:30:48.051405 140310902786048 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 228.44

Steps executed: 1000 Episode length: 1000 Return: -153.1961992213415
I0902 23:30:55.175386 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.20
INFO:tensorflow:Starting iteration 5
I0902 23:30:59.531791 140310902786048 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 233.93

Steps executed: 1000 Episode length: 1000 Return: -91.00163922841871
I0902 23:31:08.002002 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.00
INFO:tensorflow:Starting iteration 6
I0902 23:31:12.304993 140310902786048 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 230.32

Steps executed: 1000 Episode length: 1000 Return: -140.76210629925293
I0902 23:31:19.329065 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.76
INFO:tensorflow:Starting iteration 7
I0902 23:31:23.520239 140310902786048 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 228.36

Steps executed: 1000 Episode length: 1000 Return: -138.57234882042394
I0902 23:31:30.264423 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.57
INFO:tensorflow:Starting iteration 8
I0902 23:31:34.456290 140310902786048 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 227.67

Steps executed: 960 Episode length: 960 Return: -329.5228801778314494
I0902 23:31:41.395028 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.52
INFO:tensorflow:Starting iteration 9
I0902 23:31:45.820960 140310902786048 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 228.65

Steps executed: 538 Episode length: 538 Return: -544.7313504921665494
I0902 23:31:51.278413 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -544.73
INFO:tensorflow:Starting iteration 10

Steps executed: 322 Episode length: 322 Return: -184.4498382290253794
INFO:tensorflow:Average training steps per second: 230.36
I0902 23:31:59.923431 140310902786048 replay_runner.py:36] Average training steps per second: 230.36
I0902 23:32:00.352969 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.45
INFO:tensorflow:Starting iteration 11

Steps executed: 192 Episode length: 192 Return: -25.44411686410946794
INFO:tensorflow:Average training steps per second: 219.52

Steps executed: 1131 Episode length: 939 Return: -337.405814861554594
I0902 23:32:12.353940 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -181.42
INFO:tensorflow:Starting iteration 12
I0902 23:32:16.735212 140310902786048 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 223.70

Steps executed: 1000 Episode length: 1000 Return: -86.646928592806434
I0902 23:32:23.895275 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.65
INFO:tensorflow:Starting iteration 13
I0902 23:32:28.274652 140310902786048 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 224.57

Steps executed: 1000 Episode length: 1000 Return: -131.44579934916018
I0902 23:32:36.759377 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.45
INFO:tensorflow:Starting iteration 14
I0902 23:32:40.943084 140310902786048 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 221.42

Steps executed: 1000 Episode length: 1000 Return: -152.83015791684022
I0902 23:32:47.736586 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.83
INFO:tensorflow:Starting iteration 15
I0902 23:32:52.057337 140310902786048 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 224.85

Steps executed: 1000 Episode length: 1000 Return: -161.44836604550822
I0902 23:32:59.657176 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.45
INFO:tensorflow:Starting iteration 16
I0902 23:33:04.017249 140310902786048 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 224.20

Steps executed: 1000 Episode length: 1000 Return: -23.126641935706086
I0902 23:33:11.873078 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -23.13
INFO:tensorflow:Starting iteration 17
I0902 23:33:16.234467 140310902786048 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 223.62

Steps executed: 1000 Episode length: 1000 Return: -109.36499608077906
I0902 23:33:24.060548 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.36
INFO:tensorflow:Starting iteration 18
I0902 23:33:28.458173 140310902786048 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 222.28

Steps executed: 822 Episode length: 822 Return: -39.36045191070217906
I0902 23:33:35.220016 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -39.36
INFO:tensorflow:Starting iteration 19

Steps executed: 225 Episode length: 152 Return: -59.56538007647181906
INFO:tensorflow:Average training steps per second: 228.55
I0902 23:33:43.774053 140310902786048 replay_runner.py:36] Average training steps per second: 228.55
I0902 23:33:43.959975 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -34.04
INFO:tensorflow:Starting iteration 20
I0902 23:33:48.185684 140310902786048 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 228.57

Steps executed: 224 Episode length: 224 Return: -124.6711828531985606
I0902 23:33:52.792550 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.67
INFO:tensorflow:Starting iteration 21

Steps executed: 211 Episode length: 90 Return: -64.516095575015859606
INFO:tensorflow:Average training steps per second: 225.72
I0902 23:34:01.453854 140310902786048 replay_runner.py:36] Average training steps per second: 225.72
I0902 23:34:01.635230 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.34
INFO:tensorflow:Starting iteration 22

Steps executed: 118 Episode length: 118 Return: -308.0511659576656606
INFO:tensorflow:Average training steps per second: 221.61

Steps executed: 250 Episode length: 132 Return: -114.3372444829163606
I0902 23:34:10.686563 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.19
INFO:tensorflow:Starting iteration 23

Steps executed: 446 Episode length: 446 Return: -137.4044557373162506
INFO:tensorflow:Average training steps per second: 230.83
I0902 23:34:19.395992 140310902786048 replay_runner.py:36] Average training steps per second: 230.83
I0902 23:34:20.277407 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.40
INFO:tensorflow:Starting iteration 24

Steps executed: 295 Episode length: 217 Return: -474.0597672953288706
INFO:tensorflow:Average training steps per second: 234.30
I0902 23:34:28.750346 140310902786048 replay_runner.py:36] Average training steps per second: 234.30
I0902 23:34:29.020417 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.42
INFO:tensorflow:Starting iteration 25

Steps executed: 326 Episode length: 165 Return: -114.6162452221025606
INFO:tensorflow:Average training steps per second: 237.64
I0902 23:34:37.759776 140310902786048 replay_runner.py:36] Average training steps per second: 237.64
I0902 23:34:38.038737 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.99
INFO:tensorflow:Starting iteration 26
I0902 23:34:42.380208 140310902786048 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 225.36

Steps executed: 220 Episode length: 220 Return: 233.06430253564025606
I0902 23:34:47.070379 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: 233.06
INFO:tensorflow:Starting iteration 27

Steps executed: 211 Episode length: 54 Return: -94.831044524872178406
INFO:tensorflow:Average training steps per second: 228.07
I0902 23:34:55.826793 140310902786048 replay_runner.py:36] Average training steps per second: 228.07
I0902 23:34:56.000168 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.44
INFO:tensorflow:Starting iteration 28
I0902 23:35:00.464565 140310902786048 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 228.75
I0902 23:35:04.836571 140310902786048 replay_runner.py:36] Average training steps per second: 228.75

Steps executed: 682 Episode length: 682 Return: -491.2240306152085606
INFO:tensorflow:Starting iteration 29

Steps executed: 256 Episode length: 77 Return: -18.883381488601534606
INFO:tensorflow:Average training steps per second: 221.67
I0902 23:35:15.787077 140310902786048 replay_runner.py:36] Average training steps per second: 221.67

Done fixed training!Episode length: 77 Return: -18.883381488601534606