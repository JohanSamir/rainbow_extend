Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0902 00:04:50.735307 140149719906304 run_experiment.py:549] Creating TrainRunner ...
I0902 00:04:50.747767 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:04:50.748240 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:04:50.748439 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:04:50.748618 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:04:50.748853 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0902 00:04:50.749002 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:04:50.749185 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:04:50.749281 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:04:50.749359 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:04:50.749469 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0902 00:04:50.749565 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:04:50.749673 140149719906304 dqn_agent.py:283] 	 seed: 1630541090747696
I0902 00:04:50.752147 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:04:50.752350 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:04:50.752476 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:04:50.752549 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:04:50.752631 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:04:50.752696 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:04:50.753019 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:04:50.753161 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:04:50.753260 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:04:50.794445 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:04:51.217377 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:04:51.257782 140149719906304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:04:51.268289 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:04:51.268490 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:04:51.268568 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:04:51.268634 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:04:51.268689 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0902 00:04:51.268769 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:04:51.268823 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:04:51.268963 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:04:51.269032 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:04:51.269149 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0902 00:04:51.269335 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:04:51.269426 140149719906304 dqn_agent.py:283] 	 seed: 1630541091268213
I0902 00:04:51.272393 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:04:51.272652 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:04:51.272807 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:04:51.272946 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:04:51.273076 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:04:51.273199 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:04:51.273319 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:04:51.273477 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:04:51.273610 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:04:51.307706 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:04:51.331550 140149719906304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:04:51.331915 140149719906304 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 167.45
I0902 00:04:57.304139 140149719906304 replay_runner.py:36] Average training steps per second: 167.45
Steps executed: 270 Episode length: 158 Return: -443.02572250556216
I0902 00:04:58.535663 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.91
INFO:tensorflow:Starting iteration 1

Steps executed: 282 Episode length: 151 Return: -113.46881777422621
INFO:tensorflow:Average training steps per second: 222.20
I0902 00:05:07.248218 140149719906304 replay_runner.py:36] Average training steps per second: 222.20
I0902 00:05:07.521709 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -181.47
INFO:tensorflow:Starting iteration 2
I0902 00:05:11.863255 140149719906304 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 220.18

Steps executed: 283 Episode length: 159 Return: -298.98990881462237
I0902 00:05:16.699818 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -370.21
INFO:tensorflow:Starting iteration 3

Steps executed: 306 Episode length: 189 Return: -505.16126471517174
INFO:tensorflow:Average training steps per second: 221.78
I0902 00:05:25.563414 140149719906304 replay_runner.py:36] Average training steps per second: 221.78
I0902 00:05:25.877866 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -498.68
INFO:tensorflow:Starting iteration 4
I0902 00:05:30.246775 140149719906304 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 229.56

Steps executed: 1000 Episode length: 1000 Return: -40.451373869284595
I0902 00:05:37.373993 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -40.45
INFO:tensorflow:Starting iteration 5
I0902 00:05:41.709694 140149719906304 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 227.31

Steps executed: 815 Episode length: 815 Return: -357.9737988367527495
I0902 00:05:48.957916 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -357.97
INFO:tensorflow:Starting iteration 6
I0902 00:05:53.273857 140149719906304 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 243.05

Steps executed: 1000 Episode length: 1000 Return: -159.39333363182917
I0902 00:05:59.940942 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.39
INFO:tensorflow:Starting iteration 7
I0902 00:06:04.312561 140149719906304 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 228.27

Steps executed: 1000 Episode length: 1000 Return: -140.00738567393162
I0902 00:06:10.947392 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.01
INFO:tensorflow:Starting iteration 8

Steps executed: 282 Episode length: 282 Return: -281.7829521829053162
INFO:tensorflow:Average training steps per second: 224.93
I0902 00:06:19.589389 140149719906304 replay_runner.py:36] Average training steps per second: 224.93
I0902 00:06:19.937579 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.78
INFO:tensorflow:Starting iteration 9
I0902 00:06:24.323879 140149719906304 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 228.01
I0902 00:06:28.710160 140149719906304 replay_runner.py:36] Average training steps per second: 228.01

Steps executed: 1000 Episode length: 1000 Return: -325.77498819450922
INFO:tensorflow:Starting iteration 10

Steps executed: 489 Episode length: 489 Return: -285.1541870212184922
INFO:tensorflow:Average training steps per second: 221.43
I0902 00:06:39.745398 140149719906304 replay_runner.py:36] Average training steps per second: 221.43
I0902 00:06:40.462522 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.15
INFO:tensorflow:Starting iteration 11
I0902 00:06:44.745018 140149719906304 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 224.65

Steps executed: 935 Episode length: 935 Return: -430.7696940687308922
I0902 00:06:51.717381 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -430.77
INFO:tensorflow:Starting iteration 12
I0902 00:06:56.132144 140149719906304 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 219.16

Steps executed: 1000 Episode length: 1000 Return: -183.20125107695446
I0902 00:07:03.936333 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -183.20
INFO:tensorflow:Starting iteration 13
I0902 00:07:08.271322 140149719906304 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 227.04

Steps executed: 441 Episode length: 441 Return: -336.4718070795596546
I0902 00:07:13.408710 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -336.47
INFO:tensorflow:Starting iteration 14
I0902 00:07:17.630343 140149719906304 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 228.41

Steps executed: 913 Episode length: 913 Return: -427.7005364969037446
I0902 00:07:24.064366 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -427.70
INFO:tensorflow:Starting iteration 15
I0902 00:07:28.349847 140149719906304 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 228.80

Steps executed: 376 Episode length: 376 Return: -325.8914962500113446
I0902 00:07:33.383329 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.89
INFO:tensorflow:Starting iteration 16

Steps executed: 488 Episode length: 290 Return: -118.8624419206738646
INFO:tensorflow:Average training steps per second: 236.22
I0902 00:07:42.043128 140149719906304 replay_runner.py:36] Average training steps per second: 236.22
I0902 00:07:42.460283 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.79
INFO:tensorflow:Starting iteration 17
I0902 00:07:46.948227 140149719906304 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 237.53

Steps executed: 472 Episode length: 472 Return: -431.2733313316951546
I0902 00:07:51.878212 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -431.27
INFO:tensorflow:Starting iteration 18

Steps executed: 284 Episode length: 153 Return: -176.6209225681673746
INFO:tensorflow:Average training steps per second: 232.37
I0902 00:08:00.464164 140149719906304 replay_runner.py:36] Average training steps per second: 232.37
I0902 00:08:00.705576 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.49
INFO:tensorflow:Starting iteration 19

Steps executed: 212 Episode length: 68 Return: -170.91843720203864746
INFO:tensorflow:Average training steps per second: 224.65
I0902 00:08:09.547034 140149719906304 replay_runner.py:36] Average training steps per second: 224.65
I0902 00:08:09.691076 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.34
INFO:tensorflow:Starting iteration 20

Steps executed: 207 Episode length: 62 Return: -132.53583448259857746
INFO:tensorflow:Average training steps per second: 225.92
I0902 00:08:18.349170 140149719906304 replay_runner.py:36] Average training steps per second: 225.92
I0902 00:08:18.498197 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.93
INFO:tensorflow:Starting iteration 21

Steps executed: 223 Episode length: 131 Return: -357.3009250344599646
INFO:tensorflow:Average training steps per second: 223.42
I0902 00:08:27.419008 140149719906304 replay_runner.py:36] Average training steps per second: 223.42
I0902 00:08:27.621416 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -510.39
INFO:tensorflow:Starting iteration 22

Steps executed: 239 Episode length: 54 Return: -111.44774855481872646
INFO:tensorflow:Average training steps per second: 225.03
I0902 00:08:36.406642 140149719906304 replay_runner.py:36] Average training steps per second: 225.03
I0902 00:08:36.595926 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.20
INFO:tensorflow:Starting iteration 23

Steps executed: 200 Episode length: 58 Return: -117.98606729642838646
INFO:tensorflow:Average training steps per second: 223.82
I0902 00:08:45.391803 140149719906304 replay_runner.py:36] Average training steps per second: 223.82
I0902 00:08:45.516981 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.73
INFO:tensorflow:Starting iteration 24

Steps executed: 265 Episode length: 89 Return: -350.61434106004253646
INFO:tensorflow:Average training steps per second: 230.17
I0902 00:08:54.146539 140149719906304 replay_runner.py:36] Average training steps per second: 230.17
I0902 00:08:54.381280 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.72
INFO:tensorflow:Starting iteration 25

Steps executed: 182 Episode length: 122 Return: -436.8521010383823646
INFO:tensorflow:Average training steps per second: 230.82
I0902 00:09:02.880519 140149719906304 replay_runner.py:36] Average training steps per second: 230.82

Steps executed: 253 Episode length: 71 Return: -313.37598665802263646
INFO:tensorflow:Starting iteration 26

Steps executed: 255 Episode length: 74 Return: -464.23046900369275646
INFO:tensorflow:Average training steps per second: 223.96
I0902 00:09:11.884048 140149719906304 replay_runner.py:36] Average training steps per second: 223.96
I0902 00:09:12.116922 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -411.04
INFO:tensorflow:Starting iteration 27

Steps executed: 235 Episode length: 68 Return: -137.64318788848666646
INFO:tensorflow:Average training steps per second: 224.22
I0902 00:09:20.904292 140149719906304 replay_runner.py:36] Average training steps per second: 224.22
I0902 00:09:21.078929 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.30
INFO:tensorflow:Starting iteration 28

Steps executed: 238 Episode length: 93 Return: -130.43699939552684646
INFO:tensorflow:Average training steps per second: 223.68
I0902 00:09:30.105523 140149719906304 replay_runner.py:36] Average training steps per second: 223.68
I0902 00:09:30.287641 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.92
INFO:tensorflow:Starting iteration 29
I0902 00:09:34.740059 140149719906304 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 221.22

Steps executed: 206 Episode length: 79 Return: -760.27581949959684646

Done fixed training!Episode length: 79 Return: -760.27581949959684646