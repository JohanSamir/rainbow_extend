I0902 18:13:58.402671 140131099109376 run_experiment.py:549] Creating TrainRunner ...
I0902 18:13:58.409071 140131099109376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:13:58.409180 140131099109376 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:13:58.409239 140131099109376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:13:58.409374 140131099109376 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:13:58.409430 140131099109376 dqn_agent.py:275] 	 update_period: 4
I0902 18:13:58.409484 140131099109376 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:13:58.409543 140131099109376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:13:58.409615 140131099109376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:13:58.409680 140131099109376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:13:58.409745 140131099109376 dqn_agent.py:280] 	 optimizer: adam
I0902 18:13:58.409809 140131099109376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:13:58.409866 140131099109376 dqn_agent.py:283] 	 seed: 1630606438409042
I0902 18:13:58.411425 140131099109376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:13:58.411541 140131099109376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:13:58.411614 140131099109376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:13:58.411676 140131099109376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:13:58.411733 140131099109376 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:13:58.411825 140131099109376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:13:58.411902 140131099109376 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:13:58.411981 140131099109376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:13:58.412055 140131099109376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:13:58.431909 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.003125
I0902 18:13:58.632213 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.003125
I0902 18:13:58.639662 140131099109376 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:13:58.645098 140131099109376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:13:58.645216 140131099109376 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:13:58.645298 140131099109376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:13:58.645355 140131099109376 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:13:58.645407 140131099109376 dqn_agent.py:275] 	 update_period: 4
I0902 18:13:58.645479 140131099109376 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:13:58.645566 140131099109376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:13:58.645626 140131099109376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:13:58.645701 140131099109376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:13:58.645754 140131099109376 dqn_agent.py:280] 	 optimizer: adam
I0902 18:13:58.645799 140131099109376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:13:58.645865 140131099109376 dqn_agent.py:283] 	 seed: 1630606438645072
I0902 18:13:58.647198 140131099109376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:13:58.647302 140131099109376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:13:58.647368 140131099109376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:13:58.647425 140131099109376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:13:58.647479 140131099109376 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:13:58.647530 140131099109376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:13:58.647600 140131099109376 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:13:58.647661 140131099109376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:13:58.647730 140131099109376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:13:58.664418 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.003125
I0902 18:13:58.678027 140131099109376 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:13:58.678126 140131099109376 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
Steps executed: 402 Episode length: 301 Return: -281.61689187677986
INFO:tensorflow:Average training steps per second: 256.89
I0902 18:14:02.570986 140131099109376 replay_runner.py:36] Average training steps per second: 256.89
I0902 18:14:03.483452 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -272.42
INFO:tensorflow:Starting iteration 1

Steps executed: 297 Episode length: 143 Return: -278.61049862210476
INFO:tensorflow:Average training steps per second: 342.38
I0902 18:14:09.562782 140131099109376 replay_runner.py:36] Average training steps per second: 342.38
I0902 18:14:09.756258 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.65
INFO:tensorflow:Starting iteration 2

Steps executed: 276 Episode length: 155 Return: -286.10090598994614
INFO:tensorflow:Average training steps per second: 340.96
I0902 18:14:16.068188 140131099109376 replay_runner.py:36] Average training steps per second: 340.96
I0902 18:14:16.224073 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.03
INFO:tensorflow:Starting iteration 3

Steps executed: 248 Episode length: 150 Return: -384.40529922837817
INFO:tensorflow:Average training steps per second: 340.13
I0902 18:14:22.599862 140131099109376 replay_runner.py:36] Average training steps per second: 340.13
I0902 18:14:22.735488 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -360.59
INFO:tensorflow:Starting iteration 4

Steps executed: 230 Episode length: 126 Return: -137.64529685318448
INFO:tensorflow:Average training steps per second: 331.45
I0902 18:14:29.191449 140131099109376 replay_runner.py:36] Average training steps per second: 331.45
I0902 18:14:29.308814 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.10
INFO:tensorflow:Starting iteration 5

Steps executed: 244 Episode length: 244 Return: -13.763192154989738
INFO:tensorflow:Average training steps per second: 334.92
I0902 18:14:35.680807 140131099109376 replay_runner.py:36] Average training steps per second: 334.92
I0902 18:14:35.866263 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -13.76
INFO:tensorflow:Starting iteration 6
I0902 18:14:39.243399 140131099109376 replay_runner.py:41] Starting iteration 6

Steps executed: 1000 Episode length: 1000 Return: -108.38706454326197
I0902 18:14:42.219114 140131099109376 replay_runner.py:36] Average training steps per second: 336.08
I0902 18:14:43.946712 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.39
INFO:tensorflow:Starting iteration 7
I0902 18:14:47.292359 140131099109376 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 344.22

Steps executed: 1000 Episode length: 1000 Return: 13.3363191056413427
I0902 18:14:53.112137 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: 13.34
INFO:tensorflow:Starting iteration 8
I0902 18:14:56.386385 140131099109376 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 330.79

Steps executed: 975 Episode length: 975 Return: -1804.368501032468427
I0902 18:15:01.573620 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -1804.37
INFO:tensorflow:Starting iteration 9

Steps executed: 127 Episode length: 127 Return: -277.7275260734777527
INFO:tensorflow:Average training steps per second: 327.03

Steps executed: 573 Episode length: 446 Return: -156.9834389456058827
I0902 18:15:08.459296 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.36
INFO:tensorflow:Starting iteration 10

Steps executed: 567 Episode length: 567 Return: -285.0220775559835827
INFO:tensorflow:Average training steps per second: 319.85
I0902 18:15:14.806285 140131099109376 replay_runner.py:36] Average training steps per second: 319.85
I0902 18:15:15.603988 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.02
INFO:tensorflow:Starting iteration 11

Steps executed: 96 Episode length: 96 Return: -598.434609634685135827
INFO:tensorflow:Average training steps per second: 315.95

Steps executed: 538 Episode length: 442 Return: -246.2114413876943527
I0902 18:15:22.494930 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -422.32
INFO:tensorflow:Starting iteration 12

Steps executed: 529 Episode length: 529 Return: -159.0632291925188627
INFO:tensorflow:Average training steps per second: 327.72
I0902 18:15:28.801651 140131099109376 replay_runner.py:36] Average training steps per second: 327.72
I0902 18:15:29.478235 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.06
INFO:tensorflow:Starting iteration 13
I0902 18:15:32.687940 140131099109376 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 334.77

Steps executed: 1000 Episode length: 1000 Return: -138.42055429841967
I0902 18:15:37.380983 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.42
INFO:tensorflow:Starting iteration 14
I0902 18:15:40.571023 140131099109376 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 331.61

Steps executed: 1000 Episode length: 1000 Return: -123.64632038867101
I0902 18:15:45.736420 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.65
INFO:tensorflow:Starting iteration 15

Steps executed: 61 Episode length: 61 Return: -211.084401850762737101
INFO:tensorflow:Average training steps per second: 346.28

Steps executed: 1061 Episode length: 1000 Return: -113.24509291521548
I0902 18:15:54.079794 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.16
INFO:tensorflow:Starting iteration 16
I0902 18:15:57.442324 140131099109376 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 339.07

Steps executed: 1000 Episode length: 1000 Return: -55.265764683633748
I0902 18:16:02.355211 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -55.27
INFO:tensorflow:Starting iteration 17
I0902 18:16:05.806077 140131099109376 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 350.72
I0902 18:16:08.657741 140131099109376 replay_runner.py:36] Average training steps per second: 350.72

Steps executed: 242 Episode length: 50 Return: -323.38189433566185848
INFO:tensorflow:Starting iteration 18

Steps executed: 183 Episode length: 183 Return: -407.1701627353718348
INFO:tensorflow:Average training steps per second: 347.84

Steps executed: 1183 Episode length: 1000 Return: -102.39101546556005
I0902 18:16:17.306872 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.78
INFO:tensorflow:Starting iteration 19

Steps executed: 57 Episode length: 57 Return: -370.749574569294746005
INFO:tensorflow:Average training steps per second: 357.36
I0902 18:16:23.458991 140131099109376 replay_runner.py:36] Average training steps per second: 357.36

Steps executed: 1057 Episode length: 1000 Return: -92.763673208515475
INFO:tensorflow:Starting iteration 20
I0902 18:16:29.710795 140131099109376 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 324.45

Steps executed: 1144 Episode length: 1000 Return: -63.801851692602855
I0902 18:16:34.030640 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.98
INFO:tensorflow:Starting iteration 21
I0902 18:16:37.337451 140131099109376 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 339.37

Steps executed: 1000 Episode length: 1000 Return: -89.437008310121235
I0902 18:16:43.082651 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.44
INFO:tensorflow:Starting iteration 22

Steps executed: 458 Episode length: 399 Return: -204.7130039105813235
INFO:tensorflow:Average training steps per second: 350.22
I0902 18:16:49.349861 140131099109376 replay_runner.py:36] Average training steps per second: 350.22
I0902 18:16:49.773982 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.84
INFO:tensorflow:Starting iteration 23

Steps executed: 132 Episode length: 132 Return: -65.46628483121543235
INFO:tensorflow:Average training steps per second: 323.63

Steps executed: 722 Episode length: 590 Return: -312.4688276487226235
I0902 18:16:57.388031 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.97
INFO:tensorflow:Starting iteration 24

Steps executed: 392 Episode length: 223 Return: -116.1432262156860335
INFO:tensorflow:Average training steps per second: 338.85
I0902 18:17:03.665110 140131099109376 replay_runner.py:36] Average training steps per second: 338.85
I0902 18:17:03.942845 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.89
INFO:tensorflow:Starting iteration 25

Steps executed: 203 Episode length: 63 Return: -171.15425784487599335
INFO:tensorflow:Average training steps per second: 349.19
I0902 18:17:10.176504 140131099109376 replay_runner.py:36] Average training steps per second: 349.19
I0902 18:17:10.322725 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -62.44
INFO:tensorflow:Starting iteration 26
I0902 18:17:13.782715 140131099109376 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 352.85

Steps executed: 1053 Episode length: 1000 Return: 8.50080553633498335
I0902 18:17:18.605647 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -22.04
INFO:tensorflow:Starting iteration 27
I0902 18:17:21.948740 140131099109376 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 343.07

Steps executed: 1000 Episode length: 1000 Return: -50.174899173186745
I0902 18:17:27.458691 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -50.17
INFO:tensorflow:Starting iteration 28

Steps executed: 280 Episode length: 132 Return: -480.5075103015842745
INFO:tensorflow:Average training steps per second: 356.23
I0902 18:17:33.530091 140131099109376 replay_runner.py:36] Average training steps per second: 356.23
I0902 18:17:33.717666 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.68
INFO:tensorflow:Starting iteration 29

Steps executed: 477 Episode length: 477 Return: -623.8667285429884745
INFO:tensorflow:Average training steps per second: 362.85
I0902 18:17:39.905976 140131099109376 replay_runner.py:36] Average training steps per second: 362.85

Done fixed training!Episode length: 477 Return: -623.8667285429884745