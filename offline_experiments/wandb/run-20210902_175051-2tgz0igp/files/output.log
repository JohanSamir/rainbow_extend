Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0902 17:50:58.485026 140284730537984 run_experiment.py:549] Creating TrainRunner ...
I0902 17:50:58.496415 140284730537984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:50:58.496660 140284730537984 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:50:58.496812 140284730537984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:50:58.496940 140284730537984 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:50:58.497051 140284730537984 dqn_agent.py:275] 	 update_period: 4
I0902 17:50:58.497159 140284730537984 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:50:58.497274 140284730537984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:50:58.497382 140284730537984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:50:58.497479 140284730537984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:50:58.497573 140284730537984 dqn_agent.py:280] 	 optimizer: adam
I0902 17:50:58.497667 140284730537984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:50:58.497759 140284730537984 dqn_agent.py:283] 	 seed: 1630605058496353
I0902 17:50:58.500371 140284730537984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:50:58.500544 140284730537984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:50:58.500656 140284730537984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:50:58.500750 140284730537984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:50:58.500927 140284730537984 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:50:58.501030 140284730537984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:50:58.501120 140284730537984 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:50:58.501214 140284730537984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:50:58.501303 140284730537984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:50:58.537448 140284730537984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:50:58.926331 140284730537984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:50:58.939438 140284730537984 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 17:50:58.947364 140284730537984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:50:58.947647 140284730537984 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:50:58.947794 140284730537984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:50:58.947907 140284730537984 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:50:58.947989 140284730537984 dqn_agent.py:275] 	 update_period: 4
I0902 17:50:58.948089 140284730537984 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:50:58.948302 140284730537984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:50:58.948436 140284730537984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:50:58.948533 140284730537984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:50:58.948706 140284730537984 dqn_agent.py:280] 	 optimizer: adam
I0902 17:50:58.948798 140284730537984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:50:58.948880 140284730537984 dqn_agent.py:283] 	 seed: 1630605058947296
I0902 17:50:58.951795 140284730537984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:50:58.952080 140284730537984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:50:58.952275 140284730537984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:50:58.952457 140284730537984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:50:58.952595 140284730537984 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:50:58.952754 140284730537984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:50:58.952885 140284730537984 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:50:58.953006 140284730537984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:50:58.953180 140284730537984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:50:59.016361 140284730537984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:50:59.037742 140284730537984 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 17:50:59.038035 140284730537984 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 165.64
I0902 17:51:05.075362 140284730537984 replay_runner.py:36] Average training steps per second: 165.64
Steps executed: 237 Episode length: 81 Return: -657.4656539599472
I0902 17:51:06.302394 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -659.31
INFO:tensorflow:Starting iteration 1

Steps executed: 220 Episode length: 109 Return: -594.4144889523795
INFO:tensorflow:Average training steps per second: 221.99
I0902 17:51:15.170732 140284730537984 replay_runner.py:36] Average training steps per second: 221.99
I0902 17:51:15.388037 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -637.11
INFO:tensorflow:Starting iteration 2

Steps executed: 200 Episode length: 121 Return: -634.1248980268543
INFO:tensorflow:Average training steps per second: 225.06
I0902 17:51:24.228124 140284730537984 replay_runner.py:36] Average training steps per second: 225.06
I0902 17:51:24.418014 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -664.17
INFO:tensorflow:Starting iteration 3

Steps executed: 200 Episode length: 78 Return: -680.78976476244433
INFO:tensorflow:Average training steps per second: 222.57
I0902 17:51:33.265453 140284730537984 replay_runner.py:36] Average training steps per second: 222.57
I0902 17:51:33.437783 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -641.72
INFO:tensorflow:Starting iteration 4

Steps executed: 247 Episode length: 76 Return: -552.42100134126713
INFO:tensorflow:Average training steps per second: 220.80
I0902 17:51:42.325135 140284730537984 replay_runner.py:36] Average training steps per second: 220.80
I0902 17:51:42.550631 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -562.32
INFO:tensorflow:Starting iteration 5

Steps executed: 291 Episode length: 128 Return: -616.6470722368263
INFO:tensorflow:Average training steps per second: 223.14
I0902 17:51:51.386182 140284730537984 replay_runner.py:36] Average training steps per second: 223.14
I0902 17:51:51.669751 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -609.07
INFO:tensorflow:Starting iteration 6

Steps executed: 209 Episode length: 81 Return: -580.21131702899991
INFO:tensorflow:Average training steps per second: 225.21
I0902 17:52:00.486597 140284730537984 replay_runner.py:36] Average training steps per second: 225.21
I0902 17:52:00.682081 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -615.52
INFO:tensorflow:Starting iteration 7

Steps executed: 305 Episode length: 115 Return: -614.3860814156403
INFO:tensorflow:Average training steps per second: 226.42
I0902 17:52:09.470272 140284730537984 replay_runner.py:36] Average training steps per second: 226.42
I0902 17:52:09.756674 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -559.82
INFO:tensorflow:Starting iteration 8

Steps executed: 284 Episode length: 106 Return: -707.4077782094721
INFO:tensorflow:Average training steps per second: 223.77
I0902 17:52:18.628685 140284730537984 replay_runner.py:36] Average training steps per second: 223.77
I0902 17:52:18.888610 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -626.97
INFO:tensorflow:Starting iteration 9

Steps executed: 277 Episode length: 100 Return: -562.1718483950798
INFO:tensorflow:Average training steps per second: 224.59
I0902 17:52:27.677362 140284730537984 replay_runner.py:36] Average training steps per second: 224.59
I0902 17:52:27.940425 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -644.83
INFO:tensorflow:Starting iteration 10

Steps executed: 265 Episode length: 86 Return: -598.45671034038348
INFO:tensorflow:Average training steps per second: 224.75
I0902 17:52:36.775645 140284730537984 replay_runner.py:36] Average training steps per second: 224.75
I0902 17:52:37.017769 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -576.76
INFO:tensorflow:Starting iteration 11

Steps executed: 208 Episode length: 97 Return: -461.79816164012723
INFO:tensorflow:Average training steps per second: 225.29
I0902 17:52:45.777064 140284730537984 replay_runner.py:36] Average training steps per second: 225.29
I0902 17:52:45.965471 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -562.00
INFO:tensorflow:Starting iteration 12

Steps executed: 229 Episode length: 109 Return: -409.47004371089945
INFO:tensorflow:Average training steps per second: 226.06
I0902 17:52:54.765988 140284730537984 replay_runner.py:36] Average training steps per second: 226.06
I0902 17:52:54.966145 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -442.47
INFO:tensorflow:Starting iteration 13

Steps executed: 300 Episode length: 111 Return: -591.59899765801215
INFO:tensorflow:Average training steps per second: 228.97
I0902 17:53:03.690185 140284730537984 replay_runner.py:36] Average training steps per second: 228.97
I0902 17:53:03.946702 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -564.19
INFO:tensorflow:Starting iteration 14

Steps executed: 263 Episode length: 129 Return: -474.38302249114395
INFO:tensorflow:Average training steps per second: 242.75
I0902 17:53:12.206584 140284730537984 replay_runner.py:36] Average training steps per second: 242.75
I0902 17:53:12.508285 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -369.22
INFO:tensorflow:Starting iteration 15

Steps executed: 271 Episode length: 80 Return: -406.129500976555955
INFO:tensorflow:Average training steps per second: 234.11
I0902 17:53:21.032703 140284730537984 replay_runner.py:36] Average training steps per second: 234.11
I0902 17:53:21.266996 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -584.36
INFO:tensorflow:Starting iteration 16

Steps executed: 378 Episode length: 200 Return: -502.05746235399306
INFO:tensorflow:Average training steps per second: 225.17
I0902 17:53:30.001007 140284730537984 replay_runner.py:36] Average training steps per second: 225.17
I0902 17:53:30.373988 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -336.41
INFO:tensorflow:Starting iteration 17
I0902 17:53:34.630733 140284730537984 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 241.41

Steps executed: 332 Episode length: 332 Return: -413.40216565788786
I0902 17:53:39.166219 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -413.40
INFO:tensorflow:Starting iteration 18

Steps executed: 260 Episode length: 154 Return: -623.02721913578566
INFO:tensorflow:Average training steps per second: 233.01
I0902 17:53:47.669097 140284730537984 replay_runner.py:36] Average training steps per second: 233.01
I0902 17:53:47.883587 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -658.59
INFO:tensorflow:Starting iteration 19
I0902 17:53:52.156296 140284730537984 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 227.07
I0902 17:53:56.560786 140284730537984 replay_runner.py:36] Average training steps per second: 227.07

Steps executed: 291 Episode length: 98 Return: -415.774436825344656
INFO:tensorflow:Starting iteration 20

Steps executed: 335 Episode length: 335 Return: -734.03643660299946
INFO:tensorflow:Average training steps per second: 221.23
I0902 17:54:05.651949 140284730537984 replay_runner.py:36] Average training steps per second: 221.23
I0902 17:54:06.099345 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -734.04
INFO:tensorflow:Starting iteration 21

Steps executed: 300 Episode length: 132 Return: -417.67032686572686
INFO:tensorflow:Average training steps per second: 225.90
I0902 17:54:14.921893 140284730537984 replay_runner.py:36] Average training steps per second: 225.90
I0902 17:54:15.184991 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -404.08
INFO:tensorflow:Starting iteration 22

Steps executed: 396 Episode length: 315 Return: -747.45693669158386
INFO:tensorflow:Average training steps per second: 226.90
I0902 17:54:23.975429 140284730537984 replay_runner.py:36] Average training steps per second: 226.90
I0902 17:54:24.418328 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -559.57
INFO:tensorflow:Starting iteration 23

Steps executed: 201 Episode length: 78 Return: -331.865442050132636
INFO:tensorflow:Average training steps per second: 220.72
I0902 17:54:33.351207 140284730537984 replay_runner.py:36] Average training steps per second: 220.72
I0902 17:54:33.532296 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -403.39
INFO:tensorflow:Starting iteration 24

Steps executed: 185 Episode length: 185 Return: -317.02541003288166
INFO:tensorflow:Average training steps per second: 224.65

Steps executed: 310 Episode length: 125 Return: -360.76488603458483
I0902 17:54:42.718841 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.90
INFO:tensorflow:Starting iteration 25

Steps executed: 366 Episode length: 366 Return: -684.84112741701383
INFO:tensorflow:Average training steps per second: 222.75
I0902 17:54:51.624736 140284730537984 replay_runner.py:36] Average training steps per second: 222.75
I0902 17:54:52.087699 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -684.84
INFO:tensorflow:Starting iteration 26

Steps executed: 260 Episode length: 100 Return: -340.08696239965923
INFO:tensorflow:Average training steps per second: 219.15
I0902 17:55:01.042876 140284730537984 replay_runner.py:36] Average training steps per second: 219.15
I0902 17:55:01.272887 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -396.12
INFO:tensorflow:Starting iteration 27

Steps executed: 339 Episode length: 142 Return: -333.66326046869533
INFO:tensorflow:Average training steps per second: 223.40
I0902 17:55:10.089699 140284730537984 replay_runner.py:36] Average training steps per second: 223.40
I0902 17:55:10.405584 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -523.55
INFO:tensorflow:Starting iteration 28

Steps executed: 204 Episode length: 204 Return: -187.17000363034793
INFO:tensorflow:Average training steps per second: 221.05
I0902 17:55:19.270064 140284730537984 replay_runner.py:36] Average training steps per second: 221.05
I0902 17:55:19.446715 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.17
INFO:tensorflow:Starting iteration 29

Steps executed: 280 Episode length: 118 Return: -310.40079862358773
INFO:tensorflow:Average training steps per second: 235.36
I0902 17:55:28.092274 140284730537984 replay_runner.py:36] Average training steps per second: 235.36

Done fixed training!Episode length: 118 Return: -310.40079862358773