I0903 00:08:37.267440 140006414895104 run_experiment.py:549] Creating TrainRunner ...
I0903 00:08:37.275034 140006414895104 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:08:37.275203 140006414895104 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:08:37.275307 140006414895104 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:08:37.275374 140006414895104 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:08:37.275435 140006414895104 dqn_agent.py:275] 	 update_period: 4
I0903 00:08:37.275491 140006414895104 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:08:37.275653 140006414895104 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:08:37.275871 140006414895104 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:08:37.275986 140006414895104 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:08:37.276087 140006414895104 dqn_agent.py:280] 	 optimizer: adam
I0903 00:08:37.276212 140006414895104 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:08:37.276407 140006414895104 dqn_agent.py:283] 	 seed: 1630627717274990
I0903 00:08:37.278947 140006414895104 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:08:37.279075 140006414895104 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:08:37.279155 140006414895104 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:08:37.279221 140006414895104 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:08:37.279282 140006414895104 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:08:37.279429 140006414895104 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:08:37.279495 140006414895104 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:08:37.279581 140006414895104 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:08:37.279667 140006414895104 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:08:37.304538 140006414895104 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:37.578722 140006414895104 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:37.589749 140006414895104 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:08:37.597127 140006414895104 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:08:37.597289 140006414895104 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:08:37.597363 140006414895104 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:08:37.597426 140006414895104 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:08:37.597482 140006414895104 dqn_agent.py:275] 	 update_period: 4
I0903 00:08:37.597558 140006414895104 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:08:37.597655 140006414895104 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:08:37.597728 140006414895104 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:08:37.597806 140006414895104 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:08:37.597882 140006414895104 dqn_agent.py:280] 	 optimizer: adam
I0903 00:08:37.597963 140006414895104 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:08:37.598034 140006414895104 dqn_agent.py:283] 	 seed: 1630627717597093
I0903 00:08:37.599487 140006414895104 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:08:37.599616 140006414895104 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:08:37.599689 140006414895104 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:08:37.599753 140006414895104 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:08:37.599811 140006414895104 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:08:37.599905 140006414895104 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:08:37.599986 140006414895104 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:08:37.600062 140006414895104 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:08:37.600135 140006414895104 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:08:37.622228 140006414895104 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:37.638868 140006414895104 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:08:37.639182 140006414895104 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
Steps executed: 271 Episode length: 78 Return: -442.79197788350736
INFO:tensorflow:Average training steps per second: 228.07
I0903 00:08:42.024008 140006414895104 replay_runner.py:36] Average training steps per second: 228.07
I0903 00:08:42.785007 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -429.60
INFO:tensorflow:Starting iteration 1

Steps executed: 321 Episode length: 164 Return: -592.3655444931336
INFO:tensorflow:Average training steps per second: 321.46
I0903 00:08:49.332799 140006414895104 replay_runner.py:36] Average training steps per second: 321.46
I0903 00:08:49.524278 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -578.51
INFO:tensorflow:Starting iteration 2

Steps executed: 270 Episode length: 125 Return: -357.30622305219125
INFO:tensorflow:Average training steps per second: 315.46
I0903 00:08:56.113123 140006414895104 replay_runner.py:36] Average training steps per second: 315.46
I0903 00:08:56.264039 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -336.55
INFO:tensorflow:Starting iteration 3
I0903 00:08:59.377771 140006414895104 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 306.15

Steps executed: 622 Episode length: 622 Return: -107.10921610221745
I0903 00:09:03.784473 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.11
INFO:tensorflow:Starting iteration 4
I0903 00:09:06.929104 140006414895104 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 305.42

Steps executed: 1000 Episode length: 1000 Return: -154.5775133893696
I0903 00:09:12.042660 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.58
INFO:tensorflow:Starting iteration 5
I0903 00:09:15.437246 140006414895104 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 327.24

Steps executed: 1000 Episode length: 1000 Return: -356.10318257729784
I0903 00:09:20.475136 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -356.10
INFO:tensorflow:Starting iteration 6
I0903 00:09:23.915075 140006414895104 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 317.26

Steps executed: 1000 Episode length: 1000 Return: -113.85457611327384
I0903 00:09:29.077842 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.85
INFO:tensorflow:Starting iteration 7

Steps executed: 1000 Episode length: 1000 Return: -710.58159405700754
INFO:tensorflow:Average training steps per second: 336.08
I0903 00:09:35.541303 140006414895104 replay_runner.py:36] Average training steps per second: 336.08
I0903 00:09:36.696351 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -710.58
INFO:tensorflow:Starting iteration 8
I0903 00:09:40.197585 140006414895104 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 345.18

Steps executed: 1000 Episode length: 1000 Return: -13.346610461263484
I0903 00:09:45.070345 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -13.35
INFO:tensorflow:Starting iteration 9

Steps executed: 1000 Episode length: 1000 Return: -250.51735802059858
INFO:tensorflow:Average training steps per second: 368.39
I0903 00:09:51.322681 140006414895104 replay_runner.py:36] Average training steps per second: 368.39
I0903 00:09:52.598288 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -250.52
INFO:tensorflow:Starting iteration 10
I0903 00:09:56.107492 140006414895104 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 340.25

Steps executed: 1000 Episode length: 1000 Return: -47.792105909305838
I0903 00:10:01.974911 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -47.79
INFO:tensorflow:Starting iteration 11
I0903 00:10:05.242982 140006414895104 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 315.98

Steps executed: 1000 Episode length: 1000 Return: -191.67636985508892
I0903 00:10:10.760795 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.68
INFO:tensorflow:Starting iteration 12
I0903 00:10:14.148683 140006414895104 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 313.99

Steps executed: 1000 Episode length: 1000 Return: -237.62033973518682
I0903 00:10:19.931172 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.62
INFO:tensorflow:Starting iteration 13
I0903 00:10:23.427717 140006414895104 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 346.21

Steps executed: 1000 Episode length: 1000 Return: -158.55128292451138
I0903 00:10:28.042263 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.55
INFO:tensorflow:Starting iteration 14
I0903 00:10:31.449562 140006414895104 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 345.38

Steps executed: 1000 Episode length: 1000 Return: -149.77796147558394
I0903 00:10:36.926226 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.78
INFO:tensorflow:Starting iteration 15
I0903 00:10:40.061878 140006414895104 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 302.76
I0903 00:10:43.365151 140006414895104 replay_runner.py:36] Average training steps per second: 302.76

Steps executed: 214 Episode length: 140 Return: -115.8197664594382394
INFO:tensorflow:Starting iteration 16

Steps executed: 225 Episode length: 55 Return: -131.10600384738913394
INFO:tensorflow:Average training steps per second: 303.52
I0903 00:10:49.979734 140006414895104 replay_runner.py:36] Average training steps per second: 303.52
I0903 00:10:50.104997 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.02
INFO:tensorflow:Starting iteration 17

Steps executed: 393 Episode length: 260 Return: -42.69807251352558194
INFO:tensorflow:Average training steps per second: 312.86
I0903 00:10:56.499508 140006414895104 replay_runner.py:36] Average training steps per second: 312.86
I0903 00:10:56.838512 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -22.12
INFO:tensorflow:Starting iteration 18

Steps executed: 63 Episode length: 63 Return: -67.9016934539772558194
INFO:tensorflow:Average training steps per second: 312.96

Steps executed: 322 Episode length: 129 Return: -182.8887991607302394
I0903 00:11:03.453215 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.85
INFO:tensorflow:Starting iteration 19

Steps executed: 228 Episode length: 131 Return: -132.6011284416044394
INFO:tensorflow:Average training steps per second: 299.49
I0903 00:11:10.107813 140006414895104 replay_runner.py:36] Average training steps per second: 299.49
I0903 00:11:10.254475 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.86
INFO:tensorflow:Starting iteration 20

Steps executed: 290 Episode length: 102 Return: -3.285254527498352794
INFO:tensorflow:Average training steps per second: 310.67
I0903 00:11:16.775873 140006414895104 replay_runner.py:36] Average training steps per second: 310.67
I0903 00:11:16.940968 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.61
INFO:tensorflow:Starting iteration 21
I0903 00:11:20.205278 140006414895104 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 313.99

Steps executed: 252 Episode length: 59 Return: -157.81905776324230794
I0903 00:11:23.547002 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.55
INFO:tensorflow:Starting iteration 22

Steps executed: 203 Episode length: 73 Return: -477.77844006323290794
INFO:tensorflow:Average training steps per second: 319.55
I0903 00:11:29.986876 140006414895104 replay_runner.py:36] Average training steps per second: 319.55
I0903 00:11:30.117316 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -452.53
INFO:tensorflow:Starting iteration 23

Steps executed: 259 Episode length: 69 Return: -160.27904575368072794
INFO:tensorflow:Average training steps per second: 324.55
I0903 00:11:36.531482 140006414895104 replay_runner.py:36] Average training steps per second: 324.55
I0903 00:11:36.658280 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.61
INFO:tensorflow:Starting iteration 24

Steps executed: 220 Episode length: 51 Return: -119.35043810669092794
INFO:tensorflow:Average training steps per second: 327.14
I0903 00:11:43.004498 140006414895104 replay_runner.py:36] Average training steps per second: 327.14
I0903 00:11:43.146860 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.92
INFO:tensorflow:Starting iteration 25

Steps executed: 183 Episode length: 54 Return: -138.67311241942454794
INFO:tensorflow:Average training steps per second: 324.36

Steps executed: 268 Episode length: 85 Return: -695.64502328553334794
I0903 00:11:49.674005 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.06
INFO:tensorflow:Starting iteration 26

Steps executed: 1000 Episode length: 1000 Return: 35.8322949259340394
INFO:tensorflow:Average training steps per second: 337.38
I0903 00:11:55.917676 140006414895104 replay_runner.py:36] Average training steps per second: 337.38
I0903 00:11:57.494063 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: 35.83
INFO:tensorflow:Starting iteration 27

Steps executed: 228 Episode length: 118 Return: -328.6124901145957494
INFO:tensorflow:Average training steps per second: 319.48
I0903 00:12:03.799415 140006414895104 replay_runner.py:36] Average training steps per second: 319.48
I0903 00:12:03.939188 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.58
INFO:tensorflow:Starting iteration 28

Steps executed: 265 Episode length: 120 Return: -94.50675914478532594
INFO:tensorflow:Average training steps per second: 310.20
I0903 00:12:10.379546 140006414895104 replay_runner.py:36] Average training steps per second: 310.20
I0903 00:12:10.537981 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.33
INFO:tensorflow:Starting iteration 29

Steps executed: 264 Episode length: 109 Return: -307.7004578901596794
INFO:tensorflow:Average training steps per second: 321.45
I0903 00:12:16.900684 140006414895104 replay_runner.py:36] Average training steps per second: 321.45

Done fixed training!Episode length: 109 Return: -307.7004578901596794