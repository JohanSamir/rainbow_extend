Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0902 00:09:56.804657 140149719906304 run_experiment.py:549] Creating TrainRunner ...
I0902 00:09:56.816068 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:09:56.816334 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:09:56.816484 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:09:56.816600 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:09:56.816712 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0902 00:09:56.816866 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:09:56.816980 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:09:56.817072 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:09:56.817166 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:09:56.817245 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0902 00:09:56.817319 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:09:56.817474 140149719906304 dqn_agent.py:283] 	 seed: 1630541396815993
I0902 00:09:56.820687 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:09:56.820952 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:09:56.821192 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:09:56.821372 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:09:56.821521 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:09:56.821651 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:09:56.821895 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:09:56.822101 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:09:56.822294 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:09:56.861138 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:09:57.268063 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:09:57.284406 140149719906304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:09:57.316489 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:09:57.316829 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:09:57.317024 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:09:57.317166 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:09:57.317266 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0902 00:09:57.317342 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:09:57.317413 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:09:57.317489 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:09:57.317598 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:09:57.317785 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0902 00:09:57.318147 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:09:57.318406 140149719906304 dqn_agent.py:283] 	 seed: 1630541397316408
I0902 00:09:57.321358 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:09:57.321585 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:09:57.321732 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:09:57.321833 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:09:57.321956 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:09:57.322036 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:09:57.322229 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:09:57.322315 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:09:57.322366 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:09:57.357152 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:09:57.382310 140149719906304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:09:57.382632 140149719906304 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 164.16
I0902 00:10:03.474601 140149719906304 replay_runner.py:36] Average training steps per second: 164.16
Steps executed: 294 Episode length: 123 Return: -286.91746969780604
I0902 00:10:04.844187 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -271.57
INFO:tensorflow:Starting iteration 1

Steps executed: 236 Episode length: 131 Return: -278.35896873513434
INFO:tensorflow:Average training steps per second: 228.73
I0902 00:10:13.592405 140149719906304 replay_runner.py:36] Average training steps per second: 228.73
I0902 00:10:13.796280 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -323.12
INFO:tensorflow:Starting iteration 2

Steps executed: 210 Episode length: 210 Return: -182.20723043666328
INFO:tensorflow:Average training steps per second: 225.99
I0902 00:10:22.652590 140149719906304 replay_runner.py:36] Average training steps per second: 225.99
I0902 00:10:22.869966 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.21
INFO:tensorflow:Starting iteration 3
I0902 00:10:27.103326 140149719906304 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 228.97


Steps executed: 655 Episode length: 533 Return: -415.60995580658268
I0902 00:10:32.779894 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -512.55
INFO:tensorflow:Starting iteration 4
I0902 00:10:37.149043 140149719906304 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 231.41

Steps executed: 869 Episode length: 869 Return: -745.28025909371928
I0902 00:10:43.148149 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -745.28
INFO:tensorflow:Starting iteration 5
I0902 00:10:47.416023 140149719906304 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 226.35

Steps executed: 1000 Episode length: 1000 Return: -137.73923555276156
I0902 00:10:54.883129 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.74
INFO:tensorflow:Starting iteration 6

Steps executed: 158 Episode length: 158 Return: -124.1380411452173156
INFO:tensorflow:Average training steps per second: 228.49

Steps executed: 1158 Episode length: 1000 Return: -130.23329175198543
I0902 00:11:07.288319 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.19
INFO:tensorflow:Starting iteration 7
I0902 00:11:11.956561 140149719906304 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 219.05

Steps executed: 1000 Episode length: 1000 Return: -173.55367484672342
I0902 00:11:18.673172 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.55
INFO:tensorflow:Starting iteration 8
I0902 00:11:23.007164 140149719906304 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 219.04

Steps executed: 1000 Episode length: 1000 Return: -117.26385779530813
I0902 00:11:31.260854 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.26
INFO:tensorflow:Starting iteration 9

Steps executed: 375 Episode length: 375 Return: -211.0930581292813313
INFO:tensorflow:Average training steps per second: 221.67
I0902 00:11:40.105300 140149719906304 replay_runner.py:36] Average training steps per second: 221.67
I0902 00:11:40.576826 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.09
INFO:tensorflow:Starting iteration 10

Steps executed: 377 Episode length: 377 Return: -243.5634523101363313
INFO:tensorflow:Average training steps per second: 220.29
I0902 00:11:49.436691 140149719906304 replay_runner.py:36] Average training steps per second: 220.29
I0902 00:11:49.931138 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.56
INFO:tensorflow:Starting iteration 11

Steps executed: 233 Episode length: 233 Return: -72.51040528396683313
INFO:tensorflow:Average training steps per second: 235.91
I0902 00:11:58.323206 140149719906304 replay_runner.py:36] Average training steps per second: 235.91
I0902 00:11:58.577095 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.51
INFO:tensorflow:Starting iteration 12

Steps executed: 527 Episode length: 359 Return: -311.0964853966083613
INFO:tensorflow:Average training steps per second: 232.22
I0902 00:12:07.047216 140149719906304 replay_runner.py:36] Average training steps per second: 232.22
I0902 00:12:07.856099 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.27
INFO:tensorflow:Starting iteration 13

Steps executed: 281 Episode length: 107 Return: -191.0202963658753613
INFO:tensorflow:Average training steps per second: 228.45
I0902 00:12:16.447385 140149719906304 replay_runner.py:36] Average training steps per second: 228.45
I0902 00:12:16.712780 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -267.57
INFO:tensorflow:Starting iteration 14

Steps executed: 279 Episode length: 138 Return: -360.1616780249933413
INFO:tensorflow:Average training steps per second: 225.69
I0902 00:12:25.491156 140149719906304 replay_runner.py:36] Average training steps per second: 225.69
I0902 00:12:25.743215 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -372.27
INFO:tensorflow:Starting iteration 15
I0902 00:12:30.027899 140149719906304 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 222.85
I0902 00:12:34.515632 140149719906304 replay_runner.py:36] Average training steps per second: 222.85

Steps executed: 234 Episode length: 234 Return: -429.0278782350241413
INFO:tensorflow:Starting iteration 16

Steps executed: 174 Episode length: 174 Return: -518.3242202056811413
INFO:tensorflow:Average training steps per second: 217.65

Steps executed: 904 Episode length: 730 Return: -341.9423494367648613
I0902 00:12:45.875089 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -430.13
INFO:tensorflow:Starting iteration 17

Steps executed: 222 Episode length: 147 Return: -79.25595357351824613
INFO:tensorflow:Average training steps per second: 223.30
I0902 00:12:54.473182 140149719906304 replay_runner.py:36] Average training steps per second: 223.30
I0902 00:12:54.676824 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.35
INFO:tensorflow:Starting iteration 18
I0902 00:12:58.888024 140149719906304 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 218.80

Steps executed: 1000 Episode length: 1000 Return: -223.57845211301506
I0902 00:13:06.838130 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.58
INFO:tensorflow:Starting iteration 19

Steps executed: 284 Episode length: 147 Return: -184.3595315061109506
INFO:tensorflow:Average training steps per second: 225.21
I0902 00:13:15.700908 140149719906304 replay_runner.py:36] Average training steps per second: 225.21
I0902 00:13:15.924077 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.39
INFO:tensorflow:Starting iteration 20

Steps executed: 240 Episode length: 60 Return: -115.10286079528532706
INFO:tensorflow:Average training steps per second: 225.54
I0902 00:13:24.759951 140149719906304 replay_runner.py:36] Average training steps per second: 225.54
I0902 00:13:24.947880 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.12
INFO:tensorflow:Starting iteration 21

Steps executed: 206 Episode length: 82 Return: -396.00061594239579706
INFO:tensorflow:Average training steps per second: 228.76
I0902 00:13:33.701757 140149719906304 replay_runner.py:36] Average training steps per second: 228.76
I0902 00:13:33.860688 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.26
INFO:tensorflow:Starting iteration 22

Steps executed: 355 Episode length: 170 Return: -230.0524419681346706
INFO:tensorflow:Average training steps per second: 229.64
I0902 00:13:42.572980 140149719906304 replay_runner.py:36] Average training steps per second: 229.64
I0902 00:13:42.938644 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.31
INFO:tensorflow:Starting iteration 23

Steps executed: 313 Episode length: 155 Return: -508.1329478585580506
INFO:tensorflow:Average training steps per second: 224.83
I0902 00:13:51.799541 140149719906304 replay_runner.py:36] Average training steps per second: 224.83
I0902 00:13:52.118135 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -471.57
INFO:tensorflow:Starting iteration 24

Steps executed: 199 Episode length: 57 Return: -103.64380630146779506
INFO:tensorflow:Average training steps per second: 225.98

Steps executed: 349 Episode length: 150 Return: -531.7116834684364506
I0902 00:14:01.288655 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -375.17
INFO:tensorflow:Starting iteration 25

Steps executed: 230 Episode length: 81 Return: -734.02668607624714506
INFO:tensorflow:Average training steps per second: 224.95
I0902 00:14:10.175707 140149719906304 replay_runner.py:36] Average training steps per second: 224.95
I0902 00:14:10.358767 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -494.14
INFO:tensorflow:Starting iteration 26

Steps executed: 210 Episode length: 62 Return: -132.47354125209174506
INFO:tensorflow:Average training steps per second: 226.00
I0902 00:14:19.072717 140149719906304 replay_runner.py:36] Average training steps per second: 226.00
I0902 00:14:19.247766 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.93
INFO:tensorflow:Starting iteration 27

Steps executed: 221 Episode length: 83 Return: -726.76135847654694506
INFO:tensorflow:Average training steps per second: 222.60
I0902 00:14:28.105224 140149719906304 replay_runner.py:36] Average training steps per second: 222.60
I0902 00:14:28.302844 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -642.22
INFO:tensorflow:Starting iteration 28

Steps executed: 220 Episode length: 66 Return: -137.95598570588277506
INFO:tensorflow:Average training steps per second: 220.53
I0902 00:14:37.138269 140149719906304 replay_runner.py:36] Average training steps per second: 220.53
I0902 00:14:37.283492 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.78
INFO:tensorflow:Starting iteration 29

Steps executed: 286 Episode length: 120 Return: -103.2678140627236906
INFO:tensorflow:Average training steps per second: 228.35
I0902 00:14:45.844916 140149719906304 replay_runner.py:36] Average training steps per second: 228.35

Done fixed training!Episode length: 120 Return: -103.2678140627236906