Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0828 10:28:06.490306 140053337282560 run_experiment.py:549] Creating TrainRunner ...
I0828 10:28:06.507243 140053337282560 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:28:06.507487 140053337282560 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:28:06.507604 140053337282560 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:28:06.507763 140053337282560 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:28:06.507849 140053337282560 dqn_agent.py:275] 	 update_period: 4
I0828 10:28:06.508013 140053337282560 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:28:06.508131 140053337282560 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:28:06.508256 140053337282560 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:28:06.508449 140053337282560 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:28:06.508539 140053337282560 dqn_agent.py:280] 	 optimizer: adam
I0828 10:28:06.508623 140053337282560 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:28:06.508749 140053337282560 dqn_agent.py:283] 	 seed: 1630146486507178
I0828 10:28:06.511943 140053337282560 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:28:06.512256 140053337282560 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:28:06.512396 140053337282560 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:28:06.512551 140053337282560 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:28:06.512841 140053337282560 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:28:06.512947 140053337282560 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:28:06.513051 140053337282560 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:28:06.513289 140053337282560 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:28:06.513499 140053337282560 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:28:06.564580 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:06.949464 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:06.964219 140053337282560 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:28:06.996777 140053337282560 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:28:06.997043 140053337282560 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:28:06.997194 140053337282560 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:28:06.997308 140053337282560 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:28:06.997411 140053337282560 dqn_agent.py:275] 	 update_period: 4
I0828 10:28:06.997506 140053337282560 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:28:06.997727 140053337282560 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:28:06.997845 140053337282560 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:28:06.997948 140053337282560 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:28:06.998052 140053337282560 dqn_agent.py:280] 	 optimizer: adam
I0828 10:28:06.998338 140053337282560 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:28:06.998480 140053337282560 dqn_agent.py:283] 	 seed: 1630146486996716
I0828 10:28:07.003247 140053337282560 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:28:07.003602 140053337282560 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:28:07.003772 140053337282560 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:28:07.003902 140053337282560 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:28:07.004058 140053337282560 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:28:07.004198 140053337282560 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:28:07.004322 140053337282560 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:28:07.004434 140053337282560 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:28:07.004621 140053337282560 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:28:07.040394 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:07.063897 140053337282560 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:28:07.064206 140053337282560 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 166.72
I0828 10:28:13.062776 140053337282560 replay_runner.py:36] Average training steps per second: 166.72
Steps executed: 221 Episode length: 60 Return: -149.15548479637738
I0828 10:28:14.278661 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.24
INFO:tensorflow:Starting iteration 1

Steps executed: 225 Episode length: 93 Return: -145.93386075933364
INFO:tensorflow:Average training steps per second: 226.19
I0828 10:28:23.057821 140053337282560 replay_runner.py:36] Average training steps per second: 226.19
I0828 10:28:23.206032 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.46
INFO:tensorflow:Starting iteration 2

Steps executed: 70 Episode length: 70 Return: -554.894453995241964
INFO:tensorflow:Average training steps per second: 223.87

Steps executed: 275 Episode length: 78 Return: -731.20944485886784
I0828 10:28:32.235458 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -595.24
INFO:tensorflow:Starting iteration 3

Steps executed: 277 Episode length: 82 Return: -744.66010050017947
INFO:tensorflow:Average training steps per second: 226.84
I0828 10:28:41.101017 140053337282560 replay_runner.py:36] Average training steps per second: 226.84
I0828 10:28:41.354902 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.12
INFO:tensorflow:Starting iteration 4
I0828 10:28:45.782895 140053337282560 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 226.81

Steps executed: 223 Episode length: 70 Return: -143.52923558677512
I0828 10:28:50.350008 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.94
INFO:tensorflow:Starting iteration 5

Steps executed: 242 Episode length: 54 Return: -436.594803340568666
INFO:tensorflow:Average training steps per second: 229.63
I0828 10:28:59.146943 140053337282560 replay_runner.py:36] Average training steps per second: 229.63
I0828 10:28:59.378216 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -818.42
INFO:tensorflow:Starting iteration 6

Steps executed: 175 Episode length: 94 Return: -598.423281329598566
INFO:tensorflow:Average training steps per second: 230.23
I0828 10:29:08.065956 140053337282560 replay_runner.py:36] Average training steps per second: 230.23

Steps executed: 255 Episode length: 80 Return: -628.386452068450666
INFO:tensorflow:Starting iteration 7

Steps executed: 241 Episode length: 84 Return: -844.573058444242256
INFO:tensorflow:Average training steps per second: 229.70
I0828 10:29:17.141296 140053337282560 replay_runner.py:36] Average training steps per second: 229.70
I0828 10:29:17.375047 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -650.11
INFO:tensorflow:Starting iteration 8

Steps executed: 201 Episode length: 71 Return: -217.674332513995326
INFO:tensorflow:Average training steps per second: 229.21
I0828 10:29:26.129248 140053337282560 replay_runner.py:36] Average training steps per second: 229.21
I0828 10:29:26.292897 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.08
INFO:tensorflow:Starting iteration 9

Steps executed: 241 Episode length: 51 Return: -421.705738001891756
INFO:tensorflow:Average training steps per second: 229.64
I0828 10:29:34.925298 140053337282560 replay_runner.py:36] Average training steps per second: 229.64
I0828 10:29:35.156529 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -506.51
INFO:tensorflow:Starting iteration 10

Steps executed: 220 Episode length: 71 Return: -704.777346308648156
INFO:tensorflow:Average training steps per second: 227.81
I0828 10:29:43.809864 140053337282560 replay_runner.py:36] Average training steps per second: 227.81
I0828 10:29:44.004601 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -641.93
INFO:tensorflow:Starting iteration 11

Steps executed: 281 Episode length: 114 Return: -301.22510828814527
INFO:tensorflow:Average training steps per second: 226.02
I0828 10:29:52.845246 140053337282560 replay_runner.py:36] Average training steps per second: 226.02
I0828 10:29:53.084105 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.18
INFO:tensorflow:Starting iteration 12

Steps executed: 223 Episode length: 93 Return: -182.780178199736497
INFO:tensorflow:Average training steps per second: 229.35
I0828 10:30:01.856283 140053337282560 replay_runner.py:36] Average training steps per second: 229.35
I0828 10:30:02.010100 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.49
INFO:tensorflow:Starting iteration 13

Steps executed: 131 Episode length: 58 Return: -417.872817753370447
INFO:tensorflow:Average training steps per second: 237.30

Steps executed: 213 Episode length: 82 Return: -756.244349515251147
I0828 10:30:10.726572 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -614.54
INFO:tensorflow:Starting iteration 14

Steps executed: 242 Episode length: 70 Return: -165.572822777829437
INFO:tensorflow:Average training steps per second: 246.06
I0828 10:30:19.199570 140053337282560 replay_runner.py:36] Average training steps per second: 246.06
I0828 10:30:19.346913 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.57
INFO:tensorflow:Starting iteration 15

Steps executed: 249 Episode length: 249 Return: -2345.4949525205666
INFO:tensorflow:Average training steps per second: 236.62
I0828 10:30:27.987876 140053337282560 replay_runner.py:36] Average training steps per second: 236.62
I0828 10:30:28.267992 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -2345.49
INFO:tensorflow:Starting iteration 16

Steps executed: 266 Episode length: 71 Return: -174.298837800691446
INFO:tensorflow:Average training steps per second: 231.45
I0828 10:30:36.800585 140053337282560 replay_runner.py:36] Average training steps per second: 231.45
I0828 10:30:36.964503 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.95
INFO:tensorflow:Starting iteration 17

Steps executed: 264 Episode length: 95 Return: -594.586102248865446
INFO:tensorflow:Average training steps per second: 233.33
I0828 10:30:45.518568 140053337282560 replay_runner.py:36] Average training steps per second: 233.33
I0828 10:30:45.754449 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -632.67
INFO:tensorflow:Starting iteration 18

Steps executed: 205 Episode length: 73 Return: -474.849686443224476
INFO:tensorflow:Average training steps per second: 243.55
I0828 10:30:54.156215 140053337282560 replay_runner.py:36] Average training steps per second: 243.55
I0828 10:30:54.319147 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -547.02
INFO:tensorflow:Starting iteration 19
I0828 10:30:58.684419 140053337282560 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 245.22

Steps executed: 313 Episode length: 158 Return: -674.39493270782416
I0828 10:31:03.052750 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -557.33
INFO:tensorflow:Starting iteration 20

Steps executed: 215 Episode length: 76 Return: -542.387032496003116
INFO:tensorflow:Average training steps per second: 241.82
I0828 10:31:11.566648 140053337282560 replay_runner.py:36] Average training steps per second: 241.82
I0828 10:31:11.770079 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -571.32
INFO:tensorflow:Starting iteration 21
I0828 10:31:16.164945 140053337282560 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 229.33
I0828 10:31:20.525974 140053337282560 replay_runner.py:36] Average training steps per second: 229.33

Steps executed: 201 Episode length: 70 Return: -634.168366845687616
INFO:tensorflow:Starting iteration 22

Steps executed: 200 Episode length: 68 Return: -688.864598046250356
INFO:tensorflow:Average training steps per second: 226.76
I0828 10:31:29.510085 140053337282560 replay_runner.py:36] Average training steps per second: 226.76
I0828 10:31:29.679257 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -584.86
INFO:tensorflow:Starting iteration 23

Steps executed: 220 Episode length: 60 Return: -463.716627616987076
INFO:tensorflow:Average training steps per second: 227.50
I0828 10:31:38.379752 140053337282560 replay_runner.py:36] Average training steps per second: 227.50
I0828 10:31:38.550151 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -412.01
INFO:tensorflow:Starting iteration 24

Steps executed: 239 Episode length: 67 Return: -148.767401276191186
INFO:tensorflow:Average training steps per second: 223.75
I0828 10:31:47.497773 140053337282560 replay_runner.py:36] Average training steps per second: 223.75
I0828 10:31:47.650453 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.50
INFO:tensorflow:Starting iteration 25

Steps executed: 264 Episode length: 76 Return: -727.187136251231986
INFO:tensorflow:Average training steps per second: 228.64
I0828 10:31:56.480118 140053337282560 replay_runner.py:36] Average training steps per second: 228.64
I0828 10:31:56.704975 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -582.27
INFO:tensorflow:Starting iteration 26

Steps executed: 203 Episode length: 62 Return: -400.754754303927486
INFO:tensorflow:Average training steps per second: 228.86
I0828 10:32:05.503086 140053337282560 replay_runner.py:36] Average training steps per second: 228.86
I0828 10:32:05.665368 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -435.55
INFO:tensorflow:Starting iteration 27

Steps executed: 210 Episode length: 80 Return: -256.573245638084366
INFO:tensorflow:Average training steps per second: 225.90
I0828 10:32:14.510772 140053337282560 replay_runner.py:36] Average training steps per second: 225.90
I0828 10:32:14.656086 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.88
INFO:tensorflow:Starting iteration 28

Steps executed: 215 Episode length: 57 Return: -378.968830724607876
INFO:tensorflow:Average training steps per second: 222.73
I0828 10:32:23.417900 140053337282560 replay_runner.py:36] Average training steps per second: 222.73
I0828 10:32:23.596313 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -484.47
INFO:tensorflow:Starting iteration 29

Steps executed: 261 Episode length: 79 Return: -350.727897618848266
INFO:tensorflow:Average training steps per second: 224.73
I0828 10:32:32.376191 140053337282560 replay_runner.py:36] Average training steps per second: 224.73

Done fixed training!Episode length: 79 Return: -350.727897618848266