Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0901 13:04:13.820338 139803418769408 run_experiment.py:549] Creating TrainRunner ...
I0901 13:04:13.830376 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:04:13.830636 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:04:13.830775 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:04:13.830981 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:04:13.831218 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 13:04:13.831476 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:04:13.831699 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:04:13.831821 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:04:13.831951 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:04:13.832035 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 13:04:13.832104 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:04:13.832174 139803418769408 dqn_agent.py:283] 	 seed: 1630501453830320
I0901 13:04:13.834636 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:04:13.834921 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:04:13.835111 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:04:13.835206 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:04:13.835283 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:04:13.835371 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:04:13.835475 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:04:13.835765 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:04:13.835937 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:04:13.872749 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:04:14.238008 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:04:14.251810 139803418769408 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:04:14.262096 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:04:14.262341 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:04:14.262476 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:04:14.262578 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:04:14.262667 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 13:04:14.262821 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:04:14.262939 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:04:14.263019 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:04:14.263120 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:04:14.263223 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 13:04:14.263418 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:04:14.263525 139803418769408 dqn_agent.py:283] 	 seed: 1630501454262044
I0901 13:04:14.265673 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:04:14.265841 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:04:14.265940 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:04:14.266071 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:04:14.266184 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:04:14.266258 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:04:14.266329 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:04:14.266419 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:04:14.266514 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:04:14.297335 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:04:14.362155 139803418769408 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:04:14.362447 139803418769408 replay_runner.py:41] Starting iteration 0
Steps executed: 411 Episode length: 259 Return: -7.4791831220222497
INFO:tensorflow:Average training steps per second: 177.52
I0901 13:04:19.995955 139803418769408 replay_runner.py:36] Average training steps per second: 177.52
I0901 13:04:21.238375 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.00
INFO:tensorflow:Starting iteration 1

Steps executed: 247 Episode length: 136 Return: -122.95464511014066
INFO:tensorflow:Average training steps per second: 256.00
I0901 13:04:29.167047 139803418769408 replay_runner.py:36] Average training steps per second: 256.00
I0901 13:04:29.328055 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.84
INFO:tensorflow:Starting iteration 2

Steps executed: 208 Episode length: 208 Return: -136.09302550241046
INFO:tensorflow:Average training steps per second: 271.24
I0901 13:04:37.022316 139803418769408 replay_runner.py:36] Average training steps per second: 271.24
I0901 13:04:37.215760 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.09
INFO:tensorflow:Starting iteration 3

Steps executed: 282 Episode length: 121 Return: -34.972705561226795
INFO:tensorflow:Average training steps per second: 286.78
I0901 13:04:44.647810 139803418769408 replay_runner.py:36] Average training steps per second: 286.78
I0901 13:04:44.849708 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -264.29
INFO:tensorflow:Starting iteration 4

Steps executed: 360 Episode length: 237 Return: -249.37721353632872
INFO:tensorflow:Average training steps per second: 286.35
I0901 13:04:52.278415 139803418769408 replay_runner.py:36] Average training steps per second: 286.35
I0901 13:04:52.551897 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.97
INFO:tensorflow:Starting iteration 5

Steps executed: 252 Episode length: 131 Return: -307.02135190348313
INFO:tensorflow:Average training steps per second: 278.17
I0901 13:04:59.983818 139803418769408 replay_runner.py:36] Average training steps per second: 278.17
I0901 13:05:00.193849 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -315.83
INFO:tensorflow:Starting iteration 6

Steps executed: 171 Episode length: 90 Return: -317.753544371085613
INFO:tensorflow:Average training steps per second: 280.33

Steps executed: 315 Episode length: 144 Return: -450.02067863342383
I0901 13:05:07.824316 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -384.58
INFO:tensorflow:Starting iteration 7

Steps executed: 202 Episode length: 115 Return: -103.75670102438366
INFO:tensorflow:Average training steps per second: 283.88
I0901 13:05:15.257221 139803418769408 replay_runner.py:36] Average training steps per second: 283.88
I0901 13:05:15.402091 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -239.37
INFO:tensorflow:Starting iteration 8

Steps executed: 298 Episode length: 137 Return: -416.64677556827936
INFO:tensorflow:Average training steps per second: 301.95
I0901 13:05:22.586775 139803418769408 replay_runner.py:36] Average training steps per second: 301.95
I0901 13:05:22.795451 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -365.93
INFO:tensorflow:Starting iteration 9

Steps executed: 223 Episode length: 223 Return: -171.34270721312058
INFO:tensorflow:Average training steps per second: 222.26
I0901 13:05:31.215369 139803418769408 replay_runner.py:36] Average training steps per second: 222.26
I0901 13:05:31.434625 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.34
INFO:tensorflow:Starting iteration 10

Steps executed: 246 Episode length: 107 Return: -376.28791691750354
INFO:tensorflow:Average training steps per second: 295.51
I0901 13:05:38.662689 139803418769408 replay_runner.py:36] Average training steps per second: 295.51
I0901 13:05:38.821013 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.71
INFO:tensorflow:Starting iteration 11


Steps executed: 210 Episode length: 68 Return: -184.905220660673764
INFO:tensorflow:Average training steps per second: 305.42
I0901 13:05:45.896766 139803418769408 replay_runner.py:36] Average training steps per second: 305.42
I0901 13:05:46.026405 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.56
INFO:tensorflow:Starting iteration 12

Steps executed: 245 Episode length: 145 Return: -194.37216161288887
INFO:tensorflow:Average training steps per second: 319.01
I0901 13:05:52.906768 139803418769408 replay_runner.py:36] Average training steps per second: 319.01
I0901 13:05:53.074719 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.77
INFO:tensorflow:Starting iteration 13

Steps executed: 214 Episode length: 80 Return: -144.858266039116547
INFO:tensorflow:Average training steps per second: 323.25
I0901 13:05:59.841779 139803418769408 replay_runner.py:36] Average training steps per second: 323.25
I0901 13:05:59.966028 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.15
INFO:tensorflow:Starting iteration 14

Steps executed: 302 Episode length: 103 Return: -99.824865383893787
INFO:tensorflow:Average training steps per second: 335.02
I0901 13:06:06.621633 139803418769408 replay_runner.py:36] Average training steps per second: 335.02
I0901 13:06:06.862757 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.39
INFO:tensorflow:Starting iteration 15

Steps executed: 228 Episode length: 72 Return: -48.0528511075560887
INFO:tensorflow:Average training steps per second: 341.43
I0901 13:06:13.464962 139803418769408 replay_runner.py:36] Average training steps per second: 341.43
I0901 13:06:13.587586 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.39
INFO:tensorflow:Starting iteration 16

Steps executed: 264 Episode length: 89 Return: -116.439996208490547
INFO:tensorflow:Average training steps per second: 354.26
I0901 13:06:20.050021 139803418769408 replay_runner.py:36] Average training steps per second: 354.26
I0901 13:06:20.168971 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.96
INFO:tensorflow:Starting iteration 17

Steps executed: 279 Episode length: 109 Return: -462.99929944954135
INFO:tensorflow:Average training steps per second: 348.54
I0901 13:06:26.684729 139803418769408 replay_runner.py:36] Average training steps per second: 348.54
I0901 13:06:26.822320 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -320.56
INFO:tensorflow:Starting iteration 18

Steps executed: 269 Episode length: 205 Return: -223.03490615248545
INFO:tensorflow:Average training steps per second: 348.76
I0901 13:06:33.307659 139803418769408 replay_runner.py:36] Average training steps per second: 348.76
I0901 13:06:33.459331 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.81
INFO:tensorflow:Starting iteration 19
I0901 13:06:37.071299 139803418769408 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 338.51

Steps executed: 214 Episode length: 79 Return: -262.098456251102595
I0901 13:06:40.147465 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -302.25
INFO:tensorflow:Starting iteration 20

Steps executed: 246 Episode length: 110 Return: -124.11624420685769
INFO:tensorflow:Average training steps per second: 344.35
I0901 13:06:46.662720 139803418769408 replay_runner.py:36] Average training steps per second: 344.35
I0901 13:06:46.800829 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.06
INFO:tensorflow:Starting iteration 21

Steps executed: 205 Episode length: 75 Return: -585.098748773097449
INFO:tensorflow:Average training steps per second: 339.94
I0901 13:06:53.323208 139803418769408 replay_runner.py:36] Average training steps per second: 339.94
I0901 13:06:53.430173 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -769.64
INFO:tensorflow:Starting iteration 22
I0901 13:06:56.969171 139803418769408 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 338.93
I0901 13:06:59.919925 139803418769408 replay_runner.py:36] Average training steps per second: 338.93

Steps executed: 236 Episode length: 88 Return: -28.3601704485169829
INFO:tensorflow:Starting iteration 23

Steps executed: 202 Episode length: 59 Return: -456.208456100931369
INFO:tensorflow:Average training steps per second: 331.74
I0901 13:07:06.571622 139803418769408 replay_runner.py:36] Average training steps per second: 331.74
I0901 13:07:06.672034 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -546.40
INFO:tensorflow:Starting iteration 24

Steps executed: 255 Episode length: 66 Return: -231.243173215494349
INFO:tensorflow:Average training steps per second: 334.12
I0901 13:07:13.187832 139803418769408 replay_runner.py:36] Average training steps per second: 334.12
I0901 13:07:13.296683 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.42
INFO:tensorflow:Starting iteration 25

Steps executed: 258 Episode length: 77 Return: -677.254640833866649
INFO:tensorflow:Average training steps per second: 326.25
I0901 13:07:19.846496 139803418769408 replay_runner.py:36] Average training steps per second: 326.25
I0901 13:07:19.965658 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -439.58
INFO:tensorflow:Starting iteration 26

Steps executed: 207 Episode length: 55 Return: -323.824342444957959
INFO:tensorflow:Average training steps per second: 329.89
I0901 13:07:26.485464 139803418769408 replay_runner.py:36] Average training steps per second: 329.89
I0901 13:07:26.582966 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -408.76
INFO:tensorflow:Starting iteration 27

Steps executed: 276 Episode length: 84 Return: -612.906285367057449
INFO:tensorflow:Average training steps per second: 325.09
I0901 13:07:33.121911 139803418769408 replay_runner.py:36] Average training steps per second: 325.09
I0901 13:07:33.273042 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -428.62
INFO:tensorflow:Starting iteration 28

Steps executed: 221 Episode length: 90 Return: 2.982485685295046449
INFO:tensorflow:Average training steps per second: 326.33
I0901 13:07:39.790216 139803418769408 replay_runner.py:36] Average training steps per second: 326.33
I0901 13:07:39.886281 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -32.22
INFO:tensorflow:Starting iteration 29
I0901 13:07:43.317082 139803418769408 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 320.85

Steps executed: 257 Episode length: 77 Return: -536.780833198348859

Done fixed training!Episode length: 77 Return: -536.780833198348859