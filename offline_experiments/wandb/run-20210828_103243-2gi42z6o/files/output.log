Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0828 10:32:49.743427 140053337282560 run_experiment.py:549] Creating TrainRunner ...
I0828 10:32:49.779749 140053337282560 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:49.780042 140053337282560 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:49.780332 140053337282560 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:49.780478 140053337282560 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:49.780611 140053337282560 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:49.780734 140053337282560 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:49.780966 140053337282560 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:49.781246 140053337282560 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:49.781378 140053337282560 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:49.781874 140053337282560 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:49.782052 140053337282560 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:49.782212 140053337282560 dqn_agent.py:283] 	 seed: 1630146769779691
I0828 10:32:49.784504 140053337282560 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:49.784627 140053337282560 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:49.784724 140053337282560 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:49.784804 140053337282560 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:49.784882 140053337282560 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:49.784962 140053337282560 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:49.785059 140053337282560 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:49.785251 140053337282560 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:49.785408 140053337282560 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:49.840880 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:50.241214 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:50.254444 140053337282560 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:32:50.263559 140053337282560 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:50.263844 140053337282560 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:50.264039 140053337282560 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:50.264360 140053337282560 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:50.264474 140053337282560 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:50.264557 140053337282560 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:50.264931 140053337282560 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:50.265074 140053337282560 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:50.265196 140053337282560 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:50.265306 140053337282560 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:50.265412 140053337282560 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:50.265657 140053337282560 dqn_agent.py:283] 	 seed: 1630146770263508
I0828 10:32:50.268608 140053337282560 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:50.268804 140053337282560 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:50.268919 140053337282560 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:50.269068 140053337282560 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:50.269259 140053337282560 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:50.269411 140053337282560 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:50.269589 140053337282560 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:50.269670 140053337282560 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:50.269749 140053337282560 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:50.300933 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:50.320341 140053337282560 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:32:50.320627 140053337282560 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 163.15
I0828 10:32:56.450634 140053337282560 replay_runner.py:36] Average training steps per second: 163.15
Steps executed: 283 Episode length: 96 Return: -116.171398677476263
I0828 10:32:57.679697 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.75
INFO:tensorflow:Starting iteration 1

Steps executed: 218 Episode length: 65 Return: -504.277467977453463
INFO:tensorflow:Average training steps per second: 227.31
I0828 10:33:06.487407 140053337282560 replay_runner.py:36] Average training steps per second: 227.31
I0828 10:33:06.673818 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -585.37
INFO:tensorflow:Starting iteration 2
I0828 10:33:10.932396 140053337282560 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 227.88

Steps executed: 240 Episode length: 68 Return: -135.162140416634143
I0828 10:33:15.467334 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.42
INFO:tensorflow:Starting iteration 3

Steps executed: 275 Episode length: 78 Return: -543.644416724252143
INFO:tensorflow:Average training steps per second: 225.71
I0828 10:33:24.185635 140053337282560 replay_runner.py:36] Average training steps per second: 225.71
I0828 10:33:24.406095 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -450.06
INFO:tensorflow:Starting iteration 4

Steps executed: 222 Episode length: 73 Return: -133.996256757347233
INFO:tensorflow:Average training steps per second: 230.59
I0828 10:33:32.956809 140053337282560 replay_runner.py:36] Average training steps per second: 230.59
I0828 10:33:33.097851 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.24
INFO:tensorflow:Starting iteration 5

Steps executed: 216 Episode length: 53 Return: -348.960333745752563
INFO:tensorflow:Average training steps per second: 226.72
I0828 10:33:41.955492 140053337282560 replay_runner.py:36] Average training steps per second: 226.72
I0828 10:33:42.409975 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -508.51
INFO:tensorflow:Starting iteration 6

Steps executed: 213 Episode length: 79 Return: -118.013661712194253
INFO:tensorflow:Average training steps per second: 223.81
I0828 10:33:51.245914 140053337282560 replay_runner.py:36] Average training steps per second: 223.81
I0828 10:33:51.370811 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.67
INFO:tensorflow:Starting iteration 7

Steps executed: 229 Episode length: 77 Return: -471.913713200122863
INFO:tensorflow:Average training steps per second: 234.51
I0828 10:33:59.991011 140053337282560 replay_runner.py:36] Average training steps per second: 234.51
I0828 10:34:00.192147 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.76
INFO:tensorflow:Starting iteration 8

Steps executed: 250 Episode length: 70 Return: -511.886537323915153
INFO:tensorflow:Average training steps per second: 239.05
I0828 10:34:08.709617 140053337282560 replay_runner.py:36] Average training steps per second: 239.05
I0828 10:34:08.898853 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -313.91
INFO:tensorflow:Starting iteration 9

Steps executed: 137 Episode length: 52 Return: -328.669146238106153
INFO:tensorflow:Average training steps per second: 236.18

Steps executed: 216 Episode length: 79 Return: -502.861772179119953
I0828 10:34:17.748120 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -435.04
INFO:tensorflow:Starting iteration 10

Steps executed: 204 Episode length: 68 Return: -272.250270197559363
INFO:tensorflow:Average training steps per second: 226.46
I0828 10:34:26.533282 140053337282560 replay_runner.py:36] Average training steps per second: 226.46
I0828 10:34:26.710075 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -435.74
INFO:tensorflow:Starting iteration 11

Steps executed: 159 Episode length: 79 Return: -406.843866060541563
INFO:tensorflow:Average training steps per second: 221.93

Steps executed: 242 Episode length: 83 Return: -420.097266462264943
I0828 10:34:35.846253 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -373.42
INFO:tensorflow:Starting iteration 12

Steps executed: 268 Episode length: 268 Return: -2453.1899037798917
INFO:tensorflow:Average training steps per second: 221.35
I0828 10:34:44.729891 140053337282560 replay_runner.py:36] Average training steps per second: 221.35
I0828 10:34:45.082344 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -2453.19
INFO:tensorflow:Starting iteration 13

Steps executed: 252 Episode length: 55 Return: -463.757809925009217
INFO:tensorflow:Average training steps per second: 223.80
I0828 10:34:53.944936 140053337282560 replay_runner.py:36] Average training steps per second: 223.80
I0828 10:34:54.148061 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -533.20
INFO:tensorflow:Starting iteration 14

Steps executed: 245 Episode length: 82 Return: -190.465858151964067
INFO:tensorflow:Average training steps per second: 223.24
I0828 10:35:03.038171 140053337282560 replay_runner.py:36] Average training steps per second: 223.24
I0828 10:35:03.186770 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.89
INFO:tensorflow:Starting iteration 15

Steps executed: 242 Episode length: 57 Return: -528.937385135627777
INFO:tensorflow:Average training steps per second: 220.41
I0828 10:35:12.061350 140053337282560 replay_runner.py:36] Average training steps per second: 220.41
I0828 10:35:12.247784 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -537.26
INFO:tensorflow:Starting iteration 16

Steps executed: 262 Episode length: 84 Return: -647.959297555200157
INFO:tensorflow:Average training steps per second: 222.83
I0828 10:35:21.070714 140053337282560 replay_runner.py:36] Average training steps per second: 222.83
I0828 10:35:21.308225 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -658.32
INFO:tensorflow:Starting iteration 17

Steps executed: 218 Episode length: 60 Return: -607.284992061050257
INFO:tensorflow:Average training steps per second: 221.38
I0828 10:35:30.198791 140053337282560 replay_runner.py:36] Average training steps per second: 221.38
I0828 10:35:30.380029 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -536.61
INFO:tensorflow:Starting iteration 18

Steps executed: 298 Episode length: 99 Return: -475.737111618642137
INFO:tensorflow:Average training steps per second: 218.81
I0828 10:35:39.209650 140053337282560 replay_runner.py:36] Average training steps per second: 218.81
I0828 10:35:39.496540 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -566.47
INFO:tensorflow:Starting iteration 19

Steps executed: 223 Episode length: 74 Return: -139.522257852193047
INFO:tensorflow:Average training steps per second: 225.58
I0828 10:35:48.276207 140053337282560 replay_runner.py:36] Average training steps per second: 225.58
I0828 10:35:48.424152 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.52
INFO:tensorflow:Starting iteration 20

Steps executed: 266 Episode length: 67 Return: -679.191283259970377
INFO:tensorflow:Average training steps per second: 222.44
I0828 10:35:57.256811 140053337282560 replay_runner.py:36] Average training steps per second: 222.44
I0828 10:35:57.471290 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -570.98
INFO:tensorflow:Starting iteration 21

Steps executed: 224 Episode length: 80 Return: -594.184241854996789
INFO:tensorflow:Average training steps per second: 224.37
I0828 10:36:06.273312 140053337282560 replay_runner.py:36] Average training steps per second: 224.37
I0828 10:36:06.481179 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -820.43
INFO:tensorflow:Starting iteration 22

Steps executed: 209 Episode length: 133 Return: -826.23326025518489
INFO:tensorflow:Average training steps per second: 227.98
I0828 10:36:15.205242 140053337282560 replay_runner.py:36] Average training steps per second: 227.98
I0828 10:36:15.395926 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -710.87
INFO:tensorflow:Starting iteration 23

Steps executed: 253 Episode length: 89 Return: -396.872896658762789
INFO:tensorflow:Average training steps per second: 220.36
I0828 10:36:24.216239 140053337282560 replay_runner.py:36] Average training steps per second: 220.36
I0828 10:36:24.437196 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -501.23
INFO:tensorflow:Starting iteration 24

Steps executed: 342 Episode length: 232 Return: -2020.4433620822617
INFO:tensorflow:Average training steps per second: 230.73
I0828 10:36:32.960442 140053337282560 replay_runner.py:36] Average training steps per second: 230.73
I0828 10:36:33.323488 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -1425.14
INFO:tensorflow:Starting iteration 25
I0828 10:36:37.628413 140053337282560 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 227.13
I0828 10:36:42.031574 140053337282560 replay_runner.py:36] Average training steps per second: 227.13

Steps executed: 242 Episode length: 90 Return: -704.918331837010117
INFO:tensorflow:Starting iteration 26

Steps executed: 284 Episode length: 100 Return: -532.37622754321387
INFO:tensorflow:Average training steps per second: 223.62
I0828 10:36:50.997548 140053337282560 replay_runner.py:36] Average training steps per second: 223.62
I0828 10:36:51.256317 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -616.49
INFO:tensorflow:Starting iteration 27

Steps executed: 202 Episode length: 79 Return: -509.596653299109967
INFO:tensorflow:Average training steps per second: 224.11
I0828 10:37:00.133946 140053337282560 replay_runner.py:36] Average training steps per second: 224.11
I0828 10:37:00.291511 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.45
INFO:tensorflow:Starting iteration 28

Steps executed: 293 Episode length: 215 Return: -1730.2367190912405
INFO:tensorflow:Average training steps per second: 221.36
I0828 10:37:09.071069 140053337282560 replay_runner.py:36] Average training steps per second: 221.36
I0828 10:37:09.377755 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -1044.55
INFO:tensorflow:Starting iteration 29

Steps executed: 246 Episode length: 246 Return: -1756.8806129391705
INFO:tensorflow:Average training steps per second: 236.54
I0828 10:37:17.748973 140053337282560 replay_runner.py:36] Average training steps per second: 236.54

Done fixed training!Episode length: 246 Return: -1756.8806129391705