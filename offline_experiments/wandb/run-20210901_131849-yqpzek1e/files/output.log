I0901 13:18:55.422660 140265790818304 run_experiment.py:549] Creating TrainRunner ...
I0901 13:18:55.430263 140265790818304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:18:55.430409 140265790818304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:18:55.430661 140265790818304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:18:55.430873 140265790818304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:18:55.431003 140265790818304 dqn_agent.py:275] 	 update_period: 4
I0901 13:18:55.431086 140265790818304 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:18:55.431159 140265790818304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:18:55.431260 140265790818304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:18:55.431372 140265790818304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:18:55.431468 140265790818304 dqn_agent.py:280] 	 optimizer: adam
I0901 13:18:55.431523 140265790818304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:18:55.431591 140265790818304 dqn_agent.py:283] 	 seed: 1630502335430232
I0901 13:18:55.433842 140265790818304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:18:55.433956 140265790818304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:18:55.434041 140265790818304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:18:55.434103 140265790818304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:18:55.434181 140265790818304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:18:55.434258 140265790818304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:18:55.434374 140265790818304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:18:55.434439 140265790818304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:18:55.434519 140265790818304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:18:55.460381 140265790818304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:18:55.707931 140265790818304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:18:55.717678 140265790818304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:18:55.724521 140265790818304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:18:55.724653 140265790818304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:18:55.724742 140265790818304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:18:55.724810 140265790818304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:18:55.724873 140265790818304 dqn_agent.py:275] 	 update_period: 4
I0901 13:18:55.724941 140265790818304 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:18:55.725023 140265790818304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:18:55.725133 140265790818304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:18:55.725210 140265790818304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:18:55.725289 140265790818304 dqn_agent.py:280] 	 optimizer: adam
I0901 13:18:55.725359 140265790818304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:18:55.725434 140265790818304 dqn_agent.py:283] 	 seed: 1630502335724494
I0901 13:18:55.727035 140265790818304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:18:55.727154 140265790818304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:18:55.727218 140265790818304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:18:55.727314 140265790818304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:18:55.727414 140265790818304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:18:55.727474 140265790818304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:18:55.727568 140265790818304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:18:55.727667 140265790818304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:18:55.727743 140265790818304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:18:55.750266 140265790818304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:18:55.765485 140265790818304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:18:55.765670 140265790818304 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
Steps executed: 190 Episode length: 190 Return: -60.40923409870526
INFO:tensorflow:Average training steps per second: 227.02
I0901 13:19:00.170701 140265790818304 replay_runner.py:36] Average training steps per second: 227.02

Steps executed: 325 Episode length: 135 Return: -49.027709010199686
INFO:tensorflow:Starting iteration 1

Steps executed: 319 Episode length: 129 Return: -212.52911525085693
INFO:tensorflow:Average training steps per second: 332.50
I0901 13:19:07.324122 140265790818304 replay_runner.py:36] Average training steps per second: 332.50
I0901 13:19:07.499629 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.50
INFO:tensorflow:Starting iteration 2

Steps executed: 227 Episode length: 138 Return: -378.31590699058293
INFO:tensorflow:Average training steps per second: 347.84
I0901 13:19:13.650401 140265790818304 replay_runner.py:36] Average training steps per second: 347.84
I0901 13:19:13.783732 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -429.09
INFO:tensorflow:Starting iteration 3

Steps executed: 217 Episode length: 150 Return: -31.461648883455443
INFO:tensorflow:Average training steps per second: 352.94
I0901 13:19:19.786367 140265790818304 replay_runner.py:36] Average training steps per second: 352.94
I0901 13:19:19.900083 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.81
INFO:tensorflow:Starting iteration 4

Steps executed: 336 Episode length: 199 Return: -144.62459141059367
INFO:tensorflow:Average training steps per second: 340.91
I0901 13:19:26.252517 140265790818304 replay_runner.py:36] Average training steps per second: 340.91
I0901 13:19:26.482528 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.54
INFO:tensorflow:Starting iteration 5

Steps executed: 208 Episode length: 90 Return: -252.367200483685567
INFO:tensorflow:Average training steps per second: 335.79
I0901 13:19:32.979281 140265790818304 replay_runner.py:36] Average training steps per second: 335.79
I0901 13:19:33.084585 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.64
INFO:tensorflow:Starting iteration 6

Steps executed: 201 Episode length: 80 Return: -291.168757189615237
INFO:tensorflow:Average training steps per second: 323.61
I0901 13:19:39.597057 140265790818304 replay_runner.py:36] Average training steps per second: 323.61
I0901 13:19:39.695630 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.11
INFO:tensorflow:Starting iteration 7

Steps executed: 228 Episode length: 83 Return: -128.686896806055968
INFO:tensorflow:Average training steps per second: 343.91
I0901 13:19:45.974646 140265790818304 replay_runner.py:36] Average training steps per second: 343.91
I0901 13:19:46.080321 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.00
INFO:tensorflow:Starting iteration 8

Steps executed: 408 Episode length: 231 Return: -171.31514341682967
INFO:tensorflow:Average training steps per second: 324.92
I0901 13:19:52.606768 140265790818304 replay_runner.py:36] Average training steps per second: 324.92
I0901 13:19:52.877168 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.72
INFO:tensorflow:Starting iteration 9
I0901 13:19:56.279374 140265790818304 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 328.52

Steps executed: 615 Episode length: 615 Return: -361.33245025014837
I0901 13:20:00.192312 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.33
INFO:tensorflow:Starting iteration 10

Steps executed: 377 Episode length: 377 Return: -207.77865040395204
INFO:tensorflow:Average training steps per second: 328.33
I0901 13:20:06.602706 140265790818304 replay_runner.py:36] Average training steps per second: 328.33
I0901 13:20:06.959609 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.78
INFO:tensorflow:Starting iteration 11
I0901 13:20:10.343134 140265790818304 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 330.86

Steps executed: 397 Episode length: 397 Return: -295.82211749792776
I0901 13:20:13.861145 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -295.82
INFO:tensorflow:Starting iteration 12

Steps executed: 506 Episode length: 376 Return: -215.77611888680977
INFO:tensorflow:Average training steps per second: 325.90
I0901 13:20:20.343898 140265790818304 replay_runner.py:36] Average training steps per second: 325.90
I0901 13:20:20.892402 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.65
INFO:tensorflow:Starting iteration 13

Steps executed: 59 Episode length: 59 Return: -133.9940984284082277
INFO:tensorflow:Average training steps per second: 319.00

Steps executed: 263 Episode length: 204 Return: -233.72059674407043
I0901 13:20:27.595037 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -183.86
INFO:tensorflow:Starting iteration 14

Steps executed: 312 Episode length: 134 Return: -178.83497221961187
INFO:tensorflow:Average training steps per second: 325.14
I0901 13:20:33.957322 140265790818304 replay_runner.py:36] Average training steps per second: 325.14
I0901 13:20:34.163965 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -264.52
INFO:tensorflow:Starting iteration 15

Steps executed: 234 Episode length: 234 Return: -232.36848901100397
INFO:tensorflow:Average training steps per second: 314.59
I0901 13:20:40.625649 140265790818304 replay_runner.py:36] Average training steps per second: 314.59
I0901 13:20:40.822605 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.37
INFO:tensorflow:Starting iteration 16

Steps executed: 305 Episode length: 118 Return: -117.90910020839192
INFO:tensorflow:Average training steps per second: 329.74
I0901 13:20:47.115812 140265790818304 replay_runner.py:36] Average training steps per second: 329.74
I0901 13:20:47.284052 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.65
INFO:tensorflow:Starting iteration 17
I0901 13:20:50.662936 140265790818304 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 327.00

Steps executed: 742 Episode length: 742 Return: -525.95914443128122
I0901 13:20:55.179264 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -525.96
INFO:tensorflow:Starting iteration 18
I0901 13:20:58.505932 140265790818304 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 325.03

Steps executed: 691 Episode length: 493 Return: -301.54013505799832
I0901 13:21:02.398989 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -252.54
INFO:tensorflow:Starting iteration 19

Steps executed: 244 Episode length: 84 Return: -122.989659509517572
INFO:tensorflow:Average training steps per second: 338.24
I0901 13:21:08.685430 140265790818304 replay_runner.py:36] Average training steps per second: 338.24
I0901 13:21:08.848005 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.57
INFO:tensorflow:Starting iteration 20

Steps executed: 409 Episode length: 226 Return: -106.10034846525247
INFO:tensorflow:Average training steps per second: 339.05
I0901 13:21:15.188050 140265790818304 replay_runner.py:36] Average training steps per second: 339.05
I0901 13:21:15.480349 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.89
INFO:tensorflow:Starting iteration 21
I0901 13:21:18.929336 140265790818304 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 355.07

Steps executed: 251 Episode length: 251 Return: -336.11395092993687
I0901 13:21:21.969527 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -336.11
INFO:tensorflow:Starting iteration 22
I0901 13:21:25.500810 140265790818304 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 347.25

Steps executed: 987 Episode length: 987 Return: -269.72645576068277
I0901 13:21:30.115824 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.73
INFO:tensorflow:Starting iteration 23

Steps executed: 251 Episode length: 163 Return: 27.4012407203551977
INFO:tensorflow:Average training steps per second: 329.59
I0901 13:21:36.534437 140265790818304 replay_runner.py:36] Average training steps per second: 329.59
I0901 13:21:36.688813 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -21.64
INFO:tensorflow:Starting iteration 24

Steps executed: 227 Episode length: 114 Return: -280.73650731205987
INFO:tensorflow:Average training steps per second: 332.02
I0901 13:21:43.110286 140265790818304 replay_runner.py:36] Average training steps per second: 332.02
I0901 13:21:43.235599 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -286.62
INFO:tensorflow:Starting iteration 25
I0901 13:21:46.674346 140265790818304 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 346.92
I0901 13:21:49.557135 140265790818304 replay_runner.py:36] Average training steps per second: 346.92

Steps executed: 1000 Episode length: 1000 Return: -56.40518557424082
INFO:tensorflow:Starting iteration 26
I0901 13:21:55.159507 140265790818304 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 334.64

Steps executed: 1000 Episode length: 1000 Return: -102.82121983560761
I0901 13:21:59.929250 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.82
INFO:tensorflow:Starting iteration 27

Steps executed: 248 Episode length: 112 Return: -173.5739463500319261
INFO:tensorflow:Average training steps per second: 310.50
I0901 13:22:06.448051 140265790818304 replay_runner.py:36] Average training steps per second: 310.50
I0901 13:22:06.587580 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.25
INFO:tensorflow:Starting iteration 28
I0901 13:22:09.891552 140265790818304 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 338.19

Steps executed: 1000 Episode length: 1000 Return: -70.937274593868741
I0901 13:22:15.179979 140265790818304 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.94
INFO:tensorflow:Starting iteration 29

Steps executed: 184 Episode length: 104 Return: -396.7527199116929741
INFO:tensorflow:Average training steps per second: 327.60
I0901 13:22:21.589987 140265790818304 replay_runner.py:36] Average training steps per second: 327.60


Done fixed training!Episode length: 85 Return: -113.83552186717355741