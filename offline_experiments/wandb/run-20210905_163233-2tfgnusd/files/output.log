I0905 16:32:41.000422 140439533856768 run_experiment.py:549] Creating TrainRunner ...
I0905 16:32:41.039975 140439533856768 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:32:41.040493 140439533856768 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:32:41.040748 140439533856768 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:32:41.041134 140439533856768 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:32:41.041368 140439533856768 dqn_agent.py:275] 	 update_period: 4
I0905 16:32:41.041563 140439533856768 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:32:41.042443 140439533856768 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:32:41.042842 140439533856768 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:32:41.043515 140439533856768 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:32:41.044013 140439533856768 dqn_agent.py:280] 	 optimizer: adam
I0905 16:32:41.044274 140439533856768 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:32:41.044502 140439533856768 dqn_agent.py:283] 	 seed: 1630859561039893
I0905 16:32:41.049612 140439533856768 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:32:41.050439 140439533856768 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:32:41.051095 140439533856768 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:32:41.051563 140439533856768 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:32:41.052147 140439533856768 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:32:41.052361 140439533856768 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:32:41.052556 140439533856768 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:32:41.052868 140439533856768 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:32:41.053014 140439533856768 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:32:44.033427 140439533856768 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0905 16:32:45.183863 140439533856768 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:32:45.201263 140439533856768 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:32:45.228668 140439533856768 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:32:45.229205 140439533856768 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:32:45.229665 140439533856768 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:32:45.229878 140439533856768 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:32:45.230085 140439533856768 dqn_agent.py:275] 	 update_period: 4
I0905 16:32:45.230824 140439533856768 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:32:45.231016 140439533856768 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:32:45.231355 140439533856768 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:32:45.231528 140439533856768 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:32:45.231652 140439533856768 dqn_agent.py:280] 	 optimizer: adam
I0905 16:32:45.231877 140439533856768 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:32:45.232653 140439533856768 dqn_agent.py:283] 	 seed: 1630859565228607
I0905 16:32:45.237347 140439533856768 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:32:45.237607 140439533856768 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:32:45.237768 140439533856768 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:32:45.238349 140439533856768 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:32:45.238680 140439533856768 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:32:45.238918 140439533856768 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:32:45.239136 140439533856768 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:32:45.239256 140439533856768 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:32:45.239706 140439533856768 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:32:45.289951 140439533856768 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:32:45.339168 140439533856768 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:32:45.340044 140439533856768 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 109.83
I0905 16:32:54.446317 140439533856768 replay_runner.py:36] Average training steps per second: 109.83
Steps executed: 258 Episode length: 98 Return: -366.556832385273385
I0905 16:32:56.331590 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.63
INFO:tensorflow:Starting iteration 1

Steps executed: 274 Episode length: 126 Return: -444.77733186630337
INFO:tensorflow:Average training steps per second: 160.47
I0905 16:33:07.788135 140439533856768 replay_runner.py:36] Average training steps per second: 160.47
I0905 16:33:08.134668 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -477.49
INFO:tensorflow:Starting iteration 2

Steps executed: 109 Episode length: 109 Return: -546.37934082922477
INFO:tensorflow:Average training steps per second: 168.48

Steps executed: 378 Episode length: 269 Return: -117.31032971024132
I0905 16:33:19.009760 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.84
INFO:tensorflow:Starting iteration 3

Steps executed: 131 Episode length: 131 Return: -191.33945300582639
INFO:tensorflow:Average training steps per second: 174.20

Steps executed: 1094 Episode length: 963 Return: -444.18896280288834
I0905 16:33:34.160157 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -317.76
INFO:tensorflow:Starting iteration 4
I0905 16:33:38.698060 140439533856768 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 167.01

Steps executed: 1000 Episode length: 1000 Return: -101.06767192722243
I0905 16:33:47.700177 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.07
INFO:tensorflow:Starting iteration 5
I0905 16:33:52.078968 140439533856768 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 175.52
I0905 16:33:57.777388 140439533856768 replay_runner.py:36] Average training steps per second: 175.52

Steps executed: 1000 Episode length: 1000 Return: -87.560850842188543
INFO:tensorflow:Starting iteration 6
I0905 16:34:05.937004 140439533856768 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 159.52

Steps executed: 785 Episode length: 785 Return: -345.1570604193777343
I0905 16:34:13.930849 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -345.16
INFO:tensorflow:Starting iteration 7

Steps executed: 275 Episode length: 275 Return: -978.0115118806797343
INFO:tensorflow:Average training steps per second: 161.19
I0905 16:34:25.414007 140439533856768 replay_runner.py:36] Average training steps per second: 161.19
I0905 16:34:25.858906 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -978.01
INFO:tensorflow:Starting iteration 8
I0905 16:34:30.678718 140439533856768 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 169.51

Steps executed: 601 Episode length: 601 Return: -1026.008335614941643
I0905 16:34:37.881809 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -1026.01
INFO:tensorflow:Starting iteration 9

Steps executed: 264 Episode length: 123 Return: -539.0096847001078443
INFO:tensorflow:Average training steps per second: 159.04
I0905 16:34:49.401914 140439533856768 replay_runner.py:36] Average training steps per second: 159.04
I0905 16:34:49.731502 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -340.80
INFO:tensorflow:Starting iteration 10
I0905 16:34:54.856524 140439533856768 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 149.40

Steps executed: 783 Episode length: 783 Return: -577.0858685791178443
I0905 16:35:04.394475 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -577.09
INFO:tensorflow:Starting iteration 11

Steps executed: 286 Episode length: 149 Return: -140.0382369013359843
INFO:tensorflow:Average training steps per second: 166.85
I0905 16:35:15.192756 140439533856768 replay_runner.py:36] Average training steps per second: 166.85
I0905 16:35:15.563506 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.76
INFO:tensorflow:Starting iteration 12
I0905 16:35:20.497583 140439533856768 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 158.00

Steps executed: 788 Episode length: 788 Return: 197.71860387826869843
I0905 16:35:29.097238 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: 197.72
INFO:tensorflow:Starting iteration 13
I0905 16:35:34.189589 140439533856768 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 221.62

Steps executed: 1000 Episode length: 1000 Return: -163.09816380452264
I0905 16:35:42.138363 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.10
INFO:tensorflow:Starting iteration 14
I0905 16:35:47.259669 140439533856768 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 180.56

Steps executed: 1000 Episode length: 1000 Return: -81.240431562934764
I0905 16:35:54.813302 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.24
INFO:tensorflow:Starting iteration 15
I0905 16:35:59.520694 140439533856768 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 186.24

Steps executed: 1000 Episode length: 1000 Return: -120.51149128799864
I0905 16:36:07.648989 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.51
INFO:tensorflow:Starting iteration 16
I0905 16:36:12.368713 140439533856768 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 208.98

Steps executed: 1000 Episode length: 1000 Return: -81.834909613854364
I0905 16:36:21.299995 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.83
INFO:tensorflow:Starting iteration 17
I0905 16:36:25.568691 140439533856768 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 253.47

Steps executed: 1000 Episode length: 1000 Return: -80.012142789790574
I0905 16:36:31.961852 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.01
INFO:tensorflow:Starting iteration 18
I0905 16:36:35.757387 140439533856768 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 397.73

Steps executed: 1000 Episode length: 1000 Return: -140.58737216220726
I0905 16:36:40.784811 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.59
INFO:tensorflow:Starting iteration 19
I0905 16:36:43.853942 140439533856768 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 381.60

Steps executed: 1000 Episode length: 1000 Return: -71.446843519800226
I0905 16:36:48.949988 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.45
INFO:tensorflow:Starting iteration 20
I0905 16:36:52.026129 140439533856768 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 373.26

Steps executed: 1000 Episode length: 1000 Return: -67.092758735931476
I0905 16:36:56.899062 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -67.09
INFO:tensorflow:Starting iteration 21
I0905 16:37:00.070785 140439533856768 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 391.50

Steps executed: 1000 Episode length: 1000 Return: -16.695523022751026
I0905 16:37:04.942063 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -16.70
INFO:tensorflow:Starting iteration 22
I0905 16:37:08.007285 140439533856768 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 378.02

Steps executed: 1000 Episode length: 1000 Return: -55.609525149316674
I0905 16:37:12.798222 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -55.61
INFO:tensorflow:Starting iteration 23

Steps executed: 531 Episode length: 531 Return: -56.49894161114068674
INFO:tensorflow:Average training steps per second: 382.24
I0905 16:37:18.457627 140439533856768 replay_runner.py:36] Average training steps per second: 382.24
I0905 16:37:19.043928 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -56.50
INFO:tensorflow:Starting iteration 24

Steps executed: 229 Episode length: 229 Return: -83.70340976224622674
INFO:tensorflow:Average training steps per second: 389.17
I0905 16:37:24.711256 140439533856768 replay_runner.py:36] Average training steps per second: 389.17
I0905 16:37:24.855158 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.70
INFO:tensorflow:Starting iteration 25
I0905 16:37:27.949432 140439533856768 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 393.03

Steps executed: 902 Episode length: 902 Return: -112.7097990415371674
I0905 16:37:32.437200 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.71
INFO:tensorflow:Starting iteration 26
I0905 16:37:35.552683 140439533856768 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 389.24

Steps executed: 1000 Episode length: 1000 Return: -14.900376920534006
I0905 16:37:40.192463 140439533856768 run_experiment.py:428] Average undiscounted return per evaluation episode: -14.90
INFO:tensorflow:Starting iteration 27

Steps executed: 54 Episode length: 54 Return: -80.6818565203550334006
INFO:tensorflow:Average training steps per second: 390.14
I0905 16:37:45.899566 140439533856768 replay_runner.py:36] Average training steps per second: 390.14

Steps executed: 1054 Episode length: 1000 Return: 12.9975956432865596
INFO:tensorflow:Starting iteration 28
I0905 16:37:50.824147 140439533856768 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 394.51
I0905 16:37:53.359179 140439533856768 replay_runner.py:36] Average training steps per second: 394.51

Steps executed: 1000 Episode length: 1000 Return: -23.202791856322197
INFO:tensorflow:Starting iteration 29
I0905 16:37:58.470763 140439533856768 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 396.66
I0905 16:38:00.992046 140439533856768 replay_runner.py:36] Average training steps per second: 396.66


Done fixed training! Episode length: 1000 Return: -25.420102612040456