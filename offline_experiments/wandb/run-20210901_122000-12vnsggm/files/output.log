Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0901 12:20:07.327745 139683016574976 run_experiment.py:549] Creating TrainRunner ...
I0901 12:20:07.339837 139683016574976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:20:07.340087 139683016574976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:20:07.340210 139683016574976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:20:07.340301 139683016574976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:20:07.340397 139683016574976 dqn_agent.py:275] 	 update_period: 4
I0901 12:20:07.340490 139683016574976 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:20:07.340577 139683016574976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:20:07.340663 139683016574976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:20:07.340741 139683016574976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:20:07.340826 139683016574976 dqn_agent.py:280] 	 optimizer: adam
I0901 12:20:07.340902 139683016574976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:20:07.340979 139683016574976 dqn_agent.py:283] 	 seed: 1630498807339778
I0901 12:20:07.344788 139683016574976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:20:07.345035 139683016574976 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:20:07.345152 139683016574976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:20:07.345255 139683016574976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:20:07.345417 139683016574976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:20:07.345536 139683016574976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:20:07.345693 139683016574976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:20:07.345846 139683016574976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:20:07.345973 139683016574976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:20:07.426304 139683016574976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:20:07.860999 139683016574976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:20:07.876438 139683016574976 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:20:07.886020 139683016574976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:20:07.886247 139683016574976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:20:07.886396 139683016574976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:20:07.886517 139683016574976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:20:07.886695 139683016574976 dqn_agent.py:275] 	 update_period: 4
I0901 12:20:07.886825 139683016574976 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:20:07.886957 139683016574976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:20:07.887053 139683016574976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:20:07.887159 139683016574976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:20:07.887257 139683016574976 dqn_agent.py:280] 	 optimizer: adam
I0901 12:20:07.887367 139683016574976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:20:07.887531 139683016574976 dqn_agent.py:283] 	 seed: 1630498807885972
I0901 12:20:07.890745 139683016574976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:20:07.890931 139683016574976 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:20:07.891035 139683016574976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:20:07.891177 139683016574976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:20:07.891364 139683016574976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:20:07.891500 139683016574976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:20:07.891575 139683016574976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:20:07.891809 139683016574976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:20:07.891965 139683016574976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:20:07.929752 139683016574976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:20:07.952242 139683016574976 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:20:07.952554 139683016574976 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 160.11
I0901 12:20:14.199113 139683016574976 replay_runner.py:36] Average training steps per second: 160.11
Steps executed: 319 Episode length: 158 Return: -332.70878673373347
I0901 12:20:15.570649 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.90
INFO:tensorflow:Starting iteration 1
I0901 12:20:19.912224 139683016574976 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 215.71
I0901 12:20:24.548557 139683016574976 replay_runner.py:36] Average training steps per second: 215.71

Steps executed: 242 Episode length: 141 Return: -249.41758544188517
INFO:tensorflow:Starting iteration 2
I0901 12:20:29.091877 139683016574976 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 227.77
I0901 12:20:33.482628 139683016574976 replay_runner.py:36] Average training steps per second: 227.77

Steps executed: 479 Episode length: 326 Return: -299.99825544696437
INFO:tensorflow:Starting iteration 3
I0901 12:20:38.282531 139683016574976 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 224.84

Steps executed: 705 Episode length: 705 Return: -281.19661625661877
I0901 12:20:44.658652 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.20
INFO:tensorflow:Starting iteration 4

Steps executed: 126 Episode length: 126 Return: -784.33898995386447
INFO:tensorflow:Average training steps per second: 223.01

Steps executed: 1126 Episode length: 1000 Return: -174.83232900146547
I0901 12:20:56.268242 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -479.59
INFO:tensorflow:Starting iteration 5
I0901 12:21:00.630902 139683016574976 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 229.24

Steps executed: 1000 Episode length: 1000 Return: -51.729696004066787
I0901 12:21:07.697452 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -51.73
INFO:tensorflow:Starting iteration 6

Steps executed: 267 Episode length: 267 Return: -326.5266655534337687
INFO:tensorflow:Average training steps per second: 224.59
I0901 12:21:16.414390 139683016574976 replay_runner.py:36] Average training steps per second: 224.59
I0901 12:21:16.701085 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.53
INFO:tensorflow:Starting iteration 7

Steps executed: 632 Episode length: 632 Return: -413.4543244269116687
INFO:tensorflow:Average training steps per second: 219.89
I0901 12:21:25.636662 139683016574976 replay_runner.py:36] Average training steps per second: 219.89
I0901 12:21:27.114082 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -413.45
INFO:tensorflow:Starting iteration 8

Steps executed: 610 Episode length: 610 Return: -332.3771303129629687
INFO:tensorflow:Average training steps per second: 226.96
I0901 12:21:35.755659 139683016574976 replay_runner.py:36] Average training steps per second: 226.96
I0901 12:21:36.860230 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.38
INFO:tensorflow:Starting iteration 9
I0901 12:21:41.151191 139683016574976 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 237.70
I0901 12:21:45.358704 139683016574976 replay_runner.py:36] Average training steps per second: 237.70

Steps executed: 1000 Episode length: 1000 Return: -278.27118794684567
INFO:tensorflow:Starting iteration 10

Steps executed: 477 Episode length: 477 Return: -396.5436093252017567
INFO:tensorflow:Average training steps per second: 237.42
I0901 12:21:55.908199 139683016574976 replay_runner.py:36] Average training steps per second: 237.42
I0901 12:21:56.796509 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -396.54
INFO:tensorflow:Starting iteration 11
I0901 12:22:00.924098 139683016574976 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 232.33

Steps executed: 1000 Episode length: 1000 Return: -113.09999126396527
I0901 12:22:08.296991 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.10
INFO:tensorflow:Starting iteration 12
I0901 12:22:12.452264 139683016574976 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 235.07

Steps executed: 1000 Episode length: 1000 Return: -293.10428594574546
I0901 12:22:19.253708 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.10
INFO:tensorflow:Starting iteration 13
I0901 12:22:23.638330 139683016574976 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 225.08

Steps executed: 763 Episode length: 763 Return: -344.8675071957328546
I0901 12:22:30.004248 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.87
INFO:tensorflow:Starting iteration 14

Steps executed: 329 Episode length: 173 Return: -102.6079984523537346
INFO:tensorflow:Average training steps per second: 225.15
I0901 12:22:38.777451 139683016574976 replay_runner.py:36] Average training steps per second: 225.15
I0901 12:22:39.089490 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.68
INFO:tensorflow:Starting iteration 15
I0901 12:22:43.461238 139683016574976 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 220.43

Steps executed: 1000 Episode length: 1000 Return: -167.16191653332135
I0901 12:22:52.338450 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.16
INFO:tensorflow:Starting iteration 16

Steps executed: 208 Episode length: 208 Return: -394.5565669243691135
INFO:tensorflow:Average training steps per second: 220.20
I0901 12:23:01.262839 139683016574976 replay_runner.py:36] Average training steps per second: 220.20
I0901 12:23:01.504839 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -394.56
INFO:tensorflow:Starting iteration 17
I0901 12:23:05.950334 139683016574976 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 217.07

Steps executed: 742 Episode length: 742 Return: -494.2356610657294135
I0901 12:23:12.800524 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -494.24
INFO:tensorflow:Starting iteration 18

Steps executed: 372 Episode length: 201 Return: 23.225930205803753135
INFO:tensorflow:Average training steps per second: 220.74
I0901 12:23:21.736568 139683016574976 replay_runner.py:36] Average training steps per second: 220.74
I0901 12:23:22.106646 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.91
INFO:tensorflow:Starting iteration 19

Steps executed: 171 Episode length: 51 Return: -139.73078428007562135
INFO:tensorflow:Average training steps per second: 219.94

Steps executed: 507 Episode length: 336 Return: -235.4439172170882135
I0901 12:23:31.727059 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.63
INFO:tensorflow:Starting iteration 20

Steps executed: 319 Episode length: 126 Return: -17.46317732204367735
INFO:tensorflow:Average training steps per second: 233.94
I0901 12:23:40.098748 139683016574976 replay_runner.py:36] Average training steps per second: 233.94
I0901 12:23:40.400242 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: 0.35
INFO:tensorflow:Starting iteration 21
I0901 12:23:44.842667 139683016574976 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 223.04

Steps executed: 425 Episode length: 425 Return: -243.5163838558871735
I0901 12:23:50.107968 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.52
INFO:tensorflow:Starting iteration 22

Steps executed: 212 Episode length: 212 Return: 24.098552643536294735
INFO:tensorflow:Average training steps per second: 216.73
I0901 12:23:58.709150 139683016574976 replay_runner.py:36] Average training steps per second: 216.73
I0901 12:23:58.920558 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: 24.10
INFO:tensorflow:Starting iteration 23

Steps executed: 708 Episode length: 545 Return: -464.6836277782923635
INFO:tensorflow:Average training steps per second: 215.86
I0901 12:24:07.920637 139683016574976 replay_runner.py:36] Average training steps per second: 215.86
I0901 12:24:09.290141 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.30
INFO:tensorflow:Starting iteration 24
I0901 12:24:13.683077 139683016574976 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 215.51

Steps executed: 1000 Episode length: 1000 Return: 9.62873550787851535
I0901 12:24:22.672543 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.63
INFO:tensorflow:Starting iteration 25
I0901 12:24:27.078127 139683016574976 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 223.97

Steps executed: 1000 Episode length: 1000 Return: -9.5278664880267145
I0901 12:24:36.455265 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -9.53
INFO:tensorflow:Starting iteration 26

Steps executed: 296 Episode length: 160 Return: -73.29287615795151545
INFO:tensorflow:Average training steps per second: 233.63
I0901 12:24:44.862508 139683016574976 replay_runner.py:36] Average training steps per second: 233.63
I0901 12:24:45.126811 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.56
INFO:tensorflow:Starting iteration 27
I0901 12:24:49.429499 139683016574976 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 230.20

Steps executed: 322 Episode length: 158 Return: -221.3288871867832245
I0901 12:24:54.067963 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -316.39
INFO:tensorflow:Starting iteration 28
I0901 12:24:58.291968 139683016574976 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 227.01

Steps executed: 748 Episode length: 748 Return: 103.02242667513842245
I0901 12:25:04.253875 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: 103.02
INFO:tensorflow:Starting iteration 29

Steps executed: 264 Episode length: 94 Return: -25.576342221908618245
INFO:tensorflow:Average training steps per second: 223.91
I0901 12:25:12.997585 139683016574976 replay_runner.py:36] Average training steps per second: 223.91

Done fixed training!Episode length: 94 Return: -25.576342221908618245