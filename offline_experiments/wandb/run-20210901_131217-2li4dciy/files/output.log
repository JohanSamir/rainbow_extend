Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0901 13:12:23.624978 139982171817984 run_experiment.py:549] Creating TrainRunner ...
I0901 13:12:23.631444 139982171817984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:12:23.631569 139982171817984 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:12:23.631655 139982171817984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:12:23.631744 139982171817984 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:12:23.631798 139982171817984 dqn_agent.py:275] 	 update_period: 4
I0901 13:12:23.631850 139982171817984 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:12:23.631943 139982171817984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:12:23.632027 139982171817984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:12:23.632093 139982171817984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:12:23.632146 139982171817984 dqn_agent.py:280] 	 optimizer: adam
I0901 13:12:23.632220 139982171817984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:12:23.632293 139982171817984 dqn_agent.py:283] 	 seed: 1630501943631415
I0901 13:12:23.633950 139982171817984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:12:23.634059 139982171817984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:12:23.634142 139982171817984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:12:23.634204 139982171817984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:12:23.634257 139982171817984 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:12:23.634337 139982171817984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:12:23.634398 139982171817984 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:12:23.634452 139982171817984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:12:23.634519 139982171817984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:12:23.714275 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:12:23.907628 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:12:23.915560 139982171817984 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:12:23.921998 139982171817984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:12:23.922103 139982171817984 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:12:23.922194 139982171817984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:12:23.922251 139982171817984 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:12:23.922302 139982171817984 dqn_agent.py:275] 	 update_period: 4
I0901 13:12:23.922350 139982171817984 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:12:23.922417 139982171817984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:12:23.922492 139982171817984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:12:23.922548 139982171817984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:12:23.922612 139982171817984 dqn_agent.py:280] 	 optimizer: adam
I0901 13:12:23.922690 139982171817984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:12:23.922747 139982171817984 dqn_agent.py:283] 	 seed: 1630501943921975
I0901 13:12:23.924036 139982171817984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:12:23.924134 139982171817984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:12:23.924194 139982171817984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:12:23.924247 139982171817984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:12:23.924296 139982171817984 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:12:23.924344 139982171817984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:12:23.924423 139982171817984 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:12:23.924485 139982171817984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:12:23.924548 139982171817984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:12:23.944493 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:12:23.956938 139982171817984 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:12:23.957065 139982171817984 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 237.93
I0901 13:12:28.160248 139982171817984 replay_runner.py:36] Average training steps per second: 237.93
Steps executed: 152 Episode length: 152 Return: -18.158217775526424

Steps executed: 457 Episode length: 305 Return: 188.280310423061374
INFO:tensorflow:Starting iteration 1

Steps executed: 285 Episode length: 143 Return: -350.58098895344597
INFO:tensorflow:Average training steps per second: 323.90
I0901 13:12:35.509305 139982171817984 replay_runner.py:36] Average training steps per second: 323.90
I0901 13:12:35.699207 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -369.01
INFO:tensorflow:Starting iteration 2

Steps executed: 263 Episode length: 118 Return: -50.307975384096935
INFO:tensorflow:Average training steps per second: 320.16
I0901 13:12:42.020406 139982171817984 replay_runner.py:36] Average training steps per second: 320.16
I0901 13:12:42.177702 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.52
INFO:tensorflow:Starting iteration 3

Steps executed: 242 Episode length: 116 Return: -244.64676567673808
INFO:tensorflow:Average training steps per second: 316.00
I0901 13:12:48.558207 139982171817984 replay_runner.py:36] Average training steps per second: 316.00
I0901 13:12:48.716359 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.11
INFO:tensorflow:Starting iteration 4

Steps executed: 297 Episode length: 137 Return: -202.02423742789784
INFO:tensorflow:Average training steps per second: 315.34
I0901 13:12:55.181901 139982171817984 replay_runner.py:36] Average training steps per second: 315.34
I0901 13:12:55.349449 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.68
INFO:tensorflow:Starting iteration 5

Steps executed: 236 Episode length: 108 Return: -533.17406891555744
INFO:tensorflow:Average training steps per second: 320.29
I0901 13:13:01.799260 139982171817984 replay_runner.py:36] Average training steps per second: 320.29
I0901 13:13:01.953925 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -446.89
INFO:tensorflow:Starting iteration 6

Steps executed: 257 Episode length: 84 Return: -417.291399728907554
INFO:tensorflow:Average training steps per second: 320.89
I0901 13:13:08.387764 139982171817984 replay_runner.py:36] Average training steps per second: 320.89
I0901 13:13:08.519208 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -433.54
INFO:tensorflow:Starting iteration 7

Steps executed: 251 Episode length: 126 Return: -346.45568671069874
INFO:tensorflow:Average training steps per second: 324.85
I0901 13:13:14.944691 139982171817984 replay_runner.py:36] Average training steps per second: 324.85
I0901 13:13:15.100919 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -345.70
INFO:tensorflow:Starting iteration 8
I0901 13:13:18.457364 139982171817984 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 325.01

Steps executed: 223 Episode length: 100 Return: -219.06556372208246
I0901 13:13:21.687942 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.76
INFO:tensorflow:Starting iteration 9

Steps executed: 242 Episode length: 162 Return: -219.59791442347233
INFO:tensorflow:Average training steps per second: 321.79
I0901 13:13:28.174750 139982171817984 replay_runner.py:36] Average training steps per second: 321.79
I0901 13:13:28.339466 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -430.78
INFO:tensorflow:Starting iteration 10

Steps executed: 212 Episode length: 141 Return: -812.45203304006793
INFO:tensorflow:Average training steps per second: 317.98
I0901 13:13:34.750601 139982171817984 replay_runner.py:36] Average training steps per second: 317.98
I0901 13:13:34.887735 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -745.62
INFO:tensorflow:Starting iteration 11

Steps executed: 304 Episode length: 108 Return: -19.848403053736234
INFO:tensorflow:Average training steps per second: 316.98
I0901 13:13:41.345092 139982171817984 replay_runner.py:36] Average training steps per second: 316.98
I0901 13:13:41.554192 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.86
INFO:tensorflow:Starting iteration 12

Steps executed: 234 Episode length: 77 Return: -63.8492389633093634
INFO:tensorflow:Average training steps per second: 305.25
I0901 13:13:48.131620 139982171817984 replay_runner.py:36] Average training steps per second: 305.25
I0901 13:13:48.291529 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -379.13
INFO:tensorflow:Starting iteration 13

Steps executed: 264 Episode length: 67 Return: -229.593663089648112
INFO:tensorflow:Average training steps per second: 309.05
I0901 13:13:54.839675 139982171817984 replay_runner.py:36] Average training steps per second: 309.05
I0901 13:13:55.014854 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.99
INFO:tensorflow:Starting iteration 14

Steps executed: 202 Episode length: 80 Return: -39.8576678632980682
INFO:tensorflow:Average training steps per second: 321.64
I0901 13:14:01.430350 139982171817984 replay_runner.py:36] Average training steps per second: 321.64
I0901 13:14:01.541608 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.93
INFO:tensorflow:Starting iteration 15

Steps executed: 229 Episode length: 90 Return: -135.360795882979232
INFO:tensorflow:Average training steps per second: 324.98
I0901 13:14:08.025511 139982171817984 replay_runner.py:36] Average training steps per second: 324.98
I0901 13:14:08.156169 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.12
INFO:tensorflow:Starting iteration 16

Steps executed: 257 Episode length: 75 Return: -382.917842664198242
INFO:tensorflow:Average training steps per second: 327.77
I0901 13:14:14.602094 139982171817984 replay_runner.py:36] Average training steps per second: 327.77
I0901 13:14:14.747133 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -368.54
INFO:tensorflow:Starting iteration 17

Steps executed: 215 Episode length: 61 Return: -136.494961022842182
INFO:tensorflow:Average training steps per second: 332.28
I0901 13:14:21.136775 139982171817984 replay_runner.py:36] Average training steps per second: 332.28
I0901 13:14:21.249046 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.33
INFO:tensorflow:Starting iteration 18

Steps executed: 270 Episode length: 160 Return: -50.258727368060306
INFO:tensorflow:Average training steps per second: 336.29
I0901 13:14:27.723692 139982171817984 replay_runner.py:36] Average training steps per second: 336.29
I0901 13:14:27.885611 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.91
INFO:tensorflow:Starting iteration 19

Steps executed: 296 Episode length: 108 Return: -328.23672999857854
INFO:tensorflow:Average training steps per second: 340.66
I0901 13:14:34.321080 139982171817984 replay_runner.py:36] Average training steps per second: 340.66
I0901 13:14:34.481158 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.91
INFO:tensorflow:Starting iteration 20

Steps executed: 206 Episode length: 61 Return: -136.091221930626664
INFO:tensorflow:Average training steps per second: 337.41
I0901 13:14:40.894304 139982171817984 replay_runner.py:36] Average training steps per second: 337.41
I0901 13:14:41.002953 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.42
INFO:tensorflow:Starting iteration 21

Steps executed: 193 Episode length: 100 Return: -281.55359754329936
INFO:tensorflow:Average training steps per second: 343.59
I0901 13:14:47.406816 139982171817984 replay_runner.py:36] Average training steps per second: 343.59

Steps executed: 264 Episode length: 71 Return: -231.582810090791186
INFO:tensorflow:Starting iteration 22

Steps executed: 217 Episode length: 67 Return: -403.774106991459366
INFO:tensorflow:Average training steps per second: 337.48
I0901 13:14:53.981937 139982171817984 replay_runner.py:36] Average training steps per second: 337.48
I0901 13:14:54.117614 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -431.34
INFO:tensorflow:Starting iteration 23

Steps executed: 201 Episode length: 106 Return: -713.59899485246156
INFO:tensorflow:Average training steps per second: 344.53
I0901 13:15:00.465079 139982171817984 replay_runner.py:36] Average training steps per second: 344.53
I0901 13:15:00.606303 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -603.83
INFO:tensorflow:Starting iteration 24

Steps executed: 151 Episode length: 93 Return: -223.732671343789556
INFO:tensorflow:Average training steps per second: 326.73

Steps executed: 1029 Episode length: 878 Return: -307.1695577229493
I0901 13:15:08.593870 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.12
INFO:tensorflow:Starting iteration 25

Steps executed: 299 Episode length: 121 Return: -114.17740388669691
INFO:tensorflow:Average training steps per second: 346.24
I0901 13:15:14.958530 139982171817984 replay_runner.py:36] Average training steps per second: 346.24
I0901 13:15:15.143339 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.18
INFO:tensorflow:Starting iteration 26

Steps executed: 309 Episode length: 173 Return: -307.16273199114434
INFO:tensorflow:Average training steps per second: 362.10
I0901 13:15:21.338311 139982171817984 replay_runner.py:36] Average training steps per second: 362.10
I0901 13:15:21.517328 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -350.05
INFO:tensorflow:Starting iteration 27

Steps executed: 113 Episode length: 113 Return: -158.36007306097434
INFO:tensorflow:Average training steps per second: 353.25

Steps executed: 340 Episode length: 227 Return: -394.55631326656754
I0901 13:15:27.997023 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.46
INFO:tensorflow:Starting iteration 28

Steps executed: 253 Episode length: 87 Return: -645.294041023387664
INFO:tensorflow:Average training steps per second: 347.11
I0901 13:15:34.346435 139982171817984 replay_runner.py:36] Average training steps per second: 347.11
I0901 13:15:34.509847 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -561.30
INFO:tensorflow:Starting iteration 29

Steps executed: 261 Episode length: 110 Return: -740.50557089633144
INFO:tensorflow:Average training steps per second: 357.11
I0901 13:15:40.721507 139982171817984 replay_runner.py:36] Average training steps per second: 357.11

Done fixed training!Episode length: 110 Return: -740.50557089633144