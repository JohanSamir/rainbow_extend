I0901 23:43:48.809201 140413705484288 run_experiment.py:549] Creating TrainRunner ...
I0901 23:43:48.821993 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:43:48.822231 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:43:48.822334 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:43:48.822445 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:43:48.822534 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0901 23:43:48.822673 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:43:48.822846 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:43:48.822978 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:43:48.823083 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:43:48.823197 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0901 23:43:48.823338 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:43:48.823467 140413705484288 dqn_agent.py:283] 	 seed: 1630539828821920
I0901 23:43:48.826826 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:43:48.827113 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:43:48.827283 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:43:48.827435 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:43:48.827537 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:43:48.827688 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:43:48.827831 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:43:48.827954 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:43:48.828086 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 23:43:50.417396 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:43:50.809624 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:43:50.824885 140413705484288 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:43:50.838585 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:43:50.838814 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:43:50.838917 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:43:50.839040 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:43:50.839137 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0901 23:43:50.839192 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:43:50.839343 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:43:50.839428 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:43:50.839494 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:43:50.839554 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0901 23:43:50.839605 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:43:50.839685 140413705484288 dqn_agent.py:283] 	 seed: 1630539830838530
I0901 23:43:50.842245 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:43:50.842496 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:43:50.842719 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:43:50.842905 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:43:50.843065 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:43:50.843294 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:43:50.843429 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:43:50.843592 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:43:50.843732 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:43:50.878697 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:43:50.903305 140413705484288 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:43:50.903592 140413705484288 replay_runner.py:41] Starting iteration 0
Steps executed: 228 Episode length: 126 Return: -318.5662603547065
INFO:tensorflow:Average training steps per second: 166.11
I0901 23:43:56.923829 140413705484288 replay_runner.py:36] Average training steps per second: 166.11
I0901 23:43:58.073343 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.89
INFO:tensorflow:Starting iteration 1
I0901 23:44:02.336444 140413705484288 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 232.10

Steps executed: 301 Episode length: 152 Return: -334.99544188536305
I0901 23:44:06.877167 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.67
INFO:tensorflow:Starting iteration 2

Steps executed: 379 Episode length: 379 Return: 239.482998920024875
INFO:tensorflow:Average training steps per second: 227.61
I0901 23:44:15.374817 140413705484288 replay_runner.py:36] Average training steps per second: 227.61
I0901 23:44:15.886386 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: 239.48
INFO:tensorflow:Starting iteration 3
I0901 23:44:20.166384 140413705484288 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 238.19

Steps executed: 1000 Episode length: 1000 Return: -112.09510654403817
I0901 23:44:27.210998 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.10
INFO:tensorflow:Starting iteration 4
I0901 23:44:31.366000 140413705484288 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 245.02

Steps executed: 1000 Episode length: 1000 Return: -104.78043782361048
I0901 23:44:38.496453 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.78
INFO:tensorflow:Starting iteration 5
I0901 23:44:42.632750 140413705484288 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 232.88

Steps executed: 1000 Episode length: 1000 Return: -152.71404152917182
I0901 23:44:50.631113 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.71
INFO:tensorflow:Starting iteration 6
I0901 23:44:54.929525 140413705484288 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 229.34

Steps executed: 1000 Episode length: 1000 Return: -188.13591159404905
I0901 23:45:01.742440 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.14
INFO:tensorflow:Starting iteration 7
I0901 23:45:06.027959 140413705484288 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 233.53

Steps executed: 824 Episode length: 824 Return: -481.9349507040718905
I0901 23:45:12.704331 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -481.93
INFO:tensorflow:Starting iteration 8
I0901 23:45:17.032819 140413705484288 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 224.25

Steps executed: 1000 Episode length: 1000 Return: -143.63248037170177
I0901 23:45:24.488603 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.63
INFO:tensorflow:Starting iteration 9

Steps executed: 458 Episode length: 458 Return: -499.1672221887393477
INFO:tensorflow:Average training steps per second: 229.76
I0901 23:45:33.128762 140413705484288 replay_runner.py:36] Average training steps per second: 229.76
I0901 23:45:33.957639 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -499.17
INFO:tensorflow:Starting iteration 10
I0901 23:45:38.327610 140413705484288 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 226.64

Steps executed: 1000 Episode length: 1000 Return: -113.13097314142931
I0901 23:45:46.019216 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.13
INFO:tensorflow:Starting iteration 11
I0901 23:45:50.405899 140413705484288 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 228.10

Steps executed: 1000 Episode length: 1000 Return: -168.75175547104442
I0901 23:45:58.062862 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.75
INFO:tensorflow:Starting iteration 12
I0901 23:46:02.386382 140413705484288 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 228.17

Steps executed: 1000 Episode length: 1000 Return: -65.516533541175532
I0901 23:46:10.493924 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.52
INFO:tensorflow:Starting iteration 13
I0901 23:46:14.820019 140413705484288 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 232.07

Steps executed: 1000 Episode length: 1000 Return: -229.32675420882725
I0901 23:46:21.757403 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.33
INFO:tensorflow:Starting iteration 14
I0901 23:46:26.075855 140413705484288 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 234.26

Steps executed: 1000 Episode length: 1000 Return: -63.468468853757095
I0901 23:46:33.060620 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -63.47
INFO:tensorflow:Starting iteration 15

Steps executed: 286 Episode length: 140 Return: -176.2691529515605595
INFO:tensorflow:Average training steps per second: 232.05
I0901 23:46:41.641799 140413705484288 replay_runner.py:36] Average training steps per second: 232.05
I0901 23:46:41.880717 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.20
INFO:tensorflow:Starting iteration 16
I0901 23:46:46.295323 140413705484288 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 232.07

Steps executed: 749 Episode length: 749 Return: -289.3958950528607495
I0901 23:46:51.931443 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.40
INFO:tensorflow:Starting iteration 17

Steps executed: 394 Episode length: 230 Return: -196.9389190438466595
INFO:tensorflow:Average training steps per second: 235.26
I0901 23:47:00.462844 140413705484288 replay_runner.py:36] Average training steps per second: 235.26
I0901 23:47:00.858072 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.16
INFO:tensorflow:Starting iteration 18

Steps executed: 401 Episode length: 401 Return: -340.4314290278640695
INFO:tensorflow:Average training steps per second: 236.28
I0901 23:47:09.433706 140413705484288 replay_runner.py:36] Average training steps per second: 236.28
I0901 23:47:10.035585 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -340.43
INFO:tensorflow:Starting iteration 19

Steps executed: 124 Episode length: 124 Return: -129.3749132452157795
INFO:tensorflow:Average training steps per second: 234.65
I0901 23:47:18.620760 140413705484288 replay_runner.py:36] Average training steps per second: 234.65

Steps executed: 372 Episode length: 248 Return: -115.4663239306029795
INFO:tensorflow:Starting iteration 20

Steps executed: 290 Episode length: 125 Return: -288.8954663834988995
INFO:tensorflow:Average training steps per second: 230.92
I0901 23:47:27.648797 140413705484288 replay_runner.py:36] Average training steps per second: 230.92
I0901 23:47:27.897361 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.95
INFO:tensorflow:Starting iteration 21

Steps executed: 206 Episode length: 93 Return: -119.83787309200154195
INFO:tensorflow:Average training steps per second: 249.34
I0901 23:47:36.171682 140413705484288 replay_runner.py:36] Average training steps per second: 249.34
I0901 23:47:36.332704 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.44
INFO:tensorflow:Starting iteration 22

Steps executed: 218 Episode length: 68 Return: -148.78015889817303895
INFO:tensorflow:Average training steps per second: 248.32
I0901 23:47:44.726676 140413705484288 replay_runner.py:36] Average training steps per second: 248.32
I0901 23:47:44.912500 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.72
INFO:tensorflow:Starting iteration 23

Steps executed: 457 Episode length: 279 Return: -72.64270656975825895
INFO:tensorflow:Average training steps per second: 240.73
I0901 23:47:53.347025 140413705484288 replay_runner.py:36] Average training steps per second: 240.73
I0901 23:47:53.873130 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.58
INFO:tensorflow:Starting iteration 24
I0901 23:47:58.190390 140413705484288 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 235.88

Steps executed: 1000 Episode length: 1000 Return: 99.7244599471598495
I0901 23:48:06.005440 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: 99.72
INFO:tensorflow:Starting iteration 25
I0901 23:48:10.365057 140413705484288 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 226.92

Steps executed: 510 Episode length: 510 Return: -148.7942342736945495
I0901 23:48:15.784157 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.79
INFO:tensorflow:Starting iteration 26

Steps executed: 140 Episode length: 140 Return: -165.3404706347096295
INFO:tensorflow:Average training steps per second: 226.06

Steps executed: 1140 Episode length: 1000 Return: -3.9744737139358385
I0901 23:48:27.241111 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.66
INFO:tensorflow:Starting iteration 27
I0901 23:48:31.607928 140413705484288 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 230.24

Steps executed: 1000 Episode length: 1000 Return: -27.700949555127085
I0901 23:48:39.907370 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -27.70
INFO:tensorflow:Starting iteration 28
I0901 23:48:44.271013 140413705484288 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 224.64

Steps executed: 1000 Episode length: 1000 Return: 3.20337736708296185
I0901 23:48:52.779067 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: 3.20
INFO:tensorflow:Starting iteration 29

Steps executed: 164 Episode length: 164 Return: -231.0168262183119385
INFO:tensorflow:Average training steps per second: 227.52

Steps executed: 1164 Episode length: 1000 Return: 36.5317277530068055

Done fixed training! Episode length: 1000 Return: 36.5317277530068055