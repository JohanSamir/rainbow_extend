Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0901 12:50:44.059377 140536266098688 run_experiment.py:549] Creating TrainRunner ...
I0901 12:50:44.071642 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:50:44.071959 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:50:44.072076 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:50:44.072314 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:50:44.072448 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 12:50:44.072650 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:50:44.072826 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:50:44.072983 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:50:44.073170 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:50:44.073285 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 12:50:44.073404 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:50:44.073487 140536266098688 dqn_agent.py:283] 	 seed: 1630500644071551
I0901 12:50:44.076756 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:50:44.076941 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:50:44.077044 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:50:44.077130 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:50:44.077214 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:50:44.077292 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:50:44.077367 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:50:44.077496 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:50:44.077620 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:50:44.121716 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:44.520642 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:44.536052 140536266098688 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:50:44.567985 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:50:44.568383 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:50:44.568568 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:50:44.568699 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:50:44.568814 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 12:50:44.568959 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:50:44.569111 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:50:44.569231 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:50:44.569361 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:50:44.569487 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 12:50:44.569709 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:50:44.569864 140536266098688 dqn_agent.py:283] 	 seed: 1630500644567900
I0901 12:50:44.572916 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:50:44.573156 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:50:44.573338 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:50:44.573491 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:50:44.573611 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:50:44.573763 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:50:44.574011 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:50:44.574162 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:50:44.574307 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:50:44.615092 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:50:44.640884 140536266098688 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:50:44.641178 140536266098688 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 154.21
I0901 12:50:51.126060 140536266098688 replay_runner.py:36] Average training steps per second: 154.21
Steps executed: 212 Episode length: 212 Return: -334.22324578545675
I0901 12:50:52.390258 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -334.22
INFO:tensorflow:Starting iteration 1

Steps executed: 142 Episode length: 142 Return: -79.778992932748575
INFO:tensorflow:Average training steps per second: 217.73

Steps executed: 334 Episode length: 192 Return: -416.49699601724885
I0901 12:51:01.729999 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.14
INFO:tensorflow:Starting iteration 2

Steps executed: 334 Episode length: 179 Return: -211.42539879962789
INFO:tensorflow:Average training steps per second: 217.84
I0901 12:51:10.683671 140536266098688 replay_runner.py:36] Average training steps per second: 217.84
I0901 12:51:11.004546 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.95
INFO:tensorflow:Starting iteration 3

Steps executed: 272 Episode length: 99 Return: -712.511261444935169
INFO:tensorflow:Average training steps per second: 221.26
I0901 12:51:19.941570 140536266098688 replay_runner.py:36] Average training steps per second: 221.26
I0901 12:51:20.188065 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -396.79
INFO:tensorflow:Starting iteration 4

Steps executed: 201 Episode length: 94 Return: -93.5464049559702257
INFO:tensorflow:Average training steps per second: 220.65
I0901 12:51:29.079276 140536266098688 replay_runner.py:36] Average training steps per second: 220.65
I0901 12:51:29.241858 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.38
INFO:tensorflow:Starting iteration 5

Steps executed: 239 Episode length: 109 Return: -232.95377737900048
INFO:tensorflow:Average training steps per second: 225.42
I0901 12:51:38.118327 140536266098688 replay_runner.py:36] Average training steps per second: 225.42
I0901 12:51:38.317428 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.53
INFO:tensorflow:Starting iteration 6

Steps executed: 354 Episode length: 171 Return: -251.94773119687148
INFO:tensorflow:Average training steps per second: 218.55
I0901 12:51:47.340141 140536266098688 replay_runner.py:36] Average training steps per second: 218.55
I0901 12:51:47.690553 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.49
INFO:tensorflow:Starting iteration 7

Steps executed: 270 Episode length: 105 Return: -707.83081824991468
INFO:tensorflow:Average training steps per second: 219.99
I0901 12:51:56.468557 140536266098688 replay_runner.py:36] Average training steps per second: 219.99
I0901 12:51:56.741080 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -589.43
INFO:tensorflow:Starting iteration 8

Steps executed: 235 Episode length: 137 Return: -654.83285394123468
INFO:tensorflow:Average training steps per second: 221.83
I0901 12:52:05.598548 140536266098688 replay_runner.py:36] Average training steps per second: 221.83
I0901 12:52:05.847366 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -601.19
INFO:tensorflow:Starting iteration 9

Steps executed: 200 Episode length: 78 Return: -315.546554211548638
INFO:tensorflow:Average training steps per second: 221.39
I0901 12:52:14.799748 140536266098688 replay_runner.py:36] Average training steps per second: 221.39
I0901 12:52:14.968195 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -321.38
INFO:tensorflow:Starting iteration 10

Steps executed: 266 Episode length: 136 Return: 20.2514705189802988
INFO:tensorflow:Average training steps per second: 229.03
I0901 12:52:23.746822 140536266098688 replay_runner.py:36] Average training steps per second: 229.03
I0901 12:52:23.968275 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: 26.89
INFO:tensorflow:Starting iteration 11

Steps executed: 219 Episode length: 156 Return: -174.78496874232607
INFO:tensorflow:Average training steps per second: 235.45
I0901 12:52:32.627956 140536266098688 replay_runner.py:36] Average training steps per second: 235.45
I0901 12:52:32.816999 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.83
INFO:tensorflow:Starting iteration 12

Steps executed: 223 Episode length: 79 Return: -234.253492918424947
INFO:tensorflow:Average training steps per second: 223.10
I0901 12:52:41.476380 140536266098688 replay_runner.py:36] Average training steps per second: 223.10
I0901 12:52:41.637801 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.43
INFO:tensorflow:Starting iteration 13

Steps executed: 255 Episode length: 64 Return: -185.924013324519857
INFO:tensorflow:Average training steps per second: 221.24
I0901 12:52:50.498908 140536266098688 replay_runner.py:36] Average training steps per second: 221.24
I0901 12:52:50.683195 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.33
INFO:tensorflow:Starting iteration 14

Steps executed: 321 Episode length: 170 Return: -217.94933189627017
INFO:tensorflow:Average training steps per second: 219.90
I0901 12:52:59.431469 140536266098688 replay_runner.py:36] Average training steps per second: 219.90
I0901 12:52:59.694081 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.39
INFO:tensorflow:Starting iteration 15
I0901 12:53:03.855998 140536266098688 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 224.50

Steps executed: 206 Episode length: 87 Return: -472.884439460289977
I0901 12:53:08.460428 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -250.07
INFO:tensorflow:Starting iteration 16

Steps executed: 254 Episode length: 61 Return: -135.573793427695737
INFO:tensorflow:Average training steps per second: 221.40
I0901 12:53:17.396536 140536266098688 replay_runner.py:36] Average training steps per second: 221.40
I0901 12:53:17.593916 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.51
INFO:tensorflow:Starting iteration 17

Steps executed: 204 Episode length: 79 Return: -134.051115926157057
INFO:tensorflow:Average training steps per second: 218.18
I0901 12:53:26.595669 140536266098688 replay_runner.py:36] Average training steps per second: 218.18
I0901 12:53:26.736116 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.68
INFO:tensorflow:Starting iteration 18

Steps executed: 205 Episode length: 89 Return: -374.397932366642357
INFO:tensorflow:Average training steps per second: 217.96
I0901 12:53:35.766279 140536266098688 replay_runner.py:36] Average training steps per second: 217.96
I0901 12:53:35.930662 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.85
INFO:tensorflow:Starting iteration 19

Steps executed: 287 Episode length: 127 Return: -318.06371188304586
INFO:tensorflow:Average training steps per second: 225.80
I0901 12:53:44.708425 140536266098688 replay_runner.py:36] Average training steps per second: 225.80
I0901 12:53:44.936563 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.18
INFO:tensorflow:Starting iteration 20

Steps executed: 68 Episode length: 68 Return: -110.8867206204676686
INFO:tensorflow:Average training steps per second: 218.70
I0901 12:53:53.912009 140536266098688 replay_runner.py:36] Average training steps per second: 218.70

Steps executed: 240 Episode length: 61 Return: -148.232077519817386
INFO:tensorflow:Starting iteration 21

Steps executed: 220 Episode length: 80 Return: -725.390232613069366
INFO:tensorflow:Average training steps per second: 213.23
I0901 12:54:03.146766 140536266098688 replay_runner.py:36] Average training steps per second: 213.23
I0901 12:54:03.350177 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -488.01
INFO:tensorflow:Starting iteration 22

Steps executed: 211 Episode length: 74 Return: -278.683830551305566
INFO:tensorflow:Average training steps per second: 220.99
I0901 12:54:12.243347 140536266098688 replay_runner.py:36] Average training steps per second: 220.99
I0901 12:54:12.400043 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.24
INFO:tensorflow:Starting iteration 23

Steps executed: 248 Episode length: 59 Return: -155.018375030608326
INFO:tensorflow:Average training steps per second: 222.15
I0901 12:54:21.275508 140536266098688 replay_runner.py:36] Average training steps per second: 222.15
I0901 12:54:21.459873 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.23
INFO:tensorflow:Starting iteration 24
I0901 12:54:25.737222 140536266098688 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 225.24

Steps executed: 274 Episode length: 132 Return: -413.25754372210796
I0901 12:54:30.406939 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -275.51
INFO:tensorflow:Starting iteration 25

Steps executed: 249 Episode length: 53 Return: -427.787124119034566
INFO:tensorflow:Average training steps per second: 216.18
I0901 12:54:39.494866 140536266098688 replay_runner.py:36] Average training steps per second: 216.18
I0901 12:54:39.716022 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -536.92
INFO:tensorflow:Starting iteration 26

Steps executed: 201 Episode length: 78 Return: -501.239480588856746
INFO:tensorflow:Average training steps per second: 219.97
I0901 12:54:48.530523 140536266098688 replay_runner.py:36] Average training steps per second: 219.97
I0901 12:54:48.720411 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -535.01
INFO:tensorflow:Starting iteration 27

Steps executed: 252 Episode length: 68 Return: -689.915385701231556
INFO:tensorflow:Average training steps per second: 221.91
I0901 12:54:57.700717 140536266098688 replay_runner.py:36] Average training steps per second: 221.91
I0901 12:54:57.941846 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -532.52
INFO:tensorflow:Starting iteration 28

Steps executed: 223 Episode length: 90 Return: -174.373876774965086
INFO:tensorflow:Average training steps per second: 217.75
I0901 12:55:06.968505 140536266098688 replay_runner.py:36] Average training steps per second: 217.75
I0901 12:55:07.126979 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.84
INFO:tensorflow:Starting iteration 29
I0901 12:55:11.527106 140536266098688 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 219.73

Steps executed: 550 Episode length: 550 Return: -892.59709272650646

Done fixed training!Episode length: 550 Return: -892.59709272650646