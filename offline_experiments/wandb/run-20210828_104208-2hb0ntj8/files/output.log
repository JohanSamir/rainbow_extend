Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0828 10:42:14.766762 139821415028736 run_experiment.py:549] Creating TrainRunner ...
I0828 10:42:14.776875 139821415028736 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:14.777382 139821415028736 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:14.777569 139821415028736 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:14.777666 139821415028736 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:14.777789 139821415028736 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:14.777919 139821415028736 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:14.778040 139821415028736 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:14.778134 139821415028736 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:14.778206 139821415028736 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:14.778277 139821415028736 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:14.778501 139821415028736 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:14.778658 139821415028736 dqn_agent.py:283] 	 seed: 1630147334776806
I0828 10:42:14.781421 139821415028736 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:14.781610 139821415028736 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:14.781788 139821415028736 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:14.781888 139821415028736 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:14.781976 139821415028736 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:14.782090 139821415028736 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:14.782257 139821415028736 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:14.782469 139821415028736 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:14.782613 139821415028736 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:14.817680 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:15.170000 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:15.183354 139821415028736 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:42:15.191200 139821415028736 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:15.191481 139821415028736 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:15.191636 139821415028736 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:15.191755 139821415028736 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:15.191895 139821415028736 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:15.191987 139821415028736 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:15.192102 139821415028736 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:15.192236 139821415028736 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:15.192405 139821415028736 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:15.192658 139821415028736 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:15.192770 139821415028736 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:15.192901 139821415028736 dqn_agent.py:283] 	 seed: 1630147335191140
I0828 10:42:15.195946 139821415028736 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:15.196101 139821415028736 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:15.196224 139821415028736 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:15.196327 139821415028736 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:15.196540 139821415028736 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:15.196637 139821415028736 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:15.196765 139821415028736 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:15.196974 139821415028736 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:15.197145 139821415028736 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:15.225939 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:15.248813 139821415028736 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:42:15.249140 139821415028736 replay_runner.py:41] Starting iteration 0
Steps executed: 376 Episode length: 180 Return: -406.36784725498427
INFO:tensorflow:Average training steps per second: 175.16
I0828 10:42:20.958891 139821415028736 replay_runner.py:36] Average training steps per second: 175.16
I0828 10:42:22.277995 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.48
INFO:tensorflow:Starting iteration 1

Steps executed: 218 Episode length: 145 Return: -744.73668314283867
INFO:tensorflow:Average training steps per second: 241.85
I0828 10:42:30.654920 139821415028736 replay_runner.py:36] Average training steps per second: 241.85
I0828 10:42:30.838396 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -607.65
INFO:tensorflow:Starting iteration 2

Steps executed: 234 Episode length: 234 Return: -284.57680850933867
INFO:tensorflow:Average training steps per second: 233.75
I0828 10:42:39.412826 139821415028736 replay_runner.py:36] Average training steps per second: 233.75
I0828 10:42:39.657877 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.58
INFO:tensorflow:Starting iteration 3
I0828 10:42:43.915511 139821415028736 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 223.54

Steps executed: 851 Episode length: 851 Return: -584.61700112216847
I0828 10:42:50.942106 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -584.62
INFO:tensorflow:Starting iteration 4
I0828 10:42:55.433718 139821415028736 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 230.36

Steps executed: 1000 Episode length: 1000 Return: -344.99374436470106
I0828 10:43:04.088678 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.99
INFO:tensorflow:Starting iteration 5
I0828 10:43:08.220333 139821415028736 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 236.33

Steps executed: 242 Episode length: 242 Return: -907.0208386853967106
I0828 10:43:12.730911 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -907.02
INFO:tensorflow:Starting iteration 6
I0828 10:43:16.961776 139821415028736 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 239.41

Steps executed: 831 Episode length: 831 Return: -645.9246197583602106
I0828 10:43:22.889448 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -645.92
INFO:tensorflow:Starting iteration 7

Steps executed: 262 Episode length: 262 Return: -213.5180114158121106
INFO:tensorflow:Average training steps per second: 235.83
I0828 10:43:31.317278 139821415028736 replay_runner.py:36] Average training steps per second: 235.83
I0828 10:43:31.605910 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.52
INFO:tensorflow:Starting iteration 8
I0828 10:43:35.840879 139821415028736 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 227.79

Steps executed: 1000 Episode length: 1000 Return: -335.12904255663443
I0828 10:43:42.552127 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -335.13
INFO:tensorflow:Starting iteration 9

Steps executed: 411 Episode length: 316 Return: -380.2540517448657443
INFO:tensorflow:Average training steps per second: 230.13
I0828 10:43:51.317426 139821415028736 replay_runner.py:36] Average training steps per second: 230.13
I0828 10:43:51.853149 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.97
INFO:tensorflow:Starting iteration 10
I0828 10:43:56.139670 139821415028736 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 229.42

Steps executed: 419 Episode length: 419 Return: -370.6415141129727443
I0828 10:44:01.032636 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -370.64
INFO:tensorflow:Starting iteration 11

Steps executed: 314 Episode length: 314 Return: -264.8016866248525543
INFO:tensorflow:Average training steps per second: 223.44
I0828 10:44:09.836245 139821415028736 replay_runner.py:36] Average training steps per second: 223.44
I0828 10:44:10.248135 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -264.80
INFO:tensorflow:Starting iteration 12
I0828 10:44:14.529994 139821415028736 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 226.73

Steps executed: 626 Episode length: 439 Return: -486.1910556232937543
I0828 10:44:19.861131 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -378.12
INFO:tensorflow:Starting iteration 13

Steps executed: 89 Episode length: 89 Return: -314.094742330556137543
INFO:tensorflow:Average training steps per second: 225.73
I0828 10:44:28.676835 139821415028736 replay_runner.py:36] Average training steps per second: 225.73

Steps executed: 352 Episode length: 263 Return: -73.97392320787256543
INFO:tensorflow:Starting iteration 14

Steps executed: 376 Episode length: 214 Return: -865.2270904400513543
INFO:tensorflow:Average training steps per second: 230.16
I0828 10:44:37.712804 139821415028736 replay_runner.py:36] Average training steps per second: 230.16
I0828 10:44:38.097753 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -722.46
INFO:tensorflow:Starting iteration 15
I0828 10:44:42.378959 139821415028736 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 228.99

Steps executed: 829 Episode length: 674 Return: -107.2070235879795543
I0828 10:44:48.362547 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.04
INFO:tensorflow:Starting iteration 16
I0828 10:44:52.639152 139821415028736 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 236.95

Steps executed: 1000 Episode length: 1000 Return: -94.537873642313463
I0828 10:45:02.274011 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.54
INFO:tensorflow:Starting iteration 17
I0828 10:45:06.641950 139821415028736 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 246.83

Steps executed: 383 Episode length: 383 Return: 159.25241728438172463
I0828 10:45:11.306529 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: 159.25
INFO:tensorflow:Starting iteration 18

Steps executed: 243 Episode length: 126 Return: -48.21765859448249463
INFO:tensorflow:Average training steps per second: 254.35
I0828 10:45:19.427940 139821415028736 replay_runner.py:36] Average training steps per second: 254.35
I0828 10:45:19.638286 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.53
INFO:tensorflow:Starting iteration 19

Steps executed: 285 Episode length: 285 Return: -114.1397673419488463
INFO:tensorflow:Average training steps per second: 260.36
I0828 10:45:27.623831 139821415028736 replay_runner.py:36] Average training steps per second: 260.36
I0828 10:45:27.958039 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.14
INFO:tensorflow:Starting iteration 20

Steps executed: 478 Episode length: 478 Return: -141.8161121240954463
INFO:tensorflow:Average training steps per second: 271.53
I0828 10:45:35.656925 139821415028736 replay_runner.py:36] Average training steps per second: 271.53
I0828 10:45:36.256796 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.82
INFO:tensorflow:Starting iteration 21

Steps executed: 204 Episode length: 137 Return: -600.8370381026868463
INFO:tensorflow:Average training steps per second: 266.48
I0828 10:45:44.030368 139821415028736 replay_runner.py:36] Average training steps per second: 266.48
I0828 10:45:44.186513 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.21
INFO:tensorflow:Starting iteration 22

Steps executed: 229 Episode length: 71 Return: -88.948285916549248463
INFO:tensorflow:Average training steps per second: 282.20
I0828 10:45:51.724988 139821415028736 replay_runner.py:36] Average training steps per second: 282.20
I0828 10:45:51.869066 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -282.83
INFO:tensorflow:Starting iteration 23

Steps executed: 296 Episode length: 117 Return: -235.8079273653708363
INFO:tensorflow:Average training steps per second: 287.28
I0828 10:45:59.371137 139821415028736 replay_runner.py:36] Average training steps per second: 287.28
I0828 10:45:59.571521 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.63
INFO:tensorflow:Starting iteration 24

Steps executed: 289 Episode length: 146 Return: -95.48097377218537663
INFO:tensorflow:Average training steps per second: 302.40
I0828 10:46:06.823938 139821415028736 replay_runner.py:36] Average training steps per second: 302.40
I0828 10:46:07.003533 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.20
INFO:tensorflow:Starting iteration 25

Steps executed: 274 Episode length: 274 Return: 202.56323903059376663
INFO:tensorflow:Average training steps per second: 310.98
I0828 10:46:14.074328 139821415028736 replay_runner.py:36] Average training steps per second: 310.98
I0828 10:46:14.280403 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: 202.56
INFO:tensorflow:Starting iteration 26

Steps executed: 304 Episode length: 110 Return: -541.1462245898517663
INFO:tensorflow:Average training steps per second: 350.56
I0828 10:46:20.835961 139821415028736 replay_runner.py:36] Average training steps per second: 350.56
I0828 10:46:20.978810 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.87
INFO:tensorflow:Starting iteration 27
I0828 10:46:24.512403 139821415028736 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 356.03

Steps executed: 247 Episode length: 80 Return: -335.33316548750677663
I0828 10:46:27.434374 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -366.08
INFO:tensorflow:Starting iteration 28

Steps executed: 266 Episode length: 110 Return: -241.8741918987250363
INFO:tensorflow:Average training steps per second: 356.59
I0828 10:46:33.739833 139821415028736 replay_runner.py:36] Average training steps per second: 356.59
I0828 10:46:33.864459 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.14
INFO:tensorflow:Starting iteration 29

Steps executed: 266 Episode length: 92 Return: -99.907448415588564363
INFO:tensorflow:Average training steps per second: 359.91
I0828 10:46:40.066273 139821415028736 replay_runner.py:36] Average training steps per second: 359.91

Done fixed training!Episode length: 92 Return: -99.907448415588564363