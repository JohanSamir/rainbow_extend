Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0902 00:27:22.312646 139752435963904 run_experiment.py:549] Creating TrainRunner ...
I0902 00:27:22.319954 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:27:22.320062 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:27:22.320133 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:27:22.320196 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:27:22.320256 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0902 00:27:22.320307 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:27:22.320379 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:27:22.320429 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:27:22.320477 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:27:22.320562 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0902 00:27:22.320612 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:27:22.320680 139752435963904 dqn_agent.py:283] 	 seed: 1630542442319927
I0902 00:27:22.323461 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:27:22.323606 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:27:22.323714 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:27:22.323838 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:27:22.323915 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:27:22.323997 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:27:22.324090 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:27:22.324151 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:27:22.324215 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:27:22.348688 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:27:22.590490 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:27:22.599594 139752435963904 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:27:22.605500 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:27:22.605616 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:27:22.605690 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:27:22.605757 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:27:22.605813 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0902 00:27:22.605868 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:27:22.605944 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:27:22.606001 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:27:22.606085 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:27:22.606151 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0902 00:27:22.606248 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:27:22.606303 139752435963904 dqn_agent.py:283] 	 seed: 1630542442605476
I0902 00:27:22.607774 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:27:22.607885 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:27:22.607956 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:27:22.608068 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:27:22.608130 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:27:22.608226 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:27:22.608368 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:27:22.608461 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:27:22.608533 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:27:22.630148 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:27:22.646457 139752435963904 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:27:22.646609 139752435963904 replay_runner.py:41] Starting iteration 0
Steps executed: 277 Episode length: 138 Return: -384.6858236396111
INFO:tensorflow:Average training steps per second: 255.35
I0902 00:27:26.563042 139752435963904 replay_runner.py:36] Average training steps per second: 255.35
I0902 00:27:27.329040 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -368.05
INFO:tensorflow:Starting iteration 1

Steps executed: 264 Episode length: 163 Return: -336.03090948050897
INFO:tensorflow:Average training steps per second: 335.24
I0902 00:27:33.595930 139752435963904 replay_runner.py:36] Average training steps per second: 335.24
I0902 00:27:33.753443 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -386.63
INFO:tensorflow:Starting iteration 2

Steps executed: 235 Episode length: 118 Return: -267.00849634348823
INFO:tensorflow:Average training steps per second: 332.55
I0902 00:27:40.122922 139752435963904 replay_runner.py:36] Average training steps per second: 332.55
I0902 00:27:40.256563 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.65
INFO:tensorflow:Starting iteration 3

Steps executed: 401 Episode length: 401 Return: -108.24272197862916
INFO:tensorflow:Average training steps per second: 351.50
I0902 00:27:46.455602 139752435963904 replay_runner.py:36] Average training steps per second: 351.50
I0902 00:27:46.920992 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.24
INFO:tensorflow:Starting iteration 4
I0902 00:27:50.263398 139752435963904 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 339.02

Steps executed: 1000 Episode length: 1000 Return: -190.46592004717766
I0902 00:27:54.821617 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.47
INFO:tensorflow:Starting iteration 5
I0902 00:27:58.142651 139752435963904 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 315.52

Steps executed: 887 Episode length: 887 Return: -389.8012555029291766
I0902 00:28:02.686244 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -389.80
INFO:tensorflow:Starting iteration 6

Steps executed: 731 Episode length: 731 Return: -242.5646838191428766
INFO:tensorflow:Average training steps per second: 349.64
I0902 00:28:08.844417 139752435963904 replay_runner.py:36] Average training steps per second: 349.64
I0902 00:28:09.849218 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.56
INFO:tensorflow:Starting iteration 7
I0902 00:28:13.228997 139752435963904 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 341.32

Steps executed: 1000 Episode length: 1000 Return: -46.085488546459176
I0902 00:28:17.768886 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -46.09
INFO:tensorflow:Starting iteration 8
I0902 00:28:21.097041 139752435963904 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 334.61

Steps executed: 1000 Episode length: 1000 Return: -130.41306141916036
I0902 00:28:26.108275 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.41
INFO:tensorflow:Starting iteration 9

Steps executed: 1000 Episode length: 1000 Return: -17.423446854911894
INFO:tensorflow:Average training steps per second: 344.45
I0902 00:28:32.352970 139752435963904 replay_runner.py:36] Average training steps per second: 344.45
I0902 00:28:33.597506 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -17.42
INFO:tensorflow:Starting iteration 10
I0902 00:28:36.782398 139752435963904 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 340.16

Steps executed: 1000 Episode length: 1000 Return: -292.97080985155003
I0902 00:28:41.235863 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -292.97
INFO:tensorflow:Starting iteration 11
I0902 00:28:44.434625 139752435963904 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 326.52

Steps executed: 1000 Episode length: 1000 Return: -149.41779874445473
I0902 00:28:49.781080 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.42
INFO:tensorflow:Starting iteration 12
I0902 00:28:53.074276 139752435963904 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 328.87

Steps executed: 1000 Episode length: 1000 Return: -216.77496000046673
I0902 00:28:57.974471 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.77
INFO:tensorflow:Starting iteration 13
I0902 00:29:01.324278 139752435963904 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 340.01

Steps executed: 1000 Episode length: 1000 Return: -99.286773255591093
I0902 00:29:05.850322 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.29
INFO:tensorflow:Starting iteration 14
I0902 00:29:09.202058 139752435963904 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 332.60

Steps executed: 1000 Episode length: 1000 Return: -165.58558321216339
I0902 00:29:14.417668 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.59
INFO:tensorflow:Starting iteration 15

Steps executed: 349 Episode length: 349 Return: -225.8294539637994439
INFO:tensorflow:Average training steps per second: 325.18
I0902 00:29:20.808100 139752435963904 replay_runner.py:36] Average training steps per second: 325.18
I0902 00:29:21.184082 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.83
INFO:tensorflow:Starting iteration 16

Steps executed: 472 Episode length: 472 Return: -80.76159550640824439
INFO:tensorflow:Average training steps per second: 335.06
I0902 00:29:27.386256 139752435963904 replay_runner.py:36] Average training steps per second: 335.06
I0902 00:29:27.918880 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.76
INFO:tensorflow:Starting iteration 17
I0902 00:29:31.230550 139752435963904 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 340.84
I0902 00:29:34.164736 139752435963904 replay_runner.py:36] Average training steps per second: 340.84

Steps executed: 305 Episode length: 153 Return: -284.3066827657586439
INFO:tensorflow:Starting iteration 18
I0902 00:29:37.737726 139752435963904 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 333.35

Steps executed: 240 Episode length: 124 Return: -187.4175005694498939
I0902 00:29:40.868345 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -204.05
INFO:tensorflow:Starting iteration 19

Steps executed: 259 Episode length: 68 Return: -476.36409035882177939
INFO:tensorflow:Average training steps per second: 338.09
I0902 00:29:47.215363 139752435963904 replay_runner.py:36] Average training steps per second: 338.09
I0902 00:29:47.364757 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -375.06
INFO:tensorflow:Starting iteration 20

Steps executed: 311 Episode length: 311 Return: -124.7073395586017939
INFO:tensorflow:Average training steps per second: 330.24
I0902 00:29:53.766399 139752435963904 replay_runner.py:36] Average training steps per second: 330.24
I0902 00:29:54.017529 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.71
INFO:tensorflow:Starting iteration 21
I0902 00:29:57.378524 139752435963904 replay_runner.py:41] Starting iteration 21

Steps executed: 216 Episode length: 102 Return: -401.9433525413427939
I0902 00:30:00.390402 139752435963904 replay_runner.py:36] Average training steps per second: 332.05
I0902 00:30:00.528097 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -496.27
INFO:tensorflow:Starting iteration 22

Steps executed: 346 Episode length: 163 Return: -224.8823552907773939
INFO:tensorflow:Average training steps per second: 331.59
I0902 00:30:06.870696 139752435963904 replay_runner.py:36] Average training steps per second: 331.59
I0902 00:30:07.078845 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.77
INFO:tensorflow:Starting iteration 23
I0902 00:30:10.411148 139752435963904 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 332.01

Steps executed: 1000 Episode length: 1000 Return: -103.29850068908706
I0902 00:30:16.128218 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.30
INFO:tensorflow:Starting iteration 24

Steps executed: 331 Episode length: 142 Return: 28.158008497156374706
INFO:tensorflow:Average training steps per second: 327.49
I0902 00:30:22.564359 139752435963904 replay_runner.py:36] Average training steps per second: 327.49
I0902 00:30:22.756238 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: 10.98
INFO:tensorflow:Starting iteration 25

Steps executed: 219 Episode length: 103 Return: -456.7831869220099606
INFO:tensorflow:Average training steps per second: 336.78
I0902 00:30:29.103290 139752435963904 replay_runner.py:36] Average training steps per second: 336.78
I0902 00:30:29.225800 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.60
INFO:tensorflow:Starting iteration 26

Steps executed: 253 Episode length: 253 Return: -2.048043982714773406
INFO:tensorflow:Average training steps per second: 334.69
I0902 00:30:35.495294 139752435963904 replay_runner.py:36] Average training steps per second: 334.69
I0902 00:30:35.684227 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -2.05
INFO:tensorflow:Starting iteration 27

Steps executed: 216 Episode length: 53 Return: -344.42311786406435406
INFO:tensorflow:Average training steps per second: 339.27
I0902 00:30:41.896365 139752435963904 replay_runner.py:36] Average training steps per second: 339.27
I0902 00:30:42.022007 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -450.63
INFO:tensorflow:Starting iteration 28

Steps executed: 201 Episode length: 135 Return: -6.670445433536585406
INFO:tensorflow:Average training steps per second: 370.02
I0902 00:30:48.065329 139752435963904 replay_runner.py:36] Average training steps per second: 370.02
I0902 00:30:48.181883 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.16
INFO:tensorflow:Starting iteration 29

Steps executed: 219 Episode length: 111 Return: -77.33136024314598406
INFO:tensorflow:Average training steps per second: 354.80
I0902 00:30:54.399429 139752435963904 replay_runner.py:36] Average training steps per second: 354.80

Done fixed training!Episode length: 111 Return: -77.33136024314598406