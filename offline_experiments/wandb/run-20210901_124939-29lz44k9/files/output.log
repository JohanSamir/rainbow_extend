Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0901 12:49:46.459513 139803418769408 run_experiment.py:549] Creating TrainRunner ...
I0901 12:49:46.471567 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:49:46.471870 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:49:46.471994 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:49:46.472404 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:49:46.472529 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 12:49:46.472609 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:49:46.472691 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:49:46.472832 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:49:46.472980 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:49:46.473167 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 12:49:46.473279 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:49:46.473684 139803418769408 dqn_agent.py:283] 	 seed: 1630500586471481
I0901 12:49:46.477649 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:49:46.477847 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:49:46.477963 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:49:46.478074 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:49:46.478213 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:49:46.478336 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:49:46.478483 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:49:46.478595 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:49:46.478760 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:49:46.521565 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:49:46.921778 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:49:46.934838 139803418769408 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:49:46.955972 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:49:46.956236 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:49:46.956588 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:49:46.962377 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:49:46.968026 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 12:49:46.971451 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:49:46.971644 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:49:46.971739 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:49:46.971915 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:49:46.972048 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 12:49:46.972165 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:49:46.972265 139803418769408 dqn_agent.py:283] 	 seed: 1630500586955913
I0901 12:49:46.975444 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:49:46.975603 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:49:46.975696 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:49:46.975782 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:49:46.975885 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:49:46.976134 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:49:46.976354 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:49:46.976485 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:49:46.976598 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:49:47.013324 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:49:47.042937 139803418769408 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:49:47.043520 139803418769408 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 158.15
I0901 12:49:53.367128 139803418769408 replay_runner.py:36] Average training steps per second: 158.15
Steps executed: 262 Episode length: 88 Return: -311.54220475530497
I0901 12:49:54.647178 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.67
INFO:tensorflow:Starting iteration 1

Steps executed: 207 Episode length: 105 Return: -664.7950341577945
INFO:tensorflow:Average training steps per second: 224.97
I0901 12:50:03.402687 139803418769408 replay_runner.py:36] Average training steps per second: 224.97
I0901 12:50:03.587399 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -589.74
INFO:tensorflow:Starting iteration 2

Steps executed: 217 Episode length: 85 Return: -721.61387099241559
INFO:tensorflow:Average training steps per second: 224.69
I0901 12:50:12.412485 139803418769408 replay_runner.py:36] Average training steps per second: 224.69
I0901 12:50:12.621568 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -591.38
INFO:tensorflow:Starting iteration 3

Steps executed: 311 Episode length: 131 Return: -6.841653986632352
INFO:tensorflow:Average training steps per second: 224.10
I0901 12:50:21.473899 139803418769408 replay_runner.py:36] Average training steps per second: 224.10
I0901 12:50:21.723724 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.67
INFO:tensorflow:Starting iteration 4

Steps executed: 233 Episode length: 107 Return: -132.70347216937875
INFO:tensorflow:Average training steps per second: 230.47
I0901 12:50:30.315521 139803418769408 replay_runner.py:36] Average training steps per second: 230.47
I0901 12:50:30.528543 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.01
INFO:tensorflow:Starting iteration 5

Steps executed: 290 Episode length: 290 Return: -465.04468134447916
INFO:tensorflow:Average training steps per second: 224.51
I0901 12:50:39.208019 139803418769408 replay_runner.py:36] Average training steps per second: 224.51
I0901 12:50:39.562005 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -465.04
INFO:tensorflow:Starting iteration 6
I0901 12:50:43.769052 139803418769408 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 224.58

Steps executed: 202 Episode length: 120 Return: -312.69390501742446
I0901 12:50:48.471270 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -432.32
INFO:tensorflow:Starting iteration 7

Steps executed: 281 Episode length: 139 Return: -64.508790194426556
INFO:tensorflow:Average training steps per second: 222.34
I0901 12:50:57.247690 139803418769408 replay_runner.py:36] Average training steps per second: 222.34
I0901 12:50:57.508268 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.72
INFO:tensorflow:Starting iteration 8
I0901 12:51:01.893290 139803418769408 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 221.54

Steps executed: 280 Episode length: 104 Return: -330.90898617743646
I0901 12:51:06.669255 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -349.71
INFO:tensorflow:Starting iteration 9

Steps executed: 226 Episode length: 77 Return: -416.976865912724446
INFO:tensorflow:Average training steps per second: 220.04
I0901 12:51:15.652881 139803418769408 replay_runner.py:36] Average training steps per second: 220.04
I0901 12:51:15.856871 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.54
INFO:tensorflow:Starting iteration 10

Steps executed: 243 Episode length: 79 Return: -289.134332067505176
INFO:tensorflow:Average training steps per second: 217.79
I0901 12:51:24.916242 139803418769408 replay_runner.py:36] Average training steps per second: 217.79
I0901 12:51:25.129249 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -380.47
INFO:tensorflow:Starting iteration 11

Steps executed: 257 Episode length: 91 Return: -417.486977993277666
INFO:tensorflow:Average training steps per second: 223.48
I0901 12:51:33.737677 139803418769408 replay_runner.py:36] Average training steps per second: 223.48
I0901 12:51:33.948765 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.41
INFO:tensorflow:Starting iteration 12

Steps executed: 272 Episode length: 98 Return: -84.2362059402611966
INFO:tensorflow:Average training steps per second: 217.43
I0901 12:51:42.866281 139803418769408 replay_runner.py:36] Average training steps per second: 217.43
I0901 12:51:43.098835 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.21
INFO:tensorflow:Starting iteration 13

Steps executed: 208 Episode length: 89 Return: -395.045658079047928
INFO:tensorflow:Average training steps per second: 223.55
I0901 12:51:51.857825 139803418769408 replay_runner.py:36] Average training steps per second: 223.55
I0901 12:51:52.039239 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -305.28
INFO:tensorflow:Starting iteration 14

Steps executed: 273 Episode length: 144 Return: -58.755432421881178
INFO:tensorflow:Average training steps per second: 215.20
I0901 12:52:00.998470 139803418769408 replay_runner.py:36] Average training steps per second: 215.20
I0901 12:52:01.255829 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.44
INFO:tensorflow:Starting iteration 15

Steps executed: 226 Episode length: 84 Return: -306.933706208784227
INFO:tensorflow:Average training steps per second: 217.34
I0901 12:52:09.869899 139803418769408 replay_runner.py:36] Average training steps per second: 217.34
I0901 12:52:10.045035 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.81
INFO:tensorflow:Starting iteration 16

Steps executed: 219 Episode length: 219 Return: -166.19063485497833
INFO:tensorflow:Average training steps per second: 220.34
I0901 12:52:18.855894 139803418769408 replay_runner.py:36] Average training steps per second: 220.34
I0901 12:52:19.073235 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.19
INFO:tensorflow:Starting iteration 17

Steps executed: 277 Episode length: 116 Return: -308.35050949047525
INFO:tensorflow:Average training steps per second: 224.50
I0901 12:52:27.917916 139803418769408 replay_runner.py:36] Average training steps per second: 224.50
I0901 12:52:28.196809 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.52
INFO:tensorflow:Starting iteration 18

Steps executed: 267 Episode length: 117 Return: -276.25288636471345
INFO:tensorflow:Average training steps per second: 227.65
I0901 12:52:36.958408 139803418769408 replay_runner.py:36] Average training steps per second: 227.65
I0901 12:52:37.216474 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.19
INFO:tensorflow:Starting iteration 19

Steps executed: 237 Episode length: 90 Return: -259.516294518938855
INFO:tensorflow:Average training steps per second: 220.19
I0901 12:52:46.022741 139803418769408 replay_runner.py:36] Average training steps per second: 220.19
I0901 12:52:46.235617 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.42
INFO:tensorflow:Starting iteration 20

Steps executed: 207 Episode length: 62 Return: -137.341334555921725
INFO:tensorflow:Average training steps per second: 223.93
I0901 12:52:55.083385 139803418769408 replay_runner.py:36] Average training steps per second: 223.93
I0901 12:52:55.249390 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.55
INFO:tensorflow:Starting iteration 21

Steps executed: 154 Episode length: 154 Return: -203.19304694983015
INFO:tensorflow:Average training steps per second: 218.62
I0901 12:53:04.281129 139803418769408 replay_runner.py:36] Average training steps per second: 218.62

Steps executed: 287 Episode length: 133 Return: -380.15624396633433
INFO:tensorflow:Starting iteration 22

Steps executed: 505 Episode length: 413 Return: -958.22470902635133
INFO:tensorflow:Average training steps per second: 223.02
I0901 12:53:13.149672 139803418769408 replay_runner.py:36] Average training steps per second: 223.02
I0901 12:53:13.978703 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -829.20
INFO:tensorflow:Starting iteration 23

Steps executed: 203 Episode length: 203 Return: -520.45154616407663
INFO:tensorflow:Average training steps per second: 225.69
I0901 12:53:22.736516 139803418769408 replay_runner.py:36] Average training steps per second: 225.69
I0901 12:53:22.968177 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -520.45
INFO:tensorflow:Starting iteration 24

Steps executed: 218 Episode length: 139 Return: -160.47354856631847
INFO:tensorflow:Average training steps per second: 223.37
I0901 12:53:31.959347 139803418769408 replay_runner.py:36] Average training steps per second: 223.37
I0901 12:53:32.156470 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.18
INFO:tensorflow:Starting iteration 25

Steps executed: 202 Episode length: 104 Return: -28.735849696477267
INFO:tensorflow:Average training steps per second: 226.81
I0901 12:53:40.929244 139803418769408 replay_runner.py:36] Average training steps per second: 226.81
I0901 12:53:41.086381 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.94
INFO:tensorflow:Starting iteration 26

Steps executed: 253 Episode length: 57 Return: -360.183174719449547
INFO:tensorflow:Average training steps per second: 226.71
I0901 12:53:49.727824 139803418769408 replay_runner.py:36] Average training steps per second: 226.71
I0901 12:53:49.984706 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -509.47
INFO:tensorflow:Starting iteration 27
I0901 12:53:54.190379 139803418769408 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 219.48

Steps executed: 290 Episode length: 97 Return: -620.076700797742547
I0901 12:53:59.075950 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -542.89
INFO:tensorflow:Starting iteration 28

Steps executed: 247 Episode length: 58 Return: -127.056392378591247
INFO:tensorflow:Average training steps per second: 223.10
I0901 12:54:07.940620 139803418769408 replay_runner.py:36] Average training steps per second: 223.10
I0901 12:54:08.157985 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -380.25
INFO:tensorflow:Starting iteration 29
I0901 12:54:12.492834 139803418769408 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 227.63

Steps executed: 258 Episode length: 61 Return: -322.814809241714647

Done fixed training!Episode length: 61 Return: -322.814809241714647