Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 12:35:00.163767 140315766171648 run_experiment.py:549] Creating TrainRunner ...
I0901 12:35:00.175117 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:35:00.175444 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:35:00.175584 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:35:00.175702 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:35:00.175812 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 12:35:00.175918 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:35:00.176069 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:35:00.176182 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:35:00.176287 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:35:00.176393 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 12:35:00.176554 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:35:00.176665 140315766171648 dqn_agent.py:283] 	 seed: 1630499700175049
I0901 12:35:00.180061 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:35:00.180269 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:35:00.180401 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:35:00.180554 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:35:00.180671 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:35:00.180778 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:35:00.180907 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:35:00.181163 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:35:00.181330 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:35:00.249384 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:35:00.648168 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:35:00.685022 140315766171648 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:35:00.695911 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:35:00.696247 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:35:00.696427 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:35:00.696601 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:35:00.696854 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 12:35:00.697033 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:35:00.697240 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:35:00.697368 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:35:00.697456 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:35:00.697535 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 12:35:00.697614 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:35:00.697677 140315766171648 dqn_agent.py:283] 	 seed: 1630499700695844
I0901 12:35:00.700118 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:35:00.700411 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:35:00.700653 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:35:00.700769 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:35:00.700850 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:35:00.700923 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:35:00.701031 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:35:00.701110 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:35:00.701215 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:35:00.734859 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:35:00.757480 140315766171648 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:35:00.757840 140315766171648 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 157.18
I0901 12:35:07.120453 140315766171648 replay_runner.py:36] Average training steps per second: 157.18
Steps executed: 202 Episode length: 116 Return: -240.13545844043009
I0901 12:35:08.276813 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -339.70
INFO:tensorflow:Starting iteration 1
I0901 12:35:12.739046 140315766171648 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 206.15

Steps executed: 262 Episode length: 80 Return: -257.103160009859048
I0901 12:35:17.846417 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.76
INFO:tensorflow:Starting iteration 2

Steps executed: 317 Episode length: 138 Return: -52.202325500772198
INFO:tensorflow:Average training steps per second: 207.54
I0901 12:35:27.150358 140315766171648 replay_runner.py:36] Average training steps per second: 207.54
I0901 12:35:27.440093 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.83
INFO:tensorflow:Starting iteration 3

Steps executed: 203 Episode length: 203 Return: -303.53105164205715
INFO:tensorflow:Average training steps per second: 205.48
I0901 12:35:36.760972 140315766171648 replay_runner.py:36] Average training steps per second: 205.48
I0901 12:35:36.988059 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.53
INFO:tensorflow:Starting iteration 4

Steps executed: 273 Episode length: 147 Return: -96.466417093836285
INFO:tensorflow:Average training steps per second: 202.55
I0901 12:35:46.386045 140315766171648 replay_runner.py:36] Average training steps per second: 202.55
I0901 12:35:46.605410 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.99
INFO:tensorflow:Starting iteration 5
I0901 12:35:51.075752 140315766171648 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 205.70

Steps executed: 343 Episode length: 209 Return: -252.48597300441874
I0901 12:35:56.294313 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -292.84
INFO:tensorflow:Starting iteration 6

Steps executed: 234 Episode length: 77 Return: -315.050476689444745
INFO:tensorflow:Average training steps per second: 207.69
I0901 12:36:05.461930 140315766171648 replay_runner.py:36] Average training steps per second: 207.69
I0901 12:36:05.679684 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.00
INFO:tensorflow:Starting iteration 7

Steps executed: 249 Episode length: 83 Return: -371.857880630136655
INFO:tensorflow:Average training steps per second: 204.45
I0901 12:36:14.850917 140315766171648 replay_runner.py:36] Average training steps per second: 204.45
I0901 12:36:15.065580 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.06
INFO:tensorflow:Starting iteration 8
I0901 12:36:19.449186 140315766171648 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 212.52

Steps executed: 248 Episode length: 248 Return: 126.143369336085075
I0901 12:36:24.460408 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: 126.14
INFO:tensorflow:Starting iteration 9
I0901 12:36:28.825289 140315766171648 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 210.37

Steps executed: 1000 Episode length: 1000 Return: -54.867742417464335
I0901 12:36:36.607172 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.87
INFO:tensorflow:Starting iteration 10
I0901 12:36:41.062412 140315766171648 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 206.48

Steps executed: 312 Episode length: 312 Return: -209.2470373245086335
I0901 12:36:46.337166 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.25
INFO:tensorflow:Starting iteration 11

Steps executed: 254 Episode length: 115 Return: -57.72895388285806535
INFO:tensorflow:Average training steps per second: 210.92
I0901 12:36:55.529523 140315766171648 replay_runner.py:36] Average training steps per second: 210.92
I0901 12:36:55.784280 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.50
INFO:tensorflow:Starting iteration 12

Steps executed: 343 Episode length: 212 Return: -283.2342638649474535
INFO:tensorflow:Average training steps per second: 222.71
I0901 12:37:04.613638 140315766171648 replay_runner.py:36] Average training steps per second: 222.71
I0901 12:37:04.960933 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.68
INFO:tensorflow:Starting iteration 13
I0901 12:37:09.369309 140315766171648 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 212.75
I0901 12:37:14.070430 140315766171648 replay_runner.py:36] Average training steps per second: 212.75

Steps executed: 285 Episode length: 285 Return: -226.8923158548009635
INFO:tensorflow:Starting iteration 14
I0901 12:37:18.799165 140315766171648 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 213.94

Steps executed: 535 Episode length: 535 Return: -182.3634833120232835
I0901 12:37:24.964167 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.36
INFO:tensorflow:Starting iteration 15
I0901 12:37:29.379959 140315766171648 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 212.25
I0901 12:37:34.091765 140315766171648 replay_runner.py:36] Average training steps per second: 212.25

Steps executed: 344 Episode length: 344 Return: -182.3941733824254835
INFO:tensorflow:Starting iteration 16

Steps executed: 261 Episode length: 261 Return: -97.93715614211354835
INFO:tensorflow:Average training steps per second: 211.47
I0901 12:37:43.818974 140315766171648 replay_runner.py:36] Average training steps per second: 211.47
I0901 12:37:44.095051 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.94
INFO:tensorflow:Starting iteration 17
I0901 12:37:48.503381 140315766171648 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 214.67

Steps executed: 1000 Episode length: 1000 Return: -87.028243644624155
I0901 12:37:56.793075 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.03
INFO:tensorflow:Starting iteration 18

Steps executed: 180 Episode length: 180 Return: -37.25835651377719155
INFO:tensorflow:Average training steps per second: 214.28

Steps executed: 1180 Episode length: 1000 Return: -117.66308745858782
I0901 12:38:09.559551 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.46
INFO:tensorflow:Starting iteration 19
I0901 12:38:13.905856 140315766171648 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 209.14

Steps executed: 1000 Episode length: 1000 Return: -48.390601907571212
I0901 12:38:20.886953 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -48.39
INFO:tensorflow:Starting iteration 20
I0901 12:38:25.226216 140315766171648 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 208.86

Steps executed: 1000 Episode length: 1000 Return: -33.391365311259812
I0901 12:38:33.516072 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -33.39
INFO:tensorflow:Starting iteration 21
I0901 12:38:37.959131 140315766171648 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 210.90

Steps executed: 1000 Episode length: 1000 Return: -101.64977574521343
I0901 12:38:45.298745 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.65
INFO:tensorflow:Starting iteration 22
I0901 12:38:49.802854 140315766171648 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 227.89

Steps executed: 1000 Episode length: 1000 Return: -63.867317496766843
I0901 12:38:59.148739 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -63.87
INFO:tensorflow:Starting iteration 23
I0901 12:39:03.651015 140315766171648 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 212.06

Steps executed: 396 Episode length: 225 Return: -34.26678715851052543
I0901 12:39:08.792210 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -55.13
INFO:tensorflow:Starting iteration 24
I0901 12:39:13.276642 140315766171648 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 209.14

Steps executed: 1000 Episode length: 1000 Return: -49.286485074521295
I0901 12:39:20.676942 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -49.29
INFO:tensorflow:Starting iteration 25
I0901 12:39:24.980402 140315766171648 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 207.30

Steps executed: 1000 Episode length: 1000 Return: -25.475673922431938
I0901 12:39:33.521298 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -25.48
INFO:tensorflow:Starting iteration 26
I0901 12:39:37.857949 140315766171648 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 210.57

Steps executed: 1000 Episode length: 1000 Return: -77.319553339306148
I0901 12:39:45.014194 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.32
INFO:tensorflow:Starting iteration 27
I0901 12:39:49.396219 140315766171648 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 209.73

Steps executed: 1000 Episode length: 1000 Return: -167.69805265177953
I0901 12:39:57.433066 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.70
INFO:tensorflow:Starting iteration 28

Steps executed: 97 Episode length: 97 Return: -447.509716444914157953
INFO:tensorflow:Average training steps per second: 215.01

Steps executed: 1097 Episode length: 1000 Return: -68.147215396384783
I0901 12:40:08.943775 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.83
INFO:tensorflow:Starting iteration 29
I0901 12:40:13.056487 140315766171648 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 225.41

Steps executed: 1000 Episode length: 1000 Return: -106.85912680465196

Done fixed training! Episode length: 1000 Return: -106.85912680465196