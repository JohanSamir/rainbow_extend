Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0902 23:56:18.459253 140006414895104 run_experiment.py:549] Creating TrainRunner ...
I0902 23:56:18.471261 140006414895104 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:56:18.471642 140006414895104 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:56:18.471874 140006414895104 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:56:18.472427 140006414895104 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:56:18.472595 140006414895104 dqn_agent.py:275] 	 update_period: 4
I0902 23:56:18.472714 140006414895104 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:56:18.472808 140006414895104 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:56:18.472938 140006414895104 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:56:18.473067 140006414895104 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:56:18.473196 140006414895104 dqn_agent.py:280] 	 optimizer: adam
I0902 23:56:18.473283 140006414895104 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:56:18.473356 140006414895104 dqn_agent.py:283] 	 seed: 1630626978471184
I0902 23:56:18.476812 140006414895104 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:56:18.477059 140006414895104 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:56:18.477183 140006414895104 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:56:18.477292 140006414895104 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:56:18.477400 140006414895104 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:56:18.477491 140006414895104 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:56:18.477584 140006414895104 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:56:18.477811 140006414895104 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:56:18.478012 140006414895104 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:56:18.512291 140006414895104 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:56:18.969160 140006414895104 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:56:18.984831 140006414895104 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:56:18.994647 140006414895104 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:56:18.994905 140006414895104 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:56:18.995013 140006414895104 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:56:18.995318 140006414895104 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:56:18.995485 140006414895104 dqn_agent.py:275] 	 update_period: 4
I0902 23:56:18.995607 140006414895104 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:56:18.995733 140006414895104 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:56:18.995854 140006414895104 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:56:18.995991 140006414895104 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:56:18.996097 140006414895104 dqn_agent.py:280] 	 optimizer: adam
I0902 23:56:18.996256 140006414895104 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:56:18.996412 140006414895104 dqn_agent.py:283] 	 seed: 1630626978994574
I0902 23:56:18.999247 140006414895104 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:56:18.999482 140006414895104 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:56:18.999619 140006414895104 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:56:18.999723 140006414895104 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:56:18.999868 140006414895104 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:56:19.000013 140006414895104 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:56:19.000252 140006414895104 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:56:19.000399 140006414895104 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:56:19.000495 140006414895104 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:56:19.033627 140006414895104 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:56:19.054584 140006414895104 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:56:19.054912 140006414895104 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 165.26
I0902 23:56:25.106360 140006414895104 replay_runner.py:36] Average training steps per second: 165.26
Steps executed: 278 Episode length: 119 Return: -640.0732710168838
I0902 23:56:26.393479 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -457.24
INFO:tensorflow:Starting iteration 1

Steps executed: 256 Episode length: 112 Return: -631.4349351086058
INFO:tensorflow:Average training steps per second: 218.67
I0902 23:56:35.344665 140006414895104 replay_runner.py:36] Average training steps per second: 218.67
I0902 23:56:35.610292 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -455.02
INFO:tensorflow:Starting iteration 2

Steps executed: 651 Episode length: 651 Return: 142.44938999611344
INFO:tensorflow:Average training steps per second: 219.22
I0902 23:56:44.449419 140006414895104 replay_runner.py:36] Average training steps per second: 219.22
I0902 23:56:45.994940 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: 142.45
INFO:tensorflow:Starting iteration 3

Steps executed: 448 Episode length: 448 Return: -265.0838646092024
INFO:tensorflow:Average training steps per second: 218.84
I0902 23:56:54.923909 140006414895104 replay_runner.py:36] Average training steps per second: 218.84
I0902 23:56:55.685414 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.08
INFO:tensorflow:Starting iteration 4
I0902 23:57:00.050785 140006414895104 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 230.36

Steps executed: 1000 Episode length: 1000 Return: 6.534063844899306
I0902 23:57:07.706593 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: 6.53
INFO:tensorflow:Starting iteration 5
I0902 23:57:11.955590 140006414895104 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 224.91

Steps executed: 1000 Episode length: 1000 Return: -19.936030755195866
I0902 23:57:18.657700 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -19.94
INFO:tensorflow:Starting iteration 6
I0902 23:57:23.043924 140006414895104 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 224.62

Steps executed: 1000 Episode length: 1000 Return: -7.8369798025248576
I0902 23:57:30.143029 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -7.84
INFO:tensorflow:Starting iteration 7
I0902 23:57:34.416519 140006414895104 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 223.98

Steps executed: 1000 Episode length: 1000 Return: -155.61474398499416
I0902 23:57:41.652161 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.61
INFO:tensorflow:Starting iteration 8
I0902 23:57:45.893824 140006414895104 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 231.68
I0902 23:57:50.210358 140006414895104 replay_runner.py:36] Average training steps per second: 231.68

Steps executed: 297 Episode length: 297 Return: -339.8293938127328416
INFO:tensorflow:Starting iteration 9
I0902 23:57:54.754369 140006414895104 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 234.21

Steps executed: 1000 Episode length: 1000 Return: -34.185815514587226
I0902 23:58:02.333761 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -34.19
INFO:tensorflow:Starting iteration 10
I0902 23:58:06.441220 140006414895104 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 243.90

Steps executed: 1000 Episode length: 1000 Return: -146.15299754145406
I0902 23:58:13.633134 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.15
INFO:tensorflow:Starting iteration 11
I0902 23:58:17.753530 140006414895104 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 240.84

Steps executed: 1000 Episode length: 1000 Return: -315.54419055134496
I0902 23:58:24.905137 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -315.54
INFO:tensorflow:Starting iteration 12
I0902 23:58:29.037806 140006414895104 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 246.38

Steps executed: 1000 Episode length: 1000 Return: -323.03122244897566
I0902 23:58:35.083977 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -323.03
INFO:tensorflow:Starting iteration 13

Steps executed: 345 Episode length: 274 Return: -229.8935045827095766
INFO:tensorflow:Average training steps per second: 249.11
I0902 23:58:43.099988 140006414895104 replay_runner.py:36] Average training steps per second: 249.11
I0902 23:58:43.407248 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.65
INFO:tensorflow:Starting iteration 14

Steps executed: 575 Episode length: 575 Return: -481.6352010301539566
INFO:tensorflow:Average training steps per second: 271.54
I0902 23:58:51.073241 140006414895104 replay_runner.py:36] Average training steps per second: 271.54
I0902 23:58:52.108860 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -481.64
INFO:tensorflow:Starting iteration 15

Steps executed: 290 Episode length: 156 Return: -138.4336773708356866
INFO:tensorflow:Average training steps per second: 285.36
I0902 23:58:59.542358 140006414895104 replay_runner.py:36] Average training steps per second: 285.36
I0902 23:58:59.743943 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.95
INFO:tensorflow:Starting iteration 16

Steps executed: 306 Episode length: 113 Return: -411.6088530721542666
INFO:tensorflow:Average training steps per second: 305.18
I0902 23:59:06.849768 140006414895104 replay_runner.py:36] Average training steps per second: 305.18
I0902 23:59:07.032328 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -214.79
INFO:tensorflow:Starting iteration 17

Steps executed: 303 Episode length: 148 Return: -96.16090457879562666
INFO:tensorflow:Average training steps per second: 298.75
I0902 23:59:14.162056 140006414895104 replay_runner.py:36] Average training steps per second: 298.75
I0902 23:59:14.343015 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.15
INFO:tensorflow:Starting iteration 18

Steps executed: 282 Episode length: 171 Return: -558.0507935009711666
INFO:tensorflow:Average training steps per second: 304.65
I0902 23:59:21.302803 140006414895104 replay_runner.py:36] Average training steps per second: 304.65
I0902 23:59:21.474190 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -530.14
INFO:tensorflow:Starting iteration 19

Steps executed: 213 Episode length: 103 Return: -161.2660792495938466
INFO:tensorflow:Average training steps per second: 320.54
I0902 23:59:28.285774 140006414895104 replay_runner.py:36] Average training steps per second: 320.54
I0902 23:59:28.413141 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.06
INFO:tensorflow:Starting iteration 20

Steps executed: 260 Episode length: 136 Return: -780.0135824510686466
INFO:tensorflow:Average training steps per second: 330.24
I0902 23:59:35.100476 140006414895104 replay_runner.py:36] Average training steps per second: 330.24
I0902 23:59:35.268359 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -805.65
INFO:tensorflow:Starting iteration 21

Steps executed: 245 Episode length: 85 Return: -134.28395890504616466
INFO:tensorflow:Average training steps per second: 319.28
I0902 23:59:41.964016 140006414895104 replay_runner.py:36] Average training steps per second: 319.28
I0902 23:59:42.086171 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.56
INFO:tensorflow:Starting iteration 22
I0902 23:59:45.601293 140006414895104 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 315.11

Steps executed: 266 Episode length: 156 Return: -527.5937648333688466
I0902 23:59:48.913477 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -526.24
INFO:tensorflow:Starting iteration 23

Steps executed: 297 Episode length: 136 Return: -121.2463719707079466
INFO:tensorflow:Average training steps per second: 324.89
I0902 23:59:55.483396 140006414895104 replay_runner.py:36] Average training steps per second: 324.89
I0902 23:59:55.603814 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.15
INFO:tensorflow:Starting iteration 24

Steps executed: 211 Episode length: 62 Return: -147.70273159273395266
INFO:tensorflow:Average training steps per second: 312.83
I0903 00:00:02.130262 140006414895104 replay_runner.py:36] Average training steps per second: 312.83
I0903 00:00:02.226359 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.40
INFO:tensorflow:Starting iteration 25

Steps executed: 209 Episode length: 92 Return: -171.28424590871395466
INFO:tensorflow:Average training steps per second: 307.66
I0903 00:00:08.657559 140006414895104 replay_runner.py:36] Average training steps per second: 307.66
I0903 00:00:08.739527 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.55
INFO:tensorflow:Starting iteration 26

Steps executed: 55 Episode length: 55 Return: -107.878055564440675466
INFO:tensorflow:Average training steps per second: 318.72
I0903 00:00:14.925393 140006414895104 replay_runner.py:36] Average training steps per second: 318.72

Steps executed: 311 Episode length: 138 Return: -262.0755630674504566
INFO:tensorflow:Starting iteration 27

Steps executed: 215 Episode length: 71 Return: -52.378420207398996566
INFO:tensorflow:Average training steps per second: 309.64
I0903 00:00:21.378390 140006414895104 replay_runner.py:36] Average training steps per second: 309.64
I0903 00:00:21.475860 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -282.29
INFO:tensorflow:Starting iteration 28

Steps executed: 216 Episode length: 113 Return: -164.3056612935506666
INFO:tensorflow:Average training steps per second: 324.76
I0903 00:00:27.576474 140006414895104 replay_runner.py:36] Average training steps per second: 324.76
I0903 00:00:27.697782 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -462.39
INFO:tensorflow:Starting iteration 29

Steps executed: 274 Episode length: 106 Return: -748.5037846392115666
INFO:tensorflow:Average training steps per second: 311.27
I0903 00:00:33.888162 140006414895104 replay_runner.py:36] Average training steps per second: 311.27

Done fixed training!Episode length: 106 Return: -748.5037846392115666