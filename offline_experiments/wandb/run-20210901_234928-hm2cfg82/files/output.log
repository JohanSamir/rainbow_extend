I0901 23:49:34.799437 139644712736768 run_experiment.py:549] Creating TrainRunner ...
I0901 23:49:34.811792 139644712736768 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:34.812577 139644712736768 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:34.812966 139644712736768 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:34.813129 139644712736768 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:34.813237 139644712736768 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:34.813339 139644712736768 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:34.813438 139644712736768 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:34.813534 139644712736768 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:34.813929 139644712736768 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:34.814135 139644712736768 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:34.814502 139644712736768 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:34.814647 139644712736768 dqn_agent.py:283] 	 seed: 1630540174811721
I0901 23:49:34.817859 139644712736768 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:34.818027 139644712736768 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:34.818173 139644712736768 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:34.818282 139644712736768 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:34.818370 139644712736768 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:34.818444 139644712736768 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:34.818518 139644712736768 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:34.818568 139644712736768 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:34.818765 139644712736768 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0901 23:49:36.743182 139644712736768 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:37.128869 139644712736768 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:37.143123 139644712736768 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:49:37.153494 139644712736768 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:37.153760 139644712736768 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:37.153889 139644712736768 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:37.153996 139644712736768 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:37.154100 139644712736768 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:37.154195 139644712736768 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:37.154307 139644712736768 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:37.154447 139644712736768 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:37.154693 139644712736768 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:37.154839 139644712736768 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:37.154951 139644712736768 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:37.155034 139644712736768 dqn_agent.py:283] 	 seed: 1630540177153436
I0901 23:49:37.157750 139644712736768 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:37.157932 139644712736768 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:37.158030 139644712736768 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:37.158136 139644712736768 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:37.158208 139644712736768 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:37.158274 139644712736768 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:37.158403 139644712736768 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:37.158488 139644712736768 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:37.158571 139644712736768 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:49:37.192742 139644712736768 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:37.213438 139644712736768 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:49:37.213856 139644712736768 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 165.06
I0901 23:49:43.272637 139644712736768 replay_runner.py:36] Average training steps per second: 165.06
Steps executed: 236 Episode length: 92 Return: -341.64419172732676
I0901 23:49:44.509678 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -343.66
INFO:tensorflow:Starting iteration 1

Steps executed: 280 Episode length: 155 Return: -398.9383244194031
INFO:tensorflow:Average training steps per second: 228.21
I0901 23:49:53.205425 139644712736768 replay_runner.py:36] Average training steps per second: 228.21
I0901 23:49:53.461494 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -369.93
INFO:tensorflow:Starting iteration 2

Steps executed: 208 Episode length: 208 Return: 41.285926102133031
INFO:tensorflow:Average training steps per second: 231.58
I0901 23:50:02.108921 139644712736768 replay_runner.py:36] Average training steps per second: 231.58
I0901 23:50:02.325174 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: 41.29
INFO:tensorflow:Starting iteration 3
I0901 23:50:06.555905 139644712736768 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 225.70

Steps executed: 1000 Episode length: 1000 Return: -114.8374646845466
I0901 23:50:14.854534 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.84
INFO:tensorflow:Starting iteration 4
I0901 23:50:19.179165 139644712736768 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 224.20

Steps executed: 1000 Episode length: 1000 Return: -147.41313392281228
I0901 23:50:27.815011 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.41
INFO:tensorflow:Starting iteration 5
I0901 23:50:32.099451 139644712736768 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 232.49

Steps executed: 1000 Episode length: 1000 Return: -224.95236470751064
I0901 23:50:38.340964 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.95
INFO:tensorflow:Starting iteration 6
I0901 23:50:42.519129 139644712736768 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 229.80

Steps executed: 1000 Episode length: 1000 Return: -172.58773823902574
I0901 23:50:49.893956 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -172.59
INFO:tensorflow:Starting iteration 7
I0901 23:50:54.044429 139644712736768 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 231.46

Steps executed: 1000 Episode length: 1000 Return: -120.78071985212613
I0901 23:51:02.755745 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.78
INFO:tensorflow:Starting iteration 8

Steps executed: 271 Episode length: 271 Return: -332.3988133086282313
INFO:tensorflow:Average training steps per second: 218.66
I0901 23:51:11.594431 139644712736768 replay_runner.py:36] Average training steps per second: 218.66
I0901 23:51:11.939550 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.40
INFO:tensorflow:Starting iteration 9
I0901 23:51:16.154300 139644712736768 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 219.28


Steps executed: 1131 Episode length: 1000 Return: -334.81320281928963
I0901 23:51:23.201807 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.51
INFO:tensorflow:Starting iteration 10

Steps executed: 529 Episode length: 529 Return: -326.0957103770143763
INFO:tensorflow:Average training steps per second: 217.74
I0901 23:51:32.031184 139644712736768 replay_runner.py:36] Average training steps per second: 217.74
I0901 23:51:32.861353 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.10
INFO:tensorflow:Starting iteration 11
I0901 23:51:37.162940 139644712736768 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 219.54

Steps executed: 746 Episode length: 746 Return: -261.6952106629683763
I0901 23:51:43.502366 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.70
INFO:tensorflow:Starting iteration 12

Steps executed: 357 Episode length: 357 Return: -309.4526900420797763
INFO:tensorflow:Average training steps per second: 225.33
I0901 23:51:52.303460 139644712736768 replay_runner.py:36] Average training steps per second: 225.33
I0901 23:51:52.815298 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.45
INFO:tensorflow:Starting iteration 13

Steps executed: 644 Episode length: 644 Return: -329.7302455302547763
INFO:tensorflow:Average training steps per second: 224.88
I0901 23:52:01.586704 139644712736768 replay_runner.py:36] Average training steps per second: 224.88
I0901 23:52:02.937709 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.73
INFO:tensorflow:Starting iteration 14
I0901 23:52:07.337883 139644712736768 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 220.09

Steps executed: 750 Episode length: 750 Return: -159.6353541493619463
I0901 23:52:14.197011 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.64
INFO:tensorflow:Starting iteration 15
I0901 23:52:18.581713 139644712736768 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 216.46

Steps executed: 262 Episode length: 159 Return: -584.5451810305005463
I0901 23:52:23.428136 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -399.24
INFO:tensorflow:Starting iteration 16
I0901 23:52:27.504515 139644712736768 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 218.47

Steps executed: 572 Episode length: 572 Return: -32.07137844374692463
I0901 23:52:33.535310 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -32.07
INFO:tensorflow:Starting iteration 17

Steps executed: 283 Episode length: 283 Return: -257.9799537246081463
INFO:tensorflow:Average training steps per second: 216.09
I0901 23:52:42.311553 139644712736768 replay_runner.py:36] Average training steps per second: 216.09
I0901 23:52:42.686857 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.98
INFO:tensorflow:Starting iteration 18

Steps executed: 245 Episode length: 245 Return: -257.5096533700807463
INFO:tensorflow:Average training steps per second: 224.97
I0901 23:52:51.311262 139644712736768 replay_runner.py:36] Average training steps per second: 224.97
I0901 23:52:51.583446 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.51
INFO:tensorflow:Starting iteration 19

Steps executed: 252 Episode length: 252 Return: -248.7341935506005763
INFO:tensorflow:Average training steps per second: 223.03
I0901 23:53:00.366032 139644712736768 replay_runner.py:36] Average training steps per second: 223.03
I0901 23:53:00.665630 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.73
INFO:tensorflow:Starting iteration 20

Steps executed: 399 Episode length: 244 Return: 5.1009340712094861363
INFO:tensorflow:Average training steps per second: 222.90
I0901 23:53:09.350798 139644712736768 replay_runner.py:36] Average training steps per second: 222.90
I0901 23:53:09.788968 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -6.27
INFO:tensorflow:Starting iteration 21

Steps executed: 265 Episode length: 134 Return: -306.4874565190370463
INFO:tensorflow:Average training steps per second: 218.50
I0901 23:53:18.651802 139644712736768 replay_runner.py:36] Average training steps per second: 218.50
I0901 23:53:18.857647 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.93
INFO:tensorflow:Starting iteration 22

Steps executed: 659 Episode length: 508 Return: 215.92370072742787463
INFO:tensorflow:Average training steps per second: 221.43
I0901 23:53:27.785438 139644712736768 replay_runner.py:36] Average training steps per second: 221.43
I0901 23:53:28.931290 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: 119.30
INFO:tensorflow:Starting iteration 23
I0901 23:53:33.157230 139644712736768 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 227.72

Steps executed: 979 Episode length: 979 Return: -201.8252576599947563
I0901 23:53:40.342013 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.83
INFO:tensorflow:Starting iteration 24

Steps executed: 132 Episode length: 132 Return: -339.4143071498706463
INFO:tensorflow:Average training steps per second: 237.23
I0901 23:53:48.900701 139644712736768 replay_runner.py:36] Average training steps per second: 237.23

Steps executed: 307 Episode length: 175 Return: -282.1374111304774663
INFO:tensorflow:Starting iteration 25

Steps executed: 147 Episode length: 147 Return: -327.9452903842713563
INFO:tensorflow:Average training steps per second: 233.68

Steps executed: 795 Episode length: 648 Return: -140.3543816144355763
I0901 23:53:59.886512 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.15
INFO:tensorflow:Starting iteration 26

Steps executed: 314 Episode length: 165 Return: -438.6756211271110763
INFO:tensorflow:Average training steps per second: 228.81
I0901 23:54:08.354903 139644712736768 replay_runner.py:36] Average training steps per second: 228.81
I0901 23:54:08.644889 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -407.89
INFO:tensorflow:Starting iteration 27
I0901 23:54:12.869610 139644712736768 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 226.46

Steps executed: 503 Episode length: 338 Return: -159.9773070120264763
I0901 23:54:17.886791 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.47
INFO:tensorflow:Starting iteration 28

Steps executed: 361 Episode length: 166 Return: -503.1420929345407763
INFO:tensorflow:Average training steps per second: 218.49
I0901 23:54:26.828368 139644712736768 replay_runner.py:36] Average training steps per second: 218.49
I0901 23:54:27.143456 139644712736768 run_experiment.py:428] Average undiscounted return per evaluation episode: -436.01
INFO:tensorflow:Starting iteration 29

Steps executed: 631 Episode length: 631 Return: -678.5135206882063763
INFO:tensorflow:Average training steps per second: 217.90
I0901 23:54:35.913625 139644712736768 replay_runner.py:36] Average training steps per second: 217.90

Done fixed training!Episode length: 631 Return: -678.5135206882063763