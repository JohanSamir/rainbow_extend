I0901 23:49:18.888484 140149719906304 run_experiment.py:549] Creating TrainRunner ...
I0901 23:49:18.899781 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:18.900101 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:18.900306 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:18.900444 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:18.900667 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:18.901045 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:18.901221 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:18.901358 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:18.901470 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:18.901650 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:18.901803 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:18.901965 140149719906304 dqn_agent.py:283] 	 seed: 1630540158899695
I0901 23:49:18.905089 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:18.905232 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:18.905330 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:18.905464 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:18.905568 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:18.905660 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:18.905760 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:18.905848 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:18.905976 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0901 23:49:20.742351 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:21.138271 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:21.149536 140149719906304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:49:21.159303 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:21.159587 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:21.159698 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:21.159816 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:21.159946 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:21.160048 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:21.160123 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:21.160195 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:21.160335 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:21.160408 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:21.160494 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:21.160591 140149719906304 dqn_agent.py:283] 	 seed: 1630540161159224
I0901 23:49:21.162167 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:21.162288 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:21.162359 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:21.162424 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:21.162481 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:21.162533 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:21.162604 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:21.162684 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:21.162752 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:49:21.195685 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:21.216735 140149719906304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:49:21.217122 140149719906304 replay_runner.py:41] Starting iteration 0
Steps executed: 88 Episode length: 88 Return: -254.47019802741517
INFO:tensorflow:Average training steps per second: 163.21

Steps executed: 271 Episode length: 86 Return: -179.63807685626458
I0901 23:49:28.572126 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.93
INFO:tensorflow:Starting iteration 1

Steps executed: 343 Episode length: 188 Return: -481.89716436267876
INFO:tensorflow:Average training steps per second: 216.59
I0901 23:49:37.575576 140149719906304 replay_runner.py:36] Average training steps per second: 216.59
I0901 23:49:37.912192 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.09
INFO:tensorflow:Starting iteration 2

Steps executed: 378 Episode length: 206 Return: -383.98726286232656
INFO:tensorflow:Average training steps per second: 223.74
I0901 23:49:46.720516 140149719906304 replay_runner.py:36] Average training steps per second: 223.74
I0901 23:49:47.151780 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -374.88
INFO:tensorflow:Starting iteration 3

Steps executed: 113 Episode length: 113 Return: -228.85121919795356
INFO:tensorflow:Average training steps per second: 225.08

Steps executed: 574 Episode length: 461 Return: -307.37191388089666
I0901 23:49:56.859956 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.11
INFO:tensorflow:Starting iteration 4

Steps executed: 102 Episode length: 102 Return: -287.87186625420626
INFO:tensorflow:Average training steps per second: 230.44

Steps executed: 1020 Episode length: 918 Return: -193.36455445259566
I0901 23:50:07.747006 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -240.62
INFO:tensorflow:Starting iteration 5
I0901 23:50:12.106523 140149719906304 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 220.78

Steps executed: 1000 Episode length: 1000 Return: -187.9048731895897
I0901 23:50:20.474922 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.90
INFO:tensorflow:Starting iteration 6
I0901 23:50:24.550804 140149719906304 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 227.10

Steps executed: 1000 Episode length: 1000 Return: -61.268267000607004
I0901 23:50:31.578839 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.27
INFO:tensorflow:Starting iteration 7
I0901 23:50:35.868947 140149719906304 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 237.76

Steps executed: 1000 Episode length: 1000 Return: -124.78472454278476
I0901 23:50:41.969106 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.78
INFO:tensorflow:Starting iteration 8
I0901 23:50:46.286127 140149719906304 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 235.30

Steps executed: 867 Episode length: 867 Return: -331.6531820094698476
I0901 23:50:52.274589 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.65
INFO:tensorflow:Starting iteration 9

Steps executed: 444 Episode length: 444 Return: -380.2227914365757476
INFO:tensorflow:Average training steps per second: 220.12
I0901 23:51:01.139351 140149719906304 replay_runner.py:36] Average training steps per second: 220.12
I0901 23:51:01.816194 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -380.22
INFO:tensorflow:Starting iteration 10
I0901 23:51:06.016362 140149719906304 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 216.74

Steps executed: 1000 Episode length: 1000 Return: -189.40800591939808
I0901 23:51:12.559742 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.41
INFO:tensorflow:Starting iteration 11
I0901 23:51:16.838640 140149719906304 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 215.67

Steps executed: 1000 Episode length: 1000 Return: -110.60713799415238
I0901 23:51:24.293072 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.61
INFO:tensorflow:Starting iteration 12
I0901 23:51:28.535163 140149719906304 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 219.99

Steps executed: 1000 Episode length: 1000 Return: -151.85983587578457
I0901 23:51:35.636773 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.86
INFO:tensorflow:Starting iteration 13

Steps executed: 399 Episode length: 399 Return: -320.3144836051305457
INFO:tensorflow:Average training steps per second: 219.19
I0901 23:51:44.432568 140149719906304 replay_runner.py:36] Average training steps per second: 219.19
I0901 23:51:45.076786 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -320.31
INFO:tensorflow:Starting iteration 14

Steps executed: 276 Episode length: 276 Return: -491.4075526440164457
INFO:tensorflow:Average training steps per second: 221.57
I0901 23:51:53.943153 140149719906304 replay_runner.py:36] Average training steps per second: 221.57
I0901 23:51:54.268207 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -491.41
INFO:tensorflow:Starting iteration 15
I0901 23:51:58.606133 140149719906304 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 223.30

Steps executed: 911 Episode length: 911 Return: -452.5823675352591557
I0901 23:52:05.187861 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -452.58
INFO:tensorflow:Starting iteration 16

Steps executed: 252 Episode length: 252 Return: -494.0866079465045557
INFO:tensorflow:Average training steps per second: 221.04
I0901 23:52:13.932321 140149719906304 replay_runner.py:36] Average training steps per second: 221.04
I0901 23:52:14.223866 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -494.09
INFO:tensorflow:Starting iteration 17
I0901 23:52:18.623407 140149719906304 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 220.20
I0901 23:52:23.165159 140149719906304 replay_runner.py:36] Average training steps per second: 220.20

Steps executed: 252 Episode length: 131 Return: -139.7011400922146757
INFO:tensorflow:Starting iteration 18

Steps executed: 246 Episode length: 175 Return: -267.1464033660882457
INFO:tensorflow:Average training steps per second: 219.67
I0901 23:52:32.057399 140149719906304 replay_runner.py:36] Average training steps per second: 219.67
I0901 23:52:32.295915 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.66
INFO:tensorflow:Starting iteration 19

Steps executed: 305 Episode length: 114 Return: -709.0291908044965257
INFO:tensorflow:Average training steps per second: 221.25
I0901 23:52:41.125149 140149719906304 replay_runner.py:36] Average training steps per second: 221.25
I0901 23:52:41.411262 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -316.25
INFO:tensorflow:Starting iteration 20

Steps executed: 238 Episode length: 123 Return: -270.7649096565250557
INFO:tensorflow:Average training steps per second: 226.85
I0901 23:52:50.078836 140149719906304 replay_runner.py:36] Average training steps per second: 226.85
I0901 23:52:50.320528 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.27
INFO:tensorflow:Starting iteration 21

Steps executed: 344 Episode length: 209 Return: -62.31498435172546357
INFO:tensorflow:Average training steps per second: 216.78
I0901 23:52:59.256853 140149719906304 replay_runner.py:36] Average training steps per second: 216.78
I0901 23:52:59.589474 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.12
INFO:tensorflow:Starting iteration 22

Steps executed: 246 Episode length: 52 Return: -97.082475857752162357
INFO:tensorflow:Average training steps per second: 223.57
I0901 23:53:08.253189 140149719906304 replay_runner.py:36] Average training steps per second: 223.57
I0901 23:53:08.504106 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -35.54
INFO:tensorflow:Starting iteration 23

Steps executed: 203 Episode length: 203 Return: -281.2188034885813357
INFO:tensorflow:Average training steps per second: 213.28
I0901 23:53:17.477339 140149719906304 replay_runner.py:36] Average training steps per second: 213.28
I0901 23:53:17.711076 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.22
INFO:tensorflow:Starting iteration 24

Steps executed: 207 Episode length: 153 Return: -152.4375636858216657
INFO:tensorflow:Average training steps per second: 217.17
I0901 23:53:26.547621 140149719906304 replay_runner.py:36] Average training steps per second: 217.17
I0901 23:53:26.753988 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.05
INFO:tensorflow:Starting iteration 25

Steps executed: 200 Episode length: 62 Return: -119.78123084887764357
INFO:tensorflow:Average training steps per second: 221.69
I0901 23:53:35.555865 140149719906304 replay_runner.py:36] Average training steps per second: 221.69
I0901 23:53:35.732444 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.33
INFO:tensorflow:Starting iteration 26

Steps executed: 283 Episode length: 178 Return: -83.25809291163259857
INFO:tensorflow:Average training steps per second: 235.01
I0901 23:53:44.133227 140149719906304 replay_runner.py:36] Average training steps per second: 235.01
I0901 23:53:44.374552 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.69
INFO:tensorflow:Starting iteration 27

Steps executed: 149 Episode length: 149 Return: -139.2023478724593857
INFO:tensorflow:Average training steps per second: 228.02
I0901 23:53:53.036126 140149719906304 replay_runner.py:36] Average training steps per second: 228.02

Steps executed: 289 Episode length: 140 Return: -158.6051796208304357
INFO:tensorflow:Starting iteration 28

Steps executed: 253 Episode length: 118 Return: -167.9595721800659557
INFO:tensorflow:Average training steps per second: 227.49
I0901 23:54:01.898252 140149719906304 replay_runner.py:36] Average training steps per second: 227.49
I0901 23:54:02.109669 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.72
INFO:tensorflow:Starting iteration 29

Steps executed: 375 Episode length: 202 Return: -475.8391286534977757
INFO:tensorflow:Average training steps per second: 220.98
I0901 23:54:10.910360 140149719906304 replay_runner.py:36] Average training steps per second: 220.98

Done fixed training!Episode length: 202 Return: -475.8391286534977757