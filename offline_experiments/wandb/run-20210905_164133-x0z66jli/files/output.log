I0905 16:41:39.670658 140202555004928 run_experiment.py:549] Creating TrainRunner ...
I0905 16:41:39.682722 140202555004928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:41:39.682873 140202555004928 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:41:39.682980 140202555004928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:41:39.683120 140202555004928 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:41:39.683336 140202555004928 dqn_agent.py:275] 	 update_period: 4
I0905 16:41:39.683430 140202555004928 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:41:39.683554 140202555004928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:41:39.683681 140202555004928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:41:39.683759 140202555004928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:41:39.683830 140202555004928 dqn_agent.py:280] 	 optimizer: adam
I0905 16:41:39.683909 140202555004928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:41:39.684031 140202555004928 dqn_agent.py:283] 	 seed: 1630860099682682
I0905 16:41:39.686236 140202555004928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:41:39.686357 140202555004928 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:41:39.686490 140202555004928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:41:39.686563 140202555004928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:41:39.686620 140202555004928 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:41:39.686698 140202555004928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:41:39.686826 140202555004928 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:41:39.686889 140202555004928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:41:39.686969 140202555004928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:41:41.015662 140202555004928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0905 16:41:41.672567 140202555004928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:41:41.683765 140202555004928 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:41:41.691813 140202555004928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:41:41.692001 140202555004928 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:41:41.692113 140202555004928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:41:41.692175 140202555004928 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:41:41.692230 140202555004928 dqn_agent.py:275] 	 update_period: 4
I0905 16:41:41.692283 140202555004928 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:41:41.692369 140202555004928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:41:41.692422 140202555004928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:41:41.692473 140202555004928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:41:41.692524 140202555004928 dqn_agent.py:280] 	 optimizer: adam
I0905 16:41:41.692575 140202555004928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:41:41.692625 140202555004928 dqn_agent.py:283] 	 seed: 1630860101691762
I0905 16:41:41.694199 140202555004928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:41:41.694316 140202555004928 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:41:41.694389 140202555004928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:41:41.694452 140202555004928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:41:41.694509 140202555004928 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:41:41.694562 140202555004928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:41:41.694642 140202555004928 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:41:41.694695 140202555004928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:41:41.694745 140202555004928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:41:41.715255 140202555004928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:41:41.730690 140202555004928 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:41:41.730878 140202555004928 replay_runner.py:41] Starting iteration 0
Steps executed: 283 Episode length: 172 Return: -574.38859838702737
INFO:tensorflow:Average training steps per second: 218.99
I0905 16:41:46.297529 140202555004928 replay_runner.py:36] Average training steps per second: 218.99
I0905 16:41:47.210879 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.94
INFO:tensorflow:Starting iteration 1

Steps executed: 323 Episode length: 185 Return: -383.88555648705056
INFO:tensorflow:Average training steps per second: 280.37
I0905 16:41:54.160333 140202555004928 replay_runner.py:36] Average training steps per second: 280.37
I0905 16:41:54.456001 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -313.84
INFO:tensorflow:Starting iteration 2

Steps executed: 962 Episode length: 804 Return: -416.40702364131243
INFO:tensorflow:Average training steps per second: 268.59
I0905 16:42:01.591248 140202555004928 replay_runner.py:36] Average training steps per second: 268.59
I0905 16:42:03.118056 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.01
INFO:tensorflow:Starting iteration 3
I0905 16:42:06.603049 140202555004928 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 256.83

Steps executed: 1000 Episode length: 1000 Return: -141.17555375213354
I0905 16:42:13.476883 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.18
INFO:tensorflow:Starting iteration 4
I0905 16:42:17.204740 140202555004928 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 239.49

Steps executed: 1000 Episode length: 1000 Return: -111.60307170737528
I0905 16:42:23.024944 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.60
INFO:tensorflow:Starting iteration 5
I0905 16:42:27.101322 140202555004928 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 238.42

Steps executed: 1000 Episode length: 1000 Return: -161.21335142175138
I0905 16:42:35.234949 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.21
INFO:tensorflow:Starting iteration 6
I0905 16:42:39.477488 140202555004928 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 268.31

Steps executed: 1000 Episode length: 1000 Return: -154.89768903331043
I0905 16:42:45.496941 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.90
INFO:tensorflow:Starting iteration 7
I0905 16:42:49.784872 140202555004928 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 280.43

Steps executed: 1000 Episode length: 1000 Return: -48.042959445979335
I0905 16:42:56.933394 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -48.04
INFO:tensorflow:Starting iteration 8
I0905 16:43:00.988969 140202555004928 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 250.88

Steps executed: 1000 Episode length: 1000 Return: -187.69502868427625
I0905 16:43:07.640563 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.70
INFO:tensorflow:Starting iteration 9
I0905 16:43:11.646524 140202555004928 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 241.91

Steps executed: 751 Episode length: 751 Return: -499.4621014744001325
I0905 16:43:17.186355 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -499.46
INFO:tensorflow:Starting iteration 10
I0905 16:43:21.322406 140202555004928 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 244.30

Steps executed: 1000 Episode length: 1000 Return: -275.99263209014665
I0905 16:43:28.696279 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -275.99
INFO:tensorflow:Starting iteration 11
I0905 16:43:32.749373 140202555004928 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 251.41

Steps executed: 928 Episode length: 928 Return: -595.3840976964241665
I0905 16:43:39.168976 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -595.38
INFO:tensorflow:Starting iteration 12
I0905 16:43:43.377335 140202555004928 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 248.84

Steps executed: 1000 Episode length: 1000 Return: -187.82172232921613
I0905 16:43:50.360031 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.82
INFO:tensorflow:Starting iteration 13

Steps executed: 293 Episode length: 146 Return: -268.2885233959443713
INFO:tensorflow:Average training steps per second: 237.35
I0905 16:43:58.471544 140202555004928 replay_runner.py:36] Average training steps per second: 237.35
I0905 16:43:58.763564 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.62
INFO:tensorflow:Starting iteration 14
I0905 16:44:02.706144 140202555004928 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 244.27

Steps executed: 1000 Episode length: 1000 Return: -88.330511408277053
I0905 16:44:11.206762 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.33
INFO:tensorflow:Starting iteration 15
I0905 16:44:15.041879 140202555004928 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 223.62
I0905 16:44:19.514805 140202555004928 replay_runner.py:36] Average training steps per second: 223.62

Steps executed: 321 Episode length: 321 Return: 6.3041904872806577053
INFO:tensorflow:Starting iteration 16
I0905 16:44:23.757035 140202555004928 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 233.89

Steps executed: 229 Episode length: 229 Return: -40.47886854244594053
I0905 16:44:28.366856 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -40.48
INFO:tensorflow:Starting iteration 17

Steps executed: 477 Episode length: 477 Return: -231.7192103703161053
INFO:tensorflow:Average training steps per second: 250.91
I0905 16:44:36.245327 140202555004928 replay_runner.py:36] Average training steps per second: 250.91
I0905 16:44:37.260792 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.72
INFO:tensorflow:Starting iteration 18

Steps executed: 293 Episode length: 114 Return: -750.7182381503169753
INFO:tensorflow:Average training steps per second: 284.68
I0905 16:44:44.845108 140202555004928 replay_runner.py:36] Average training steps per second: 284.68
I0905 16:44:45.230274 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -464.97
INFO:tensorflow:Starting iteration 19

Steps executed: 206 Episode length: 55 Return: -104.29724439768586753
INFO:tensorflow:Average training steps per second: 271.17
I0905 16:44:53.239341 140202555004928 replay_runner.py:36] Average training steps per second: 271.17
I0905 16:44:53.449769 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.26
INFO:tensorflow:Starting iteration 20
I0905 16:44:57.727166 140202555004928 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 260.65

Steps executed: 483 Episode length: 483 Return: -291.3492177058494753
I0905 16:45:02.354866 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -291.35
INFO:tensorflow:Starting iteration 21

Steps executed: 260 Episode length: 73 Return: -171.31421356200042753
INFO:tensorflow:Average training steps per second: 246.17
I0905 16:45:10.612221 140202555004928 replay_runner.py:36] Average training steps per second: 246.17
I0905 16:45:10.835637 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.26
INFO:tensorflow:Starting iteration 22

Steps executed: 282 Episode length: 144 Return: 1.0663446048727536253
INFO:tensorflow:Average training steps per second: 247.61
I0905 16:45:18.979669 140202555004928 replay_runner.py:36] Average training steps per second: 247.61
I0905 16:45:19.277180 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.38
INFO:tensorflow:Starting iteration 23
I0905 16:45:23.469130 140202555004928 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 250.24

Steps executed: 623 Episode length: 623 Return: -235.5573194347201253
I0905 16:45:28.396452 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.56
INFO:tensorflow:Starting iteration 24

Steps executed: 308 Episode length: 174 Return: -102.6748306583689553
INFO:tensorflow:Average training steps per second: 246.55
I0905 16:45:36.568123 140202555004928 replay_runner.py:36] Average training steps per second: 246.55
I0905 16:45:36.902012 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.97
INFO:tensorflow:Starting iteration 25

Steps executed: 220 Episode length: 105 Return: -387.5878887288917553
INFO:tensorflow:Average training steps per second: 252.15
I0905 16:45:45.131861 140202555004928 replay_runner.py:36] Average training steps per second: 252.15
I0905 16:45:45.397445 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -390.73
INFO:tensorflow:Starting iteration 26
I0905 16:45:49.632995 140202555004928 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 276.19

Steps executed: 474 Episode length: 474 Return: -607.3731218924248553
I0905 16:45:54.258565 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -607.37
INFO:tensorflow:Starting iteration 27

Steps executed: 222 Episode length: 222 Return: -132.1232916791270253
INFO:tensorflow:Average training steps per second: 302.91
I0905 16:46:01.810483 140202555004928 replay_runner.py:36] Average training steps per second: 302.91
I0905 16:46:02.065798 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.12
INFO:tensorflow:Starting iteration 28

Steps executed: 288 Episode length: 137 Return: 23.601122877823542953
INFO:tensorflow:Average training steps per second: 272.01
I0905 16:46:10.132459 140202555004928 replay_runner.py:36] Average training steps per second: 272.01
I0905 16:46:10.323354 140202555004928 run_experiment.py:428] Average undiscounted return per evaluation episode: 5.41
INFO:tensorflow:Starting iteration 29

Steps executed: 67 Episode length: 67 Return: -327.942633470946642953
INFO:tensorflow:Average training steps per second: 245.39

Steps executed: 1067 Episode length: 1000 Return: 11.0827242394141663

Done fixed training! Episode length: 1000 Return: 11.0827242394141663