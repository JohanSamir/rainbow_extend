I0902 23:09:47.212132 140527680751616 run_experiment.py:549] Creating TrainRunner ...
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0902 23:09:47.212719 140527680751616 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0902 23:09:47.277046 140527680751616 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:09:47.278166 140527680751616 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:09:47.278249 140527680751616 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:09:47.278358 140527680751616 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:09:47.278407 140527680751616 dqn_agent.py:275] 	 update_period: 4
I0902 23:09:47.278451 140527680751616 dqn_agent.py:276] 	 target_update_period: 100
I0902 23:09:47.278543 140527680751616 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:09:47.278597 140527680751616 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:09:47.278652 140527680751616 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:09:47.278707 140527680751616 dqn_agent.py:280] 	 optimizer: adam
I0902 23:09:47.278833 140527680751616 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:09:47.278918 140527680751616 dqn_agent.py:283] 	 seed: 1630624187276981
I0902 23:09:47.280817 140527680751616 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:09:47.281010 140527680751616 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0902 23:09:47.281084 140527680751616 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:09:47.281151 140527680751616 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:09:47.281209 140527680751616 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:09:47.281272 140527680751616 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:09:47.281351 140527680751616 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:09:47.281411 140527680751616 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:09:47.281463 140527680751616 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:09:52.833035 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in acrobot
I0902 23:09:54.354317 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:09:54.439333 140527680751616 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:09:54.485288 140527680751616 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:09:54.485523 140527680751616 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:09:54.488538 140527680751616 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:09:54.490000 140527680751616 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:09:54.491055 140527680751616 dqn_agent.py:275] 	 update_period: 4
I0902 23:09:54.491951 140527680751616 dqn_agent.py:276] 	 target_update_period: 100
I0902 23:09:54.492953 140527680751616 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:09:54.493965 140527680751616 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:09:54.494859 140527680751616 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:09:54.495779 140527680751616 dqn_agent.py:280] 	 optimizer: adam
I0902 23:09:54.496828 140527680751616 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:09:54.497856 140527680751616 dqn_agent.py:283] 	 seed: 1630624194485232
I0902 23:09:54.509643 140527680751616 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:09:54.511475 140527680751616 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0902 23:09:54.512580 140527680751616 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:09:54.513653 140527680751616 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:09:54.514705 140527680751616 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:09:54.515709 140527680751616 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:09:54.516851 140527680751616 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:09:54.518190 140527680751616 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:09:54.519166 140527680751616 circular_replay_buffer.py:163] 	 gamma: 0.990000
Training fixed agent 7, please be patient, may be a while...
I0902 23:09:55.338735 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:09:55.440947 140527680751616 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:09:55.441330 140527680751616 replay_runner.py:41] Starting iteration 0
Steps executed: 143 Episode length: 143 Return: -142.0
INFO:tensorflow:Average training steps per second: 119.68

Steps executed: 497 Episode length: 354 Return: -353.0
I0902 23:10:04.845824 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -247.50
INFO:tensorflow:Starting iteration 1

Steps executed: 319 Episode length: 163 Return: -162.0
INFO:tensorflow:Average training steps per second: 193.30
I0902 23:10:10.244438 140527680751616 replay_runner.py:36] Average training steps per second: 193.30
I0902 23:10:10.547163 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.50
INFO:tensorflow:Starting iteration 2

Steps executed: 489 Episode length: 295 Return: -294.0
INFO:tensorflow:Average training steps per second: 192.35
I0902 23:10:16.003089 140527680751616 replay_runner.py:36] Average training steps per second: 192.35
I0902 23:10:16.367403 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.50
INFO:tensorflow:Starting iteration 3

Steps executed: 244 Episode length: 244 Return: -243.0
INFO:tensorflow:Average training steps per second: 182.33
I0902 23:10:22.087450 140527680751616 replay_runner.py:36] Average training steps per second: 182.33
I0902 23:10:22.305202 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.00
INFO:tensorflow:Starting iteration 4

Steps executed: 373 Episode length: 209 Return: -208.0
INFO:tensorflow:Average training steps per second: 201.82
I0902 23:10:27.517680 140527680751616 replay_runner.py:36] Average training steps per second: 201.82
I0902 23:10:27.864917 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.50
INFO:tensorflow:Starting iteration 5

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 185.13
I0902 23:10:33.500719 140527680751616 replay_runner.py:36] Average training steps per second: 185.13
I0902 23:10:33.904258 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6
I0902 23:10:34.143238 140527680751616 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 207.69
I0902 23:10:38.958857 140527680751616 replay_runner.py:36] Average training steps per second: 207.69
I0902 23:10:39.409629 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7
I0902 23:10:39.669582 140527680751616 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 190.39
I0902 23:10:44.922607 140527680751616 replay_runner.py:36] Average training steps per second: 190.39
I0902 23:10:45.340501 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 8

Steps executed: 615 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 206.52
I0902 23:10:50.409770 140527680751616 replay_runner.py:36] Average training steps per second: 206.52
I0902 23:10:50.949975 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.00
INFO:tensorflow:Starting iteration 9

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 195.16
I0902 23:10:56.315039 140527680751616 replay_runner.py:36] Average training steps per second: 195.16
I0902 23:10:56.715796 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 10

Steps executed: 245 Episode length: 76 Return: -75.0.0
INFO:tensorflow:Average training steps per second: 201.99
I0902 23:11:01.899344 140527680751616 replay_runner.py:36] Average training steps per second: 201.99
I0902 23:11:02.111805 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.67
INFO:tensorflow:Starting iteration 11
I0902 23:11:02.358193 140527680751616 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 196.89

Steps executed: 240 Episode length: 65 Return: -64.0.0
I0902 23:11:07.634639 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.00
INFO:tensorflow:Starting iteration 12

Steps executed: 200 Episode length: 75 Return: -74.0.0
INFO:tensorflow:Average training steps per second: 204.07
I0902 23:11:12.773304 140527680751616 replay_runner.py:36] Average training steps per second: 204.07
I0902 23:11:12.973811 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.00
INFO:tensorflow:Starting iteration 13

Steps executed: 253 Episode length: 78 Return: -77.0.0
INFO:tensorflow:Average training steps per second: 196.87
I0902 23:11:18.314904 140527680751616 replay_runner.py:36] Average training steps per second: 196.87
I0902 23:11:18.528717 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.33
INFO:tensorflow:Starting iteration 14

Steps executed: 250 Episode length: 79 Return: -78.0.0
INFO:tensorflow:Average training steps per second: 199.93
I0902 23:11:23.764803 140527680751616 replay_runner.py:36] Average training steps per second: 199.93
I0902 23:11:23.982432 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.33
INFO:tensorflow:Starting iteration 15

Steps executed: 221 Episode length: 112 Return: -111.0
INFO:tensorflow:Average training steps per second: 199.82
I0902 23:11:29.240143 140527680751616 replay_runner.py:36] Average training steps per second: 199.82
I0902 23:11:29.423883 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.50
INFO:tensorflow:Starting iteration 16

Steps executed: 253 Episode length: 86 Return: -85.0.0
INFO:tensorflow:Average training steps per second: 201.95
I0902 23:11:34.614650 140527680751616 replay_runner.py:36] Average training steps per second: 201.95
I0902 23:11:34.836595 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.33
INFO:tensorflow:Starting iteration 17

Steps executed: 203 Episode length: 93 Return: -92.0.0
INFO:tensorflow:Average training steps per second: 198.37
I0902 23:11:40.128836 140527680751616 replay_runner.py:36] Average training steps per second: 198.37
I0902 23:11:40.288529 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.50
INFO:tensorflow:Starting iteration 18


Steps executed: 335 Episode length: 179 Return: -178.0
INFO:tensorflow:Average training steps per second: 201.34
I0902 23:11:45.491132 140527680751616 replay_runner.py:36] Average training steps per second: 201.34
I0902 23:11:45.804175 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.67
INFO:tensorflow:Starting iteration 19
I0902 23:11:46.060628 140527680751616 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 196.79
I0902 23:11:51.142698 140527680751616 replay_runner.py:36] Average training steps per second: 196.79

Steps executed: 249 Episode length: 91 Return: -90.0.0
INFO:tensorflow:Starting iteration 20

Steps executed: 330 Episode length: 330 Return: -329.0
INFO:tensorflow:Average training steps per second: 195.51
I0902 23:11:56.686773 140527680751616 replay_runner.py:36] Average training steps per second: 195.51
I0902 23:11:56.986063 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.00
INFO:tensorflow:Starting iteration 21

Steps executed: 241 Episode length: 79 Return: -78.0.0
INFO:tensorflow:Average training steps per second: 198.31
I0902 23:12:02.263039 140527680751616 replay_runner.py:36] Average training steps per second: 198.31
I0902 23:12:02.454345 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.33
INFO:tensorflow:Starting iteration 22

Steps executed: 281 Episode length: 99 Return: -98.0.0
INFO:tensorflow:Average training steps per second: 198.84
I0902 23:12:07.730599 140527680751616 replay_runner.py:36] Average training steps per second: 198.84
I0902 23:12:07.986293 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.67
INFO:tensorflow:Starting iteration 23

Steps executed: 170 Episode length: 77 Return: -76.0.0
INFO:tensorflow:Average training steps per second: 202.71
I0902 23:12:13.173209 140527680751616 replay_runner.py:36] Average training steps per second: 202.71

Steps executed: 242 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Starting iteration 24

Steps executed: 264 Episode length: 74 Return: -73.0.0
INFO:tensorflow:Average training steps per second: 197.31
I0902 23:12:18.686483 140527680751616 replay_runner.py:36] Average training steps per second: 197.31
I0902 23:12:18.923897 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.00
INFO:tensorflow:Starting iteration 25

Steps executed: 222 Episode length: 74 Return: -73.0.0
INFO:tensorflow:Average training steps per second: 203.57
I0902 23:12:24.070985 140527680751616 replay_runner.py:36] Average training steps per second: 203.57
I0902 23:12:24.258444 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.00
INFO:tensorflow:Starting iteration 26
I0902 23:12:24.500146 140527680751616 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 196.49

Steps executed: 253 Episode length: 64 Return: -63.0.0
I0902 23:12:29.811268 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.50
INFO:tensorflow:Starting iteration 27

Steps executed: 234 Episode length: 73 Return: -72.0.0
INFO:tensorflow:Average training steps per second: 197.31
I0902 23:12:35.130057 140527680751616 replay_runner.py:36] Average training steps per second: 197.31
I0902 23:12:35.322830 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.00
INFO:tensorflow:Starting iteration 28

Steps executed: 275 Episode length: 87 Return: -86.0.0
INFO:tensorflow:Average training steps per second: 199.55
I0902 23:12:40.578816 140527680751616 replay_runner.py:36] Average training steps per second: 199.55
I0902 23:12:40.817367 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.67
INFO:tensorflow:Starting iteration 29
I0902 23:12:41.067281 140527680751616 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 210.38

Done fixed training!Episode length: 70 Return: -69.0.0
I0902 23:12:45.995076 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.00