Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0902 00:27:56.036164 139929824643072 run_experiment.py:549] Creating TrainRunner ...
I0902 00:27:56.044708 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:27:56.044856 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:27:56.044939 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:27:56.045008 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:27:56.045071 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0902 00:27:56.045155 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:27:56.045224 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:27:56.045376 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:27:56.045442 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:27:56.045508 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0902 00:27:56.045593 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:27:56.045666 139929824643072 dqn_agent.py:283] 	 seed: 1630542476044667
I0902 00:27:56.047491 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:27:56.047616 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:27:56.047739 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:27:56.047876 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:27:56.047976 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:27:56.048052 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:27:56.048148 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:27:56.048291 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:27:56.048398 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:27:56.076632 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:27:56.324986 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:27:56.336108 139929824643072 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:27:56.342557 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:27:56.342748 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:27:56.342869 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:27:56.342960 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:27:56.343019 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0902 00:27:56.343074 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:27:56.343154 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:27:56.343246 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:27:56.343410 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:27:56.343534 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0902 00:27:56.343612 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:27:56.343687 139929824643072 dqn_agent.py:283] 	 seed: 1630542476342520
I0902 00:27:56.345247 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:27:56.345362 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:27:56.345433 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:27:56.345496 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:27:56.345553 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:27:56.345648 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:27:56.345708 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:27:56.345785 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:27:56.345869 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:27:56.366652 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:27:56.380184 139929824643072 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:27:56.380335 139929824643072 replay_runner.py:41] Starting iteration 0
Steps executed: 235 Episode length: 125 Return: -380.32007394944054
INFO:tensorflow:Average training steps per second: 256.90
I0902 00:28:00.273111 139929824643072 replay_runner.py:36] Average training steps per second: 256.90
I0902 00:28:01.110520 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -355.34
INFO:tensorflow:Starting iteration 1

Steps executed: 284 Episode length: 182 Return: -578.11753778552114
INFO:tensorflow:Average training steps per second: 351.69
I0902 00:28:07.310879 139929824643072 replay_runner.py:36] Average training steps per second: 351.69
I0902 00:28:07.486946 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -519.13
INFO:tensorflow:Starting iteration 2
I0902 00:28:10.856701 139929824643072 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 350.72

Steps executed: 392 Episode length: 253 Return: -495.55667528878396
I0902 00:28:14.013474 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -417.45
INFO:tensorflow:Starting iteration 3

Steps executed: 339 Episode length: 339 Return: -604.80066599146946
INFO:tensorflow:Average training steps per second: 367.69
I0902 00:28:20.103379 139929824643072 replay_runner.py:36] Average training steps per second: 367.69
I0902 00:28:20.388175 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -604.80
INFO:tensorflow:Starting iteration 4

Steps executed: 192 Episode length: 192 Return: -101.11889401730971
INFO:tensorflow:Average training steps per second: 379.04

Steps executed: 1090 Episode length: 898 Return: 88.711625887867091
I0902 00:28:28.095746 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -6.20
INFO:tensorflow:Starting iteration 5
I0902 00:28:31.587476 139929824643072 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 366.55

Steps executed: 1000 Episode length: 1000 Return: -58.17098598335871
I0902 00:28:36.292337 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -58.17
INFO:tensorflow:Starting iteration 6

Steps executed: 1000 Episode length: 1000 Return: -119.80389734265884
INFO:tensorflow:Average training steps per second: 368.87
I0902 00:28:42.513669 139929824643072 replay_runner.py:36] Average training steps per second: 368.87
I0902 00:28:43.794018 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.80
INFO:tensorflow:Starting iteration 7

Steps executed: 740 Episode length: 740 Return: -352.6087217503008884
INFO:tensorflow:Average training steps per second: 353.38
I0902 00:28:50.140159 139929824643072 replay_runner.py:36] Average training steps per second: 353.38
I0902 00:28:51.251112 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.61
INFO:tensorflow:Starting iteration 8
I0902 00:28:54.685178 139929824643072 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 340.76

Steps executed: 1000 Episode length: 1000 Return: -112.53534194888164
I0902 00:28:59.728011 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.54
INFO:tensorflow:Starting iteration 9

Steps executed: 423 Episode length: 423 Return: -276.1235666415903164
INFO:tensorflow:Average training steps per second: 348.04
I0902 00:29:06.088956 139929824643072 replay_runner.py:36] Average training steps per second: 348.04
I0902 00:29:06.590599 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.12
INFO:tensorflow:Starting iteration 10

Steps executed: 588 Episode length: 588 Return: -261.9942059997340564
INFO:tensorflow:Average training steps per second: 326.33
I0902 00:29:13.043530 139929824643072 replay_runner.py:36] Average training steps per second: 326.33
I0902 00:29:13.746150 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.99
INFO:tensorflow:Starting iteration 11

Steps executed: 1000 Episode length: 1000 Return: -229.73120882969258
INFO:tensorflow:Average training steps per second: 322.24
I0902 00:29:20.137515 139929824643072 replay_runner.py:36] Average training steps per second: 322.24
I0902 00:29:21.700987 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.73
INFO:tensorflow:Starting iteration 12
I0902 00:29:24.931600 139929824643072 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 325.63

Steps executed: 575 Episode length: 575 Return: -260.3187546073278358
I0902 00:29:28.903723 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.32
INFO:tensorflow:Starting iteration 13

Steps executed: 309 Episode length: 185 Return: -95.77108678104915358
INFO:tensorflow:Average training steps per second: 338.36
I0902 00:29:35.249890 139929824643072 replay_runner.py:36] Average training steps per second: 338.36
I0902 00:29:35.437880 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.73
INFO:tensorflow:Starting iteration 14

Steps executed: 207 Episode length: 102 Return: -749.3984465658558358
INFO:tensorflow:Average training steps per second: 339.52
I0902 00:29:41.784300 139929824643072 replay_runner.py:36] Average training steps per second: 339.52
I0902 00:29:41.911291 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -762.31
INFO:tensorflow:Starting iteration 15
I0902 00:29:45.286350 139929824643072 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 338.79

Steps executed: 234 Episode length: 234 Return: -616.6317358457778358
I0902 00:29:48.405036 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -616.63
INFO:tensorflow:Starting iteration 16

Steps executed: 292 Episode length: 292 Return: -170.3379611720445458
INFO:tensorflow:Average training steps per second: 338.27
I0902 00:29:54.765308 139929824643072 replay_runner.py:36] Average training steps per second: 338.27
I0902 00:29:54.991428 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.34
INFO:tensorflow:Starting iteration 17

Steps executed: 406 Episode length: 406 Return: -233.4601104911273458
INFO:tensorflow:Average training steps per second: 329.09
I0902 00:30:01.447253 139929824643072 replay_runner.py:36] Average training steps per second: 329.09
I0902 00:30:01.887095 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.46
INFO:tensorflow:Starting iteration 18

Steps executed: 236 Episode length: 84 Return: -552.47744353153893458
INFO:tensorflow:Average training steps per second: 327.64
I0902 00:30:08.308814 139929824643072 replay_runner.py:36] Average training steps per second: 327.64
I0902 00:30:08.448349 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.48
INFO:tensorflow:Starting iteration 19

Steps executed: 241 Episode length: 128 Return: -535.4613070708926558
INFO:tensorflow:Average training steps per second: 320.56
I0902 00:30:14.871128 139929824643072 replay_runner.py:36] Average training steps per second: 320.56
I0902 00:30:15.012698 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -497.46
INFO:tensorflow:Starting iteration 20

Steps executed: 319 Episode length: 171 Return: -89.32318898909377258
INFO:tensorflow:Average training steps per second: 322.52
I0902 00:30:21.404216 139929824643072 replay_runner.py:36] Average training steps per second: 322.52
I0902 00:30:21.637711 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.58
INFO:tensorflow:Starting iteration 21

Steps executed: 247 Episode length: 71 Return: -227.12129635993165258
INFO:tensorflow:Average training steps per second: 330.71
I0902 00:30:27.973246 139929824643072 replay_runner.py:36] Average training steps per second: 330.71
I0902 00:30:28.117641 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.60
INFO:tensorflow:Starting iteration 22

Steps executed: 221 Episode length: 221 Return: -560.9714267493969258
INFO:tensorflow:Average training steps per second: 331.09
I0902 00:30:34.396035 139929824643072 replay_runner.py:36] Average training steps per second: 331.09
I0902 00:30:34.583817 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -560.97
INFO:tensorflow:Starting iteration 23

Steps executed: 263 Episode length: 141 Return: -193.5892762022197258
INFO:tensorflow:Average training steps per second: 345.22
I0902 00:30:40.735099 139929824643072 replay_runner.py:36] Average training steps per second: 345.22
I0902 00:30:40.894199 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.37
INFO:tensorflow:Starting iteration 24

Steps executed: 228 Episode length: 135 Return: -159.6352734662519358
INFO:tensorflow:Average training steps per second: 352.62
I0902 00:30:47.158726 139929824643072 replay_runner.py:36] Average training steps per second: 352.62
I0902 00:30:47.285119 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.16
INFO:tensorflow:Starting iteration 25

Steps executed: 288 Episode length: 124 Return: -242.9615853671148858
INFO:tensorflow:Average training steps per second: 340.10
I0902 00:30:53.633841 139929824643072 replay_runner.py:36] Average training steps per second: 340.10
I0902 00:30:53.792295 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.53
INFO:tensorflow:Starting iteration 26

Steps executed: 192 Episode length: 135 Return: -132.3883474509700658
INFO:tensorflow:Average training steps per second: 338.22
I0902 00:31:00.050652 139929824643072 replay_runner.py:36] Average training steps per second: 338.22

Steps executed: 310 Episode length: 118 Return: -67.08683819274793658
INFO:tensorflow:Starting iteration 27

Steps executed: 277 Episode length: 119 Return: -37.85164715435577458
INFO:tensorflow:Average training steps per second: 347.25
I0902 00:31:06.409211 139929824643072 replay_runner.py:36] Average training steps per second: 347.25
I0902 00:31:06.561165 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.77
INFO:tensorflow:Starting iteration 28

Steps executed: 283 Episode length: 142 Return: -41.62850742100865958
INFO:tensorflow:Average training steps per second: 345.79
I0902 00:31:12.740607 139929824643072 replay_runner.py:36] Average training steps per second: 345.79
I0902 00:31:12.908371 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.74
INFO:tensorflow:Starting iteration 29

Steps executed: 248 Episode length: 91 Return: -450.81124786196858658
INFO:tensorflow:Average training steps per second: 340.12
I0902 00:31:19.125996 139929824643072 replay_runner.py:36] Average training steps per second: 340.12

Done fixed training!Episode length: 91 Return: -450.81124786196858658