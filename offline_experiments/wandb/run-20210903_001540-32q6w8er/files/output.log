Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0903 00:15:46.192113 140457530894336 run_experiment.py:549] Creating TrainRunner ...
I0903 00:15:46.200350 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:15:46.200567 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:15:46.200772 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:15:46.200935 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:15:46.201016 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0903 00:15:46.201091 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:15:46.201195 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:15:46.201292 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:15:46.201428 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:15:46.201597 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0903 00:15:46.201718 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:15:46.201820 140457530894336 dqn_agent.py:283] 	 seed: 1630628146200284
I0903 00:15:46.204741 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:15:46.204907 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:15:46.205058 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:15:46.205145 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:15:46.205244 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:15:46.205314 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:15:46.205379 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:15:46.205456 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:15:46.205525 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:15:46.233990 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:15:46.507542 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:15:46.518462 140457530894336 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:15:46.526460 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:15:46.526737 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:15:46.526959 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:15:46.527060 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:15:46.527194 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0903 00:15:46.527289 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:15:46.527361 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:15:46.527484 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:15:46.527595 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:15:46.527802 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0903 00:15:46.527887 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:15:46.527978 140457530894336 dqn_agent.py:283] 	 seed: 1630628146526402
I0903 00:15:46.530138 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:15:46.530271 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:15:46.530397 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:15:46.530538 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:15:46.530745 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:15:46.530837 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:15:46.530912 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:15:46.530989 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:15:46.531060 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:15:46.553967 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:15:46.572762 140457530894336 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:15:46.572978 140457530894336 replay_runner.py:41] Starting iteration 0
Steps executed: 307 Episode length: 169 Return: -55.38109028251721
INFO:tensorflow:Average training steps per second: 245.12
I0903 00:15:50.652942 140457530894336 replay_runner.py:36] Average training steps per second: 245.12
I0903 00:15:51.425177 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.83
INFO:tensorflow:Starting iteration 1
I0903 00:15:54.829567 140457530894336 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 347.47

Steps executed: 277 Episode length: 143 Return: -580.88819445034971
I0903 00:15:57.908048 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -399.90
INFO:tensorflow:Starting iteration 2

Steps executed: 323 Episode length: 202 Return: -403.19566947628016
INFO:tensorflow:Average training steps per second: 355.91
I0903 00:16:04.233282 140457530894336 replay_runner.py:36] Average training steps per second: 355.91
I0903 00:16:04.435446 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -337.45
INFO:tensorflow:Starting iteration 3

Steps executed: 356 Episode length: 189 Return: -509.60083516402826
INFO:tensorflow:Average training steps per second: 342.01
I0903 00:16:10.833716 140457530894336 replay_runner.py:36] Average training steps per second: 342.01
I0903 00:16:11.072885 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -505.98
INFO:tensorflow:Starting iteration 4

Steps executed: 294 Episode length: 294 Return: -248.25436605123096
INFO:tensorflow:Average training steps per second: 329.40
I0903 00:16:17.525758 140457530894336 replay_runner.py:36] Average training steps per second: 329.40
I0903 00:16:17.739643 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.25
INFO:tensorflow:Starting iteration 5

Steps executed: 200 Episode length: 200 Return: -277.17377388104156
INFO:tensorflow:Average training steps per second: 330.08
I0903 00:16:24.222241 140457530894336 replay_runner.py:36] Average training steps per second: 330.08
I0903 00:16:24.352015 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.17
INFO:tensorflow:Starting iteration 6

Steps executed: 151 Episode length: 55 Return: -390.252876650786756
INFO:tensorflow:Average training steps per second: 338.56

Steps executed: 1151 Episode length: 1000 Return: -352.03415846939157
I0903 00:16:33.718617 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -357.38
INFO:tensorflow:Starting iteration 7
I0903 00:16:37.107928 140457530894336 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 335.15

Steps executed: 1000 Episode length: 1000 Return: -162.19083428454374
I0903 00:16:42.544976 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.19
INFO:tensorflow:Starting iteration 8
I0903 00:16:45.871415 140457530894336 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 315.68

Steps executed: 864 Episode length: 864 Return: -654.7576152880405374
I0903 00:16:50.219295 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -654.76
INFO:tensorflow:Starting iteration 9

Steps executed: 152 Episode length: 152 Return: -304.6378671609340474
INFO:tensorflow:Average training steps per second: 319.33

Steps executed: 1152 Episode length: 1000 Return: -52.250134428909374
I0903 00:16:58.781243 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.44
INFO:tensorflow:Starting iteration 10

Steps executed: 297 Episode length: 297 Return: -182.2283563443578574
INFO:tensorflow:Average training steps per second: 339.00
I0903 00:17:05.267160 140457530894336 replay_runner.py:36] Average training steps per second: 339.00
I0903 00:17:05.484400 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.23
INFO:tensorflow:Starting iteration 11

Steps executed: 224 Episode length: 170 Return: -183.3383913095224574
INFO:tensorflow:Average training steps per second: 349.50
I0903 00:17:11.887907 140457530894336 replay_runner.py:36] Average training steps per second: 349.50
I0903 00:17:12.012763 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.32
INFO:tensorflow:Starting iteration 12

Steps executed: 235 Episode length: 235 Return: -286.7461307720864574
INFO:tensorflow:Average training steps per second: 341.41
I0903 00:17:18.440387 140457530894336 replay_runner.py:36] Average training steps per second: 341.41
I0903 00:17:18.592575 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -286.75
INFO:tensorflow:Starting iteration 13
I0903 00:17:22.100319 140457530894336 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 348.05
I0903 00:17:24.973825 140457530894336 replay_runner.py:36] Average training steps per second: 348.05

Steps executed: 321 Episode length: 151 Return: -209.9324660840247874
INFO:tensorflow:Starting iteration 14

Steps executed: 371 Episode length: 317 Return: -178.4659878484737674
INFO:tensorflow:Average training steps per second: 341.46
I0903 00:17:31.576111 140457530894336 replay_runner.py:36] Average training steps per second: 341.46
I0903 00:17:31.899338 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.54
INFO:tensorflow:Starting iteration 15
I0903 00:17:35.311405 140457530894336 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 321.34

Steps executed: 273 Episode length: 87 Return: -234.22279914769555674
I0903 00:17:38.556654 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.46
INFO:tensorflow:Starting iteration 16

Steps executed: 246 Episode length: 64 Return: -153.92842518451164674
INFO:tensorflow:Average training steps per second: 334.13
I0903 00:17:44.861075 140457530894336 replay_runner.py:36] Average training steps per second: 334.13
I0903 00:17:44.996106 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -317.69
INFO:tensorflow:Starting iteration 17

Steps executed: 205 Episode length: 138 Return: -410.7711474935046674
INFO:tensorflow:Average training steps per second: 319.08
I0903 00:17:51.490500 140457530894336 replay_runner.py:36] Average training steps per second: 319.08
I0903 00:17:51.609982 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.53
INFO:tensorflow:Starting iteration 18

Steps executed: 265 Episode length: 81 Return: -465.26519043999136674
INFO:tensorflow:Average training steps per second: 298.60
I0903 00:17:58.221795 140457530894336 replay_runner.py:36] Average training steps per second: 298.60
I0903 00:17:58.367612 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -410.92
INFO:tensorflow:Starting iteration 19

Steps executed: 230 Episode length: 72 Return: -36.550903856643636674
INFO:tensorflow:Average training steps per second: 305.87
I0903 00:18:04.852365 140457530894336 replay_runner.py:36] Average training steps per second: 305.87
I0903 00:18:04.980148 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.50
INFO:tensorflow:Starting iteration 20

Steps executed: 205 Episode length: 62 Return: -144.62132792686882674
INFO:tensorflow:Average training steps per second: 305.19
I0903 00:18:11.466292 140457530894336 replay_runner.py:36] Average training steps per second: 305.19
I0903 00:18:11.562234 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.56
INFO:tensorflow:Starting iteration 21

Steps executed: 59 Episode length: 59 Return: -559.028911791322882674
INFO:tensorflow:Average training steps per second: 303.79
I0903 00:18:18.059075 140457530894336 replay_runner.py:36] Average training steps per second: 303.79

Steps executed: 257 Episode length: 67 Return: -306.70986367522452674
INFO:tensorflow:Starting iteration 22

Steps executed: 264 Episode length: 86 Return: -98.792278834406762674
INFO:tensorflow:Average training steps per second: 292.55
I0903 00:18:24.763334 140457530894336 replay_runner.py:36] Average training steps per second: 292.55
I0903 00:18:24.933285 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -374.60
INFO:tensorflow:Starting iteration 23

Steps executed: 208 Episode length: 87 Return: -654.09700647934312674
INFO:tensorflow:Average training steps per second: 302.48
I0903 00:18:31.416498 140457530894336 replay_runner.py:36] Average training steps per second: 302.48
I0903 00:18:31.546587 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -590.81
INFO:tensorflow:Starting iteration 24

Steps executed: 234 Episode length: 53 Return: -382.89320160471544674
INFO:tensorflow:Average training steps per second: 305.02
I0903 00:18:37.993396 140457530894336 replay_runner.py:36] Average training steps per second: 305.02
I0903 00:18:38.147129 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.24
INFO:tensorflow:Starting iteration 25

Steps executed: 278 Episode length: 80 Return: -866.94101316647115674
INFO:tensorflow:Average training steps per second: 313.42
I0903 00:18:44.527492 140457530894336 replay_runner.py:36] Average training steps per second: 313.42
I0903 00:18:44.697990 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -567.10
INFO:tensorflow:Starting iteration 26

Steps executed: 206 Episode length: 76 Return: -493.91196593948355674
INFO:tensorflow:Average training steps per second: 297.36
I0903 00:18:51.171067 140457530894336 replay_runner.py:36] Average training steps per second: 297.36
I0903 00:18:51.299407 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -546.51
INFO:tensorflow:Starting iteration 27

Steps executed: 214 Episode length: 70 Return: -673.74725847959745674
INFO:tensorflow:Average training steps per second: 324.08
I0903 00:18:57.473142 140457530894336 replay_runner.py:36] Average training steps per second: 324.08
I0903 00:18:57.625848 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -615.14
INFO:tensorflow:Starting iteration 28

Steps executed: 247 Episode length: 83 Return: -787.12400185608625674
INFO:tensorflow:Average training steps per second: 329.42
I0903 00:19:03.865896 140457530894336 replay_runner.py:36] Average training steps per second: 329.42
I0903 00:19:04.029767 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -708.45
INFO:tensorflow:Starting iteration 29
I0903 00:19:07.293278 140457530894336 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 317.09
I0903 00:19:10.447216 140457530894336 replay_runner.py:36] Average training steps per second: 317.09


Done fixed training!Episode length: 86 Return: -907.47765164454435674