Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0901 13:19:17.636596 140240877414400 run_experiment.py:549] Creating TrainRunner ...
I0901 13:19:17.644251 140240877414400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:19:17.644375 140240877414400 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:19:17.644461 140240877414400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:19:17.644534 140240877414400 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:19:17.644594 140240877414400 dqn_agent.py:275] 	 update_period: 4
I0901 13:19:17.644656 140240877414400 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:19:17.644741 140240877414400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:19:17.644804 140240877414400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:19:17.644903 140240877414400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:19:17.644989 140240877414400 dqn_agent.py:280] 	 optimizer: adam
I0901 13:19:17.645051 140240877414400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:19:17.645172 140240877414400 dqn_agent.py:283] 	 seed: 1630502357644220
I0901 13:19:17.647406 140240877414400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:19:17.647601 140240877414400 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:19:17.647728 140240877414400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:19:17.647815 140240877414400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:19:17.647914 140240877414400 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:19:17.648102 140240877414400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:19:17.648243 140240877414400 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:19:17.648327 140240877414400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:19:17.648400 140240877414400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:19:17.676805 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:17.931277 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:17.941419 140240877414400 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:19:17.949249 140240877414400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:19:17.949386 140240877414400 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:19:17.949467 140240877414400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:19:17.949527 140240877414400 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:19:17.949604 140240877414400 dqn_agent.py:275] 	 update_period: 4
I0901 13:19:17.949704 140240877414400 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:19:17.949768 140240877414400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:19:17.949826 140240877414400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:19:17.949885 140240877414400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:19:17.949947 140240877414400 dqn_agent.py:280] 	 optimizer: adam
I0901 13:19:17.950004 140240877414400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:19:17.950088 140240877414400 dqn_agent.py:283] 	 seed: 1630502357949217
I0901 13:19:17.951623 140240877414400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:19:17.951732 140240877414400 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:19:17.951801 140240877414400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:19:17.951861 140240877414400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:19:17.951917 140240877414400 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:19:17.952000 140240877414400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:19:17.952070 140240877414400 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:19:17.952137 140240877414400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:19:17.952204 140240877414400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:19:17.975362 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:17.992429 140240877414400 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:19:17.992604 140240877414400 replay_runner.py:41] Starting iteration 0
Steps executed: 216 Episode length: 124 Return: -424.46190657545446
INFO:tensorflow:Average training steps per second: 236.97
I0901 13:19:22.212726 140240877414400 replay_runner.py:36] Average training steps per second: 236.97
I0901 13:19:22.967080 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -434.96
INFO:tensorflow:Starting iteration 1

Steps executed: 245 Episode length: 166 Return: -65.350419186632546
INFO:tensorflow:Average training steps per second: 338.49
I0901 13:19:29.337649 140240877414400 replay_runner.py:36] Average training steps per second: 338.49
I0901 13:19:29.485617 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.12
INFO:tensorflow:Starting iteration 2

Steps executed: 208 Episode length: 123 Return: -268.38262911479486
INFO:tensorflow:Average training steps per second: 338.27
I0901 13:19:35.924221 140240877414400 replay_runner.py:36] Average training steps per second: 338.27
I0901 13:19:36.044588 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -295.45
INFO:tensorflow:Starting iteration 3

Steps executed: 201 Episode length: 119 Return: -47.150239913052326
INFO:tensorflow:Average training steps per second: 353.90
I0901 13:19:42.406795 140240877414400 replay_runner.py:36] Average training steps per second: 353.90
I0901 13:19:42.498457 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -172.74
INFO:tensorflow:Starting iteration 4

Steps executed: 206 Episode length: 82 Return: -130.088576234785695
INFO:tensorflow:Average training steps per second: 334.31
I0901 13:19:48.927434 140240877414400 replay_runner.py:36] Average training steps per second: 334.31
I0901 13:19:49.053490 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.47
INFO:tensorflow:Starting iteration 5
I0901 13:19:52.549802 140240877414400 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 356.73

Steps executed: 277 Episode length: 277 Return: 9.62969504146916295
I0901 13:19:55.589051 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.63
INFO:tensorflow:Starting iteration 6

Steps executed: 223 Episode length: 60 Return: -183.584383703960695
INFO:tensorflow:Average training steps per second: 348.63
I0901 13:20:01.994714 140240877414400 replay_runner.py:36] Average training steps per second: 348.63
I0901 13:20:02.092741 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.20
INFO:tensorflow:Starting iteration 7

Steps executed: 673 Episode length: 521 Return: -223.28199866968185
INFO:tensorflow:Average training steps per second: 333.28
I0901 13:20:08.515846 140240877414400 replay_runner.py:36] Average training steps per second: 333.28
I0901 13:20:09.151945 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.88
INFO:tensorflow:Starting iteration 8
I0901 13:20:12.589101 140240877414400 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 346.34

Steps executed: 838 Episode length: 685 Return: -131.36835240447869
I0901 13:20:16.694543 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.53
INFO:tensorflow:Starting iteration 9

Steps executed: 238 Episode length: 68 Return: -167.907695064106381
INFO:tensorflow:Average training steps per second: 354.27
I0901 13:20:23.052663 140240877414400 replay_runner.py:36] Average training steps per second: 354.27
I0901 13:20:23.161354 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.06
INFO:tensorflow:Starting iteration 10
I0901 13:20:26.727765 140240877414400 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 351.21

Steps executed: 359 Episode length: 246 Return: -149.88849603212255
I0901 13:20:29.827289 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.51
INFO:tensorflow:Starting iteration 11

Steps executed: 276 Episode length: 276 Return: -224.76253698422633
INFO:tensorflow:Average training steps per second: 344.30
I0901 13:20:36.239456 140240877414400 replay_runner.py:36] Average training steps per second: 344.30
I0901 13:20:36.422191 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.76
INFO:tensorflow:Starting iteration 12
I0901 13:20:39.890707 140240877414400 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 337.54

Steps executed: 1000 Episode length: 1000 Return: -365.82296485685316
I0901 13:20:44.274962 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -365.82
INFO:tensorflow:Starting iteration 13

Steps executed: 551 Episode length: 551 Return: -152.7389658123629216
INFO:tensorflow:Average training steps per second: 352.04
I0901 13:20:50.637208 140240877414400 replay_runner.py:36] Average training steps per second: 352.04
I0901 13:20:51.411331 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.74
INFO:tensorflow:Starting iteration 14
I0901 13:20:54.968444 140240877414400 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 349.07

Steps executed: 238 Episode length: 238 Return: -227.4935381113163216
I0901 13:20:58.005079 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.49
INFO:tensorflow:Starting iteration 15

Steps executed: 326 Episode length: 135 Return: -175.4323995609639216
INFO:tensorflow:Average training steps per second: 343.59
I0901 13:21:04.400863 140240877414400 replay_runner.py:36] Average training steps per second: 343.59
I0901 13:21:04.572487 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.51
INFO:tensorflow:Starting iteration 16
I0901 13:21:07.910984 140240877414400 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 319.13

Steps executed: 938 Episode length: 938 Return: -277.3797724899862216
I0901 13:21:12.665611 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.38
INFO:tensorflow:Starting iteration 17

Steps executed: 273 Episode length: 162 Return: -130.9065300635555516
INFO:tensorflow:Average training steps per second: 335.37
I0901 13:21:19.103749 140240877414400 replay_runner.py:36] Average training steps per second: 335.37
I0901 13:21:19.254365 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.67
INFO:tensorflow:Starting iteration 18

Steps executed: 214 Episode length: 79 Return: -123.32978926270486516
INFO:tensorflow:Average training steps per second: 325.71
I0901 13:21:25.757326 140240877414400 replay_runner.py:36] Average training steps per second: 325.71
I0901 13:21:25.860817 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.59
INFO:tensorflow:Starting iteration 19

Steps executed: 661 Episode length: 539 Return: -118.4043140022806116
INFO:tensorflow:Average training steps per second: 324.40
I0901 13:21:32.345759 140240877414400 replay_runner.py:36] Average training steps per second: 324.40
I0901 13:21:32.972044 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.78
INFO:tensorflow:Starting iteration 20
I0901 13:21:36.450719 140240877414400 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 326.06
I0901 13:21:39.517937 140240877414400 replay_runner.py:36] Average training steps per second: 326.06

Steps executed: 258 Episode length: 120 Return: -211.8891265420693316
INFO:tensorflow:Starting iteration 21
I0901 13:21:43.094103 140240877414400 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 336.20

Steps executed: 209 Episode length: 72 Return: -242.87160683246609316
I0901 13:21:46.188701 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.53
INFO:tensorflow:Starting iteration 22

Steps executed: 294 Episode length: 134 Return: -114.4395284290200616
INFO:tensorflow:Average training steps per second: 319.04
I0901 13:21:52.677712 140240877414400 replay_runner.py:36] Average training steps per second: 319.04
I0901 13:21:52.841889 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.55
INFO:tensorflow:Starting iteration 23

Steps executed: 205 Episode length: 53 Return: -241.89388241312143616
INFO:tensorflow:Average training steps per second: 323.10
I0901 13:21:59.277514 140240877414400 replay_runner.py:36] Average training steps per second: 323.10
I0901 13:21:59.393169 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.88
INFO:tensorflow:Starting iteration 24
I0901 13:22:02.696657 140240877414400 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 322.94
I0901 13:22:05.793751 140240877414400 replay_runner.py:36] Average training steps per second: 322.94

Steps executed: 336 Episode length: 166 Return: 14.055304978462559616
INFO:tensorflow:Starting iteration 25
I0901 13:22:09.386878 140240877414400 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 348.72
I0901 13:22:12.254820 140240877414400 replay_runner.py:36] Average training steps per second: 348.72

Steps executed: 976 Episode length: 976 Return: -657.8487081293822616
INFO:tensorflow:Starting iteration 26

Steps executed: 1000 Episode length: 1000 Return: -146.76746100047356
INFO:tensorflow:Average training steps per second: 353.19
I0901 13:22:20.260722 140240877414400 replay_runner.py:36] Average training steps per second: 353.19
I0901 13:22:21.616639 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.77
INFO:tensorflow:Starting iteration 27
I0901 13:22:24.986067 140240877414400 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 352.39

Steps executed: 348 Episode length: 235 Return: -351.0511854401932356
I0901 13:22:28.036813 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.02
INFO:tensorflow:Starting iteration 28

Steps executed: 201 Episode length: 60 Return: -155.09155242674512356
INFO:tensorflow:Average training steps per second: 350.19
I0901 13:22:34.341037 140240877414400 replay_runner.py:36] Average training steps per second: 350.19
I0901 13:22:34.440212 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.64
INFO:tensorflow:Starting iteration 29

Steps executed: 212 Episode length: 121 Return: -494.9526918297025356
INFO:tensorflow:Average training steps per second: 313.22
I0901 13:22:40.981731 140240877414400 replay_runner.py:36] Average training steps per second: 313.22

Done fixed training!Episode length: 121 Return: -494.9526918297025356