I0902 00:19:35.453797 140413705484288 run_experiment.py:549] Creating TrainRunner ...
I0902 00:19:35.465020 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:19:35.465225 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:19:35.465411 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:19:35.465539 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:19:35.465653 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0902 00:19:35.465768 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:19:35.465882 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:19:35.466046 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:19:35.466186 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:19:35.466331 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0902 00:19:35.466444 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:19:35.466603 140413705484288 dqn_agent.py:283] 	 seed: 1630541975464966
I0902 00:19:35.469648 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:19:35.469818 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:19:35.469970 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:19:35.470092 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:19:35.470228 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:19:35.470383 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:19:35.470509 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:19:35.470675 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:19:35.470827 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:19:35.507150 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:35.787515 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:35.796646 140413705484288 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:19:35.803707 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:19:35.803863 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:19:35.803982 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:19:35.804051 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:19:35.804113 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0902 00:19:35.804198 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:19:35.804334 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:19:35.804414 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:19:35.804497 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:19:35.804570 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0902 00:19:35.804644 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:19:35.804726 140413705484288 dqn_agent.py:283] 	 seed: 1630541975803671
I0902 00:19:35.806411 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:19:35.806543 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:19:35.806620 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:19:35.806700 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:19:35.806766 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:19:35.806849 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:19:35.806911 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:19:35.806988 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:19:35.807079 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:19:35.827538 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:35.842359 140413705484288 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:19:35.842513 140413705484288 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 270.30
I0902 00:19:39.542217 140413705484288 replay_runner.py:36] Average training steps per second: 270.30
I0902 00:19:40.360874 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -416.76
Steps executed: 274 Episode length: 102 Return: -268.1867226997782
INFO:tensorflow:Starting iteration 1

Steps executed: 287 Episode length: 178 Return: -509.5491581673764
INFO:tensorflow:Average training steps per second: 377.04
I0902 00:19:46.230813 140413705484288 replay_runner.py:36] Average training steps per second: 377.04
I0902 00:19:46.395095 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -463.02
INFO:tensorflow:Starting iteration 2

Steps executed: 209 Episode length: 209 Return: -266.5900444827581
INFO:tensorflow:Average training steps per second: 347.01
I0902 00:19:52.714075 140413705484288 replay_runner.py:36] Average training steps per second: 347.01
I0902 00:19:52.878331 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.59
INFO:tensorflow:Starting iteration 3

Steps executed: 358 Episode length: 358 Return: -435.19589138927137
INFO:tensorflow:Average training steps per second: 348.00
I0902 00:19:59.194965 140413705484288 replay_runner.py:36] Average training steps per second: 348.00
I0902 00:19:59.606656 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -435.20
INFO:tensorflow:Starting iteration 4
I0902 00:20:03.000219 140413705484288 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 350.32

Steps executed: 1000 Episode length: 1000 Return: -77.2863133311409
I0902 00:20:07.546233 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.29
INFO:tensorflow:Starting iteration 5
I0902 00:20:10.869299 140413705484288 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 342.68
I0902 00:20:13.788491 140413705484288 replay_runner.py:36] Average training steps per second: 342.68

Steps executed: 1000 Episode length: 1000 Return: -35.98924901485919
INFO:tensorflow:Starting iteration 6
I0902 00:20:18.590837 140413705484288 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 339.21

Steps executed: 1000 Episode length: 1000 Return: -125.57483802138503
I0902 00:20:24.233534 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.57
INFO:tensorflow:Starting iteration 7
I0902 00:20:27.565831 140413705484288 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 352.14

Steps executed: 1000 Episode length: 1000 Return: -28.122955037339004
I0902 00:20:32.983788 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -28.12
INFO:tensorflow:Starting iteration 8
I0902 00:20:36.311140 140413705484288 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 353.14

Steps executed: 1000 Episode length: 1000 Return: -117.66629269554254
I0902 00:20:41.139685 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.67
INFO:tensorflow:Starting iteration 9
I0902 00:20:44.325505 140413705484288 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 330.63

Steps executed: 1000 Episode length: 1000 Return: -67.037068845427484
I0902 00:20:49.262542 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -67.04
INFO:tensorflow:Starting iteration 10
I0902 00:20:52.440299 140413705484288 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 337.15

Steps executed: 1000 Episode length: 1000 Return: -60.014308637678984
I0902 00:20:57.280226 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -60.01
INFO:tensorflow:Starting iteration 11
I0902 00:21:00.431568 140413705484288 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 339.97

Steps executed: 1000 Episode length: 1000 Return: -155.20279742133064
I0902 00:21:05.042317 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.20
INFO:tensorflow:Starting iteration 12
I0902 00:21:08.263043 140413705484288 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 329.19

Steps executed: 353 Episode length: 353 Return: -255.6686509420167064
I0902 00:21:11.695487 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.67
INFO:tensorflow:Starting iteration 13
I0902 00:21:14.818353 140413705484288 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 345.42

Steps executed: 1000 Episode length: 1000 Return: -119.82403500517631
I0902 00:21:19.794510 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.82
INFO:tensorflow:Starting iteration 14

Steps executed: 750 Episode length: 750 Return: -188.7649124448163331
INFO:tensorflow:Average training steps per second: 340.14
I0902 00:21:25.809793 140413705484288 replay_runner.py:36] Average training steps per second: 340.14
I0902 00:21:27.062792 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.76
INFO:tensorflow:Starting iteration 15

Steps executed: 276 Episode length: 276 Return: -63.33184699220575531
INFO:tensorflow:Average training steps per second: 327.75
I0902 00:21:33.299269 140413705484288 replay_runner.py:36] Average training steps per second: 327.75
I0902 00:21:33.551835 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -63.33
INFO:tensorflow:Starting iteration 16
I0902 00:21:36.904688 140413705484288 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 348.99
I0902 00:21:39.770417 140413705484288 replay_runner.py:36] Average training steps per second: 348.99

Steps executed: 1000 Episode length: 1000 Return: -65.700359065611541
INFO:tensorflow:Starting iteration 17

Steps executed: 1000 Episode length: 1000 Return: 127.807786052255121
INFO:tensorflow:Average training steps per second: 341.22
I0902 00:21:48.123919 140413705484288 replay_runner.py:36] Average training steps per second: 341.22
I0902 00:21:49.701876 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: 127.81
INFO:tensorflow:Starting iteration 18

Steps executed: 337 Episode length: 337 Return: -390.7859197759323121
INFO:tensorflow:Average training steps per second: 348.48
I0902 00:21:55.956046 140413705484288 replay_runner.py:36] Average training steps per second: 348.48
I0902 00:21:56.293705 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -390.79
INFO:tensorflow:Starting iteration 19

Steps executed: 241 Episode length: 241 Return: -1120.232829345026921
INFO:tensorflow:Average training steps per second: 336.14
I0902 00:22:02.639006 140413705484288 replay_runner.py:36] Average training steps per second: 336.14
I0902 00:22:02.828761 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -1120.23
INFO:tensorflow:Starting iteration 20

Steps executed: 231 Episode length: 66 Return: -92.336347656869916921
INFO:tensorflow:Average training steps per second: 336.97
I0902 00:22:09.108383 140413705484288 replay_runner.py:36] Average training steps per second: 336.97
I0902 00:22:09.259419 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -3.52
INFO:tensorflow:Starting iteration 21
I0902 00:22:12.604999 140413705484288 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 341.26

Steps executed: 424 Episode length: 230 Return: -205.6870111659212721
I0902 00:22:15.839523 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.46
INFO:tensorflow:Starting iteration 22

Steps executed: 339 Episode length: 175 Return: -31.73061704600331721
INFO:tensorflow:Average training steps per second: 356.38
I0902 00:22:21.981921 140413705484288 replay_runner.py:36] Average training steps per second: 356.38
I0902 00:22:22.218791 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -30.67
INFO:tensorflow:Starting iteration 23

Steps executed: 325 Episode length: 325 Return: 39.952381147288065721
INFO:tensorflow:Average training steps per second: 356.82
I0902 00:22:28.456802 140413705484288 replay_runner.py:36] Average training steps per second: 356.82
I0902 00:22:28.750970 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: 39.95
INFO:tensorflow:Starting iteration 24

Steps executed: 202 Episode length: 202 Return: -99.18994232060987721
INFO:tensorflow:Average training steps per second: 358.75
I0902 00:22:34.979569 140413705484288 replay_runner.py:36] Average training steps per second: 358.75
I0902 00:22:35.123305 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.19
INFO:tensorflow:Starting iteration 25

Steps executed: 96 Episode length: 96 Return: -270.720398378588477721
INFO:tensorflow:Average training steps per second: 345.53
I0902 00:22:41.338327 140413705484288 replay_runner.py:36] Average training steps per second: 345.53

Steps executed: 296 Episode length: 200 Return: -263.7465727045303721
INFO:tensorflow:Starting iteration 26

Steps executed: 354 Episode length: 354 Return: -254.5078381087624621
INFO:tensorflow:Average training steps per second: 344.19
I0902 00:22:47.769841 140413705484288 replay_runner.py:36] Average training steps per second: 344.19
I0902 00:22:48.159201 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.51
INFO:tensorflow:Starting iteration 27

Steps executed: 235 Episode length: 235 Return: -234.5281873158148521
INFO:tensorflow:Average training steps per second: 368.95
I0902 00:22:54.265293 140413705484288 replay_runner.py:36] Average training steps per second: 368.95
I0902 00:22:54.471413 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.53
INFO:tensorflow:Starting iteration 28

Steps executed: 231 Episode length: 118 Return: -63.78303950082072521
INFO:tensorflow:Average training steps per second: 375.84
I0902 00:23:00.665540 140413705484288 replay_runner.py:36] Average training steps per second: 375.84
I0902 00:23:00.799205 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.82
INFO:tensorflow:Starting iteration 29

Steps executed: 444 Episode length: 356 Return: -408.7032235849084721
INFO:tensorflow:Average training steps per second: 348.02
I0902 00:23:07.112095 140413705484288 replay_runner.py:36] Average training steps per second: 348.02

Done fixed training!Episode length: 356 Return: -408.7032235849084721