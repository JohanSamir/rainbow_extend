Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0828 10:37:30.895246 139821415028736 run_experiment.py:549] Creating TrainRunner ...
I0828 10:37:30.904922 139821415028736 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:30.905107 139821415028736 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:30.905390 139821415028736 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:30.905527 139821415028736 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:30.905594 139821415028736 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:30.905674 139821415028736 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:37:30.905765 139821415028736 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:30.905830 139821415028736 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:30.905883 139821415028736 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:30.905938 139821415028736 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:30.905991 139821415028736 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:30.906086 139821415028736 dqn_agent.py:283] 	 seed: 1630147050904876
I0828 10:37:30.909439 139821415028736 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:30.909685 139821415028736 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:37:30.909856 139821415028736 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:30.909969 139821415028736 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:30.910067 139821415028736 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:30.910182 139821415028736 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:30.910276 139821415028736 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:30.910382 139821415028736 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:30.910485 139821415028736 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:30.942582 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:31.608415 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:31.622306 139821415028736 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:37:31.629518 139821415028736 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:31.629685 139821415028736 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:31.629760 139821415028736 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:31.629838 139821415028736 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:31.629947 139821415028736 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:31.630042 139821415028736 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:37:31.630206 139821415028736 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:31.630377 139821415028736 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:31.630537 139821415028736 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:31.630715 139821415028736 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:31.630948 139821415028736 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:31.631241 139821415028736 dqn_agent.py:283] 	 seed: 1630147051629479
I0828 10:37:31.633890 139821415028736 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:31.634054 139821415028736 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:37:31.634185 139821415028736 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:31.634257 139821415028736 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:31.634370 139821415028736 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:31.634476 139821415028736 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:31.634606 139821415028736 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:31.634757 139821415028736 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:31.634937 139821415028736 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:31.662624 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:31.683201 139821415028736 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:37:31.683423 139821415028736 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 172.18
I0828 10:37:37.491329 139821415028736 replay_runner.py:36] Average training steps per second: 172.18
Steps executed: 202 Episode length: 57 Return: -429.2691216852465
I0828 10:37:38.712616 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -571.85
INFO:tensorflow:Starting iteration 1

Steps executed: 237 Episode length: 77 Return: -265.07048918647996
INFO:tensorflow:Average training steps per second: 229.19
I0828 10:37:47.281708 139821415028736 replay_runner.py:36] Average training steps per second: 229.19
I0828 10:37:47.520126 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -246.04
INFO:tensorflow:Starting iteration 2

Steps executed: 278 Episode length: 86 Return: -290.17081810795836
INFO:tensorflow:Average training steps per second: 230.68
I0828 10:37:56.189811 139821415028736 replay_runner.py:36] Average training steps per second: 230.68
I0828 10:37:56.414181 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -378.21
INFO:tensorflow:Starting iteration 3

Steps executed: 211 Episode length: 78 Return: -573.60181021367866
INFO:tensorflow:Average training steps per second: 229.28
I0828 10:38:05.105896 139821415028736 replay_runner.py:36] Average training steps per second: 229.28
I0828 10:38:05.278425 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -526.52
INFO:tensorflow:Starting iteration 4

Steps executed: 245 Episode length: 70 Return: -546.30963716341696
INFO:tensorflow:Average training steps per second: 232.17
I0828 10:38:14.000207 139821415028736 replay_runner.py:36] Average training steps per second: 232.17
I0828 10:38:14.210311 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -481.34
INFO:tensorflow:Starting iteration 5
I0828 10:38:18.513865 139821415028736 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 232.22

Steps executed: 221 Episode length: 87 Return: -399.83720476126796
I0828 10:38:23.018057 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -434.44
INFO:tensorflow:Starting iteration 6

Steps executed: 277 Episode length: 80 Return: -324.765197482584774
INFO:tensorflow:Average training steps per second: 233.12
I0828 10:38:31.644180 139821415028736 replay_runner.py:36] Average training steps per second: 233.12
I0828 10:38:31.864948 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -396.09
INFO:tensorflow:Starting iteration 7

Steps executed: 279 Episode length: 86 Return: -968.759482034708274
INFO:tensorflow:Average training steps per second: 229.13
I0828 10:38:40.606349 139821415028736 replay_runner.py:36] Average training steps per second: 229.13
I0828 10:38:40.858963 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -628.95
INFO:tensorflow:Starting iteration 8

Steps executed: 229 Episode length: 65 Return: -135.227656694755724
INFO:tensorflow:Average training steps per second: 225.42
I0828 10:38:49.753141 139821415028736 replay_runner.py:36] Average training steps per second: 225.42
I0828 10:38:49.925618 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.09
INFO:tensorflow:Starting iteration 9

Steps executed: 216 Episode length: 67 Return: -628.865002949729324
INFO:tensorflow:Average training steps per second: 228.33
I0828 10:38:58.593116 139821415028736 replay_runner.py:36] Average training steps per second: 228.33
I0828 10:38:58.778928 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -621.94
INFO:tensorflow:Starting iteration 10

Steps executed: 229 Episode length: 80 Return: -587.858932590877524
INFO:tensorflow:Average training steps per second: 227.64
I0828 10:39:07.607298 139821415028736 replay_runner.py:36] Average training steps per second: 227.64
I0828 10:39:07.809896 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -546.46
INFO:tensorflow:Starting iteration 11

Steps executed: 262 Episode length: 63 Return: -434.726122441929354
INFO:tensorflow:Average training steps per second: 238.59
I0828 10:39:16.369007 139821415028736 replay_runner.py:36] Average training steps per second: 238.59
I0828 10:39:16.619455 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -512.98
INFO:tensorflow:Starting iteration 12

Steps executed: 202 Episode length: 79 Return: -552.258022005556154
INFO:tensorflow:Average training steps per second: 235.35
I0828 10:39:25.313150 139821415028736 replay_runner.py:36] Average training steps per second: 235.35
I0828 10:39:25.486835 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -599.42
INFO:tensorflow:Starting iteration 13

Steps executed: 207 Episode length: 101 Return: -720.27751500935794
INFO:tensorflow:Average training steps per second: 240.73
I0828 10:39:33.919456 139821415028736 replay_runner.py:36] Average training steps per second: 240.73
I0828 10:39:34.110795 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -729.06
INFO:tensorflow:Starting iteration 14
I0828 10:39:38.507938 139821415028736 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 230.38
I0828 10:39:42.849265 139821415028736 replay_runner.py:36] Average training steps per second: 230.38

Steps executed: 215 Episode length: 67 Return: -558.339969999427194
INFO:tensorflow:Starting iteration 15

Steps executed: 269 Episode length: 104 Return: -552.24773406366194
INFO:tensorflow:Average training steps per second: 229.13
I0828 10:39:51.749967 139821415028736 replay_runner.py:36] Average training steps per second: 229.13
I0828 10:39:51.993706 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -431.84
INFO:tensorflow:Starting iteration 16

Steps executed: 164 Episode length: 89 Return: -383.602401940735594
INFO:tensorflow:Average training steps per second: 231.97
I0828 10:40:00.650395 139821415028736 replay_runner.py:36] Average training steps per second: 231.97

Steps executed: 242 Episode length: 78 Return: -491.502154671988544
INFO:tensorflow:Starting iteration 17

Steps executed: 204 Episode length: 75 Return: -484.679934343496444
INFO:tensorflow:Average training steps per second: 233.80
I0828 10:40:09.630427 139821415028736 replay_runner.py:36] Average training steps per second: 233.80
I0828 10:40:09.800107 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -501.46
INFO:tensorflow:Starting iteration 18

Steps executed: 217 Episode length: 89 Return: -644.159275868902474
INFO:tensorflow:Average training steps per second: 241.51
I0828 10:40:18.248825 139821415028736 replay_runner.py:36] Average training steps per second: 241.51
I0828 10:40:18.437856 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -542.42
INFO:tensorflow:Starting iteration 19

Steps executed: 211 Episode length: 211 Return: -1970.5725863318314
INFO:tensorflow:Average training steps per second: 230.56
I0828 10:40:27.155226 139821415028736 replay_runner.py:36] Average training steps per second: 230.56
I0828 10:40:27.378036 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -1970.57
INFO:tensorflow:Starting iteration 20

Steps executed: 211 Episode length: 83 Return: -739.351733559064214
INFO:tensorflow:Average training steps per second: 228.77
I0828 10:40:35.943387 139821415028736 replay_runner.py:36] Average training steps per second: 228.77
I0828 10:40:36.144885 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -652.37
INFO:tensorflow:Starting iteration 21
I0828 10:40:40.602422 139821415028736 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 225.98

Steps executed: 237 Episode length: 125 Return: -432.11717628107944
I0828 10:40:45.268443 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -494.82
INFO:tensorflow:Starting iteration 22

Steps executed: 212 Episode length: 54 Return: -491.080623199719074
INFO:tensorflow:Average training steps per second: 225.79
I0828 10:40:53.987956 139821415028736 replay_runner.py:36] Average training steps per second: 225.79
I0828 10:40:54.176237 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.90
INFO:tensorflow:Starting iteration 23

Steps executed: 145 Episode length: 145 Return: -389.95895630924414
INFO:tensorflow:Average training steps per second: 230.62
I0828 10:41:02.942248 139821415028736 replay_runner.py:36] Average training steps per second: 230.62

Steps executed: 252 Episode length: 107 Return: -219.73645025276664
INFO:tensorflow:Starting iteration 24

Steps executed: 278 Episode length: 122 Return: -649.41483822159664
INFO:tensorflow:Average training steps per second: 226.93
I0828 10:41:12.069569 139821415028736 replay_runner.py:36] Average training steps per second: 226.93
I0828 10:41:12.325477 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -608.77
INFO:tensorflow:Starting iteration 25

Steps executed: 87 Episode length: 87 Return: -550.4498216415692664
INFO:tensorflow:Average training steps per second: 228.49
I0828 10:41:21.120473 139821415028736 replay_runner.py:36] Average training steps per second: 228.49

Steps executed: 252 Episode length: 165 Return: -625.33324409204034
INFO:tensorflow:Starting iteration 26

Steps executed: 304 Episode length: 120 Return: -1007.4221029594272
INFO:tensorflow:Average training steps per second: 224.77
I0828 10:41:30.189637 139821415028736 replay_runner.py:36] Average training steps per second: 224.77
I0828 10:41:30.466122 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -650.08
INFO:tensorflow:Starting iteration 27
I0828 10:41:34.955206 139821415028736 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 227.55

Steps executed: 353 Episode length: 157 Return: -357.14010492581222
I0828 10:41:39.657845 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.79
INFO:tensorflow:Starting iteration 28

Steps executed: 226 Episode length: 73 Return: -386.006051280559232
INFO:tensorflow:Average training steps per second: 231.37
I0828 10:41:48.439414 139821415028736 replay_runner.py:36] Average training steps per second: 231.37
I0828 10:41:48.645201 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -450.23
INFO:tensorflow:Starting iteration 29

Steps executed: 54 Episode length: 54 Return: -470.0393302318624232
INFO:tensorflow:Average training steps per second: 229.90
I0828 10:41:57.414261 139821415028736 replay_runner.py:36] Average training steps per second: 229.90


Done fixed training!Episode length: 70 Return: -448.944676058982742