Loaded trained dqn in acrobot
Training fixed agent 7, please be patient, may be a while...
I0828 10:34:08.674611 140659155802112 run_experiment.py:549] Creating TrainRunner ...
I0828 10:34:08.684114 140659155802112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:34:08.684354 140659155802112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:34:08.684478 140659155802112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:34:08.684573 140659155802112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:34:08.684660 140659155802112 dqn_agent.py:275] 	 update_period: 4
I0828 10:34:08.684751 140659155802112 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:34:08.684846 140659155802112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:34:08.684936 140659155802112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:34:08.685029 140659155802112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:34:08.685125 140659155802112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:34:08.685222 140659155802112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:34:08.685312 140659155802112 dqn_agent.py:283] 	 seed: 1630146848684059
I0828 10:34:08.688029 140659155802112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:34:08.688230 140659155802112 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:34:08.688371 140659155802112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:34:08.688482 140659155802112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:34:08.688607 140659155802112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:34:08.688720 140659155802112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:34:08.688819 140659155802112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:34:08.688926 140659155802112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:34:08.689031 140659155802112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:34:08.726621 140659155802112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:34:09.126466 140659155802112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:34:09.139904 140659155802112 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:34:09.147320 140659155802112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:34:09.147490 140659155802112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:34:09.147621 140659155802112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:34:09.147685 140659155802112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:34:09.147802 140659155802112 dqn_agent.py:275] 	 update_period: 4
I0828 10:34:09.147914 140659155802112 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:34:09.147986 140659155802112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:34:09.148063 140659155802112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:34:09.148142 140659155802112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:34:09.148225 140659155802112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:34:09.148364 140659155802112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:34:09.148515 140659155802112 dqn_agent.py:283] 	 seed: 1630146849147280
I0828 10:34:09.151350 140659155802112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:34:09.151623 140659155802112 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:34:09.151788 140659155802112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:34:09.151938 140659155802112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:34:09.152050 140659155802112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:34:09.152130 140659155802112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:34:09.152278 140659155802112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:34:09.152460 140659155802112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:34:09.152548 140659155802112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:34:09.223469 140659155802112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:34:09.246563 140659155802112 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:34:09.246853 140659155802112 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 147.13
I0828 10:34:16.044018 140659155802112 replay_runner.py:36] Average training steps per second: 147.13
Steps executed: 500 Episode length: 500 Return: -500.0
I0828 10:34:17.437285 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1

Steps executed: 693 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 195.81
I0828 10:34:22.776670 140659155802112 replay_runner.py:36] Average training steps per second: 195.81
I0828 10:34:23.393234 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.00
INFO:tensorflow:Starting iteration 2

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 204.15
I0828 10:34:28.539003 140659155802112 replay_runner.py:36] Average training steps per second: 204.15
I0828 10:34:28.964179 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 3
I0828 10:34:29.208022 140659155802112 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 191.22
I0828 10:34:34.438100 140659155802112 replay_runner.py:36] Average training steps per second: 191.22
I0828 10:34:34.841195 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 4

Steps executed: 198 Episode length: 85 Return: -84.0.0
INFO:tensorflow:Average training steps per second: 198.84
I0828 10:34:40.106970 140659155802112 replay_runner.py:36] Average training steps per second: 198.84

Steps executed: 364 Episode length: 166 Return: -165.0
INFO:tensorflow:Starting iteration 5

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 194.86
I0828 10:34:45.796272 140659155802112 replay_runner.py:36] Average training steps per second: 194.86
I0828 10:34:46.181592 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6
I0828 10:34:46.408217 140659155802112 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 190.53
I0828 10:34:51.657212 140659155802112 replay_runner.py:36] Average training steps per second: 190.53
I0828 10:34:52.053249 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7

Steps executed: 479 Episode length: 479 Return: -478.0
INFO:tensorflow:Average training steps per second: 199.85
I0828 10:34:57.305238 140659155802112 replay_runner.py:36] Average training steps per second: 199.85
I0828 10:34:57.728627 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -478.00
INFO:tensorflow:Starting iteration 8

Steps executed: 240 Episode length: 94 Return: -93.0.0
INFO:tensorflow:Average training steps per second: 193.37
I0828 10:35:03.152652 140659155802112 replay_runner.py:36] Average training steps per second: 193.37
I0828 10:35:03.336421 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.00
INFO:tensorflow:Starting iteration 9

Steps executed: 212 Episode length: 125 Return: -124.0
INFO:tensorflow:Average training steps per second: 194.41
I0828 10:35:08.713811 140659155802112 replay_runner.py:36] Average training steps per second: 194.41
I0828 10:35:08.936580 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.00
INFO:tensorflow:Starting iteration 10

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 199.17
I0828 10:35:14.218287 140659155802112 replay_runner.py:36] Average training steps per second: 199.17
I0828 10:35:14.632363 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 11
I0828 10:35:14.886517 140659155802112 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 191.10
I0828 10:35:20.120085 140659155802112 replay_runner.py:36] Average training steps per second: 191.10
I0828 10:35:20.534802 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 12

Steps executed: 276 Episode length: 100 Return: -99.00
INFO:tensorflow:Average training steps per second: 198.74
I0828 10:35:25.797834 140659155802112 replay_runner.py:36] Average training steps per second: 198.74
I0828 10:35:26.041799 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.00
INFO:tensorflow:Starting iteration 13

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 198.54
I0828 10:35:31.326146 140659155802112 replay_runner.py:36] Average training steps per second: 198.54
I0828 10:35:31.725527 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 14
I0828 10:35:31.963108 140659155802112 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 191.74
I0828 10:35:37.179030 140659155802112 replay_runner.py:36] Average training steps per second: 191.74
I0828 10:35:37.646085 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 15

Steps executed: 256 Episode length: 77 Return: -76.0.0
INFO:tensorflow:Average training steps per second: 192.48
I0828 10:35:43.069952 140659155802112 replay_runner.py:36] Average training steps per second: 192.48
I0828 10:35:43.308572 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.33
INFO:tensorflow:Starting iteration 16
I0828 10:35:43.556437 140659155802112 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 193.01
I0828 10:35:48.738029 140659155802112 replay_runner.py:36] Average training steps per second: 193.01

Steps executed: 262 Episode length: 71 Return: -70.0.0
INFO:tensorflow:Starting iteration 17

Steps executed: 181 Episode length: 81 Return: -80.000
INFO:tensorflow:Average training steps per second: 193.02

Steps executed: 277 Episode length: 96 Return: -95.000
I0828 10:35:54.611557 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.33
INFO:tensorflow:Starting iteration 18

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 201.06
I0828 10:35:59.834363 140659155802112 replay_runner.py:36] Average training steps per second: 201.06
I0828 10:36:00.229265 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 19
I0828 10:36:00.463243 140659155802112 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 190.53
I0828 10:36:05.712241 140659155802112 replay_runner.py:36] Average training steps per second: 190.53
I0828 10:36:06.107575 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 20

Steps executed: 256 Episode length: 71 Return: -70.0.0
INFO:tensorflow:Average training steps per second: 202.02
I0828 10:36:11.289148 140659155802112 replay_runner.py:36] Average training steps per second: 202.02
I0828 10:36:11.511093 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.33
INFO:tensorflow:Starting iteration 21

Steps executed: 119 Episode length: 119 Return: -118.0
INFO:tensorflow:Average training steps per second: 204.97

Steps executed: 619 Episode length: 500 Return: -500.0
I0828 10:36:17.131794 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.00
INFO:tensorflow:Starting iteration 22
I0828 10:36:17.365052 140659155802112 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 194.70

Steps executed: 500 Episode length: 500 Return: -500.0
I0828 10:36:22.932692 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 23
I0828 10:36:23.174971 140659155802112 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 210.79
I0828 10:36:27.919374 140659155802112 replay_runner.py:36] Average training steps per second: 210.79
I0828 10:36:28.321038 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 24
I0828 10:36:28.561756 140659155802112 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 205.97
I0828 10:36:33.417322 140659155802112 replay_runner.py:36] Average training steps per second: 205.97
I0828 10:36:33.791391 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 25

Steps executed: 390 Episode length: 390 Return: -389.0
INFO:tensorflow:Average training steps per second: 198.31
I0828 10:36:39.057721 140659155802112 replay_runner.py:36] Average training steps per second: 198.31
I0828 10:36:39.385994 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -389.00
INFO:tensorflow:Starting iteration 26

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 209.18
I0828 10:36:44.415887 140659155802112 replay_runner.py:36] Average training steps per second: 209.18
I0828 10:36:44.831597 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 27

Steps executed: 269 Episode length: 93 Return: -92.0.0
INFO:tensorflow:Average training steps per second: 196.25
I0828 10:36:50.167636 140659155802112 replay_runner.py:36] Average training steps per second: 196.25
I0828 10:36:50.390146 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.67
INFO:tensorflow:Starting iteration 28

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 201.50
I0828 10:36:55.593835 140659155802112 replay_runner.py:36] Average training steps per second: 201.50
I0828 10:36:56.025677 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 200.90
I0828 10:37:01.239562 140659155802112 replay_runner.py:36] Average training steps per second: 200.90
I0828 10:37:01.620813 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00