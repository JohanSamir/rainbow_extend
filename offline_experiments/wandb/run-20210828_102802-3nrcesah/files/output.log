Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0828 10:28:08.657533 139779140274176 run_experiment.py:549] Creating TrainRunner ...
I0828 10:28:08.668325 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:28:08.668627 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:28:08.668816 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:28:08.668961 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:28:08.669091 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:28:08.669214 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:28:08.669332 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:28:08.669464 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:28:08.669591 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:28:08.669801 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:28:08.670022 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:28:08.670350 139779140274176 dqn_agent.py:283] 	 seed: 1630146488668263
I0828 10:28:08.673356 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:28:08.673563 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:28:08.673700 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:28:08.673818 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:28:08.673914 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:28:08.674019 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:28:08.674136 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:28:08.674239 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:28:08.674350 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:28:08.710557 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:09.082205 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:09.097148 139779140274176 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:28:09.105780 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:28:09.105963 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:28:09.106039 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:28:09.106233 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:28:09.106312 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:28:09.106389 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:28:09.106449 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:28:09.106524 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:28:09.106594 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:28:09.106777 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:28:09.106925 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:28:09.107011 139779140274176 dqn_agent.py:283] 	 seed: 1630146489105740
I0828 10:28:09.109861 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:28:09.110075 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:28:09.110191 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:28:09.110274 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:28:09.110359 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:28:09.110482 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:28:09.110620 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:28:09.110924 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:28:09.111126 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:28:09.156103 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:09.204907 139779140274176 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:28:09.205160 139779140274176 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 166.36
I0828 10:28:15.216449 139779140274176 replay_runner.py:36] Average training steps per second: 166.36
Steps executed: 245 Episode length: 150 Return: -728.5020255231376
I0828 10:28:16.488512 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -479.85
INFO:tensorflow:Starting iteration 1

Steps executed: 219 Episode length: 75 Return: -530.57159489364896
INFO:tensorflow:Average training steps per second: 219.14
I0828 10:28:25.245624 139779140274176 replay_runner.py:36] Average training steps per second: 219.14
I0828 10:28:25.458286 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -665.97
INFO:tensorflow:Starting iteration 2

Steps executed: 212 Episode length: 126 Return: -900.8087011388952
INFO:tensorflow:Average training steps per second: 221.14
I0828 10:28:34.362594 139779140274176 replay_runner.py:36] Average training steps per second: 221.14
I0828 10:28:34.567374 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -624.86
INFO:tensorflow:Starting iteration 3

Steps executed: 203 Episode length: 90 Return: -145.41003878911172
INFO:tensorflow:Average training steps per second: 219.28
I0828 10:28:43.464392 139779140274176 replay_runner.py:36] Average training steps per second: 219.28
I0828 10:28:43.593280 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.95
INFO:tensorflow:Starting iteration 4

Steps executed: 286 Episode length: 88 Return: -450.163898108988753
INFO:tensorflow:Average training steps per second: 213.56
I0828 10:28:52.606250 139779140274176 replay_runner.py:36] Average training steps per second: 213.56
I0828 10:28:52.931012 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -885.92
INFO:tensorflow:Starting iteration 5

Steps executed: 286 Episode length: 286 Return: -2517.2282274664644
INFO:tensorflow:Average training steps per second: 221.31
I0828 10:29:01.797531 139779140274176 replay_runner.py:36] Average training steps per second: 221.31
I0828 10:29:02.216386 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -2517.23
INFO:tensorflow:Starting iteration 6

Steps executed: 250 Episode length: 250 Return: -1887.3490694421764
INFO:tensorflow:Average training steps per second: 218.94
I0828 10:29:10.975153 139779140274176 replay_runner.py:36] Average training steps per second: 218.94
I0828 10:29:11.293101 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -1887.35
INFO:tensorflow:Starting iteration 7

Steps executed: 194 Episode length: 104 Return: -502.16108273392414
INFO:tensorflow:Average training steps per second: 218.28
I0828 10:29:20.222230 139779140274176 replay_runner.py:36] Average training steps per second: 218.28

Steps executed: 326 Episode length: 132 Return: -894.38373360058324
INFO:tensorflow:Starting iteration 8

Steps executed: 262 Episode length: 81 Return: -479.220097744616574
INFO:tensorflow:Average training steps per second: 220.65
I0828 10:29:29.406107 139779140274176 replay_runner.py:36] Average training steps per second: 220.65
I0828 10:29:29.666326 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -556.59
INFO:tensorflow:Starting iteration 9

Steps executed: 142 Episode length: 142 Return: -995.38320629207274
INFO:tensorflow:Average training steps per second: 218.36
I0828 10:29:38.390371 139779140274176 replay_runner.py:36] Average training steps per second: 218.36

Steps executed: 226 Episode length: 84 Return: -606.720396594265874
INFO:tensorflow:Starting iteration 10

Steps executed: 263 Episode length: 112 Return: -582.31625079958374
INFO:tensorflow:Average training steps per second: 219.95
I0828 10:29:47.504392 139779140274176 replay_runner.py:36] Average training steps per second: 219.95
I0828 10:29:47.761889 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -513.90
INFO:tensorflow:Starting iteration 11

Steps executed: 324 Episode length: 232 Return: -1546.3790429113574
INFO:tensorflow:Average training steps per second: 214.68
I0828 10:29:56.753326 139779140274176 replay_runner.py:36] Average training steps per second: 214.68
I0828 10:29:57.159850 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -1021.37
INFO:tensorflow:Starting iteration 12

Steps executed: 387 Episode length: 295 Return: -2346.3076908828775
INFO:tensorflow:Average training steps per second: 219.94
I0828 10:30:06.052436 139779140274176 replay_runner.py:36] Average training steps per second: 219.94
I0828 10:30:06.561805 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -1382.66
INFO:tensorflow:Starting iteration 13

Steps executed: 305 Episode length: 232 Return: -1784.6878670315475
INFO:tensorflow:Average training steps per second: 220.28
I0828 10:30:15.308163 139779140274176 replay_runner.py:36] Average training steps per second: 220.28
I0828 10:30:15.666849 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -1080.38
INFO:tensorflow:Starting iteration 14

Steps executed: 224 Episode length: 76 Return: -418.939523449385555
INFO:tensorflow:Average training steps per second: 232.93
I0828 10:30:24.092559 139779140274176 replay_runner.py:36] Average training steps per second: 232.93
I0828 10:30:24.301283 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -696.58
INFO:tensorflow:Starting iteration 15

Steps executed: 207 Episode length: 82 Return: -770.911407429379755
INFO:tensorflow:Average training steps per second: 226.16
I0828 10:30:32.973171 139779140274176 replay_runner.py:36] Average training steps per second: 226.16
I0828 10:30:33.151387 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -629.86
INFO:tensorflow:Starting iteration 16

Steps executed: 271 Episode length: 72 Return: -518.587707692691155
INFO:tensorflow:Average training steps per second: 229.93
I0828 10:30:41.756527 139779140274176 replay_runner.py:36] Average training steps per second: 229.93
I0828 10:30:41.988105 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -512.10
INFO:tensorflow:Starting iteration 17
I0828 10:30:46.284129 139779140274176 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 217.17
I0828 10:30:50.889131 139779140274176 replay_runner.py:36] Average training steps per second: 217.17

Steps executed: 201 Episode length: 116 Return: -633.43905438308555
INFO:tensorflow:Starting iteration 18

Steps executed: 250 Episode length: 91 Return: -137.107797179684185
INFO:tensorflow:Average training steps per second: 233.23
I0828 10:30:59.615560 139779140274176 replay_runner.py:36] Average training steps per second: 233.23
I0828 10:30:59.787685 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.72
INFO:tensorflow:Starting iteration 19
I0828 10:31:04.029263 139779140274176 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 221.51

Steps executed: 244 Episode length: 57 Return: -513.722727547584885
I0828 10:31:08.733665 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -517.06
INFO:tensorflow:Starting iteration 20

Steps executed: 260 Episode length: 140 Return: -635.55827447738025
INFO:tensorflow:Average training steps per second: 227.09
I0828 10:31:17.420047 139779140274176 replay_runner.py:36] Average training steps per second: 227.09
I0828 10:31:17.680678 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -761.74
INFO:tensorflow:Starting iteration 21
I0828 10:31:21.987621 139779140274176 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 219.67
I0828 10:31:26.540182 139779140274176 replay_runner.py:36] Average training steps per second: 219.67

Steps executed: 251 Episode length: 128 Return: -645.87025471181395
INFO:tensorflow:Starting iteration 22

Steps executed: 280 Episode length: 166 Return: -1072.2721088658515
INFO:tensorflow:Average training steps per second: 217.55
I0828 10:31:35.681318 139779140274176 replay_runner.py:36] Average training steps per second: 217.55
I0828 10:31:35.948177 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -706.36
INFO:tensorflow:Starting iteration 23
I0828 10:31:40.255667 139779140274176 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 215.46
I0828 10:31:44.897305 139779140274176 replay_runner.py:36] Average training steps per second: 215.46

Steps executed: 243 Episode length: 81 Return: -546.872177865182715
INFO:tensorflow:Starting iteration 24

Steps executed: 246 Episode length: 49 Return: -417.685885386230275
INFO:tensorflow:Average training steps per second: 219.64
I0828 10:31:53.995355 139779140274176 replay_runner.py:36] Average training steps per second: 219.64
I0828 10:31:54.200732 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -545.79
INFO:tensorflow:Starting iteration 25
I0828 10:31:58.450899 139779140274176 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 219.87
I0828 10:32:02.999589 139779140274176 replay_runner.py:36] Average training steps per second: 219.87

Steps executed: 214 Episode length: 106 Return: -397.93981461600935
INFO:tensorflow:Starting iteration 26

Steps executed: 324 Episode length: 324 Return: -3011.6005355438365
INFO:tensorflow:Average training steps per second: 216.00
I0828 10:32:12.145206 139779140274176 replay_runner.py:36] Average training steps per second: 216.00
I0828 10:32:12.580098 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -3011.60
INFO:tensorflow:Starting iteration 27
I0828 10:32:16.949130 139779140274176 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 220.64

Steps executed: 262 Episode length: 144 Return: -826.04355742257135
I0828 10:32:21.746089 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -827.67
INFO:tensorflow:Starting iteration 28

Steps executed: 220 Episode length: 60 Return: -113.651423645352282
INFO:tensorflow:Average training steps per second: 219.17
I0828 10:32:30.661584 139779140274176 replay_runner.py:36] Average training steps per second: 219.17
I0828 10:32:30.837133 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.72
INFO:tensorflow:Starting iteration 29

Steps executed: 229 Episode length: 229 Return: -1682.7221789544033
INFO:tensorflow:Average training steps per second: 227.34
I0828 10:32:39.548504 139779140274176 replay_runner.py:36] Average training steps per second: 227.34

Done fixed training!Episode length: 229 Return: -1682.7221789544033