Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0828 10:28:03.411641 139821415028736 run_experiment.py:549] Creating TrainRunner ...
I0828 10:28:03.422793 139821415028736 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:28:03.423071 139821415028736 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:28:03.423258 139821415028736 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:28:03.423393 139821415028736 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:28:03.423516 139821415028736 dqn_agent.py:275] 	 update_period: 4
I0828 10:28:03.423624 139821415028736 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:28:03.423724 139821415028736 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:28:03.423823 139821415028736 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:28:03.423921 139821415028736 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:28:03.424025 139821415028736 dqn_agent.py:280] 	 optimizer: adam
I0828 10:28:03.424123 139821415028736 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:28:03.424218 139821415028736 dqn_agent.py:283] 	 seed: 1630146483422726
I0828 10:28:03.427277 139821415028736 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:28:03.427506 139821415028736 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:28:03.427643 139821415028736 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:28:03.427757 139821415028736 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:28:03.427861 139821415028736 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:28:03.427963 139821415028736 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:28:03.428060 139821415028736 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:28:03.428154 139821415028736 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:28:03.428247 139821415028736 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:28:03.467767 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:03.863841 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:03.880487 139821415028736 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:28:03.891243 139821415028736 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:28:03.891482 139821415028736 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:28:03.891604 139821415028736 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:28:03.891701 139821415028736 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:28:03.891769 139821415028736 dqn_agent.py:275] 	 update_period: 4
I0828 10:28:03.891844 139821415028736 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:28:03.891925 139821415028736 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:28:03.891999 139821415028736 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:28:03.892076 139821415028736 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:28:03.892171 139821415028736 dqn_agent.py:280] 	 optimizer: adam
I0828 10:28:03.892307 139821415028736 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:28:03.892384 139821415028736 dqn_agent.py:283] 	 seed: 1630146483891185
I0828 10:28:03.894905 139821415028736 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:28:03.895139 139821415028736 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:28:03.895327 139821415028736 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:28:03.895495 139821415028736 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:28:03.895704 139821415028736 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:28:03.895869 139821415028736 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:28:03.896011 139821415028736 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:28:03.896136 139821415028736 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:28:03.896275 139821415028736 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:28:03.966872 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:03.989722 139821415028736 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:28:03.989964 139821415028736 replay_runner.py:41] Starting iteration 0
Steps executed: 171 Episode length: 53 Return: -97.745869780322754
INFO:tensorflow:Average training steps per second: 170.98
I0828 10:28:09.838770 139821415028736 replay_runner.py:36] Average training steps per second: 170.98

Steps executed: 225 Episode length: 54 Return: -128.81994038288826
INFO:tensorflow:Starting iteration 1

Steps executed: 215 Episode length: 84 Return: -796.79583595767336
INFO:tensorflow:Average training steps per second: 233.68
I0828 10:28:19.517300 139821415028736 replay_runner.py:36] Average training steps per second: 233.68
I0828 10:28:19.704363 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -660.02
INFO:tensorflow:Starting iteration 2

Steps executed: 202 Episode length: 58 Return: -371.84833733656566
INFO:tensorflow:Average training steps per second: 230.50
I0828 10:28:28.382650 139821415028736 replay_runner.py:36] Average training steps per second: 230.50
I0828 10:28:28.542051 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -423.09
INFO:tensorflow:Starting iteration 3

Steps executed: 251 Episode length: 72 Return: -634.55215709761393
INFO:tensorflow:Average training steps per second: 227.76
I0828 10:28:37.345663 139821415028736 replay_runner.py:36] Average training steps per second: 227.76
I0828 10:28:37.543748 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -411.00
INFO:tensorflow:Starting iteration 4

Steps executed: 230 Episode length: 78 Return: -394.18551234433416
INFO:tensorflow:Average training steps per second: 225.83
I0828 10:28:46.406237 139821415028736 replay_runner.py:36] Average training steps per second: 225.83
I0828 10:28:46.586817 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -317.67
INFO:tensorflow:Starting iteration 5

Steps executed: 246 Episode length: 82 Return: -713.43020067039616
INFO:tensorflow:Average training steps per second: 223.19
I0828 10:28:55.442102 139821415028736 replay_runner.py:36] Average training steps per second: 223.19
I0828 10:28:55.651366 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -788.94
INFO:tensorflow:Starting iteration 6

Steps executed: 290 Episode length: 119 Return: -700.9324119034443
INFO:tensorflow:Average training steps per second: 229.24
I0828 10:29:04.325983 139821415028736 replay_runner.py:36] Average training steps per second: 229.24
I0828 10:29:04.599906 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -530.29
INFO:tensorflow:Starting iteration 7

Steps executed: 211 Episode length: 90 Return: -730.49361489278253
INFO:tensorflow:Average training steps per second: 227.27
I0828 10:29:13.374493 139821415028736 replay_runner.py:36] Average training steps per second: 227.27
I0828 10:29:13.565151 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -640.80
INFO:tensorflow:Starting iteration 8

Steps executed: 219 Episode length: 79 Return: -655.14792049867223
INFO:tensorflow:Average training steps per second: 228.13
I0828 10:29:22.306987 139821415028736 replay_runner.py:36] Average training steps per second: 228.13
I0828 10:29:22.478626 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -557.47
INFO:tensorflow:Starting iteration 9

Steps executed: 239 Episode length: 51 Return: -416.53385501645516
INFO:tensorflow:Average training steps per second: 226.28
I0828 10:29:31.127819 139821415028736 replay_runner.py:36] Average training steps per second: 226.28
I0828 10:29:31.337205 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -528.72
INFO:tensorflow:Starting iteration 10

Steps executed: 215 Episode length: 122 Return: -852.0362126226122
INFO:tensorflow:Average training steps per second: 220.98
I0828 10:29:40.301478 139821415028736 replay_runner.py:36] Average training steps per second: 220.98
I0828 10:29:40.502064 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -742.99
INFO:tensorflow:Starting iteration 11

Steps executed: 85 Episode length: 85 Return: -811.622178102309722
INFO:tensorflow:Average training steps per second: 224.44
I0828 10:29:49.344742 139821415028736 replay_runner.py:36] Average training steps per second: 224.44

Steps executed: 210 Episode length: 66 Return: -594.48250780606845
INFO:tensorflow:Starting iteration 12

Steps executed: 415 Episode length: 248 Return: -1771.9516884397904
INFO:tensorflow:Average training steps per second: 223.46
I0828 10:29:58.335450 139821415028736 replay_runner.py:36] Average training steps per second: 223.46
I0828 10:29:58.773832 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -930.07
INFO:tensorflow:Starting iteration 13

Steps executed: 72 Episode length: 72 Return: -702.6892989661953904
INFO:tensorflow:Average training steps per second: 226.92
I0828 10:30:07.412876 139821415028736 replay_runner.py:36] Average training steps per second: 226.92

Steps executed: 221 Episode length: 83 Return: -743.541807489820504
INFO:tensorflow:Starting iteration 14

Steps executed: 219 Episode length: 90 Return: -1095.33579860250984
INFO:tensorflow:Average training steps per second: 223.22
I0828 10:30:16.354528 139821415028736 replay_runner.py:36] Average training steps per second: 223.22
I0828 10:30:16.533355 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -727.03
INFO:tensorflow:Starting iteration 15

Steps executed: 250 Episode length: 57 Return: -396.581095737065834
INFO:tensorflow:Average training steps per second: 230.97
I0828 10:30:24.991183 139821415028736 replay_runner.py:36] Average training steps per second: 230.97
I0828 10:30:25.192528 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -548.86
INFO:tensorflow:Starting iteration 16

Steps executed: 219 Episode length: 89 Return: -565.659417525501134
INFO:tensorflow:Average training steps per second: 233.71
I0828 10:30:33.569538 139821415028736 replay_runner.py:36] Average training steps per second: 233.71
I0828 10:30:33.818314 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -773.02
INFO:tensorflow:Starting iteration 17

Steps executed: 230 Episode length: 88 Return: -1029.01879385929214
INFO:tensorflow:Average training steps per second: 234.13
I0828 10:30:42.424326 139821415028736 replay_runner.py:36] Average training steps per second: 234.13
I0828 10:30:42.628512 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -739.28
INFO:tensorflow:Starting iteration 18

Steps executed: 226 Episode length: 59 Return: -531.968733945110414
INFO:tensorflow:Average training steps per second: 229.64
I0828 10:30:51.338490 139821415028736 replay_runner.py:36] Average training steps per second: 229.64
I0828 10:30:51.531638 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -721.93
INFO:tensorflow:Starting iteration 19

Steps executed: 224 Episode length: 130 Return: -949.36947792529914
INFO:tensorflow:Average training steps per second: 240.94
I0828 10:30:59.954652 139821415028736 replay_runner.py:36] Average training steps per second: 240.94
I0828 10:31:00.154959 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -740.09
INFO:tensorflow:Starting iteration 20

Steps executed: 275 Episode length: 82 Return: -747.508001757331314
INFO:tensorflow:Average training steps per second: 227.20
I0828 10:31:08.758325 139821415028736 replay_runner.py:36] Average training steps per second: 227.20
I0828 10:31:08.978955 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -608.73
INFO:tensorflow:Starting iteration 21

Steps executed: 220 Episode length: 54 Return: -435.428754379319344
INFO:tensorflow:Average training steps per second: 228.46
I0828 10:31:17.840318 139821415028736 replay_runner.py:36] Average training steps per second: 228.46
I0828 10:31:18.024351 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -415.04
INFO:tensorflow:Starting iteration 22

Steps executed: 272 Episode length: 79 Return: -620.115578854729384
INFO:tensorflow:Average training steps per second: 223.10
I0828 10:31:26.796636 139821415028736 replay_runner.py:36] Average training steps per second: 223.10
I0828 10:31:27.041391 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -596.90
INFO:tensorflow:Starting iteration 23

Steps executed: 259 Episode length: 259 Return: -1907.6235841909033
INFO:tensorflow:Average training steps per second: 225.26
I0828 10:31:35.834762 139821415028736 replay_runner.py:36] Average training steps per second: 225.26
I0828 10:31:36.159306 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -1907.62
INFO:tensorflow:Starting iteration 24

Steps executed: 283 Episode length: 89 Return: -541.176254501122533
INFO:tensorflow:Average training steps per second: 222.54
I0828 10:31:44.926633 139821415028736 replay_runner.py:36] Average training steps per second: 222.54
I0828 10:31:45.233463 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -1025.15
INFO:tensorflow:Starting iteration 25

Steps executed: 256 Episode length: 154 Return: -959.88639594806673
INFO:tensorflow:Average training steps per second: 224.52
I0828 10:31:53.962443 139821415028736 replay_runner.py:36] Average training steps per second: 224.52
I0828 10:31:54.219820 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -738.32
INFO:tensorflow:Starting iteration 26

Steps executed: 227 Episode length: 79 Return: -714.426249977402873
INFO:tensorflow:Average training steps per second: 226.23
I0828 10:32:02.908846 139821415028736 replay_runner.py:36] Average training steps per second: 226.23
I0828 10:32:03.114618 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -647.20
INFO:tensorflow:Starting iteration 27

Steps executed: 371 Episode length: 290 Return: -2639.9298232560604
INFO:tensorflow:Average training steps per second: 221.63
I0828 10:32:11.933713 139821415028736 replay_runner.py:36] Average training steps per second: 221.63
I0828 10:32:12.409526 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -1571.04
INFO:tensorflow:Starting iteration 28

Steps executed: 273 Episode length: 103 Return: -482.42238984766534
INFO:tensorflow:Average training steps per second: 224.55
I0828 10:32:21.187583 139821415028736 replay_runner.py:36] Average training steps per second: 224.55
I0828 10:32:21.475222 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -638.42
INFO:tensorflow:Starting iteration 29

Steps executed: 211 Episode length: 49 Return: -387.565613018047664
INFO:tensorflow:Average training steps per second: 225.33
I0828 10:32:30.227560 139821415028736 replay_runner.py:36] Average training steps per second: 225.33

Done fixed training!Episode length: 49 Return: -387.565613018047664