I0905 16:33:22.432388 140275076675584 run_experiment.py:549] Creating TrainRunner ...
I0905 16:33:22.468873 140275076675584 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:33:22.469310 140275076675584 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:33:22.470765 140275076675584 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:33:22.471366 140275076675584 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:33:22.471790 140275076675584 dqn_agent.py:275] 	 update_period: 4
I0905 16:33:22.472084 140275076675584 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:33:22.488535 140275076675584 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:33:22.488859 140275076675584 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:33:22.489036 140275076675584 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:33:22.489154 140275076675584 dqn_agent.py:280] 	 optimizer: adam
I0905 16:33:22.489321 140275076675584 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:33:22.489467 140275076675584 dqn_agent.py:283] 	 seed: 1630859602468793
I0905 16:33:22.493036 140275076675584 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:33:22.493379 140275076675584 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:33:22.499118 140275076675584 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:33:22.499424 140275076675584 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:33:22.502509 140275076675584 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:33:22.502717 140275076675584 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:33:22.502878 140275076675584 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:33:22.503792 140275076675584 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:33:22.504861 140275076675584 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:33:25.332202 140275076675584 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:26.032696 140275076675584 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:26.058743 140275076675584 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:33:26.110801 140275076675584 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:33:26.111130 140275076675584 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:33:26.111337 140275076675584 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:33:26.111627 140275076675584 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:33:26.111832 140275076675584 dqn_agent.py:275] 	 update_period: 4
I0905 16:33:26.112104 140275076675584 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:33:26.112260 140275076675584 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:33:26.112617 140275076675584 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:33:26.112791 140275076675584 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:33:26.113124 140275076675584 dqn_agent.py:280] 	 optimizer: adam
I0905 16:33:26.113806 140275076675584 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:33:26.114442 140275076675584 dqn_agent.py:283] 	 seed: 1630859606110744
I0905 16:33:26.122293 140275076675584 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:33:26.123092 140275076675584 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:33:26.123324 140275076675584 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0905 16:33:26.124634 140275076675584 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:33:26.125793 140275076675584 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:33:26.125982 140275076675584 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:33:26.126313 140275076675584 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:33:26.126985 140275076675584 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:33:26.127170 140275076675584 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:33:26.195343 140275076675584 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:26.249351 140275076675584 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:33:26.249661 140275076675584 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 113.57
I0905 16:33:35.055649 140275076675584 replay_runner.py:36] Average training steps per second: 113.57
Steps executed: 263 Episode length: 104 Return: -492.82008096888245
I0905 16:33:36.429918 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -398.23
INFO:tensorflow:Starting iteration 1

Steps executed: 229 Episode length: 120 Return: -383.61997059035575
INFO:tensorflow:Average training steps per second: 172.69
I0905 16:33:47.136506 140275076675584 replay_runner.py:36] Average training steps per second: 172.69
I0905 16:33:47.350899 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.18
INFO:tensorflow:Starting iteration 2
I0905 16:33:51.946996 140275076675584 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 164.63

Steps executed: 315 Episode length: 171 Return: -442.43553475163714
I0905 16:33:58.482203 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -374.20
INFO:tensorflow:Starting iteration 3
I0905 16:34:03.822669 140275076675584 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 155.63

Steps executed: 1000 Episode length: 1000 Return: -111.44277138090034
I0905 16:34:16.288620 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.44
INFO:tensorflow:Starting iteration 4
I0905 16:34:21.229584 140275076675584 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 155.90

Steps executed: 1000 Episode length: 1000 Return: -79.416045307905334
I0905 16:34:31.501495 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.42
INFO:tensorflow:Starting iteration 5
I0905 16:34:35.887260 140275076675584 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 168.57

Steps executed: 1000 Episode length: 1000 Return: -81.972868578392444
I0905 16:34:45.391069 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.97
INFO:tensorflow:Starting iteration 6
I0905 16:34:49.681600 140275076675584 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 155.13

Steps executed: 1000 Episode length: 1000 Return: -93.307497265093094
I0905 16:34:59.104021 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.31
INFO:tensorflow:Starting iteration 7
I0905 16:35:04.247802 140275076675584 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 151.40

Steps executed: 1000 Episode length: 1000 Return: -160.80431147219093
I0905 16:35:15.190155 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.80
INFO:tensorflow:Starting iteration 8
I0905 16:35:20.265825 140275076675584 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 173.39

Steps executed: 1000 Episode length: 1000 Return: -142.03008452404686
I0905 16:35:29.128476 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.03
INFO:tensorflow:Starting iteration 9
I0905 16:35:33.049369 140275076675584 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 158.50

Steps executed: 1000 Episode length: 1000 Return: -134.67820854503873
I0905 16:35:41.674857 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.68
INFO:tensorflow:Starting iteration 10
I0905 16:35:46.805853 140275076675584 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 177.27

Steps executed: 1000 Episode length: 1000 Return: -163.35698147664948
I0905 16:35:56.299238 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.36
INFO:tensorflow:Starting iteration 11
I0905 16:36:01.033044 140275076675584 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 182.61

Steps executed: 1000 Episode length: 1000 Return: -129.70297659058505
I0905 16:36:09.042591 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.70
INFO:tensorflow:Starting iteration 12
I0905 16:36:13.707165 140275076675584 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 206.12

Steps executed: 234 Episode length: 75 Return: -113.79003718100442505
I0905 16:36:18.762546 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.89
INFO:tensorflow:Starting iteration 13

Steps executed: 111 Episode length: 111 Return: -52.28531000868624505
INFO:tensorflow:Average training steps per second: 242.31

Steps executed: 1111 Episode length: 1000 Return: -137.22838819186714
I0905 16:36:29.118138 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.76
INFO:tensorflow:Starting iteration 14

Steps executed: 185 Episode length: 185 Return: -125.9042253960883514
INFO:tensorflow:Average training steps per second: 296.55
I0905 16:36:36.324723 140275076675584 replay_runner.py:36] Average training steps per second: 296.55

Steps executed: 565 Episode length: 380 Return: -238.3653567693462814
INFO:tensorflow:Starting iteration 15

Steps executed: 54 Episode length: 54 Return: -123.234818917626382814
INFO:tensorflow:Average training steps per second: 379.32
I0905 16:36:42.476997 140275076675584 replay_runner.py:36] Average training steps per second: 379.32

Steps executed: 368 Episode length: 314 Return: -126.3482852713232814
INFO:tensorflow:Starting iteration 16

Steps executed: 58 Episode length: 58 Return: -174.622643241203322814
INFO:tensorflow:Average training steps per second: 377.56

Steps executed: 703 Episode length: 645 Return: -146.5195546060658714
I0905 16:36:49.105550 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.57
INFO:tensorflow:Starting iteration 17

Steps executed: 383 Episode length: 218 Return: -396.3181296670444714
INFO:tensorflow:Average training steps per second: 375.51
I0905 16:36:54.862492 140275076675584 replay_runner.py:36] Average training steps per second: 375.51
I0905 16:36:55.066087 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -398.28
INFO:tensorflow:Starting iteration 18
I0905 16:36:58.179997 140275076675584 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 380.08

Steps executed: 473 Episode length: 282 Return: -269.1250632345953714
I0905 16:37:01.104815 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.35
INFO:tensorflow:Starting iteration 19

Steps executed: 326 Episode length: 153 Return: -90.78694865582602714
INFO:tensorflow:Average training steps per second: 374.86
I0905 16:37:06.957324 140275076675584 replay_runner.py:36] Average training steps per second: 374.86
I0905 16:37:07.091745 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.27
INFO:tensorflow:Starting iteration 20
I0905 16:37:10.221842 140275076675584 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 376.07

Steps executed: 511 Episode length: 511 Return: -270.3383284639927514
I0905 16:37:13.405534 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.34
INFO:tensorflow:Starting iteration 21

Steps executed: 208 Episode length: 208 Return: -14.76388161899487314
INFO:tensorflow:Average training steps per second: 371.61
I0905 16:37:19.160179 140275076675584 replay_runner.py:36] Average training steps per second: 371.61
I0905 16:37:19.273184 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -14.76
INFO:tensorflow:Starting iteration 22

Steps executed: 234 Episode length: 114 Return: -362.0173036079997414
INFO:tensorflow:Average training steps per second: 380.43
I0905 16:37:25.002676 140275076675584 replay_runner.py:36] Average training steps per second: 380.43
I0905 16:37:25.111526 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.54
INFO:tensorflow:Starting iteration 23
I0905 16:37:28.177523 140275076675584 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 380.84
I0905 16:37:30.803650 140275076675584 replay_runner.py:36] Average training steps per second: 380.84

Steps executed: 224 Episode length: 100 Return: -456.7141544726428614
INFO:tensorflow:Starting iteration 24

Steps executed: 247 Episode length: 247 Return: -422.4584270367979614
INFO:tensorflow:Average training steps per second: 383.27
I0905 16:37:36.612375 140275076675584 replay_runner.py:36] Average training steps per second: 383.27
I0905 16:37:36.764441 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -422.46
INFO:tensorflow:Starting iteration 25
I0905 16:37:39.882827 140275076675584 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 384.69

Steps executed: 385 Episode length: 261 Return: -13.50452476813079314
I0905 16:37:42.726881 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -382.30
INFO:tensorflow:Starting iteration 26

Steps executed: 66 Episode length: 66 Return: -231.726427902663869314
INFO:tensorflow:Average training steps per second: 384.93
I0905 16:37:48.452629 140275076675584 replay_runner.py:36] Average training steps per second: 384.93

Steps executed: 245 Episode length: 58 Return: -227.65555613764099314
INFO:tensorflow:Starting iteration 27

Steps executed: 185 Episode length: 185 Return: -404.3944589326939614
INFO:tensorflow:Average training steps per second: 373.29
I0905 16:37:54.416679 140275076675584 replay_runner.py:36] Average training steps per second: 373.29

Steps executed: 317 Episode length: 132 Return: -204.1978929993109414
INFO:tensorflow:Starting iteration 28

Steps executed: 276 Episode length: 126 Return: -448.2367032177824414
INFO:tensorflow:Average training steps per second: 381.89
I0905 16:38:00.326518 140275076675584 replay_runner.py:36] Average training steps per second: 381.89
I0905 16:38:00.465452 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -413.50
INFO:tensorflow:Starting iteration 29

Steps executed: 252 Episode length: 129 Return: -154.7896179077596314
INFO:tensorflow:Average training steps per second: 370.36
I0905 16:38:06.245660 140275076675584 replay_runner.py:36] Average training steps per second: 370.36

Done fixed training!Episode length: 129 Return: -154.7896179077596314