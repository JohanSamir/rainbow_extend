I0905 16:42:31.665482 139789596633088 run_experiment.py:549] Creating TrainRunner ...
I0905 16:42:31.677731 139789596633088 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:42:31.678103 139789596633088 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:42:31.678244 139789596633088 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:42:31.678422 139789596633088 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:42:31.678549 139789596633088 dqn_agent.py:275] 	 update_period: 4
I0905 16:42:31.678700 139789596633088 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:42:31.678807 139789596633088 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:42:31.678919 139789596633088 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:42:31.679028 139789596633088 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:42:31.679124 139789596633088 dqn_agent.py:280] 	 optimizer: adam
I0905 16:42:31.679224 139789596633088 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:42:31.679302 139789596633088 dqn_agent.py:283] 	 seed: 1630860151677675
I0905 16:42:31.682183 139789596633088 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:42:31.682322 139789596633088 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:42:31.682391 139789596633088 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:42:31.682470 139789596633088 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:42:31.682541 139789596633088 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:42:31.682590 139789596633088 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:42:31.682638 139789596633088 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:42:31.682684 139789596633088 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:42:31.682730 139789596633088 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0905 16:42:33.233361 139789596633088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:42:34.025200 139789596633088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:42:34.039423 139789596633088 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:42:34.046568 139789596633088 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:42:34.046761 139789596633088 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:42:34.046869 139789596633088 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:42:34.046952 139789596633088 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:42:34.047046 139789596633088 dqn_agent.py:275] 	 update_period: 4
I0905 16:42:34.047101 139789596633088 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:42:34.047341 139789596633088 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:42:34.047444 139789596633088 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:42:34.047570 139789596633088 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:42:34.047807 139789596633088 dqn_agent.py:280] 	 optimizer: adam
I0905 16:42:34.048065 139789596633088 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:42:34.048249 139789596633088 dqn_agent.py:283] 	 seed: 1630860154046524
I0905 16:42:34.050976 139789596633088 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:42:34.051178 139789596633088 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:42:34.051374 139789596633088 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:42:34.051525 139789596633088 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:42:34.051795 139789596633088 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:42:34.051896 139789596633088 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:42:34.051970 139789596633088 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:42:34.052046 139789596633088 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:42:34.052155 139789596633088 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:42:34.076844 139789596633088 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:42:34.094775 139789596633088 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:42:34.095099 139789596633088 replay_runner.py:41] Starting iteration 0
Steps executed: 223 Episode length: 118 Return: -534.5496623559661
INFO:tensorflow:Average training steps per second: 165.08
I0905 16:42:40.153249 139789596633088 replay_runner.py:36] Average training steps per second: 165.08
I0905 16:42:41.182822 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -527.16
INFO:tensorflow:Starting iteration 1

Steps executed: 264 Episode length: 264 Return: -267.0242076558088
INFO:tensorflow:Average training steps per second: 225.51
I0905 16:42:49.675516 139789596633088 replay_runner.py:36] Average training steps per second: 225.51
I0905 16:42:50.049677 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -267.02
INFO:tensorflow:Starting iteration 2

Steps executed: 249 Episode length: 124 Return: -361.75788109837736
INFO:tensorflow:Average training steps per second: 238.83
I0905 16:42:58.008232 139789596633088 replay_runner.py:36] Average training steps per second: 238.83
I0905 16:42:58.283876 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.99
INFO:tensorflow:Starting iteration 3
I0905 16:43:02.322479 139789596633088 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 251.29

Steps executed: 1000 Episode length: 1000 Return: -79.25358552949218
I0905 16:43:09.393018 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.25
INFO:tensorflow:Starting iteration 4

Steps executed: 860 Episode length: 860 Return: -240.972070866141488
INFO:tensorflow:Average training steps per second: 244.10
I0905 16:43:17.568615 139789596633088 replay_runner.py:36] Average training steps per second: 244.10
I0905 16:43:19.363007 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -240.97
INFO:tensorflow:Starting iteration 5
I0905 16:43:23.432402 139789596633088 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 245.07

Steps executed: 1000 Episode length: 1000 Return: -218.13520947476263
I0905 16:43:30.577775 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.14
INFO:tensorflow:Starting iteration 6

Steps executed: 146 Episode length: 146 Return: -331.1816530403545263
INFO:tensorflow:Average training steps per second: 243.24

Steps executed: 1146 Episode length: 1000 Return: -148.83528610961284
I0905 16:43:41.755223 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -240.01
INFO:tensorflow:Starting iteration 7
I0905 16:43:45.774015 139789596633088 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 227.83

Steps executed: 1000 Episode length: 1000 Return: -249.03181870124143
I0905 16:43:53.054674 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -249.03
INFO:tensorflow:Starting iteration 8
I0905 16:43:57.145497 139789596633088 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 250.10

Steps executed: 1000 Episode length: 1000 Return: -359.21595584353093
I0905 16:44:04.522968 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.22
INFO:tensorflow:Starting iteration 9
I0905 16:44:08.749684 139789596633088 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 263.21

Steps executed: 1000 Episode length: 1000 Return: -187.82759323504463
I0905 16:44:15.157650 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.83
INFO:tensorflow:Starting iteration 10
I0905 16:44:19.504473 139789596633088 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 286.46

Steps executed: 1000 Episode length: 1000 Return: -156.34426368826388
I0905 16:44:24.930737 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.34
INFO:tensorflow:Starting iteration 11

Steps executed: 540 Episode length: 353 Return: -39.53582735974119288
INFO:tensorflow:Average training steps per second: 283.72
I0905 16:44:32.770999 139789596633088 replay_runner.py:36] Average training steps per second: 283.72
I0905 16:44:33.369642 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.15
INFO:tensorflow:Starting iteration 12
I0905 16:44:37.696552 139789596633088 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 259.74

Steps executed: 1000 Episode length: 1000 Return: -142.87462773025237
I0905 16:44:45.143682 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.87
INFO:tensorflow:Starting iteration 13

Steps executed: 312 Episode length: 312 Return: -7.368301782012315237
INFO:tensorflow:Average training steps per second: 265.62
I0905 16:44:53.151309 139789596633088 replay_runner.py:36] Average training steps per second: 265.62
I0905 16:44:53.552367 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -7.37
INFO:tensorflow:Starting iteration 14

Steps executed: 159 Episode length: 159 Return: -172.3134980455501237
INFO:tensorflow:Average training steps per second: 259.16

Steps executed: 340 Episode length: 181 Return: 26.650491320767501237
I0905 16:45:01.938977 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.83
INFO:tensorflow:Starting iteration 15
I0905 16:45:06.050538 139789596633088 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 240.33

Steps executed: 1000 Episode length: 1000 Return: -180.09824618244176
I0905 16:45:13.096097 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.10
INFO:tensorflow:Starting iteration 16
I0905 16:45:17.292170 139789596633088 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 238.26

Steps executed: 1000 Episode length: 1000 Return: -115.69721526945452
I0905 16:45:24.639231 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.70
INFO:tensorflow:Starting iteration 17

Steps executed: 273 Episode length: 153 Return: -104.4114438254498552
INFO:tensorflow:Average training steps per second: 248.83
I0905 16:45:32.709340 139789596633088 replay_runner.py:36] Average training steps per second: 248.83
I0905 16:45:33.015216 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.28
INFO:tensorflow:Starting iteration 18

Steps executed: 279 Episode length: 279 Return: -9.928213762102246552
INFO:tensorflow:Average training steps per second: 237.79
I0905 16:45:41.428875 139789596633088 replay_runner.py:36] Average training steps per second: 237.79
I0905 16:45:41.756857 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -9.93
INFO:tensorflow:Starting iteration 19
I0905 16:45:45.910089 139789596633088 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 241.58

Steps executed: 294 Episode length: 105 Return: -386.1635087455340552
I0905 16:45:50.331770 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -473.33
INFO:tensorflow:Starting iteration 20

Steps executed: 297 Episode length: 167 Return: -50.75501683805608552
INFO:tensorflow:Average training steps per second: 235.13
I0905 16:45:58.647517 139789596633088 replay_runner.py:36] Average training steps per second: 235.13
I0905 16:45:58.950936 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.63
INFO:tensorflow:Starting iteration 21
I0905 16:46:02.748482 139789596633088 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 225.61

Steps executed: 884 Episode length: 884 Return: -92.00947772954756552
I0905 16:46:09.558626 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.01
INFO:tensorflow:Starting iteration 22

Steps executed: 226 Episode length: 105 Return: -621.2594205346684552
INFO:tensorflow:Average training steps per second: 225.72
I0905 16:46:17.907733 139789596633088 replay_runner.py:36] Average training steps per second: 225.72
I0905 16:46:18.132672 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -612.17
INFO:tensorflow:Starting iteration 23
I0905 16:46:21.937620 139789596633088 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 258.04
I0905 16:46:25.813470 139789596633088 replay_runner.py:36] Average training steps per second: 258.04

Steps executed: 335 Episode length: 146 Return: -108.0255236057281852
INFO:tensorflow:Starting iteration 24
I0905 16:46:30.384218 139789596633088 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 288.85
I0905 16:46:33.846710 139789596633088 replay_runner.py:36] Average training steps per second: 288.85

Steps executed: 262 Episode length: 129 Return: -211.6596704353673852
INFO:tensorflow:Starting iteration 25
I0905 16:46:38.297245 139789596633088 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 277.39
I0905 16:46:41.902973 139789596633088 replay_runner.py:36] Average training steps per second: 277.39

Steps executed: 262 Episode length: 109 Return: -386.9689450182891652
INFO:tensorflow:Starting iteration 26
I0905 16:46:45.984873 139789596633088 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 250.46
I0905 16:46:49.978012 139789596633088 replay_runner.py:36] Average training steps per second: 250.46

Steps executed: 311 Episode length: 156 Return: -442.2085142928412452
INFO:tensorflow:Starting iteration 27
I0905 16:46:53.964107 139789596633088 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 266.54
I0905 16:46:57.716581 139789596633088 replay_runner.py:36] Average training steps per second: 266.54

Steps executed: 360 Episode length: 360 Return: -409.4653074895965752
INFO:tensorflow:Starting iteration 28
I0905 16:47:01.029726 139789596633088 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 295.96

Steps executed: 205 Episode length: 205 Return: -502.5187966191008452
I0905 16:47:04.615020 139789596633088 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.52
INFO:tensorflow:Starting iteration 29

Steps executed: 208 Episode length: 91 Return: -333.69425759856533452
INFO:tensorflow:Average training steps per second: 326.56
I0905 16:47:11.170544 139789596633088 replay_runner.py:36] Average training steps per second: 326.56

Done fixed training!Episode length: 91 Return: -333.69425759856533452