Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 23:54:50.403836 140413705484288 run_experiment.py:549] Creating TrainRunner ...
I0901 23:54:50.414720 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:54:50.414921 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:54:50.414999 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:54:50.415061 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:54:50.415116 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0901 23:54:50.415211 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:54:50.415267 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:54:50.415328 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:54:50.415389 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:54:50.415442 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0901 23:54:50.415498 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:54:50.415549 140413705484288 dqn_agent.py:283] 	 seed: 1630540490414660
I0901 23:54:50.418189 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:54:50.418478 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:54:50.418692 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:54:50.418880 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:54:50.419007 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:54:50.419119 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:54:50.419384 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:54:50.419574 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:54:50.419928 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:54:50.459598 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:50.849944 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:50.865010 140413705484288 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:54:50.874760 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:54:50.875048 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:54:50.875159 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:54:50.875492 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:54:50.875748 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0901 23:54:50.875849 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:54:50.875924 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:54:50.876001 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:54:50.876083 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:54:50.876153 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0901 23:54:50.876334 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:54:50.876464 140413705484288 dqn_agent.py:283] 	 seed: 1630540490874673
I0901 23:54:50.879395 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:54:50.879610 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:54:50.879738 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:54:50.879828 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:54:50.879904 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:54:50.879983 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:54:50.880101 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:54:50.880178 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:54:50.880275 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:54:50.951631 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:54:50.975492 140413705484288 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:54:50.975782 140413705484288 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.55
I0901 23:54:57.128032 140413705484288 replay_runner.py:36] Average training steps per second: 162.55
Steps executed: 245 Episode length: 78 Return: -332.76926736875646
I0901 23:54:58.269469 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.84
INFO:tensorflow:Starting iteration 1

Steps executed: 330 Episode length: 160 Return: -437.61272457183967
INFO:tensorflow:Average training steps per second: 224.56
I0901 23:55:07.006343 140413705484288 replay_runner.py:36] Average training steps per second: 224.56
I0901 23:55:07.332131 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -443.36
INFO:tensorflow:Starting iteration 2

Steps executed: 222 Episode length: 97 Return: -129.826102359596797
INFO:tensorflow:Average training steps per second: 224.79
I0901 23:55:16.120474 140413705484288 replay_runner.py:36] Average training steps per second: 224.79
I0901 23:55:16.319707 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -157.27
INFO:tensorflow:Starting iteration 3

Steps executed: 276 Episode length: 141 Return: -401.92822730319415
INFO:tensorflow:Average training steps per second: 219.66
I0901 23:55:25.191017 140413705484288 replay_runner.py:36] Average training steps per second: 219.66
I0901 23:55:25.456932 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -510.66
INFO:tensorflow:Starting iteration 4
I0901 23:55:29.737643 140413705484288 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 223.78

Steps executed: 824 Episode length: 824 Return: -399.86687835557915
I0901 23:55:36.964160 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -399.87
INFO:tensorflow:Starting iteration 5
I0901 23:55:41.340385 140413705484288 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 226.18

Steps executed: 1000 Episode length: 1000 Return: -31.627257071879406
I0901 23:55:48.256030 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -31.63
INFO:tensorflow:Starting iteration 6
I0901 23:55:52.538362 140413705484288 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 224.22

Steps executed: 1000 Episode length: 1000 Return: -20.705869702948007
I0901 23:56:00.018088 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -20.71
INFO:tensorflow:Starting iteration 7
I0901 23:56:04.426397 140413705484288 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 226.06

Steps executed: 1000 Episode length: 1000 Return: -450.11907532862997
I0901 23:56:11.208275 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -450.12
INFO:tensorflow:Starting iteration 8

Steps executed: 193 Episode length: 193 Return: -130.7682213475331797
INFO:tensorflow:Average training steps per second: 227.86

Steps executed: 686 Episode length: 493 Return: -305.8394735023980597
I0901 23:56:21.027898 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.30
INFO:tensorflow:Starting iteration 9
I0901 23:56:25.333815 140413705484288 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 225.17

Steps executed: 575 Episode length: 575 Return: -352.6457840640854397
I0901 23:56:30.790832 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.65
INFO:tensorflow:Starting iteration 10

Steps executed: 486 Episode length: 486 Return: -308.7278245060378397
INFO:tensorflow:Average training steps per second: 233.90
I0901 23:56:39.300194 140413705484288 replay_runner.py:36] Average training steps per second: 233.90
I0901 23:56:40.183043 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.73
INFO:tensorflow:Starting iteration 11
I0901 23:56:44.335392 140413705484288 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 245.18
I0901 23:56:48.414439 140413705484288 replay_runner.py:36] Average training steps per second: 245.18

Steps executed: 1000 Episode length: 1000 Return: -95.446164437788747
INFO:tensorflow:Starting iteration 12

Steps executed: 274 Episode length: 216 Return: -78.14302020508964747
INFO:tensorflow:Average training steps per second: 239.61
I0901 23:56:59.089268 140413705484288 replay_runner.py:36] Average training steps per second: 239.61
I0901 23:56:59.375766 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.50
INFO:tensorflow:Starting iteration 13

Steps executed: 245 Episode length: 245 Return: -133.3796523237381647
INFO:tensorflow:Average training steps per second: 241.86
I0901 23:57:07.771660 140413705484288 replay_runner.py:36] Average training steps per second: 241.86
I0901 23:57:08.042159 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.38
INFO:tensorflow:Starting iteration 14
I0901 23:57:12.462094 140413705484288 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 237.87

Steps executed: 343 Episode length: 343 Return: -162.0532907095512547
I0901 23:57:17.175659 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.05
INFO:tensorflow:Starting iteration 15

Steps executed: 264 Episode length: 129 Return: -245.5897513542425447
INFO:tensorflow:Average training steps per second: 227.08
I0901 23:57:25.964443 140413705484288 replay_runner.py:36] Average training steps per second: 227.08
I0901 23:57:26.191304 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.32
INFO:tensorflow:Starting iteration 16

Steps executed: 354 Episode length: 222 Return: -66.92957531705216447
INFO:tensorflow:Average training steps per second: 225.58
I0901 23:57:35.046525 140413705484288 replay_runner.py:36] Average training steps per second: 225.58
I0901 23:57:35.362343 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.56
INFO:tensorflow:Starting iteration 17
I0901 23:57:39.675823 140413705484288 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 226.86

Steps executed: 989 Episode length: 989 Return: -481.8603947601643447
I0901 23:57:47.168843 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -481.86
INFO:tensorflow:Starting iteration 18
I0901 23:57:51.581775 140413705484288 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 230.33

Steps executed: 1000 Episode length: 1000 Return: -143.27673404257376
I0901 23:57:59.089155 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.28
INFO:tensorflow:Starting iteration 19

Steps executed: 321 Episode length: 183 Return: -651.1677572379369576
INFO:tensorflow:Average training steps per second: 227.19
I0901 23:58:07.960874 140413705484288 replay_runner.py:36] Average training steps per second: 227.19
I0901 23:58:08.301224 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -515.09
INFO:tensorflow:Starting iteration 20

Steps executed: 255 Episode length: 132 Return: -589.6127524993503576
INFO:tensorflow:Average training steps per second: 229.96
I0901 23:58:17.014379 140413705484288 replay_runner.py:36] Average training steps per second: 229.96
I0901 23:58:17.279176 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -589.59
INFO:tensorflow:Starting iteration 21

Steps executed: 251 Episode length: 143 Return: -139.7211790237891576
INFO:tensorflow:Average training steps per second: 227.08
I0901 23:58:25.996817 140413705484288 replay_runner.py:36] Average training steps per second: 227.08
I0901 23:58:26.239917 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.92
INFO:tensorflow:Starting iteration 22

Steps executed: 278 Episode length: 84 Return: -172.99364081074503376
INFO:tensorflow:Average training steps per second: 227.85
I0901 23:58:35.026342 140413705484288 replay_runner.py:36] Average training steps per second: 227.85
I0901 23:58:35.245532 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.47
INFO:tensorflow:Starting iteration 23

Steps executed: 222 Episode length: 138 Return: -649.8421073471493376
INFO:tensorflow:Average training steps per second: 230.06
I0901 23:58:44.037719 140413705484288 replay_runner.py:36] Average training steps per second: 230.06
I0901 23:58:44.251712 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -672.39
INFO:tensorflow:Starting iteration 24

Steps executed: 297 Episode length: 131 Return: -158.1994117105536576
INFO:tensorflow:Average training steps per second: 230.22
I0901 23:58:52.976197 140413705484288 replay_runner.py:36] Average training steps per second: 230.22
I0901 23:58:53.226857 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.86
INFO:tensorflow:Starting iteration 25

Steps executed: 207 Episode length: 90 Return: -145.07357050504459776
INFO:tensorflow:Average training steps per second: 237.58
I0901 23:59:01.781013 140413705484288 replay_runner.py:36] Average training steps per second: 237.58
I0901 23:59:01.944154 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.53
INFO:tensorflow:Starting iteration 26

Steps executed: 197 Episode length: 70 Return: -514.07709289292028776
INFO:tensorflow:Average training steps per second: 235.72
I0901 23:59:10.590034 140413705484288 replay_runner.py:36] Average training steps per second: 235.72

Steps executed: 281 Episode length: 84 Return: -415.48838035222668776
INFO:tensorflow:Starting iteration 27

Steps executed: 220 Episode length: 84 Return: -465.58101518102926776
INFO:tensorflow:Average training steps per second: 232.09
I0901 23:59:19.574244 140413705484288 replay_runner.py:36] Average training steps per second: 232.09
I0901 23:59:19.764244 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -536.37
INFO:tensorflow:Starting iteration 28

Steps executed: 235 Episode length: 62 Return: -508.97632258562530376
INFO:tensorflow:Average training steps per second: 239.33
I0901 23:59:28.251283 140413705484288 replay_runner.py:36] Average training steps per second: 239.33
I0901 23:59:28.450959 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -422.24
INFO:tensorflow:Starting iteration 29
I0901 23:59:32.877336 140413705484288 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 240.99

Steps executed: 246 Episode length: 104 Return: -341.0211351488025376

Done fixed training!Episode length: 104 Return: -341.0211351488025376