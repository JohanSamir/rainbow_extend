I0905 16:28:15.680813 140275076675584 run_experiment.py:549] Creating TrainRunner ...
I0905 16:28:15.689673 140275076675584 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:28:15.689861 140275076675584 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:28:15.689955 140275076675584 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:28:15.690025 140275076675584 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:28:15.690119 140275076675584 dqn_agent.py:275] 	 update_period: 4
I0905 16:28:15.690200 140275076675584 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:28:15.690305 140275076675584 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:28:15.690383 140275076675584 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:28:15.690468 140275076675584 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:28:15.690579 140275076675584 dqn_agent.py:280] 	 optimizer: adam
I0905 16:28:15.690715 140275076675584 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:28:15.690818 140275076675584 dqn_agent.py:283] 	 seed: 1630859295689620
I0905 16:28:15.693002 140275076675584 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:28:15.693189 140275076675584 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:28:15.693294 140275076675584 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:28:15.693427 140275076675584 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:28:15.693537 140275076675584 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:28:15.693687 140275076675584 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:28:15.693785 140275076675584 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:28:15.693865 140275076675584 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:28:15.693936 140275076675584 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0905 16:28:17.497351 140275076675584 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:17.862502 140275076675584 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:17.873656 140275076675584 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:28:17.880305 140275076675584 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:28:17.880606 140275076675584 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:28:17.880828 140275076675584 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:28:17.881060 140275076675584 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:28:17.881194 140275076675584 dqn_agent.py:275] 	 update_period: 4
I0905 16:28:17.881303 140275076675584 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:28:17.881383 140275076675584 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:28:17.881494 140275076675584 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:28:17.881601 140275076675584 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:28:17.881677 140275076675584 dqn_agent.py:280] 	 optimizer: adam
I0905 16:28:17.881816 140275076675584 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:28:17.881895 140275076675584 dqn_agent.py:283] 	 seed: 1630859297880263
I0905 16:28:17.883750 140275076675584 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:28:17.883884 140275076675584 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:28:17.883973 140275076675584 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:28:17.884042 140275076675584 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:28:17.884108 140275076675584 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:28:17.884167 140275076675584 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:28:17.884231 140275076675584 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:28:17.884288 140275076675584 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:28:17.884366 140275076675584 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:28:17.908758 140275076675584 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:17.924582 140275076675584 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:28:17.924851 140275076675584 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 212.82
I0905 16:28:22.623809 140275076675584 replay_runner.py:36] Average training steps per second: 212.82
Steps executed: 220 Episode length: 220 Return: -37.51781417211075
I0905 16:28:23.603299 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.52
INFO:tensorflow:Starting iteration 1

Steps executed: 324 Episode length: 132 Return: -356.00394267469798
INFO:tensorflow:Average training steps per second: 291.78
I0905 16:28:30.736147 140275076675584 replay_runner.py:36] Average training steps per second: 291.78
I0905 16:28:30.945643 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -239.50
INFO:tensorflow:Starting iteration 2

Steps executed: 261 Episode length: 108 Return: -306.32247007833438
INFO:tensorflow:Average training steps per second: 280.42
I0905 16:28:38.223687 140275076675584 replay_runner.py:36] Average training steps per second: 280.42
I0905 16:28:38.372752 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.14
INFO:tensorflow:Starting iteration 3
I0905 16:28:42.061838 140275076675584 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 300.26

Steps executed: 236 Episode length: 141 Return: -219.89632420842958
I0905 16:28:45.513108 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.21
INFO:tensorflow:Starting iteration 4

Steps executed: 262 Episode length: 111 Return: -60.145598782096647
INFO:tensorflow:Average training steps per second: 299.58
I0905 16:28:52.582505 140275076675584 replay_runner.py:36] Average training steps per second: 299.58
I0905 16:28:52.725441 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.57
INFO:tensorflow:Starting iteration 5

Steps executed: 684 Episode length: 684 Return: -477.79442195609457
INFO:tensorflow:Average training steps per second: 303.19
I0905 16:28:59.642914 140275076675584 replay_runner.py:36] Average training steps per second: 303.19
I0905 16:29:00.653761 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -477.79
INFO:tensorflow:Starting iteration 6
I0905 16:29:04.281472 140275076675584 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 305.11

Steps executed: 212 Episode length: 106 Return: -185.81143634546197
I0905 16:29:07.675444 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.52
INFO:tensorflow:Starting iteration 7
I0905 16:29:11.249077 140275076675584 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 282.77

Steps executed: 859 Episode length: 859 Return: -3266.2147095226937
I0905 16:29:16.361017 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -3266.21
INFO:tensorflow:Starting iteration 8
I0905 16:29:20.275409 140275076675584 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 248.74

Steps executed: 1000 Episode length: 1000 Return: -90.98794101401717
I0905 16:29:26.574705 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.99
INFO:tensorflow:Starting iteration 9
I0905 16:29:30.747436 140275076675584 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 232.06

Steps executed: 684 Episode length: 684 Return: -2935.54476983336917
I0905 16:29:36.404830 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -2935.54
INFO:tensorflow:Starting iteration 10
I0905 16:29:40.635468 140275076675584 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 232.35

Steps executed: 1000 Episode length: 1000 Return: -319.74187155838507
I0905 16:29:48.603762 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -319.74
INFO:tensorflow:Starting iteration 11
I0905 16:29:52.813438 140275076675584 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 232.21
I0905 16:29:57.120126 140275076675584 replay_runner.py:36] Average training steps per second: 232.21

Steps executed: 571 Episode length: 571 Return: -309.3453674703328607
INFO:tensorflow:Starting iteration 12

Steps executed: 114 Episode length: 114 Return: -648.9432693980415607
INFO:tensorflow:Average training steps per second: 234.41
I0905 16:30:06.340270 140275076675584 replay_runner.py:36] Average training steps per second: 234.41

Steps executed: 1038 Episode length: 924 Return: -1125.86278602068847
INFO:tensorflow:Starting iteration 13
I0905 16:30:14.193300 140275076675584 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 234.88

Steps executed: 749 Episode length: 749 Return: -920.7591320870548847
I0905 16:30:20.413971 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -920.76
INFO:tensorflow:Starting iteration 14

Steps executed: 241 Episode length: 74 Return: -17.424154761024525847
INFO:tensorflow:Average training steps per second: 231.63
I0905 16:30:28.940021 140275076675584 replay_runner.py:36] Average training steps per second: 231.63
I0905 16:30:29.118099 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: 106.01
INFO:tensorflow:Starting iteration 15
I0905 16:30:33.326812 140275076675584 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 235.16

Steps executed: 528 Episode length: 528 Return: -95.79670969152934847
I0905 16:30:38.411563 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.80
INFO:tensorflow:Starting iteration 16
I0905 16:30:42.502229 140275076675584 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 231.96

Steps executed: 1000 Episode length: 1000 Return: -140.18579605489128
I0905 16:30:48.999762 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.19
INFO:tensorflow:Starting iteration 17
I0905 16:30:53.254517 140275076675584 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 231.46

Steps executed: 300 Episode length: 121 Return: -254.4216019261392128
I0905 16:30:57.802386 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.58
INFO:tensorflow:Starting iteration 18
I0905 16:31:02.040048 140275076675584 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 229.99

Steps executed: 1000 Episode length: 1000 Return: -75.425654226954968
I0905 16:31:10.083585 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.43
INFO:tensorflow:Starting iteration 19
I0905 16:31:14.342626 140275076675584 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 230.54

Steps executed: 936 Episode length: 936 Return: 123.44774458877363968
I0905 16:31:20.913541 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: 123.45
INFO:tensorflow:Starting iteration 20

Steps executed: 213 Episode length: 213 Return: -25.63016934919527968
INFO:tensorflow:Average training steps per second: 231.68
I0905 16:31:29.407436 140275076675584 replay_runner.py:36] Average training steps per second: 231.68
I0905 16:31:29.603147 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -25.63
INFO:tensorflow:Starting iteration 21
I0905 16:31:33.867209 140275076675584 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 231.46
I0905 16:31:38.187961 140275076675584 replay_runner.py:36] Average training steps per second: 231.46

Steps executed: 1000 Episode length: 1000 Return: -59.680405133952778
INFO:tensorflow:Starting iteration 22
I0905 16:31:46.135818 140275076675584 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 253.79

Steps executed: 497 Episode length: 497 Return: -360.6957060238744478
I0905 16:31:51.108971 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -360.70
INFO:tensorflow:Starting iteration 23

Steps executed: 282 Episode length: 148 Return: -417.1158054842119378
INFO:tensorflow:Average training steps per second: 236.24
I0905 16:31:59.366086 140275076675584 replay_runner.py:36] Average training steps per second: 236.24
I0905 16:31:59.552206 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -316.18
INFO:tensorflow:Starting iteration 24

Steps executed: 339 Episode length: 199 Return: -478.7024199124137578
INFO:tensorflow:Average training steps per second: 198.53
I0905 16:32:08.756932 140275076675584 replay_runner.py:36] Average training steps per second: 198.53
I0905 16:32:09.080957 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -417.60
INFO:tensorflow:Starting iteration 25

Steps executed: 275 Episode length: 132 Return: -313.7297653057891678
INFO:tensorflow:Average training steps per second: 201.68
I0905 16:32:18.474518 140275076675584 replay_runner.py:36] Average training steps per second: 201.68
I0905 16:32:18.733537 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -357.64
INFO:tensorflow:Starting iteration 26

Steps executed: 267 Episode length: 106 Return: -511.8135113077420378
INFO:tensorflow:Average training steps per second: 181.24
I0905 16:32:28.990517 140275076675584 replay_runner.py:36] Average training steps per second: 181.24
I0905 16:32:29.258819 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.29
INFO:tensorflow:Starting iteration 27
I0905 16:32:33.855191 140275076675584 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 161.36

Steps executed: 292 Episode length: 118 Return: -538.3123364513764378
I0905 16:32:40.410724 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.60
INFO:tensorflow:Starting iteration 28

Steps executed: 282 Episode length: 282 Return: -426.5466512684135478
INFO:tensorflow:Average training steps per second: 175.22
I0905 16:32:51.402913 140275076675584 replay_runner.py:36] Average training steps per second: 175.22
I0905 16:32:51.886989 140275076675584 run_experiment.py:428] Average undiscounted return per evaluation episode: -426.55
INFO:tensorflow:Starting iteration 29

Steps executed: 349 Episode length: 184 Return: -355.2892094022090578
INFO:tensorflow:Average training steps per second: 168.65
I0905 16:33:02.955982 140275076675584 replay_runner.py:36] Average training steps per second: 168.65

Done fixed training!Episode length: 184 Return: -355.2892094022090578