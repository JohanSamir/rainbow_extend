Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0901 13:08:43.387782 139982171817984 run_experiment.py:549] Creating TrainRunner ...
I0901 13:08:43.396750 139982171817984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:08:43.396907 139982171817984 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:08:43.396983 139982171817984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:08:43.397044 139982171817984 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:08:43.397100 139982171817984 dqn_agent.py:275] 	 update_period: 4
I0901 13:08:43.397183 139982171817984 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:08:43.397271 139982171817984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:08:43.397360 139982171817984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:08:43.397429 139982171817984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:08:43.397507 139982171817984 dqn_agent.py:280] 	 optimizer: adam
I0901 13:08:43.397588 139982171817984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:08:43.397669 139982171817984 dqn_agent.py:283] 	 seed: 1630501723396708
I0901 13:08:43.399335 139982171817984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:08:43.399445 139982171817984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:08:43.399520 139982171817984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:08:43.399583 139982171817984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:08:43.399706 139982171817984 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:08:43.399761 139982171817984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:08:43.399844 139982171817984 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:08:43.399935 139982171817984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:08:43.400014 139982171817984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:08:43.511073 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:43.771012 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:43.778950 139982171817984 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:08:43.785983 139982171817984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:08:43.786143 139982171817984 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:08:43.786219 139982171817984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:08:43.786282 139982171817984 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:08:43.786339 139982171817984 dqn_agent.py:275] 	 update_period: 4
I0901 13:08:43.786422 139982171817984 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:08:43.786480 139982171817984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:08:43.786587 139982171817984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:08:43.786677 139982171817984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:08:43.786749 139982171817984 dqn_agent.py:280] 	 optimizer: adam
I0901 13:08:43.786815 139982171817984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:08:43.786895 139982171817984 dqn_agent.py:283] 	 seed: 1630501723785950
I0901 13:08:43.788259 139982171817984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:08:43.788368 139982171817984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:08:43.788462 139982171817984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:08:43.788528 139982171817984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:08:43.788585 139982171817984 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:08:43.788668 139982171817984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:08:43.788742 139982171817984 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:08:43.788807 139982171817984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:08:43.788884 139982171817984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:08:43.809688 139982171817984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:43.823560 139982171817984 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:08:43.823741 139982171817984 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 240.58
I0901 13:08:47.980569 139982171817984 replay_runner.py:36] Average training steps per second: 240.58
I0901 13:08:48.787686 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.32
Steps executed: 229 Episode length: 114 Return: -316.81866920709596
INFO:tensorflow:Starting iteration 1

Steps executed: 252 Episode length: 133 Return: -333.47815120022036
INFO:tensorflow:Average training steps per second: 356.79
I0901 13:08:55.052327 139982171817984 replay_runner.py:36] Average training steps per second: 356.79
I0901 13:08:55.209182 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.42
INFO:tensorflow:Starting iteration 2

Steps executed: 222 Episode length: 118 Return: -11.865018735222066
INFO:tensorflow:Average training steps per second: 351.42
I0901 13:09:01.461424 139982171817984 replay_runner.py:36] Average training steps per second: 351.42
I0901 13:09:01.587802 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.76
INFO:tensorflow:Starting iteration 3

Steps executed: 261 Episode length: 100 Return: -403.30993484745743
INFO:tensorflow:Average training steps per second: 355.24
I0901 13:09:07.888941 139982171817984 replay_runner.py:36] Average training steps per second: 355.24
I0901 13:09:08.060320 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -374.89
INFO:tensorflow:Starting iteration 4

Steps executed: 245 Episode length: 101 Return: -179.72007224994132
INFO:tensorflow:Average training steps per second: 345.45
I0901 13:09:14.440117 139982171817984 replay_runner.py:36] Average training steps per second: 345.45
I0901 13:09:14.599315 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -295.35
INFO:tensorflow:Starting iteration 5

Steps executed: 243 Episode length: 102 Return: -302.25949911183614
INFO:tensorflow:Average training steps per second: 353.08
I0901 13:09:20.933332 139982171817984 replay_runner.py:36] Average training steps per second: 353.08
I0901 13:09:21.093715 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -401.57
INFO:tensorflow:Starting iteration 6

Steps executed: 265 Episode length: 130 Return: -134.10350811048824
INFO:tensorflow:Average training steps per second: 349.04
I0901 13:09:27.455880 139982171817984 replay_runner.py:36] Average training steps per second: 349.04
I0901 13:09:27.619256 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.35
INFO:tensorflow:Starting iteration 7

Steps executed: 301 Episode length: 189 Return: 229.348288285720543
INFO:tensorflow:Average training steps per second: 348.92
I0901 13:09:33.989204 139982171817984 replay_runner.py:36] Average training steps per second: 348.92
I0901 13:09:34.177192 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: 102.28
INFO:tensorflow:Starting iteration 8

Steps executed: 212 Episode length: 108 Return: -148.48543586914457
INFO:tensorflow:Average training steps per second: 347.50
I0901 13:09:40.565688 139982171817984 replay_runner.py:36] Average training steps per second: 347.50
I0901 13:09:40.676198 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.88
INFO:tensorflow:Starting iteration 9

Steps executed: 296 Episode length: 148 Return: 21.2341590738581817
INFO:tensorflow:Average training steps per second: 342.95
I0901 13:09:47.021230 139982171817984 replay_runner.py:36] Average training steps per second: 342.95
I0901 13:09:47.187792 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -11.48
INFO:tensorflow:Starting iteration 10

Steps executed: 228 Episode length: 113 Return: -35.005735820449677
INFO:tensorflow:Average training steps per second: 339.49
I0901 13:09:53.595658 139982171817984 replay_runner.py:36] Average training steps per second: 339.49
I0901 13:09:53.718930 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -21.37
INFO:tensorflow:Starting iteration 11

Steps executed: 280 Episode length: 144 Return: -175.08163225477777
INFO:tensorflow:Average training steps per second: 343.20
I0901 13:10:00.097813 139982171817984 replay_runner.py:36] Average training steps per second: 343.20
I0901 13:10:00.266168 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.72
INFO:tensorflow:Starting iteration 12

Steps executed: 217 Episode length: 106 Return: -456.05969913845854
INFO:tensorflow:Average training steps per second: 344.94
I0901 13:10:06.617573 139982171817984 replay_runner.py:36] Average training steps per second: 344.94
I0901 13:10:06.736696 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -486.34
INFO:tensorflow:Starting iteration 13

Steps executed: 267 Episode length: 108 Return: -176.80070486090096
INFO:tensorflow:Average training steps per second: 347.93
I0901 13:10:13.004137 139982171817984 replay_runner.py:36] Average training steps per second: 347.93
I0901 13:10:13.149722 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.08
INFO:tensorflow:Starting iteration 14
I0901 13:10:16.615585 139982171817984 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 350.63

Steps executed: 224 Episode length: 118 Return: -52.480321847072363
I0901 13:10:19.601264 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.81
INFO:tensorflow:Starting iteration 15

Steps executed: 306 Episode length: 306 Return: -287.60193342786383
INFO:tensorflow:Average training steps per second: 344.01
I0901 13:10:25.926894 139982171817984 replay_runner.py:36] Average training steps per second: 344.01
I0901 13:10:26.224017 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.60
INFO:tensorflow:Starting iteration 16

Steps executed: 277 Episode length: 83 Return: -136.708948004801444
INFO:tensorflow:Average training steps per second: 338.88
I0901 13:10:32.538760 139982171817984 replay_runner.py:36] Average training steps per second: 338.88
I0901 13:10:32.710015 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.86
INFO:tensorflow:Starting iteration 17

Steps executed: 219 Episode length: 119 Return: -126.98517568352534
INFO:tensorflow:Average training steps per second: 326.40
I0901 13:10:39.111008 139982171817984 replay_runner.py:36] Average training steps per second: 326.40
I0901 13:10:39.244137 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.71
INFO:tensorflow:Starting iteration 18

Steps executed: 146 Episode length: 146 Return: -162.55615148804194
INFO:tensorflow:Average training steps per second: 329.44
I0901 13:10:45.581231 139982171817984 replay_runner.py:36] Average training steps per second: 329.44

Steps executed: 280 Episode length: 134 Return: -65.394206996539494
INFO:tensorflow:Starting iteration 19

Steps executed: 216 Episode length: 164 Return: 4.61401811750671794
INFO:tensorflow:Average training steps per second: 331.09
I0901 13:10:52.087381 139982171817984 replay_runner.py:36] Average training steps per second: 331.09
I0901 13:10:52.204816 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -38.62
INFO:tensorflow:Starting iteration 20

Steps executed: 214 Episode length: 102 Return: -96.832183416852434
INFO:tensorflow:Average training steps per second: 322.99
I0901 13:10:58.536442 139982171817984 replay_runner.py:36] Average training steps per second: 322.99
I0901 13:10:58.653862 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.88
INFO:tensorflow:Starting iteration 21

Steps executed: 220 Episode length: 111 Return: -61.136621791223384
INFO:tensorflow:Average training steps per second: 319.94
I0901 13:11:04.895951 139982171817984 replay_runner.py:36] Average training steps per second: 319.94
I0901 13:11:05.023583 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.95
INFO:tensorflow:Starting iteration 22

Steps executed: 203 Episode length: 96 Return: -112.942583494149934
INFO:tensorflow:Average training steps per second: 317.53
I0901 13:11:11.225489 139982171817984 replay_runner.py:36] Average training steps per second: 317.53
I0901 13:11:11.344851 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.42
INFO:tensorflow:Starting iteration 23
I0901 13:11:14.493453 139982171817984 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 350.43

Steps executed: 1000 Episode length: 1000 Return: -37.573738623228756
I0901 13:11:19.525068 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.57
INFO:tensorflow:Starting iteration 24

Steps executed: 1000 Episode length: 1000 Return: -115.58845543350304
INFO:tensorflow:Average training steps per second: 321.09
I0901 13:11:25.788591 139982171817984 replay_runner.py:36] Average training steps per second: 321.09
I0901 13:11:27.165278 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.59
INFO:tensorflow:Starting iteration 25
I0901 13:11:30.345555 139982171817984 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 329.25

Steps executed: 1000 Episode length: 1000 Return: -111.68749993667747
I0901 13:11:35.188883 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.69
INFO:tensorflow:Starting iteration 26
I0901 13:11:38.550323 139982171817984 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 342.72

Steps executed: 1000 Episode length: 1000 Return: -59.124820936126647
I0901 13:11:43.146226 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -59.12
INFO:tensorflow:Starting iteration 27
I0901 13:11:46.495577 139982171817984 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 360.36

Steps executed: 1000 Episode length: 1000 Return: -111.10434820195283
I0901 13:11:52.146466 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.10
INFO:tensorflow:Starting iteration 28
I0901 13:11:55.542510 139982171817984 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 350.11

Steps executed: 1000 Episode length: 1000 Return: -175.69345073693993
I0901 13:12:01.393949 139982171817984 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.69
INFO:tensorflow:Starting iteration 29
I0901 13:12:04.771307 139982171817984 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 359.90

Steps executed: 1000 Episode length: 1000 Return: -160.61979721417114

Done fixed training! Episode length: 1000 Return: -160.61979721417114