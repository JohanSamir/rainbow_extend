Loaded trained dqn in cartpole
Training fixed agent 2, please be patient, may be a while...
I0828 10:24:39.409905 140137371908096 run_experiment.py:549] Creating TrainRunner ...
I0828 10:24:39.418071 140137371908096 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:24:39.418288 140137371908096 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:24:39.418370 140137371908096 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:24:39.418476 140137371908096 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:24:39.418688 140137371908096 dqn_agent.py:275] 	 update_period: 4
I0828 10:24:39.418795 140137371908096 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:24:39.418875 140137371908096 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:24:39.418948 140137371908096 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:24:39.419056 140137371908096 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:24:39.419175 140137371908096 dqn_agent.py:280] 	 optimizer: adam
I0828 10:24:39.419308 140137371908096 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:24:39.419384 140137371908096 dqn_agent.py:283] 	 seed: 1630146279418024
I0828 10:24:39.422709 140137371908096 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:24:39.422901 140137371908096 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0828 10:24:39.423066 140137371908096 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:24:39.423148 140137371908096 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:24:39.423208 140137371908096 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:24:39.423265 140137371908096 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:24:39.423372 140137371908096 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:24:39.423441 140137371908096 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:24:39.423532 140137371908096 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:24:39.457594 140137371908096 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:24:39.937822 140137371908096 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:24:39.953963 140137371908096 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:24:39.964941 140137371908096 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:24:39.965188 140137371908096 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:24:39.965331 140137371908096 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:24:39.965440 140137371908096 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:24:39.965542 140137371908096 dqn_agent.py:275] 	 update_period: 4
I0828 10:24:39.965657 140137371908096 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:24:39.965825 140137371908096 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:24:39.965946 140137371908096 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:24:39.966050 140137371908096 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:24:39.966232 140137371908096 dqn_agent.py:280] 	 optimizer: adam
I0828 10:24:39.966371 140137371908096 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:24:39.966548 140137371908096 dqn_agent.py:283] 	 seed: 1630146279964880
I0828 10:24:39.969024 140137371908096 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:24:39.969190 140137371908096 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0828 10:24:39.969340 140137371908096 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:24:39.969498 140137371908096 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:24:39.969640 140137371908096 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:24:39.969773 140137371908096 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:24:39.969905 140137371908096 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:24:39.970043 140137371908096 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:24:39.970196 140137371908096 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:24:40.005439 140137371908096 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:24:40.029627 140137371908096 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:24:40.030043 140137371908096 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 161.51
I0828 10:24:46.222089 140137371908096 replay_runner.py:36] Average training steps per second: 161.51
Steps executed: 204 Episode length: 9 Return: 9.0.0
I0828 10:24:47.290581 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.27
INFO:tensorflow:Starting iteration 1

Steps executed: 207 Episode length: 11 Return: 11.0
INFO:tensorflow:Average training steps per second: 203.96
I0828 10:24:52.377791 140137371908096 replay_runner.py:36] Average training steps per second: 203.96
I0828 10:24:52.525761 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.86
INFO:tensorflow:Starting iteration 2

Steps executed: 202 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 190.52
I0828 10:24:57.953995 140137371908096 replay_runner.py:36] Average training steps per second: 190.52
I0828 10:24:58.106780 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.18
INFO:tensorflow:Starting iteration 3

Steps executed: 253 Episode length: 64 Return: 64.0
INFO:tensorflow:Average training steps per second: 193.56
I0828 10:25:03.465343 140137371908096 replay_runner.py:36] Average training steps per second: 193.56
I0828 10:25:03.642473 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 63.25
INFO:tensorflow:Starting iteration 4

Steps executed: 128 Episode length: 51 Return: 51.0
INFO:tensorflow:Average training steps per second: 192.12
I0828 10:25:09.046376 140137371908096 replay_runner.py:36] Average training steps per second: 192.12

Steps executed: 210 Episode length: 43 Return: 43.0
INFO:tensorflow:Starting iteration 5

Steps executed: 265 Episode length: 87 Return: 87.0
INFO:tensorflow:Average training steps per second: 193.75
I0828 10:25:14.548988 140137371908096 replay_runner.py:36] Average training steps per second: 193.75
I0828 10:25:14.742225 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 88.33
INFO:tensorflow:Starting iteration 6

Steps executed: 293 Episode length: 99 Return: 99.0
INFO:tensorflow:Average training steps per second: 189.21
I0828 10:25:20.220510 140137371908096 replay_runner.py:36] Average training steps per second: 189.21
I0828 10:25:20.424212 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 97.67
INFO:tensorflow:Starting iteration 7

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 190.07
I0828 10:25:25.861339 140137371908096 replay_runner.py:36] Average training steps per second: 190.07
I0828 10:25:25.999458 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 8
I0828 10:25:26.178602 140137371908096 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 193.90

Steps executed: 281 Episode length: 96 Return: 96.0.0
I0828 10:25:31.530055 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 93.67
INFO:tensorflow:Starting iteration 9

Steps executed: 202 Episode length: 102 Return: 102.0
INFO:tensorflow:Average training steps per second: 188.30
I0828 10:25:37.029256 140137371908096 replay_runner.py:36] Average training steps per second: 188.30
I0828 10:25:37.166791 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 101.00
INFO:tensorflow:Starting iteration 10

Steps executed: 290 Episode length: 95 Return: 95.0.0
INFO:tensorflow:Average training steps per second: 192.10
I0828 10:25:42.561928 140137371908096 replay_runner.py:36] Average training steps per second: 192.10
I0828 10:25:42.756893 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 96.67
INFO:tensorflow:Starting iteration 11

Steps executed: 213 Episode length: 15 Return: 15.0.0
INFO:tensorflow:Average training steps per second: 194.15
I0828 10:25:48.103815 140137371908096 replay_runner.py:36] Average training steps per second: 194.15
I0828 10:25:48.255869 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 15.21
INFO:tensorflow:Starting iteration 12
I0828 10:25:48.452817 140137371908096 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 195.82

Steps executed: 221 Episode length: 114 Return: 114.0
I0828 10:25:53.726529 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 110.50
INFO:tensorflow:Starting iteration 13

Steps executed: 267 Episode length: 90 Return: 90.0.0
INFO:tensorflow:Average training steps per second: 191.88
I0828 10:25:59.126414 140137371908096 replay_runner.py:36] Average training steps per second: 191.88
I0828 10:25:59.303857 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 89.00
INFO:tensorflow:Starting iteration 14

Steps executed: 296 Episode length: 102 Return: 102.0
INFO:tensorflow:Average training steps per second: 193.08
I0828 10:26:04.677237 140137371908096 replay_runner.py:36] Average training steps per second: 193.08
I0828 10:26:04.878775 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 98.67
INFO:tensorflow:Starting iteration 15

Steps executed: 284 Episode length: 96 Return: 96.0.0
INFO:tensorflow:Average training steps per second: 192.75
I0828 10:26:10.264799 140137371908096 replay_runner.py:36] Average training steps per second: 192.75
I0828 10:26:10.456975 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 94.67
INFO:tensorflow:Starting iteration 16
I0828 10:26:10.648385 140137371908096 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 193.04

Steps executed: 212 Episode length: 107 Return: 107.0
I0828 10:26:15.978661 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 106.00
INFO:tensorflow:Starting iteration 17
I0828 10:26:16.169221 140137371908096 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 191.32

Steps executed: 204 Episode length: 102 Return: 102.0
I0828 10:26:21.539898 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 102.00
INFO:tensorflow:Starting iteration 18

Steps executed: 215 Episode length: 105 Return: 105.0
INFO:tensorflow:Average training steps per second: 194.75
I0828 10:26:26.860557 140137371908096 replay_runner.py:36] Average training steps per second: 194.75
I0828 10:26:27.015105 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 107.50
INFO:tensorflow:Starting iteration 19

Steps executed: 274 Episode length: 136 Return: 136.0
INFO:tensorflow:Average training steps per second: 190.86
I0828 10:26:32.434533 140137371908096 replay_runner.py:36] Average training steps per second: 190.86
I0828 10:26:32.620763 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 137.00
INFO:tensorflow:Starting iteration 20

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 194.09
I0828 10:26:37.968525 140137371908096 replay_runner.py:36] Average training steps per second: 194.09
I0828 10:26:38.110734 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 21
I0828 10:26:38.302625 140137371908096 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 195.08
I0828 10:26:43.429231 140137371908096 replay_runner.py:36] Average training steps per second: 195.08
I0828 10:26:43.560783 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 22

Steps executed: 281 Episode length: 86 Return: 86.0.0
INFO:tensorflow:Average training steps per second: 192.47
I0828 10:26:48.945302 140137371908096 replay_runner.py:36] Average training steps per second: 192.47
I0828 10:26:49.140784 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 93.67
INFO:tensorflow:Starting iteration 23

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 198.71
I0828 10:26:54.367617 140137371908096 replay_runner.py:36] Average training steps per second: 198.71
I0828 10:26:54.496077 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 24

Steps executed: 201 Episode length: 99 Return: 99.0.0
INFO:tensorflow:Average training steps per second: 193.16
I0828 10:26:59.864371 140137371908096 replay_runner.py:36] Average training steps per second: 193.16
I0828 10:26:59.994634 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 100.50
INFO:tensorflow:Starting iteration 25

Steps executed: 252 Episode length: 124 Return: 124.0
INFO:tensorflow:Average training steps per second: 195.59
I0828 10:27:05.295916 140137371908096 replay_runner.py:36] Average training steps per second: 195.59
I0828 10:27:05.467851 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 126.00
INFO:tensorflow:Starting iteration 26

Steps executed: 231 Episode length: 124 Return: 124.0
INFO:tensorflow:Average training steps per second: 197.24
I0828 10:27:10.733438 140137371908096 replay_runner.py:36] Average training steps per second: 197.24
I0828 10:27:10.892525 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 115.50
INFO:tensorflow:Starting iteration 27

Steps executed: 227 Episode length: 114 Return: 114.0
INFO:tensorflow:Average training steps per second: 196.01
I0828 10:27:16.186042 140137371908096 replay_runner.py:36] Average training steps per second: 196.01
I0828 10:27:16.341388 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 113.50
INFO:tensorflow:Starting iteration 28

Steps executed: 258 Episode length: 123 Return: 123.0
INFO:tensorflow:Average training steps per second: 210.26
I0828 10:27:21.283786 140137371908096 replay_runner.py:36] Average training steps per second: 210.26
I0828 10:27:21.442023 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 129.00
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 202.92
I0828 10:27:26.545412 140137371908096 replay_runner.py:36] Average training steps per second: 202.92
I0828 10:27:26.664078 140137371908096 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00