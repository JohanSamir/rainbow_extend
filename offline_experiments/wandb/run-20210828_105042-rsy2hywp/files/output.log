Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0828 10:50:47.197906 140214119393280 run_experiment.py:549] Creating TrainRunner ...
I0828 10:50:47.208785 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:50:47.209018 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:50:47.209144 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:50:47.209259 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:50:47.209616 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:50:47.210046 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:50:47.210444 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:50:47.210579 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:50:47.210690 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:50:47.210795 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:50:47.210897 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:50:47.210995 140214119393280 dqn_agent.py:283] 	 seed: 1630147847208729
I0828 10:50:47.214473 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:50:47.214665 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:50:47.214820 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:50:47.214940 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:50:47.215045 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:50:47.215145 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:50:47.215243 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:50:47.215350 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:50:47.215454 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:50:47.253189 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:50:47.519940 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:50:47.529828 140214119393280 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:50:47.537084 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:50:47.537225 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:50:47.537305 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:50:47.537368 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:50:47.537425 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:50:47.537478 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:50:47.537531 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:50:47.537584 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:50:47.537635 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:50:47.537686 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:50:47.537738 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:50:47.537788 140214119393280 dqn_agent.py:283] 	 seed: 1630147847537054
I0828 10:50:47.539575 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:50:47.539697 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:50:47.539773 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:50:47.539840 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:50:47.539895 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:50:47.539963 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:50:47.540044 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:50:47.540120 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:50:47.540210 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:50:47.559331 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:50:47.573126 140214119393280 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:50:47.573261 140214119393280 replay_runner.py:41] Starting iteration 0
Steps executed: 322 Episode length: 182 Return: -480.76194594673444
INFO:tensorflow:Average training steps per second: 256.42
I0828 10:50:51.473247 140214119393280 replay_runner.py:36] Average training steps per second: 256.42
I0828 10:50:52.218929 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -453.64
INFO:tensorflow:Starting iteration 1

Steps executed: 240 Episode length: 129 Return: -326.79083289273285
INFO:tensorflow:Average training steps per second: 351.07
I0828 10:50:58.433698 140214119393280 replay_runner.py:36] Average training steps per second: 351.07
I0828 10:50:58.575602 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.71
INFO:tensorflow:Starting iteration 2
I0828 10:51:02.059732 140214119393280 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 352.22

Steps executed: 438 Episode length: 308 Return: -22.951822593477065
I0828 10:51:05.220042 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -183.65
INFO:tensorflow:Starting iteration 3

Steps executed: 217 Episode length: 132 Return: -324.15415195079584
INFO:tensorflow:Average training steps per second: 341.15
I0828 10:51:11.615270 140214119393280 replay_runner.py:36] Average training steps per second: 341.15
I0828 10:51:11.728394 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -375.08
INFO:tensorflow:Starting iteration 4

Steps executed: 235 Episode length: 98 Return: -455.692945906806954
INFO:tensorflow:Average training steps per second: 343.01
I0828 10:51:18.006362 140214119393280 replay_runner.py:36] Average training steps per second: 343.01
I0828 10:51:18.143041 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -453.21
INFO:tensorflow:Starting iteration 5

Steps executed: 221 Episode length: 126 Return: -334.86174589212277
INFO:tensorflow:Average training steps per second: 339.59
I0828 10:51:24.532556 140214119393280 replay_runner.py:36] Average training steps per second: 339.59
I0828 10:51:24.648397 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -286.17
INFO:tensorflow:Starting iteration 6

Steps executed: 226 Episode length: 98 Return: -222.158473479773767
INFO:tensorflow:Average training steps per second: 334.52
I0828 10:51:31.080652 140214119393280 replay_runner.py:36] Average training steps per second: 334.52
I0828 10:51:31.192050 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -294.46
INFO:tensorflow:Starting iteration 7

Steps executed: 234 Episode length: 99 Return: -404.675837025794077
INFO:tensorflow:Average training steps per second: 332.28
I0828 10:51:37.600072 140214119393280 replay_runner.py:36] Average training steps per second: 332.28
I0828 10:51:37.721766 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -399.30
INFO:tensorflow:Starting iteration 8

Steps executed: 270 Episode length: 96 Return: -261.546130425582967
INFO:tensorflow:Average training steps per second: 334.58
I0828 10:51:44.107635 140214119393280 replay_runner.py:36] Average training steps per second: 334.58
I0828 10:51:44.249704 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -372.05
INFO:tensorflow:Starting iteration 9

Steps executed: 222 Episode length: 132 Return: -303.54549791975557
INFO:tensorflow:Average training steps per second: 335.44
I0828 10:51:50.651278 140214119393280 replay_runner.py:36] Average training steps per second: 335.44
I0828 10:51:50.778914 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.13
INFO:tensorflow:Starting iteration 10

Steps executed: 237 Episode length: 160 Return: -292.76509979325957
INFO:tensorflow:Average training steps per second: 328.80
I0828 10:51:57.222450 140214119393280 replay_runner.py:36] Average training steps per second: 328.80
I0828 10:51:57.376885 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -305.44
INFO:tensorflow:Starting iteration 11

Steps executed: 290 Episode length: 130 Return: -321.51253803942166
INFO:tensorflow:Average training steps per second: 324.00
I0828 10:52:03.847776 140214119393280 replay_runner.py:36] Average training steps per second: 324.00
I0828 10:52:04.019231 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.50
INFO:tensorflow:Starting iteration 12

Steps executed: 219 Episode length: 69 Return: -211.162224226133816
INFO:tensorflow:Average training steps per second: 332.96
I0828 10:52:10.384162 140214119393280 replay_runner.py:36] Average training steps per second: 332.96
I0828 10:52:10.527281 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.66
INFO:tensorflow:Starting iteration 13

Steps executed: 299 Episode length: 145 Return: -275.31213795255985
INFO:tensorflow:Average training steps per second: 332.70
I0828 10:52:16.906935 140214119393280 replay_runner.py:36] Average training steps per second: 332.70
I0828 10:52:17.064803 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.22
INFO:tensorflow:Starting iteration 14

Steps executed: 270 Episode length: 183 Return: -445.49561788358477
INFO:tensorflow:Average training steps per second: 328.57
I0828 10:52:23.476840 140214119393280 replay_runner.py:36] Average training steps per second: 328.57
I0828 10:52:23.653579 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.41
INFO:tensorflow:Starting iteration 15

Steps executed: 249 Episode length: 89 Return: -605.615065735566877
INFO:tensorflow:Average training steps per second: 338.29
I0828 10:52:29.990351 140214119393280 replay_runner.py:36] Average training steps per second: 338.29
I0828 10:52:30.138870 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -455.31
INFO:tensorflow:Starting iteration 16

Steps executed: 214 Episode length: 84 Return: -245.549046303845057
INFO:tensorflow:Average training steps per second: 329.12
I0828 10:52:36.555037 140214119393280 replay_runner.py:36] Average training steps per second: 329.12
I0828 10:52:36.686949 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -297.61
INFO:tensorflow:Starting iteration 17

Steps executed: 245 Episode length: 110 Return: -103.58541143906814
INFO:tensorflow:Average training steps per second: 340.13
I0828 10:52:43.036908 140214119393280 replay_runner.py:36] Average training steps per second: 340.13
I0828 10:52:43.193800 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.00
INFO:tensorflow:Starting iteration 18

Steps executed: 224 Episode length: 117 Return: -188.85138237305566
INFO:tensorflow:Average training steps per second: 339.52
I0828 10:52:49.566739 140214119393280 replay_runner.py:36] Average training steps per second: 339.52
I0828 10:52:49.703745 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.87
INFO:tensorflow:Starting iteration 19

Steps executed: 284 Episode length: 135 Return: -152.53078109141887
INFO:tensorflow:Average training steps per second: 345.70
I0828 10:52:56.014786 140214119393280 replay_runner.py:36] Average training steps per second: 345.70
I0828 10:52:56.181917 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.98
INFO:tensorflow:Starting iteration 20

Steps executed: 382 Episode length: 382 Return: -477.87731939117047
INFO:tensorflow:Average training steps per second: 346.83
I0828 10:53:02.530562 140214119393280 replay_runner.py:36] Average training steps per second: 346.83
I0828 10:53:03.006524 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -477.88
INFO:tensorflow:Starting iteration 21

Steps executed: 296 Episode length: 144 Return: -474.72958288555517
INFO:tensorflow:Average training steps per second: 337.38
I0828 10:53:09.439160 140214119393280 replay_runner.py:36] Average training steps per second: 337.38
I0828 10:53:09.626298 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -522.47
INFO:tensorflow:Starting iteration 22

Steps executed: 246 Episode length: 118 Return: -285.99096085652855
INFO:tensorflow:Average training steps per second: 340.91
I0828 10:53:15.997543 140214119393280 replay_runner.py:36] Average training steps per second: 340.91
I0828 10:53:16.157802 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.28
INFO:tensorflow:Starting iteration 23

Steps executed: 311 Episode length: 130 Return: -92.216796337980045
INFO:tensorflow:Average training steps per second: 346.42
I0828 10:53:22.500040 140214119393280 replay_runner.py:36] Average training steps per second: 346.42
I0828 10:53:22.691056 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.99
INFO:tensorflow:Starting iteration 24

Steps executed: 109 Episode length: 109 Return: -89.478647414979365
INFO:tensorflow:Average training steps per second: 350.38

Steps executed: 1069 Episode length: 960 Return: -245.38204678957322
I0828 10:53:30.463026 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.43
INFO:tensorflow:Starting iteration 25

Steps executed: 244 Episode length: 158 Return: -401.337693539620222
INFO:tensorflow:Average training steps per second: 357.96
I0828 10:53:36.775285 140214119393280 replay_runner.py:36] Average training steps per second: 357.96
I0828 10:53:36.929047 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -452.69
INFO:tensorflow:Starting iteration 26
I0828 10:53:40.446977 140214119393280 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 363.61

Steps executed: 1000 Episode length: 1000 Return: -91.68527237644209
I0828 10:53:44.541868 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.69
INFO:tensorflow:Starting iteration 27

Steps executed: 204 Episode length: 90 Return: -185.9262631692066679
INFO:tensorflow:Average training steps per second: 343.51
I0828 10:53:50.923643 140214119393280 replay_runner.py:36] Average training steps per second: 343.51
I0828 10:53:51.046453 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.08
INFO:tensorflow:Starting iteration 28
I0828 10:53:54.467972 140214119393280 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 351.95
I0828 10:53:57.309504 140214119393280 replay_runner.py:36] Average training steps per second: 351.95

Steps executed: 265 Episode length: 265 Return: -24.9422194905246079
INFO:tensorflow:Starting iteration 29

Steps executed: 214 Episode length: 163 Return: -84.3801229634389579
INFO:tensorflow:Average training steps per second: 336.57
I0828 10:54:03.755795 140214119393280 replay_runner.py:36] Average training steps per second: 336.57

Done fixed training!Episode length: 163 Return: -84.3801229634389579