Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0828 10:37:33.487863 140618562066432 run_experiment.py:549] Creating TrainRunner ...
I0828 10:37:33.498183 140618562066432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:33.498372 140618562066432 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:33.498468 140618562066432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:33.498531 140618562066432 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:33.498618 140618562066432 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:33.498739 140618562066432 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:37:33.498825 140618562066432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:33.498896 140618562066432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:33.498964 140618562066432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:33.499064 140618562066432 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:33.499263 140618562066432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:33.499344 140618562066432 dqn_agent.py:283] 	 seed: 1630147053498101
I0828 10:37:33.503323 140618562066432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:33.503547 140618562066432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:37:33.503723 140618562066432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:33.503916 140618562066432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:33.504162 140618562066432 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:33.504325 140618562066432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:33.504440 140618562066432 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:33.504592 140618562066432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:33.504781 140618562066432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:33.541885 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:33.910923 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:33.925738 140618562066432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:37:33.934938 140618562066432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:33.935242 140618562066432 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:33.935494 140618562066432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:33.935764 140618562066432 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:33.935905 140618562066432 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:33.936075 140618562066432 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:37:33.936168 140618562066432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:33.936251 140618562066432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:33.936515 140618562066432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:33.936734 140618562066432 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:33.936864 140618562066432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:33.936981 140618562066432 dqn_agent.py:283] 	 seed: 1630147053934876
I0828 10:37:33.939680 140618562066432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:33.939846 140618562066432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:37:33.940006 140618562066432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:33.940238 140618562066432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:33.940413 140618562066432 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:33.940555 140618562066432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:33.940656 140618562066432 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:33.940747 140618562066432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:33.940839 140618562066432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:33.972476 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:34.034600 140618562066432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:37:34.035344 140618562066432 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 167.53
I0828 10:37:40.004626 140618562066432 replay_runner.py:36] Average training steps per second: 167.53
Steps executed: 263 Episode length: 75 Return: -38.106444122285411
I0828 10:37:41.257164 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.47
INFO:tensorflow:Starting iteration 1

Steps executed: 333 Episode length: 172 Return: -1290.1576922006193
INFO:tensorflow:Average training steps per second: 220.59
I0828 10:37:50.111439 140618562066432 replay_runner.py:36] Average training steps per second: 220.59
I0828 10:37:50.410507 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -534.06
INFO:tensorflow:Starting iteration 2

Steps executed: 249 Episode length: 62 Return: -439.129758235925643
INFO:tensorflow:Average training steps per second: 226.52
I0828 10:37:59.240273 140618562066432 replay_runner.py:36] Average training steps per second: 226.52
I0828 10:37:59.468208 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -366.53
INFO:tensorflow:Starting iteration 3

Steps executed: 219 Episode length: 106 Return: -183.60750553254223
INFO:tensorflow:Average training steps per second: 223.01
I0828 10:38:08.370099 140618562066432 replay_runner.py:36] Average training steps per second: 223.01
I0828 10:38:08.559439 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.03
INFO:tensorflow:Starting iteration 4

Steps executed: 302 Episode length: 113 Return: -12.481450600004024
INFO:tensorflow:Average training steps per second: 220.30
I0828 10:38:17.479677 140618562066432 replay_runner.py:36] Average training steps per second: 220.30
I0828 10:38:17.714333 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -59.39
INFO:tensorflow:Starting iteration 5

Steps executed: 221 Episode length: 64 Return: -114.399495990382184
INFO:tensorflow:Average training steps per second: 224.48
I0828 10:38:26.517740 140618562066432 replay_runner.py:36] Average training steps per second: 224.48
I0828 10:38:26.657639 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.28
INFO:tensorflow:Starting iteration 6

Steps executed: 224 Episode length: 82 Return: -119.883269627865674
INFO:tensorflow:Average training steps per second: 225.60
I0828 10:38:35.424877 140618562066432 replay_runner.py:36] Average training steps per second: 225.60
I0828 10:38:35.572193 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.92
INFO:tensorflow:Starting iteration 7

Steps executed: 270 Episode length: 71 Return: -142.460380252046154
INFO:tensorflow:Average training steps per second: 222.26
I0828 10:38:44.256788 140618562066432 replay_runner.py:36] Average training steps per second: 222.26
I0828 10:38:44.442780 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.04
INFO:tensorflow:Starting iteration 8

Steps executed: 133 Episode length: 77 Return: -786.710511086859854
INFO:tensorflow:Average training steps per second: 225.74

Steps executed: 275 Episode length: 82 Return: -804.543149443255434
I0828 10:38:53.518164 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -626.41
INFO:tensorflow:Starting iteration 9

Steps executed: 236 Episode length: 59 Return: -98.6023493571463534
INFO:tensorflow:Average training steps per second: 222.94
I0828 10:39:02.343843 140618562066432 replay_runner.py:36] Average training steps per second: 222.94
I0828 10:39:02.500282 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.22
INFO:tensorflow:Starting iteration 10

Steps executed: 218 Episode length: 92 Return: -237.699375104059164
INFO:tensorflow:Average training steps per second: 224.05
I0828 10:39:11.122075 140618562066432 replay_runner.py:36] Average training steps per second: 224.05
I0828 10:39:11.311331 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.30
INFO:tensorflow:Starting iteration 11

Steps executed: 284 Episode length: 116 Return: -517.03678990587974
INFO:tensorflow:Average training steps per second: 225.57
I0828 10:39:19.898174 140618562066432 replay_runner.py:36] Average training steps per second: 225.57
I0828 10:39:20.151264 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -602.04
INFO:tensorflow:Starting iteration 12

Steps executed: 221 Episode length: 76 Return: -126.175392124297824
INFO:tensorflow:Average training steps per second: 230.81
I0828 10:39:28.749429 140618562066432 replay_runner.py:36] Average training steps per second: 230.81
I0828 10:39:28.885922 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.33
INFO:tensorflow:Starting iteration 13

Steps executed: 106 Episode length: 106 Return: -660.98614723666294
INFO:tensorflow:Average training steps per second: 228.17

Steps executed: 308 Episode length: 202 Return: -1416.6060177995687
I0828 10:39:37.907778 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -1038.80
INFO:tensorflow:Starting iteration 14

Steps executed: 342 Episode length: 222 Return: -128.14984029622832
INFO:tensorflow:Average training steps per second: 228.45
I0828 10:39:46.533084 140618562066432 replay_runner.py:36] Average training steps per second: 228.45
I0828 10:39:46.887006 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -150.24
INFO:tensorflow:Starting iteration 15

Steps executed: 241 Episode length: 52 Return: -288.337954103345732
INFO:tensorflow:Average training steps per second: 228.07
I0828 10:39:55.433929 140618562066432 replay_runner.py:36] Average training steps per second: 228.07
I0828 10:39:55.640176 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -355.99
INFO:tensorflow:Starting iteration 16

Steps executed: 252 Episode length: 71 Return: 14.37062364940840162
INFO:tensorflow:Average training steps per second: 227.83
I0828 10:40:04.407081 140618562066432 replay_runner.py:36] Average training steps per second: 227.83
I0828 10:40:04.623673 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.10
INFO:tensorflow:Starting iteration 17
I0828 10:40:08.991181 140618562066432 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 217.73

Steps executed: 248 Episode length: 248 Return: -722.37490862943262
I0828 10:40:13.917390 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -722.37
INFO:tensorflow:Starting iteration 18

Steps executed: 236 Episode length: 236 Return: -1042.0581082275662
INFO:tensorflow:Average training steps per second: 232.04
I0828 10:40:22.299783 140618562066432 replay_runner.py:36] Average training steps per second: 232.04
I0828 10:40:22.535498 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -1042.06
INFO:tensorflow:Starting iteration 19

Steps executed: 205 Episode length: 66 Return: -511.785121996683562
INFO:tensorflow:Average training steps per second: 235.57
I0828 10:40:31.152454 140618562066432 replay_runner.py:36] Average training steps per second: 235.57
I0828 10:40:31.328011 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -625.16
INFO:tensorflow:Starting iteration 20

Steps executed: 224 Episode length: 224 Return: -229.51864207642362
INFO:tensorflow:Average training steps per second: 223.16
I0828 10:40:40.102898 140618562066432 replay_runner.py:36] Average training steps per second: 223.16
I0828 10:40:40.325867 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.52
INFO:tensorflow:Starting iteration 21

Steps executed: 244 Episode length: 76 Return: -77.0399002727534442
INFO:tensorflow:Average training steps per second: 218.75
I0828 10:40:49.253463 140618562066432 replay_runner.py:36] Average training steps per second: 218.75
I0828 10:40:49.442508 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.14
INFO:tensorflow:Starting iteration 22

Steps executed: 271 Episode length: 93 Return: -412.834784872499142
INFO:tensorflow:Average training steps per second: 223.28
I0828 10:40:58.261682 140618562066432 replay_runner.py:36] Average training steps per second: 223.28
I0828 10:40:58.496214 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -412.99
INFO:tensorflow:Starting iteration 23

Steps executed: 329 Episode length: 142 Return: -1237.9334703161446
INFO:tensorflow:Average training steps per second: 222.66
I0828 10:41:07.258880 140618562066432 replay_runner.py:36] Average training steps per second: 222.66
I0828 10:41:07.582185 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -667.60
INFO:tensorflow:Starting iteration 24

Steps executed: 250 Episode length: 75 Return: -733.768338391921746
INFO:tensorflow:Average training steps per second: 220.56
I0828 10:41:16.430930 140618562066432 replay_runner.py:36] Average training steps per second: 220.56
I0828 10:41:16.662656 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -515.27
INFO:tensorflow:Starting iteration 25

Steps executed: 234 Episode length: 60 Return: -456.064346810538676
INFO:tensorflow:Average training steps per second: 231.04
I0828 10:41:25.389515 140618562066432 replay_runner.py:36] Average training steps per second: 231.04
I0828 10:41:25.587156 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -483.27
INFO:tensorflow:Starting iteration 26

Steps executed: 345 Episode length: 219 Return: -655.04381488087786
INFO:tensorflow:Average training steps per second: 218.59
I0828 10:41:34.586251 140618562066432 replay_runner.py:36] Average training steps per second: 218.59
I0828 10:41:34.907472 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -450.55
INFO:tensorflow:Starting iteration 27
I0828 10:41:39.328409 140618562066432 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 222.59

Steps executed: 227 Episode length: 75 Return: -515.867003757649756
I0828 10:41:44.016085 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -374.01
INFO:tensorflow:Starting iteration 28

Steps executed: 307 Episode length: 150 Return: -1400.6039388694676
INFO:tensorflow:Average training steps per second: 222.04
I0828 10:41:52.892891 140618562066432 replay_runner.py:36] Average training steps per second: 222.04
I0828 10:41:53.204533 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -1072.94
INFO:tensorflow:Starting iteration 29
I0828 10:41:57.536482 140618562066432 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 227.14

Steps executed: 256 Episode length: 119 Return: -486.70174668663765

Done fixed training!Episode length: 119 Return: -486.70174668663765