Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0905 18:51:34.218227 140098254071808 run_experiment.py:549] Creating TrainRunner ...
I0905 18:51:34.234549 140098254071808 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 18:51:34.234832 140098254071808 dqn_agent.py:272] 	 gamma: 0.990000
I0905 18:51:34.235184 140098254071808 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 18:51:34.235419 140098254071808 dqn_agent.py:274] 	 min_replay_history: 500
I0905 18:51:34.235628 140098254071808 dqn_agent.py:275] 	 update_period: 4
I0905 18:51:34.235857 140098254071808 dqn_agent.py:276] 	 target_update_period: 300
I0905 18:51:34.235978 140098254071808 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 18:51:34.236081 140098254071808 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 18:51:34.236258 140098254071808 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 18:51:34.236397 140098254071808 dqn_agent.py:280] 	 optimizer: adam
I0905 18:51:34.236543 140098254071808 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 18:51:34.236668 140098254071808 dqn_agent.py:283] 	 seed: 1630867894234482
I0905 18:51:34.239702 140098254071808 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 18:51:34.239893 140098254071808 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 18:51:34.240034 140098254071808 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 18:51:34.240155 140098254071808 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 18:51:34.240267 140098254071808 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 18:51:34.240424 140098254071808 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 18:51:34.240546 140098254071808 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 18:51:34.240658 140098254071808 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 18:51:34.240805 140098254071808 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 18:51:34.739401 140098254071808 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:51:35.147940 140098254071808 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:51:35.163849 140098254071808 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 18:51:35.170536 140098254071808 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 18:51:35.170799 140098254071808 dqn_agent.py:272] 	 gamma: 0.990000
I0905 18:51:35.170966 140098254071808 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 18:51:35.171096 140098254071808 dqn_agent.py:274] 	 min_replay_history: 500
I0905 18:51:35.171391 140098254071808 dqn_agent.py:275] 	 update_period: 4
I0905 18:51:35.171643 140098254071808 dqn_agent.py:276] 	 target_update_period: 300
I0905 18:51:35.172119 140098254071808 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 18:51:35.172280 140098254071808 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 18:51:35.172467 140098254071808 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 18:51:35.172755 140098254071808 dqn_agent.py:280] 	 optimizer: adam
I0905 18:51:35.172867 140098254071808 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 18:51:35.172979 140098254071808 dqn_agent.py:283] 	 seed: 1630867895170482
I0905 18:51:35.176477 140098254071808 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 18:51:35.176743 140098254071808 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 18:51:35.177004 140098254071808 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 18:51:35.177150 140098254071808 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 18:51:35.177250 140098254071808 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 18:51:35.177416 140098254071808 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 18:51:35.177552 140098254071808 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 18:51:35.177803 140098254071808 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 18:51:35.178027 140098254071808 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 18:51:35.209473 140098254071808 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:51:35.542627 140098254071808 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 18:51:35.542942 140098254071808 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 164.65
I0905 18:51:41.616926 140098254071808 replay_runner.py:36] Average training steps per second: 164.65
Steps executed: 255 Episode length: 145 Return: -426.95452610627724
I0905 18:51:42.894907 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -390.37
INFO:tensorflow:Starting iteration 1
I0905 18:51:47.274181 140098254071808 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 217.13

Steps executed: 267 Episode length: 123 Return: -266.89635122972805
I0905 18:51:52.123671 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.36
INFO:tensorflow:Starting iteration 2

Steps executed: 219 Episode length: 124 Return: -347.02439618649925
INFO:tensorflow:Average training steps per second: 222.53
I0905 18:52:01.010431 140098254071808 replay_runner.py:36] Average training steps per second: 222.53
I0905 18:52:01.198008 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -393.37
INFO:tensorflow:Starting iteration 3
I0905 18:52:05.520729 140098254071808 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 217.95


Steps executed: 1054 Episode length: 923 Return: -192.2903633164441
I0905 18:52:12.613236 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.34
INFO:tensorflow:Starting iteration 4

Steps executed: 236 Episode length: 236 Return: -263.32100044487953
INFO:tensorflow:Average training steps per second: 246.64
I0905 18:52:20.838156 140098254071808 replay_runner.py:36] Average training steps per second: 246.64
I0905 18:52:21.065928 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.32
INFO:tensorflow:Starting iteration 5

Steps executed: 617 Episode length: 617 Return: -338.79885269785383
INFO:tensorflow:Average training steps per second: 255.69
I0905 18:52:28.884018 140098254071808 replay_runner.py:36] Average training steps per second: 255.69
I0905 18:52:29.882695 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.80
INFO:tensorflow:Starting iteration 6
I0905 18:52:34.295876 140098254071808 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 215.42

Steps executed: 1000 Episode length: 1000 Return: -226.45667395100918
I0905 18:52:41.112433 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.46
INFO:tensorflow:Starting iteration 7
I0905 18:52:44.845924 140098254071808 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 206.45

Steps executed: 1000 Episode length: 1000 Return: -271.90751866138004
I0905 18:52:52.881338 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -271.91
INFO:tensorflow:Starting iteration 8
I0905 18:52:57.557647 140098254071808 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 201.24

Steps executed: 1000 Episode length: 1000 Return: -172.20350136766533
I0905 18:53:04.852758 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -172.20
INFO:tensorflow:Starting iteration 9
I0905 18:53:09.407616 140098254071808 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 200.04

Steps executed: 1000 Episode length: 1000 Return: -201.05857141805873
I0905 18:53:17.855951 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.06
INFO:tensorflow:Starting iteration 10
I0905 18:53:22.304623 140098254071808 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 202.45

Steps executed: 1000 Episode length: 1000 Return: -224.00402633067363
I0905 18:53:29.957136 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.00
INFO:tensorflow:Starting iteration 11

Steps executed: 304 Episode length: 304 Return: -633.8806212010447363
INFO:tensorflow:Average training steps per second: 203.11
I0905 18:53:39.537032 140098254071808 replay_runner.py:36] Average training steps per second: 203.11
I0905 18:53:40.068895 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -633.88
INFO:tensorflow:Starting iteration 12
I0905 18:53:44.580607 140098254071808 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 200.08

Steps executed: 1000 Episode length: 1000 Return: -224.75562955910155
I0905 18:53:52.567016 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.76
INFO:tensorflow:Starting iteration 13
I0905 18:53:57.222297 140098254071808 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 199.15

Steps executed: 1000 Episode length: 1000 Return: -87.593384750574245
I0905 18:54:06.484485 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.59
INFO:tensorflow:Starting iteration 14

Steps executed: 84 Episode length: 84 Return: -100.307778243831484245
INFO:tensorflow:Average training steps per second: 199.98

Steps executed: 533 Episode length: 449 Return: -52.54135369210161245
I0905 18:54:16.470461 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.42
INFO:tensorflow:Starting iteration 15
I0905 18:54:21.134342 140098254071808 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 199.22

Steps executed: 1000 Episode length: 1000 Return: -200.58308247245855
I0905 18:54:29.069251 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.58
INFO:tensorflow:Starting iteration 16
I0905 18:54:33.770302 140098254071808 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 202.57

Steps executed: 1000 Episode length: 1000 Return: -61.340687357511535
I0905 18:54:43.450925 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.34
INFO:tensorflow:Starting iteration 17
I0905 18:54:47.716567 140098254071808 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 200.91

Steps executed: 1000 Episode length: 1000 Return: -65.646344810531185
I0905 18:54:56.318738 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.65
INFO:tensorflow:Starting iteration 18
I0905 18:55:00.983906 140098254071808 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 198.71

Steps executed: 449 Episode length: 449 Return: -105.0306965138766885
I0905 18:55:06.876560 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.03
INFO:tensorflow:Starting iteration 19
I0905 18:55:11.480819 140098254071808 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 203.41

Steps executed: 788 Episode length: 788 Return: -390.1158015552645885
I0905 18:55:19.460913 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -390.12
INFO:tensorflow:Starting iteration 20
I0905 18:55:24.122112 140098254071808 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 196.06

Steps executed: 1000 Episode length: 1000 Return: -8.9596021405193085
I0905 18:55:34.077121 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -8.96
INFO:tensorflow:Starting iteration 21
I0905 18:55:38.673734 140098254071808 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 226.01

Steps executed: 1000 Episode length: 1000 Return: 124.841864581807395
I0905 18:55:45.277268 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: 124.84
INFO:tensorflow:Starting iteration 22
I0905 18:55:49.730281 140098254071808 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 226.03

Steps executed: 611 Episode length: 611 Return: -342.0618811810222395
I0905 18:55:55.278345 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.06
INFO:tensorflow:Starting iteration 23
I0905 18:55:59.908678 140098254071808 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 204.01
I0905 18:56:04.810984 140098254071808 replay_runner.py:36] Average training steps per second: 204.01

Steps executed: 1000 Episode length: 1000 Return: -126.57374544442109
INFO:tensorflow:Starting iteration 24
I0905 18:56:13.337416 140098254071808 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 185.78
I0905 18:56:18.720538 140098254071808 replay_runner.py:36] Average training steps per second: 185.78

Steps executed: 1000 Episode length: 1000 Return: 33.2335927026801509
INFO:tensorflow:Starting iteration 25
I0905 18:56:27.190884 140098254071808 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 187.41

Steps executed: 1000 Episode length: 1000 Return: -75.279960679603899
I0905 18:56:36.125788 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.28
INFO:tensorflow:Starting iteration 26

Steps executed: 79 Episode length: 79 Return: -642.492328587404603899
INFO:tensorflow:Average training steps per second: 180.73
I0905 18:56:46.440283 140098254071808 replay_runner.py:36] Average training steps per second: 180.73

Steps executed: 206 Episode length: 127 Return: -580.5549447239409899
INFO:tensorflow:Starting iteration 27
I0905 18:56:51.578630 140098254071808 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 183.90
I0905 18:56:57.017198 140098254071808 replay_runner.py:36] Average training steps per second: 183.90

Steps executed: 551 Episode length: 551 Return: -306.6597437847084899
INFO:tensorflow:Starting iteration 28

Steps executed: 457 Episode length: 457 Return: -85.09643582402664899
INFO:tensorflow:Average training steps per second: 182.84
I0905 18:57:08.905241 140098254071808 replay_runner.py:36] Average training steps per second: 182.84
I0905 18:57:10.129664 140098254071808 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.10
INFO:tensorflow:Starting iteration 29

Steps executed: 314 Episode length: 314 Return: -360.9687675904371599
INFO:tensorflow:Average training steps per second: 174.86
I0905 18:57:20.962141 140098254071808 replay_runner.py:36] Average training steps per second: 174.86

Done fixed training!Episode length: 314 Return: -360.9687675904371599