Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0828 10:42:32.268133 139825303013376 run_experiment.py:549] Creating TrainRunner ...
I0828 10:42:32.279106 139825303013376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:32.279353 139825303013376 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:32.279482 139825303013376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:32.279581 139825303013376 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:32.279653 139825303013376 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:32.279724 139825303013376 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:32.279858 139825303013376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:32.280138 139825303013376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:32.280253 139825303013376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:32.280328 139825303013376 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:32.280416 139825303013376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:32.280527 139825303013376 dqn_agent.py:283] 	 seed: 1630147352278963
I0828 10:42:32.283310 139825303013376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:32.283455 139825303013376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:32.283540 139825303013376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:32.283625 139825303013376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:32.283864 139825303013376 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:32.283992 139825303013376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:32.284077 139825303013376 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:32.284185 139825303013376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:32.284248 139825303013376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:32.320422 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:32.686708 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:32.701743 139825303013376 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:42:32.711570 139825303013376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:32.711848 139825303013376 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:32.712116 139825303013376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:32.712332 139825303013376 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:32.712432 139825303013376 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:32.712516 139825303013376 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:32.712609 139825303013376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:32.712731 139825303013376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:32.712849 139825303013376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:32.713075 139825303013376 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:32.713224 139825303013376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:32.713365 139825303013376 dqn_agent.py:283] 	 seed: 1630147352711514
I0828 10:42:32.716389 139825303013376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:32.716592 139825303013376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:32.716745 139825303013376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:32.716899 139825303013376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:32.717016 139825303013376 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:32.717098 139825303013376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:32.717166 139825303013376 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:32.717237 139825303013376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:32.717350 139825303013376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:32.748215 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:32.816902 139825303013376 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:42:32.817196 139825303013376 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 168.37
I0828 10:42:38.756639 139825303013376 replay_runner.py:36] Average training steps per second: 168.37
Steps executed: 136 Episode length: 136 Return: -165.1959250969245

Steps executed: 229 Episode length: 93 Return: -399.61713403695215
INFO:tensorflow:Starting iteration 1

Steps executed: 267 Episode length: 96 Return: -752.03108378974415
INFO:tensorflow:Average training steps per second: 222.91
I0828 10:42:48.549023 139825303013376 replay_runner.py:36] Average training steps per second: 222.91
I0828 10:42:48.803477 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -682.08
INFO:tensorflow:Starting iteration 2

Steps executed: 179 Episode length: 179 Return: -150.56814425891935
INFO:tensorflow:Average training steps per second: 227.91

Steps executed: 494 Episode length: 315 Return: -9.4777395945829145
I0828 10:42:57.957125 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.02
INFO:tensorflow:Starting iteration 3
I0828 10:43:02.213139 139825303013376 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 233.38

Steps executed: 1000 Episode length: 1000 Return: -132.57595490308168
I0828 10:43:09.429912 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.58
INFO:tensorflow:Starting iteration 4
I0828 10:43:13.835686 139825303013376 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 233.66

Steps executed: 1000 Episode length: 1000 Return: -345.87836698323018
I0828 10:43:21.146473 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -345.88
INFO:tensorflow:Starting iteration 5
I0828 10:43:25.353028 139825303013376 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 238.03

Steps executed: 706 Episode length: 706 Return: -385.4332518201786718
I0828 10:43:31.425239 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -385.43
INFO:tensorflow:Starting iteration 6
I0828 10:43:35.639252 139825303013376 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 226.59

Steps executed: 933 Episode length: 933 Return: -457.1359760521103718
I0828 10:43:41.987689 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -457.14
INFO:tensorflow:Starting iteration 7
I0828 10:43:46.389506 139825303013376 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 221.20

Steps executed: 1000 Episode length: 1000 Return: -315.44586796640493
I0828 10:43:54.876033 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -315.45
INFO:tensorflow:Starting iteration 8

Steps executed: 228 Episode length: 82 Return: -131.56967580867314493
INFO:tensorflow:Average training steps per second: 231.70
I0828 10:44:03.586989 139825303013376 replay_runner.py:36] Average training steps per second: 231.70
I0828 10:44:03.773190 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.70
INFO:tensorflow:Starting iteration 9

Steps executed: 245 Episode length: 60 Return: -165.28839127508107493
INFO:tensorflow:Average training steps per second: 225.50
I0828 10:44:12.578189 139825303013376 replay_runner.py:36] Average training steps per second: 225.50
I0828 10:44:12.813822 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.46
INFO:tensorflow:Starting iteration 10

Steps executed: 215 Episode length: 215 Return: -268.2770212967627793
INFO:tensorflow:Average training steps per second: 228.90
I0828 10:44:21.593487 139825303013376 replay_runner.py:36] Average training steps per second: 228.90
I0828 10:44:21.838829 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.28
INFO:tensorflow:Starting iteration 11
I0828 10:44:25.963992 139825303013376 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 227.23

Steps executed: 203 Episode length: 203 Return: -29.05440048116111793
I0828 10:44:30.557837 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -29.05
INFO:tensorflow:Starting iteration 12

Steps executed: 246 Episode length: 61 Return: -109.12718046951169793
INFO:tensorflow:Average training steps per second: 235.88
I0828 10:44:39.241013 139825303013376 replay_runner.py:36] Average training steps per second: 235.88
I0828 10:44:39.431604 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.99
INFO:tensorflow:Starting iteration 13

Steps executed: 375 Episode length: 285 Return: -21.87216580425452793
INFO:tensorflow:Average training steps per second: 232.17
I0828 10:44:48.123727 139825303013376 replay_runner.py:36] Average training steps per second: 232.17
I0828 10:44:48.482486 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.87
INFO:tensorflow:Starting iteration 14

Steps executed: 348 Episode length: 155 Return: -176.1042289329356693
INFO:tensorflow:Average training steps per second: 231.31
I0828 10:44:57.101670 139825303013376 replay_runner.py:36] Average training steps per second: 231.31
I0828 10:44:57.424509 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -181.77
INFO:tensorflow:Starting iteration 15

Steps executed: 151 Episode length: 151 Return: -102.5470428984387693
INFO:tensorflow:Average training steps per second: 237.90
I0828 10:45:05.947882 139825303013376 replay_runner.py:36] Average training steps per second: 237.90

Steps executed: 482 Episode length: 331 Return: -65.97156173166778693
INFO:tensorflow:Starting iteration 16

Steps executed: 258 Episode length: 177 Return: -185.9368224194418593
INFO:tensorflow:Average training steps per second: 244.52
I0828 10:45:14.949957 139825303013376 replay_runner.py:36] Average training steps per second: 244.52
I0828 10:45:15.176110 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.51
INFO:tensorflow:Starting iteration 17

Steps executed: 283 Episode length: 155 Return: -347.4349112232005793
INFO:tensorflow:Average training steps per second: 249.18
I0828 10:45:23.346445 139825303013376 replay_runner.py:36] Average training steps per second: 249.18
I0828 10:45:23.558760 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -246.65
INFO:tensorflow:Starting iteration 18

Steps executed: 246 Episode length: 72 Return: -140.91227894753558393
INFO:tensorflow:Average training steps per second: 258.66
I0828 10:45:31.523818 139825303013376 replay_runner.py:36] Average training steps per second: 258.66
I0828 10:45:31.706738 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.81
INFO:tensorflow:Starting iteration 19

Steps executed: 204 Episode length: 55 Return: -450.50892987861447393
INFO:tensorflow:Average training steps per second: 262.85
I0828 10:45:39.517093 139825303013376 replay_runner.py:36] Average training steps per second: 262.85
I0828 10:45:39.666657 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -483.80
INFO:tensorflow:Starting iteration 20

Steps executed: 312 Episode length: 156 Return: -268.5979540908183593
INFO:tensorflow:Average training steps per second: 261.83
I0828 10:45:47.427448 139825303013376 replay_runner.py:36] Average training steps per second: 261.83
I0828 10:45:47.645382 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -317.28
INFO:tensorflow:Starting iteration 21

Steps executed: 249 Episode length: 67 Return: -541.81110540744663593
INFO:tensorflow:Average training steps per second: 265.34
I0828 10:45:55.333746 139825303013376 replay_runner.py:36] Average training steps per second: 265.34
I0828 10:45:55.508512 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -538.96
INFO:tensorflow:Starting iteration 22

Steps executed: 226 Episode length: 58 Return: -343.72646188121826493
INFO:tensorflow:Average training steps per second: 271.59
I0828 10:46:03.038573 139825303013376 replay_runner.py:36] Average training steps per second: 271.59
I0828 10:46:03.199282 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.33
INFO:tensorflow:Starting iteration 23

Steps executed: 254 Episode length: 92 Return: -495.92478954409015493
INFO:tensorflow:Average training steps per second: 284.92
I0828 10:46:10.362957 139825303013376 replay_runner.py:36] Average training steps per second: 284.92
I0828 10:46:10.538944 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -440.34
INFO:tensorflow:Starting iteration 24

Steps executed: 225 Episode length: 87 Return: -227.65493112007653493
INFO:tensorflow:Average training steps per second: 302.90
I0828 10:46:17.549414 139825303013376 replay_runner.py:36] Average training steps per second: 302.90
I0828 10:46:17.697182 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.95
INFO:tensorflow:Starting iteration 25

Steps executed: 237 Episode length: 65 Return: -91.503085751154378493
INFO:tensorflow:Average training steps per second: 323.92
I0828 10:46:24.205780 139825303013376 replay_runner.py:36] Average training steps per second: 323.92
I0828 10:46:24.343615 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.26
INFO:tensorflow:Starting iteration 26

Steps executed: 256 Episode length: 80 Return: -105.14848522748001493
INFO:tensorflow:Average training steps per second: 322.79
I0828 10:46:30.790563 139825303013376 replay_runner.py:36] Average training steps per second: 322.79
I0828 10:46:30.957297 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.48
INFO:tensorflow:Starting iteration 27

Steps executed: 200 Episode length: 117 Return: -654.2378432075411493
INFO:tensorflow:Average training steps per second: 334.37
I0828 10:46:37.239541 139825303013376 replay_runner.py:36] Average training steps per second: 334.37
I0828 10:46:37.370244 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -450.59
INFO:tensorflow:Starting iteration 28

Steps executed: 214 Episode length: 99 Return: -129.26815014971922493
INFO:tensorflow:Average training steps per second: 335.73
I0828 10:46:43.616144 139825303013376 replay_runner.py:36] Average training steps per second: 335.73
I0828 10:46:43.758817 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.01
INFO:tensorflow:Starting iteration 29

Steps executed: 290 Episode length: 290 Return: -398.2396257958458493
INFO:tensorflow:Average training steps per second: 337.50
I0828 10:46:49.637072 139825303013376 replay_runner.py:36] Average training steps per second: 337.50

Done fixed training!Episode length: 290 Return: -398.2396257958458493