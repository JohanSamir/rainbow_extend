Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0828 10:46:54.827383 139821415028736 run_experiment.py:549] Creating TrainRunner ...
I0828 10:46:54.835728 139821415028736 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:46:54.835871 139821415028736 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:46:54.835928 139821415028736 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:46:54.836003 139821415028736 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:46:54.836055 139821415028736 dqn_agent.py:275] 	 update_period: 4
I0828 10:46:54.836121 139821415028736 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:46:54.836167 139821415028736 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:46:54.836253 139821415028736 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:46:54.836338 139821415028736 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:46:54.836427 139821415028736 dqn_agent.py:280] 	 optimizer: adam
I0828 10:46:54.836485 139821415028736 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:46:54.836554 139821415028736 dqn_agent.py:283] 	 seed: 1630147614835698
I0828 10:46:54.838525 139821415028736 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:46:54.838636 139821415028736 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:46:54.838712 139821415028736 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:46:54.838778 139821415028736 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:46:54.838837 139821415028736 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:46:54.838894 139821415028736 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:46:54.838966 139821415028736 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:46:54.839040 139821415028736 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:46:54.839107 139821415028736 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:46:54.864143 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:55.107261 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:55.116116 139821415028736 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:46:55.122399 139821415028736 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:46:55.122564 139821415028736 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:46:55.122670 139821415028736 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:46:55.122772 139821415028736 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:46:55.122862 139821415028736 dqn_agent.py:275] 	 update_period: 4
I0828 10:46:55.122949 139821415028736 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:46:55.123046 139821415028736 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:46:55.123100 139821415028736 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:46:55.123153 139821415028736 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:46:55.123264 139821415028736 dqn_agent.py:280] 	 optimizer: adam
I0828 10:46:55.123396 139821415028736 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:46:55.123481 139821415028736 dqn_agent.py:283] 	 seed: 1630147615122362
I0828 10:46:55.125191 139821415028736 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:46:55.125301 139821415028736 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:46:55.125372 139821415028736 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:46:55.125448 139821415028736 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:46:55.125555 139821415028736 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:46:55.125614 139821415028736 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:46:55.125693 139821415028736 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:46:55.125763 139821415028736 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:46:55.125829 139821415028736 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:46:55.144070 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:55.157295 139821415028736 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:46:55.157483 139821415028736 replay_runner.py:41] Starting iteration 0
Steps executed: 231 Episode length: 139 Return: -469.18284260109704
INFO:tensorflow:Average training steps per second: 253.36
I0828 10:46:59.104739 139821415028736 replay_runner.py:36] Average training steps per second: 253.36
I0828 10:46:59.805245 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -431.90
INFO:tensorflow:Starting iteration 1

Steps executed: 231 Episode length: 119 Return: -238.58038697604718
INFO:tensorflow:Average training steps per second: 356.03
I0828 10:47:05.836127 139821415028736 replay_runner.py:36] Average training steps per second: 356.03
I0828 10:47:05.958381 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -397.16
INFO:tensorflow:Starting iteration 2

Steps executed: 232 Episode length: 103 Return: -396.82517273058363
INFO:tensorflow:Average training steps per second: 347.18
I0828 10:47:12.210425 139821415028736 replay_runner.py:36] Average training steps per second: 347.18
I0828 10:47:12.337738 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.22
INFO:tensorflow:Starting iteration 3

Steps executed: 1058 Episode length: 891 Return: -419.82979783234777
INFO:tensorflow:Average training steps per second: 342.13
I0828 10:47:18.684962 139821415028736 replay_runner.py:36] Average training steps per second: 342.13
I0828 10:47:19.834196 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.68
INFO:tensorflow:Starting iteration 4
I0828 10:47:23.297487 139821415028736 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 349.91

Steps executed: 758 Episode length: 758 Return: 200.6276184512864777
I0828 10:47:27.415728 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.63
INFO:tensorflow:Starting iteration 5

Steps executed: 716 Episode length: 716 Return: -263.522226507055777
INFO:tensorflow:Average training steps per second: 350.32
I0828 10:47:33.641247 139821415028736 replay_runner.py:36] Average training steps per second: 350.32
I0828 10:47:34.613891 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.52
INFO:tensorflow:Starting iteration 6

Steps executed: 858 Episode length: 774 Return: -351.197255652094377
INFO:tensorflow:Average training steps per second: 350.81
I0828 10:47:40.877054 139821415028736 replay_runner.py:36] Average training steps per second: 350.81
I0828 10:47:41.891851 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.00
INFO:tensorflow:Starting iteration 7
I0828 10:47:45.299534 139821415028736 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 344.97

Steps executed: 904 Episode length: 904 Return: -590.207190404230677
I0828 10:47:49.213746 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -590.21
INFO:tensorflow:Starting iteration 8
I0828 10:47:52.649564 139821415028736 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 353.83

Steps executed: 945 Episode length: 945 Return: -609.900401258913277
I0828 10:47:56.925507 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -609.90
INFO:tensorflow:Starting iteration 9

Steps executed: 364 Episode length: 170 Return: -93.6989157219001177
INFO:tensorflow:Average training steps per second: 346.27
I0828 10:48:03.251507 139821415028736 replay_runner.py:36] Average training steps per second: 346.27
I0828 10:48:03.466406 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.35
INFO:tensorflow:Starting iteration 10
I0828 10:48:06.765393 139821415028736 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 328.48

Steps executed: 630 Episode length: 630 Return: -188.688039590495177
I0828 10:48:11.009999 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.69
INFO:tensorflow:Starting iteration 11

Steps executed: 568 Episode length: 395 Return: -150.333216682106377
INFO:tensorflow:Average training steps per second: 328.13
I0828 10:48:17.362161 139821415028736 replay_runner.py:36] Average training steps per second: 328.13
I0828 10:48:17.879005 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.38
INFO:tensorflow:Starting iteration 12
I0828 10:48:21.127409 139821415028736 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 337.95

Steps executed: 1000 Episode length: 1000 Return: -57.16571717075935
I0828 10:48:25.992394 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.17
INFO:tensorflow:Starting iteration 13
I0828 10:48:29.414131 139821415028736 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 345.26

Steps executed: 1000 Episode length: 1000 Return: -164.85922804156178
I0828 10:48:33.965425 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.86
INFO:tensorflow:Starting iteration 14

Steps executed: 251 Episode length: 81 Return: -115.03449630432394178
INFO:tensorflow:Average training steps per second: 340.86
I0828 10:48:40.302882 139821415028736 replay_runner.py:36] Average training steps per second: 340.86
I0828 10:48:40.410309 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.43
INFO:tensorflow:Starting iteration 15
I0828 10:48:43.785385 139821415028736 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 341.03

Steps executed: 808 Episode length: 808 Return: -327.6807908029592178
I0828 10:48:48.881068 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.68
INFO:tensorflow:Starting iteration 16

Steps executed: 272 Episode length: 154 Return: -94.64077110091081178
INFO:tensorflow:Average training steps per second: 337.26
I0828 10:48:55.224690 139821415028736 replay_runner.py:36] Average training steps per second: 337.26
I0828 10:48:55.392446 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -421.17
INFO:tensorflow:Starting iteration 17

Steps executed: 248 Episode length: 61 Return: -226.61156944641138678
INFO:tensorflow:Average training steps per second: 307.24
I0828 10:49:01.758785 139821415028736 replay_runner.py:36] Average training steps per second: 307.24
I0828 10:49:01.916084 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.78
INFO:tensorflow:Starting iteration 18
I0828 10:49:05.010349 139821415028736 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 351.44

Steps executed: 1000 Episode length: 1000 Return: -139.73621680336947
I0828 10:49:10.140942 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.74
INFO:tensorflow:Starting iteration 19

Steps executed: 207 Episode length: 143 Return: -136.1478168646243947
INFO:tensorflow:Average training steps per second: 317.20
I0828 10:49:16.238444 139821415028736 replay_runner.py:36] Average training steps per second: 317.20
I0828 10:49:16.368669 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.38
INFO:tensorflow:Starting iteration 20

Steps executed: 274 Episode length: 87 Return: -16.875422346085656947
INFO:tensorflow:Average training steps per second: 348.95
I0828 10:49:22.360732 139821415028736 replay_runner.py:36] Average training steps per second: 348.95
I0828 10:49:22.526671 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.07
INFO:tensorflow:Starting iteration 21

Steps executed: 123 Episode length: 65 Return: -202.37899464531645947
INFO:tensorflow:Average training steps per second: 360.02

Steps executed: 745 Episode length: 622 Return: -111.0644229165053247
I0828 10:49:29.555436 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.26
INFO:tensorflow:Starting iteration 22

Steps executed: 303 Episode length: 133 Return: -277.3195207714692347
INFO:tensorflow:Average training steps per second: 344.16
I0828 10:49:35.782085 139821415028736 replay_runner.py:36] Average training steps per second: 344.16
I0828 10:49:35.993517 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.34
INFO:tensorflow:Starting iteration 23

Steps executed: 210 Episode length: 104 Return: -125.1211649954627547
INFO:tensorflow:Average training steps per second: 353.09
I0828 10:49:42.146555 139821415028736 replay_runner.py:36] Average training steps per second: 353.09
I0828 10:49:42.286724 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -52.50
INFO:tensorflow:Starting iteration 24
I0828 10:49:45.697418 139821415028736 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 361.74

Steps executed: 1000 Episode length: 1000 Return: 149.723073935167347
I0828 10:49:50.287118 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: 149.72
INFO:tensorflow:Starting iteration 25

Steps executed: 238 Episode length: 77 Return: -502.44512421970126347
INFO:tensorflow:Average training steps per second: 338.79
I0828 10:49:56.494131 139821415028736 replay_runner.py:36] Average training steps per second: 338.79
I0828 10:49:56.638542 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -427.75
INFO:tensorflow:Starting iteration 26

Steps executed: 225 Episode length: 101 Return: -502.1990637385195347
INFO:tensorflow:Average training steps per second: 334.35
I0828 10:50:02.832447 139821415028736 replay_runner.py:36] Average training steps per second: 334.35
I0828 10:50:02.971948 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.95
INFO:tensorflow:Starting iteration 27
I0828 10:50:06.239801 139821415028736 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 341.67

Steps executed: 329 Episode length: 139 Return: -255.7742141021712447
I0828 10:50:09.355991 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.70
INFO:tensorflow:Starting iteration 28

Steps executed: 246 Episode length: 79 Return: -85.715241963478357447
INFO:tensorflow:Average training steps per second: 344.83
I0828 10:50:15.615082 139821415028736 replay_runner.py:36] Average training steps per second: 344.83
I0828 10:50:15.761252 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.49
INFO:tensorflow:Starting iteration 29

Steps executed: 273 Episode length: 90 Return: -152.20490934363886447
INFO:tensorflow:Average training steps per second: 366.57
I0828 10:50:21.865976 139821415028736 replay_runner.py:36] Average training steps per second: 366.57

Done fixed training!Episode length: 90 Return: -152.20490934363886447