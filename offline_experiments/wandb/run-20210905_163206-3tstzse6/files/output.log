I0905 16:32:13.706146 140625605064704 run_experiment.py:549] Creating TrainRunner ...
I0905 16:32:13.718396 140625605064704 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:32:13.718631 140625605064704 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:32:13.718722 140625605064704 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:32:13.718813 140625605064704 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:32:13.718887 140625605064704 dqn_agent.py:275] 	 update_period: 4
I0905 16:32:13.718979 140625605064704 dqn_agent.py:276] 	 target_update_period: 100
I0905 16:32:13.719107 140625605064704 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:32:13.719182 140625605064704 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:32:13.719259 140625605064704 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:32:13.719348 140625605064704 dqn_agent.py:280] 	 optimizer: adam
I0905 16:32:13.719527 140625605064704 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:32:13.719657 140625605064704 dqn_agent.py:283] 	 seed: 1630859533718330
I0905 16:32:13.723680 140625605064704 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:32:13.723953 140625605064704 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0905 16:32:13.724101 140625605064704 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:32:13.724212 140625605064704 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:32:13.724299 140625605064704 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:32:13.724424 140625605064704 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:32:13.724526 140625605064704 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:32:13.724663 140625605064704 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:32:13.724736 140625605064704 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in acrobot
Training fixed agent 4, please be patient, may be a while...
I0905 16:32:15.715595 140625605064704 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:32:16.778606 140625605064704 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:32:16.796746 140625605064704 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:32:16.813933 140625605064704 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:32:16.814716 140625605064704 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:32:16.815200 140625605064704 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:32:16.815576 140625605064704 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:32:16.815789 140625605064704 dqn_agent.py:275] 	 update_period: 4
I0905 16:32:16.816159 140625605064704 dqn_agent.py:276] 	 target_update_period: 100
I0905 16:32:16.816454 140625605064704 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:32:16.816819 140625605064704 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:32:16.817106 140625605064704 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:32:16.817240 140625605064704 dqn_agent.py:280] 	 optimizer: adam
I0905 16:32:16.817319 140625605064704 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:32:16.817575 140625605064704 dqn_agent.py:283] 	 seed: 1630859536813670
I0905 16:32:16.822419 140625605064704 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:32:16.822705 140625605064704 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0905 16:32:16.822812 140625605064704 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:32:16.822924 140625605064704 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:32:16.823468 140625605064704 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:32:16.823953 140625605064704 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:32:16.824105 140625605064704 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:32:16.824220 140625605064704 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:32:16.824453 140625605064704 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:32:16.870606 140625605064704 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:32:16.900275 140625605064704 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:32:16.900602 140625605064704 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 117.20
I0905 16:32:25.433464 140625605064704 replay_runner.py:36] Average training steps per second: 117.20
Steps executed: 500 Episode length: 500 Return: -500.0
I0905 16:32:27.614177 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1
I0905 16:32:27.907901 140625605064704 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 140.65

Steps executed: 205 Episode length: 205 Return: -204.0
I0905 16:32:35.582468 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -204.00
INFO:tensorflow:Starting iteration 2
I0905 16:32:35.916577 140625605064704 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 140.91

Steps executed: 330 Episode length: 188 Return: -187.0
I0905 16:32:44.235110 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.00
INFO:tensorflow:Starting iteration 3

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 140.19
I0905 16:32:51.729315 140625605064704 replay_runner.py:36] Average training steps per second: 140.19
I0905 16:32:53.239961 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 4
I0905 16:32:53.551984 140625605064704 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 134.12

Steps executed: 231 Episode length: 231 Return: -230.0
I0905 16:33:01.761345 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.00
INFO:tensorflow:Starting iteration 5
I0905 16:33:02.050314 140625605064704 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 135.02

Steps executed: 500 Episode length: 500 Return: -500.0
I0905 16:33:10.692221 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6
I0905 16:33:10.997202 140625605064704 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 138.25
I0905 16:33:18.231251 140625605064704 replay_runner.py:36] Average training steps per second: 138.25
I0905 16:33:19.496070 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7
I0905 16:33:19.811766 140625605064704 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 134.95

Steps executed: 345 Episode length: 251 Return: -250.0
I0905 16:33:28.200480 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.50
INFO:tensorflow:Starting iteration 8

Steps executed: 107 Episode length: 107 Return: -106.0
INFO:tensorflow:Average training steps per second: 140.70
I0905 16:33:35.820948 140625605064704 replay_runner.py:36] Average training steps per second: 140.70

Steps executed: 607 Episode length: 500 Return: -500.0
INFO:tensorflow:Starting iteration 9
I0905 16:33:37.775038 140625605064704 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 139.08

Steps executed: 303 Episode length: 113 Return: -112.0
I0905 16:33:45.977223 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.00
INFO:tensorflow:Starting iteration 10
I0905 16:33:46.309417 140625605064704 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 106.97

Steps executed: 295 Episode length: 107 Return: -106.0
I0905 16:33:56.391183 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.33
INFO:tensorflow:Starting iteration 11

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 137.53
I0905 16:34:03.986183 140625605064704 replay_runner.py:36] Average training steps per second: 137.53
I0905 16:34:05.423730 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 12
I0905 16:34:05.738199 140625605064704 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 139.46
I0905 16:34:12.909527 140625605064704 replay_runner.py:36] Average training steps per second: 139.46
I0905 16:34:14.139681 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 13
I0905 16:34:14.498489 140625605064704 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 147.07

Steps executed: 234 Episode length: 81 Return: -80.0.0
I0905 16:34:22.204748 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.00
INFO:tensorflow:Starting iteration 14
I0905 16:34:22.552655 140625605064704 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 144.91

Steps executed: 228 Episode length: 79 Return: -78.0.0
I0905 16:34:30.099564 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.00
INFO:tensorflow:Starting iteration 15
I0905 16:34:30.497741 140625605064704 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 145.41

Steps executed: 263 Episode length: 72 Return: -71.0.0
I0905 16:34:38.287945 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.67
INFO:tensorflow:Starting iteration 16
I0905 16:34:38.630829 140625605064704 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 139.16

Steps executed: 203 Episode length: 128 Return: -127.0
I0905 16:34:46.479092 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.50
INFO:tensorflow:Starting iteration 17
I0905 16:34:46.824331 140625605064704 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 144.79

Steps executed: 253 Episode length: 70 Return: -69.0.0
I0905 16:34:54.488577 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.33
INFO:tensorflow:Starting iteration 18
I0905 16:34:54.848561 140625605064704 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 143.62

Steps executed: 306 Episode length: 112 Return: -111.0
I0905 16:35:02.698437 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.00
INFO:tensorflow:Starting iteration 19

Steps executed: 234 Episode length: 75 Return: -74.0.0
INFO:tensorflow:Average training steps per second: 141.00
I0905 16:35:10.108150 140625605064704 replay_runner.py:36] Average training steps per second: 141.00
I0905 16:35:10.841620 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.00
INFO:tensorflow:Starting iteration 20

Steps executed: 259 Episode length: 77 Return: -76.0.0
INFO:tensorflow:Average training steps per second: 138.02
I0905 16:35:18.456420 140625605064704 replay_runner.py:36] Average training steps per second: 138.02
I0905 16:35:19.087010 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.33
INFO:tensorflow:Starting iteration 21
I0905 16:35:19.450707 140625605064704 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 135.46

Steps executed: 500 Episode length: 500 Return: -500.0
I0905 16:35:28.178408 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 22
I0905 16:35:28.522221 140625605064704 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 139.42

Steps executed: 532 Episode length: 440 Return: -439.0
I0905 16:35:37.054661 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.00
INFO:tensorflow:Starting iteration 23

Steps executed: 201 Episode length: 69 Return: -68.0.0
INFO:tensorflow:Average training steps per second: 139.21
I0905 16:35:44.555439 140625605064704 replay_runner.py:36] Average training steps per second: 139.21
I0905 16:35:45.123448 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -66.00
INFO:tensorflow:Starting iteration 24

Steps executed: 225 Episode length: 88 Return: -87.0.0
INFO:tensorflow:Average training steps per second: 141.12
I0905 16:35:52.497472 140625605064704 replay_runner.py:36] Average training steps per second: 141.12
I0905 16:35:52.856623 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.00
INFO:tensorflow:Starting iteration 25

Steps executed: 162 Episode length: 78 Return: -77.0.0
INFO:tensorflow:Average training steps per second: 154.98
I0905 16:35:59.604210 140625605064704 replay_runner.py:36] Average training steps per second: 154.98

Steps executed: 240 Episode length: 78 Return: -77.0.0
INFO:tensorflow:Starting iteration 26

Steps executed: 212 Episode length: 71 Return: -70.0.0
INFO:tensorflow:Average training steps per second: 160.84
I0905 16:36:06.554126 140625605064704 replay_runner.py:36] Average training steps per second: 160.84
I0905 16:36:06.931796 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.00
INFO:tensorflow:Starting iteration 27

Steps executed: 224 Episode length: 130 Return: -129.0
INFO:tensorflow:Average training steps per second: 164.81
I0905 16:36:13.301850 140625605064704 replay_runner.py:36] Average training steps per second: 164.81
I0905 16:36:13.600503 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.00
INFO:tensorflow:Starting iteration 28

Steps executed: 319 Episode length: 125 Return: -124.0
INFO:tensorflow:Average training steps per second: 182.44
I0905 16:36:19.355576 140625605064704 replay_runner.py:36] Average training steps per second: 182.44
I0905 16:36:19.681972 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.33
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 191.68
I0905 16:36:25.160943 140625605064704 replay_runner.py:36] Average training steps per second: 191.68
I0905 16:36:25.646161 140625605064704 run_experiment.py:428] Average undiscounted return per evaluation episode: -297.50