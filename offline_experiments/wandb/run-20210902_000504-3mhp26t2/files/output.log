Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0902 00:05:10.798820 140413705484288 run_experiment.py:549] Creating TrainRunner ...
I0902 00:05:10.808385 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:05:10.808789 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:05:10.808965 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:05:10.809467 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:05:10.809619 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0902 00:05:10.809791 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:05:10.809965 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:05:10.810330 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:05:10.810510 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:05:10.810622 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0902 00:05:10.810730 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:05:10.810827 140413705484288 dqn_agent.py:283] 	 seed: 1630541110808315
I0902 00:05:10.813227 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:05:10.813424 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:05:10.813517 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:05:10.813600 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:05:10.813676 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:05:10.813746 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:05:10.813817 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:05:10.813884 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:05:10.813959 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:05:10.848472 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:11.231701 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:11.245639 140413705484288 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:05:11.254959 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:05:11.255241 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:05:11.255400 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:05:11.255544 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:05:11.255671 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0902 00:05:11.255942 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:05:11.256039 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:05:11.256144 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:05:11.256279 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:05:11.256406 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0902 00:05:11.256492 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:05:11.256587 140413705484288 dqn_agent.py:283] 	 seed: 1630541111254897
I0902 00:05:11.259350 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:05:11.259523 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:05:11.259624 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:05:11.259706 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:05:11.259781 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:05:11.259887 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:05:11.260005 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:05:11.260071 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:05:11.260131 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:05:11.334009 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:11.356858 140413705484288 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:05:11.357176 140413705484288 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 164.99
I0902 00:05:17.418389 140413705484288 replay_runner.py:36] Average training steps per second: 164.99
Steps executed: 292 Episode length: 96 Return: -335.97067525252055
I0902 00:05:18.608916 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -320.33
INFO:tensorflow:Starting iteration 1

Steps executed: 235 Episode length: 106 Return: -454.6504455390124
INFO:tensorflow:Average training steps per second: 223.05
I0902 00:05:27.527304 140413705484288 replay_runner.py:36] Average training steps per second: 223.05
I0902 00:05:27.719064 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -412.10
INFO:tensorflow:Starting iteration 2
I0902 00:05:32.025064 140413705484288 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 232.82

Steps executed: 461 Episode length: 266 Return: -533.8750903228131
I0902 00:05:36.833908 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -552.99
INFO:tensorflow:Starting iteration 3

Steps executed: 277 Episode length: 146 Return: -130.26255118532547
INFO:tensorflow:Average training steps per second: 232.87
I0902 00:05:45.507711 140413705484288 replay_runner.py:36] Average training steps per second: 232.87
I0902 00:05:45.735419 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.59
INFO:tensorflow:Starting iteration 4

Steps executed: 167 Episode length: 167 Return: -454.90841176754057
INFO:tensorflow:Average training steps per second: 237.90

Steps executed: 748 Episode length: 581 Return: -358.85862365965187
I0902 00:05:55.323665 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.88
INFO:tensorflow:Starting iteration 5
I0902 00:05:59.591178 140413705484288 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 237.35

Steps executed: 1000 Episode length: 1000 Return: -31.180434074339363
I0902 00:06:07.476463 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -31.18
INFO:tensorflow:Starting iteration 6
I0902 00:06:11.804090 140413705484288 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 229.82

Steps executed: 817 Episode length: 817 Return: -261.1011374088230463
I0902 00:06:18.328038 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.10
INFO:tensorflow:Starting iteration 7

Steps executed: 247 Episode length: 247 Return: -283.5299859645163463
INFO:tensorflow:Average training steps per second: 224.01
I0902 00:06:27.120609 140413705484288 replay_runner.py:36] Average training steps per second: 224.01
I0902 00:06:27.401299 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.53
INFO:tensorflow:Starting iteration 8

Steps executed: 198 Episode length: 198 Return: -75.98750692011166463
INFO:tensorflow:Average training steps per second: 223.78

Steps executed: 1189 Episode length: 991 Return: -504.163157993979263
I0902 00:06:38.878190 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.08
INFO:tensorflow:Starting iteration 9
I0902 00:06:43.231756 140413705484288 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 228.22

Steps executed: 818 Episode length: 818 Return: -496.9303673054663263
I0902 00:06:50.358500 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -496.93
INFO:tensorflow:Starting iteration 10

Steps executed: 336 Episode length: 167 Return: -79.32341045800375563
INFO:tensorflow:Average training steps per second: 227.63
I0902 00:06:59.123505 140413705484288 replay_runner.py:36] Average training steps per second: 227.63
I0902 00:06:59.440002 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -50.96
INFO:tensorflow:Starting iteration 11

Steps executed: 345 Episode length: 345 Return: -339.9281124804558763
INFO:tensorflow:Average training steps per second: 224.29
I0902 00:07:08.289419 140413705484288 replay_runner.py:36] Average training steps per second: 224.29
I0902 00:07:08.774031 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -339.93
INFO:tensorflow:Starting iteration 12

Steps executed: 436 Episode length: 436 Return: -333.0866892481879763
INFO:tensorflow:Average training steps per second: 229.79
I0902 00:07:17.536184 140413705484288 replay_runner.py:36] Average training steps per second: 229.79
I0902 00:07:18.055629 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.09
INFO:tensorflow:Starting iteration 13
I0902 00:07:22.343432 140413705484288 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 224.54

Steps executed: 284 Episode length: 284 Return: -508.3162361862544663
I0902 00:07:27.142911 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -508.32
INFO:tensorflow:Starting iteration 14
I0902 00:07:31.454680 140413705484288 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 223.41

Steps executed: 548 Episode length: 548 Return: -271.5050636101648663
I0902 00:07:37.241586 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -271.51
INFO:tensorflow:Starting iteration 15

Steps executed: 283 Episode length: 148 Return: -198.6843767223032863
INFO:tensorflow:Average training steps per second: 229.88
I0902 00:07:45.853794 140413705484288 replay_runner.py:36] Average training steps per second: 229.88
I0902 00:07:46.145224 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.84
INFO:tensorflow:Starting iteration 16
I0902 00:07:50.524787 140413705484288 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 231.39
I0902 00:07:54.846928 140413705484288 replay_runner.py:36] Average training steps per second: 231.39

Steps executed: 202 Episode length: 66 Return: -167.05833546255175263
INFO:tensorflow:Starting iteration 17

Steps executed: 285 Episode length: 154 Return: 26.319734892542747263
INFO:tensorflow:Average training steps per second: 233.64
I0902 00:08:03.699117 140413705484288 replay_runner.py:36] Average training steps per second: 233.64
I0902 00:08:03.980261 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.98
INFO:tensorflow:Starting iteration 18

Steps executed: 140 Episode length: 140 Return: -341.9545490673758663
INFO:tensorflow:Average training steps per second: 237.80
I0902 00:08:12.554852 140413705484288 replay_runner.py:36] Average training steps per second: 237.80

Steps executed: 267 Episode length: 127 Return: -348.0325945936781463
INFO:tensorflow:Starting iteration 19

Steps executed: 350 Episode length: 188 Return: -211.0183983816167463
INFO:tensorflow:Average training steps per second: 231.45
I0902 00:08:21.504946 140413705484288 replay_runner.py:36] Average training steps per second: 231.45
I0902 00:08:21.874161 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.03
INFO:tensorflow:Starting iteration 20

Steps executed: 192 Episode length: 63 Return: -41.034573631645197463
INFO:tensorflow:Average training steps per second: 227.98

Steps executed: 317 Episode length: 125 Return: -100.4373208618869463
I0902 00:08:30.973248 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.03
INFO:tensorflow:Starting iteration 21

Steps executed: 205 Episode length: 76 Return: -594.55019026044819463
INFO:tensorflow:Average training steps per second: 235.47
I0902 00:08:39.673134 140413705484288 replay_runner.py:36] Average training steps per second: 235.47
I0902 00:08:39.867253 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -429.50
INFO:tensorflow:Starting iteration 22

Steps executed: 233 Episode length: 120 Return: -532.7971068719364763
INFO:tensorflow:Average training steps per second: 236.57
I0902 00:08:48.520731 140413705484288 replay_runner.py:36] Average training steps per second: 236.57
I0902 00:08:48.721483 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -495.57
INFO:tensorflow:Starting iteration 23

Steps executed: 398 Episode length: 345 Return: -364.2557303018101763
INFO:tensorflow:Average training steps per second: 225.57
I0902 00:08:57.461019 140413705484288 replay_runner.py:36] Average training steps per second: 225.57
I0902 00:08:57.958157 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -370.01
INFO:tensorflow:Starting iteration 24

Steps executed: 307 Episode length: 131 Return: -215.0080684101531663
INFO:tensorflow:Average training steps per second: 233.86
I0902 00:09:06.648363 140413705484288 replay_runner.py:36] Average training steps per second: 233.86
I0902 00:09:06.924391 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -294.28
INFO:tensorflow:Starting iteration 25

Steps executed: 211 Episode length: 153 Return: 18.644250066833308663
INFO:tensorflow:Average training steps per second: 232.30
I0902 00:09:15.505656 140413705484288 replay_runner.py:36] Average training steps per second: 232.30
I0902 00:09:15.680314 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.35
INFO:tensorflow:Starting iteration 26

Steps executed: 300 Episode length: 216 Return: -679.3434233469945663
INFO:tensorflow:Average training steps per second: 228.84
I0902 00:09:24.418281 140413705484288 replay_runner.py:36] Average training steps per second: 228.84
I0902 00:09:24.685292 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -418.51
INFO:tensorflow:Starting iteration 27

Steps executed: 295 Episode length: 148 Return: -214.9754280614818663
INFO:tensorflow:Average training steps per second: 227.70
I0902 00:09:33.451530 140413705484288 replay_runner.py:36] Average training steps per second: 227.70
I0902 00:09:33.700462 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.54
INFO:tensorflow:Starting iteration 28

Steps executed: 203 Episode length: 86 Return: -453.01026293719804663
INFO:tensorflow:Average training steps per second: 227.91
I0902 00:09:42.521269 140413705484288 replay_runner.py:36] Average training steps per second: 227.91
I0902 00:09:42.698604 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -515.44
INFO:tensorflow:Starting iteration 29
I0902 00:09:46.989430 140413705484288 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 232.45
I0902 00:09:51.292189 140413705484288 replay_runner.py:36] Average training steps per second: 232.45


Done fixed training!Episode length: 64 Return: -237.47552245303856663