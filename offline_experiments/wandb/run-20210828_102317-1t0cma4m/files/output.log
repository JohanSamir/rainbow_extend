Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0828 10:23:24.271911 139825303013376 run_experiment.py:549] Creating TrainRunner ...
I0828 10:23:24.284633 139825303013376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:23:24.284875 139825303013376 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:23:24.285020 139825303013376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:23:24.285235 139825303013376 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:23:24.285449 139825303013376 dqn_agent.py:275] 	 update_period: 4
I0828 10:23:24.285549 139825303013376 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:23:24.285797 139825303013376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:23:24.285987 139825303013376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:23:24.286080 139825303013376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:23:24.286208 139825303013376 dqn_agent.py:280] 	 optimizer: adam
I0828 10:23:24.286450 139825303013376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:23:24.286545 139825303013376 dqn_agent.py:283] 	 seed: 1630146204284558
I0828 10:23:24.289005 139825303013376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:23:24.289133 139825303013376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:23:24.289205 139825303013376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:23:24.289281 139825303013376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:23:24.289377 139825303013376 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:23:24.289504 139825303013376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:23:24.289600 139825303013376 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:23:24.289656 139825303013376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:23:24.289708 139825303013376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:23:24.330713 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:24.717854 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:24.733033 139825303013376 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:23:24.742526 139825303013376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:23:24.742793 139825303013376 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:23:24.742901 139825303013376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:23:24.742992 139825303013376 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:23:24.743069 139825303013376 dqn_agent.py:275] 	 update_period: 4
I0828 10:23:24.743157 139825303013376 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:23:24.743239 139825303013376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:23:24.743349 139825303013376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:23:24.743422 139825303013376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:23:24.743492 139825303013376 dqn_agent.py:280] 	 optimizer: adam
I0828 10:23:24.743561 139825303013376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:23:24.743631 139825303013376 dqn_agent.py:283] 	 seed: 1630146204742462
I0828 10:23:24.746254 139825303013376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:23:24.746532 139825303013376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:23:24.746698 139825303013376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:23:24.746861 139825303013376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:23:24.747006 139825303013376 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:23:24.747095 139825303013376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:23:24.747370 139825303013376 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:23:24.747583 139825303013376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:23:24.747756 139825303013376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:23:25.093041 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:25.116200 139825303013376 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:23:25.116529 139825303013376 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 165.13
I0828 10:23:31.172505 139825303013376 replay_runner.py:36] Average training steps per second: 165.13
Steps executed: 252 Episode length: 54 Return: -311.73471443486044
I0828 10:23:32.306657 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.63
INFO:tensorflow:Starting iteration 1

Steps executed: 204 Episode length: 89 Return: -193.12455288235564
INFO:tensorflow:Average training steps per second: 224.80
I0828 10:23:41.186175 139825303013376 replay_runner.py:36] Average training steps per second: 224.80
I0828 10:23:41.314894 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.16
INFO:tensorflow:Starting iteration 2
I0828 10:23:45.689223 139825303013376 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 226.19

Steps executed: 235 Episode length: 59 Return: -461.76537484141653
I0828 10:23:50.304501 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -521.96
INFO:tensorflow:Starting iteration 3

Steps executed: 253 Episode length: 70 Return: -614.92626779771913
INFO:tensorflow:Average training steps per second: 220.10
I0828 10:23:59.043977 139825303013376 replay_runner.py:36] Average training steps per second: 220.10
I0828 10:23:59.250907 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -566.98
INFO:tensorflow:Starting iteration 4
I0828 10:24:03.638651 139825303013376 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 222.44

Steps executed: 236 Episode length: 51 Return: -401.36945285365413
I0828 10:24:08.333234 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -480.40
INFO:tensorflow:Starting iteration 5

Steps executed: 297 Episode length: 99 Return: -358.96129478376355
INFO:tensorflow:Average training steps per second: 227.21
I0828 10:24:17.146348 139825303013376 replay_runner.py:36] Average training steps per second: 227.21
I0828 10:24:17.318343 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.12
INFO:tensorflow:Starting iteration 6

Steps executed: 253 Episode length: 95 Return: 1.96797654151880863
INFO:tensorflow:Average training steps per second: 234.61
I0828 10:24:25.866888 139825303013376 replay_runner.py:36] Average training steps per second: 234.61
I0828 10:24:26.000712 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.85
INFO:tensorflow:Starting iteration 7

Steps executed: 242 Episode length: 60 Return: -535.20713470731383
INFO:tensorflow:Average training steps per second: 245.17
I0828 10:24:34.247009 139825303013376 replay_runner.py:36] Average training steps per second: 245.17
I0828 10:24:34.427349 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -499.60
INFO:tensorflow:Starting iteration 8

Steps executed: 234 Episode length: 52 Return: -361.01673276910014
INFO:tensorflow:Average training steps per second: 254.29
I0828 10:24:42.575200 139825303013376 replay_runner.py:36] Average training steps per second: 254.29
I0828 10:24:42.772847 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -457.25
INFO:tensorflow:Starting iteration 9

Steps executed: 237 Episode length: 92 Return: -639.88603913371748
INFO:tensorflow:Average training steps per second: 230.99
I0828 10:24:51.403248 139825303013376 replay_runner.py:36] Average training steps per second: 230.99
I0828 10:24:51.621351 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -744.79
INFO:tensorflow:Starting iteration 10

Steps executed: 245 Episode length: 85 Return: -604.82179054789618
INFO:tensorflow:Average training steps per second: 225.58
I0828 10:25:00.352703 139825303013376 replay_runner.py:36] Average training steps per second: 225.58
I0828 10:25:00.584304 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -562.83
INFO:tensorflow:Starting iteration 11

Steps executed: 315 Episode length: 230 Return: -1744.982177887157
INFO:tensorflow:Average training steps per second: 227.40
I0828 10:25:09.388208 139825303013376 replay_runner.py:36] Average training steps per second: 227.40
I0828 10:25:09.723432 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -1059.85
INFO:tensorflow:Starting iteration 12

Steps executed: 255 Episode length: 83 Return: -533.57789441115377
INFO:tensorflow:Average training steps per second: 223.48
I0828 10:25:18.522883 139825303013376 replay_runner.py:36] Average training steps per second: 223.48
I0828 10:25:18.772786 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -576.71
INFO:tensorflow:Starting iteration 13

Steps executed: 249 Episode length: 74 Return: -667.61136170050977
INFO:tensorflow:Average training steps per second: 222.73
I0828 10:25:27.645478 139825303013376 replay_runner.py:36] Average training steps per second: 222.73
I0828 10:25:27.869571 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -884.15
INFO:tensorflow:Starting iteration 14

Steps executed: 204 Episode length: 101 Return: -797.5262799036122
INFO:tensorflow:Average training steps per second: 216.65
I0828 10:25:36.765053 139825303013376 replay_runner.py:36] Average training steps per second: 216.65
I0828 10:25:36.961680 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -755.41
INFO:tensorflow:Starting iteration 15

Steps executed: 344 Episode length: 160 Return: -1163.813489719629
INFO:tensorflow:Average training steps per second: 219.08
I0828 10:25:45.851792 139825303013376 replay_runner.py:36] Average training steps per second: 219.08
I0828 10:25:46.183796 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -768.84
INFO:tensorflow:Starting iteration 16

Steps executed: 225 Episode length: 84 Return: -711.23627471248689
INFO:tensorflow:Average training steps per second: 224.91
I0828 10:25:54.962243 139825303013376 replay_runner.py:36] Average training steps per second: 224.91
I0828 10:25:55.148743 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -609.73
INFO:tensorflow:Starting iteration 17

Steps executed: 248 Episode length: 72 Return: -721.89419616320459
INFO:tensorflow:Average training steps per second: 223.30
I0828 10:26:04.023736 139825303013376 replay_runner.py:36] Average training steps per second: 223.30
I0828 10:26:04.236137 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -555.14
INFO:tensorflow:Starting iteration 18

Steps executed: 223 Episode length: 106 Return: -757.5170152658225
INFO:tensorflow:Average training steps per second: 223.30
I0828 10:26:13.071451 139825303013376 replay_runner.py:36] Average training steps per second: 223.30
I0828 10:26:13.285123 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -812.24
INFO:tensorflow:Starting iteration 19
I0828 10:26:17.685822 139825303013376 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 222.64
I0828 10:26:22.177796 139825303013376 replay_runner.py:36] Average training steps per second: 222.64

Steps executed: 262 Episode length: 82 Return: -379.51295564689104
INFO:tensorflow:Starting iteration 20

Steps executed: 270 Episode length: 115 Return: -735.6343606275065
INFO:tensorflow:Average training steps per second: 224.87
I0828 10:26:31.182796 139825303013376 replay_runner.py:36] Average training steps per second: 224.87
I0828 10:26:31.438637 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -652.13
INFO:tensorflow:Starting iteration 21
I0828 10:26:35.832369 139825303013376 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 222.15
I0828 10:26:40.334524 139825303013376 replay_runner.py:36] Average training steps per second: 222.15

Steps executed: 291 Episode length: 146 Return: -1037.3707057951167
INFO:tensorflow:Starting iteration 22

Steps executed: 212 Episode length: 212 Return: -1911.7332031309197
INFO:tensorflow:Average training steps per second: 220.06
I0828 10:26:49.565029 139825303013376 replay_runner.py:36] Average training steps per second: 220.06
I0828 10:26:49.807637 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -1911.73
INFO:tensorflow:Starting iteration 23
I0828 10:26:54.184958 139825303013376 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 223.40

Steps executed: 240 Episode length: 88 Return: -527.646692815454857
I0828 10:26:58.908785 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -783.23
INFO:tensorflow:Starting iteration 24

Steps executed: 241 Episode length: 241 Return: -1611.4401985396535
INFO:tensorflow:Average training steps per second: 222.43
I0828 10:27:07.734308 139825303013376 replay_runner.py:36] Average training steps per second: 222.43
I0828 10:27:08.050885 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -1611.44
INFO:tensorflow:Starting iteration 25
I0828 10:27:12.409929 139825303013376 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 229.29

Steps executed: 210 Episode length: 210 Return: -1227.6329144095925
I0828 10:27:17.027597 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -1227.63
INFO:tensorflow:Starting iteration 26

Steps executed: 272 Episode length: 87 Return: -863.053412835567945
INFO:tensorflow:Average training steps per second: 233.70
I0828 10:27:25.608849 139825303013376 replay_runner.py:36] Average training steps per second: 233.70
I0828 10:27:25.824459 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -614.17
INFO:tensorflow:Starting iteration 27

Steps executed: 299 Episode length: 121 Return: -639.01696573684565
INFO:tensorflow:Average training steps per second: 234.77
I0828 10:27:34.163722 139825303013376 replay_runner.py:36] Average training steps per second: 234.77
I0828 10:27:34.491705 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -516.87
INFO:tensorflow:Starting iteration 28

Steps executed: 216 Episode length: 73 Return: -618.304679451779565
INFO:tensorflow:Average training steps per second: 233.25
I0828 10:27:43.007362 139825303013376 replay_runner.py:36] Average training steps per second: 233.25
I0828 10:27:43.195756 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -657.76
INFO:tensorflow:Starting iteration 29

Steps executed: 263 Episode length: 113 Return: -752.65614860253916
INFO:tensorflow:Average training steps per second: 244.76
I0828 10:27:51.518972 139825303013376 replay_runner.py:36] Average training steps per second: 244.76

Done fixed training!Episode length: 113 Return: -752.65614860253916