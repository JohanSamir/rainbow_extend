Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0902 23:35:43.457127 140369919707136 run_experiment.py:549] Creating TrainRunner ...
I0902 23:35:43.469071 140369919707136 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:35:43.469331 140369919707136 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:35:43.469475 140369919707136 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:35:43.469626 140369919707136 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:35:43.469720 140369919707136 dqn_agent.py:275] 	 update_period: 4
I0902 23:35:43.469796 140369919707136 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:35:43.469900 140369919707136 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:35:43.469986 140369919707136 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:35:43.470100 140369919707136 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:35:43.470216 140369919707136 dqn_agent.py:280] 	 optimizer: adam
I0902 23:35:43.470331 140369919707136 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:35:43.470410 140369919707136 dqn_agent.py:283] 	 seed: 1630625743469007
I0902 23:35:43.474040 140369919707136 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:35:43.474311 140369919707136 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:35:43.474465 140369919707136 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:35:43.474586 140369919707136 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:35:43.474710 140369919707136 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:35:43.474830 140369919707136 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:35:43.475003 140369919707136 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:35:43.475114 140369919707136 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:35:43.475217 140369919707136 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:35:43.514636 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:35:43.885211 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:35:43.899190 140369919707136 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:35:43.908647 140369919707136 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:35:43.908899 140369919707136 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:35:43.909035 140369919707136 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:35:43.909159 140369919707136 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:35:43.909256 140369919707136 dqn_agent.py:275] 	 update_period: 4
I0902 23:35:43.909518 140369919707136 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:35:43.909677 140369919707136 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:35:43.909762 140369919707136 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:35:43.909836 140369919707136 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:35:43.909911 140369919707136 dqn_agent.py:280] 	 optimizer: adam
I0902 23:35:43.910015 140369919707136 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:35:43.910132 140369919707136 dqn_agent.py:283] 	 seed: 1630625743908595
I0902 23:35:43.912809 140369919707136 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:35:43.913024 140369919707136 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:35:43.913307 140369919707136 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:35:43.913476 140369919707136 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:35:43.913570 140369919707136 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:35:43.913643 140369919707136 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:35:43.913718 140369919707136 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:35:43.913789 140369919707136 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:35:43.913856 140369919707136 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:35:43.985960 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:35:44.007241 140369919707136 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:35:44.007594 140369919707136 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.07
I0902 23:35:50.178144 140369919707136 replay_runner.py:36] Average training steps per second: 162.07
Steps executed: 370 Episode length: 186 Return: -451.3075795432342
I0902 23:35:52.085821 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -485.63
INFO:tensorflow:Starting iteration 1

Steps executed: 301 Episode length: 145 Return: -443.5335808906085
INFO:tensorflow:Average training steps per second: 221.43
I0902 23:36:00.832382 140369919707136 replay_runner.py:36] Average training steps per second: 221.43
I0902 23:36:01.134711 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -394.79
INFO:tensorflow:Starting iteration 2

Steps executed: 220 Episode length: 114 Return: -333.03160020053866
INFO:tensorflow:Average training steps per second: 222.10
I0902 23:36:10.026103 140369919707136 replay_runner.py:36] Average training steps per second: 222.10
I0902 23:36:10.214875 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.86
INFO:tensorflow:Starting iteration 3
I0902 23:36:14.540954 140369919707136 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 223.21

Steps executed: 220 Episode length: 220 Return: -179.18578549830602
I0902 23:36:19.289708 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.19
INFO:tensorflow:Starting iteration 4
I0902 23:36:23.457984 140369919707136 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 223.42

Steps executed: 1000 Episode length: 1000 Return: -37.12708136361717
I0902 23:36:30.324267 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.13
INFO:tensorflow:Starting iteration 5
I0902 23:36:34.560366 140369919707136 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 217.08

Steps executed: 1000 Episode length: 1000 Return: -42.994279008235885
I0902 23:36:43.010148 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -42.99
INFO:tensorflow:Starting iteration 6
I0902 23:36:47.315744 140369919707136 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 223.77

Steps executed: 1000 Episode length: 1000 Return: -124.17971284905173
I0902 23:36:53.935589 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.18
INFO:tensorflow:Starting iteration 7
I0902 23:36:58.209688 140369919707136 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 217.79
I0902 23:37:02.801837 140369919707136 replay_runner.py:36] Average training steps per second: 217.79

Steps executed: 1000 Episode length: 1000 Return: -81.907059523250573
INFO:tensorflow:Starting iteration 8
I0902 23:37:09.944038 140369919707136 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 223.09

Steps executed: 1000 Episode length: 1000 Return: -258.78325726984533
I0902 23:37:16.919077 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.78
INFO:tensorflow:Starting iteration 9
I0902 23:37:21.421090 140369919707136 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 231.77

Steps executed: 1000 Episode length: 1000 Return: -134.52042600176236
I0902 23:37:28.129914 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.52
INFO:tensorflow:Starting iteration 10
I0902 23:37:32.356589 140369919707136 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 237.84

Steps executed: 961 Episode length: 961 Return: -752.5498912238746236
I0902 23:37:38.189425 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -752.55
INFO:tensorflow:Starting iteration 11
I0902 23:37:42.426970 140369919707136 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 228.60

Steps executed: 1000 Episode length: 1000 Return: -169.91189550265856
I0902 23:37:50.150190 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.91
INFO:tensorflow:Starting iteration 12

Steps executed: 348 Episode length: 160 Return: -164.1808635346250256
INFO:tensorflow:Average training steps per second: 228.81
I0902 23:37:58.776360 140369919707136 replay_runner.py:36] Average training steps per second: 228.81
I0902 23:37:59.104417 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.33
INFO:tensorflow:Starting iteration 13
I0902 23:38:03.526695 140369919707136 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 232.15

Steps executed: 1000 Episode length: 1000 Return: -77.506092885197666
I0902 23:38:10.757909 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.51
INFO:tensorflow:Starting iteration 14
I0902 23:38:15.136112 140369919707136 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 223.77

Steps executed: 490 Episode length: 490 Return: -151.5659044501049766
I0902 23:38:20.527424 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.57
INFO:tensorflow:Starting iteration 15
I0902 23:38:24.836890 140369919707136 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 215.42

Steps executed: 560 Episode length: 421 Return: -184.6952861989527266
I0902 23:38:30.308262 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.82
INFO:tensorflow:Starting iteration 16

Steps executed: 86 Episode length: 86 Return: -674.535556002129927266
INFO:tensorflow:Average training steps per second: 215.12

Steps executed: 289 Episode length: 101 Return: -717.3895923968458266
I0902 23:38:39.651114 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -712.19
INFO:tensorflow:Starting iteration 17

Steps executed: 201 Episode length: 201 Return: -533.0644322132875266
INFO:tensorflow:Average training steps per second: 212.24
I0902 23:38:48.699090 140369919707136 replay_runner.py:36] Average training steps per second: 212.24
I0902 23:38:48.936142 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -533.06
INFO:tensorflow:Starting iteration 18

Steps executed: 281 Episode length: 281 Return: 44.140824461578546266
INFO:tensorflow:Average training steps per second: 216.73
I0902 23:38:57.818724 140369919707136 replay_runner.py:36] Average training steps per second: 216.73
I0902 23:38:58.151996 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: 44.14
INFO:tensorflow:Starting iteration 19

Steps executed: 283 Episode length: 132 Return: -452.0478585384807266
INFO:tensorflow:Average training steps per second: 212.32
I0902 23:39:07.177295 140369919707136 replay_runner.py:36] Average training steps per second: 212.32
I0902 23:39:07.449145 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -537.61
INFO:tensorflow:Starting iteration 20

Steps executed: 274 Episode length: 77 Return: -150.61402135192998266
INFO:tensorflow:Average training steps per second: 216.32
I0902 23:39:16.351351 140369919707136 replay_runner.py:36] Average training steps per second: 216.32
I0902 23:39:16.575335 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.42
INFO:tensorflow:Starting iteration 21

Steps executed: 247 Episode length: 125 Return: -514.3943459166412266
INFO:tensorflow:Average training steps per second: 220.30
I0902 23:39:25.222775 140369919707136 replay_runner.py:36] Average training steps per second: 220.30
I0902 23:39:25.476043 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -557.62
INFO:tensorflow:Starting iteration 22

Steps executed: 664 Episode length: 532 Return: -530.3508900752754266
INFO:tensorflow:Average training steps per second: 216.76
I0902 23:39:34.124885 140369919707136 replay_runner.py:36] Average training steps per second: 216.76
I0902 23:39:35.438718 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -337.64
INFO:tensorflow:Starting iteration 23

Steps executed: 217 Episode length: 116 Return: -738.6724140693204566
INFO:tensorflow:Average training steps per second: 218.58
I0902 23:39:44.292389 140369919707136 replay_runner.py:36] Average training steps per second: 218.58
I0902 23:39:44.488676 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -617.19
INFO:tensorflow:Starting iteration 24

Steps executed: 211 Episode length: 97 Return: -884.46569463150834566
INFO:tensorflow:Average training steps per second: 223.81
I0902 23:39:53.277162 140369919707136 replay_runner.py:36] Average training steps per second: 223.81
I0902 23:39:53.436481 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -373.47
INFO:tensorflow:Starting iteration 25

Steps executed: 280 Episode length: 121 Return: -319.4449389879730566
INFO:tensorflow:Average training steps per second: 222.55
I0902 23:40:02.118083 140369919707136 replay_runner.py:36] Average training steps per second: 222.55
I0902 23:40:02.341665 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.53
INFO:tensorflow:Starting iteration 26

Steps executed: 305 Episode length: 305 Return: -639.7465015295535566
INFO:tensorflow:Average training steps per second: 214.69
I0902 23:40:11.259086 140369919707136 replay_runner.py:36] Average training steps per second: 214.69
I0902 23:40:11.662069 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -639.75
INFO:tensorflow:Starting iteration 27

Steps executed: 209 Episode length: 53 Return: -206.20186229866704566
INFO:tensorflow:Average training steps per second: 232.86
I0902 23:40:19.960259 140369919707136 replay_runner.py:36] Average training steps per second: 232.86
I0902 23:40:20.130511 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -392.43
INFO:tensorflow:Starting iteration 28

Steps executed: 214 Episode length: 110 Return: -660.0419987937404566
INFO:tensorflow:Average training steps per second: 229.93
I0902 23:40:28.779634 140369919707136 replay_runner.py:36] Average training steps per second: 229.93
I0902 23:40:28.974993 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -743.48
INFO:tensorflow:Starting iteration 29

Steps executed: 251 Episode length: 79 Return: -487.02072881166686566
INFO:tensorflow:Average training steps per second: 223.31
I0902 23:40:37.571341 140369919707136 replay_runner.py:36] Average training steps per second: 223.31

Done fixed training!Episode length: 79 Return: -487.02072881166686566