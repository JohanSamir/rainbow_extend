Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0901 13:19:24.461344 140536266098688 run_experiment.py:549] Creating TrainRunner ...
I0901 13:19:24.469602 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:19:24.469758 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:19:24.469851 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:19:24.469918 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:19:24.469993 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 13:19:24.470077 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:19:24.470157 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:19:24.470254 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:19:24.470326 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:19:24.470402 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 13:19:24.470473 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:19:24.470542 140536266098688 dqn_agent.py:283] 	 seed: 1630502364469557
I0901 13:19:24.472553 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:19:24.472686 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:19:24.472763 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:19:24.472835 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:19:24.472898 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:19:24.472961 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:19:24.473052 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:19:24.473174 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:19:24.473242 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:19:24.504405 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:24.756790 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:24.765812 140536266098688 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:19:24.773252 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:19:24.773516 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:19:24.773649 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:19:24.773741 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:19:24.774067 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 13:19:24.774249 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:19:24.774352 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:19:24.774435 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:19:24.774554 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:19:24.774692 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 13:19:24.774830 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:19:24.774907 140536266098688 dqn_agent.py:283] 	 seed: 1630502364773204
I0901 13:19:24.776778 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:19:24.776926 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:19:24.777020 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:19:24.777102 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:19:24.777184 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:19:24.777250 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:19:24.777345 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:19:24.777410 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:19:24.777495 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:19:24.801897 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:24.815909 140536266098688 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:19:24.816090 140536266098688 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 244.82
I0901 13:19:28.900925 140536266098688 replay_runner.py:36] Average training steps per second: 244.82
I0901 13:19:29.784560 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.02
Steps executed: 234 Episode length: 129 Return: -157.59819622408357
INFO:tensorflow:Starting iteration 1

Steps executed: 264 Episode length: 138 Return: -537.77177790614974
INFO:tensorflow:Average training steps per second: 340.86
I0901 13:19:36.201531 140536266098688 replay_runner.py:36] Average training steps per second: 340.86
I0901 13:19:36.382640 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -415.89
INFO:tensorflow:Starting iteration 2

Steps executed: 203 Episode length: 76 Return: -353.452070305170374
INFO:tensorflow:Average training steps per second: 349.61
I0901 13:19:42.810582 140536266098688 replay_runner.py:36] Average training steps per second: 349.61
I0901 13:19:42.928944 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -320.94
INFO:tensorflow:Starting iteration 3

Steps executed: 240 Episode length: 79 Return: -190.795075124618626
INFO:tensorflow:Average training steps per second: 327.94
I0901 13:19:49.405094 140536266098688 replay_runner.py:36] Average training steps per second: 327.94
I0901 13:19:49.549668 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.30
INFO:tensorflow:Starting iteration 4

Steps executed: 282 Episode length: 88 Return: -255.294090231103386
INFO:tensorflow:Average training steps per second: 354.09
I0901 13:19:55.844998 140536266098688 replay_runner.py:36] Average training steps per second: 354.09
I0901 13:19:55.989943 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.90
INFO:tensorflow:Starting iteration 5

Steps executed: 412 Episode length: 412 Return: -155.12053521523208
INFO:tensorflow:Average training steps per second: 348.96
I0901 13:20:02.352789 140536266098688 replay_runner.py:36] Average training steps per second: 348.96
I0901 13:20:02.778214 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.12
INFO:tensorflow:Starting iteration 6
I0901 13:20:06.300165 140536266098688 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 338.41
I0901 13:20:09.255565 140536266098688 replay_runner.py:36] Average training steps per second: 338.41

Steps executed: 1000 Episode length: 1000 Return: -207.2644709956172
INFO:tensorflow:Starting iteration 7

Steps executed: 546 Episode length: 546 Return: -182.987212933105162
INFO:tensorflow:Average training steps per second: 329.94
I0901 13:20:18.753401 140536266098688 replay_runner.py:36] Average training steps per second: 329.94
I0901 13:20:19.718272 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.99
INFO:tensorflow:Starting iteration 8
I0901 13:20:23.092963 140536266098688 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 325.50

Steps executed: 821 Episode length: 821 Return: -371.066406957090862
I0901 13:20:27.807506 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -371.07
INFO:tensorflow:Starting iteration 9

Steps executed: 244 Episode length: 70 Return: -161.4094815348173462
INFO:tensorflow:Average training steps per second: 314.67
I0901 13:20:34.265577 140536266098688 replay_runner.py:36] Average training steps per second: 314.67
I0901 13:20:34.383054 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.38
INFO:tensorflow:Starting iteration 10
I0901 13:20:37.629096 140536266098688 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 306.76

Steps executed: 902 Episode length: 902 Return: -303.542831995018862
I0901 13:20:42.632239 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.54
INFO:tensorflow:Starting iteration 11

Steps executed: 600 Episode length: 426 Return: -247.414217602923832
INFO:tensorflow:Average training steps per second: 323.83
I0901 13:20:48.990308 140536266098688 replay_runner.py:36] Average training steps per second: 323.83
I0901 13:20:49.618873 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.67
INFO:tensorflow:Starting iteration 12

Steps executed: 359 Episode length: 359 Return: -282.504646870673832
INFO:tensorflow:Average training steps per second: 322.25
I0901 13:20:56.120861 140536266098688 replay_runner.py:36] Average training steps per second: 322.25
I0901 13:20:56.477145 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -282.50
INFO:tensorflow:Starting iteration 13

Steps executed: 505 Episode length: 505 Return: -592.062354789914732
INFO:tensorflow:Average training steps per second: 321.61
I0901 13:21:02.936384 140536266098688 replay_runner.py:36] Average training steps per second: 321.61
I0901 13:21:03.570730 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -592.06
INFO:tensorflow:Starting iteration 14

Steps executed: 565 Episode length: 373 Return: -361.883998831393632
INFO:tensorflow:Average training steps per second: 317.25
I0901 13:21:10.017894 140536266098688 replay_runner.py:36] Average training steps per second: 317.25
I0901 13:21:10.608067 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -392.51
INFO:tensorflow:Starting iteration 15

Steps executed: 344 Episode length: 285 Return: -145.725926968687732
INFO:tensorflow:Average training steps per second: 309.08
I0901 13:21:17.109555 140536266098688 replay_runner.py:36] Average training steps per second: 309.08
I0901 13:21:17.364527 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.59
INFO:tensorflow:Starting iteration 16

Steps executed: 312 Episode length: 161 Return: -162.421719427308532
INFO:tensorflow:Average training steps per second: 318.63
I0901 13:21:23.830038 140536266098688 replay_runner.py:36] Average training steps per second: 318.63
I0901 13:21:23.992995 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.75
INFO:tensorflow:Starting iteration 17

Steps executed: 264 Episode length: 75 Return: -100.5359879902783232
INFO:tensorflow:Average training steps per second: 320.24
I0901 13:21:30.481922 140536266098688 replay_runner.py:36] Average training steps per second: 320.24
I0901 13:21:30.644953 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.31
INFO:tensorflow:Starting iteration 18

Steps executed: 239 Episode length: 239 Return: 30.00970209139737232
INFO:tensorflow:Average training steps per second: 320.79
I0901 13:21:37.128391 140536266098688 replay_runner.py:36] Average training steps per second: 320.79
I0901 13:21:37.305283 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: 30.01
INFO:tensorflow:Starting iteration 19
I0901 13:21:40.704553 140536266098688 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 321.82

Steps executed: 1000 Episode length: 1000 Return: -193.56596550798594
I0901 13:21:46.394000 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.57
INFO:tensorflow:Starting iteration 20

Steps executed: 437 Episode length: 363 Return: -319.1063061132541594
INFO:tensorflow:Average training steps per second: 320.93
I0901 13:21:52.886250 140536266098688 replay_runner.py:36] Average training steps per second: 320.93
I0901 13:21:53.251109 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.87
INFO:tensorflow:Starting iteration 21

Steps executed: 270 Episode length: 135 Return: -402.1967163396746594
INFO:tensorflow:Average training steps per second: 317.14
I0901 13:21:59.771699 140536266098688 replay_runner.py:36] Average training steps per second: 317.14
I0901 13:21:59.952622 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.46
INFO:tensorflow:Starting iteration 22

Steps executed: 69 Episode length: 69 Return: -65.9001746802828246594
INFO:tensorflow:Average training steps per second: 312.13
I0901 13:22:06.411706 140536266098688 replay_runner.py:36] Average training steps per second: 312.13

Steps executed: 222 Episode length: 153 Return: -395.6738718240601494
INFO:tensorflow:Starting iteration 23

Steps executed: 379 Episode length: 231 Return: -155.7850784241193194
INFO:tensorflow:Average training steps per second: 338.43
I0901 13:22:12.833363 140536266098688 replay_runner.py:36] Average training steps per second: 338.43
I0901 13:22:13.109297 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.96
INFO:tensorflow:Starting iteration 24

Steps executed: 370 Episode length: 370 Return: -338.9182150946536594
INFO:tensorflow:Average training steps per second: 370.44
I0901 13:22:19.219990 140536266098688 replay_runner.py:36] Average training steps per second: 370.44
I0901 13:22:19.620790 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.92
INFO:tensorflow:Starting iteration 25

Steps executed: 254 Episode length: 58 Return: -153.15309626240122594
INFO:tensorflow:Average training steps per second: 347.64
I0901 13:22:26.023212 140536266098688 replay_runner.py:36] Average training steps per second: 347.64
I0901 13:22:26.158548 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.55
INFO:tensorflow:Starting iteration 26
I0901 13:22:29.588770 140536266098688 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 333.45
I0901 13:22:32.587984 140536266098688 replay_runner.py:36] Average training steps per second: 333.45

Steps executed: 213 Episode length: 63 Return: -12.394568473433267594
INFO:tensorflow:Starting iteration 27

Steps executed: 243 Episode length: 61 Return: -136.45227025762293894
INFO:tensorflow:Average training steps per second: 332.29
I0901 13:22:39.043988 140536266098688 replay_runner.py:36] Average training steps per second: 332.29
I0901 13:22:39.172871 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.72
INFO:tensorflow:Starting iteration 28
I0901 13:22:42.586856 140536266098688 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 360.43

Steps executed: 1000 Episode length: 1000 Return: -15.173891749234091
I0901 13:22:47.503373 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -15.17
INFO:tensorflow:Starting iteration 29

Steps executed: 474 Episode length: 474 Return: -32.02676481559061091
INFO:tensorflow:Average training steps per second: 330.65
I0901 13:22:53.863641 140536266098688 replay_runner.py:36] Average training steps per second: 330.65

Done fixed training!Episode length: 474 Return: -32.02676481559061091