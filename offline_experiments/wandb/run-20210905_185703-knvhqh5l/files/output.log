Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0905 18:57:10.701086 139920723499008 run_experiment.py:549] Creating TrainRunner ...
I0905 18:57:10.713984 139920723499008 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 18:57:10.714384 139920723499008 dqn_agent.py:272] 	 gamma: 0.990000
I0905 18:57:10.714581 139920723499008 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 18:57:10.714724 139920723499008 dqn_agent.py:274] 	 min_replay_history: 500
I0905 18:57:10.714972 139920723499008 dqn_agent.py:275] 	 update_period: 4
I0905 18:57:10.715115 139920723499008 dqn_agent.py:276] 	 target_update_period: 300
I0905 18:57:10.715342 139920723499008 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 18:57:10.715487 139920723499008 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 18:57:10.715613 139920723499008 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 18:57:10.715730 139920723499008 dqn_agent.py:280] 	 optimizer: adam
I0905 18:57:10.715841 139920723499008 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 18:57:10.715954 139920723499008 dqn_agent.py:283] 	 seed: 1630868230713916
I0905 18:57:10.719544 139920723499008 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 18:57:10.720206 139920723499008 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 18:57:10.720416 139920723499008 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 18:57:10.720799 139920723499008 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 18:57:10.720944 139920723499008 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 18:57:10.721071 139920723499008 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 18:57:10.721179 139920723499008 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 18:57:10.721271 139920723499008 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 18:57:10.721447 139920723499008 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 18:57:10.778114 139920723499008 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:57:11.346052 139920723499008 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:57:11.365956 139920723499008 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 18:57:11.379308 139920723499008 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 18:57:11.379650 139920723499008 dqn_agent.py:272] 	 gamma: 0.990000
I0905 18:57:11.379795 139920723499008 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 18:57:11.379921 139920723499008 dqn_agent.py:274] 	 min_replay_history: 500
I0905 18:57:11.380046 139920723499008 dqn_agent.py:275] 	 update_period: 4
I0905 18:57:11.380161 139920723499008 dqn_agent.py:276] 	 target_update_period: 300
I0905 18:57:11.380741 139920723499008 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 18:57:11.381087 139920723499008 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 18:57:11.381311 139920723499008 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 18:57:11.381452 139920723499008 dqn_agent.py:280] 	 optimizer: adam
I0905 18:57:11.381592 139920723499008 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 18:57:11.381900 139920723499008 dqn_agent.py:283] 	 seed: 1630868231379233
I0905 18:57:11.385725 139920723499008 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 18:57:11.386053 139920723499008 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 18:57:11.386236 139920723499008 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 18:57:11.386377 139920723499008 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 18:57:11.386481 139920723499008 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 18:57:11.386693 139920723499008 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 18:57:11.386861 139920723499008 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 18:57:11.387184 139920723499008 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 18:57:11.387391 139920723499008 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 18:57:11.457156 139920723499008 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 18:57:11.502578 139920723499008 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 18:57:11.503015 139920723499008 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 123.63
I0905 18:57:19.592247 139920723499008 replay_runner.py:36] Average training steps per second: 123.63
Steps executed: 307 Episode length: 131 Return: -270.22326894866983
I0905 18:57:21.391144 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.10
INFO:tensorflow:Starting iteration 1

Steps executed: 137 Episode length: 137 Return: -349.32630276659543
INFO:tensorflow:Average training steps per second: 174.84

Steps executed: 311 Episode length: 174 Return: -503.12691307224523
I0905 18:57:32.467418 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -426.23
INFO:tensorflow:Starting iteration 2

Steps executed: 364 Episode length: 364 Return: -581.48482912336933
INFO:tensorflow:Average training steps per second: 178.42
I0905 18:57:42.884927 139920723499008 replay_runner.py:36] Average training steps per second: 178.42
I0905 18:57:43.669734 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -581.48
INFO:tensorflow:Starting iteration 3
I0905 18:57:47.623428 139920723499008 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 183.72

Steps executed: 1000 Episode length: 1000 Return: -127.03111013046424
I0905 18:57:57.874052 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.03
INFO:tensorflow:Starting iteration 4
I0905 18:58:02.706066 139920723499008 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 189.33

Steps executed: 1000 Episode length: 1000 Return: -201.37088992063824
I0905 18:58:12.541089 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.37
INFO:tensorflow:Starting iteration 5
I0905 18:58:17.162208 139920723499008 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 183.70

Steps executed: 1000 Episode length: 1000 Return: -337.26186181723924
I0905 18:58:25.782721 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -337.26
INFO:tensorflow:Starting iteration 6
I0905 18:58:30.634294 139920723499008 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 177.22

Steps executed: 1000 Episode length: 1000 Return: -328.66337341668935
I0905 18:58:40.140097 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.66
INFO:tensorflow:Starting iteration 7
I0905 18:58:44.709870 139920723499008 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 188.83

Steps executed: 1000 Episode length: 1000 Return: -263.10422782208385
I0905 18:58:54.217443 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.10
INFO:tensorflow:Starting iteration 8
I0905 18:58:58.739369 139920723499008 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 180.16

Steps executed: 1000 Episode length: 1000 Return: -339.46454531309075
I0905 18:59:07.681029 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -339.46
INFO:tensorflow:Starting iteration 9
I0905 18:59:12.228963 139920723499008 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 196.37

Steps executed: 1000 Episode length: 1000 Return: -351.52315433628735
I0905 18:59:21.076227 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -351.52
INFO:tensorflow:Starting iteration 10

Steps executed: 208 Episode length: 208 Return: -75.31239367354618735
INFO:tensorflow:Average training steps per second: 212.31
I0905 18:59:30.311814 139920723499008 replay_runner.py:36] Average training steps per second: 212.31
I0905 18:59:30.526165 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.31
INFO:tensorflow:Starting iteration 11
I0905 18:59:35.073572 139920723499008 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 222.88

Steps executed: 838 Episode length: 838 Return: -281.7834688251046735
I0905 18:59:41.471967 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.78
INFO:tensorflow:Starting iteration 12

Steps executed: 259 Episode length: 259 Return: -121.8862251095823435
INFO:tensorflow:Average training steps per second: 262.90
I0905 18:59:49.610421 139920723499008 replay_runner.py:36] Average training steps per second: 262.90
I0905 18:59:49.848525 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.89
INFO:tensorflow:Starting iteration 13

Steps executed: 212 Episode length: 212 Return: -194.7002873131183435
INFO:tensorflow:Average training steps per second: 263.83
I0905 18:59:56.970778 139920723499008 replay_runner.py:36] Average training steps per second: 263.83
I0905 18:59:57.149678 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -194.70
INFO:tensorflow:Starting iteration 14
I0905 19:00:00.498388 139920723499008 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 276.60

Steps executed: 1000 Episode length: 1000 Return: -49.972311171667135
I0905 19:00:06.414444 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -49.97
INFO:tensorflow:Starting iteration 15
I0905 19:00:09.947309 139920723499008 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 271.29

Steps executed: 1000 Episode length: 1000 Return: -24.465488035273726
I0905 19:00:16.224380 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -24.47
INFO:tensorflow:Starting iteration 16

Steps executed: 353 Episode length: 201 Return: -133.9670743349386226
INFO:tensorflow:Average training steps per second: 294.97
I0905 19:00:23.233246 139920723499008 replay_runner.py:36] Average training steps per second: 294.97
I0905 19:00:23.506995 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.85
INFO:tensorflow:Starting iteration 17

Steps executed: 344 Episode length: 166 Return: -509.9330408465235726
INFO:tensorflow:Average training steps per second: 330.52
I0905 19:00:30.246421 139920723499008 replay_runner.py:36] Average training steps per second: 330.52
I0905 19:00:30.514143 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.96
INFO:tensorflow:Starting iteration 18

Steps executed: 443 Episode length: 286 Return: -45.05146626135516626
INFO:tensorflow:Average training steps per second: 319.49
I0905 19:00:37.478298 139920723499008 replay_runner.py:36] Average training steps per second: 319.49
I0905 19:00:37.866442 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -52.95
INFO:tensorflow:Starting iteration 19
I0905 19:00:41.620783 139920723499008 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 319.15

Steps executed: 121 Episode length: 121 Return: -33.25322878465125626

Steps executed: 1121 Episode length: 1000 Return: 111.798121701534236
INFO:tensorflow:Starting iteration 20

Steps executed: 311 Episode length: 156 Return: -32.20198466204776436
INFO:tensorflow:Average training steps per second: 304.44
I0905 19:00:54.015048 139920723499008 replay_runner.py:36] Average training steps per second: 304.44
I0905 19:00:54.286746 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -58.33
INFO:tensorflow:Starting iteration 21
I0905 19:00:58.059540 139920723499008 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 323.94

Steps executed: 458 Episode length: 458 Return: -348.1778147396230536
I0905 19:01:01.784991 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -348.18
INFO:tensorflow:Starting iteration 22
I0905 19:01:05.534350 139920723499008 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 322.34

Steps executed: 1000 Episode length: 1000 Return: 26.8487207447433466
I0905 19:01:11.411104 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: 26.85
INFO:tensorflow:Starting iteration 23
I0905 19:01:15.049899 139920723499008 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 296.53

Steps executed: 1000 Episode length: 1000 Return: -13.692503688644765
I0905 19:01:20.527276 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -13.69
INFO:tensorflow:Starting iteration 24

Steps executed: 302 Episode length: 302 Return: -57.99618540632569765
INFO:tensorflow:Average training steps per second: 274.47
I0905 19:01:27.649090 139920723499008 replay_runner.py:36] Average training steps per second: 274.47
I0905 19:01:27.981606 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -58.00
INFO:tensorflow:Starting iteration 25
I0905 19:01:31.359018 139920723499008 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 275.63

Steps executed: 433 Episode length: 433 Return: 191.26545915700405765
I0905 19:01:35.588201 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: 191.27
INFO:tensorflow:Starting iteration 26
I0905 19:01:39.149875 139920723499008 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 283.04

Steps executed: 406 Episode length: 406 Return: -67.19549621110261765
I0905 19:01:43.317385 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -67.20
INFO:tensorflow:Starting iteration 27
I0905 19:01:46.745578 139920723499008 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 287.12
I0905 19:01:50.228744 139920723499008 replay_runner.py:36] Average training steps per second: 287.12

Steps executed: 572 Episode length: 572 Return: -390.7436901921161765
INFO:tensorflow:Starting iteration 28
I0905 19:01:54.574010 139920723499008 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 286.56

Steps executed: 1000 Episode length: 1000 Return: -27.886725791534045
I0905 19:02:00.597000 139920723499008 run_experiment.py:428] Average undiscounted return per evaluation episode: -27.89
INFO:tensorflow:Starting iteration 29

Steps executed: 362 Episode length: 188 Return: -319.4939226259390445
INFO:tensorflow:Average training steps per second: 295.80
I0905 19:02:07.804703 139920723499008 replay_runner.py:36] Average training steps per second: 295.80

Done fixed training!Episode length: 188 Return: -319.4939226259390445