Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 12:45:46.151248 140315766171648 run_experiment.py:549] Creating TrainRunner ...
I0901 12:45:46.165054 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:45:46.165566 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:45:46.166023 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:45:46.166353 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:45:46.166479 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 12:45:46.166578 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:45:46.166666 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:45:46.166846 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:45:46.166967 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:45:46.167061 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 12:45:46.167172 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:45:46.167297 140315766171648 dqn_agent.py:283] 	 seed: 1630500346164976
I0901 12:45:46.170247 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:45:46.170388 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:45:46.170474 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:45:46.170549 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:45:46.170613 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:45:46.170702 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:45:46.170763 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:45:46.170819 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:45:46.170876 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:45:46.214693 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:45:46.606717 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:45:46.622789 140315766171648 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:45:46.634084 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:45:46.639580 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:45:46.639831 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:45:46.640002 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:45:46.640159 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 12:45:46.645973 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:45:46.651617 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:45:46.651873 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:45:46.652089 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:45:46.657556 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 12:45:46.657820 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:45:46.657941 140315766171648 dqn_agent.py:283] 	 seed: 1630500346634017
I0901 12:45:46.664968 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:45:46.665248 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:45:46.665363 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:45:46.665451 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:45:46.665821 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:45:46.666135 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:45:46.666338 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:45:46.666499 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:45:46.666660 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:45:46.704448 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:45:46.730051 140315766171648 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:45:46.730279 140315766171648 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 156.94
I0901 12:45:53.102373 140315766171648 replay_runner.py:36] Average training steps per second: 156.94
Steps executed: 205 Episode length: 205 Return: -260.70065486651947
I0901 12:45:54.413956 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.70
INFO:tensorflow:Starting iteration 1

Steps executed: 253 Episode length: 167 Return: -66.710478520816987
INFO:tensorflow:Average training steps per second: 217.42
I0901 12:46:03.488508 140315766171648 replay_runner.py:36] Average training steps per second: 217.42
I0901 12:46:03.703003 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.67
INFO:tensorflow:Starting iteration 2

Steps executed: 228 Episode length: 115 Return: -68.909826107141247
INFO:tensorflow:Average training steps per second: 219.26
I0901 12:46:12.721777 140315766171648 replay_runner.py:36] Average training steps per second: 219.26
I0901 12:46:12.928754 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.83
INFO:tensorflow:Starting iteration 3
I0901 12:46:17.309317 140315766171648 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 220.46

Steps executed: 270 Episode length: 82 Return: -234.371451323002877
I0901 12:46:22.079189 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.91
INFO:tensorflow:Starting iteration 4

Steps executed: 207 Episode length: 125 Return: -250.54342017310682
INFO:tensorflow:Average training steps per second: 230.06
I0901 12:46:30.867717 140315766171648 replay_runner.py:36] Average training steps per second: 230.06
I0901 12:46:31.035239 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.08
INFO:tensorflow:Starting iteration 5

Steps executed: 260 Episode length: 110 Return: -360.08514099136372
INFO:tensorflow:Average training steps per second: 217.10
I0901 12:46:40.138484 140315766171648 replay_runner.py:36] Average training steps per second: 217.10
I0901 12:46:40.345078 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -315.24
INFO:tensorflow:Starting iteration 6

Steps executed: 316 Episode length: 128 Return: -312.99594922398954
INFO:tensorflow:Average training steps per second: 221.12
I0901 12:46:49.305690 140315766171648 replay_runner.py:36] Average training steps per second: 221.12
I0901 12:46:49.629889 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -282.47
INFO:tensorflow:Starting iteration 7

Steps executed: 263 Episode length: 111 Return: -221.96586787269325
INFO:tensorflow:Average training steps per second: 219.13
I0901 12:46:58.685708 140315766171648 replay_runner.py:36] Average training steps per second: 219.13
I0901 12:46:58.901896 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -249.62
INFO:tensorflow:Starting iteration 8

Steps executed: 126 Episode length: 126 Return: -247.98767749573474
INFO:tensorflow:Average training steps per second: 217.38

Steps executed: 249 Episode length: 123 Return: -208.85993170214488
I0901 12:47:08.177434 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.42
INFO:tensorflow:Starting iteration 9

Steps executed: 234 Episode length: 63 Return: -59.7251691629002264
INFO:tensorflow:Average training steps per second: 220.06
I0901 12:47:17.123384 140315766171648 replay_runner.py:36] Average training steps per second: 220.06
I0901 12:47:17.309334 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.81
INFO:tensorflow:Starting iteration 10
I0901 12:47:21.680363 140315766171648 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 221.91

Steps executed: 201 Episode length: 68 Return: -211.460003900938634
I0901 12:47:26.366969 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -249.26
INFO:tensorflow:Starting iteration 11

Steps executed: 224 Episode length: 74 Return: -245.373545040692484
INFO:tensorflow:Average training steps per second: 226.00
I0901 12:47:35.184200 140315766171648 replay_runner.py:36] Average training steps per second: 226.00
I0901 12:47:35.340884 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.92
INFO:tensorflow:Starting iteration 12

Steps executed: 231 Episode length: 61 Return: -116.293653136245854
INFO:tensorflow:Average training steps per second: 228.75
I0901 12:47:44.067234 140315766171648 replay_runner.py:36] Average training steps per second: 228.75
I0901 12:47:44.246160 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.67
INFO:tensorflow:Starting iteration 13

Steps executed: 220 Episode length: 86 Return: -236.807593261175756
INFO:tensorflow:Average training steps per second: 223.33
I0901 12:47:53.160184 140315766171648 replay_runner.py:36] Average training steps per second: 223.33
I0901 12:47:53.348482 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.35
INFO:tensorflow:Starting iteration 14

Steps executed: 137 Episode length: 137 Return: -146.14937849635453
INFO:tensorflow:Average training steps per second: 221.77

Steps executed: 249 Episode length: 112 Return: -215.60638398600946
I0901 12:48:02.452045 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.88
INFO:tensorflow:Starting iteration 15

Steps executed: 217 Episode length: 55 Return: -251.265426198550336
INFO:tensorflow:Average training steps per second: 222.59
I0901 12:48:11.142932 140315766171648 replay_runner.py:36] Average training steps per second: 222.59
I0901 12:48:11.328058 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.60
INFO:tensorflow:Starting iteration 16
I0901 12:48:15.645049 140315766171648 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 219.44
I0901 12:48:20.202510 140315766171648 replay_runner.py:36] Average training steps per second: 219.44

Steps executed: 216 Episode length: 143 Return: -498.84037531958216
INFO:tensorflow:Starting iteration 17

Steps executed: 240 Episode length: 82 Return: -440.091405358131356
INFO:tensorflow:Average training steps per second: 218.25
I0901 12:48:29.415153 140315766171648 replay_runner.py:36] Average training steps per second: 218.25
I0901 12:48:29.635586 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -562.55
INFO:tensorflow:Starting iteration 18

Steps executed: 216 Episode length: 131 Return: -298.20779656840376
INFO:tensorflow:Average training steps per second: 215.95
I0901 12:48:38.672949 140315766171648 replay_runner.py:36] Average training steps per second: 215.95
I0901 12:48:38.874236 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -449.33
INFO:tensorflow:Starting iteration 19

Steps executed: 218 Episode length: 51 Return: -389.778555503237566
INFO:tensorflow:Average training steps per second: 222.90
I0901 12:48:47.704055 140315766171648 replay_runner.py:36] Average training steps per second: 222.90
I0901 12:48:47.897509 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -465.59
INFO:tensorflow:Starting iteration 20

Steps executed: 252 Episode length: 77 Return: -466.606281094714636
INFO:tensorflow:Average training steps per second: 222.80
I0901 12:48:56.709841 140315766171648 replay_runner.py:36] Average training steps per second: 222.80
I0901 12:48:56.900396 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.81
INFO:tensorflow:Starting iteration 21

Steps executed: 210 Episode length: 75 Return: -576.075106080450536
INFO:tensorflow:Average training steps per second: 219.33
I0901 12:49:05.856833 140315766171648 replay_runner.py:36] Average training steps per second: 219.33
I0901 12:49:06.047188 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -533.16
INFO:tensorflow:Starting iteration 22

Steps executed: 245 Episode length: 57 Return: -349.598938300549636
INFO:tensorflow:Average training steps per second: 219.63
I0901 12:49:15.006153 140315766171648 replay_runner.py:36] Average training steps per second: 219.63
I0901 12:49:15.205363 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -430.12
INFO:tensorflow:Starting iteration 23

Steps executed: 226 Episode length: 64 Return: -627.340207467127626
INFO:tensorflow:Average training steps per second: 224.77
I0901 12:49:23.720048 140315766171648 replay_runner.py:36] Average training steps per second: 224.77
I0901 12:49:23.897834 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -336.82
INFO:tensorflow:Starting iteration 24

Steps executed: 251 Episode length: 57 Return: -534.234754563296326
INFO:tensorflow:Average training steps per second: 224.52
I0901 12:49:32.616998 140315766171648 replay_runner.py:36] Average training steps per second: 224.52
I0901 12:49:32.824980 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -505.72
INFO:tensorflow:Starting iteration 25

Steps executed: 202 Episode length: 69 Return: -585.491472102472636
INFO:tensorflow:Average training steps per second: 215.71
I0901 12:49:41.734131 140315766171648 replay_runner.py:36] Average training steps per second: 215.71
I0901 12:49:41.921580 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -575.27
INFO:tensorflow:Starting iteration 26

Steps executed: 208 Episode length: 83 Return: -704.912412622888236
INFO:tensorflow:Average training steps per second: 222.37
I0901 12:49:50.774279 140315766171648 replay_runner.py:36] Average training steps per second: 222.37
I0901 12:49:50.950397 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -562.44
INFO:tensorflow:Starting iteration 27

Steps executed: 237 Episode length: 92 Return: -187.952836582352466
INFO:tensorflow:Average training steps per second: 225.19
I0901 12:49:59.822933 140315766171648 replay_runner.py:36] Average training steps per second: 225.19
I0901 12:50:00.031149 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -282.77
INFO:tensorflow:Starting iteration 28

Steps executed: 243 Episode length: 64 Return: -680.429749447734536
INFO:tensorflow:Average training steps per second: 221.01
I0901 12:50:08.922972 140315766171648 replay_runner.py:36] Average training steps per second: 221.01
I0901 12:50:09.125437 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.04
INFO:tensorflow:Starting iteration 29

Steps executed: 205 Episode length: 65 Return: -684.683221568848636
INFO:tensorflow:Average training steps per second: 221.18
I0901 12:50:18.078942 140315766171648 replay_runner.py:36] Average training steps per second: 221.18

Done fixed training!Episode length: 65 Return: -684.683221568848636