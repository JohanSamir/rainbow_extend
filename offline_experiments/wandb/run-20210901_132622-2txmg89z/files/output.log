
Loaded trained dqn in lunarlander
I0901 13:26:28.194675 140460307478528 run_experiment.py:549] Creating TrainRunner ...
I0901 13:26:28.202056 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:26:28.202254 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:26:28.202373 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:26:28.202443 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:26:28.202506 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 13:26:28.202604 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:26:28.202677 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:26:28.202781 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:26:28.202843 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:26:28.202924 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 13:26:28.203054 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:26:28.203205 140460307478528 dqn_agent.py:283] 	 seed: 1630502788202012
I0901 13:26:28.205679 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:26:28.205916 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:26:28.206056 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:26:28.206191 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:26:28.206295 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:26:28.206413 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:26:28.206549 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:26:28.206674 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:26:28.206757 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:26:29.388400 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:26:29.671269 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:26:29.679248 140460307478528 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:26:29.685549 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:26:29.685681 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:26:29.685760 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:26:29.685829 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:26:29.685890 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 13:26:29.685954 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:26:29.686031 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:26:29.686127 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:26:29.686199 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:26:29.686305 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 13:26:29.686422 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:26:29.686513 140460307478528 dqn_agent.py:283] 	 seed: 1630502789685522
I0901 13:26:29.688023 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:26:29.688151 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:26:29.688245 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:26:29.688329 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:26:29.688408 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:26:29.688489 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:26:29.688572 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:26:29.688672 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:26:29.688771 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:26:29.710290 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Training fixed agent 10, please be patient, may be a while...
I0901 13:26:29.737261 140460307478528 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:26:29.737414 140460307478528 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 279.38
I0901 13:26:33.317219 140460307478528 replay_runner.py:36] Average training steps per second: 279.38
Steps executed: 244 Episode length: 112 Return: -105.15040221520891
I0901 13:26:34.090030 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.21
INFO:tensorflow:Starting iteration 1

Steps executed: 348 Episode length: 170 Return: -21.273191445420593
INFO:tensorflow:Average training steps per second: 402.65
I0901 13:26:39.964028 140460307478528 replay_runner.py:36] Average training steps per second: 402.65
I0901 13:26:40.103304 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.77
INFO:tensorflow:Starting iteration 2

Steps executed: 252 Episode length: 118 Return: -278.54065384037063
INFO:tensorflow:Average training steps per second: 365.34
I0901 13:26:45.990209 140460307478528 replay_runner.py:36] Average training steps per second: 365.34
I0901 13:26:46.105518 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.88
INFO:tensorflow:Starting iteration 3

Steps executed: 250 Episode length: 126 Return: -328.28866969950943
INFO:tensorflow:Average training steps per second: 372.56
I0901 13:26:51.890613 140460307478528 replay_runner.py:36] Average training steps per second: 372.56
I0901 13:26:52.011552 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.89
INFO:tensorflow:Starting iteration 4

Steps executed: 218 Episode length: 128 Return: -259.01082009718543
INFO:tensorflow:Average training steps per second: 386.04
I0901 13:26:57.907649 140460307478528 replay_runner.py:36] Average training steps per second: 386.04
I0901 13:26:58.004465 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -298.13
INFO:tensorflow:Starting iteration 5
I0901 13:27:01.295390 140460307478528 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 378.96

Steps executed: 212 Episode length: 212 Return: -126.72865722432333
I0901 13:27:04.039207 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.73
INFO:tensorflow:Starting iteration 6
I0901 13:27:07.210304 140460307478528 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 381.35
I0901 13:27:09.832857 140460307478528 replay_runner.py:36] Average training steps per second: 381.35

Steps executed: 230 Episode length: 230 Return: -285.99616637844153
INFO:tensorflow:Starting iteration 7

Steps executed: 232 Episode length: 138 Return: -161.55839995252213
INFO:tensorflow:Average training steps per second: 373.32
I0901 13:27:15.785328 140460307478528 replay_runner.py:36] Average training steps per second: 373.32
I0901 13:27:15.903611 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -214.17
INFO:tensorflow:Starting iteration 8

Steps executed: 312 Episode length: 137 Return: -99.325407396943923
INFO:tensorflow:Average training steps per second: 366.37
I0901 13:27:21.718436 140460307478528 replay_runner.py:36] Average training steps per second: 366.37
I0901 13:27:21.858183 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.05
INFO:tensorflow:Starting iteration 9

Steps executed: 217 Episode length: 217 Return: -219.78310070127958
INFO:tensorflow:Average training steps per second: 361.31
I0901 13:27:27.728692 140460307478528 replay_runner.py:36] Average training steps per second: 361.31
I0901 13:27:27.883248 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -219.78
INFO:tensorflow:Starting iteration 10

Steps executed: 212 Episode length: 128 Return: -366.16977513639347
INFO:tensorflow:Average training steps per second: 364.69
I0901 13:27:33.755649 140460307478528 replay_runner.py:36] Average training steps per second: 364.69
I0901 13:27:33.848953 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -395.48
INFO:tensorflow:Starting iteration 11

Steps executed: 223 Episode length: 66 Return: -325.357529724372147
INFO:tensorflow:Average training steps per second: 365.50
I0901 13:27:39.715834 140460307478528 replay_runner.py:36] Average training steps per second: 365.50
I0901 13:27:39.800996 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.20
INFO:tensorflow:Starting iteration 12

Steps executed: 387 Episode length: 195 Return: -700.37911331457277
INFO:tensorflow:Average training steps per second: 366.18
I0901 13:27:45.722311 140460307478528 replay_runner.py:36] Average training steps per second: 366.18
I0901 13:27:45.922256 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -472.79
INFO:tensorflow:Starting iteration 13

Steps executed: 260 Episode length: 83 Return: -288.649572111926277
INFO:tensorflow:Average training steps per second: 369.80
I0901 13:27:51.790105 140460307478528 replay_runner.py:36] Average training steps per second: 369.80
I0901 13:27:51.908452 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.55
INFO:tensorflow:Starting iteration 14

Steps executed: 314 Episode length: 244 Return: -427.67244388259317
INFO:tensorflow:Average training steps per second: 370.48
I0901 13:27:57.778901 140460307478528 replay_runner.py:36] Average training steps per second: 370.48
I0901 13:27:57.967927 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -497.41
INFO:tensorflow:Starting iteration 15

Steps executed: 361 Episode length: 248 Return: -437.90560708849256
INFO:tensorflow:Average training steps per second: 370.84
I0901 13:28:03.805994 140460307478528 replay_runner.py:36] Average training steps per second: 370.84
I0901 13:28:04.033079 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -222.53
INFO:tensorflow:Starting iteration 16

Steps executed: 281 Episode length: 104 Return: 27.8360463881295676
INFO:tensorflow:Average training steps per second: 380.78
I0901 13:28:09.837426 140460307478528 replay_runner.py:36] Average training steps per second: 380.78
I0901 13:28:09.995204 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.14
INFO:tensorflow:Starting iteration 17

Steps executed: 268 Episode length: 83 Return: -125.472149958664436
INFO:tensorflow:Average training steps per second: 373.37
I0901 13:28:15.936752 140460307478528 replay_runner.py:36] Average training steps per second: 373.37
I0901 13:28:16.026880 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.44
INFO:tensorflow:Starting iteration 18

Steps executed: 250 Episode length: 250 Return: -314.32569137522614
INFO:tensorflow:Average training steps per second: 372.00
I0901 13:28:21.978337 140460307478528 replay_runner.py:36] Average training steps per second: 372.00
I0901 13:28:22.126973 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.33
INFO:tensorflow:Starting iteration 19
I0901 13:28:25.373592 140460307478528 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 369.18
I0901 13:28:28.082524 140460307478528 replay_runner.py:36] Average training steps per second: 369.18

Steps executed: 233 Episode length: 56 Return: -303.319493933683724
INFO:tensorflow:Starting iteration 20
I0901 13:28:31.388375 140460307478528 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 376.22
I0901 13:28:34.046668 140460307478528 replay_runner.py:36] Average training steps per second: 376.22

Steps executed: 268 Episode length: 75 Return: -546.859859250143524
INFO:tensorflow:Starting iteration 21
I0901 13:28:37.344837 140460307478528 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 372.59
I0901 13:28:40.029072 140460307478528 replay_runner.py:36] Average training steps per second: 372.59

Steps executed: 218 Episode length: 113 Return: -796.13473449370934
INFO:tensorflow:Starting iteration 22
I0901 13:28:43.362419 140460307478528 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 371.57
I0901 13:28:46.053933 140460307478528 replay_runner.py:36] Average training steps per second: 371.57

Steps executed: 263 Episode length: 91 Return: -287.323885491690754
INFO:tensorflow:Starting iteration 23
I0901 13:28:49.400046 140460307478528 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 371.48
I0901 13:28:52.092231 140460307478528 replay_runner.py:36] Average training steps per second: 371.48

Steps executed: 213 Episode length: 106 Return: -737.43503245114414
INFO:tensorflow:Starting iteration 24

Steps executed: 70 Episode length: 70 Return: -502.4453459335233414
INFO:tensorflow:Average training steps per second: 374.89
I0901 13:28:58.090105 140460307478528 replay_runner.py:36] Average training steps per second: 374.89

Steps executed: 206 Episode length: 76 Return: -625.412016624881414
INFO:tensorflow:Starting iteration 25

Steps executed: 209 Episode length: 68 Return: -539.953116128599614
INFO:tensorflow:Average training steps per second: 369.18
I0901 13:29:04.082562 140460307478528 replay_runner.py:36] Average training steps per second: 369.18
I0901 13:29:04.174775 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -533.22
INFO:tensorflow:Starting iteration 26

Steps executed: 236 Episode length: 76 Return: -168.953711797921384
INFO:tensorflow:Average training steps per second: 366.98
I0901 13:29:10.094659 140460307478528 replay_runner.py:36] Average training steps per second: 366.98
I0901 13:29:10.173874 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.53
INFO:tensorflow:Starting iteration 27

Steps executed: 238 Episode length: 83 Return: -474.699263974310564
INFO:tensorflow:Average training steps per second: 369.31
I0901 13:29:16.005947 140460307478528 replay_runner.py:36] Average training steps per second: 369.31
I0901 13:29:16.110324 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -460.10
INFO:tensorflow:Starting iteration 28

Steps executed: 258 Episode length: 59 Return: -471.566850507914144
INFO:tensorflow:Average training steps per second: 382.01
I0901 13:29:21.868494 140460307478528 replay_runner.py:36] Average training steps per second: 382.01
I0901 13:29:22.001495 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -512.22
INFO:tensorflow:Starting iteration 29

Steps executed: 229 Episode length: 72 Return: -501.642411757754534
INFO:tensorflow:Average training steps per second: 385.04
I0901 13:29:27.722042 140460307478528 replay_runner.py:36] Average training steps per second: 385.04

Done fixed training!Episode length: 72 Return: -501.642411757754534