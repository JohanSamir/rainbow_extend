Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0828 10:28:02.920831 140618562066432 run_experiment.py:549] Creating TrainRunner ...
I0828 10:28:02.931133 140618562066432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:28:02.931437 140618562066432 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:28:02.931592 140618562066432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:28:02.931751 140618562066432 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:28:02.931854 140618562066432 dqn_agent.py:275] 	 update_period: 4
I0828 10:28:02.931925 140618562066432 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:28:02.931990 140618562066432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:28:02.932056 140618562066432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:28:02.932119 140618562066432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:28:02.932182 140618562066432 dqn_agent.py:280] 	 optimizer: adam
I0828 10:28:02.932246 140618562066432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:28:02.932331 140618562066432 dqn_agent.py:283] 	 seed: 1630146482930916
I0828 10:28:02.935207 140618562066432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:28:02.935396 140618562066432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:28:02.935555 140618562066432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:28:02.935674 140618562066432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:28:02.935740 140618562066432 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:28:02.935855 140618562066432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:28:02.935958 140618562066432 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:28:02.936028 140618562066432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:28:02.936092 140618562066432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:28:02.977077 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:03.438969 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:03.456399 140618562066432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:28:03.476712 140618562066432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:28:03.476957 140618562066432 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:28:03.477091 140618562066432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:28:03.477241 140618562066432 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:28:03.477407 140618562066432 dqn_agent.py:275] 	 update_period: 4
I0828 10:28:03.477522 140618562066432 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:28:03.477604 140618562066432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:28:03.477733 140618562066432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:28:03.477856 140618562066432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:28:03.477980 140618562066432 dqn_agent.py:280] 	 optimizer: adam
I0828 10:28:03.478097 140618562066432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:28:03.478242 140618562066432 dqn_agent.py:283] 	 seed: 1630146483476645
I0828 10:28:03.480782 140618562066432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:28:03.480942 140618562066432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:28:03.481065 140618562066432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:28:03.481202 140618562066432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:28:03.481341 140618562066432 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:28:03.481472 140618562066432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:28:03.481591 140618562066432 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:28:03.481722 140618562066432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:28:03.481853 140618562066432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:28:03.568252 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:03.594466 140618562066432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:28:03.594655 140618562066432 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.39
I0828 10:28:09.753362 140618562066432 replay_runner.py:36] Average training steps per second: 162.39
Steps executed: 246 Episode length: 54 Return: -385.5201434952383
I0828 10:28:10.984558 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -569.84
INFO:tensorflow:Starting iteration 1

Steps executed: 206 Episode length: 61 Return: -102.14154643534627
INFO:tensorflow:Average training steps per second: 228.60
I0828 10:28:19.791386 140618562066432 replay_runner.py:36] Average training steps per second: 228.60
I0828 10:28:19.917743 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.20
INFO:tensorflow:Starting iteration 2

Steps executed: 205 Episode length: 67 Return: -254.64409039964858
INFO:tensorflow:Average training steps per second: 227.54
I0828 10:28:28.613867 140618562066432 replay_runner.py:36] Average training steps per second: 227.54
I0828 10:28:28.796585 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -238.66
INFO:tensorflow:Starting iteration 3

Steps executed: 215 Episode length: 65 Return: -258.19961754655924
INFO:tensorflow:Average training steps per second: 225.51
I0828 10:28:37.656562 140618562066432 replay_runner.py:36] Average training steps per second: 225.51
I0828 10:28:37.800682 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.28
INFO:tensorflow:Starting iteration 4
I0828 10:28:42.192796 140618562066432 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 225.93

Steps executed: 230 Episode length: 66 Return: -102.53388653070746
I0828 10:28:46.784077 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.03
INFO:tensorflow:Starting iteration 5

Steps executed: 221 Episode length: 67 Return: -409.91022250777957
INFO:tensorflow:Average training steps per second: 225.20
I0828 10:28:55.602749 140618562066432 replay_runner.py:36] Average training steps per second: 225.20
I0828 10:28:55.791670 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -572.32
INFO:tensorflow:Starting iteration 6

Steps executed: 200 Episode length: 68 Return: -346.71179922420254
INFO:tensorflow:Average training steps per second: 223.29
I0828 10:29:04.593247 140618562066432 replay_runner.py:36] Average training steps per second: 223.29
I0828 10:29:04.744275 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -389.26
INFO:tensorflow:Starting iteration 7

Steps executed: 236 Episode length: 62 Return: -498.51176835645588
INFO:tensorflow:Average training steps per second: 223.16
I0828 10:29:13.635330 140618562066432 replay_runner.py:36] Average training steps per second: 223.16
I0828 10:29:13.834789 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -391.40
INFO:tensorflow:Starting iteration 8

Steps executed: 246 Episode length: 103 Return: -559.0909167444867
INFO:tensorflow:Average training steps per second: 227.68
I0828 10:29:22.610048 140618562066432 replay_runner.py:36] Average training steps per second: 227.68
I0828 10:29:22.790832 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.35
INFO:tensorflow:Starting iteration 9

Steps executed: 263 Episode length: 64 Return: -506.75921367259394
INFO:tensorflow:Average training steps per second: 227.99
I0828 10:29:31.592953 140618562066432 replay_runner.py:36] Average training steps per second: 227.99
I0828 10:29:31.827335 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -601.45
INFO:tensorflow:Starting iteration 10

Steps executed: 227 Episode length: 48 Return: -412.32483097099174
INFO:tensorflow:Average training steps per second: 219.42
I0828 10:29:40.583632 140618562066432 replay_runner.py:36] Average training steps per second: 219.42
I0828 10:29:40.774380 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -755.44
INFO:tensorflow:Starting iteration 11

Steps executed: 274 Episode length: 88 Return: -837.35019298952174
INFO:tensorflow:Average training steps per second: 224.54
I0828 10:29:49.557118 140618562066432 replay_runner.py:36] Average training steps per second: 224.54
I0828 10:29:49.791789 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -585.59
INFO:tensorflow:Starting iteration 12

Steps executed: 231 Episode length: 67 Return: -485.42478054371577
INFO:tensorflow:Average training steps per second: 222.05
I0828 10:29:58.579772 140618562066432 replay_runner.py:36] Average training steps per second: 222.05
I0828 10:29:58.772866 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -440.03
INFO:tensorflow:Starting iteration 13

Steps executed: 251 Episode length: 81 Return: -597.85942849412814
INFO:tensorflow:Average training steps per second: 224.69
I0828 10:30:07.583507 140618562066432 replay_runner.py:36] Average training steps per second: 224.69
I0828 10:30:07.782299 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -470.65
INFO:tensorflow:Starting iteration 14

Steps executed: 230 Episode length: 89 Return: -167.74105091470426
INFO:tensorflow:Average training steps per second: 221.92
I0828 10:30:16.569093 140618562066432 replay_runner.py:36] Average training steps per second: 221.92
I0828 10:30:16.698331 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.93
INFO:tensorflow:Starting iteration 15

Steps executed: 218 Episode length: 68 Return: -310.93014566474366
INFO:tensorflow:Average training steps per second: 224.06
I0828 10:30:25.298718 140618562066432 replay_runner.py:36] Average training steps per second: 224.06
I0828 10:30:25.459379 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -517.07
INFO:tensorflow:Starting iteration 16

Steps executed: 246 Episode length: 80 Return: -757.04539172433234
INFO:tensorflow:Average training steps per second: 228.01
I0828 10:30:34.074988 140618562066432 replay_runner.py:36] Average training steps per second: 228.01
I0828 10:30:34.307354 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -503.82
INFO:tensorflow:Starting iteration 17
I0828 10:30:38.544189 140618562066432 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 230.17
I0828 10:30:42.889195 140618562066432 replay_runner.py:36] Average training steps per second: 230.17

Steps executed: 237 Episode length: 51 Return: -319.79238956736253
INFO:tensorflow:Starting iteration 18

Steps executed: 217 Episode length: 84 Return: -658.26741782012026
INFO:tensorflow:Average training steps per second: 236.69
I0828 10:30:51.488200 140618562066432 replay_runner.py:36] Average training steps per second: 236.69
I0828 10:30:51.655198 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -549.12
INFO:tensorflow:Starting iteration 19

Steps executed: 222 Episode length: 78 Return: -160.40766017441646
INFO:tensorflow:Average training steps per second: 234.47
I0828 10:31:00.097185 140618562066432 replay_runner.py:36] Average training steps per second: 234.47
I0828 10:31:00.221725 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.07
INFO:tensorflow:Starting iteration 20

Steps executed: 225 Episode length: 75 Return: -456.36291050016146
INFO:tensorflow:Average training steps per second: 230.73
I0828 10:31:08.681129 140618562066432 replay_runner.py:36] Average training steps per second: 230.73
I0828 10:31:08.849537 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -552.99
INFO:tensorflow:Starting iteration 21

Steps executed: 266 Episode length: 71 Return: -433.99471430581336
INFO:tensorflow:Average training steps per second: 225.77
I0828 10:31:17.538511 140618562066432 replay_runner.py:36] Average training steps per second: 225.77
I0828 10:31:17.747614 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -440.68
INFO:tensorflow:Starting iteration 22

Steps executed: 239 Episode length: 74 Return: -458.384486118690354
INFO:tensorflow:Average training steps per second: 220.32
I0828 10:31:26.505372 140618562066432 replay_runner.py:36] Average training steps per second: 220.32
I0828 10:31:26.708840 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -438.92
INFO:tensorflow:Starting iteration 23

Steps executed: 226 Episode length: 83 Return: -603.289104987720974
INFO:tensorflow:Average training steps per second: 221.88
I0828 10:31:35.534633 140618562066432 replay_runner.py:36] Average training steps per second: 221.88
I0828 10:31:35.728360 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -504.69
INFO:tensorflow:Starting iteration 24

Steps executed: 264 Episode length: 76 Return: -635.531794502055274
INFO:tensorflow:Average training steps per second: 217.44
I0828 10:31:44.564083 140618562066432 replay_runner.py:36] Average training steps per second: 217.44
I0828 10:31:44.803796 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -748.14
INFO:tensorflow:Starting iteration 25

Steps executed: 230 Episode length: 67 Return: -129.413060492272344
INFO:tensorflow:Average training steps per second: 225.21
I0828 10:31:53.524461 140618562066432 replay_runner.py:36] Average training steps per second: 225.21
I0828 10:31:53.681167 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.88
INFO:tensorflow:Starting iteration 26

Steps executed: 244 Episode length: 53 Return: -370.297455915591974
INFO:tensorflow:Average training steps per second: 222.07
I0828 10:32:02.498316 140618562066432 replay_runner.py:36] Average training steps per second: 222.07
I0828 10:32:02.702881 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -510.56
INFO:tensorflow:Starting iteration 27

Steps executed: 263 Episode length: 81 Return: -708.872221608985874
INFO:tensorflow:Average training steps per second: 218.58
I0828 10:32:11.569686 140618562066432 replay_runner.py:36] Average training steps per second: 218.58
I0828 10:32:11.815825 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -723.39
INFO:tensorflow:Starting iteration 28

Steps executed: 270 Episode length: 71 Return: -714.378667450376854
INFO:tensorflow:Average training steps per second: 220.11
I0828 10:32:20.692889 140618562066432 replay_runner.py:36] Average training steps per second: 220.11
I0828 10:32:20.935969 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -573.30
INFO:tensorflow:Starting iteration 29

Steps executed: 220 Episode length: 81 Return: -655.399253441418854
INFO:tensorflow:Average training steps per second: 221.98
I0828 10:32:29.807925 140618562066432 replay_runner.py:36] Average training steps per second: 221.98

Done fixed training!Episode length: 81 Return: -655.399253441418854