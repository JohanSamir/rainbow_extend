Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 12:25:14.459218 140315766171648 run_experiment.py:549] Creating TrainRunner ...
I0901 12:25:14.471372 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:25:14.471648 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:25:14.471776 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:25:14.471888 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:25:14.471977 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 12:25:14.472068 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:25:14.472164 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:25:14.472266 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:25:14.472360 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:25:14.472457 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 12:25:14.472542 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:25:14.472634 140315766171648 dqn_agent.py:283] 	 seed: 1630499114471300
I0901 12:25:14.475746 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:25:14.475973 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:25:14.476091 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:25:14.476211 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:25:14.476306 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:25:14.476397 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:25:14.476480 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:25:14.476559 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:25:14.476640 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:25:14.699059 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:15.155086 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:15.168519 140315766171648 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:25:15.177387 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:25:15.177615 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:25:15.177747 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:25:15.177867 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:25:15.177967 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 12:25:15.178070 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:25:15.178210 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:25:15.178351 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:25:15.178464 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:25:15.178612 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 12:25:15.178729 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:25:15.178916 140315766171648 dqn_agent.py:283] 	 seed: 1630499115177340
I0901 12:25:15.182035 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:25:15.182241 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:25:15.182370 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:25:15.182490 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:25:15.182606 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:25:15.182740 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:25:15.182853 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:25:15.182952 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:25:15.183049 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:25:15.212206 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:15.232150 140315766171648 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:25:15.232427 140315766171648 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 160.08
I0901 12:25:21.479774 140315766171648 replay_runner.py:36] Average training steps per second: 160.08
Steps executed: 259 Episode length: 148 Return: -318.00768362766496
I0901 12:25:22.741121 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.63
INFO:tensorflow:Starting iteration 1

Steps executed: 219 Episode length: 107 Return: -106.38091141381511
INFO:tensorflow:Average training steps per second: 220.68
I0901 12:25:31.726557 140315766171648 replay_runner.py:36] Average training steps per second: 220.68
I0901 12:25:31.918134 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.43
INFO:tensorflow:Starting iteration 2

Steps executed: 245 Episode length: 84 Return: -710.773619166393111
INFO:tensorflow:Average training steps per second: 218.58
I0901 12:25:41.049395 140315766171648 replay_runner.py:36] Average training steps per second: 218.58
I0901 12:25:41.273320 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -636.68
INFO:tensorflow:Starting iteration 3

Steps executed: 267 Episode length: 133 Return: -197.14683224824208
INFO:tensorflow:Average training steps per second: 213.01
I0901 12:25:50.422732 140315766171648 replay_runner.py:36] Average training steps per second: 213.01
I0901 12:25:50.673058 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.77
INFO:tensorflow:Starting iteration 4

Steps executed: 252 Episode length: 100 Return: -252.50101735355383
INFO:tensorflow:Average training steps per second: 213.24
I0901 12:25:59.752584 140315766171648 replay_runner.py:36] Average training steps per second: 213.24
I0901 12:25:59.992626 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -358.71
INFO:tensorflow:Starting iteration 5

Steps executed: 334 Episode length: 201 Return: -550.74390733876333
INFO:tensorflow:Average training steps per second: 207.88
I0901 12:26:09.305383 140315766171648 replay_runner.py:36] Average training steps per second: 207.88
I0901 12:26:09.628936 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -517.89
INFO:tensorflow:Starting iteration 6

Steps executed: 251 Episode length: 132 Return: -397.78273737917173
INFO:tensorflow:Average training steps per second: 211.06
I0901 12:26:18.656891 140315766171648 replay_runner.py:36] Average training steps per second: 211.06
I0901 12:26:18.898858 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -426.58
INFO:tensorflow:Starting iteration 7

Steps executed: 215 Episode length: 215 Return: -291.77962839860493
INFO:tensorflow:Average training steps per second: 212.78
I0901 12:26:27.962973 140315766171648 replay_runner.py:36] Average training steps per second: 212.78
I0901 12:26:28.198710 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -291.78
INFO:tensorflow:Starting iteration 8

Steps executed: 232 Episode length: 135 Return: -289.25101775004263
INFO:tensorflow:Average training steps per second: 212.28
I0901 12:26:37.425967 140315766171648 replay_runner.py:36] Average training steps per second: 212.28
I0901 12:26:37.660468 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.92
INFO:tensorflow:Starting iteration 9

Steps executed: 298 Episode length: 169 Return: -287.61170391964754
INFO:tensorflow:Average training steps per second: 210.30
I0901 12:26:46.899641 140315766171648 replay_runner.py:36] Average training steps per second: 210.30
I0901 12:26:47.169785 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.80
INFO:tensorflow:Starting iteration 10

Steps executed: 255 Episode length: 111 Return: -395.68723324220497
INFO:tensorflow:Average training steps per second: 198.84
I0901 12:26:56.945338 140315766171648 replay_runner.py:36] Average training steps per second: 198.84
I0901 12:26:57.183064 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -506.26
INFO:tensorflow:Starting iteration 11

Steps executed: 143 Episode length: 143 Return: -175.35511406599414
INFO:tensorflow:Average training steps per second: 214.62

Steps executed: 289 Episode length: 146 Return: -592.14403017145014
I0901 12:27:06.595298 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -383.75
INFO:tensorflow:Starting iteration 12

Steps executed: 362 Episode length: 170 Return: -378.60233499694857
INFO:tensorflow:Average training steps per second: 212.95
I0901 12:27:15.697273 140315766171648 replay_runner.py:36] Average training steps per second: 212.95
I0901 12:27:16.035555 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -418.91
INFO:tensorflow:Starting iteration 13

Steps executed: 218 Episode length: 218 Return: -90.181577784451117
INFO:tensorflow:Average training steps per second: 210.96
I0901 12:27:25.239259 140315766171648 replay_runner.py:36] Average training steps per second: 210.96
I0901 12:27:25.484003 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.18
INFO:tensorflow:Starting iteration 14

Steps executed: 149 Episode length: 149 Return: -485.68218320881287
INFO:tensorflow:Average training steps per second: 215.76

Steps executed: 308 Episode length: 159 Return: -316.15605902667557
I0901 12:27:34.785938 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.92
INFO:tensorflow:Starting iteration 15

Steps executed: 307 Episode length: 165 Return: -135.53634848923542
INFO:tensorflow:Average training steps per second: 213.02
I0901 12:27:43.919408 140315766171648 replay_runner.py:36] Average training steps per second: 213.02
I0901 12:27:44.220109 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.37
INFO:tensorflow:Starting iteration 16

Steps executed: 230 Episode length: 138 Return: -451.40083926937872
INFO:tensorflow:Average training steps per second: 225.66
I0901 12:27:53.066181 140315766171648 replay_runner.py:36] Average training steps per second: 225.66
I0901 12:27:53.272074 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -458.57
INFO:tensorflow:Starting iteration 17

Steps executed: 216 Episode length: 216 Return: -300.70578635424994
INFO:tensorflow:Average training steps per second: 222.71
I0901 12:28:02.188097 140315766171648 replay_runner.py:36] Average training steps per second: 222.71
I0901 12:28:02.402789 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.71
INFO:tensorflow:Starting iteration 18

Steps executed: 287 Episode length: 287 Return: -289.00610161417184
INFO:tensorflow:Average training steps per second: 221.44
I0901 12:28:11.228480 140315766171648 replay_runner.py:36] Average training steps per second: 221.44
I0901 12:28:11.604125 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.01
INFO:tensorflow:Starting iteration 19
I0901 12:28:16.009643 140315766171648 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 229.28
I0901 12:28:20.371685 140315766171648 replay_runner.py:36] Average training steps per second: 229.28

Steps executed: 290 Episode length: 184 Return: -318.33102112582674
INFO:tensorflow:Starting iteration 20

Steps executed: 240 Episode length: 86 Return: -269.042413677508756
INFO:tensorflow:Average training steps per second: 228.25
I0901 12:28:29.139251 140315766171648 replay_runner.py:36] Average training steps per second: 228.25
I0901 12:28:29.327007 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.02
INFO:tensorflow:Starting iteration 21

Steps executed: 220 Episode length: 119 Return: -447.28138011532011
INFO:tensorflow:Average training steps per second: 223.17
I0901 12:28:38.098454 140315766171648 replay_runner.py:36] Average training steps per second: 223.17
I0901 12:28:38.269082 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.99
INFO:tensorflow:Starting iteration 22

Steps executed: 344 Episode length: 195 Return: -347.67029639675081
INFO:tensorflow:Average training steps per second: 220.41
I0901 12:28:47.203208 140315766171648 replay_runner.py:36] Average training steps per second: 220.41
I0901 12:28:47.517134 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -362.18
INFO:tensorflow:Starting iteration 23

Steps executed: 278 Episode length: 150 Return: -31.711800894056511
INFO:tensorflow:Average training steps per second: 219.79
I0901 12:28:56.274843 140315766171648 replay_runner.py:36] Average training steps per second: 219.79
I0901 12:28:56.504083 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.72
INFO:tensorflow:Starting iteration 24

Steps executed: 231 Episode length: 93 Return: -115.157086931805751
INFO:tensorflow:Average training steps per second: 216.85
I0901 12:29:05.509810 140315766171648 replay_runner.py:36] Average training steps per second: 216.85
I0901 12:29:05.716720 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.72
INFO:tensorflow:Starting iteration 25

Steps executed: 328 Episode length: 208 Return: -166.62597893303386
INFO:tensorflow:Average training steps per second: 217.49
I0901 12:29:14.761405 140315766171648 replay_runner.py:36] Average training steps per second: 217.49
I0901 12:29:15.052445 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.27
INFO:tensorflow:Starting iteration 26

Steps executed: 261 Episode length: 99 Return: -318.775756174022476
INFO:tensorflow:Average training steps per second: 215.91
I0901 12:29:23.983696 140315766171648 replay_runner.py:36] Average training steps per second: 215.91
I0901 12:29:24.205625 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -384.69
INFO:tensorflow:Starting iteration 27

Steps executed: 207 Episode length: 103 Return: -509.14551619544056
INFO:tensorflow:Average training steps per second: 215.77
I0901 12:29:33.229081 140315766171648 replay_runner.py:36] Average training steps per second: 215.77
I0901 12:29:33.411219 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -523.41
INFO:tensorflow:Starting iteration 28

Steps executed: 201 Episode length: 76 Return: -447.929374569600556
INFO:tensorflow:Average training steps per second: 223.05
I0901 12:29:42.278455 140315766171648 replay_runner.py:36] Average training steps per second: 223.05
I0901 12:29:42.438725 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -453.25
INFO:tensorflow:Starting iteration 29

Steps executed: 435 Episode length: 267 Return: -5.5914536925109676
INFO:tensorflow:Average training steps per second: 223.73
I0901 12:29:51.239482 140315766171648 replay_runner.py:36] Average training steps per second: 223.73

Done fixed training!Episode length: 267 Return: -5.5914536925109676