I0902 18:14:08.759432 140216164177920 run_experiment.py:549] Creating TrainRunner ...
I0902 18:14:08.765652 140216164177920 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:14:08.765775 140216164177920 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:14:08.765858 140216164177920 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:14:08.765918 140216164177920 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:14:08.765974 140216164177920 dqn_agent.py:275] 	 update_period: 4
I0902 18:14:08.766049 140216164177920 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:14:08.766117 140216164177920 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:14:08.766210 140216164177920 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:14:08.766305 140216164177920 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:14:08.766373 140216164177920 dqn_agent.py:280] 	 optimizer: adam
I0902 18:14:08.766447 140216164177920 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:14:08.766523 140216164177920 dqn_agent.py:283] 	 seed: 1630606448765622
I0902 18:14:08.769090 140216164177920 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:14:08.769297 140216164177920 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:14:08.769454 140216164177920 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:14:08.769601 140216164177920 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:14:08.769749 140216164177920 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:14:08.769919 140216164177920 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:14:08.770030 140216164177920 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:14:08.770139 140216164177920 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:14:08.770247 140216164177920 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:14:08.794739 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.003125
I0902 18:14:09.058829 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.003125
I0902 18:14:09.067800 140216164177920 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:14:09.075573 140216164177920 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:14:09.075716 140216164177920 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:14:09.075798 140216164177920 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:14:09.075863 140216164177920 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:14:09.075920 140216164177920 dqn_agent.py:275] 	 update_period: 4
I0902 18:14:09.075997 140216164177920 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:14:09.076096 140216164177920 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:14:09.076168 140216164177920 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:14:09.076240 140216164177920 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:14:09.076321 140216164177920 dqn_agent.py:280] 	 optimizer: adam
I0902 18:14:09.076391 140216164177920 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:14:09.076474 140216164177920 dqn_agent.py:283] 	 seed: 1630606449075541
I0902 18:14:09.077927 140216164177920 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:14:09.078057 140216164177920 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:14:09.078134 140216164177920 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:14:09.078197 140216164177920 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:14:09.078256 140216164177920 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:14:09.078344 140216164177920 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:14:09.078416 140216164177920 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:14:09.078470 140216164177920 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:14:09.078527 140216164177920 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:14:09.102122 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.003125
I0902 18:14:09.117946 140216164177920 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:14:09.118120 140216164177920 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 256.02
I0902 18:14:13.024262 140216164177920 replay_runner.py:36] Average training steps per second: 256.02
I0902 18:14:13.896336 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -295.21
Steps executed: 244 Episode length: 138 Return: -376.51597601981088
INFO:tensorflow:Starting iteration 1
I0902 18:14:17.315381 140216164177920 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 341.39

Steps executed: 298 Episode length: 123 Return: -192.98350495159409
I0902 18:14:20.445207 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.36
INFO:tensorflow:Starting iteration 2

Steps executed: 241 Episode length: 118 Return: -248.13161646070189
INFO:tensorflow:Average training steps per second: 336.24
I0902 18:14:26.862998 140216164177920 replay_runner.py:36] Average training steps per second: 336.24
I0902 18:14:27.007748 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.97
INFO:tensorflow:Starting iteration 3
I0902 18:14:30.444545 140216164177920 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 339.98
I0902 18:14:33.386237 140216164177920 replay_runner.py:36] Average training steps per second: 339.98

Steps executed: 237 Episode length: 139 Return: 52.4977420873293689
INFO:tensorflow:Starting iteration 4

Steps executed: 301 Episode length: 128 Return: -165.38778462021293
INFO:tensorflow:Average training steps per second: 346.47
I0902 18:14:39.861393 140216164177920 replay_runner.py:36] Average training steps per second: 346.47
I0902 18:14:40.057566 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.17
INFO:tensorflow:Starting iteration 5
I0902 18:14:43.507707 140216164177920 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 346.55

Steps executed: 480 Episode length: 299 Return: -282.07494947568843
I0902 18:14:46.754233 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.11
INFO:tensorflow:Starting iteration 6
I0902 18:14:50.185502 140216164177920 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 337.31

Steps executed: 1000 Episode length: 1000 Return: -17.465124980568167
I0902 18:14:55.202297 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -17.47
INFO:tensorflow:Starting iteration 7
I0902 18:14:58.587983 140216164177920 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 346.78
I0902 18:15:01.471971 140216164177920 replay_runner.py:36] Average training steps per second: 346.78

Steps executed: 724 Episode length: 724 Return: -2916.960129732670367
INFO:tensorflow:Starting iteration 8

Steps executed: 346 Episode length: 346 Return: -688.4570173309321367
INFO:tensorflow:Average training steps per second: 332.80
I0902 18:15:08.820589 140216164177920 replay_runner.py:36] Average training steps per second: 332.80
I0902 18:15:09.112359 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -688.46
INFO:tensorflow:Starting iteration 9

Steps executed: 273 Episode length: 273 Return: -242.9701989422819767
INFO:tensorflow:Average training steps per second: 319.67
I0902 18:15:15.532625 140216164177920 replay_runner.py:36] Average training steps per second: 319.67
I0902 18:15:15.753903 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.97
INFO:tensorflow:Starting iteration 10

Steps executed: 110 Episode length: 110 Return: -565.2960295390526767
INFO:tensorflow:Average training steps per second: 318.65
I0902 18:15:22.062148 140216164177920 replay_runner.py:36] Average training steps per second: 318.65

Steps executed: 641 Episode length: 531 Return: -411.0290721058286767
INFO:tensorflow:Starting iteration 11

Steps executed: 611 Episode length: 611 Return: -219.1203079743549767
INFO:tensorflow:Average training steps per second: 328.48
I0902 18:15:29.099265 140216164177920 replay_runner.py:36] Average training steps per second: 328.48
I0902 18:15:29.826230 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -219.12
INFO:tensorflow:Starting iteration 12
I0902 18:15:33.070783 140216164177920 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 328.18

Steps executed: 547 Episode length: 547 Return: -249.1472626464340367
I0902 18:15:36.923327 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -249.15
INFO:tensorflow:Starting iteration 13

Steps executed: 321 Episode length: 321 Return: -312.2713039257012667
INFO:tensorflow:Average training steps per second: 326.14
I0902 18:15:43.215668 140216164177920 replay_runner.py:36] Average training steps per second: 326.14
I0902 18:15:43.492834 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -312.27
INFO:tensorflow:Starting iteration 14
I0902 18:15:46.874804 140216164177920 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 353.25

Steps executed: 1000 Episode length: 1000 Return: -127.69256000028666
I0902 18:15:52.092406 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.69
INFO:tensorflow:Starting iteration 15
I0902 18:15:55.427264 140216164177920 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 348.09

Steps executed: 1000 Episode length: 1000 Return: -130.24611922156964
I0902 18:15:59.854402 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.25
INFO:tensorflow:Starting iteration 16

Steps executed: 60 Episode length: 60 Return: -214.590669043627326964
INFO:tensorflow:Average training steps per second: 330.66

Steps executed: 1060 Episode length: 1000 Return: -102.49632563253152
I0902 18:16:08.122772 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.54
INFO:tensorflow:Starting iteration 17
I0902 18:16:11.461450 140216164177920 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 334.09

Steps executed: 866 Episode length: 866 Return: -289.5294782011232552
I0902 18:16:16.151550 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.53
INFO:tensorflow:Starting iteration 18

Steps executed: 232 Episode length: 232 Return: -206.0104204162188652
INFO:tensorflow:Average training steps per second: 360.21
I0902 18:16:22.348430 140216164177920 replay_runner.py:36] Average training steps per second: 360.21
I0902 18:16:22.516988 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.01
INFO:tensorflow:Starting iteration 19
I0902 18:16:25.961930 140216164177920 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 359.97

Steps executed: 880 Episode length: 880 Return: -361.6527612360282652
I0902 18:16:30.159799 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.65
INFO:tensorflow:Starting iteration 20
I0902 18:16:33.703667 140216164177920 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 372.08

Steps executed: 622 Episode length: 622 Return: -101.6510317504358952
I0902 18:16:37.385980 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.65
INFO:tensorflow:Starting iteration 21

Steps executed: 294 Episode length: 140 Return: -434.5212590486781252
INFO:tensorflow:Average training steps per second: 350.26
I0902 18:16:43.718495 140216164177920 replay_runner.py:36] Average training steps per second: 350.26
I0902 18:16:43.895617 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.42
INFO:tensorflow:Starting iteration 22

Steps executed: 303 Episode length: 303 Return: -342.7196010010211552
INFO:tensorflow:Average training steps per second: 338.77
I0902 18:16:50.252513 140216164177920 replay_runner.py:36] Average training steps per second: 338.77
I0902 18:16:50.537025 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.72
INFO:tensorflow:Starting iteration 23

Steps executed: 347 Episode length: 235 Return: -9.053400627556215552
INFO:tensorflow:Average training steps per second: 328.61
I0902 18:16:56.939284 140216164177920 replay_runner.py:36] Average training steps per second: 328.61
I0902 18:16:57.184529 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -44.46
INFO:tensorflow:Starting iteration 24

Steps executed: 302 Episode length: 152 Return: -164.3547914207915452
INFO:tensorflow:Average training steps per second: 335.58
I0902 18:17:03.509073 140216164177920 replay_runner.py:36] Average training steps per second: 335.58
I0902 18:17:03.683531 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -247.42
INFO:tensorflow:Starting iteration 25

Steps executed: 338 Episode length: 338 Return: -377.0548973427584752
INFO:tensorflow:Average training steps per second: 342.65
I0902 18:17:10.025135 140216164177920 replay_runner.py:36] Average training steps per second: 342.65
I0902 18:17:10.435506 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.05
INFO:tensorflow:Starting iteration 26

Steps executed: 110 Episode length: 110 Return: -288.4564294139001452
INFO:tensorflow:Average training steps per second: 343.74
I0902 18:17:16.775646 140216164177920 replay_runner.py:36] Average training steps per second: 343.74

Steps executed: 293 Episode length: 183 Return: -200.8126032374542852
INFO:tensorflow:Starting iteration 27

Steps executed: 249 Episode length: 127 Return: -401.6810720510548852
INFO:tensorflow:Average training steps per second: 354.11
I0902 18:17:23.150174 140216164177920 replay_runner.py:36] Average training steps per second: 354.11
I0902 18:17:23.297562 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -595.96
INFO:tensorflow:Starting iteration 28

Steps executed: 294 Episode length: 154 Return: -1.388700087004153352
INFO:tensorflow:Average training steps per second: 351.65
I0902 18:17:29.569013 140216164177920 replay_runner.py:36] Average training steps per second: 351.65
I0902 18:17:29.750933 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.87
INFO:tensorflow:Starting iteration 29

Steps executed: 394 Episode length: 269 Return: -319.6507100952671352
INFO:tensorflow:Average training steps per second: 338.65
I0902 18:17:36.006680 140216164177920 replay_runner.py:36] Average training steps per second: 338.65

Done fixed training!Episode length: 269 Return: -319.6507100952671352