Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0901 12:29:50.003242 140298343233536 run_experiment.py:549] Creating TrainRunner ...
I0901 12:29:50.014621 140298343233536 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:29:50.014847 140298343233536 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:29:50.014935 140298343233536 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:29:50.014999 140298343233536 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:29:50.015067 140298343233536 dqn_agent.py:275] 	 update_period: 4
I0901 12:29:50.015122 140298343233536 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:29:50.015211 140298343233536 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:29:50.015326 140298343233536 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:29:50.015417 140298343233536 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:29:50.015466 140298343233536 dqn_agent.py:280] 	 optimizer: adam
I0901 12:29:50.015554 140298343233536 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:29:50.015640 140298343233536 dqn_agent.py:283] 	 seed: 1630499390014574
I0901 12:29:50.018839 140298343233536 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:29:50.019170 140298343233536 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:29:50.019411 140298343233536 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:29:50.019745 140298343233536 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:29:50.019863 140298343233536 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:29:50.020083 140298343233536 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:29:50.020184 140298343233536 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:29:50.020419 140298343233536 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:29:50.020563 140298343233536 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:29:50.222532 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:29:50.648915 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:29:50.663005 140298343233536 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:29:50.671421 140298343233536 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:29:50.671661 140298343233536 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:29:50.671779 140298343233536 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:29:50.671864 140298343233536 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:29:50.671972 140298343233536 dqn_agent.py:275] 	 update_period: 4
I0901 12:29:50.672073 140298343233536 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:29:50.672174 140298343233536 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:29:50.672317 140298343233536 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:29:50.672425 140298343233536 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:29:50.672516 140298343233536 dqn_agent.py:280] 	 optimizer: adam
I0901 12:29:50.672630 140298343233536 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:29:50.672760 140298343233536 dqn_agent.py:283] 	 seed: 1630499390671356
I0901 12:29:50.675348 140298343233536 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:29:50.675557 140298343233536 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:29:50.675810 140298343233536 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:29:50.676074 140298343233536 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:29:50.676214 140298343233536 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:29:50.676342 140298343233536 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:29:50.676425 140298343233536 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:29:50.676560 140298343233536 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:29:50.676699 140298343233536 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:29:50.714417 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:29:50.736335 140298343233536 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:29:50.736762 140298343233536 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 160.16
I0901 12:29:56.981003 140298343233536 replay_runner.py:36] Average training steps per second: 160.16
Steps executed: 234 Episode length: 82 Return: -420.18375114670533
I0901 12:29:58.258279 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -601.85
INFO:tensorflow:Starting iteration 1

Steps executed: 335 Episode length: 190 Return: -305.12779579151515
INFO:tensorflow:Average training steps per second: 222.48
I0901 12:30:07.114816 140298343233536 replay_runner.py:36] Average training steps per second: 222.48
I0901 12:30:07.427959 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.92
INFO:tensorflow:Starting iteration 2

Steps executed: 285 Episode length: 160 Return: -57.970184190918535
INFO:tensorflow:Average training steps per second: 225.67
I0901 12:30:16.137018 140298343233536 replay_runner.py:36] Average training steps per second: 225.67
I0901 12:30:16.406289 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.92
INFO:tensorflow:Starting iteration 3

Steps executed: 295 Episode length: 106 Return: -23.1473598439107357
INFO:tensorflow:Average training steps per second: 215.27
I0901 12:30:25.272165 140298343233536 replay_runner.py:36] Average training steps per second: 215.27
I0901 12:30:25.531035 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.60
INFO:tensorflow:Starting iteration 4

Steps executed: 205 Episode length: 128 Return: -331.830218329974347
INFO:tensorflow:Average training steps per second: 219.32
I0901 12:30:34.405321 140298343233536 replay_runner.py:36] Average training steps per second: 219.32
I0901 12:30:34.603894 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -524.80
INFO:tensorflow:Starting iteration 5

Steps executed: 114 Episode length: 114 Return: -269.190708782150147
INFO:tensorflow:Average training steps per second: 220.65
I0901 12:30:43.553335 140298343233536 replay_runner.py:36] Average training steps per second: 220.65

Steps executed: 269 Episode length: 155 Return: -34.6345188118530147
INFO:tensorflow:Starting iteration 6

Steps executed: 241 Episode length: 101 Return: -229.460342811000437
INFO:tensorflow:Average training steps per second: 230.28
I0901 12:30:52.521759 140298343233536 replay_runner.py:36] Average training steps per second: 230.28
I0901 12:30:52.725871 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.80
INFO:tensorflow:Starting iteration 7

Steps executed: 269 Episode length: 77 Return: -297.0172241133663857
INFO:tensorflow:Average training steps per second: 232.82
I0901 12:31:01.322762 140298343233536 replay_runner.py:36] Average training steps per second: 232.82
I0901 12:31:01.556182 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.86
INFO:tensorflow:Starting iteration 8

Steps executed: 210 Episode length: 121 Return: -213.450543261438387
INFO:tensorflow:Average training steps per second: 225.36
I0901 12:31:10.206212 140298343233536 replay_runner.py:36] Average training steps per second: 225.36
I0901 12:31:10.409555 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.18
INFO:tensorflow:Starting iteration 9

Steps executed: 251 Episode length: 108 Return: -95.8369369788567187
INFO:tensorflow:Average training steps per second: 226.47
I0901 12:31:19.251250 140298343233536 replay_runner.py:36] Average training steps per second: 226.47
I0901 12:31:19.448282 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.63
INFO:tensorflow:Starting iteration 10
I0901 12:31:23.718286 140298343233536 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 232.20

Steps executed: 231 Episode length: 99 Return: -205.0938337289936787
I0901 12:31:28.222917 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.96
INFO:tensorflow:Starting iteration 11

Steps executed: 206 Episode length: 124 Return: -348.762350335817257
INFO:tensorflow:Average training steps per second: 232.37
I0901 12:31:36.718763 140298343233536 replay_runner.py:36] Average training steps per second: 232.37
I0901 12:31:36.893104 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.94
INFO:tensorflow:Starting iteration 12
I0901 12:31:41.056007 140298343233536 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 232.88

Steps executed: 1000 Episode length: 1000 Return: -1.4877338319242028
I0901 12:31:48.024626 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -1.49
INFO:tensorflow:Starting iteration 13

Steps executed: 248 Episode length: 81 Return: -274.67801155250158028
INFO:tensorflow:Average training steps per second: 212.45
I0901 12:31:57.095108 140298343233536 replay_runner.py:36] Average training steps per second: 212.45
I0901 12:31:57.264138 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.65
INFO:tensorflow:Starting iteration 14
I0901 12:32:01.608276 140298343233536 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 217.61

Steps executed: 217 Episode length: 81 Return: -181.60743763807466028
I0901 12:32:06.365671 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.27
INFO:tensorflow:Starting iteration 15

Steps executed: 296 Episode length: 136 Return: -70.34145325176834028
INFO:tensorflow:Average training steps per second: 217.23
I0901 12:32:15.261489 140298343233536 replay_runner.py:36] Average training steps per second: 217.23
I0901 12:32:15.508264 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.72
INFO:tensorflow:Starting iteration 16

Steps executed: 211 Episode length: 84 Return: -179.02763941466462628
INFO:tensorflow:Average training steps per second: 217.97
I0901 12:32:24.443757 140298343233536 replay_runner.py:36] Average training steps per second: 217.97
I0901 12:32:24.614701 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.07
INFO:tensorflow:Starting iteration 17

Steps executed: 351 Episode length: 183 Return: -34.10047405174937628
INFO:tensorflow:Average training steps per second: 220.62
I0901 12:32:33.551361 140298343233536 replay_runner.py:36] Average training steps per second: 220.62
I0901 12:32:33.930823 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.22
INFO:tensorflow:Starting iteration 18

Steps executed: 231 Episode length: 88 Return: -499.25267240840575628
INFO:tensorflow:Average training steps per second: 215.24
I0901 12:32:42.877543 140298343233536 replay_runner.py:36] Average training steps per second: 215.24
I0901 12:32:43.060561 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -393.30
INFO:tensorflow:Starting iteration 19
I0901 12:32:47.289215 140298343233536 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 212.99

Steps executed: 247 Episode length: 74 Return: -326.48606208038456628
I0901 12:32:52.195761 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.19
INFO:tensorflow:Starting iteration 20

Steps executed: 234 Episode length: 95 Return: -344.93098049721874628
INFO:tensorflow:Average training steps per second: 214.05
I0901 12:33:00.860790 140298343233536 replay_runner.py:36] Average training steps per second: 214.05
I0901 12:33:01.066839 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -330.59
INFO:tensorflow:Starting iteration 21
I0901 12:33:05.387705 140298343233536 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 216.56

Steps executed: 277 Episode length: 124 Return: -241.7939196072284728
I0901 12:33:10.264928 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -347.32
INFO:tensorflow:Starting iteration 22

Steps executed: 285 Episode length: 285 Return: -344.1926604607633628
INFO:tensorflow:Average training steps per second: 211.71
I0901 12:33:19.328603 140298343233536 replay_runner.py:36] Average training steps per second: 211.71
I0901 12:33:19.648426 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.19
INFO:tensorflow:Starting iteration 23

Steps executed: 252 Episode length: 56 Return: -447.44657023339965628
INFO:tensorflow:Average training steps per second: 218.23
I0901 12:33:28.474998 140298343233536 replay_runner.py:36] Average training steps per second: 218.23
I0901 12:33:28.706075 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -535.17
INFO:tensorflow:Starting iteration 24

Steps executed: 279 Episode length: 150 Return: -486.3111049211870528
INFO:tensorflow:Average training steps per second: 218.47
I0901 12:33:37.694474 140298343233536 replay_runner.py:36] Average training steps per second: 218.47
I0901 12:33:37.975989 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -438.57
INFO:tensorflow:Starting iteration 25

Steps executed: 296 Episode length: 99 Return: -404.78291448023847528
INFO:tensorflow:Average training steps per second: 221.23
I0901 12:33:46.814467 140298343233536 replay_runner.py:36] Average training steps per second: 221.23
I0901 12:33:47.118083 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -389.91
INFO:tensorflow:Starting iteration 26

Steps executed: 287 Episode length: 97 Return: -254.23127302862588528
INFO:tensorflow:Average training steps per second: 227.85
I0901 12:33:55.852330 140298343233536 replay_runner.py:36] Average training steps per second: 227.85
I0901 12:33:56.057790 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.52
INFO:tensorflow:Starting iteration 27

Steps executed: 292 Episode length: 292 Return: -324.9415752036257528
INFO:tensorflow:Average training steps per second: 223.31
I0901 12:34:04.796861 140298343233536 replay_runner.py:36] Average training steps per second: 223.31
I0901 12:34:05.194489 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -324.94
INFO:tensorflow:Starting iteration 28

Steps executed: 164 Episode length: 55 Return: -143.08925904935808528
INFO:tensorflow:Average training steps per second: 217.90
I0901 12:34:14.109072 140298343233536 replay_runner.py:36] Average training steps per second: 217.90

Steps executed: 265 Episode length: 101 Return: -603.5444114544655528
INFO:tensorflow:Starting iteration 29

Steps executed: 227 Episode length: 95 Return: -679.01474014286515528
INFO:tensorflow:Average training steps per second: 216.72
I0901 12:34:23.282492 140298343233536 replay_runner.py:36] Average training steps per second: 216.72

Done fixed training!Episode length: 95 Return: -679.01474014286515528