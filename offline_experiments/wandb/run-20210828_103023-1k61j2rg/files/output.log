Loaded trained dqn in cartpole
Training fixed agent 6, please be patient, may be a while...
I0828 10:30:30.002004 140290573805568 run_experiment.py:549] Creating TrainRunner ...
I0828 10:30:30.011711 140290573805568 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:30:30.011936 140290573805568 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:30:30.012073 140290573805568 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:30:30.012186 140290573805568 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:30:30.012252 140290573805568 dqn_agent.py:275] 	 update_period: 4
I0828 10:30:30.012438 140290573805568 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:30:30.012563 140290573805568 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:30:30.012681 140290573805568 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:30:30.012767 140290573805568 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:30:30.012897 140290573805568 dqn_agent.py:280] 	 optimizer: adam
I0828 10:30:30.013052 140290573805568 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:30:30.013181 140290573805568 dqn_agent.py:283] 	 seed: 1630146630011656
I0828 10:30:30.016619 140290573805568 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:30:30.016876 140290573805568 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0828 10:30:30.017030 140290573805568 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:30:30.017115 140290573805568 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:30:30.017223 140290573805568 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:30:30.017330 140290573805568 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:30:30.017444 140290573805568 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:30:30.017513 140290573805568 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:30:30.017603 140290573805568 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:30:30.058500 140290573805568 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:30:30.618205 140290573805568 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:30:30.633482 140290573805568 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:30:30.642848 140290573805568 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:30:30.643161 140290573805568 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:30:30.643351 140290573805568 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:30:30.643547 140290573805568 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:30:30.643782 140290573805568 dqn_agent.py:275] 	 update_period: 4
I0828 10:30:30.643907 140290573805568 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:30:30.643993 140290573805568 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:30:30.644087 140290573805568 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:30:30.644265 140290573805568 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:30:30.644421 140290573805568 dqn_agent.py:280] 	 optimizer: adam
I0828 10:30:30.644525 140290573805568 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:30:30.644656 140290573805568 dqn_agent.py:283] 	 seed: 1630146630642797
I0828 10:30:30.647732 140290573805568 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:30:30.647903 140290573805568 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0828 10:30:30.648008 140290573805568 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:30:30.648085 140290573805568 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:30:30.648180 140290573805568 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:30:30.648245 140290573805568 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:30:30.648332 140290573805568 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:30:30.648429 140290573805568 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:30:30.648625 140290573805568 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:30:30.681393 140290573805568 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:30:30.703992 140290573805568 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:30:30.704400 140290573805568 replay_runner.py:41] Starting iteration 0
Steps executed: 201 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 143.94
I0828 10:30:37.651873 140290573805568 replay_runner.py:36] Average training steps per second: 143.94
I0828 10:30:38.793578 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.57
INFO:tensorflow:Starting iteration 1

Steps executed: 202 Episode length: 21 Return: 21.0
INFO:tensorflow:Average training steps per second: 199.41
I0828 10:30:44.000791 140290573805568 replay_runner.py:36] Average training steps per second: 199.41
I0828 10:30:44.143420 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 16.83
INFO:tensorflow:Starting iteration 2

Steps executed: 223 Episode length: 24 Return: 24.0
INFO:tensorflow:Average training steps per second: 196.26
I0828 10:30:49.490230 140290573805568 replay_runner.py:36] Average training steps per second: 196.26
I0828 10:30:49.642254 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 22.30
INFO:tensorflow:Starting iteration 3

Steps executed: 226 Episode length: 30 Return: 30.0
INFO:tensorflow:Average training steps per second: 208.61
I0828 10:30:54.626086 140290573805568 replay_runner.py:36] Average training steps per second: 208.61
I0828 10:30:54.768468 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 28.25
INFO:tensorflow:Starting iteration 4
I0828 10:30:54.953493 140290573805568 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 205.00

Steps executed: 385 Episode length: 192 Return: 192.0
I0828 10:31:00.058175 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 192.50
INFO:tensorflow:Starting iteration 5

Steps executed: 269 Episode length: 92 Return: 92.0.0
INFO:tensorflow:Average training steps per second: 203.45
I0828 10:31:05.153793 140290573805568 replay_runner.py:36] Average training steps per second: 203.45
I0828 10:31:05.337193 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 89.67
INFO:tensorflow:Starting iteration 6

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 203.00
I0828 10:31:10.454668 140290573805568 replay_runner.py:36] Average training steps per second: 203.00
I0828 10:31:10.584095 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 7
I0828 10:31:10.764117 140290573805568 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 194.50
I0828 10:31:15.906071 140290573805568 replay_runner.py:36] Average training steps per second: 194.50
I0828 10:31:16.045888 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 8

Steps executed: 208 Episode length: 105 Return: 105.0
INFO:tensorflow:Average training steps per second: 198.63
I0828 10:31:21.279789 140290573805568 replay_runner.py:36] Average training steps per second: 198.63
I0828 10:31:21.415094 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 104.00
INFO:tensorflow:Starting iteration 9

Steps executed: 205 Episode length: 102 Return: 102.0
INFO:tensorflow:Average training steps per second: 190.65
I0828 10:31:26.847309 140290573805568 replay_runner.py:36] Average training steps per second: 190.65
I0828 10:31:26.996315 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 102.50
INFO:tensorflow:Starting iteration 10

Steps executed: 226 Episode length: 76 Return: 76.0.0
INFO:tensorflow:Average training steps per second: 199.39
I0828 10:31:32.202591 140290573805568 replay_runner.py:36] Average training steps per second: 199.39
I0828 10:31:32.356113 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 75.33
INFO:tensorflow:Starting iteration 11

Steps executed: 227 Episode length: 110 Return: 110.0
INFO:tensorflow:Average training steps per second: 193.89
I0828 10:31:37.691153 140290573805568 replay_runner.py:36] Average training steps per second: 193.89
I0828 10:31:37.839885 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 113.50
INFO:tensorflow:Starting iteration 12

Steps executed: 291 Episode length: 101 Return: 101.0
INFO:tensorflow:Average training steps per second: 191.44
I0828 10:31:43.243261 140290573805568 replay_runner.py:36] Average training steps per second: 191.44
I0828 10:31:43.443363 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 97.00
INFO:tensorflow:Starting iteration 13

Steps executed: 201 Episode length: 99 Return: 99.0.0
INFO:tensorflow:Average training steps per second: 201.46
I0828 10:31:48.601576 140290573805568 replay_runner.py:36] Average training steps per second: 201.46
I0828 10:31:48.734341 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 100.50
INFO:tensorflow:Starting iteration 14
I0828 10:31:48.928000 140290573805568 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 191.25
I0828 10:31:54.157061 140290573805568 replay_runner.py:36] Average training steps per second: 191.25

Steps executed: 300 Episode length: 149 Return: 149.0
INFO:tensorflow:Starting iteration 15

Steps executed: 376 Episode length: 191 Return: 191.0
INFO:tensorflow:Average training steps per second: 199.72
I0828 10:31:59.550665 140290573805568 replay_runner.py:36] Average training steps per second: 199.72
I0828 10:31:59.810445 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 188.00
INFO:tensorflow:Starting iteration 16

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 195.96
I0828 10:32:05.112339 140290573805568 replay_runner.py:36] Average training steps per second: 195.96
I0828 10:32:05.239674 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 17

Steps executed: 255 Episode length: 125 Return: 125.0
INFO:tensorflow:Average training steps per second: 190.94
I0828 10:32:10.664862 140290573805568 replay_runner.py:36] Average training steps per second: 190.94
I0828 10:32:10.844385 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 127.50
INFO:tensorflow:Starting iteration 18
I0828 10:32:11.047062 140290573805568 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 198.40
I0828 10:32:16.087625 140290573805568 replay_runner.py:36] Average training steps per second: 198.40
I0828 10:32:16.274317 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 141.50
INFO:tensorflow:Starting iteration 19


Steps executed: 306 Episode length: 158 Return: 158.0
INFO:tensorflow:Average training steps per second: 192.58
I0828 10:32:21.667437 140290573805568 replay_runner.py:36] Average training steps per second: 192.58
I0828 10:32:21.872901 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 153.00
INFO:tensorflow:Starting iteration 20

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 200.86
I0828 10:32:27.050911 140290573805568 replay_runner.py:36] Average training steps per second: 200.86
I0828 10:32:27.189745 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 21
I0828 10:32:27.393077 140290573805568 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 197.57
I0828 10:32:32.454913 140290573805568 replay_runner.py:36] Average training steps per second: 197.57
I0828 10:32:32.577065 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 22
I0828 10:32:32.759272 140290573805568 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 202.26
I0828 10:32:37.703832 140290573805568 replay_runner.py:36] Average training steps per second: 202.26
I0828 10:32:37.833261 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 23
I0828 10:32:38.019757 140290573805568 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 198.49
I0828 10:32:43.058289 140290573805568 replay_runner.py:36] Average training steps per second: 198.49
I0828 10:32:43.177098 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 24
I0828 10:32:43.364683 140290573805568 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 202.58
I0828 10:32:48.301744 140290573805568 replay_runner.py:36] Average training steps per second: 202.58
I0828 10:32:48.429430 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 25
I0828 10:32:48.613107 140290573805568 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 195.80
I0828 10:32:53.720764 140290573805568 replay_runner.py:36] Average training steps per second: 195.80
I0828 10:32:53.851561 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26
I0828 10:32:54.031330 140290573805568 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 207.01
I0828 10:32:58.862415 140290573805568 replay_runner.py:36] Average training steps per second: 207.01
I0828 10:32:58.985349 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 27

Steps executed: 222 Episode length: 111 Return: 111.0
INFO:tensorflow:Average training steps per second: 196.68
I0828 10:33:04.260457 140290573805568 replay_runner.py:36] Average training steps per second: 196.68
I0828 10:33:04.407261 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 111.00
INFO:tensorflow:Starting iteration 28

Steps executed: 222 Episode length: 107 Return: 107.0
INFO:tensorflow:Average training steps per second: 199.05
I0828 10:33:09.630711 140290573805568 replay_runner.py:36] Average training steps per second: 199.05
I0828 10:33:09.780137 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 111.00
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 196.29
I0828 10:33:15.064295 140290573805568 replay_runner.py:36] Average training steps per second: 196.29
I0828 10:33:15.193997 140290573805568 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00