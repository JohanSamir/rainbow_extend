Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0903 00:12:11.415796 139926926592000 run_experiment.py:549] Creating TrainRunner ...
I0903 00:12:11.424687 139926926592000 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:12:11.424854 139926926592000 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:12:11.424951 139926926592000 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:12:11.425048 139926926592000 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:12:11.425127 139926926592000 dqn_agent.py:275] 	 update_period: 4
I0903 00:12:11.425181 139926926592000 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:12:11.425253 139926926592000 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:12:11.425348 139926926592000 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:12:11.425418 139926926592000 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:12:11.425485 139926926592000 dqn_agent.py:280] 	 optimizer: adam
I0903 00:12:11.425559 139926926592000 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:12:11.425626 139926926592000 dqn_agent.py:283] 	 seed: 1630627931424644
I0903 00:12:11.427416 139926926592000 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:12:11.427532 139926926592000 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:12:11.427607 139926926592000 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:12:11.427674 139926926592000 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:12:11.427729 139926926592000 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:12:11.427798 139926926592000 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:12:11.427867 139926926592000 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:12:11.427923 139926926592000 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:12:11.428012 139926926592000 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:12:11.452633 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:12:11.723444 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:12:11.733259 139926926592000 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:12:11.740007 139926926592000 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:12:11.740140 139926926592000 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:12:11.740233 139926926592000 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:12:11.740389 139926926592000 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:12:11.740454 139926926592000 dqn_agent.py:275] 	 update_period: 4
I0903 00:12:11.740533 139926926592000 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:12:11.740602 139926926592000 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:12:11.740667 139926926592000 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:12:11.740735 139926926592000 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:12:11.740809 139926926592000 dqn_agent.py:280] 	 optimizer: adam
I0903 00:12:11.740879 139926926592000 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:12:11.740953 139926926592000 dqn_agent.py:283] 	 seed: 1630627931739939
I0903 00:12:11.742495 139926926592000 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:12:11.742611 139926926592000 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:12:11.742675 139926926592000 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:12:11.742737 139926926592000 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:12:11.742793 139926926592000 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:12:11.742846 139926926592000 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:12:11.742923 139926926592000 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:12:11.743129 139926926592000 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:12:11.743325 139926926592000 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:12:11.777471 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:12:11.800762 139926926592000 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:12:11.801078 139926926592000 replay_runner.py:41] Starting iteration 0
Steps executed: 315 Episode length: 134 Return: -350.7013473032612
INFO:tensorflow:Average training steps per second: 253.01
I0903 00:12:15.753763 139926926592000 replay_runner.py:36] Average training steps per second: 253.01
I0903 00:12:16.621692 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.02
INFO:tensorflow:Starting iteration 1
I0903 00:12:19.938757 139926926592000 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 325.21

Steps executed: 298 Episode length: 165 Return: -292.54259766159595
I0903 00:12:23.221161 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.16
INFO:tensorflow:Starting iteration 2

Steps executed: 260 Episode length: 141 Return: -312.85257075063285
INFO:tensorflow:Average training steps per second: 312.85
I0903 00:12:29.678872 139926926592000 replay_runner.py:36] Average training steps per second: 312.85
I0903 00:12:29.856135 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.95
INFO:tensorflow:Starting iteration 3

Steps executed: 249 Episode length: 132 Return: -463.30001924208204
INFO:tensorflow:Average training steps per second: 323.24
I0903 00:12:36.244083 139926926592000 replay_runner.py:36] Average training steps per second: 323.24
I0903 00:12:36.410465 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -486.29
INFO:tensorflow:Starting iteration 4

Steps executed: 387 Episode length: 202 Return: -320.65208199566414
INFO:tensorflow:Average training steps per second: 330.15
I0903 00:12:42.788285 139926926592000 replay_runner.py:36] Average training steps per second: 330.15
I0903 00:12:43.063988 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -383.33
INFO:tensorflow:Starting iteration 5

Steps executed: 232 Episode length: 232 Return: -266.18883706784294
INFO:tensorflow:Average training steps per second: 325.50
I0903 00:12:49.469450 139926926592000 replay_runner.py:36] Average training steps per second: 325.50
I0903 00:12:49.670292 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.19
INFO:tensorflow:Starting iteration 6
I0903 00:12:52.967439 139926926592000 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 310.57

Steps executed: 955 Episode length: 955 Return: -251.75238068501624
I0903 00:12:58.093017 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -251.75
INFO:tensorflow:Starting iteration 7
I0903 00:13:01.366600 139926926592000 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 314.20

Steps executed: 1000 Episode length: 1000 Return: -132.6030211961461
I0903 00:13:06.272011 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.60
INFO:tensorflow:Starting iteration 8

Steps executed: 243 Episode length: 243 Return: -139.613882075584741
INFO:tensorflow:Average training steps per second: 321.20
I0903 00:13:12.716631 139926926592000 replay_runner.py:36] Average training steps per second: 321.20
I0903 00:13:12.888043 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.61
INFO:tensorflow:Starting iteration 9

Steps executed: 152 Episode length: 152 Return: -937.943146747785741
INFO:tensorflow:Average training steps per second: 334.30

Steps executed: 318 Episode length: 166 Return: -847.929122809425741
I0903 00:13:19.486164 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -892.94
INFO:tensorflow:Starting iteration 10

Steps executed: 251 Episode length: 83 Return: -452.1559529315655441
INFO:tensorflow:Average training steps per second: 319.32
I0903 00:13:25.985545 139926926592000 replay_runner.py:36] Average training steps per second: 319.32
I0903 00:13:26.145937 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -503.72
INFO:tensorflow:Starting iteration 11

Steps executed: 257 Episode length: 257 Return: -37.8570781243120461
INFO:tensorflow:Average training steps per second: 318.25
I0903 00:13:32.631491 139926926592000 replay_runner.py:36] Average training steps per second: 318.25
I0903 00:13:32.862156 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.86
INFO:tensorflow:Starting iteration 12
I0903 00:13:36.174092 139926926592000 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 328.42

Steps executed: 587 Episode length: 587 Return: -246.187526802275361
I0903 00:13:39.892207 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -246.19
INFO:tensorflow:Starting iteration 13

Steps executed: 259 Episode length: 259 Return: -41.3618580291169451
INFO:tensorflow:Average training steps per second: 327.54
I0903 00:13:46.256388 139926926592000 replay_runner.py:36] Average training steps per second: 327.54
I0903 00:13:46.476570 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -41.36
INFO:tensorflow:Starting iteration 14

Steps executed: 220 Episode length: 220 Return: -1023.01854554564161
INFO:tensorflow:Average training steps per second: 330.63
I0903 00:13:52.938785 139926926592000 replay_runner.py:36] Average training steps per second: 330.63
I0903 00:13:53.100528 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -1023.02
INFO:tensorflow:Starting iteration 15

Steps executed: 162 Episode length: 162 Return: -173.675039817882071
INFO:tensorflow:Average training steps per second: 334.70
I0903 00:13:59.476326 139926926592000 replay_runner.py:36] Average training steps per second: 334.70

Steps executed: 267 Episode length: 105 Return: -659.320543479871471
INFO:tensorflow:Starting iteration 16

Steps executed: 218 Episode length: 152 Return: -280.570084171068471
INFO:tensorflow:Average training steps per second: 319.06
I0903 00:14:06.170827 139926926592000 replay_runner.py:36] Average training steps per second: 319.06
I0903 00:14:06.318723 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.70
INFO:tensorflow:Starting iteration 17

Steps executed: 269 Episode length: 269 Return: -472.256367280418571
INFO:tensorflow:Average training steps per second: 314.20
I0903 00:14:12.828893 139926926592000 replay_runner.py:36] Average training steps per second: 314.20
I0903 00:14:13.076635 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -472.26
INFO:tensorflow:Starting iteration 18


Steps executed: 299 Episode length: 140 Return: -772.610076089391991
INFO:tensorflow:Average training steps per second: 323.31
I0903 00:14:19.513871 139926926592000 replay_runner.py:36] Average training steps per second: 323.31
I0903 00:14:19.718974 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -450.24
INFO:tensorflow:Starting iteration 19

Steps executed: 251 Episode length: 110 Return: -615.817848455350991
INFO:tensorflow:Average training steps per second: 322.14
I0903 00:14:26.191304 139926926592000 replay_runner.py:36] Average training steps per second: 322.14
I0903 00:14:26.388418 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -627.22
INFO:tensorflow:Starting iteration 20

Steps executed: 221 Episode length: 83 Return: -758.8879365846088991
INFO:tensorflow:Average training steps per second: 323.02
I0903 00:14:32.860186 139926926592000 replay_runner.py:36] Average training steps per second: 323.02
I0903 00:14:32.991194 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -545.90
INFO:tensorflow:Starting iteration 21
I0903 00:14:36.405902 139926926592000 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 333.03

Steps executed: 213 Episode length: 213 Return: -640.116178892927391
I0903 00:14:39.569340 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -640.12
INFO:tensorflow:Starting iteration 22

Steps executed: 235 Episode length: 86 Return: -449.2940026430962191
INFO:tensorflow:Average training steps per second: 347.59
I0903 00:14:45.852767 139926926592000 replay_runner.py:36] Average training steps per second: 347.59
I0903 00:14:45.995151 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -440.90
INFO:tensorflow:Starting iteration 23

Steps executed: 217 Episode length: 87 Return: -780.0779564792656191
INFO:tensorflow:Average training steps per second: 342.14
I0903 00:14:52.376088 139926926592000 replay_runner.py:36] Average training steps per second: 342.14
I0903 00:14:52.527841 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -506.73
INFO:tensorflow:Starting iteration 24

Steps executed: 214 Episode length: 84 Return: -753.8458303687695191
INFO:tensorflow:Average training steps per second: 339.45
I0903 00:14:58.961766 139926926592000 replay_runner.py:36] Average training steps per second: 339.45
I0903 00:14:59.112801 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -601.40
INFO:tensorflow:Starting iteration 25
I0903 00:15:02.598065 139926926592000 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 340.53
I0903 00:15:05.535134 139926926592000 replay_runner.py:36] Average training steps per second: 340.53

Steps executed: 276 Episode length: 90 Return: -601.9457301812668391
INFO:tensorflow:Starting iteration 26

Steps executed: 213 Episode length: 83 Return: -714.9260733650932491
INFO:tensorflow:Average training steps per second: 342.53
I0903 00:15:12.126346 139926926592000 replay_runner.py:36] Average training steps per second: 342.53
I0903 00:15:12.273746 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -580.96
INFO:tensorflow:Starting iteration 27

Steps executed: 242 Episode length: 50 Return: -350.9855866259138591
INFO:tensorflow:Average training steps per second: 349.15
I0903 00:15:18.544911 139926926592000 replay_runner.py:36] Average training steps per second: 349.15
I0903 00:15:18.692550 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -461.23
INFO:tensorflow:Starting iteration 28

Steps executed: 237 Episode length: 70 Return: -495.0475415662401791
INFO:tensorflow:Average training steps per second: 337.53
I0903 00:15:25.064848 139926926592000 replay_runner.py:36] Average training steps per second: 337.53
I0903 00:15:25.199142 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -421.27
INFO:tensorflow:Starting iteration 29

Steps executed: 210 Episode length: 80 Return: -703.2668215053747791
INFO:tensorflow:Average training steps per second: 351.48
I0903 00:15:31.427109 139926926592000 replay_runner.py:36] Average training steps per second: 351.48

Done fixed training!Episode length: 80 Return: -703.2668215053747791