Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0901 12:51:07.135731 139809518303232 run_experiment.py:549] Creating TrainRunner ...
I0901 12:51:07.147367 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:51:07.147687 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:51:07.147907 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:51:07.148190 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:51:07.148328 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 12:51:07.148495 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:51:07.148677 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:51:07.148806 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:51:07.148919 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:51:07.149028 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 12:51:07.149131 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:51:07.149388 139809518303232 dqn_agent.py:283] 	 seed: 1630500667147296
I0901 12:51:07.152887 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:51:07.153135 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:51:07.153264 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:51:07.153352 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:51:07.153471 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:51:07.153562 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:51:07.153653 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:51:07.153804 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:51:07.153900 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:51:07.193466 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:51:07.580531 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:51:07.592951 139809518303232 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:51:07.601349 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:51:07.601699 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:51:07.601967 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:51:07.602132 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:51:07.602236 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 12:51:07.602335 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:51:07.602418 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:51:07.602535 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:51:07.602632 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:51:07.602715 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 12:51:07.602858 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:51:07.602971 139809518303232 dqn_agent.py:283] 	 seed: 1630500667601289
I0901 12:51:07.605814 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:51:07.606038 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:51:07.606165 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:51:07.606300 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:51:07.606434 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:51:07.606521 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:51:07.606705 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:51:07.606812 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:51:07.606963 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:51:07.683711 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:51:07.708679 139809518303232 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:51:07.709160 139809518303232 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 153.71
I0901 12:51:14.215258 139809518303232 replay_runner.py:36] Average training steps per second: 153.71
Steps executed: 206 Episode length: 103 Return: -134.74649110521506
I0901 12:51:15.465717 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.14
INFO:tensorflow:Starting iteration 1
I0901 12:51:19.926709 139809518303232 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 212.94

Steps executed: 223 Episode length: 131 Return: -496.06494671269906
I0901 12:51:24.853497 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -615.08
INFO:tensorflow:Starting iteration 2

Steps executed: 313 Episode length: 185 Return: 1.13409339907782686
INFO:tensorflow:Average training steps per second: 216.56
I0901 12:51:33.930389 139809518303232 replay_runner.py:36] Average training steps per second: 216.56
I0901 12:51:34.268792 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.13
INFO:tensorflow:Starting iteration 3

Steps executed: 256 Episode length: 128 Return: -23.966509530667764
INFO:tensorflow:Average training steps per second: 214.91
I0901 12:51:43.297738 139809518303232 replay_runner.py:36] Average training steps per second: 214.91
I0901 12:51:43.529668 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -33.93
INFO:tensorflow:Starting iteration 4

Steps executed: 252 Episode length: 132 Return: -101.51580743058666
INFO:tensorflow:Average training steps per second: 216.83
I0901 12:51:52.608329 139809518303232 replay_runner.py:36] Average training steps per second: 216.83
I0901 12:51:52.831483 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.34
INFO:tensorflow:Starting iteration 5

Steps executed: 300 Episode length: 190 Return: -329.93712804244956
INFO:tensorflow:Average training steps per second: 209.72
I0901 12:52:02.016176 139809518303232 replay_runner.py:36] Average training steps per second: 209.72
I0901 12:52:02.326726 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -305.31
INFO:tensorflow:Starting iteration 6

Steps executed: 229 Episode length: 93 Return: -736.093840000290156
INFO:tensorflow:Average training steps per second: 217.68
I0901 12:52:11.382734 139809518303232 replay_runner.py:36] Average training steps per second: 217.68
I0901 12:52:11.610246 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -507.70
INFO:tensorflow:Starting iteration 7

Steps executed: 287 Episode length: 92 Return: -232.548136356550315
INFO:tensorflow:Average training steps per second: 219.79
I0901 12:52:20.477604 139809518303232 replay_runner.py:36] Average training steps per second: 219.79
I0901 12:52:20.714126 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -305.35
INFO:tensorflow:Starting iteration 8

Steps executed: 348 Episode length: 173 Return: -45.404337490192525
INFO:tensorflow:Average training steps per second: 226.30
I0901 12:52:29.601755 139809518303232 replay_runner.py:36] Average training steps per second: 226.30
I0901 12:52:29.906511 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -363.91
INFO:tensorflow:Starting iteration 9

Steps executed: 296 Episode length: 165 Return: 38.6109482122304545
INFO:tensorflow:Average training steps per second: 222.24
I0901 12:52:38.592714 139809518303232 replay_runner.py:36] Average training steps per second: 222.24
I0901 12:52:38.862803 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: 23.40
INFO:tensorflow:Starting iteration 10

Steps executed: 209 Episode length: 104 Return: 11.6785526379239145
INFO:tensorflow:Average training steps per second: 217.57
I0901 12:52:47.843553 139809518303232 replay_runner.py:36] Average training steps per second: 217.57
I0901 12:52:48.027811 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -4.15
INFO:tensorflow:Starting iteration 11

Steps executed: 106 Episode length: 106 Return: -202.23835535445955
INFO:tensorflow:Average training steps per second: 217.56
I0901 12:52:57.024919 139809518303232 replay_runner.py:36] Average training steps per second: 217.56

Steps executed: 206 Episode length: 100 Return: -299.18447712963507
INFO:tensorflow:Starting iteration 12

Steps executed: 201 Episode length: 119 Return: 30.6107767569468767
INFO:tensorflow:Average training steps per second: 218.14
I0901 12:53:06.267249 139809518303232 replay_runner.py:36] Average training steps per second: 218.14
I0901 12:53:06.450633 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.03
INFO:tensorflow:Starting iteration 13
I0901 12:53:10.842573 139809518303232 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 223.01

Steps executed: 285 Episode length: 285 Return: 247.747190648467727
I0901 12:53:15.614233 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: 247.75
INFO:tensorflow:Starting iteration 14

Steps executed: 299 Episode length: 141 Return: -139.55539116712495
INFO:tensorflow:Average training steps per second: 216.61
I0901 12:53:24.580355 139809518303232 replay_runner.py:36] Average training steps per second: 216.61
I0901 12:53:24.828934 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.14
INFO:tensorflow:Starting iteration 15

Steps executed: 330 Episode length: 137 Return: -130.93881815164838
INFO:tensorflow:Average training steps per second: 215.61
I0901 12:53:33.937221 139809518303232 replay_runner.py:36] Average training steps per second: 215.61
I0901 12:53:34.208503 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.08
INFO:tensorflow:Starting iteration 16

Steps executed: 237 Episode length: 87 Return: -314.275994930146068
INFO:tensorflow:Average training steps per second: 223.75
I0901 12:53:43.109709 139809518303232 replay_runner.py:36] Average training steps per second: 223.75
I0901 12:53:43.289334 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -181.57
INFO:tensorflow:Starting iteration 17

Steps executed: 244 Episode length: 84 Return: -408.603678666615348
INFO:tensorflow:Average training steps per second: 216.90
I0901 12:53:52.283070 139809518303232 replay_runner.py:36] Average training steps per second: 216.90
I0901 12:53:52.462275 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.67
INFO:tensorflow:Starting iteration 18
I0901 12:53:56.853385 139809518303232 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 218.39

Steps executed: 301 Episode length: 196 Return: -574.04017160153428
I0901 12:54:01.763029 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -381.70
INFO:tensorflow:Starting iteration 19

Steps executed: 202 Episode length: 79 Return: -435.959784141744252
INFO:tensorflow:Average training steps per second: 221.46
I0901 12:54:10.684688 139809518303232 replay_runner.py:36] Average training steps per second: 221.46
I0901 12:54:10.861057 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.67
INFO:tensorflow:Starting iteration 20

Steps executed: 205 Episode length: 86 Return: -144.930490212135342
INFO:tensorflow:Average training steps per second: 220.47
I0901 12:54:19.727079 139809518303232 replay_runner.py:36] Average training steps per second: 220.47
I0901 12:54:19.879658 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.18
INFO:tensorflow:Starting iteration 21

Steps executed: 210 Episode length: 69 Return: -276.434321892218862
INFO:tensorflow:Average training steps per second: 217.04
I0901 12:54:28.877297 139809518303232 replay_runner.py:36] Average training steps per second: 217.04
I0901 12:54:29.073585 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -387.51
INFO:tensorflow:Starting iteration 22

Steps executed: 214 Episode length: 135 Return: -296.47538112390362
INFO:tensorflow:Average training steps per second: 218.62
I0901 12:54:37.990179 139809518303232 replay_runner.py:36] Average training steps per second: 218.62
I0901 12:54:38.185505 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -249.05
INFO:tensorflow:Starting iteration 23

Steps executed: 139 Episode length: 139 Return: -396.73411951751046
INFO:tensorflow:Average training steps per second: 222.67
I0901 12:54:46.983961 139809518303232 replay_runner.py:36] Average training steps per second: 222.67

Steps executed: 272 Episode length: 133 Return: -367.19321303183716
INFO:tensorflow:Starting iteration 24

Steps executed: 267 Episode length: 78 Return: -453.615231651933116
INFO:tensorflow:Average training steps per second: 219.94
I0901 12:54:56.123835 139809518303232 replay_runner.py:36] Average training steps per second: 219.94
I0901 12:54:56.362202 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.86
INFO:tensorflow:Starting iteration 25

Steps executed: 234 Episode length: 93 Return: -689.438037481903216
INFO:tensorflow:Average training steps per second: 212.70
I0901 12:55:05.508064 139809518303232 replay_runner.py:36] Average training steps per second: 212.70
I0901 12:55:05.717259 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -425.37
INFO:tensorflow:Starting iteration 26

Steps executed: 304 Episode length: 124 Return: -214.36677522141767
INFO:tensorflow:Average training steps per second: 215.21
I0901 12:55:14.764640 139809518303232 replay_runner.py:36] Average training steps per second: 215.21
I0901 12:55:15.012473 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -214.16
INFO:tensorflow:Starting iteration 27

Steps executed: 220 Episode length: 101 Return: -717.27483743027435
INFO:tensorflow:Average training steps per second: 226.11
I0901 12:55:23.787357 139809518303232 replay_runner.py:36] Average training steps per second: 226.11
I0901 12:55:23.969550 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -424.68
INFO:tensorflow:Starting iteration 28

Steps executed: 225 Episode length: 81 Return: -176.085301432891675
INFO:tensorflow:Average training steps per second: 231.09
I0901 12:55:32.555085 139809518303232 replay_runner.py:36] Average training steps per second: 231.09
I0901 12:55:32.710773 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -204.80
INFO:tensorflow:Starting iteration 29
I0901 12:55:37.069135 139809518303232 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 223.26

Steps executed: 233 Episode length: 90 Return: -700.852183785118165

Done fixed training!Episode length: 90 Return: -700.852183785118165