Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0828 10:42:22.465493 140053337282560 run_experiment.py:549] Creating TrainRunner ...
I0828 10:42:22.476385 140053337282560 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:22.476700 140053337282560 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:22.476884 140053337282560 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:22.477017 140053337282560 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:22.477098 140053337282560 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:22.477167 140053337282560 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:22.477230 140053337282560 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:22.477294 140053337282560 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:22.477368 140053337282560 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:22.477466 140053337282560 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:22.477565 140053337282560 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:22.477644 140053337282560 dqn_agent.py:283] 	 seed: 1630147342476317
I0828 10:42:22.480267 140053337282560 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:22.480489 140053337282560 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:22.480669 140053337282560 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:22.480775 140053337282560 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:22.480849 140053337282560 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:22.480942 140053337282560 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:22.481295 140053337282560 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:22.481404 140053337282560 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:22.481481 140053337282560 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:22.518089 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:22.883931 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:22.896634 140053337282560 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:42:22.905780 140053337282560 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:42:22.905978 140053337282560 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:42:22.906071 140053337282560 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:42:22.906149 140053337282560 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:42:22.906207 140053337282560 dqn_agent.py:275] 	 update_period: 4
I0828 10:42:22.906280 140053337282560 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:42:22.906413 140053337282560 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:42:22.906558 140053337282560 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:42:22.906685 140053337282560 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:42:22.906800 140053337282560 dqn_agent.py:280] 	 optimizer: adam
I0828 10:42:22.906875 140053337282560 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:42:22.906933 140053337282560 dqn_agent.py:283] 	 seed: 1630147342905731
I0828 10:42:22.909752 140053337282560 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:42:22.910004 140053337282560 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:42:22.910204 140053337282560 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:42:22.910341 140053337282560 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:42:22.910466 140053337282560 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:42:22.910637 140053337282560 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:42:22.910709 140053337282560 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:42:22.910795 140053337282560 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:42:22.911147 140053337282560 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:42:22.940585 140053337282560 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:42:22.996047 140053337282560 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:42:22.996318 140053337282560 replay_runner.py:41] Starting iteration 0
Steps executed: 250 Episode length: 144 Return: -247.55291475678547
INFO:tensorflow:Average training steps per second: 172.74
I0828 10:42:28.785511 140053337282560 replay_runner.py:36] Average training steps per second: 172.74
I0828 10:42:29.931324 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -452.26
INFO:tensorflow:Starting iteration 1
I0828 10:42:34.152338 140053337282560 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 224.62

Steps executed: 1000 Episode length: 1000 Return: -112.09388277891972
I0828 10:42:41.507375 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.09
INFO:tensorflow:Starting iteration 2

Steps executed: 428 Episode length: 250 Return: -314.3478393315732972
INFO:tensorflow:Average training steps per second: 226.15
I0828 10:42:50.209982 140053337282560 replay_runner.py:36] Average training steps per second: 226.15
I0828 10:42:50.628369 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -315.19
INFO:tensorflow:Starting iteration 3
I0828 10:42:54.860940 140053337282560 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 226.22

Steps executed: 1000 Episode length: 1000 Return: -293.18906725228277
I0828 10:43:03.120396 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.19
INFO:tensorflow:Starting iteration 4
I0828 10:43:07.334134 140053337282560 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 233.75

Steps executed: 1000 Episode length: 1000 Return: -213.40888271805667
I0828 10:43:15.208895 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.41
INFO:tensorflow:Starting iteration 5
I0828 10:43:19.454173 140053337282560 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 239.93

Steps executed: 1000 Episode length: 1000 Return: -13.640669306499658
I0828 10:43:26.958459 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -13.64
INFO:tensorflow:Starting iteration 6
I0828 10:43:31.327512 140053337282560 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 240.08

Steps executed: 1000 Episode length: 1000 Return: -74.893109852137348
I0828 10:43:37.590575 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.89
INFO:tensorflow:Starting iteration 7
I0828 10:43:41.876001 140053337282560 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 227.24

Steps executed: 847 Episode length: 655 Return: -316.9700353828129348
I0828 10:43:47.858071 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.89
INFO:tensorflow:Starting iteration 8

Steps executed: 339 Episode length: 339 Return: -791.8265238388333348
INFO:tensorflow:Average training steps per second: 228.93
I0828 10:43:56.569410 140053337282560 replay_runner.py:36] Average training steps per second: 228.93
I0828 10:43:57.082695 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -791.83
INFO:tensorflow:Starting iteration 9

Steps executed: 403 Episode length: 403 Return: -377.4848083709781348
INFO:tensorflow:Average training steps per second: 232.18
I0828 10:44:05.688135 140053337282560 replay_runner.py:36] Average training steps per second: 232.18
I0828 10:44:06.308045 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.48
INFO:tensorflow:Starting iteration 10
I0828 10:44:10.553604 140053337282560 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 221.24

Steps executed: 832 Episode length: 832 Return: -241.6808648547510448
I0828 10:44:17.338611 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -241.68
INFO:tensorflow:Starting iteration 11

Steps executed: 195 Episode length: 68 Return: -212.30684263825982248
INFO:tensorflow:Average training steps per second: 220.91
I0828 10:44:26.168656 140053337282560 replay_runner.py:36] Average training steps per second: 220.91

Steps executed: 419 Episode length: 224 Return: -166.0201225546209248
INFO:tensorflow:Starting iteration 12

Steps executed: 153 Episode length: 153 Return: -63.11904313453146648
INFO:tensorflow:Average training steps per second: 225.53

Steps executed: 970 Episode length: 817 Return: -110.1639943491456848
I0828 10:44:37.421329 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.64
INFO:tensorflow:Starting iteration 13

Steps executed: 275 Episode length: 275 Return: -372.1879281303471848
INFO:tensorflow:Average training steps per second: 224.47
I0828 10:44:46.119191 140053337282560 replay_runner.py:36] Average training steps per second: 224.47
I0828 10:44:46.463548 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -372.19
INFO:tensorflow:Starting iteration 14

Steps executed: 201 Episode length: 87 Return: -211.74139584513506848
INFO:tensorflow:Average training steps per second: 222.64
I0828 10:44:55.104910 140053337282560 replay_runner.py:36] Average training steps per second: 222.64
I0828 10:44:55.257818 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.82
INFO:tensorflow:Starting iteration 15

Steps executed: 69 Episode length: 69 Return: -130.809901686013506848
INFO:tensorflow:Average training steps per second: 226.46

Steps executed: 753 Episode length: 684 Return: -98.86062697265035848
I0828 10:45:05.929033 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.84
INFO:tensorflow:Starting iteration 16

Steps executed: 78 Episode length: 78 Return: -187.294318238337935848
INFO:tensorflow:Average training steps per second: 239.06
I0828 10:45:14.310484 140053337282560 replay_runner.py:36] Average training steps per second: 239.06

Steps executed: 214 Episode length: 61 Return: -314.15086830092834848
INFO:tensorflow:Starting iteration 17

Steps executed: 302 Episode length: 147 Return: -64.83865250284374848
INFO:tensorflow:Average training steps per second: 239.55
I0828 10:45:22.717900 140053337282560 replay_runner.py:36] Average training steps per second: 239.55
I0828 10:45:22.936738 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.50
INFO:tensorflow:Starting iteration 18

Steps executed: 245 Episode length: 72 Return: -175.42963327331287848
INFO:tensorflow:Average training steps per second: 250.64
I0828 10:45:30.982301 140053337282560 replay_runner.py:36] Average training steps per second: 250.64
I0828 10:45:31.139255 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.48
INFO:tensorflow:Starting iteration 19

Steps executed: 247 Episode length: 61 Return: -122.01576082682368848
INFO:tensorflow:Average training steps per second: 257.87
I0828 10:45:39.010754 140053337282560 replay_runner.py:36] Average training steps per second: 257.87
I0828 10:45:39.170165 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.59
INFO:tensorflow:Starting iteration 20

Steps executed: 245 Episode length: 59 Return: -238.45340086519776548
INFO:tensorflow:Average training steps per second: 251.54
I0828 10:45:47.074859 140053337282560 replay_runner.py:36] Average training steps per second: 251.54
I0828 10:45:47.254897 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.55
INFO:tensorflow:Starting iteration 21

Steps executed: 298 Episode length: 141 Return: -157.1509349557583748
INFO:tensorflow:Average training steps per second: 265.94
I0828 10:45:54.930045 140053337282560 replay_runner.py:36] Average training steps per second: 265.94
I0828 10:45:55.166860 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.59
INFO:tensorflow:Starting iteration 22
I0828 10:45:59.040177 140053337282560 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 269.36

Steps executed: 288 Episode length: 153 Return: -945.4634353268266748
I0828 10:46:02.999610 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -754.07
INFO:tensorflow:Starting iteration 23

Steps executed: 223 Episode length: 100 Return: -619.6506001517258748
INFO:tensorflow:Average training steps per second: 280.50
I0828 10:46:10.256490 140053337282560 replay_runner.py:36] Average training steps per second: 280.50
I0828 10:46:10.406939 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.78
INFO:tensorflow:Starting iteration 24

Steps executed: 268 Episode length: 86 Return: -96.253517446025848748
INFO:tensorflow:Average training steps per second: 304.56
I0828 10:46:17.391525 140053337282560 replay_runner.py:36] Average training steps per second: 304.56
I0828 10:46:17.535062 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.29
INFO:tensorflow:Starting iteration 25

Steps executed: 236 Episode length: 90 Return: -258.85618776720423748
INFO:tensorflow:Average training steps per second: 327.15
I0828 10:46:24.015302 140053337282560 replay_runner.py:36] Average training steps per second: 327.15
I0828 10:46:24.141339 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.97
INFO:tensorflow:Starting iteration 26

Steps executed: 245 Episode length: 59 Return: -378.97201437001854748
INFO:tensorflow:Average training steps per second: 331.60
I0828 10:46:30.511925 140053337282560 replay_runner.py:36] Average training steps per second: 331.60
I0828 10:46:30.668364 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -517.96
INFO:tensorflow:Starting iteration 27
I0828 10:46:34.015897 140053337282560 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 340.65

Steps executed: 350 Episode length: 181 Return: -790.7934312122687748
I0828 10:46:37.177858 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -497.97
INFO:tensorflow:Starting iteration 28

Steps executed: 254 Episode length: 68 Return: -521.00743203641517748
INFO:tensorflow:Average training steps per second: 337.28
I0828 10:46:43.405958 140053337282560 replay_runner.py:36] Average training steps per second: 337.28
I0828 10:46:43.544769 140053337282560 run_experiment.py:428] Average undiscounted return per evaluation episode: -483.77
INFO:tensorflow:Starting iteration 29

Steps executed: 207 Episode length: 56 Return: -324.31014596129853748
INFO:tensorflow:Average training steps per second: 333.75
I0828 10:46:49.525892 140053337282560 replay_runner.py:36] Average training steps per second: 333.75

Done fixed training!Episode length: 56 Return: -324.31014596129853748