Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0902 00:10:53.705295 139929824643072 run_experiment.py:549] Creating TrainRunner ...
I0902 00:10:53.720128 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:10:53.720410 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:10:53.720523 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:10:53.720607 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:10:53.720688 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0902 00:10:53.720755 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:10:53.720845 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:10:53.721027 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:10:53.721129 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:10:53.721409 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0902 00:10:53.721644 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:10:53.721910 139929824643072 dqn_agent.py:283] 	 seed: 1630541453720044
I0902 00:10:53.725754 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:10:53.726004 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:10:53.726186 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:10:53.726374 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:10:53.726539 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:10:53.726666 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:10:53.726855 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:10:53.726990 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:10:53.727153 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:10:53.770098 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:10:54.149418 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:10:54.163724 139929824643072 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:10:54.182106 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:10:54.182433 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:10:54.182651 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:10:54.182785 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:10:54.183061 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0902 00:10:54.183702 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:10:54.183906 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:10:54.184548 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:10:54.184708 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:10:54.184815 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0902 00:10:54.184953 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:10:54.185080 139929824643072 dqn_agent.py:283] 	 seed: 1630541454182038
I0902 00:10:54.213865 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:10:54.214183 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:10:54.214318 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:10:54.214489 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:10:54.214665 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:10:54.214983 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:10:54.215153 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:10:54.215382 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:10:54.215628 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:10:54.250019 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:10:54.273295 139929824643072 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:10:54.273610 139929824643072 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 158.35
I0902 00:11:00.588878 139929824643072 replay_runner.py:36] Average training steps per second: 158.35
Steps executed: 231 Episode length: 95 Return: -427.30858958170484
I0902 00:11:01.824697 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -347.64
INFO:tensorflow:Starting iteration 1

Steps executed: 272 Episode length: 164 Return: -366.67233102422654
INFO:tensorflow:Average training steps per second: 218.28
I0902 00:11:10.810658 139929824643072 replay_runner.py:36] Average training steps per second: 218.28
I0902 00:11:11.072229 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -306.53
INFO:tensorflow:Starting iteration 2

Steps executed: 233 Episode length: 233 Return: -279.07977994655005
INFO:tensorflow:Average training steps per second: 221.16
I0902 00:11:20.004772 139929824643072 replay_runner.py:36] Average training steps per second: 221.16
I0902 00:11:20.272560 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.08
INFO:tensorflow:Starting iteration 3

Steps executed: 268 Episode length: 120 Return: -510.66773078404026
INFO:tensorflow:Average training steps per second: 222.65
I0902 00:11:29.088212 139929824643072 replay_runner.py:36] Average training steps per second: 222.65
I0902 00:11:29.387845 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -472.08
INFO:tensorflow:Starting iteration 4

Steps executed: 475 Episode length: 475 Return: -580.44072026453536
INFO:tensorflow:Average training steps per second: 224.69
I0902 00:11:37.935021 139929824643072 replay_runner.py:36] Average training steps per second: 224.69
I0902 00:11:38.814496 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -580.44
INFO:tensorflow:Starting iteration 5
I0902 00:11:43.094137 139929824643072 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 223.94

Steps executed: 915 Episode length: 915 Return: -533.80002317071476
I0902 00:11:49.990942 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -533.80
INFO:tensorflow:Starting iteration 6
I0902 00:11:54.272334 139929824643072 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 232.01

Steps executed: 660 Episode length: 660 Return: -79.846497373273626
I0902 00:12:00.210402 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.85
INFO:tensorflow:Starting iteration 7
I0902 00:12:04.474456 139929824643072 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 222.96

Steps executed: 1000 Episode length: 1000 Return: -82.39863974002057
I0902 00:12:11.217455 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.40
INFO:tensorflow:Starting iteration 8

Steps executed: 472 Episode length: 472 Return: -358.746306212970557
INFO:tensorflow:Average training steps per second: 226.62
I0902 00:12:19.893891 139929824643072 replay_runner.py:36] Average training steps per second: 226.62
I0902 00:12:20.608820 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -358.75
INFO:tensorflow:Starting iteration 9

Steps executed: 332 Episode length: 153 Return: -636.470119259790657
INFO:tensorflow:Average training steps per second: 231.25
I0902 00:12:29.315223 139929824643072 replay_runner.py:36] Average training steps per second: 231.25
I0902 00:12:29.671656 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -588.10
INFO:tensorflow:Starting iteration 10

Steps executed: 306 Episode length: 306 Return: -54.8573338528071457
INFO:tensorflow:Average training steps per second: 226.90
I0902 00:12:38.205996 139929824643072 replay_runner.py:36] Average training steps per second: 226.90
I0902 00:12:38.567212 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.86
INFO:tensorflow:Starting iteration 11
I0902 00:12:42.982667 139929824643072 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 219.67

Steps executed: 1000 Episode length: 1000 Return: -100.54358271344522
I0902 00:12:51.017277 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.54
INFO:tensorflow:Starting iteration 12

Steps executed: 467 Episode length: 467 Return: -190.0224125417127522
INFO:tensorflow:Average training steps per second: 226.20
I0902 00:12:59.749040 139929824643072 replay_runner.py:36] Average training steps per second: 226.20
I0902 00:13:00.551215 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.02
INFO:tensorflow:Starting iteration 13
I0902 00:13:04.770888 139929824643072 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 218.69

Steps executed: 445 Episode length: 445 Return: -308.1799202242695522
I0902 00:13:10.018766 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.18
INFO:tensorflow:Starting iteration 14

Steps executed: 361 Episode length: 361 Return: -193.4872529421648522
INFO:tensorflow:Average training steps per second: 224.62
I0902 00:13:18.675663 139929824643072 replay_runner.py:36] Average training steps per second: 224.62
I0902 00:13:19.178525 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.49
INFO:tensorflow:Starting iteration 15

Steps executed: 433 Episode length: 433 Return: -44.09390769772821522
INFO:tensorflow:Average training steps per second: 219.33
I0902 00:13:28.108410 139929824643072 replay_runner.py:36] Average training steps per second: 219.33
I0902 00:13:28.773579 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -44.09
INFO:tensorflow:Starting iteration 16
I0902 00:13:33.155385 139929824643072 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 221.66
I0902 00:13:37.667150 139929824643072 replay_runner.py:36] Average training steps per second: 221.66

Steps executed: 875 Episode length: 875 Return: -322.1710827083255522
INFO:tensorflow:Starting iteration 17

Steps executed: 430 Episode length: 430 Return: -321.9668547518412522
INFO:tensorflow:Average training steps per second: 225.44
I0902 00:13:48.799158 139929824643072 replay_runner.py:36] Average training steps per second: 225.44
I0902 00:13:49.535639 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -321.97
INFO:tensorflow:Starting iteration 18

Steps executed: 397 Episode length: 209 Return: 4.3289577511760295822
INFO:tensorflow:Average training steps per second: 219.18
I0902 00:13:58.541184 139929824643072 replay_runner.py:36] Average training steps per second: 219.18
I0902 00:13:58.946563 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -9.09
INFO:tensorflow:Starting iteration 19
I0902 00:14:03.267127 139929824643072 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 218.93
I0902 00:14:07.835414 139929824643072 replay_runner.py:36] Average training steps per second: 218.93

Steps executed: 249 Episode length: 83 Return: -44.820643181125258822
INFO:tensorflow:Starting iteration 20

Steps executed: 275 Episode length: 140 Return: -55.11984821397263822
INFO:tensorflow:Average training steps per second: 222.40
I0902 00:14:16.969832 139929824643072 replay_runner.py:36] Average training steps per second: 222.40
I0902 00:14:17.210667 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.36
INFO:tensorflow:Starting iteration 21
I0902 00:14:21.481516 139929824643072 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 224.30

Steps executed: 841 Episode length: 841 Return: -423.2357725781969322
I0902 00:14:28.753017 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -423.24
INFO:tensorflow:Starting iteration 22
I0902 00:14:33.191915 139929824643072 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 224.28
I0902 00:14:37.651082 139929824643072 replay_runner.py:36] Average training steps per second: 224.28

Steps executed: 248 Episode length: 248 Return: 271.22783212603434322
INFO:tensorflow:Starting iteration 23

Steps executed: 279 Episode length: 84 Return: -186.31504304871526322
INFO:tensorflow:Average training steps per second: 225.58
I0902 00:14:46.716423 139929824643072 replay_runner.py:36] Average training steps per second: 225.58
I0902 00:14:47.001999 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -373.85
INFO:tensorflow:Starting iteration 24

Steps executed: 396 Episode length: 234 Return: -336.9295018378266322
INFO:tensorflow:Average training steps per second: 236.49
I0902 00:14:55.559857 139929824643072 replay_runner.py:36] Average training steps per second: 236.49
I0902 00:14:55.902026 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.54
INFO:tensorflow:Starting iteration 25
I0902 00:15:00.132709 139929824643072 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 235.62

Steps executed: 209 Episode length: 129 Return: -558.5089590621095322
I0902 00:15:04.559965 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -427.45
INFO:tensorflow:Starting iteration 26
I0902 00:15:08.818203 139929824643072 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 234.93

Steps executed: 569 Episode length: 569 Return: -486.1080933602997322
I0902 00:15:14.264622 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -486.11
INFO:tensorflow:Starting iteration 27

Steps executed: 409 Episode length: 218 Return: -29.03642385396615622
INFO:tensorflow:Average training steps per second: 237.99
I0902 00:15:22.724162 139929824643072 replay_runner.py:36] Average training steps per second: 237.99
I0902 00:15:23.145393 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.48
INFO:tensorflow:Starting iteration 28

Steps executed: 218 Episode length: 104 Return: -207.8573051811965822
INFO:tensorflow:Average training steps per second: 229.97
I0902 00:15:31.826494 139929824643072 replay_runner.py:36] Average training steps per second: 229.97
I0902 00:15:32.008020 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -433.54
INFO:tensorflow:Starting iteration 29

Steps executed: 148 Episode length: 82 Return: 2.87661131538743585822
INFO:tensorflow:Average training steps per second: 233.41

Steps executed: 1148 Episode length: 1000 Return: 34.5066755676157322

Done fixed training! Episode length: 1000 Return: 34.5066755676157322