I0828 10:50:54.476337 139825303013376 run_experiment.py:549] Creating TrainRunner ...
I0828 10:50:54.484460 139825303013376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:50:54.484586 139825303013376 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:50:54.484668 139825303013376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:50:54.484770 139825303013376 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:50:54.484827 139825303013376 dqn_agent.py:275] 	 update_period: 4
I0828 10:50:54.484882 139825303013376 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:50:54.484958 139825303013376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:50:54.485045 139825303013376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:50:54.485108 139825303013376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:50:54.485180 139825303013376 dqn_agent.py:280] 	 optimizer: adam
I0828 10:50:54.485261 139825303013376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:50:54.485323 139825303013376 dqn_agent.py:283] 	 seed: 1630147854484430
I0828 10:50:54.488120 139825303013376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:50:54.488275 139825303013376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:50:54.488376 139825303013376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:50:54.488461 139825303013376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:50:54.488535 139825303013376 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:50:54.488609 139825303013376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:50:54.488701 139825303013376 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:50:54.488788 139825303013376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:50:54.488866 139825303013376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:50:54.513922 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:50:54.756868 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:50:54.766372 139825303013376 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:50:54.772634 139825303013376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:50:54.772777 139825303013376 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:50:54.772927 139825303013376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:50:54.773012 139825303013376 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:50:54.773221 139825303013376 dqn_agent.py:275] 	 update_period: 4
I0828 10:50:54.773310 139825303013376 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:50:54.773406 139825303013376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:50:54.773508 139825303013376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:50:54.773600 139825303013376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:50:54.773691 139825303013376 dqn_agent.py:280] 	 optimizer: adam
I0828 10:50:54.773792 139825303013376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:50:54.773874 139825303013376 dqn_agent.py:283] 	 seed: 1630147854772604
I0828 10:50:54.775357 139825303013376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:50:54.775469 139825303013376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:50:54.775540 139825303013376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:50:54.775603 139825303013376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:50:54.775659 139825303013376 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:50:54.775747 139825303013376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:50:54.775821 139825303013376 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:50:54.775878 139825303013376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:50:54.775948 139825303013376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:50:54.795236 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:50:54.809803 139825303013376 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:50:54.809968 139825303013376 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
Steps executed: 327 Episode length: 173 Return: -466.55076400155866
INFO:tensorflow:Average training steps per second: 249.20
I0828 10:50:58.823200 139825303013376 replay_runner.py:36] Average training steps per second: 249.20
I0828 10:50:59.693898 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -466.40
INFO:tensorflow:Starting iteration 1

Steps executed: 121 Episode length: 121 Return: -257.42589234382026
INFO:tensorflow:Average training steps per second: 352.52

Steps executed: 250 Episode length: 129 Return: -397.86879898996586
I0828 10:51:06.153000 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.65
INFO:tensorflow:Starting iteration 2

Steps executed: 242 Episode length: 146 Return: -365.07692134287686
INFO:tensorflow:Average training steps per second: 346.77
I0828 10:51:12.546859 139825303013376 replay_runner.py:36] Average training steps per second: 346.77
I0828 10:51:12.698928 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -322.02
INFO:tensorflow:Starting iteration 3

Steps executed: 320 Episode length: 128 Return: -279.12131306112622
INFO:tensorflow:Average training steps per second: 341.35
I0828 10:51:19.077382 139825303013376 replay_runner.py:36] Average training steps per second: 341.35
I0828 10:51:19.258815 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -323.55
INFO:tensorflow:Starting iteration 4

Steps executed: 242 Episode length: 93 Return: -329.175405939616576
INFO:tensorflow:Average training steps per second: 340.47
I0828 10:51:25.617527 139825303013376 replay_runner.py:36] Average training steps per second: 340.47
I0828 10:51:25.771588 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.42
INFO:tensorflow:Starting iteration 5

Steps executed: 122 Episode length: 122 Return: -412.46742716153585
INFO:tensorflow:Average training steps per second: 342.75
I0828 10:51:32.143103 139825303013376 replay_runner.py:36] Average training steps per second: 342.75

Steps executed: 235 Episode length: 113 Return: -313.97093728773225
INFO:tensorflow:Starting iteration 6

Steps executed: 273 Episode length: 126 Return: -373.08886540228835
INFO:tensorflow:Average training steps per second: 342.27
I0828 10:51:38.632377 139825303013376 replay_runner.py:36] Average training steps per second: 342.27
I0828 10:51:38.801673 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.65
INFO:tensorflow:Starting iteration 7

Steps executed: 232 Episode length: 147 Return: -220.81837249025557
INFO:tensorflow:Average training steps per second: 341.03
I0828 10:51:45.196988 139825303013376 replay_runner.py:36] Average training steps per second: 341.03
I0828 10:51:45.325335 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.86
INFO:tensorflow:Starting iteration 8

Steps executed: 270 Episode length: 138 Return: -383.71255774894637
INFO:tensorflow:Average training steps per second: 333.21
I0828 10:51:51.810636 139825303013376 replay_runner.py:36] Average training steps per second: 333.21
I0828 10:51:51.970763 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -371.89
INFO:tensorflow:Starting iteration 9
I0828 10:51:55.419830 139825303013376 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 330.43

Steps executed: 319 Episode length: 136 Return: -338.01747808692434
I0828 10:51:58.627635 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -318.95
INFO:tensorflow:Starting iteration 10

Steps executed: 282 Episode length: 153 Return: -408.41894491056984
INFO:tensorflow:Average training steps per second: 332.58
I0828 10:52:05.063337 139825303013376 replay_runner.py:36] Average training steps per second: 332.58
I0828 10:52:05.227618 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -386.55
INFO:tensorflow:Starting iteration 11

Steps executed: 317 Episode length: 171 Return: -431.36589174286864
INFO:tensorflow:Average training steps per second: 329.14
I0828 10:52:11.714879 139825303013376 replay_runner.py:36] Average training steps per second: 329.14
I0828 10:52:11.900289 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -469.47
INFO:tensorflow:Starting iteration 12

Steps executed: 269 Episode length: 147 Return: -414.50880714425904
INFO:tensorflow:Average training steps per second: 328.59
I0828 10:52:18.328843 139825303013376 replay_runner.py:36] Average training steps per second: 328.59
I0828 10:52:18.480119 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -368.17
INFO:tensorflow:Starting iteration 13

Steps executed: 305 Episode length: 149 Return: -214.40106919169696
INFO:tensorflow:Average training steps per second: 331.60
I0828 10:52:24.893856 139825303013376 replay_runner.py:36] Average training steps per second: 331.60
I0828 10:52:25.080110 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.18
INFO:tensorflow:Starting iteration 14

Steps executed: 532 Episode length: 337 Return: -328.52408466001964
INFO:tensorflow:Average training steps per second: 328.61
I0828 10:52:31.534651 139825303013376 replay_runner.py:36] Average training steps per second: 328.61
I0828 10:52:31.961448 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -350.26
INFO:tensorflow:Starting iteration 15

Steps executed: 320 Episode length: 153 Return: -144.42018056153148
INFO:tensorflow:Average training steps per second: 330.13
I0828 10:52:38.410207 139825303013376 replay_runner.py:36] Average training steps per second: 330.13
I0828 10:52:38.588611 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.13
INFO:tensorflow:Starting iteration 16

Steps executed: 250 Episode length: 154 Return: -302.53464983517958
INFO:tensorflow:Average training steps per second: 340.61
I0828 10:52:44.955987 139825303013376 replay_runner.py:36] Average training steps per second: 340.61
I0828 10:52:45.094768 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -420.39
INFO:tensorflow:Starting iteration 17

Steps executed: 204 Episode length: 104 Return: -375.13544620949137
INFO:tensorflow:Average training steps per second: 334.18
I0828 10:52:51.586852 139825303013376 replay_runner.py:36] Average training steps per second: 334.18
I0828 10:52:51.694547 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -320.71
INFO:tensorflow:Starting iteration 18

Steps executed: 364 Episode length: 205 Return: -27.990427386056766
INFO:tensorflow:Average training steps per second: 339.99
I0828 10:52:58.060890 139825303013376 replay_runner.py:36] Average training steps per second: 339.99
I0828 10:52:58.311903 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -19.58
INFO:tensorflow:Starting iteration 19

Steps executed: 272 Episode length: 169 Return: -66.670979568845385
INFO:tensorflow:Average training steps per second: 338.19
I0828 10:53:04.723804 139825303013376 replay_runner.py:36] Average training steps per second: 338.19
I0828 10:53:04.909197 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.90
INFO:tensorflow:Starting iteration 20

Steps executed: 267 Episode length: 85 Return: -70.2754081511977155
INFO:tensorflow:Average training steps per second: 345.01
I0828 10:53:11.296169 139825303013376 replay_runner.py:36] Average training steps per second: 345.01
I0828 10:53:11.458020 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.21
INFO:tensorflow:Starting iteration 21

Steps executed: 214 Episode length: 102 Return: -55.209574501466295
INFO:tensorflow:Average training steps per second: 338.71
I0828 10:53:17.915420 139825303013376 replay_runner.py:36] Average training steps per second: 338.71
I0828 10:53:18.052825 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -64.88
INFO:tensorflow:Starting iteration 22
I0828 10:53:21.525099 139825303013376 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 341.69

Steps executed: 1000 Episode length: 1000 Return: -47.550357584325475
I0828 10:53:26.645795 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -47.55
INFO:tensorflow:Starting iteration 23

Steps executed: 600 Episode length: 456 Return: -683.4276152129352475
INFO:tensorflow:Average training steps per second: 330.71
I0828 10:53:33.084295 139825303013376 replay_runner.py:36] Average training steps per second: 330.71
I0828 10:53:33.698229 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -610.16
INFO:tensorflow:Starting iteration 24
I0828 10:53:37.075384 139825303013376 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 325.88

Steps executed: 1000 Episode length: 1000 Return: -34.658176908370045
I0828 10:53:41.867727 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -34.66
INFO:tensorflow:Starting iteration 25

Steps executed: 300 Episode length: 114 Return: -707.0176057997859045
INFO:tensorflow:Average training steps per second: 338.34
I0828 10:53:48.266195 139825303013376 replay_runner.py:36] Average training steps per second: 338.34
I0828 10:53:48.466234 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -490.44
INFO:tensorflow:Starting iteration 26
I0828 10:53:51.898192 139825303013376 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 346.22

Steps executed: 283 Episode length: 169 Return: -49.68450548606166045
I0828 10:53:54.969106 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.69
INFO:tensorflow:Starting iteration 27
I0828 10:53:58.338367 139825303013376 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 361.93

Steps executed: 1000 Episode length: 1000 Return: -20.797774530943467
I0828 10:54:03.193339 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -20.80
INFO:tensorflow:Starting iteration 28

Steps executed: 275 Episode length: 129 Return: 42.084204951658286467
INFO:tensorflow:Average training steps per second: 347.78
I0828 10:54:09.264994 139825303013376 replay_runner.py:36] Average training steps per second: 347.78
I0828 10:54:09.436951 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.84
INFO:tensorflow:Starting iteration 29

Steps executed: 454 Episode length: 368 Return: -279.1059442560703467
INFO:tensorflow:Average training steps per second: 357.46
I0828 10:54:15.591110 139825303013376 replay_runner.py:36] Average training steps per second: 357.46

Done fixed training!Episode length: 368 Return: -279.1059442560703467