I0903 00:15:37.223632 139900407642112 run_experiment.py:549] Creating TrainRunner ...
I0903 00:15:37.230555 139900407642112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:15:37.230667 139900407642112 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:15:37.230728 139900407642112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:15:37.230802 139900407642112 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:15:37.230856 139900407642112 dqn_agent.py:275] 	 update_period: 4
I0903 00:15:37.230905 139900407642112 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:15:37.230987 139900407642112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:15:37.231081 139900407642112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:15:37.231154 139900407642112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:15:37.231216 139900407642112 dqn_agent.py:280] 	 optimizer: adam
I0903 00:15:37.231288 139900407642112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:15:37.231359 139900407642112 dqn_agent.py:283] 	 seed: 1630628137230528
I0903 00:15:37.232897 139900407642112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:15:37.233013 139900407642112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:15:37.233085 139900407642112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:15:37.233146 139900407642112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:15:37.233202 139900407642112 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:15:37.233271 139900407642112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:15:37.233329 139900407642112 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:15:37.233412 139900407642112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:15:37.233479 139900407642112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:15:37.254811 139900407642112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:15:37.469477 139900407642112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:15:37.477869 139900407642112 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:15:37.483759 139900407642112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:15:37.483898 139900407642112 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:15:37.483976 139900407642112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:15:37.484035 139900407642112 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:15:37.484091 139900407642112 dqn_agent.py:275] 	 update_period: 4
I0903 00:15:37.484161 139900407642112 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:15:37.484217 139900407642112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:15:37.484302 139900407642112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:15:37.484382 139900407642112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:15:37.484438 139900407642112 dqn_agent.py:280] 	 optimizer: adam
I0903 00:15:37.484503 139900407642112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:15:37.484568 139900407642112 dqn_agent.py:283] 	 seed: 1630628137483732
I0903 00:15:37.485897 139900407642112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:15:37.486011 139900407642112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:15:37.486079 139900407642112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:15:37.486140 139900407642112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:15:37.486200 139900407642112 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:15:37.486252 139900407642112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:15:37.486320 139900407642112 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:15:37.486399 139900407642112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:15:37.486464 139900407642112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:15:37.504286 139900407642112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:15:37.517195 139900407642112 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:15:37.517324 139900407642112 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 243.34
I0903 00:15:41.626913 139900407642112 replay_runner.py:36] Average training steps per second: 243.34
I0903 00:15:42.462349 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.16
Steps executed: 374 Episode length: 180 Return: -89.877053705211244
INFO:tensorflow:Starting iteration 1
I0903 00:15:45.711866 139900407642112 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 330.16


Steps executed: 265 Episode length: 97 Return: -496.118369805706834
I0903 00:15:48.872392 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -564.92
INFO:tensorflow:Starting iteration 2

Steps executed: 210 Episode length: 86 Return: -556.224393330971237
INFO:tensorflow:Average training steps per second: 343.74
I0903 00:15:55.122738 139900407642112 replay_runner.py:36] Average training steps per second: 343.74
I0903 00:15:55.248235 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -522.26
INFO:tensorflow:Starting iteration 3
I0903 00:15:58.658091 139900407642112 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 329.81
I0903 00:16:01.690484 139900407642112 replay_runner.py:36] Average training steps per second: 329.81

Steps executed: 214 Episode length: 214 Return: -377.40369948476337
INFO:tensorflow:Starting iteration 4

Steps executed: 232 Episode length: 100 Return: -412.18930671792833
INFO:tensorflow:Average training steps per second: 336.90
I0903 00:16:08.130671 139900407642112 replay_runner.py:36] Average training steps per second: 336.90
I0903 00:16:08.255304 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -358.94
INFO:tensorflow:Starting iteration 5

Steps executed: 176 Episode length: 91 Return: -643.332508391770133
INFO:tensorflow:Average training steps per second: 336.48

Steps executed: 594 Episode length: 418 Return: -425.22021221787816
I0903 00:16:15.138976 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -581.53
INFO:tensorflow:Starting iteration 6

Steps executed: 396 Episode length: 207 Return: -592.80268873942426
INFO:tensorflow:Average training steps per second: 331.77
I0903 00:16:21.534815 139900407642112 replay_runner.py:36] Average training steps per second: 331.77
I0903 00:16:21.828608 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -624.99
INFO:tensorflow:Starting iteration 7

Steps executed: 522 Episode length: 522 Return: -413.03588822261126
INFO:tensorflow:Average training steps per second: 344.13
I0903 00:16:28.108160 139900407642112 replay_runner.py:36] Average training steps per second: 344.13
I0903 00:16:28.715857 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -413.04
INFO:tensorflow:Starting iteration 8

Steps executed: 1000 Episode length: 1000 Return: -316.5177761687863
INFO:tensorflow:Average training steps per second: 329.37
I0903 00:16:35.148949 139900407642112 replay_runner.py:36] Average training steps per second: 329.37
I0903 00:16:36.622902 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -316.52
INFO:tensorflow:Starting iteration 9

Steps executed: 253 Episode length: 60 Return: -571.0753474233059863
INFO:tensorflow:Average training steps per second: 334.20
I0903 00:16:43.002588 139900407642112 replay_runner.py:36] Average training steps per second: 334.20
I0903 00:16:43.131312 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -548.49
INFO:tensorflow:Starting iteration 10

Steps executed: 239 Episode length: 122 Return: -441.305622765416163
INFO:tensorflow:Average training steps per second: 324.89
I0903 00:16:49.580760 139900407642112 replay_runner.py:36] Average training steps per second: 324.89
I0903 00:16:49.732733 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.26
INFO:tensorflow:Starting iteration 11
I0903 00:16:53.029444 139900407642112 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 318.29

Steps executed: 1000 Episode length: 1000 Return: -76.22671905866501
I0903 00:16:57.702148 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.23
INFO:tensorflow:Starting iteration 12

Steps executed: 357 Episode length: 357 Return: -348.271447376780431
INFO:tensorflow:Average training steps per second: 331.35
I0903 00:17:04.132429 139900407642112 replay_runner.py:36] Average training steps per second: 331.35
I0903 00:17:04.447128 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -348.27
INFO:tensorflow:Starting iteration 13
I0903 00:17:07.898773 139900407642112 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 334.48

Steps executed: 1000 Episode length: 1000 Return: -184.2718755226867
I0903 00:17:12.593027 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.27
INFO:tensorflow:Starting iteration 14

Steps executed: 314 Episode length: 314 Return: -1431.82967170406167
INFO:tensorflow:Average training steps per second: 351.50
I0903 00:17:18.935265 139900407642112 replay_runner.py:36] Average training steps per second: 351.50
I0903 00:17:19.246095 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -1431.83
INFO:tensorflow:Starting iteration 15

Steps executed: 218 Episode length: 78 Return: -411.2081726894495567
INFO:tensorflow:Average training steps per second: 359.62
I0903 00:17:25.533420 139900407642112 replay_runner.py:36] Average training steps per second: 359.62
I0903 00:17:25.648919 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -433.24
INFO:tensorflow:Starting iteration 16

Steps executed: 298 Episode length: 298 Return: -502.151723962204247
INFO:tensorflow:Average training steps per second: 349.71
I0903 00:17:31.991220 139900407642112 replay_runner.py:36] Average training steps per second: 349.71
I0903 00:17:32.219850 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.15
INFO:tensorflow:Starting iteration 17

Steps executed: 265 Episode length: 265 Return: -571.455197745388747
INFO:tensorflow:Average training steps per second: 314.95
I0903 00:17:38.814495 139900407642112 replay_runner.py:36] Average training steps per second: 314.95
I0903 00:17:38.982644 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -571.46
INFO:tensorflow:Starting iteration 18

Steps executed: 337 Episode length: 178 Return: 18.47322647220741537
INFO:tensorflow:Average training steps per second: 344.98
I0903 00:17:45.322216 139900407642112 replay_runner.py:36] Average training steps per second: 344.98
I0903 00:17:45.515991 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.72
INFO:tensorflow:Starting iteration 19

Steps executed: 247 Episode length: 122 Return: -290.460900437951647
INFO:tensorflow:Average training steps per second: 334.43
I0903 00:17:51.969412 139900407642112 replay_runner.py:36] Average training steps per second: 334.43
I0903 00:17:52.094679 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -312.01
INFO:tensorflow:Starting iteration 20

Steps executed: 224 Episode length: 47 Return: -184.5538533280342877
INFO:tensorflow:Average training steps per second: 318.59
I0903 00:17:58.605131 139900407642112 replay_runner.py:36] Average training steps per second: 318.59
I0903 00:17:58.722464 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -446.99
INFO:tensorflow:Starting iteration 21
I0903 00:18:02.041167 139900407642112 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 319.89
I0903 00:18:05.167558 139900407642112 replay_runner.py:36] Average training steps per second: 319.89

Steps executed: 276 Episode length: 115 Return: -316.298565004015167
INFO:tensorflow:Starting iteration 22

Steps executed: 270 Episode length: 174 Return: -886.528323702952767
INFO:tensorflow:Average training steps per second: 316.23
I0903 00:18:11.809467 139900407642112 replay_runner.py:36] Average training steps per second: 316.23
I0903 00:18:11.969064 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -530.41
INFO:tensorflow:Starting iteration 23

Steps executed: 210 Episode length: 82 Return: -869.0915949712843767
INFO:tensorflow:Average training steps per second: 314.10
I0903 00:18:18.476282 139900407642112 replay_runner.py:36] Average training steps per second: 314.10
I0903 00:18:18.593879 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -601.66
INFO:tensorflow:Starting iteration 24

Steps executed: 207 Episode length: 97 Return: -146.0978434211201667
INFO:tensorflow:Average training steps per second: 308.95
I0903 00:18:25.113880 139900407642112 replay_runner.py:36] Average training steps per second: 308.95
I0903 00:18:25.205389 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.01
INFO:tensorflow:Starting iteration 25

Steps executed: 244 Episode length: 82 Return: -652.3092400610832667
INFO:tensorflow:Average training steps per second: 315.82
I0903 00:18:31.648455 139900407642112 replay_runner.py:36] Average training steps per second: 315.82
I0903 00:18:31.796563 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -700.84
INFO:tensorflow:Starting iteration 26

Steps executed: 274 Episode length: 84 Return: -822.3719169603393667
INFO:tensorflow:Average training steps per second: 310.22
I0903 00:18:38.277777 139900407642112 replay_runner.py:36] Average training steps per second: 310.22
I0903 00:18:38.435564 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -520.46
INFO:tensorflow:Starting iteration 27

Steps executed: 213 Episode length: 65 Return: -157.6733485856628467
INFO:tensorflow:Average training steps per second: 315.23
I0903 00:18:44.875715 139900407642112 replay_runner.py:36] Average training steps per second: 315.23
I0903 00:18:44.990256 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.32
INFO:tensorflow:Starting iteration 28

Steps executed: 223 Episode length: 80 Return: -790.1477565748748467
INFO:tensorflow:Average training steps per second: 318.57
I0903 00:18:51.325939 139900407642112 replay_runner.py:36] Average training steps per second: 318.57
I0903 00:18:51.467364 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -717.65
INFO:tensorflow:Starting iteration 29

Steps executed: 250 Episode length: 51 Return: -339.2167465473054367
INFO:tensorflow:Average training steps per second: 316.90
I0903 00:18:57.843692 139900407642112 replay_runner.py:36] Average training steps per second: 316.90

Done fixed training!Episode length: 51 Return: -339.2167465473054367