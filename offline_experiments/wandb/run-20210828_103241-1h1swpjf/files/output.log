Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0828 10:32:48.302149 139821415028736 run_experiment.py:549] Creating TrainRunner ...
I0828 10:32:48.313138 139821415028736 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:48.313442 139821415028736 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:48.313660 139821415028736 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:48.313790 139821415028736 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:48.313903 139821415028736 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:48.314098 139821415028736 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:48.314239 139821415028736 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:48.314403 139821415028736 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:48.314534 139821415028736 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:48.314656 139821415028736 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:48.314790 139821415028736 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:48.314957 139821415028736 dqn_agent.py:283] 	 seed: 1630146768313077
I0828 10:32:48.318221 139821415028736 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:48.318436 139821415028736 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:48.318600 139821415028736 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:48.318989 139821415028736 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:48.319156 139821415028736 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:48.319289 139821415028736 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:48.319573 139821415028736 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:48.319705 139821415028736 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:48.319838 139821415028736 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:48.357659 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:48.709618 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:48.723906 139821415028736 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:32:48.732633 139821415028736 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:48.732967 139821415028736 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:48.733184 139821415028736 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:48.733379 139821415028736 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:48.733532 139821415028736 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:48.733656 139821415028736 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:48.733779 139821415028736 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:48.733879 139821415028736 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:48.734200 139821415028736 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:48.734363 139821415028736 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:48.734499 139821415028736 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:48.734635 139821415028736 dqn_agent.py:283] 	 seed: 1630146768732565
I0828 10:32:48.738036 139821415028736 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:48.738248 139821415028736 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:48.738417 139821415028736 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:48.738552 139821415028736 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:48.738679 139821415028736 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:48.738763 139821415028736 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:48.739059 139821415028736 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:48.739279 139821415028736 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:48.739379 139821415028736 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:48.769228 139821415028736 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:48.824338 139821415028736 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:32:48.824598 139821415028736 replay_runner.py:41] Starting iteration 0
Steps executed: 77 Episode length: 77 Return: -251.6258306115518
INFO:tensorflow:Average training steps per second: 168.10
I0828 10:32:54.773901 139821415028736 replay_runner.py:36] Average training steps per second: 168.10

Steps executed: 218 Episode length: 61 Return: -140.37596267909692
INFO:tensorflow:Starting iteration 1

Steps executed: 204 Episode length: 58 Return: -430.82016309145575
INFO:tensorflow:Average training steps per second: 225.86
I0828 10:33:04.562823 139821415028736 replay_runner.py:36] Average training steps per second: 225.86
I0828 10:33:04.749319 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -499.02
INFO:tensorflow:Starting iteration 2

Steps executed: 300 Episode length: 103 Return: -313.03428330339864
INFO:tensorflow:Average training steps per second: 221.02
I0828 10:33:13.621668 139821415028736 replay_runner.py:36] Average training steps per second: 221.02
I0828 10:33:13.861956 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.93
INFO:tensorflow:Starting iteration 3

Steps executed: 234 Episode length: 58 Return: -221.626679637353574
INFO:tensorflow:Average training steps per second: 227.81
I0828 10:33:22.316647 139821415028736 replay_runner.py:36] Average training steps per second: 227.81
I0828 10:33:22.572767 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.04
INFO:tensorflow:Starting iteration 4

Steps executed: 206 Episode length: 73 Return: -349.245293491032674
INFO:tensorflow:Average training steps per second: 231.73
I0828 10:33:31.073232 139821415028736 replay_runner.py:36] Average training steps per second: 231.73
I0828 10:33:31.224689 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -337.26
INFO:tensorflow:Starting iteration 5

Steps executed: 209 Episode length: 58 Return: -346.061518538496674
INFO:tensorflow:Average training steps per second: 227.03
I0828 10:33:39.909406 139821415028736 replay_runner.py:36] Average training steps per second: 227.03
I0828 10:33:40.062874 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -351.76
INFO:tensorflow:Starting iteration 6

Steps executed: 277 Episode length: 108 Return: -387.66085015811007
INFO:tensorflow:Average training steps per second: 226.26
I0828 10:33:48.776743 139821415028736 replay_runner.py:36] Average training steps per second: 226.26
I0828 10:33:49.004434 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -367.68
INFO:tensorflow:Starting iteration 7

Steps executed: 264 Episode length: 93 Return: -258.006249395063047
INFO:tensorflow:Average training steps per second: 229.86
I0828 10:33:57.644109 139821415028736 replay_runner.py:36] Average training steps per second: 229.86
I0828 10:33:57.816974 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -172.30
INFO:tensorflow:Starting iteration 8

Steps executed: 233 Episode length: 84 Return: -148.900579741485447
INFO:tensorflow:Average training steps per second: 234.37
I0828 10:34:06.309750 139821415028736 replay_runner.py:36] Average training steps per second: 234.37
I0828 10:34:06.503051 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.45
INFO:tensorflow:Starting iteration 9

Steps executed: 270 Episode length: 91 Return: -237.789541004919397
INFO:tensorflow:Average training steps per second: 224.19
I0828 10:34:15.091573 139821415028736 replay_runner.py:36] Average training steps per second: 224.19
I0828 10:34:15.338137 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.52
INFO:tensorflow:Starting iteration 10

Steps executed: 226 Episode length: 70 Return: -92.6299765872944667
INFO:tensorflow:Average training steps per second: 223.81
I0828 10:34:24.043997 139821415028736 replay_runner.py:36] Average training steps per second: 223.81
I0828 10:34:24.190130 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.89
INFO:tensorflow:Starting iteration 11

Steps executed: 276 Episode length: 79 Return: -161.708844606062337
INFO:tensorflow:Average training steps per second: 218.14
I0828 10:34:33.131666 139821415028736 replay_runner.py:36] Average training steps per second: 218.14
I0828 10:34:33.331446 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.29
INFO:tensorflow:Starting iteration 12

Steps executed: 186 Episode length: 102 Return: -215.65114932142518
INFO:tensorflow:Average training steps per second: 219.43

Steps executed: 361 Episode length: 175 Return: -554.44870355634438
I0828 10:34:42.572415 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -395.37
INFO:tensorflow:Starting iteration 13

Steps executed: 277 Episode length: 109 Return: -561.61270392928088
INFO:tensorflow:Average training steps per second: 222.03
I0828 10:34:51.403952 139821415028736 replay_runner.py:36] Average training steps per second: 222.03
I0828 10:34:51.635468 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.01
INFO:tensorflow:Starting iteration 14
I0828 10:34:55.922461 139821415028736 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 221.39

Steps executed: 202 Episode length: 110 Return: -640.01649484434858
I0828 10:35:00.649447 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -512.57
INFO:tensorflow:Starting iteration 15

Steps executed: 201 Episode length: 61 Return: -516.484311976580668
INFO:tensorflow:Average training steps per second: 223.02
I0828 10:35:09.345710 139821415028736 replay_runner.py:36] Average training steps per second: 223.02
I0828 10:35:09.514087 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -478.33
INFO:tensorflow:Starting iteration 16

Steps executed: 211 Episode length: 211 Return: -331.20154548511868
INFO:tensorflow:Average training steps per second: 224.84
I0828 10:35:18.189638 139821415028736 replay_runner.py:36] Average training steps per second: 224.84
I0828 10:35:18.389936 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.20
INFO:tensorflow:Starting iteration 17

Steps executed: 209 Episode length: 53 Return: -103.015443556772078
INFO:tensorflow:Average training steps per second: 228.43
I0828 10:35:27.068226 139821415028736 replay_runner.py:36] Average training steps per second: 228.43
I0828 10:35:27.226424 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.51
INFO:tensorflow:Starting iteration 18

Steps executed: 259 Episode length: 84 Return: -105.315062168380218
INFO:tensorflow:Average training steps per second: 226.47
I0828 10:35:36.023829 139821415028736 replay_runner.py:36] Average training steps per second: 226.47
I0828 10:35:36.290287 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.92
INFO:tensorflow:Starting iteration 19

Steps executed: 255 Episode length: 62 Return: -673.701734546670818
INFO:tensorflow:Average training steps per second: 222.44
I0828 10:35:45.126575 139821415028736 replay_runner.py:36] Average training steps per second: 222.44
I0828 10:35:45.361039 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -585.94
INFO:tensorflow:Starting iteration 20

Steps executed: 193 Episode length: 98 Return: -622.666377061922718
INFO:tensorflow:Average training steps per second: 229.61
I0828 10:35:54.021607 139821415028736 replay_runner.py:36] Average training steps per second: 229.61

Steps executed: 303 Episode length: 110 Return: -632.23952999101318
INFO:tensorflow:Starting iteration 21

Steps executed: 213 Episode length: 75 Return: -573.942528056404118
INFO:tensorflow:Average training steps per second: 224.33
I0828 10:36:03.049010 139821415028736 replay_runner.py:36] Average training steps per second: 224.33
I0828 10:36:03.230836 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -656.04
INFO:tensorflow:Starting iteration 22

Steps executed: 172 Episode length: 172 Return: -372.63071757866965
INFO:tensorflow:Average training steps per second: 229.84
I0828 10:36:11.938837 139821415028736 replay_runner.py:36] Average training steps per second: 229.84

Steps executed: 408 Episode length: 236 Return: -638.29884249514735
INFO:tensorflow:Starting iteration 23

Steps executed: 274 Episode length: 77 Return: -503.704517558435955
INFO:tensorflow:Average training steps per second: 231.90
I0828 10:36:20.907795 139821415028736 replay_runner.py:36] Average training steps per second: 231.90
I0828 10:36:21.169404 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -535.94
INFO:tensorflow:Starting iteration 24

Steps executed: 200 Episode length: 62 Return: -631.377289221321755
INFO:tensorflow:Average training steps per second: 238.37
I0828 10:36:29.846274 139821415028736 replay_runner.py:36] Average training steps per second: 238.37
I0828 10:36:30.011805 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -604.99
INFO:tensorflow:Starting iteration 25

Steps executed: 394 Episode length: 211 Return: -433.64306532834915
INFO:tensorflow:Average training steps per second: 225.19
I0828 10:36:38.750591 139821415028736 replay_runner.py:36] Average training steps per second: 225.19
I0828 10:36:39.091381 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.12
INFO:tensorflow:Starting iteration 26

Steps executed: 320 Episode length: 150 Return: -687.28558368885192
INFO:tensorflow:Average training steps per second: 228.02
I0828 10:36:47.733676 139821415028736 replay_runner.py:36] Average training steps per second: 228.02
I0828 10:36:48.095400 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -922.41
INFO:tensorflow:Starting iteration 27

Steps executed: 204 Episode length: 117 Return: -878.78656438261452
INFO:tensorflow:Average training steps per second: 228.51
I0828 10:36:56.833748 139821415028736 replay_runner.py:36] Average training steps per second: 228.51
I0828 10:36:57.031327 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -734.25
INFO:tensorflow:Starting iteration 28

Steps executed: 276 Episode length: 94 Return: -456.236780789207052
INFO:tensorflow:Average training steps per second: 239.14
I0828 10:37:05.538232 139821415028736 replay_runner.py:36] Average training steps per second: 239.14
I0828 10:37:05.794952 139821415028736 run_experiment.py:428] Average undiscounted return per evaluation episode: -532.08
INFO:tensorflow:Starting iteration 29

Steps executed: 221 Episode length: 98 Return: -731.185545246470652
INFO:tensorflow:Average training steps per second: 251.47
I0828 10:37:14.099947 139821415028736 replay_runner.py:36] Average training steps per second: 251.47

Done fixed training!Episode length: 98 Return: -731.185545246470652