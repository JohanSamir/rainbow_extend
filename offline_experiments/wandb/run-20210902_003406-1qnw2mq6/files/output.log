I0902 00:34:12.548284 140413705484288 run_experiment.py:549] Creating TrainRunner ...
I0902 00:34:12.556963 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:34:12.557083 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:34:12.557149 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:34:12.557204 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:34:12.557254 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0902 00:34:12.557322 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:34:12.557397 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:34:12.557456 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:34:12.557527 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:34:12.557589 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0902 00:34:12.557646 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:34:12.557721 140413705484288 dqn_agent.py:283] 	 seed: 1630542852556929
I0902 00:34:12.560009 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:34:12.560219 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:34:12.560327 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:34:12.560420 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:34:12.560516 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:34:12.560635 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:34:12.560723 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:34:12.560797 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:34:12.560891 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:34:12.586864 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:34:12.853137 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:34:12.863426 140413705484288 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:34:12.870492 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:34:12.870692 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:34:12.870795 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:34:12.870876 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:34:12.870973 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0902 00:34:12.871086 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:34:12.871142 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:34:12.871222 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:34:12.871342 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:34:12.871502 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0902 00:34:12.871608 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:34:12.871707 140413705484288 dqn_agent.py:283] 	 seed: 1630542852870444
I0902 00:34:12.873804 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:34:12.873919 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:34:12.874025 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:34:12.874103 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:34:12.874197 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:34:12.874253 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:34:12.874305 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:34:12.874377 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:34:12.874446 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:34:12.894708 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:34:12.909614 140413705484288 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:34:12.909782 140413705484288 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
Steps executed: 223 Episode length: 58 Return: -389.2505630290171
INFO:tensorflow:Average training steps per second: 249.33
I0902 00:34:16.920733 140413705484288 replay_runner.py:36] Average training steps per second: 249.33
I0902 00:34:17.659248 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -488.59
INFO:tensorflow:Starting iteration 1

Steps executed: 272 Episode length: 98 Return: -396.797116252954556
INFO:tensorflow:Average training steps per second: 339.10
I0902 00:34:23.927450 140413705484288 replay_runner.py:36] Average training steps per second: 339.10
I0902 00:34:24.098728 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -414.57
INFO:tensorflow:Starting iteration 2

Steps executed: 261 Episode length: 137 Return: -768.63958122027886
INFO:tensorflow:Average training steps per second: 335.24
I0902 00:34:30.364794 140413705484288 replay_runner.py:36] Average training steps per second: 335.24
I0902 00:34:30.533899 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -765.37
INFO:tensorflow:Starting iteration 3
I0902 00:34:33.905548 140413705484288 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 354.61
I0902 00:34:36.726145 140413705484288 replay_runner.py:36] Average training steps per second: 354.61

Steps executed: 264 Episode length: 97 Return: -120.003112397149866
INFO:tensorflow:Starting iteration 4

Steps executed: 460 Episode length: 277 Return: -341.47443090895156
INFO:tensorflow:Average training steps per second: 358.50
I0902 00:34:42.902490 140413705484288 replay_runner.py:36] Average training steps per second: 358.50
I0902 00:34:43.277873 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -401.64
INFO:tensorflow:Starting iteration 5

Steps executed: 235 Episode length: 235 Return: -468.33162084264276
INFO:tensorflow:Average training steps per second: 356.56
I0902 00:34:49.373708 140413705484288 replay_runner.py:36] Average training steps per second: 356.56
I0902 00:34:49.568208 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -468.33
INFO:tensorflow:Starting iteration 6

Steps executed: 236 Episode length: 132 Return: -423.19662531346086
INFO:tensorflow:Average training steps per second: 355.37
I0902 00:34:55.841917 140413705484288 replay_runner.py:36] Average training steps per second: 355.37
I0902 00:34:55.976958 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -488.91
INFO:tensorflow:Starting iteration 7
I0902 00:34:59.349559 140413705484288 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 341.51

Steps executed: 372 Episode length: 372 Return: -206.04966225436362
I0902 00:35:02.676519 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.05
INFO:tensorflow:Starting iteration 8

Steps executed: 398 Episode length: 398 Return: -287.08337361787767
INFO:tensorflow:Average training steps per second: 336.71
I0902 00:35:08.968688 140413705484288 replay_runner.py:36] Average training steps per second: 336.71
I0902 00:35:09.367494 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.08
INFO:tensorflow:Starting iteration 9

Steps executed: 222 Episode length: 222 Return: -276.09126057321257
INFO:tensorflow:Average training steps per second: 337.59
I0902 00:35:15.712649 140413705484288 replay_runner.py:36] Average training steps per second: 337.59
I0902 00:35:15.869977 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.09
INFO:tensorflow:Starting iteration 10
I0902 00:35:19.259417 140413705484288 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 343.86

Steps executed: 1000 Episode length: 1000 Return: -341.6347463000761
I0902 00:35:23.748486 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.63
INFO:tensorflow:Starting iteration 11

Steps executed: 331 Episode length: 219 Return: -157.590865567890721
INFO:tensorflow:Average training steps per second: 343.90
I0902 00:35:30.141809 140413705484288 replay_runner.py:36] Average training steps per second: 343.90
I0902 00:35:30.342736 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.48
INFO:tensorflow:Starting iteration 12
I0902 00:35:33.788640 140413705484288 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 350.59

Steps executed: 290 Episode length: 99 Return: -290.7642273990412621
I0902 00:35:36.804098 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.80
INFO:tensorflow:Starting iteration 13

Steps executed: 348 Episode length: 187 Return: -403.481506047596861
INFO:tensorflow:Average training steps per second: 325.27
I0902 00:35:43.309502 140413705484288 replay_runner.py:36] Average training steps per second: 325.27
I0902 00:35:43.504992 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -302.97
INFO:tensorflow:Starting iteration 14

Steps executed: 213 Episode length: 86 Return: -241.4738137536727261
INFO:tensorflow:Average training steps per second: 340.04
I0902 00:35:49.777115 140413705484288 replay_runner.py:36] Average training steps per second: 340.04
I0902 00:35:49.866654 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -238.84
INFO:tensorflow:Starting iteration 15

Steps executed: 228 Episode length: 81 Return: -265.8316818080968561
INFO:tensorflow:Average training steps per second: 326.57
I0902 00:35:56.229681 140413705484288 replay_runner.py:36] Average training steps per second: 326.57
I0902 00:35:56.337836 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.37
INFO:tensorflow:Starting iteration 16
I0902 00:35:59.635992 140413705484288 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 326.14

Steps executed: 326 Episode length: 132 Return: -247.772722459546511
I0902 00:36:02.907341 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.77
INFO:tensorflow:Starting iteration 17

Steps executed: 275 Episode length: 129 Return: -789.926452723682511
INFO:tensorflow:Average training steps per second: 335.06
I0902 00:36:09.194464 140413705484288 replay_runner.py:36] Average training steps per second: 335.06
I0902 00:36:09.353214 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -537.84
INFO:tensorflow:Starting iteration 18

Steps executed: 205 Episode length: 74 Return: -603.9413371924959511
INFO:tensorflow:Average training steps per second: 343.04
I0902 00:36:15.620013 140413705484288 replay_runner.py:36] Average training steps per second: 343.04
I0902 00:36:15.746284 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -588.67
INFO:tensorflow:Starting iteration 19

Steps executed: 248 Episode length: 59 Return: -218.8765875216873511
INFO:tensorflow:Average training steps per second: 342.15
I0902 00:36:22.056194 140413705484288 replay_runner.py:36] Average training steps per second: 342.15
I0902 00:36:22.186916 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -384.93
INFO:tensorflow:Starting iteration 20
I0902 00:36:25.564195 140413705484288 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 336.01

Steps executed: 217 Episode length: 97 Return: -390.7427058034380711
I0902 00:36:28.657586 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.58
INFO:tensorflow:Starting iteration 21

Steps executed: 348 Episode length: 178 Return: -159.261243647378911
INFO:tensorflow:Average training steps per second: 333.13
I0902 00:36:35.011366 140413705484288 replay_runner.py:36] Average training steps per second: 333.13
I0902 00:36:35.217542 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -517.89
INFO:tensorflow:Starting iteration 22

Steps executed: 263 Episode length: 142 Return: -1.64415354614163851
INFO:tensorflow:Average training steps per second: 334.93
I0902 00:36:41.561329 140413705484288 replay_runner.py:36] Average training steps per second: 334.93
I0902 00:36:41.724060 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.30
INFO:tensorflow:Starting iteration 23

Steps executed: 221 Episode length: 80 Return: -595.3567994786808551
INFO:tensorflow:Average training steps per second: 334.11
I0902 00:36:48.014092 140413705484288 replay_runner.py:36] Average training steps per second: 334.11
I0902 00:36:48.149334 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -472.33
INFO:tensorflow:Starting iteration 24
I0902 00:36:51.530635 140413705484288 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 332.91
I0902 00:36:54.534821 140413705484288 replay_runner.py:36] Average training steps per second: 332.91

Steps executed: 240 Episode length: 106 Return: -462.036361490117541
INFO:tensorflow:Starting iteration 25

Steps executed: 279 Episode length: 87 Return: -768.9397446954849741
INFO:tensorflow:Average training steps per second: 329.26
I0902 00:37:01.095196 140413705484288 replay_runner.py:36] Average training steps per second: 329.26
I0902 00:37:01.230893 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.91
INFO:tensorflow:Starting iteration 26

Steps executed: 240 Episode length: 92 Return: -536.7844498303425541
INFO:tensorflow:Average training steps per second: 329.41
I0902 00:37:07.633145 140413705484288 replay_runner.py:36] Average training steps per second: 329.41
I0902 00:37:07.762083 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -418.84
INFO:tensorflow:Starting iteration 27

Steps executed: 276 Episode length: 89 Return: -374.8169218787685441
INFO:tensorflow:Average training steps per second: 334.35
I0902 00:37:14.136810 140413705484288 replay_runner.py:36] Average training steps per second: 334.35
I0902 00:37:14.296760 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -513.53
INFO:tensorflow:Starting iteration 28

Steps executed: 60 Episode length: 60 Return: -455.54373285304955441
INFO:tensorflow:Average training steps per second: 331.98
I0902 00:37:20.669312 140413705484288 replay_runner.py:36] Average training steps per second: 331.98

Steps executed: 229 Episode length: 51 Return: -351.9293314474847441
INFO:tensorflow:Starting iteration 29

Steps executed: 209 Episode length: 61 Return: -475.2446301455080441
INFO:tensorflow:Average training steps per second: 326.35
I0902 00:37:27.260326 140413705484288 replay_runner.py:36] Average training steps per second: 326.35

Done fixed training!Episode length: 61 Return: -475.2446301455080441