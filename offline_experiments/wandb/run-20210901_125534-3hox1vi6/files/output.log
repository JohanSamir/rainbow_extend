Loaded trained dqn in cartpole
Training fixed agent 7, please be patient, may be a while...
I0901 12:55:41.431776 140540456830976 run_experiment.py:549] Creating TrainRunner ...
I0901 12:55:41.440536 140540456830976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:55:41.440793 140540456830976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:55:41.440934 140540456830976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:55:41.441020 140540456830976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:55:41.441098 140540456830976 dqn_agent.py:275] 	 update_period: 4
I0901 12:55:41.441201 140540456830976 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:55:41.441277 140540456830976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:55:41.441382 140540456830976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:55:41.441516 140540456830976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:55:41.441600 140540456830976 dqn_agent.py:280] 	 optimizer: adam
I0901 12:55:41.441683 140540456830976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:55:41.441764 140540456830976 dqn_agent.py:283] 	 seed: 1630500941440473
I0901 12:55:41.445071 140540456830976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:55:41.445320 140540456830976 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:55:41.445652 140540456830976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:55:41.445802 140540456830976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:55:41.445892 140540456830976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:55:41.445999 140540456830976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:55:41.446174 140540456830976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:55:41.446368 140540456830976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:55:41.446481 140540456830976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:55:41.491078 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:55:42.033719 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:55:42.049543 140540456830976 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:55:42.059599 140540456830976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:55:42.059801 140540456830976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:55:42.059906 140540456830976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:55:42.060013 140540456830976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:55:42.060345 140540456830976 dqn_agent.py:275] 	 update_period: 4
I0901 12:55:42.060674 140540456830976 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:55:42.060978 140540456830976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:55:42.061223 140540456830976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:55:42.061401 140540456830976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:55:42.061521 140540456830976 dqn_agent.py:280] 	 optimizer: adam
I0901 12:55:42.061692 140540456830976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:55:42.061946 140540456830976 dqn_agent.py:283] 	 seed: 1630500942059552
I0901 12:55:42.064850 140540456830976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:55:42.065090 140540456830976 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:55:42.065221 140540456830976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:55:42.065342 140540456830976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:55:42.065461 140540456830976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:55:42.065590 140540456830976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:55:42.065716 140540456830976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:55:42.065826 140540456830976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:55:42.065952 140540456830976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:55:42.104254 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:55:42.130852 140540456830976 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:55:42.131133 140540456830976 replay_runner.py:41] Starting iteration 0
Steps executed: 200 Episode length: 11 Return: 11.0
INFO:tensorflow:Average training steps per second: 140.36
I0901 12:55:49.255918 140540456830976 replay_runner.py:36] Average training steps per second: 140.36
I0901 12:55:50.504592 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 10.53
INFO:tensorflow:Starting iteration 1

Steps executed: 208 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 188.59
I0901 12:55:56.004518 140540456830976 replay_runner.py:36] Average training steps per second: 188.59
I0901 12:55:56.170536 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.90
INFO:tensorflow:Starting iteration 2

Steps executed: 201 Episode length: 50 Return: 50.0
INFO:tensorflow:Average training steps per second: 190.14
I0901 12:56:01.618587 140540456830976 replay_runner.py:36] Average training steps per second: 190.14
I0901 12:56:01.768315 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 50.25
INFO:tensorflow:Starting iteration 3

Steps executed: 287 Episode length: 162 Return: 162.0
INFO:tensorflow:Average training steps per second: 190.80
I0901 12:56:07.186918 140540456830976 replay_runner.py:36] Average training steps per second: 190.80
I0901 12:56:07.397325 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 143.50
INFO:tensorflow:Starting iteration 4

Steps executed: 266 Episode length: 147 Return: 147.0
INFO:tensorflow:Average training steps per second: 190.43
I0901 12:56:12.847104 140540456830976 replay_runner.py:36] Average training steps per second: 190.43
I0901 12:56:13.040721 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 133.00
INFO:tensorflow:Starting iteration 5

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 193.51
I0901 12:56:18.390863 140540456830976 replay_runner.py:36] Average training steps per second: 193.51
I0901 12:56:18.532153 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 6
I0901 12:56:18.717389 140540456830976 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 206.03
I0901 12:56:23.571406 140540456830976 replay_runner.py:36] Average training steps per second: 206.03
I0901 12:56:23.699003 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 7
I0901 12:56:23.888221 140540456830976 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 190.68
I0901 12:56:29.132837 140540456830976 replay_runner.py:36] Average training steps per second: 190.68
I0901 12:56:29.273459 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 8

Steps executed: 392 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 193.75
I0901 12:56:34.630655 140540456830976 replay_runner.py:36] Average training steps per second: 193.75
I0901 12:56:34.892950 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 196.00
INFO:tensorflow:Starting iteration 9

Steps executed: 335 Episode length: 158 Return: 158.0
INFO:tensorflow:Average training steps per second: 192.43
I0901 12:56:40.282910 140540456830976 replay_runner.py:36] Average training steps per second: 192.43
I0901 12:56:40.515398 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 167.50
INFO:tensorflow:Starting iteration 10

Steps executed: 297 Episode length: 156 Return: 156.0
INFO:tensorflow:Average training steps per second: 158.07
I0901 12:56:47.029643 140540456830976 replay_runner.py:36] Average training steps per second: 158.07
I0901 12:56:47.238079 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 148.50
INFO:tensorflow:Starting iteration 11

Steps executed: 288 Episode length: 146 Return: 146.0
INFO:tensorflow:Average training steps per second: 198.22
I0901 12:56:52.516917 140540456830976 replay_runner.py:36] Average training steps per second: 198.22
I0901 12:56:52.713262 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 144.00
INFO:tensorflow:Starting iteration 12

Steps executed: 305 Episode length: 159 Return: 159.0
INFO:tensorflow:Average training steps per second: 192.52
I0901 12:56:58.099641 140540456830976 replay_runner.py:36] Average training steps per second: 192.52
I0901 12:56:58.319933 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 152.50
INFO:tensorflow:Starting iteration 13

Steps executed: 324 Episode length: 167 Return: 167.0
INFO:tensorflow:Average training steps per second: 190.78
I0901 12:57:03.744707 140540456830976 replay_runner.py:36] Average training steps per second: 190.78
I0901 12:57:03.978940 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 162.00
INFO:tensorflow:Starting iteration 14

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 188.20
I0901 12:57:09.489068 140540456830976 replay_runner.py:36] Average training steps per second: 188.20
I0901 12:57:09.628793 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 15

Steps executed: 148 Episode length: 148 Return: 148.0
INFO:tensorflow:Average training steps per second: 191.56
I0901 12:57:15.045926 140540456830976 replay_runner.py:36] Average training steps per second: 191.56

Steps executed: 313 Episode length: 165 Return: 165.0
INFO:tensorflow:Starting iteration 16

Steps executed: 349 Episode length: 168 Return: 168.0
INFO:tensorflow:Average training steps per second: 193.93
I0901 12:57:20.627002 140540456830976 replay_runner.py:36] Average training steps per second: 193.93
I0901 12:57:20.866895 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 174.50
INFO:tensorflow:Starting iteration 17

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 191.44
I0901 12:57:26.286590 140540456830976 replay_runner.py:36] Average training steps per second: 191.44
I0901 12:57:26.430576 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 18
I0901 12:57:26.630669 140540456830976 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 191.86
I0901 12:57:31.843261 140540456830976 replay_runner.py:36] Average training steps per second: 191.86
I0901 12:57:31.988698 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 19
I0901 12:57:32.184407 140540456830976 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 187.92
I0901 12:57:37.506224 140540456830976 replay_runner.py:36] Average training steps per second: 187.92
I0901 12:57:37.651010 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 20
I0901 12:57:37.843584 140540456830976 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 185.33
I0901 12:57:43.239831 140540456830976 replay_runner.py:36] Average training steps per second: 185.33
I0901 12:57:43.389937 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 21

Steps executed: 351 Episode length: 168 Return: 168.0
INFO:tensorflow:Average training steps per second: 185.42
I0901 12:57:48.987855 140540456830976 replay_runner.py:36] Average training steps per second: 185.42
I0901 12:57:49.238812 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 175.50
INFO:tensorflow:Starting iteration 22

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 190.23
I0901 12:57:54.693860 140540456830976 replay_runner.py:36] Average training steps per second: 190.23
I0901 12:57:54.840482 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 23
I0901 12:57:55.020776 140540456830976 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 196.32
I0901 12:58:00.114996 140540456830976 replay_runner.py:36] Average training steps per second: 196.32
I0901 12:58:00.267548 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 24
I0901 12:58:00.468993 140540456830976 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 188.83
I0901 12:58:05.765280 140540456830976 replay_runner.py:36] Average training steps per second: 188.83
I0901 12:58:05.912115 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 25

Steps executed: 335 Episode length: 150 Return: 150.0
INFO:tensorflow:Average training steps per second: 189.84
I0901 12:58:11.374727 140540456830976 replay_runner.py:36] Average training steps per second: 189.84
I0901 12:58:11.615968 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 167.50
INFO:tensorflow:Starting iteration 26

Steps executed: 277 Episode length: 146 Return: 146.0
INFO:tensorflow:Average training steps per second: 194.12
I0901 12:58:16.965172 140540456830976 replay_runner.py:36] Average training steps per second: 194.12
I0901 12:58:17.156678 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 138.50
INFO:tensorflow:Starting iteration 27

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 188.28
I0901 12:58:22.667168 140540456830976 replay_runner.py:36] Average training steps per second: 188.28
I0901 12:58:22.815753 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 28
I0901 12:58:22.998244 140540456830976 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 189.42
I0901 12:58:28.277844 140540456830976 replay_runner.py:36] Average training steps per second: 189.42
I0901 12:58:28.413228 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 29
I0901 12:58:28.596295 140540456830976 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 193.04

Done fixed training!Episode length: 189 Return: 189.0
I0901 12:58:34.053951 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 179.50