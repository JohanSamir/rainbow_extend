I0902 18:17:51.445778 140216164177920 run_experiment.py:549] Creating TrainRunner ...
I0902 18:17:51.453478 140216164177920 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:17:51.453624 140216164177920 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:17:51.453713 140216164177920 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:17:51.453804 140216164177920 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:17:51.453896 140216164177920 dqn_agent.py:275] 	 update_period: 4
I0902 18:17:51.453976 140216164177920 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:17:51.454044 140216164177920 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:17:51.454123 140216164177920 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:17:51.454245 140216164177920 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:17:51.454339 140216164177920 dqn_agent.py:280] 	 optimizer: adam
I0902 18:17:51.454407 140216164177920 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:17:51.454473 140216164177920 dqn_agent.py:283] 	 seed: 1630606671453442
I0902 18:17:51.456151 140216164177920 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:17:51.456270 140216164177920 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:17:51.456372 140216164177920 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:17:51.456440 140216164177920 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:17:51.456524 140216164177920 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:17:51.456577 140216164177920 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:17:51.456687 140216164177920 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:17:51.456763 140216164177920 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:17:51.456819 140216164177920 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:17:51.481594 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 18:17:51.718813 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 18:17:51.727074 140216164177920 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:17:51.733697 140216164177920 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:17:51.733822 140216164177920 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:17:51.733894 140216164177920 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:17:51.733955 140216164177920 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:17:51.734011 140216164177920 dqn_agent.py:275] 	 update_period: 4
I0902 18:17:51.734132 140216164177920 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:17:51.734199 140216164177920 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:17:51.734263 140216164177920 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:17:51.734323 140216164177920 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:17:51.734385 140216164177920 dqn_agent.py:280] 	 optimizer: adam
I0902 18:17:51.734453 140216164177920 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:17:51.734521 140216164177920 dqn_agent.py:283] 	 seed: 1630606671733669
I0902 18:17:51.735774 140216164177920 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:17:51.735874 140216164177920 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:17:51.735938 140216164177920 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:17:51.735994 140216164177920 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:17:51.736046 140216164177920 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:17:51.736130 140216164177920 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:17:51.736209 140216164177920 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:17:51.736285 140216164177920 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:17:51.736348 140216164177920 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:17:51.754342 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 18:17:51.768580 140216164177920 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:17:51.768750 140216164177920 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
Steps executed: 233 Episode length: 152 Return: -465.15154142482794
INFO:tensorflow:Average training steps per second: 269.95
I0902 18:17:55.473812 140216164177920 replay_runner.py:36] Average training steps per second: 269.95
I0902 18:17:56.339942 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -436.12
INFO:tensorflow:Starting iteration 1

Steps executed: 269 Episode length: 108 Return: -325.50859936507576
INFO:tensorflow:Average training steps per second: 370.34
I0902 18:18:02.455111 140216164177920 replay_runner.py:36] Average training steps per second: 370.34
I0902 18:18:02.607378 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -354.62
INFO:tensorflow:Starting iteration 2
I0902 18:18:06.119029 140216164177920 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 343.17

Steps executed: 319 Episode length: 177 Return: -221.59290666810924
I0902 18:18:09.227923 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.80
INFO:tensorflow:Starting iteration 3

Steps executed: 244 Episode length: 150 Return: -187.19656249729988
INFO:tensorflow:Average training steps per second: 334.81
I0902 18:18:15.612822 140216164177920 replay_runner.py:36] Average training steps per second: 334.81
I0902 18:18:15.762435 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.37
INFO:tensorflow:Starting iteration 4
I0902 18:18:19.089037 140216164177920 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 319.91

Steps executed: 1000 Episode length: 1000 Return: -90.1563591648577
I0902 18:18:24.430235 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.16
INFO:tensorflow:Starting iteration 5
I0902 18:18:27.892265 140216164177920 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 337.57

Steps executed: 1000 Episode length: 1000 Return: -91.27038721688399
I0902 18:18:33.089205 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.27
INFO:tensorflow:Starting iteration 6
I0902 18:18:36.597104 140216164177920 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 362.81

Steps executed: 1000 Episode length: 1000 Return: -108.53033945946603
I0902 18:18:41.491556 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.53
INFO:tensorflow:Starting iteration 7
I0902 18:18:45.004583 140216164177920 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 373.55

Steps executed: 1000 Episode length: 1000 Return: -445.29499180816674
I0902 18:18:50.594647 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -445.29
INFO:tensorflow:Starting iteration 8
I0902 18:18:53.877052 140216164177920 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 347.11

Steps executed: 1000 Episode length: 1000 Return: -984.22497966917764
I0902 18:18:58.275154 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -984.22
INFO:tensorflow:Starting iteration 9
I0902 18:19:01.553290 140216164177920 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 321.75

Steps executed: 657 Episode length: 657 Return: -312.1764762749202764
I0902 18:19:05.592390 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -312.18
INFO:tensorflow:Starting iteration 10

Steps executed: 420 Episode length: 420 Return: -484.2767773153745764
INFO:tensorflow:Average training steps per second: 320.55
I0902 18:19:12.030978 140216164177920 replay_runner.py:36] Average training steps per second: 320.55
I0902 18:19:12.610360 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -484.28
INFO:tensorflow:Starting iteration 11
I0902 18:19:15.938253 140216164177920 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 327.19

Steps executed: 1000 Episode length: 1000 Return: -269.95276313509885
I0902 18:19:20.514326 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.95
INFO:tensorflow:Starting iteration 12
I0902 18:19:23.935451 140216164177920 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 343.57

Steps executed: 1000 Episode length: 1000 Return: -209.02967980075184
I0902 18:19:28.607282 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.03
INFO:tensorflow:Starting iteration 13

Steps executed: 116 Episode length: 116 Return: -132.0041513000386184
INFO:tensorflow:Average training steps per second: 338.42

Steps executed: 1116 Episode length: 1000 Return: -120.33581167459634
I0902 18:19:36.829564 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.17
INFO:tensorflow:Starting iteration 14
I0902 18:19:40.286736 140216164177920 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 336.49

Steps executed: 1000 Episode length: 1000 Return: -139.05255700850324
I0902 18:19:45.237792 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.05
INFO:tensorflow:Starting iteration 15
I0902 18:19:48.760815 140216164177920 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 356.70

Steps executed: 477 Episode length: 477 Return: -65.03016203991888324
I0902 18:19:52.181677 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.03
INFO:tensorflow:Starting iteration 16

Steps executed: 384 Episode length: 384 Return: -476.3261307630048324
INFO:tensorflow:Average training steps per second: 346.40
I0902 18:19:58.536417 140216164177920 replay_runner.py:36] Average training steps per second: 346.40
I0902 18:19:58.928424 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -476.33
INFO:tensorflow:Starting iteration 17

Steps executed: 241 Episode length: 188 Return: -80.46799272931051324
INFO:tensorflow:Average training steps per second: 348.19
I0902 18:20:05.329192 140216164177920 replay_runner.py:36] Average training steps per second: 348.19
I0902 18:20:05.470832 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.25
INFO:tensorflow:Starting iteration 18
I0902 18:20:08.959412 140216164177920 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 349.87

Steps executed: 262 Episode length: 147 Return: -721.3102042271983324
I0902 18:20:11.969722 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -514.49
INFO:tensorflow:Starting iteration 19

Steps executed: 255 Episode length: 140 Return: -79.19810956636748924
INFO:tensorflow:Average training steps per second: 339.11
I0902 18:20:18.320173 140216164177920 replay_runner.py:36] Average training steps per second: 339.11
I0902 18:20:18.476111 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.75
INFO:tensorflow:Starting iteration 20

Steps executed: 293 Episode length: 167 Return: -321.1587248552424224
INFO:tensorflow:Average training steps per second: 335.54
I0902 18:20:24.898034 140216164177920 replay_runner.py:36] Average training steps per second: 335.54
I0902 18:20:25.068028 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.96
INFO:tensorflow:Starting iteration 21

Steps executed: 221 Episode length: 111 Return: -73.95304064232079224
INFO:tensorflow:Average training steps per second: 332.24
I0902 18:20:31.479491 140216164177920 replay_runner.py:36] Average training steps per second: 332.24
I0902 18:20:31.592059 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.96
INFO:tensorflow:Starting iteration 22

Steps executed: 258 Episode length: 145 Return: -52.63056681459592724
INFO:tensorflow:Average training steps per second: 320.05
I0902 18:20:38.029674 140216164177920 replay_runner.py:36] Average training steps per second: 320.05
I0902 18:20:38.169839 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.72
INFO:tensorflow:Starting iteration 23

Steps executed: 588 Episode length: 411 Return: 22.378186105384586724
INFO:tensorflow:Average training steps per second: 326.21
I0902 18:20:44.543396 140216164177920 replay_runner.py:36] Average training steps per second: 326.21
I0902 18:20:45.161465 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.09
INFO:tensorflow:Starting iteration 24

Steps executed: 319 Episode length: 123 Return: -218.2385321512698824
INFO:tensorflow:Average training steps per second: 326.21
I0902 18:20:51.578600 140216164177920 replay_runner.py:36] Average training steps per second: 326.21
I0902 18:20:51.760578 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.43
INFO:tensorflow:Starting iteration 25

Steps executed: 374 Episode length: 220 Return: -348.5639751107869424
INFO:tensorflow:Average training steps per second: 327.03
I0902 18:20:58.197481 140216164177920 replay_runner.py:36] Average training steps per second: 327.03
I0902 18:20:58.454862 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.59
INFO:tensorflow:Starting iteration 26

Steps executed: 296 Episode length: 296 Return: -403.8042034359430724
INFO:tensorflow:Average training steps per second: 340.06
I0902 18:21:04.699258 140216164177920 replay_runner.py:36] Average training steps per second: 340.06
I0902 18:21:04.924656 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -403.80
INFO:tensorflow:Starting iteration 27
I0902 18:21:08.249290 140216164177920 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 326.13
I0902 18:21:11.315956 140216164177920 replay_runner.py:36] Average training steps per second: 326.13

Steps executed: 1000 Episode length: 1000 Return: 10.8493181183367584
INFO:tensorflow:Starting iteration 28
I0902 18:21:17.009750 140216164177920 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 328.73

Steps executed: 1000 Episode length: 1000 Return: -93.353618355971764
I0902 18:21:22.405013 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.35
INFO:tensorflow:Starting iteration 29
I0902 18:21:25.699138 140216164177920 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 347.96

Steps executed: 1000 Episode length: 1000 Return: -51.814198820325594

Done fixed training! Episode length: 1000 Return: -51.814198820325594