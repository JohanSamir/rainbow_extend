Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0901 12:35:40.754806 139809518303232 run_experiment.py:549] Creating TrainRunner ...
I0901 12:35:40.766094 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:35:40.766464 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:35:40.766641 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:35:40.766762 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:35:40.766851 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 12:35:40.766973 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:35:40.767167 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:35:40.767278 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:35:40.767352 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:35:40.767424 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 12:35:40.767559 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:35:40.767653 139809518303232 dqn_agent.py:283] 	 seed: 1630499740766031
I0901 12:35:40.771031 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:35:40.771250 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:35:40.771411 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:35:40.771600 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:35:40.771781 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:35:40.772062 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:35:40.772222 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:35:40.772344 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:35:40.772458 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:35:40.839335 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:35:41.283563 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:35:41.298503 139809518303232 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:35:41.309253 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:35:41.309557 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:35:41.309762 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:35:41.309915 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:35:41.310078 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 12:35:41.310365 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:35:41.310732 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:35:41.310897 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:35:41.311066 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:35:41.311213 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 12:35:41.311518 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:35:41.311661 139809518303232 dqn_agent.py:283] 	 seed: 1630499741309182
I0901 12:35:41.314795 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:35:41.314949 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:35:41.315086 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:35:41.315342 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:35:41.315443 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:35:41.315531 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:35:41.315610 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:35:41.315682 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:35:41.315757 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:35:41.354478 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:35:41.381564 139809518303232 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:35:41.382139 139809518303232 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 151.43
I0901 12:35:47.986406 139809518303232 replay_runner.py:36] Average training steps per second: 151.43
Steps executed: 246 Episode length: 97 Return: -613.59924859257078
I0901 12:35:49.281084 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -453.40
INFO:tensorflow:Starting iteration 1

Steps executed: 263 Episode length: 128 Return: -327.36051704763014
INFO:tensorflow:Average training steps per second: 212.19
I0901 12:35:58.551913 139809518303232 replay_runner.py:36] Average training steps per second: 212.19
I0901 12:35:58.806880 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -371.88
INFO:tensorflow:Starting iteration 2

Steps executed: 216 Episode length: 120 Return: -154.79177867946692
INFO:tensorflow:Average training steps per second: 209.78
I0901 12:36:07.787026 139809518303232 replay_runner.py:36] Average training steps per second: 209.78
I0901 12:36:07.980251 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.30
INFO:tensorflow:Starting iteration 3

Steps executed: 635 Episode length: 533 Return: -214.01573043462736
INFO:tensorflow:Average training steps per second: 209.39
I0901 12:36:17.078630 139809518303232 replay_runner.py:36] Average training steps per second: 209.39
I0901 12:36:17.987798 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -299.17
INFO:tensorflow:Starting iteration 4

Steps executed: 658 Episode length: 658 Return: -90.595251061447236
INFO:tensorflow:Average training steps per second: 212.18
I0901 12:36:26.919615 139809518303232 replay_runner.py:36] Average training steps per second: 212.18
I0901 12:36:28.133802 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.60
INFO:tensorflow:Starting iteration 5

Steps executed: 238 Episode length: 134 Return: -137.67715386395256
INFO:tensorflow:Average training steps per second: 211.92
I0901 12:36:37.283818 139809518303232 replay_runner.py:36] Average training steps per second: 211.92
I0901 12:36:37.505703 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.98
INFO:tensorflow:Starting iteration 6
I0901 12:36:41.880017 139809518303232 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 212.10

Steps executed: 207 Episode length: 82 Return: -63.9523579380082847
I0901 12:36:46.774752 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.14
INFO:tensorflow:Starting iteration 7

Steps executed: 290 Episode length: 124 Return: 2.76036403158538237
INFO:tensorflow:Average training steps per second: 215.10
I0901 12:36:55.829792 139809518303232 replay_runner.py:36] Average training steps per second: 215.10
I0901 12:36:56.099075 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.71
INFO:tensorflow:Starting iteration 8

Steps executed: 398 Episode length: 398 Return: -234.34866661441927
INFO:tensorflow:Average training steps per second: 220.89
I0901 12:37:04.957868 139809518303232 replay_runner.py:36] Average training steps per second: 220.89
I0901 12:37:05.596948 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.35
INFO:tensorflow:Starting iteration 9
I0901 12:37:10.029628 139809518303232 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 211.54

Steps executed: 312 Episode length: 210 Return: -33.920716963362716
I0901 12:37:15.095420 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.71
INFO:tensorflow:Starting iteration 10

Steps executed: 349 Episode length: 159 Return: 6.71733093247765116
INFO:tensorflow:Average training steps per second: 214.37
I0901 12:37:24.056287 139809518303232 replay_runner.py:36] Average training steps per second: 214.37
I0901 12:37:24.403440 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: 15.24
INFO:tensorflow:Starting iteration 11

Steps executed: 206 Episode length: 206 Return: -175.82741277708456
INFO:tensorflow:Average training steps per second: 214.13
I0901 12:37:33.496712 139809518303232 replay_runner.py:36] Average training steps per second: 214.13
I0901 12:37:33.721664 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.83
INFO:tensorflow:Starting iteration 12

Steps executed: 1000 Episode length: 1000 Return: -60.93887458049036
INFO:tensorflow:Average training steps per second: 207.73
I0901 12:37:42.979208 139809518303232 replay_runner.py:36] Average training steps per second: 207.73
I0901 12:37:44.671894 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -60.94
INFO:tensorflow:Starting iteration 13
I0901 12:37:48.994869 139809518303232 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 210.89

Steps executed: 1000 Episode length: 1000 Return: -26.86914622624333
I0901 12:37:56.432984 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -26.87
INFO:tensorflow:Starting iteration 14
I0901 12:38:00.819054 139809518303232 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 216.19

Steps executed: 1000 Episode length: 1000 Return: -71.91415523237309
I0901 12:38:09.400266 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.91
INFO:tensorflow:Starting iteration 15
I0901 12:38:13.757183 139809518303232 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 211.95

Steps executed: 1000 Episode length: 1000 Return: -71.13510937910057
I0901 12:38:22.387032 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.14
INFO:tensorflow:Starting iteration 16

Steps executed: 453 Episode length: 453 Return: -377.769942470981737
INFO:tensorflow:Average training steps per second: 210.34
I0901 12:38:31.514145 139809518303232 replay_runner.py:36] Average training steps per second: 210.34
I0901 12:38:32.428808 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.77
INFO:tensorflow:Starting iteration 17
I0901 12:38:36.707754 139809518303232 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 209.62

Steps executed: 1000 Episode length: 1000 Return: -109.10858404786985
I0901 12:38:43.903402 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.11
INFO:tensorflow:Starting iteration 18
I0901 12:38:48.363449 139809518303232 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 208.80

Steps executed: 750 Episode length: 750 Return: -310.3749242234825485
I0901 12:38:55.440278 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.37
INFO:tensorflow:Starting iteration 19
I0901 12:38:59.831923 139809518303232 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 211.53

Steps executed: 1000 Episode length: 1000 Return: -58.979051849666206
I0901 12:39:06.262411 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -58.98
INFO:tensorflow:Starting iteration 20
I0901 12:39:10.766041 139809518303232 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 214.25

Steps executed: 1000 Episode length: 1000 Return: -79.549608327630706
I0901 12:39:19.595724 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.55
INFO:tensorflow:Starting iteration 21
I0901 12:39:24.063290 139809518303232 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 212.64

Steps executed: 932 Episode length: 932 Return: -171.4435354015889706
I0901 12:39:31.767102 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.44
INFO:tensorflow:Starting iteration 22
I0901 12:39:35.832875 139809518303232 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 216.73

Steps executed: 678 Episode length: 678 Return: -227.5607719076796206
I0901 12:39:42.439203 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.56
INFO:tensorflow:Starting iteration 23

Steps executed: 227 Episode length: 107 Return: -377.7386631810487606
INFO:tensorflow:Average training steps per second: 216.20
I0901 12:39:51.438961 139809518303232 replay_runner.py:36] Average training steps per second: 216.20
I0901 12:39:51.654936 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -385.03
INFO:tensorflow:Starting iteration 24

Steps executed: 110 Episode length: 110 Return: -324.3934874053108506
INFO:tensorflow:Average training steps per second: 221.22

Steps executed: 523 Episode length: 413 Return: 206.72034466813662506
I0901 12:40:01.198621 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -58.84
INFO:tensorflow:Starting iteration 25
I0901 12:40:05.508270 139809518303232 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 229.77

Steps executed: 1000 Episode length: 1000 Return: -27.632503956064337
I0901 12:40:12.476241 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -27.63
INFO:tensorflow:Starting iteration 26
I0901 12:40:16.694091 139809518303232 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 218.71

Steps executed: 1000 Episode length: 1000 Return: -31.906381952091802
I0901 12:40:23.269588 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -31.91
INFO:tensorflow:Starting iteration 27
I0901 12:40:27.597136 139809518303232 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 216.25

Steps executed: 1000 Episode length: 1000 Return: -101.03070480917097
I0901 12:40:35.033289 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.03
INFO:tensorflow:Starting iteration 28
I0901 12:40:39.615283 139809518303232 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 212.22

Steps executed: 1000 Episode length: 1000 Return: -43.083751418389857
I0901 12:40:46.647634 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -43.08
INFO:tensorflow:Starting iteration 29
I0901 12:40:51.024229 139809518303232 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 219.96

Steps executed: 1000 Episode length: 1000 Return: -58.709214961613247

Done fixed training! Episode length: 1000 Return: -58.709214961613247