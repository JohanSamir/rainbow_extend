Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 13:23:11.691533 140315766171648 run_experiment.py:549] Creating TrainRunner ...
I0901 13:23:11.700502 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:23:11.700661 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:23:11.700755 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:23:11.700823 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:23:11.700915 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 13:23:11.701018 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:23:11.701080 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:23:11.701171 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:23:11.701290 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:23:11.701381 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 13:23:11.701477 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:23:11.701555 140315766171648 dqn_agent.py:283] 	 seed: 1630502591700446
I0901 13:23:11.703464 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:23:11.703588 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:23:11.703673 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:23:11.703745 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:23:11.703837 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:23:11.703900 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:23:11.704006 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:23:11.704087 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:23:11.704174 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:23:11.833871 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:23:12.118912 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:23:12.130206 140315766171648 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:23:12.138154 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:23:12.138396 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:23:12.138510 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:23:12.138601 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:23:12.138676 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 13:23:12.138751 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:23:12.138855 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:23:12.138964 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:23:12.139043 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:23:12.139135 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 13:23:12.139226 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:23:12.139302 140315766171648 dqn_agent.py:283] 	 seed: 1630502592138077
I0901 13:23:12.141080 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:23:12.141283 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:23:12.141438 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:23:12.141531 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:23:12.141607 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:23:12.141679 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:23:12.141748 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:23:12.141844 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:23:12.141941 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:23:12.168246 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:23:12.209566 140315766171648 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:23:12.209888 140315766171648 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 227.81
I0901 13:23:16.599734 140315766171648 replay_runner.py:36] Average training steps per second: 227.81
Steps executed: 299 Episode length: 208 Return: -26.309002783945758
I0901 13:23:17.403299 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.36
INFO:tensorflow:Starting iteration 1

Steps executed: 235 Episode length: 157 Return: -164.27755293949198
INFO:tensorflow:Average training steps per second: 322.55
I0901 13:23:23.994871 140315766171648 replay_runner.py:36] Average training steps per second: 322.55
I0901 13:23:24.128617 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.40
INFO:tensorflow:Starting iteration 2

Steps executed: 240 Episode length: 148 Return: -272.22871225645618
INFO:tensorflow:Average training steps per second: 329.50
I0901 13:23:30.657650 140315766171648 replay_runner.py:36] Average training steps per second: 329.50
I0901 13:23:30.779258 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -271.18
INFO:tensorflow:Starting iteration 3

Steps executed: 243 Episode length: 91 Return: -259.942218212579868
INFO:tensorflow:Average training steps per second: 286.82
I0901 13:23:37.714132 140315766171648 replay_runner.py:36] Average training steps per second: 286.82
I0901 13:23:37.838373 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.39
INFO:tensorflow:Starting iteration 4

Steps executed: 286 Episode length: 140 Return: -259.37632622445825
INFO:tensorflow:Average training steps per second: 317.24
I0901 13:23:44.433096 140315766171648 replay_runner.py:36] Average training steps per second: 317.24
I0901 13:23:44.624298 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.28
INFO:tensorflow:Starting iteration 5

Steps executed: 287 Episode length: 127 Return: -216.37375091040684
INFO:tensorflow:Average training steps per second: 318.13
I0901 13:23:51.226206 140315766171648 replay_runner.py:36] Average training steps per second: 318.13
I0901 13:23:51.382610 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.52
INFO:tensorflow:Starting iteration 6

Steps executed: 220 Episode length: 94 Return: -187.009422604746874
INFO:tensorflow:Average training steps per second: 315.22
I0901 13:23:58.028695 140315766171648 replay_runner.py:36] Average training steps per second: 315.22
I0901 13:23:58.160328 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.36
INFO:tensorflow:Starting iteration 7

Steps executed: 343 Episode length: 182 Return: -81.327703351105554
INFO:tensorflow:Average training steps per second: 312.72
I0901 13:24:04.816034 140315766171648 replay_runner.py:36] Average training steps per second: 312.72
I0901 13:24:05.045528 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.57
INFO:tensorflow:Starting iteration 8

Steps executed: 769 Episode length: 588 Return: -364.09853568068156
INFO:tensorflow:Average training steps per second: 301.45
I0901 13:24:11.777843 140315766171648 replay_runner.py:36] Average training steps per second: 301.45
I0901 13:24:12.787846 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.54
INFO:tensorflow:Starting iteration 9

Steps executed: 262 Episode length: 64 Return: -190.187750545074156
INFO:tensorflow:Average training steps per second: 306.74
I0901 13:24:19.465109 140315766171648 replay_runner.py:36] Average training steps per second: 306.74
I0901 13:24:19.593368 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -181.59
INFO:tensorflow:Starting iteration 10

Steps executed: 584 Episode length: 584 Return: -213.38433384553684
INFO:tensorflow:Average training steps per second: 305.56
I0901 13:24:26.247275 140315766171648 replay_runner.py:36] Average training steps per second: 305.56
I0901 13:24:27.111879 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.38
INFO:tensorflow:Starting iteration 11

Steps executed: 287 Episode length: 287 Return: -461.03051810763154
INFO:tensorflow:Average training steps per second: 305.22
I0901 13:24:33.815711 140315766171648 replay_runner.py:36] Average training steps per second: 305.22
I0901 13:24:34.069691 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -461.03
INFO:tensorflow:Starting iteration 12

Steps executed: 301 Episode length: 234 Return: -407.18676544308754
INFO:tensorflow:Average training steps per second: 303.91
I0901 13:24:40.798877 140315766171648 replay_runner.py:36] Average training steps per second: 303.91
I0901 13:24:41.036612 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.89
INFO:tensorflow:Starting iteration 13
I0901 13:24:44.445752 140315766171648 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 309.07

Steps executed: 502 Episode length: 502 Return: -205.84202927947555
I0901 13:24:48.385316 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.84
INFO:tensorflow:Starting iteration 14

Steps executed: 326 Episode length: 186 Return: -1459.9785868457163
INFO:tensorflow:Average training steps per second: 309.30
I0901 13:24:55.060510 140315766171648 replay_runner.py:36] Average training steps per second: 309.30
I0901 13:24:55.301927 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -835.41
INFO:tensorflow:Starting iteration 15
I0901 13:24:58.712536 140315766171648 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 307.79

Steps executed: 214 Episode length: 64 Return: -125.677086767502423
I0901 13:25:02.066009 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.30
INFO:tensorflow:Starting iteration 16

Steps executed: 241 Episode length: 140 Return: 18.4169115419779464
INFO:tensorflow:Average training steps per second: 307.58
I0901 13:25:08.776626 140315766171648 replay_runner.py:36] Average training steps per second: 307.58
I0901 13:25:08.945544 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.87
INFO:tensorflow:Starting iteration 17

Steps executed: 279 Episode length: 149 Return: -371.07391859239664
INFO:tensorflow:Average training steps per second: 310.81
I0901 13:25:15.621377 140315766171648 replay_runner.py:36] Average training steps per second: 310.81
I0901 13:25:15.817675 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -382.61
INFO:tensorflow:Starting iteration 18

Steps executed: 310 Episode length: 310 Return: -323.49063854133084
INFO:tensorflow:Average training steps per second: 308.13
I0901 13:25:22.522430 140315766171648 replay_runner.py:36] Average training steps per second: 308.13
I0901 13:25:22.834699 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -323.49
INFO:tensorflow:Starting iteration 19
I0901 13:25:26.286606 140315766171648 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 314.88
I0901 13:25:29.462734 140315766171648 replay_runner.py:36] Average training steps per second: 314.88

Steps executed: 248 Episode length: 248 Return: -475.61719431596646
INFO:tensorflow:Starting iteration 20

Steps executed: 365 Episode length: 219 Return: -49.777931008173696
INFO:tensorflow:Average training steps per second: 316.57
I0901 13:25:36.320902 140315766171648 replay_runner.py:36] Average training steps per second: 316.57
I0901 13:25:36.604181 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.13
INFO:tensorflow:Starting iteration 21

Steps executed: 219 Episode length: 117 Return: -394.86626937224986
INFO:tensorflow:Average training steps per second: 313.13
I0901 13:25:43.260180 140315766171648 replay_runner.py:36] Average training steps per second: 313.13
I0901 13:25:43.395194 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -387.55
INFO:tensorflow:Starting iteration 22

Steps executed: 208 Episode length: 88 Return: -168.518368420186566
INFO:tensorflow:Average training steps per second: 316.48
I0901 13:25:50.019904 140315766171648 replay_runner.py:36] Average training steps per second: 316.48
I0901 13:25:50.155864 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -249.35
INFO:tensorflow:Starting iteration 23

Steps executed: 241 Episode length: 96 Return: -56.0684796652137866
INFO:tensorflow:Average training steps per second: 324.11
I0901 13:25:56.649595 140315766171648 replay_runner.py:36] Average training steps per second: 324.11
I0901 13:25:56.817668 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.52
INFO:tensorflow:Starting iteration 24

Steps executed: 257 Episode length: 106 Return: -350.74765913472356
INFO:tensorflow:Average training steps per second: 325.19
I0901 13:26:03.349665 140315766171648 replay_runner.py:36] Average training steps per second: 325.19
I0901 13:26:03.513695 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.99
INFO:tensorflow:Starting iteration 25

Steps executed: 244 Episode length: 59 Return: -126.243767191575396
INFO:tensorflow:Average training steps per second: 308.20
I0901 13:26:10.145336 140315766171648 replay_runner.py:36] Average training steps per second: 308.20
I0901 13:26:10.286544 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.61
INFO:tensorflow:Starting iteration 26

Steps executed: 233 Episode length: 94 Return: -450.748021543212156
INFO:tensorflow:Average training steps per second: 324.14
I0901 13:26:16.698212 140315766171648 replay_runner.py:36] Average training steps per second: 324.14
I0901 13:26:16.853944 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -397.53
INFO:tensorflow:Starting iteration 27

Steps executed: 262 Episode length: 64 Return: -110.655256308372436
INFO:tensorflow:Average training steps per second: 344.76
I0901 13:26:23.010463 140315766171648 replay_runner.py:36] Average training steps per second: 344.76
I0901 13:26:23.157937 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.40
INFO:tensorflow:Starting iteration 28

Steps executed: 206 Episode length: 72 Return: -121.651036373251866
INFO:tensorflow:Average training steps per second: 332.63
I0901 13:26:29.282199 140315766171648 replay_runner.py:36] Average training steps per second: 332.63
I0901 13:26:29.387854 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -388.13
INFO:tensorflow:Starting iteration 29

Steps executed: 230 Episode length: 117 Return: -433.45959019539646
INFO:tensorflow:Average training steps per second: 338.73
I0901 13:26:35.509923 140315766171648 replay_runner.py:36] Average training steps per second: 338.73

Done fixed training!Episode length: 117 Return: -433.45959019539646