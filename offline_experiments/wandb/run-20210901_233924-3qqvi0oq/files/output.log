Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0901 23:39:31.312867 139965167532032 run_experiment.py:549] Creating TrainRunner ...
I0901 23:39:31.325935 139965167532032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:39:31.326241 139965167532032 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:39:31.326598 139965167532032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:39:31.326951 139965167532032 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:39:31.327128 139965167532032 dqn_agent.py:275] 	 update_period: 4
I0901 23:39:31.327281 139965167532032 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:39:31.327417 139965167532032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:39:31.327810 139965167532032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:39:31.327920 139965167532032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:39:31.328031 139965167532032 dqn_agent.py:280] 	 optimizer: adam
I0901 23:39:31.328128 139965167532032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:39:31.328281 139965167532032 dqn_agent.py:283] 	 seed: 1630539571325857
I0901 23:39:31.331026 139965167532032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:39:31.331156 139965167532032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:39:31.331255 139965167532032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:39:31.331327 139965167532032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:39:31.331386 139965167532032 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:39:31.331441 139965167532032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:39:31.331538 139965167532032 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:39:31.331598 139965167532032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:39:31.331667 139965167532032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:39:31.367812 139965167532032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:31.767749 139965167532032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:31.783503 139965167532032 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:39:31.793390 139965167532032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:39:31.793886 139965167532032 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:39:31.794028 139965167532032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:39:31.794148 139965167532032 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:39:31.794313 139965167532032 dqn_agent.py:275] 	 update_period: 4
I0901 23:39:31.794412 139965167532032 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:39:31.794486 139965167532032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:39:31.794577 139965167532032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:39:31.794652 139965167532032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:39:31.794724 139965167532032 dqn_agent.py:280] 	 optimizer: adam
I0901 23:39:31.794818 139965167532032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:39:31.794889 139965167532032 dqn_agent.py:283] 	 seed: 1630539571793346
I0901 23:39:31.802696 139965167532032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:39:31.802973 139965167532032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:39:31.803176 139965167532032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:39:31.803308 139965167532032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:39:31.803390 139965167532032 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:39:31.803464 139965167532032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:39:31.803579 139965167532032 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:39:31.803699 139965167532032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:39:31.814650 139965167532032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:39:31.862710 139965167532032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:31.885355 139965167532032 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:39:31.885696 139965167532032 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 164.97
I0901 23:39:37.948077 139965167532032 replay_runner.py:36] Average training steps per second: 164.97
Steps executed: 257 Episode length: 62 Return: -476.1673170581298
I0901 23:39:39.106357 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -532.93
INFO:tensorflow:Starting iteration 1

Steps executed: 229 Episode length: 74 Return: -744.2747551641282
INFO:tensorflow:Average training steps per second: 227.71
I0901 23:39:47.923263 139965167532032 replay_runner.py:36] Average training steps per second: 227.71
I0901 23:39:48.121939 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -685.54
INFO:tensorflow:Starting iteration 2
I0901 23:39:52.517444 139965167532032 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 227.73

Steps executed: 207 Episode length: 78 Return: -721.55454999675157
I0901 23:39:57.089759 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -576.38
INFO:tensorflow:Starting iteration 3

Steps executed: 272 Episode length: 120 Return: -810.8259154329227
INFO:tensorflow:Average training steps per second: 220.39
I0901 23:40:06.028957 139965167532032 replay_runner.py:36] Average training steps per second: 220.39
I0901 23:40:06.304491 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -832.30
INFO:tensorflow:Starting iteration 4
I0901 23:40:10.665418 139965167532032 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 229.18

Steps executed: 212 Episode length: 80 Return: -822.68071871604087
I0901 23:40:15.218854 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -666.16
INFO:tensorflow:Starting iteration 5

Steps executed: 212 Episode length: 76 Return: -777.11706847298267
INFO:tensorflow:Average training steps per second: 225.42
I0901 23:40:24.082288 139965167532032 replay_runner.py:36] Average training steps per second: 225.42
I0901 23:40:24.261000 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -643.88
INFO:tensorflow:Starting iteration 6
I0901 23:40:28.680979 139965167532032 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 226.12

Steps executed: 249 Episode length: 58 Return: -551.77758142300957
I0901 23:40:33.316755 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -510.31
INFO:tensorflow:Starting iteration 7

Steps executed: 305 Episode length: 213 Return: -1824.7444391453612
INFO:tensorflow:Average training steps per second: 221.27
I0901 23:40:42.206054 139965167532032 replay_runner.py:36] Average training steps per second: 221.27
I0901 23:40:42.536114 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -1159.45
INFO:tensorflow:Starting iteration 8

Steps executed: 214 Episode length: 77 Return: -434.567151188631672
INFO:tensorflow:Average training steps per second: 220.80
I0901 23:40:51.466341 139965167532032 replay_runner.py:36] Average training steps per second: 220.80
I0901 23:40:51.666085 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -762.29
INFO:tensorflow:Starting iteration 9

Steps executed: 234 Episode length: 116 Return: -770.88623879055912
INFO:tensorflow:Average training steps per second: 228.71
I0901 23:41:00.407036 139965167532032 replay_runner.py:36] Average training steps per second: 228.71
I0901 23:41:00.619277 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -758.54
INFO:tensorflow:Starting iteration 10

Steps executed: 352 Episode length: 271 Return: -2491.8745729905662
INFO:tensorflow:Average training steps per second: 226.05
I0901 23:41:09.383494 139965167532032 replay_runner.py:36] Average training steps per second: 226.05
I0901 23:41:09.802674 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -1497.32
INFO:tensorflow:Starting iteration 11

Steps executed: 292 Episode length: 100 Return: -643.80606279686512
INFO:tensorflow:Average training steps per second: 237.77
I0901 23:41:18.383761 139965167532032 replay_runner.py:36] Average training steps per second: 237.77
I0901 23:41:18.633520 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -668.59
INFO:tensorflow:Starting iteration 12

Steps executed: 351 Episode length: 155 Return: -773.90803017967782
INFO:tensorflow:Average training steps per second: 238.84
I0901 23:41:27.104885 139965167532032 replay_runner.py:36] Average training steps per second: 238.84
I0901 23:41:27.402310 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -691.20
INFO:tensorflow:Starting iteration 13

Steps executed: 261 Episode length: 77 Return: -633.313700824802282
INFO:tensorflow:Average training steps per second: 233.54
I0901 23:41:35.806259 139965167532032 replay_runner.py:36] Average training steps per second: 233.54
I0901 23:41:36.033260 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -587.17
INFO:tensorflow:Starting iteration 14

Steps executed: 207 Episode length: 103 Return: -753.63882113564152
INFO:tensorflow:Average training steps per second: 228.87
I0901 23:41:44.542642 139965167532032 replay_runner.py:36] Average training steps per second: 228.87
I0901 23:41:44.724732 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -696.11
INFO:tensorflow:Starting iteration 15

Steps executed: 81 Episode length: 81 Return: -417.2061938839552152
INFO:tensorflow:Average training steps per second: 225.28

Steps executed: 395 Episode length: 199 Return: -1323.6967490832083
I0901 23:41:53.909448 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -844.07
INFO:tensorflow:Starting iteration 16

Steps executed: 360 Episode length: 171 Return: -1323.1412391445642
INFO:tensorflow:Average training steps per second: 228.53
I0901 23:42:02.693959 139965167532032 replay_runner.py:36] Average training steps per second: 228.53
I0901 23:42:03.061028 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -892.31
INFO:tensorflow:Starting iteration 17

Steps executed: 387 Episode length: 193 Return: -1465.3759926521773
INFO:tensorflow:Average training steps per second: 223.26
I0901 23:42:11.884104 139965167532032 replay_runner.py:36] Average training steps per second: 223.26
I0901 23:42:12.270556 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -823.66
INFO:tensorflow:Starting iteration 18
I0901 23:42:16.764324 139965167532032 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 224.08
I0901 23:42:21.227436 139965167532032 replay_runner.py:36] Average training steps per second: 224.08

Steps executed: 239 Episode length: 153 Return: -763.05991981585343
INFO:tensorflow:Starting iteration 19

Steps executed: 295 Episode length: 104 Return: -598.75476410700663
INFO:tensorflow:Average training steps per second: 224.48
I0901 23:42:30.331616 139965167532032 replay_runner.py:36] Average training steps per second: 224.48
I0901 23:42:30.612530 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -613.20
INFO:tensorflow:Starting iteration 20
I0901 23:42:35.010425 139965167532032 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 228.01
I0901 23:42:39.396785 139965167532032 replay_runner.py:36] Average training steps per second: 228.01

Steps executed: 201 Episode length: 201 Return: -1752.0105514098482
INFO:tensorflow:Starting iteration 21

Steps executed: 375 Episode length: 214 Return: -1433.6438464667472
INFO:tensorflow:Average training steps per second: 225.24
I0901 23:42:48.408167 139965167532032 replay_runner.py:36] Average training steps per second: 225.24
I0901 23:42:48.809860 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -878.28
INFO:tensorflow:Starting iteration 22
I0901 23:42:53.156245 139965167532032 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 223.56
I0901 23:42:57.629770 139965167532032 replay_runner.py:36] Average training steps per second: 223.56

Steps executed: 327 Episode length: 143 Return: -908.03447958323696
INFO:tensorflow:Starting iteration 23

Steps executed: 234 Episode length: 75 Return: -514.624681309906256
INFO:tensorflow:Average training steps per second: 226.50
I0901 23:43:06.787319 139965167532032 replay_runner.py:36] Average training steps per second: 226.50
I0901 23:43:07.029031 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -851.80
INFO:tensorflow:Starting iteration 24

Steps executed: 315 Episode length: 126 Return: -870.31124536779216
INFO:tensorflow:Average training steps per second: 222.84
I0901 23:43:15.914489 139965167532032 replay_runner.py:36] Average training steps per second: 222.84
I0901 23:43:16.228753 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -750.86
INFO:tensorflow:Starting iteration 25

Steps executed: 273 Episode length: 186 Return: -1433.7791793696116
INFO:tensorflow:Average training steps per second: 219.87
I0901 23:43:25.122606 139965167532032 replay_runner.py:36] Average training steps per second: 219.87
I0901 23:43:25.413527 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -976.43
INFO:tensorflow:Starting iteration 26

Steps executed: 209 Episode length: 107 Return: -447.75420852917546
INFO:tensorflow:Average training steps per second: 228.98
I0901 23:43:34.102370 139965167532032 replay_runner.py:36] Average training steps per second: 228.98
I0901 23:43:34.305808 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -498.76
INFO:tensorflow:Starting iteration 27

Steps executed: 256 Episode length: 74 Return: -574.000885626282487
INFO:tensorflow:Average training steps per second: 218.62
I0901 23:43:43.287153 139965167532032 replay_runner.py:36] Average training steps per second: 218.62
I0901 23:43:43.560626 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -893.49
INFO:tensorflow:Starting iteration 28

Steps executed: 250 Episode length: 89 Return: -408.860084664207367
INFO:tensorflow:Average training steps per second: 225.20
I0901 23:43:52.403731 139965167532032 replay_runner.py:36] Average training steps per second: 225.20
I0901 23:43:52.652147 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -771.15
INFO:tensorflow:Starting iteration 29

Steps executed: 213 Episode length: 119 Return: -823.97930659563747
INFO:tensorflow:Average training steps per second: 248.93
I0901 23:44:00.873087 139965167532032 replay_runner.py:36] Average training steps per second: 248.93

Done fixed training!Episode length: 119 Return: -823.97930659563747