I0901 23:49:40.565542 139929824643072 run_experiment.py:549] Creating TrainRunner ...
I0901 23:49:40.577378 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:40.577648 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:40.577776 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:40.577995 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:40.578225 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:40.578324 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:40.578402 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:40.578493 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:40.578603 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:40.578734 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:40.578835 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:40.578935 139929824643072 dqn_agent.py:283] 	 seed: 1630540180577310
I0901 23:49:40.581498 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:40.581644 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:40.581742 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:40.581827 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:40.581913 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:40.581994 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:40.582099 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:40.582248 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:40.582337 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0901 23:49:42.423594 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:42.831176 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:42.844571 139929824643072 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:49:42.854428 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:42.854636 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:42.854769 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:42.854843 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:42.854918 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:42.855045 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:42.855139 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:42.855228 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:42.855353 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:42.855446 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:42.855536 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:42.855610 139929824643072 dqn_agent.py:283] 	 seed: 1630540182854381
I0901 23:49:42.857553 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:42.857686 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:42.857762 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:42.857830 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:42.857897 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:42.858028 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:42.858125 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:42.858189 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:42.858272 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:49:42.890485 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:42.911442 139929824643072 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:49:42.912186 139929824643072 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.78
I0901 23:49:49.056007 139929824643072 replay_runner.py:36] Average training steps per second: 162.78
Steps executed: 332 Episode length: 193 Return: -208.58382807681356
I0901 23:49:50.413060 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.52
INFO:tensorflow:Starting iteration 1

Steps executed: 213 Episode length: 144 Return: -211.22988030898556
INFO:tensorflow:Average training steps per second: 220.87
I0901 23:49:59.312360 139929824643072 replay_runner.py:36] Average training steps per second: 220.87
I0901 23:49:59.487813 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.42
INFO:tensorflow:Starting iteration 2
I0901 23:50:03.789774 139929824643072 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 225.26

Steps executed: 378 Episode length: 378 Return: -432.14156824701116
I0901 23:50:08.734298 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -432.14
INFO:tensorflow:Starting iteration 3

Steps executed: 203 Episode length: 203 Return: -32.395424718203566
INFO:tensorflow:Average training steps per second: 227.76
I0901 23:50:17.504303 139929824643072 replay_runner.py:36] Average training steps per second: 227.76
I0901 23:50:17.699549 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -32.40
INFO:tensorflow:Starting iteration 4
I0901 23:50:21.999499 139929824643072 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 219.97

Steps executed: 1000 Episode length: 1000 Return: -93.63671877935927
I0901 23:50:29.751595 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.64
INFO:tensorflow:Starting iteration 5
I0901 23:50:34.000747 139929824643072 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 239.77

Steps executed: 1000 Episode length: 1000 Return: -213.94495776727095
I0901 23:50:40.249752 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.94
INFO:tensorflow:Starting iteration 6
I0901 23:50:44.523578 139929824643072 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 228.62

Steps executed: 1000 Episode length: 1000 Return: -192.19233227954317
I0901 23:50:51.861456 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.19
INFO:tensorflow:Starting iteration 7
I0901 23:50:56.118265 139929824643072 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 220.80

Steps executed: 1000 Episode length: 1000 Return: -258.23565110822417
I0901 23:51:04.001831 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.24
INFO:tensorflow:Starting iteration 8
I0901 23:51:08.304883 139929824643072 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 223.28

Steps executed: 1000 Episode length: 1000 Return: -282.37138228844117
I0901 23:51:15.278897 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -282.37
INFO:tensorflow:Starting iteration 9
I0901 23:51:19.505237 139929824643072 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 224.25

Steps executed: 1000 Episode length: 1000 Return: -233.49734003982255
I0901 23:51:27.224993 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.50
INFO:tensorflow:Starting iteration 10
I0901 23:51:31.662620 139929824643072 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 223.73

Steps executed: 909 Episode length: 909 Return: -1279.898075502933455
I0901 23:51:38.241006 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -1279.90
INFO:tensorflow:Starting iteration 11
I0901 23:51:42.538957 139929824643072 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 223.66

Steps executed: 1000 Episode length: 1000 Return: -265.65267721117195
I0901 23:51:50.680562 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.65
INFO:tensorflow:Starting iteration 12

Steps executed: 396 Episode length: 242 Return: -220.0269671072009695
INFO:tensorflow:Average training steps per second: 218.32
I0901 23:51:59.667121 139929824643072 replay_runner.py:36] Average training steps per second: 218.32
I0901 23:52:00.074193 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.59
INFO:tensorflow:Starting iteration 13
I0901 23:52:04.350261 139929824643072 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 224.33
I0901 23:52:08.808398 139929824643072 replay_runner.py:36] Average training steps per second: 224.33

Steps executed: 782 Episode length: 782 Return: -451.2775868204259495
INFO:tensorflow:Starting iteration 14

Steps executed: 227 Episode length: 227 Return: -54.51829941214164495
INFO:tensorflow:Average training steps per second: 219.18
I0901 23:52:19.670449 139929824643072 replay_runner.py:36] Average training steps per second: 219.18
I0901 23:52:19.908050 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.52
INFO:tensorflow:Starting iteration 15
I0901 23:52:24.348252 139929824643072 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 223.66

Steps executed: 241 Episode length: 59 Return: -159.27322172848433495
I0901 23:52:29.054957 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.42
INFO:tensorflow:Starting iteration 16

Steps executed: 247 Episode length: 247 Return: -195.1009750975083495
INFO:tensorflow:Average training steps per second: 225.37
I0901 23:52:37.832593 139929824643072 replay_runner.py:36] Average training steps per second: 225.37
I0901 23:52:38.135835 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.10
INFO:tensorflow:Starting iteration 17
I0901 23:52:42.635345 139929824643072 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 226.31

Steps executed: 1000 Episode length: 1000 Return: -80.462305629311875
I0901 23:52:50.615114 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.46
INFO:tensorflow:Starting iteration 18

Steps executed: 200 Episode length: 55 Return: -93.526878698291571875
INFO:tensorflow:Average training steps per second: 222.01
I0901 23:52:59.459059 139929824643072 replay_runner.py:36] Average training steps per second: 222.01
I0901 23:52:59.650408 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -272.21
INFO:tensorflow:Starting iteration 19
I0901 23:53:03.809764 139929824643072 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 224.29

Steps executed: 429 Episode length: 429 Return: -14.30198475457618275
I0901 23:53:08.975517 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -14.30
INFO:tensorflow:Starting iteration 20

Steps executed: 254 Episode length: 254 Return: 27.325493757415074275
INFO:tensorflow:Average training steps per second: 212.96
I0901 23:53:17.994497 139929824643072 replay_runner.py:36] Average training steps per second: 212.96
I0901 23:53:18.301167 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: 27.33
INFO:tensorflow:Starting iteration 21

Steps executed: 263 Episode length: 139 Return: -74.64612670477928775
INFO:tensorflow:Average training steps per second: 219.97
I0901 23:53:27.114512 139929824643072 replay_runner.py:36] Average training steps per second: 219.97
I0901 23:53:27.370320 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.85
INFO:tensorflow:Starting iteration 22
I0901 23:53:31.668509 139929824643072 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 227.06

Steps executed: 1000 Episode length: 1000 Return: -19.744331141945526
I0901 23:53:40.644171 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -19.74
INFO:tensorflow:Starting iteration 23

Steps executed: 432 Episode length: 432 Return: 140.10822759180078526
INFO:tensorflow:Average training steps per second: 234.98
I0901 23:53:49.176575 139929824643072 replay_runner.py:36] Average training steps per second: 234.98
I0901 23:53:49.880372 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: 140.11
INFO:tensorflow:Starting iteration 24
I0901 23:53:54.102529 139929824643072 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 235.13

Steps executed: 1000 Episode length: 1000 Return: 25.9849889783942846
I0901 23:54:02.381451 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: 25.98
INFO:tensorflow:Starting iteration 25
I0901 23:54:06.710087 139929824643072 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 226.57

Steps executed: 1000 Episode length: 1000 Return: -69.671395914335016
I0901 23:54:15.053452 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.67
INFO:tensorflow:Starting iteration 26

Steps executed: 255 Episode length: 157 Return: -63.99762175748955016
INFO:tensorflow:Average training steps per second: 223.72
I0901 23:54:23.809162 139929824643072 replay_runner.py:36] Average training steps per second: 223.72
I0901 23:54:24.029768 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.26
INFO:tensorflow:Starting iteration 27
I0901 23:54:28.391874 139929824643072 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 226.44

Steps executed: 1000 Episode length: 1000 Return: -67.607659627616746
I0901 23:54:35.790457 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -67.61
INFO:tensorflow:Starting iteration 28
I0901 23:54:40.141082 139929824643072 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 220.60
I0901 23:54:44.674654 139929824643072 replay_runner.py:36] Average training steps per second: 220.60

Steps executed: 228 Episode length: 228 Return: -512.8647655557669746
INFO:tensorflow:Starting iteration 29

Steps executed: 466 Episode length: 466 Return: -10.80132443204475146
INFO:tensorflow:Average training steps per second: 223.14
I0901 23:54:53.703541 139929824643072 replay_runner.py:36] Average training steps per second: 223.14

Done fixed training!Episode length: 466 Return: -10.80132443204475146