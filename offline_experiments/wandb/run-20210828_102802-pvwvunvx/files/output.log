Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0828 10:28:09.070402 139825303013376 run_experiment.py:549] Creating TrainRunner ...
I0828 10:28:09.082258 139825303013376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:28:09.082554 139825303013376 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:28:09.082765 139825303013376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:28:09.082886 139825303013376 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:28:09.083080 139825303013376 dqn_agent.py:275] 	 update_period: 4
I0828 10:28:09.083203 139825303013376 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:28:09.083359 139825303013376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:28:09.083504 139825303013376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:28:09.083637 139825303013376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:28:09.083762 139825303013376 dqn_agent.py:280] 	 optimizer: adam
I0828 10:28:09.083864 139825303013376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:28:09.083941 139825303013376 dqn_agent.py:283] 	 seed: 1630146489082196
I0828 10:28:09.086998 139825303013376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:28:09.087227 139825303013376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:28:09.087448 139825303013376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:28:09.087684 139825303013376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:28:09.087828 139825303013376 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:28:09.088059 139825303013376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:28:09.088145 139825303013376 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:28:09.088218 139825303013376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:28:09.088315 139825303013376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:28:09.125739 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:09.527316 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:09.542417 139825303013376 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:28:09.552742 139825303013376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:28:09.553616 139825303013376 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:28:09.554024 139825303013376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:28:09.554204 139825303013376 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:28:09.554383 139825303013376 dqn_agent.py:275] 	 update_period: 4
I0828 10:28:09.559693 139825303013376 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:28:09.559946 139825303013376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:28:09.560084 139825303013376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:28:09.560369 139825303013376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:28:09.560521 139825303013376 dqn_agent.py:280] 	 optimizer: adam
I0828 10:28:09.560604 139825303013376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:28:09.560678 139825303013376 dqn_agent.py:283] 	 seed: 1630146489552672
I0828 10:28:09.587768 139825303013376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:28:09.588027 139825303013376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:28:09.588131 139825303013376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:28:09.588224 139825303013376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:28:09.588392 139825303013376 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:28:09.588501 139825303013376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:28:09.588589 139825303013376 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:28:09.589119 139825303013376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:28:09.589270 139825303013376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:28:09.622922 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:09.644052 139825303013376 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:28:09.644367 139825303013376 replay_runner.py:41] Starting iteration 0
Steps executed: 65 Episode length: 65 Return: -135.12408962570257
INFO:tensorflow:Average training steps per second: 169.96

Steps executed: 232 Episode length: 97 Return: 3.62090253423654936
I0828 10:28:16.717733 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.04
INFO:tensorflow:Starting iteration 1

Steps executed: 207 Episode length: 63 Return: -482.03328171835726
INFO:tensorflow:Average training steps per second: 219.00
I0828 10:28:25.653039 139825303013376 replay_runner.py:36] Average training steps per second: 219.00
I0828 10:28:25.836762 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -616.95
INFO:tensorflow:Starting iteration 2
I0828 10:28:30.182740 139825303013376 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 221.65

Steps executed: 211 Episode length: 55 Return: -483.77696982012426
I0828 10:28:34.883297 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -653.61
INFO:tensorflow:Starting iteration 3

Steps executed: 272 Episode length: 79 Return: -765.80382113409016
INFO:tensorflow:Average training steps per second: 218.55
I0828 10:28:43.728504 139825303013376 replay_runner.py:36] Average training steps per second: 218.55
I0828 10:28:43.956918 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -524.41
INFO:tensorflow:Starting iteration 4
I0828 10:28:48.123376 139825303013376 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 215.55

Steps executed: 247 Episode length: 50 Return: -436.83052210414684
I0828 10:28:52.979461 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -515.52
INFO:tensorflow:Starting iteration 5

Steps executed: 234 Episode length: 70 Return: -561.58517797807424
INFO:tensorflow:Average training steps per second: 219.81
I0828 10:29:01.888059 139825303013376 replay_runner.py:36] Average training steps per second: 219.81
I0828 10:29:02.092628 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -702.04
INFO:tensorflow:Starting iteration 6

Steps executed: 291 Episode length: 97 Return: -9.4466705360877236
INFO:tensorflow:Average training steps per second: 218.03
I0828 10:29:10.946919 139825303013376 replay_runner.py:36] Average training steps per second: 218.03
I0828 10:29:11.206296 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -442.59
INFO:tensorflow:Starting iteration 7

Steps executed: 210 Episode length: 53 Return: -163.93928141598127
INFO:tensorflow:Average training steps per second: 216.47
I0828 10:29:19.921036 139825303013376 replay_runner.py:36] Average training steps per second: 216.47
I0828 10:29:20.079775 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -239.09
INFO:tensorflow:Starting iteration 8

Steps executed: 204 Episode length: 58 Return: -504.06689741874624
INFO:tensorflow:Average training steps per second: 215.04
I0828 10:29:29.064775 139825303013376 replay_runner.py:36] Average training steps per second: 215.04
I0828 10:29:29.245493 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -601.62
INFO:tensorflow:Starting iteration 9

Steps executed: 203 Episode length: 52 Return: -454.49735470665824
INFO:tensorflow:Average training steps per second: 216.03
I0828 10:29:38.209114 139825303013376 replay_runner.py:36] Average training steps per second: 216.03
I0828 10:29:38.397077 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -560.45
INFO:tensorflow:Starting iteration 10

Steps executed: 215 Episode length: 80 Return: -648.30908349735484
INFO:tensorflow:Average training steps per second: 219.25
I0828 10:29:47.259458 139825303013376 replay_runner.py:36] Average training steps per second: 219.25
I0828 10:29:47.446809 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -626.67
INFO:tensorflow:Starting iteration 11

Steps executed: 251 Episode length: 54 Return: -417.01932741611697
INFO:tensorflow:Average training steps per second: 219.04
I0828 10:29:56.346695 139825303013376 replay_runner.py:36] Average training steps per second: 219.04
I0828 10:29:56.570899 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -511.16
INFO:tensorflow:Starting iteration 12

Steps executed: 255 Episode length: 66 Return: -545.64360114872447
INFO:tensorflow:Average training steps per second: 219.85
I0828 10:30:05.424961 139825303013376 replay_runner.py:36] Average training steps per second: 219.85
I0828 10:30:05.643921 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -563.44
INFO:tensorflow:Starting iteration 13

Steps executed: 253 Episode length: 65 Return: -641.84984713023546
INFO:tensorflow:Average training steps per second: 220.87
I0828 10:30:14.514993 139825303013376 replay_runner.py:36] Average training steps per second: 220.87
I0828 10:30:14.752197 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -548.93
INFO:tensorflow:Starting iteration 14

Steps executed: 243 Episode length: 84 Return: -926.82552716900286
INFO:tensorflow:Average training steps per second: 227.67
I0828 10:30:23.344061 139825303013376 replay_runner.py:36] Average training steps per second: 227.67
I0828 10:30:23.563647 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -896.29
INFO:tensorflow:Starting iteration 15

Steps executed: 218 Episode length: 63 Return: -474.87516867036993
INFO:tensorflow:Average training steps per second: 231.55
I0828 10:30:32.153738 139825303013376 replay_runner.py:36] Average training steps per second: 231.55
I0828 10:30:32.340672 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -684.51
INFO:tensorflow:Starting iteration 16

Steps executed: 281 Episode length: 84 Return: -774.93511587565083
INFO:tensorflow:Average training steps per second: 226.85
I0828 10:30:41.053368 139825303013376 replay_runner.py:36] Average training steps per second: 226.85
I0828 10:30:41.292923 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -639.94
INFO:tensorflow:Starting iteration 17

Steps executed: 236 Episode length: 67 Return: -655.67483668999013
INFO:tensorflow:Average training steps per second: 222.96
I0828 10:30:50.065868 139825303013376 replay_runner.py:36] Average training steps per second: 222.96
I0828 10:30:50.268182 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -781.70
INFO:tensorflow:Starting iteration 18

Steps executed: 224 Episode length: 83 Return: -108.50343125459179
INFO:tensorflow:Average training steps per second: 232.91
I0828 10:30:58.714202 139825303013376 replay_runner.py:36] Average training steps per second: 232.91
I0828 10:30:58.924600 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.01
INFO:tensorflow:Starting iteration 19

Steps executed: 221 Episode length: 80 Return: -453.62834739253589
INFO:tensorflow:Average training steps per second: 211.95
I0828 10:31:07.815278 139825303013376 replay_runner.py:36] Average training steps per second: 211.95
I0828 10:31:08.007384 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -520.34
INFO:tensorflow:Starting iteration 20

Steps executed: 109 Episode length: 51 Return: -445.96684607183649
INFO:tensorflow:Average training steps per second: 223.37
I0828 10:31:16.865008 139825303013376 replay_runner.py:36] Average training steps per second: 223.37

Steps executed: 213 Episode length: 104 Return: -435.5399070276681
INFO:tensorflow:Starting iteration 21

Steps executed: 205 Episode length: 77 Return: -565.41850766907041
INFO:tensorflow:Average training steps per second: 220.76
I0828 10:31:25.931781 139825303013376 replay_runner.py:36] Average training steps per second: 220.76
I0828 10:31:26.120045 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -532.26
INFO:tensorflow:Starting iteration 22

Steps executed: 61 Episode length: 61 Return: -425.936240445491641
INFO:tensorflow:Average training steps per second: 219.75

Steps executed: 268 Episode length: 70 Return: -646.88131411689791
I0828 10:31:35.251789 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -547.04
INFO:tensorflow:Starting iteration 23

Steps executed: 258 Episode length: 65 Return: -549.02953471339561
INFO:tensorflow:Average training steps per second: 220.87
I0828 10:31:43.973909 139825303013376 replay_runner.py:36] Average training steps per second: 220.87
I0828 10:31:44.200704 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -480.23
INFO:tensorflow:Starting iteration 24

Steps executed: 207 Episode length: 65 Return: -522.05661073727661
INFO:tensorflow:Average training steps per second: 223.68
I0828 10:31:53.028648 139825303013376 replay_runner.py:36] Average training steps per second: 223.68
I0828 10:31:53.210270 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -621.78
INFO:tensorflow:Starting iteration 25

Steps executed: 216 Episode length: 76 Return: -770.14541978110291
INFO:tensorflow:Average training steps per second: 219.95
I0828 10:32:01.986852 139825303013376 replay_runner.py:36] Average training steps per second: 219.95
I0828 10:32:02.168284 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -633.87
INFO:tensorflow:Starting iteration 26

Steps executed: 218 Episode length: 59 Return: -504.63350912472436
INFO:tensorflow:Average training steps per second: 219.91
I0828 10:32:11.023908 139825303013376 replay_runner.py:36] Average training steps per second: 219.91
I0828 10:32:11.223264 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -661.37
INFO:tensorflow:Starting iteration 27

Steps executed: 274 Episode length: 84 Return: -783.13489783752735
INFO:tensorflow:Average training steps per second: 219.36
I0828 10:32:20.118717 139825303013376 replay_runner.py:36] Average training steps per second: 219.36
I0828 10:32:20.371245 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -607.12
INFO:tensorflow:Starting iteration 28

Steps executed: 63 Episode length: 63 Return: -593.184475413798535
INFO:tensorflow:Average training steps per second: 220.28
I0828 10:32:29.286452 139825303013376 replay_runner.py:36] Average training steps per second: 220.28

Steps executed: 213 Episode length: 84 Return: -793.30914691933915
INFO:tensorflow:Starting iteration 29

Steps executed: 229 Episode length: 52 Return: -355.41311638824435
INFO:tensorflow:Average training steps per second: 228.50
I0828 10:32:38.167926 139825303013376 replay_runner.py:36] Average training steps per second: 228.50

Done fixed training!Episode length: 52 Return: -355.41311638824435