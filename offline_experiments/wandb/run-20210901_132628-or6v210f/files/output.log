I0901 13:26:34.084213 140240877414400 run_experiment.py:549] Creating TrainRunner ...
I0901 13:26:34.092027 140240877414400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:26:34.092231 140240877414400 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:26:34.092311 140240877414400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:26:34.092389 140240877414400 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:26:34.092456 140240877414400 dqn_agent.py:275] 	 update_period: 4
I0901 13:26:34.092540 140240877414400 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:26:34.092632 140240877414400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:26:34.092709 140240877414400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:26:34.092790 140240877414400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:26:34.092850 140240877414400 dqn_agent.py:280] 	 optimizer: adam
I0901 13:26:34.092902 140240877414400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:26:34.092970 140240877414400 dqn_agent.py:283] 	 seed: 1630502794091982
I0901 13:26:34.095363 140240877414400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:26:34.095489 140240877414400 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:26:34.095575 140240877414400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:26:34.095646 140240877414400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:26:34.095711 140240877414400 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:26:34.095783 140240877414400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:26:34.095864 140240877414400 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:26:34.095961 140240877414400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:26:34.096035 140240877414400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:26:35.206274 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:26:35.527377 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:26:35.536548 140240877414400 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:26:35.543677 140240877414400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:26:35.543817 140240877414400 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:26:35.543910 140240877414400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:26:35.544011 140240877414400 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:26:35.544092 140240877414400 dqn_agent.py:275] 	 update_period: 4
I0901 13:26:35.544173 140240877414400 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:26:35.544249 140240877414400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:26:35.544317 140240877414400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:26:35.544386 140240877414400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:26:35.544483 140240877414400 dqn_agent.py:280] 	 optimizer: adam
I0901 13:26:35.544671 140240877414400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:26:35.544793 140240877414400 dqn_agent.py:283] 	 seed: 1630502795543643
I0901 13:26:35.546714 140240877414400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:26:35.546852 140240877414400 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:26:35.546950 140240877414400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:26:35.547023 140240877414400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:26:35.547130 140240877414400 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:26:35.547203 140240877414400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:26:35.547300 140240877414400 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:26:35.547389 140240877414400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:26:35.547471 140240877414400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:26:35.568904 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:26:35.585236 140240877414400 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:26:35.585445 140240877414400 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 269.35
I0901 13:26:39.298716 140240877414400 replay_runner.py:36] Average training steps per second: 269.35
Steps executed: 208 Episode length: 132 Return: -286.6303785078494
I0901 13:26:39.941962 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -351.23
INFO:tensorflow:Starting iteration 1

Steps executed: 357 Episode length: 196 Return: -265.9384385094154
INFO:tensorflow:Average training steps per second: 361.15
I0901 13:26:45.832311 140240877414400 replay_runner.py:36] Average training steps per second: 361.15
I0901 13:26:46.006258 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -306.08
INFO:tensorflow:Starting iteration 2

Steps executed: 223 Episode length: 123 Return: -143.13361631822238
INFO:tensorflow:Average training steps per second: 371.90
I0901 13:26:51.791430 140240877414400 replay_runner.py:36] Average training steps per second: 371.90
I0901 13:26:51.909422 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.28
INFO:tensorflow:Starting iteration 3
I0901 13:26:55.205182 140240877414400 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 383.41

Steps executed: 269 Episode length: 147 Return: 17.1133842842959478
I0901 13:26:57.946505 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.07
INFO:tensorflow:Starting iteration 4

Steps executed: 293 Episode length: 120 Return: -156.27707238234876
INFO:tensorflow:Average training steps per second: 367.61
I0901 13:27:03.947890 140240877414400 replay_runner.py:36] Average training steps per second: 367.61
I0901 13:27:04.092161 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.22
INFO:tensorflow:Starting iteration 5

Steps executed: 205 Episode length: 90 Return: -412.563612600448552
INFO:tensorflow:Average training steps per second: 368.35
I0901 13:27:09.971923 140240877414400 replay_runner.py:36] Average training steps per second: 368.35
I0901 13:27:10.059567 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.31
INFO:tensorflow:Starting iteration 6
I0901 13:27:13.189358 140240877414400 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 369.31

Steps executed: 301 Episode length: 164 Return: 20.8345548267933226
I0901 13:27:16.037234 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.96
INFO:tensorflow:Starting iteration 7
I0901 13:27:19.198036 140240877414400 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 365.33

Steps executed: 352 Episode length: 220 Return: -385.56345886359196
I0901 13:27:22.110831 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.12
INFO:tensorflow:Starting iteration 8

Steps executed: 296 Episode length: 136 Return: -189.51645361294027
INFO:tensorflow:Average training steps per second: 359.73
I0901 13:27:28.075626 140240877414400 replay_runner.py:36] Average training steps per second: 359.73
I0901 13:27:28.234289 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.55
INFO:tensorflow:Starting iteration 9

Steps executed: 232 Episode length: 144 Return: -215.96731923895913
INFO:tensorflow:Average training steps per second: 365.35
I0901 13:27:34.102185 140240877414400 replay_runner.py:36] Average training steps per second: 365.35
I0901 13:27:34.208869 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -249.56
INFO:tensorflow:Starting iteration 10

Steps executed: 206 Episode length: 85 Return: -231.402322712481724
INFO:tensorflow:Average training steps per second: 359.80
I0901 13:27:40.167845 140240877414400 replay_runner.py:36] Average training steps per second: 359.80
I0901 13:27:40.261394 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.82
INFO:tensorflow:Starting iteration 11

Steps executed: 231 Episode length: 118 Return: -228.45495619078093
INFO:tensorflow:Average training steps per second: 361.57
I0901 13:27:46.164801 140240877414400 replay_runner.py:36] Average training steps per second: 361.57
I0901 13:27:46.261447 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.58
INFO:tensorflow:Starting iteration 12

Steps executed: 349 Episode length: 349 Return: -621.43491810330183
INFO:tensorflow:Average training steps per second: 362.22
I0901 13:27:52.170078 140240877414400 replay_runner.py:36] Average training steps per second: 362.22
I0901 13:27:52.472524 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -621.43
INFO:tensorflow:Starting iteration 13

Steps executed: 595 Episode length: 528 Return: -235.68373572019416
INFO:tensorflow:Average training steps per second: 370.34
I0901 13:27:58.353017 140240877414400 replay_runner.py:36] Average training steps per second: 370.34
I0901 13:27:59.001358 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -204.40
INFO:tensorflow:Starting iteration 14
I0901 13:28:02.141388 140240877414400 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 372.49

Steps executed: 1000 Episode length: 1000 Return: -43.055669069829634
I0901 13:28:06.724137 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -43.06
INFO:tensorflow:Starting iteration 15

Steps executed: 549 Episode length: 475 Return: -815.6632659223686634
INFO:tensorflow:Average training steps per second: 384.36
I0901 13:28:12.618267 140240877414400 replay_runner.py:36] Average training steps per second: 384.36
I0901 13:28:13.122283 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -463.56
INFO:tensorflow:Starting iteration 16

Steps executed: 216 Episode length: 127 Return: -203.3338517246464634
INFO:tensorflow:Average training steps per second: 382.99
I0901 13:28:19.031105 140240877414400 replay_runner.py:36] Average training steps per second: 382.99
I0901 13:28:19.125020 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.23
INFO:tensorflow:Starting iteration 17

Steps executed: 481 Episode length: 481 Return: -230.2466742890687234
INFO:tensorflow:Average training steps per second: 386.78
I0901 13:28:24.976922 140240877414400 replay_runner.py:36] Average training steps per second: 386.78
I0901 13:28:25.448334 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.25
INFO:tensorflow:Starting iteration 18

Steps executed: 444 Episode length: 444 Return: -389.3164901956183734
INFO:tensorflow:Average training steps per second: 397.11
I0901 13:28:31.238583 140240877414400 replay_runner.py:36] Average training steps per second: 397.11
I0901 13:28:31.647441 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -389.32
INFO:tensorflow:Starting iteration 19

Steps executed: 253 Episode length: 79 Return: -133.78781154349522734
INFO:tensorflow:Average training steps per second: 379.75
I0901 13:28:37.566680 140240877414400 replay_runner.py:36] Average training steps per second: 379.75
I0901 13:28:37.658820 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.22
INFO:tensorflow:Starting iteration 20

Steps executed: 214 Episode length: 78 Return: -65.861009738638022734
INFO:tensorflow:Average training steps per second: 394.74
I0901 13:28:43.467430 140240877414400 replay_runner.py:36] Average training steps per second: 394.74
I0901 13:28:43.548932 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.65
INFO:tensorflow:Starting iteration 21

Steps executed: 212 Episode length: 142 Return: -127.3022327436016234
INFO:tensorflow:Average training steps per second: 389.34
I0901 13:28:49.434322 140240877414400 replay_runner.py:36] Average training steps per second: 389.34
I0901 13:28:49.547463 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.61
INFO:tensorflow:Starting iteration 22

Steps executed: 273 Episode length: 88 Return: -106.56511824004482234
INFO:tensorflow:Average training steps per second: 391.19
I0901 13:28:55.362479 140240877414400 replay_runner.py:36] Average training steps per second: 391.19
I0901 13:28:55.486357 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.20
INFO:tensorflow:Starting iteration 23

Steps executed: 201 Episode length: 127 Return: -512.1086027470999234
INFO:tensorflow:Average training steps per second: 393.12
I0901 13:29:01.370844 140240877414400 replay_runner.py:36] Average training steps per second: 393.12
I0901 13:29:01.478403 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -443.03
INFO:tensorflow:Starting iteration 24

Steps executed: 260 Episode length: 125 Return: -993.7133802349865634
INFO:tensorflow:Average training steps per second: 388.87
I0901 13:29:07.342995 140240877414400 replay_runner.py:36] Average training steps per second: 388.87
I0901 13:29:07.497983 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -1024.32
INFO:tensorflow:Starting iteration 25

Steps executed: 216 Episode length: 80 Return: -490.36519970719455634
INFO:tensorflow:Average training steps per second: 396.83
I0901 13:29:13.288800 140240877414400 replay_runner.py:36] Average training steps per second: 396.83
I0901 13:29:13.391052 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -354.35
INFO:tensorflow:Starting iteration 26

Steps executed: 291 Episode length: 100 Return: -432.5400777545399634
INFO:tensorflow:Average training steps per second: 392.81
I0901 13:29:19.238830 140240877414400 replay_runner.py:36] Average training steps per second: 392.81
I0901 13:29:19.367855 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -264.08
INFO:tensorflow:Starting iteration 27

Steps executed: 224 Episode length: 68 Return: -556.00339502636339634
INFO:tensorflow:Average training steps per second: 397.10
I0901 13:29:25.134735 140240877414400 replay_runner.py:36] Average training steps per second: 397.10
I0901 13:29:25.246865 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -528.53
INFO:tensorflow:Starting iteration 28

Steps executed: 267 Episode length: 100 Return: -772.8171741253784634
INFO:tensorflow:Average training steps per second: 395.32
I0901 13:29:31.022846 140240877414400 replay_runner.py:36] Average training steps per second: 395.32
I0901 13:29:31.136933 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -445.71
INFO:tensorflow:Starting iteration 29

Steps executed: 264 Episode length: 85 Return: -646.21161080898974634
INFO:tensorflow:Average training steps per second: 398.63
I0901 13:29:36.784831 140240877414400 replay_runner.py:36] Average training steps per second: 398.63

Done fixed training!Episode length: 85 Return: -646.21161080898974634