Loaded trained dqn in acrobot
Training fixed agent 5, please be patient, may be a while...
I0902 18:06:20.515591 140223945852928 run_experiment.py:549] Creating TrainRunner ...
I0902 18:06:20.525502 140223945852928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:06:20.525733 140223945852928 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:06:20.525826 140223945852928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:06:20.525947 140223945852928 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:06:20.526065 140223945852928 dqn_agent.py:275] 	 update_period: 4
I0902 18:06:20.526500 140223945852928 dqn_agent.py:276] 	 target_update_period: 100
I0902 18:06:20.526684 140223945852928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:06:20.526817 140223945852928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:06:20.526946 140223945852928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:06:20.527159 140223945852928 dqn_agent.py:280] 	 optimizer: adam
I0902 18:06:20.527282 140223945852928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:06:20.527396 140223945852928 dqn_agent.py:283] 	 seed: 1630605980525449
I0902 18:06:20.530576 140223945852928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:06:20.530827 140223945852928 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0902 18:06:20.530951 140223945852928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:06:20.531038 140223945852928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:06:20.531165 140223945852928 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:06:20.531337 140223945852928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:06:20.531472 140223945852928 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:06:20.531548 140223945852928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:06:20.531626 140223945852928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:06:20.572370 140223945852928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 18:06:21.064346 140223945852928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 18:06:21.079262 140223945852928 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:06:21.088829 140223945852928 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:06:21.089084 140223945852928 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:06:21.089217 140223945852928 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:06:21.089372 140223945852928 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:06:21.089541 140223945852928 dqn_agent.py:275] 	 update_period: 4
I0902 18:06:21.089732 140223945852928 dqn_agent.py:276] 	 target_update_period: 100
I0902 18:06:21.089818 140223945852928 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:06:21.089903 140223945852928 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:06:21.090000 140223945852928 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:06:21.090145 140223945852928 dqn_agent.py:280] 	 optimizer: adam
I0902 18:06:21.090226 140223945852928 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:06:21.090304 140223945852928 dqn_agent.py:283] 	 seed: 1630605981088760
I0902 18:06:21.092960 140223945852928 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:06:21.093180 140223945852928 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0902 18:06:21.093345 140223945852928 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:06:21.093502 140223945852928 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:06:21.093909 140223945852928 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:06:21.094067 140223945852928 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:06:21.094217 140223945852928 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:06:21.094329 140223945852928 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:06:21.094436 140223945852928 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:06:21.128747 140223945852928 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 18:06:21.147979 140223945852928 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:06:21.148295 140223945852928 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 143.68
I0902 18:06:28.108691 140223945852928 replay_runner.py:36] Average training steps per second: 143.68
Steps executed: 500 Episode length: 500 Return: -500.0
I0902 18:06:29.676360 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1

Steps executed: 246 Episode length: 135 Return: -134.0
INFO:tensorflow:Average training steps per second: 200.82
I0902 18:06:34.904528 140223945852928 replay_runner.py:36] Average training steps per second: 200.82
I0902 18:06:35.102546 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.00
INFO:tensorflow:Starting iteration 2

Steps executed: 347 Episode length: 347 Return: -346.0
INFO:tensorflow:Average training steps per second: 199.01
I0902 18:06:40.342872 140223945852928 replay_runner.py:36] Average training steps per second: 199.01
I0902 18:06:40.650835 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.00
INFO:tensorflow:Starting iteration 3

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 205.42
I0902 18:06:45.766638 140223945852928 replay_runner.py:36] Average training steps per second: 205.42
I0902 18:06:46.197792 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 4

Steps executed: 216 Episode length: 87 Return: -86.0.0
INFO:tensorflow:Average training steps per second: 193.01
I0902 18:06:51.628479 140223945852928 replay_runner.py:36] Average training steps per second: 193.01
I0902 18:06:51.811905 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.00
INFO:tensorflow:Starting iteration 5

Steps executed: 285 Episode length: 87 Return: -86.0.0
INFO:tensorflow:Average training steps per second: 195.30
I0902 18:06:57.176288 140223945852928 replay_runner.py:36] Average training steps per second: 195.30
I0902 18:06:57.433245 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.00
INFO:tensorflow:Starting iteration 6

Steps executed: 277 Episode length: 127 Return: -126.0
INFO:tensorflow:Average training steps per second: 196.01
I0902 18:07:02.789399 140223945852928 replay_runner.py:36] Average training steps per second: 196.01
I0902 18:07:03.021878 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.50
INFO:tensorflow:Starting iteration 7
I0902 18:07:03.268234 140223945852928 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 193.09

Steps executed: 273 Episode length: 88 Return: -87.0.0
I0902 18:07:08.695025 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.00
INFO:tensorflow:Starting iteration 8

Steps executed: 214 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Average training steps per second: 200.42
I0902 18:07:13.938011 140223945852928 replay_runner.py:36] Average training steps per second: 200.42
I0902 18:07:14.123796 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.33
INFO:tensorflow:Starting iteration 9

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 194.70
I0902 18:07:19.500811 140223945852928 replay_runner.py:36] Average training steps per second: 194.70
I0902 18:07:19.913046 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 10

Steps executed: 202 Episode length: 104 Return: -103.0
INFO:tensorflow:Average training steps per second: 198.41
I0902 18:07:25.226813 140223945852928 replay_runner.py:36] Average training steps per second: 198.41
I0902 18:07:25.409840 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.00
INFO:tensorflow:Starting iteration 11
I0902 18:07:25.655592 140223945852928 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 202.55

Steps executed: 299 Episode length: 116 Return: -115.0
I0902 18:07:30.846865 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.67
INFO:tensorflow:Starting iteration 12

Steps executed: 203 Episode length: 125 Return: -124.0
INFO:tensorflow:Average training steps per second: 197.95
I0902 18:07:36.145055 140223945852928 replay_runner.py:36] Average training steps per second: 197.95
I0902 18:07:36.316839 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.50
INFO:tensorflow:Starting iteration 13

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 206.37
I0902 18:07:41.396539 140223945852928 replay_runner.py:36] Average training steps per second: 206.37
I0902 18:07:41.829840 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 14

Steps executed: 269 Episode length: 96 Return: -95.0.0
INFO:tensorflow:Average training steps per second: 200.25
I0902 18:07:47.060333 140223945852928 replay_runner.py:36] Average training steps per second: 200.25
I0902 18:07:47.273203 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.67
INFO:tensorflow:Starting iteration 15

Steps executed: 239 Episode length: 77 Return: -76.0.0
INFO:tensorflow:Average training steps per second: 199.15
I0902 18:07:52.515674 140223945852928 replay_runner.py:36] Average training steps per second: 199.15
I0902 18:07:52.717876 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.67
INFO:tensorflow:Starting iteration 16

Steps executed: 229 Episode length: 97 Return: -96.0.0
INFO:tensorflow:Average training steps per second: 205.24
I0902 18:07:57.823301 140223945852928 replay_runner.py:36] Average training steps per second: 205.24
I0902 18:07:57.999047 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.50
INFO:tensorflow:Starting iteration 17

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 204.57
I0902 18:08:03.121392 140223945852928 replay_runner.py:36] Average training steps per second: 204.57
I0902 18:08:03.570962 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 18

Steps executed: 266 Episode length: 79 Return: -78.0.0
INFO:tensorflow:Average training steps per second: 198.05
I0902 18:08:08.851794 140223945852928 replay_runner.py:36] Average training steps per second: 198.05
I0902 18:08:09.069639 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.67
INFO:tensorflow:Starting iteration 19

Steps executed: 262 Episode length: 104 Return: -103.0
INFO:tensorflow:Average training steps per second: 204.66
I0902 18:08:14.193842 140223945852928 replay_runner.py:36] Average training steps per second: 204.66
I0902 18:08:14.406625 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.33
INFO:tensorflow:Starting iteration 20

Steps executed: 255 Episode length: 71 Return: -70.0.0
INFO:tensorflow:Average training steps per second: 202.30
I0902 18:08:19.640547 140223945852928 replay_runner.py:36] Average training steps per second: 202.30
I0902 18:08:19.863026 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.00
INFO:tensorflow:Starting iteration 21

Steps executed: 288 Episode length: 93 Return: -92.0.0
INFO:tensorflow:Average training steps per second: 203.90
I0902 18:08:25.021180 140223945852928 replay_runner.py:36] Average training steps per second: 203.90
I0902 18:08:25.261018 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.00
INFO:tensorflow:Starting iteration 22
I0902 18:08:25.499193 140223945852928 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 196.21

Steps executed: 249 Episode length: 71 Return: -70.0.0
I0902 18:08:30.799164 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.00
INFO:tensorflow:Starting iteration 23

Steps executed: 267 Episode length: 82 Return: -81.0.0
INFO:tensorflow:Average training steps per second: 198.96
I0902 18:08:36.050782 140223945852928 replay_runner.py:36] Average training steps per second: 198.96
I0902 18:08:36.281791 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.00
INFO:tensorflow:Starting iteration 24

Steps executed: 291 Episode length: 96 Return: -95.0.0
INFO:tensorflow:Average training steps per second: 196.98
I0902 18:08:41.587310 140223945852928 replay_runner.py:36] Average training steps per second: 196.98
I0902 18:08:41.830197 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.00
INFO:tensorflow:Starting iteration 25

Steps executed: 300 Episode length: 187 Return: -186.0
INFO:tensorflow:Average training steps per second: 198.17
I0902 18:08:47.122528 140223945852928 replay_runner.py:36] Average training steps per second: 198.17
I0902 18:08:47.382857 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.00
INFO:tensorflow:Starting iteration 26
I0902 18:08:47.639913 140223945852928 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 202.93

Steps executed: 500 Episode length: 500 Return: -500.0
I0902 18:08:52.998441 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 27

Steps executed: 276 Episode length: 95 Return: -94.0.0
INFO:tensorflow:Average training steps per second: 202.57
I0902 18:08:58.161504 140223945852928 replay_runner.py:36] Average training steps per second: 202.57
I0902 18:08:58.365609 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.00
INFO:tensorflow:Starting iteration 28

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 206.21
I0902 18:09:03.434418 140223945852928 replay_runner.py:36] Average training steps per second: 206.21
I0902 18:09:03.839573 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 29
I0902 18:09:04.105463 140223945852928 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 206.51

Done fixed training!Episode length: 213 Return: -212.0
I0902 18:09:09.189345 140223945852928 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.50