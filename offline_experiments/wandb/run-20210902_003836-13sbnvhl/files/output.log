Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0902 00:38:41.980316 139929824643072 run_experiment.py:549] Creating TrainRunner ...
I0902 00:38:41.988385 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:38:41.988519 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:38:41.988595 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:38:41.988656 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:38:41.988711 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0902 00:38:41.988783 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:38:41.988853 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:38:41.988905 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:38:41.988984 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:38:41.989053 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0902 00:38:41.989127 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:38:41.989196 139929824643072 dqn_agent.py:283] 	 seed: 1630543121988353
I0902 00:38:41.990962 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:38:41.991096 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:38:41.991174 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:38:41.991240 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:38:41.991336 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:38:41.991493 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:38:41.991662 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:38:41.991750 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:38:41.991912 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:38:42.016230 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:38:42.599880 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:38:42.608908 139929824643072 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:38:42.616027 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:38:42.616308 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:38:42.616522 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:38:42.616635 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:38:42.616768 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0902 00:38:42.616911 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:38:42.616989 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:38:42.617065 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:38:42.617139 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:38:42.617210 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0902 00:38:42.617282 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:38:42.617353 139929824643072 dqn_agent.py:283] 	 seed: 1630543122615987
I0902 00:38:42.619022 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:38:42.619141 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:38:42.619246 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:38:42.619311 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:38:42.619404 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:38:42.619467 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:38:42.619549 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:38:42.619624 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:38:42.619690 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:38:42.642077 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:38:42.658490 139929824643072 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:38:42.658689 139929824643072 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 241.58
I0902 00:38:46.798259 139929824643072 replay_runner.py:36] Average training steps per second: 241.58
Steps executed: 278 Episode length: 278 Return: -371.5368693409416
I0902 00:38:47.646935 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -371.54
INFO:tensorflow:Starting iteration 1

Steps executed: 215 Episode length: 79 Return: -753.69323121137803
INFO:tensorflow:Average training steps per second: 340.78
I0902 00:38:54.004184 139929824643072 replay_runner.py:36] Average training steps per second: 340.78
I0902 00:38:54.133578 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -581.28
INFO:tensorflow:Starting iteration 2

Steps executed: 453 Episode length: 268 Return: -489.89420625177456
INFO:tensorflow:Average training steps per second: 339.99
I0902 00:39:00.510777 139929824643072 replay_runner.py:36] Average training steps per second: 339.99
I0902 00:39:00.823317 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -391.73
INFO:tensorflow:Starting iteration 3

Steps executed: 266 Episode length: 78 Return: -457.794985298030046
INFO:tensorflow:Average training steps per second: 342.75
I0902 00:39:07.167900 139929824643072 replay_runner.py:36] Average training steps per second: 342.75
I0902 00:39:07.310504 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -435.78
INFO:tensorflow:Starting iteration 4

Steps executed: 403 Episode length: 204 Return: -133.64487870313485
INFO:tensorflow:Average training steps per second: 330.86
I0902 00:39:13.762387 139929824643072 replay_runner.py:36] Average training steps per second: 330.86
I0902 00:39:14.021776 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -388.25
INFO:tensorflow:Starting iteration 5

Steps executed: 248 Episode length: 95 Return: -406.002860796262855
INFO:tensorflow:Average training steps per second: 335.33
I0902 00:39:20.414736 139929824643072 replay_runner.py:36] Average training steps per second: 335.33
I0902 00:39:20.561969 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -427.32
INFO:tensorflow:Starting iteration 6

Steps executed: 384 Episode length: 248 Return: -108.69330374696536
INFO:tensorflow:Average training steps per second: 335.29
I0902 00:39:26.972301 139929824643072 replay_runner.py:36] Average training steps per second: 335.29
I0902 00:39:27.203611 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.79
INFO:tensorflow:Starting iteration 7

Steps executed: 225 Episode length: 90 Return: -544.904512469358536
INFO:tensorflow:Average training steps per second: 338.73
I0902 00:39:33.580362 139929824643072 replay_runner.py:36] Average training steps per second: 338.73
I0902 00:39:33.703870 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -271.92
INFO:tensorflow:Starting iteration 8

Steps executed: 517 Episode length: 367 Return: -4032.2730350200864
INFO:tensorflow:Average training steps per second: 332.78
I0902 00:39:40.118873 139929824643072 replay_runner.py:36] Average training steps per second: 332.78
I0902 00:39:40.615056 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -2545.55
INFO:tensorflow:Starting iteration 9

Steps executed: 226 Episode length: 68 Return: -131.685945339293254
INFO:tensorflow:Average training steps per second: 336.48
I0902 00:39:46.983947 139929824643072 replay_runner.py:36] Average training steps per second: 336.48
I0902 00:39:47.109599 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.00
INFO:tensorflow:Starting iteration 10

Steps executed: 213 Episode length: 85 Return: -306.952270672410864
INFO:tensorflow:Average training steps per second: 332.98
I0902 00:39:53.503933 139929824643072 replay_runner.py:36] Average training steps per second: 332.98
I0902 00:39:53.635204 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.75
INFO:tensorflow:Starting iteration 11
I0902 00:39:57.028521 139929824643072 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 331.77

Steps executed: 231 Episode length: 90 Return: -238.011209466261424
I0902 00:40:00.150832 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.15
INFO:tensorflow:Starting iteration 12

Steps executed: 207 Episode length: 207 Return: -164.05234010714108
INFO:tensorflow:Average training steps per second: 335.23
I0902 00:40:06.514583 139929824643072 replay_runner.py:36] Average training steps per second: 335.23
I0902 00:40:06.670056 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.05
INFO:tensorflow:Starting iteration 13

Steps executed: 334 Episode length: 200 Return: -741.80485979260626
INFO:tensorflow:Average training steps per second: 330.93
I0902 00:40:13.116148 139929824643072 replay_runner.py:36] Average training steps per second: 330.93
I0902 00:40:13.335842 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -530.00
INFO:tensorflow:Starting iteration 14

Steps executed: 200 Episode length: 200 Return: -249.82471721879222
INFO:tensorflow:Average training steps per second: 330.32
I0902 00:40:19.771344 139929824643072 replay_runner.py:36] Average training steps per second: 330.32
I0902 00:40:19.920423 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -249.82
INFO:tensorflow:Starting iteration 15

Steps executed: 256 Episode length: 65 Return: -157.771396980472562
INFO:tensorflow:Average training steps per second: 330.44
I0902 00:40:26.350646 139929824643072 replay_runner.py:36] Average training steps per second: 330.44
I0902 00:40:26.524964 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.81
INFO:tensorflow:Starting iteration 16

Steps executed: 294 Episode length: 155 Return: -231.59562775929498
INFO:tensorflow:Average training steps per second: 330.83
I0902 00:40:32.950080 139929824643072 replay_runner.py:36] Average training steps per second: 330.83
I0902 00:40:33.145135 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.46
INFO:tensorflow:Starting iteration 17

Steps executed: 203 Episode length: 73 Return: -588.765957553967298
INFO:tensorflow:Average training steps per second: 332.23
I0902 00:40:39.543952 139929824643072 replay_runner.py:36] Average training steps per second: 332.23
I0902 00:40:39.672760 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -453.65
INFO:tensorflow:Starting iteration 18

Steps executed: 136 Episode length: 69 Return: -619.308017187068298
INFO:tensorflow:Average training steps per second: 328.36
I0902 00:40:46.127968 139929824643072 replay_runner.py:36] Average training steps per second: 328.36

Steps executed: 241 Episode length: 105 Return: -734.06989596825898
INFO:tensorflow:Starting iteration 19

Steps executed: 278 Episode length: 107 Return: -619.02566671646238
INFO:tensorflow:Average training steps per second: 329.01
I0902 00:40:52.728099 139929824643072 replay_runner.py:36] Average training steps per second: 329.01
I0902 00:40:52.910210 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -633.45
INFO:tensorflow:Starting iteration 20

Steps executed: 247 Episode length: 92 Return: -503.582270226699458
INFO:tensorflow:Average training steps per second: 334.01
I0902 00:40:59.288895 139929824643072 replay_runner.py:36] Average training steps per second: 334.01
I0902 00:40:59.416036 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.19
INFO:tensorflow:Starting iteration 21

Steps executed: 164 Episode length: 62 Return: -338.864289226734538
INFO:tensorflow:Average training steps per second: 332.72
I0902 00:41:05.768536 139929824643072 replay_runner.py:36] Average training steps per second: 332.72

Steps executed: 271 Episode length: 107 Return: -790.33554999128838
INFO:tensorflow:Starting iteration 22
I0902 00:41:09.101429 139929824643072 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 340.71

Steps executed: 267 Episode length: 78 Return: -150.684534749365758
I0902 00:41:12.186668 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -272.08
INFO:tensorflow:Starting iteration 23

Steps executed: 256 Episode length: 65 Return: -349.973168970886048
INFO:tensorflow:Average training steps per second: 342.88
I0902 00:41:18.252202 139929824643072 replay_runner.py:36] Average training steps per second: 342.88
I0902 00:41:18.402209 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -443.37
INFO:tensorflow:Starting iteration 24

Steps executed: 242 Episode length: 53 Return: -472.532697818505358
INFO:tensorflow:Average training steps per second: 343.15
I0902 00:41:24.486162 139929824643072 replay_runner.py:36] Average training steps per second: 343.15
I0902 00:41:24.624834 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -465.37
INFO:tensorflow:Starting iteration 25

Steps executed: 213 Episode length: 96 Return: -699.012323747018358
INFO:tensorflow:Average training steps per second: 347.97
I0902 00:41:30.514911 139929824643072 replay_runner.py:36] Average training steps per second: 347.97
I0902 00:41:30.650454 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -455.31
INFO:tensorflow:Starting iteration 26

Steps executed: 245 Episode length: 70 Return: -575.233440330810778
INFO:tensorflow:Average training steps per second: 376.44
I0902 00:41:36.313836 139929824643072 replay_runner.py:36] Average training steps per second: 376.44
I0902 00:41:36.443016 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -496.10
INFO:tensorflow:Starting iteration 27

Steps executed: 147 Episode length: 80 Return: -428.241302804659778
INFO:tensorflow:Average training steps per second: 374.83
I0902 00:41:42.057500 139929824643072 replay_runner.py:36] Average training steps per second: 374.83

Steps executed: 224 Episode length: 77 Return: -547.126419914749878
INFO:tensorflow:Starting iteration 28

Steps executed: 234 Episode length: 85 Return: -846.001341365374578
INFO:tensorflow:Average training steps per second: 428.70
I0902 00:41:47.230306 139929824643072 replay_runner.py:36] Average training steps per second: 428.70
I0902 00:41:47.338020 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -722.79
INFO:tensorflow:Starting iteration 29

Steps executed: 203 Episode length: 64 Return: -567.230310132336578
INFO:tensorflow:Average training steps per second: 417.09
I0902 00:41:52.482390 139929824643072 replay_runner.py:36] Average training steps per second: 417.09

Done fixed training!Episode length: 64 Return: -567.230310132336578