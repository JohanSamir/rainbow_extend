I0902 23:24:47.380234 140369919707136 run_experiment.py:549] Creating TrainRunner ...
I0902 23:24:47.389203 140369919707136 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:24:47.389456 140369919707136 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:24:47.389622 140369919707136 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:24:47.389710 140369919707136 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:24:47.389776 140369919707136 dqn_agent.py:275] 	 update_period: 4
I0902 23:24:47.389847 140369919707136 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:24:47.389907 140369919707136 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:24:47.389993 140369919707136 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:24:47.390125 140369919707136 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:24:47.390268 140369919707136 dqn_agent.py:280] 	 optimizer: adam
I0902 23:24:47.390489 140369919707136 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:24:47.390637 140369919707136 dqn_agent.py:283] 	 seed: 1630625087389151
I0902 23:24:47.394162 140369919707136 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:24:47.394348 140369919707136 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:24:47.394442 140369919707136 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:24:47.394519 140369919707136 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:24:47.394587 140369919707136 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:24:47.394651 140369919707136 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:24:47.394720 140369919707136 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:24:47.394767 140369919707136 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:24:47.394819 140369919707136 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:24:48.807279 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0902 23:24:49.181306 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:24:49.194790 140369919707136 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:24:49.203634 140369919707136 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:24:49.203909 140369919707136 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:24:49.204022 140369919707136 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:24:49.204132 140369919707136 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:24:49.204242 140369919707136 dqn_agent.py:275] 	 update_period: 4
I0902 23:24:49.204403 140369919707136 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:24:49.204665 140369919707136 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:24:49.204790 140369919707136 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:24:49.204941 140369919707136 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:24:49.205055 140369919707136 dqn_agent.py:280] 	 optimizer: adam
I0902 23:24:49.205194 140369919707136 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:24:49.205293 140369919707136 dqn_agent.py:283] 	 seed: 1630625089203564
I0902 23:24:49.207741 140369919707136 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:24:49.207944 140369919707136 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:24:49.208080 140369919707136 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:24:49.208223 140369919707136 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:24:49.208336 140369919707136 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:24:49.208425 140369919707136 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:24:49.208560 140369919707136 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:24:49.208631 140369919707136 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:24:49.208818 140369919707136 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:24:49.237277 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:24:49.258056 140369919707136 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:24:49.258252 140369919707136 replay_runner.py:41] Starting iteration 0
Steps executed: 220 Episode length: 123 Return: -554.5187095272463
INFO:tensorflow:Average training steps per second: 168.14
I0902 23:24:55.205950 140369919707136 replay_runner.py:36] Average training steps per second: 168.14
I0902 23:24:56.488651 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.25
INFO:tensorflow:Starting iteration 1

Steps executed: 237 Episode length: 105 Return: -17.70845371145988
INFO:tensorflow:Average training steps per second: 228.58
I0902 23:25:05.247225 140369919707136 replay_runner.py:36] Average training steps per second: 228.58
I0902 23:25:05.439699 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.30
INFO:tensorflow:Starting iteration 2

Steps executed: 285 Episode length: 285 Return: -42.99686560701009
INFO:tensorflow:Average training steps per second: 233.38
I0902 23:25:13.956927 140369919707136 replay_runner.py:36] Average training steps per second: 233.38
I0902 23:25:14.356610 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -43.00
INFO:tensorflow:Starting iteration 3
I0902 23:25:18.627478 140369919707136 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 230.76

Steps executed: 948 Episode length: 948 Return: -492.6902292309258
I0902 23:25:26.260800 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -492.69
INFO:tensorflow:Starting iteration 4
I0902 23:25:30.291760 140369919707136 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 223.55
I0902 23:25:34.766044 140369919707136 replay_runner.py:36] Average training steps per second: 223.55

Steps executed: 1000 Episode length: 1000 Return: -179.5022234742523
INFO:tensorflow:Starting iteration 5
I0902 23:25:41.511516 140369919707136 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 230.15

Steps executed: 1000 Episode length: 1000 Return: -231.9943653079649
I0902 23:25:48.185109 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.99
INFO:tensorflow:Starting iteration 6
I0902 23:25:52.490917 140369919707136 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 217.50

Steps executed: 1000 Episode length: 1000 Return: -297.5798191810707
I0902 23:25:59.532262 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -297.58
INFO:tensorflow:Starting iteration 7
I0902 23:26:03.822018 140369919707136 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 226.26

Steps executed: 1000 Episode length: 1000 Return: -280.40460427967014
I0902 23:26:10.853326 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.40
INFO:tensorflow:Starting iteration 8

Steps executed: 598 Episode length: 598 Return: -245.2753652722500714
INFO:tensorflow:Average training steps per second: 225.14
I0902 23:26:19.596992 140369919707136 replay_runner.py:36] Average training steps per second: 225.14
I0902 23:26:20.877267 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.28
INFO:tensorflow:Starting iteration 9

Steps executed: 427 Episode length: 427 Return: -165.1864082910344714
INFO:tensorflow:Average training steps per second: 228.90
I0902 23:26:29.602065 140369919707136 replay_runner.py:36] Average training steps per second: 228.90
I0902 23:26:30.249302 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.19
INFO:tensorflow:Starting iteration 10
I0902 23:26:34.622494 140369919707136 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 235.53

Steps executed: 1000 Episode length: 1000 Return: -155.59228755028834
I0902 23:26:41.882089 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.59
INFO:tensorflow:Starting iteration 11
I0902 23:26:46.222620 140369919707136 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 230.29

Steps executed: 1000 Episode length: 1000 Return: -137.38994833796874
I0902 23:26:52.584026 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.39
INFO:tensorflow:Starting iteration 12
I0902 23:26:56.998649 140369919707136 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 232.00

Steps executed: 1000 Episode length: 1000 Return: -151.18004092536624
I0902 23:27:04.011228 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.18
INFO:tensorflow:Starting iteration 13
I0902 23:27:08.303581 140369919707136 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 232.83

Steps executed: 1000 Episode length: 1000 Return: -160.78822187446054
I0902 23:27:15.727072 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.79
INFO:tensorflow:Starting iteration 14

Steps executed: 430 Episode length: 430 Return: -313.7800494601306054
INFO:tensorflow:Average training steps per second: 228.30
I0902 23:27:24.491903 140369919707136 replay_runner.py:36] Average training steps per second: 228.30
I0902 23:27:25.090719 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -313.78
INFO:tensorflow:Starting iteration 15

Steps executed: 705 Episode length: 705 Return: -178.2248370193730754
INFO:tensorflow:Average training steps per second: 227.94
I0902 23:27:33.874112 140369919707136 replay_runner.py:36] Average training steps per second: 227.94
I0902 23:27:35.576456 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.22
INFO:tensorflow:Starting iteration 16

Steps executed: 175 Episode length: 175 Return: -69.14880586312228754
INFO:tensorflow:Average training steps per second: 225.46
I0902 23:27:44.306785 140369919707136 replay_runner.py:36] Average training steps per second: 225.46

Steps executed: 948 Episode length: 773 Return: -316.3462627670785454
INFO:tensorflow:Starting iteration 17

Steps executed: 286 Episode length: 155 Return: -593.2996521366302454
INFO:tensorflow:Average training steps per second: 227.71
I0902 23:27:54.366733 140369919707136 replay_runner.py:36] Average training steps per second: 227.71
I0902 23:27:54.617080 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.08
INFO:tensorflow:Starting iteration 18

Steps executed: 263 Episode length: 133 Return: -212.3999471218901654
INFO:tensorflow:Average training steps per second: 227.11
I0902 23:28:03.129622 140369919707136 replay_runner.py:36] Average training steps per second: 227.11
I0902 23:28:03.375084 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -451.26
INFO:tensorflow:Starting iteration 19
I0902 23:28:07.333909 140369919707136 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 224.43

Steps executed: 455 Episode length: 455 Return: 240.11522216125513654
I0902 23:28:12.594343 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: 240.12
INFO:tensorflow:Starting iteration 20

Steps executed: 302 Episode length: 159 Return: -56.63904339815539454
INFO:tensorflow:Average training steps per second: 235.93
I0902 23:28:21.212925 140369919707136 replay_runner.py:36] Average training steps per second: 235.93
I0902 23:28:21.463783 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.58
INFO:tensorflow:Starting iteration 21

Steps executed: 237 Episode length: 237 Return: -15.02923701161896454
INFO:tensorflow:Average training steps per second: 238.77
I0902 23:28:29.887561 140369919707136 replay_runner.py:36] Average training steps per second: 238.77
I0902 23:28:30.192216 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -15.03
INFO:tensorflow:Starting iteration 22

Steps executed: 245 Episode length: 123 Return: -870.4035944791257454
INFO:tensorflow:Average training steps per second: 229.16
I0902 23:28:38.887303 140369919707136 replay_runner.py:36] Average training steps per second: 229.16
I0902 23:28:39.106105 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -656.90
INFO:tensorflow:Starting iteration 23

Steps executed: 235 Episode length: 235 Return: -532.4337981821437454
INFO:tensorflow:Average training steps per second: 223.54
I0902 23:28:47.775103 140369919707136 replay_runner.py:36] Average training steps per second: 223.54
I0902 23:28:48.035235 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -532.43
INFO:tensorflow:Starting iteration 24

Steps executed: 137 Episode length: 137 Return: 16.189621311906257454
INFO:tensorflow:Average training steps per second: 221.91

Steps executed: 767 Episode length: 630 Return: -134.0418729313584454
I0902 23:28:58.457765 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -58.93
INFO:tensorflow:Starting iteration 25

Steps executed: 238 Episode length: 104 Return: -111.2822429610435254
INFO:tensorflow:Average training steps per second: 223.47
I0902 23:29:07.188763 140369919707136 replay_runner.py:36] Average training steps per second: 223.47
I0902 23:29:07.387867 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -267.42
INFO:tensorflow:Starting iteration 26

Steps executed: 277 Episode length: 277 Return: -288.6097635965276254
INFO:tensorflow:Average training steps per second: 220.79
I0902 23:29:16.192948 140369919707136 replay_runner.py:36] Average training steps per second: 220.79
I0902 23:29:16.550836 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.61
INFO:tensorflow:Starting iteration 27

Steps executed: 275 Episode length: 135 Return: -99.60709974803191254
INFO:tensorflow:Average training steps per second: 218.49
I0902 23:29:25.409312 140369919707136 replay_runner.py:36] Average training steps per second: 218.49
I0902 23:29:25.664660 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.68
INFO:tensorflow:Starting iteration 28

Steps executed: 213 Episode length: 133 Return: -286.6229348214368454
INFO:tensorflow:Average training steps per second: 224.56
I0902 23:29:34.255358 140369919707136 replay_runner.py:36] Average training steps per second: 224.56
I0902 23:29:34.462302 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -381.76
INFO:tensorflow:Starting iteration 29

Steps executed: 216 Episode length: 146 Return: -203.8336773147047454
INFO:tensorflow:Average training steps per second: 220.34
I0902 23:29:43.058512 140369919707136 replay_runner.py:36] Average training steps per second: 220.34

Done fixed training!Episode length: 146 Return: -203.8336773147047454