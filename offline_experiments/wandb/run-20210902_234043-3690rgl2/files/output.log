Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0902 23:40:50.379431 140457530894336 run_experiment.py:549] Creating TrainRunner ...
I0902 23:40:50.391665 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:40:50.391943 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:40:50.392127 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:40:50.392336 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:40:50.392472 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0902 23:40:50.392628 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:40:50.392783 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:40:50.392932 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:40:50.393005 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:40:50.393080 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0902 23:40:50.393154 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:40:50.393279 140457530894336 dqn_agent.py:283] 	 seed: 1630626050391573
I0902 23:40:50.396226 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:40:50.396455 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:40:50.396543 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:40:50.396609 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:40:50.396698 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:40:50.396779 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:40:50.396871 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:40:50.396945 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:40:50.397018 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:40:50.432038 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:40:50.784209 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:40:50.797427 140457530894336 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:40:50.807428 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:40:50.807746 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:40:50.807940 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:40:50.808243 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:40:50.808443 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0902 23:40:50.808606 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:40:50.808694 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:40:50.808849 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:40:50.809022 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:40:50.809161 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0902 23:40:50.809299 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:40:50.809432 140457530894336 dqn_agent.py:283] 	 seed: 1630626050807356
I0902 23:40:50.811611 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:40:50.811735 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:40:50.811811 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:40:50.811874 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:40:50.811931 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:40:50.812004 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:40:50.812071 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:40:50.812124 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:40:50.812176 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:40:50.841863 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:40:50.863290 140457530894336 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:40:50.863590 140457530894336 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 160.49
I0902 23:40:57.101271 140457530894336 replay_runner.py:36] Average training steps per second: 160.49
Steps executed: 202 Episode length: 97 Return: -374.169651549011413
I0902 23:40:58.330079 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -411.50
INFO:tensorflow:Starting iteration 1

Steps executed: 246 Episode length: 101 Return: -328.79526719863164
INFO:tensorflow:Average training steps per second: 224.52
I0902 23:41:07.201750 140457530894336 replay_runner.py:36] Average training steps per second: 224.52
I0902 23:41:07.407255 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -372.86
INFO:tensorflow:Starting iteration 2

Steps executed: 277 Episode length: 116 Return: -335.30838411752977
INFO:tensorflow:Average training steps per second: 227.27
I0902 23:41:16.173869 140457530894336 replay_runner.py:36] Average training steps per second: 227.27
I0902 23:41:16.422447 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.06
INFO:tensorflow:Starting iteration 3

Steps executed: 265 Episode length: 265 Return: -109.76155481368892
INFO:tensorflow:Average training steps per second: 222.87
I0902 23:41:25.245764 140457530894336 replay_runner.py:36] Average training steps per second: 222.87
I0902 23:41:25.602206 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.76
INFO:tensorflow:Starting iteration 4

Steps executed: 691 Episode length: 691 Return: -192.12454649706729
INFO:tensorflow:Average training steps per second: 221.36
I0902 23:41:34.448185 140457530894336 replay_runner.py:36] Average training steps per second: 221.36
I0902 23:41:36.075810 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.12
INFO:tensorflow:Starting iteration 5
I0902 23:41:40.423752 140457530894336 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 221.87

Steps executed: 1000 Episode length: 1000 Return: 6.241572093297411
I0902 23:41:47.935362 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: 6.24
INFO:tensorflow:Starting iteration 6

Steps executed: 288 Episode length: 288 Return: -523.33637146342511
INFO:tensorflow:Average training steps per second: 223.11
I0902 23:41:56.617206 140457530894336 replay_runner.py:36] Average training steps per second: 223.11
I0902 23:41:56.990887 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -523.34
INFO:tensorflow:Starting iteration 7
I0902 23:42:01.041927 140457530894336 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 222.18

Steps executed: 1000 Episode length: 1000 Return: -29.512326579202597
I0902 23:42:09.366666 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -29.51
INFO:tensorflow:Starting iteration 8
I0902 23:42:13.777929 140457530894336 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 221.52

Steps executed: 934 Episode length: 934 Return: -149.1975157110788597
I0902 23:42:20.955026 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.20
INFO:tensorflow:Starting iteration 9
I0902 23:42:25.325614 140457530894336 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 219.29

Steps executed: 1000 Episode length: 1000 Return: -136.03190718798937
I0902 23:42:33.184682 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.03
INFO:tensorflow:Starting iteration 10

Steps executed: 370 Episode length: 370 Return: -383.1328915510671937
INFO:tensorflow:Average training steps per second: 224.45
I0902 23:42:41.876869 140457530894336 replay_runner.py:36] Average training steps per second: 224.45
I0902 23:42:42.376872 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -383.13
INFO:tensorflow:Starting iteration 11

Steps executed: 250 Episode length: 250 Return: -209.2339209535398437
INFO:tensorflow:Average training steps per second: 215.73
I0902 23:42:51.248648 140457530894336 replay_runner.py:36] Average training steps per second: 215.73
I0902 23:42:51.590255 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.23
INFO:tensorflow:Starting iteration 12
I0902 23:42:55.763974 140457530894336 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 226.55

Steps executed: 1000 Episode length: 1000 Return: -327.72291821297937
I0902 23:43:02.998745 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.72
INFO:tensorflow:Starting iteration 13
I0902 23:43:07.255102 140457530894336 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 222.15

Steps executed: 1000 Episode length: 1000 Return: -149.24617849119545
I0902 23:43:15.178812 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.25
INFO:tensorflow:Starting iteration 14

Steps executed: 391 Episode length: 199 Return: -388.3664210728412645
INFO:tensorflow:Average training steps per second: 218.14
I0902 23:43:24.199562 140457530894336 replay_runner.py:36] Average training steps per second: 218.14
I0902 23:43:24.588186 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -457.63
INFO:tensorflow:Starting iteration 15

Steps executed: 329 Episode length: 329 Return: -155.7579123170830845
INFO:tensorflow:Average training steps per second: 225.37
I0902 23:43:33.253470 140457530894336 replay_runner.py:36] Average training steps per second: 225.37
I0902 23:43:33.629005 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.76
INFO:tensorflow:Starting iteration 16
I0902 23:43:37.898186 140457530894336 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 217.38

Steps executed: 1000 Episode length: 1000 Return: -17.037094376819535
I0902 23:43:44.936183 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -17.04
INFO:tensorflow:Starting iteration 17

Steps executed: 404 Episode length: 404 Return: -146.4774704673897635
INFO:tensorflow:Average training steps per second: 227.36
I0902 23:43:53.645908 140457530894336 replay_runner.py:36] Average training steps per second: 227.36
I0902 23:43:54.327873 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.48
INFO:tensorflow:Starting iteration 18
I0902 23:43:58.601648 140457530894336 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 231.12

Steps executed: 344 Episode length: 178 Return: -25.30379025489365635
I0902 23:44:03.248823 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.99
INFO:tensorflow:Starting iteration 19
I0902 23:44:07.644702 140457530894336 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 220.22

Steps executed: 1000 Episode length: 1000 Return: -184.84019573072145
I0902 23:44:14.307221 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.84
INFO:tensorflow:Starting iteration 20

Steps executed: 402 Episode length: 402 Return: -217.6591712503379245
INFO:tensorflow:Average training steps per second: 226.63
I0902 23:44:23.172413 140457530894336 replay_runner.py:36] Average training steps per second: 226.63
I0902 23:44:23.736669 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.66
INFO:tensorflow:Starting iteration 21

Steps executed: 330 Episode length: 165 Return: -119.9252485756373645
INFO:tensorflow:Average training steps per second: 221.00
I0902 23:44:32.609079 140457530894336 replay_runner.py:36] Average training steps per second: 221.00
I0902 23:44:32.905049 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.76
INFO:tensorflow:Starting iteration 22

Steps executed: 310 Episode length: 310 Return: -252.5870733376498645
INFO:tensorflow:Average training steps per second: 223.82
I0902 23:44:41.727717 140457530894336 replay_runner.py:36] Average training steps per second: 223.82
I0902 23:44:42.203271 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -252.59
INFO:tensorflow:Starting iteration 23

Steps executed: 264 Episode length: 133 Return: -511.5609561059979645
INFO:tensorflow:Average training steps per second: 225.71
I0902 23:44:51.091379 140457530894336 replay_runner.py:36] Average training steps per second: 225.71
I0902 23:44:51.358538 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.82
INFO:tensorflow:Starting iteration 24

Steps executed: 282 Episode length: 112 Return: -781.8744904538469645
INFO:tensorflow:Average training steps per second: 226.15
I0902 23:45:00.233838 140457530894336 replay_runner.py:36] Average training steps per second: 226.15
I0902 23:45:00.500773 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -598.05
INFO:tensorflow:Starting iteration 25

Steps executed: 436 Episode length: 257 Return: -386.4298944774443545
INFO:tensorflow:Average training steps per second: 222.90
I0902 23:45:09.417111 140457530894336 replay_runner.py:36] Average training steps per second: 222.90
I0902 23:45:09.888791 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -417.52
INFO:tensorflow:Starting iteration 26
I0902 23:45:14.413793 140457530894336 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 227.59

Steps executed: 228 Episode length: 125 Return: -446.4373598331938745
I0902 23:45:19.028133 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -447.23
INFO:tensorflow:Starting iteration 27

Steps executed: 383 Episode length: 240 Return: -539.3548322868244745
INFO:tensorflow:Average training steps per second: 232.13
I0902 23:45:27.671731 140457530894336 replay_runner.py:36] Average training steps per second: 232.13
I0902 23:45:28.045433 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -560.08
INFO:tensorflow:Starting iteration 28
I0902 23:45:32.452642 140457530894336 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 220.82

Steps executed: 251 Episode length: 70 Return: -173.98509339105198745
I0902 23:45:37.179766 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.11
INFO:tensorflow:Starting iteration 29

Steps executed: 254 Episode length: 59 Return: -162.81893433496031745
INFO:tensorflow:Average training steps per second: 225.80
I0902 23:45:45.961992 140457530894336 replay_runner.py:36] Average training steps per second: 225.80

Done fixed training!Episode length: 59 Return: -162.81893433496031745