I0828 10:47:12.914091 140251198892032 run_experiment.py:549] Creating TrainRunner ...
I0828 10:47:12.923425 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:47:12.923579 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:47:12.923676 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:47:12.923771 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:47:12.923857 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:47:12.923925 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:47:12.924015 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:47:12.924118 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:47:12.924216 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:47:12.924297 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:47:12.924389 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:47:12.924471 140251198892032 dqn_agent.py:283] 	 seed: 1630147632923384
I0828 10:47:12.926648 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:47:12.926786 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:47:12.926895 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:47:12.926981 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:47:12.927120 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:47:12.927224 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:47:12.927359 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:47:12.927437 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:47:12.927511 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:47:12.955854 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:13.207376 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:13.217628 140251198892032 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:47:13.223862 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:47:13.223994 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:47:13.224074 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:47:13.224137 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:47:13.224192 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:47:13.224267 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:47:13.224357 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:47:13.224428 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:47:13.224484 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:47:13.224562 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:47:13.224618 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:47:13.224688 140251198892032 dqn_agent.py:283] 	 seed: 1630147633223833
I0828 10:47:13.226322 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:47:13.226482 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:47:13.226576 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:47:13.226658 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:47:13.226755 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:47:13.226836 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:47:13.227013 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:47:13.227113 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:47:13.227204 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:47:13.249049 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:13.264672 140251198892032 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:47:13.264900 140251198892032 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 229.93
I0828 10:47:17.614242 140251198892032 replay_runner.py:36] Average training steps per second: 229.93
I0828 10:47:18.396693 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.64
Steps executed: 219 Episode length: 104 Return: -252.49995225259283
INFO:tensorflow:Starting iteration 1

Steps executed: 243 Episode length: 95 Return: -308.163083519485633
INFO:tensorflow:Average training steps per second: 341.07
I0828 10:47:24.711846 140251198892032 replay_runner.py:36] Average training steps per second: 341.07
I0828 10:47:24.852333 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.44
INFO:tensorflow:Starting iteration 2

Steps executed: 356 Episode length: 177 Return: -159.27128493524947
INFO:tensorflow:Average training steps per second: 355.93
I0828 10:47:31.092833 140251198892032 replay_runner.py:36] Average training steps per second: 355.93
I0828 10:47:31.336934 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.45
INFO:tensorflow:Starting iteration 3

Steps executed: 388 Episode length: 269 Return: 245.815659104347827
INFO:tensorflow:Average training steps per second: 339.36
I0828 10:47:37.687368 140251198892032 replay_runner.py:36] Average training steps per second: 339.36
I0828 10:47:37.948451 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.79
INFO:tensorflow:Starting iteration 4
I0828 10:47:41.342554 140251198892032 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 341.43

Steps executed: 1000 Episode length: 1000 Return: -132.0965725840163
I0828 10:47:46.544761 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.10
INFO:tensorflow:Starting iteration 5
I0828 10:47:49.819067 140251198892032 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 331.79

Steps executed: 1000 Episode length: 1000 Return: -197.9380881605783
I0828 10:47:54.866842 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.94
INFO:tensorflow:Starting iteration 6

Steps executed: 1000 Episode length: 1000 Return: -228.68534456291763
INFO:tensorflow:Average training steps per second: 326.59
I0828 10:48:01.191657 140251198892032 replay_runner.py:36] Average training steps per second: 326.59
I0828 10:48:02.649957 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.69
INFO:tensorflow:Starting iteration 7

Steps executed: 1000 Episode length: 1000 Return: -508.44455524351763
INFO:tensorflow:Average training steps per second: 329.34
I0828 10:48:08.871451 140251198892032 replay_runner.py:36] Average training steps per second: 329.34
I0828 10:48:10.419375 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -508.44
INFO:tensorflow:Starting iteration 8
I0828 10:48:13.564573 140251198892032 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 313.33

Steps executed: 346 Episode length: 346 Return: -295.7158089311349763
I0828 10:48:17.076717 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -295.72
INFO:tensorflow:Starting iteration 9
I0828 10:48:20.252422 140251198892032 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 321.18

Steps executed: 972 Episode length: 972 Return: -490.9067198386498563
I0828 10:48:25.202098 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -490.91
INFO:tensorflow:Starting iteration 10

Steps executed: 1000 Episode length: 1000 Return: -169.93661856362874
INFO:tensorflow:Average training steps per second: 321.67
I0828 10:48:31.672950 140251198892032 replay_runner.py:36] Average training steps per second: 321.67
I0828 10:48:32.818974 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.94
INFO:tensorflow:Starting iteration 11

Steps executed: 1000 Episode length: 1000 Return: -166.99974132791624
INFO:tensorflow:Average training steps per second: 335.61
I0828 10:48:39.126772 140251198892032 replay_runner.py:36] Average training steps per second: 335.61
I0828 10:48:40.904764 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.00
INFO:tensorflow:Starting iteration 12

Steps executed: 1000 Episode length: 1000 Return: -221.24010708720194
INFO:tensorflow:Average training steps per second: 333.71
I0828 10:48:47.267884 140251198892032 replay_runner.py:36] Average training steps per second: 333.71
I0828 10:48:48.894079 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.24
INFO:tensorflow:Starting iteration 13

Steps executed: 247 Episode length: 247 Return: -155.2446977198980694
INFO:tensorflow:Average training steps per second: 329.80
I0828 10:48:55.288595 140251198892032 replay_runner.py:36] Average training steps per second: 329.80
I0828 10:48:55.459683 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.24
INFO:tensorflow:Starting iteration 14
I0828 10:48:58.584271 140251198892032 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 307.74

Steps executed: 659 Episode length: 659 Return: -388.6562654510063394
I0828 10:49:03.285535 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -388.66
INFO:tensorflow:Starting iteration 15

Steps executed: 232 Episode length: 113 Return: -566.8087462591502394
INFO:tensorflow:Average training steps per second: 316.17
I0828 10:49:09.569920 140251198892032 replay_runner.py:36] Average training steps per second: 316.17
I0828 10:49:09.718203 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -740.86
INFO:tensorflow:Starting iteration 16
I0828 10:49:12.721066 140251198892032 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 323.72

Steps executed: 1000 Episode length: 1000 Return: -398.98678528555206
I0828 10:49:18.182178 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -398.99
INFO:tensorflow:Starting iteration 17

Steps executed: 518 Episode length: 518 Return: -324.4110427525181206
INFO:tensorflow:Average training steps per second: 309.39
I0828 10:49:24.523360 140251198892032 replay_runner.py:36] Average training steps per second: 309.39
I0828 10:49:25.162129 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -324.41
INFO:tensorflow:Starting iteration 18

Steps executed: 234 Episode length: 234 Return: -278.8863680786714706
INFO:tensorflow:Average training steps per second: 333.05
I0828 10:49:31.363759 140251198892032 replay_runner.py:36] Average training steps per second: 333.05
I0828 10:49:31.506022 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -278.89
INFO:tensorflow:Starting iteration 19

Steps executed: 405 Episode length: 209 Return: -94.03458324514139706
INFO:tensorflow:Average training steps per second: 322.34
I0828 10:49:37.929386 140251198892032 replay_runner.py:36] Average training steps per second: 322.34
I0828 10:49:38.189563 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.50
INFO:tensorflow:Starting iteration 20

Steps executed: 248 Episode length: 115 Return: -536.5668288266253706
INFO:tensorflow:Average training steps per second: 324.04
I0828 10:49:44.510868 140251198892032 replay_runner.py:36] Average training steps per second: 324.04
I0828 10:49:44.652373 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.53
INFO:tensorflow:Starting iteration 21
I0828 10:49:47.949830 140251198892032 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 328.90

Steps executed: 260 Episode length: 64 Return: -169.76646464914614706
I0828 10:49:51.118884 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.79
INFO:tensorflow:Starting iteration 22

Steps executed: 497 Episode length: 383 Return: -283.3005922575863506
INFO:tensorflow:Average training steps per second: 325.89
I0828 10:49:57.468118 140251198892032 replay_runner.py:36] Average training steps per second: 325.89
I0828 10:49:57.961689 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -483.89
INFO:tensorflow:Starting iteration 23

Steps executed: 224 Episode length: 124 Return: -799.6013271709306406
INFO:tensorflow:Average training steps per second: 304.31
I0828 10:50:04.453896 140251198892032 replay_runner.py:36] Average training steps per second: 304.31
I0828 10:50:04.575961 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -625.14
INFO:tensorflow:Starting iteration 24

Steps executed: 212 Episode length: 212 Return: -328.3745353912664406
INFO:tensorflow:Average training steps per second: 326.79
I0828 10:50:10.854915 140251198892032 replay_runner.py:36] Average training steps per second: 326.79
I0828 10:50:10.995741 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.37
INFO:tensorflow:Starting iteration 25

Steps executed: 283 Episode length: 87 Return: -97.662080176899472406
INFO:tensorflow:Average training steps per second: 335.98
I0828 10:50:17.323895 140251198892032 replay_runner.py:36] Average training steps per second: 335.98
I0828 10:50:17.498616 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -343.76
INFO:tensorflow:Starting iteration 26

Steps executed: 372 Episode length: 193 Return: -598.1995677824456406
INFO:tensorflow:Average training steps per second: 335.63
I0828 10:50:23.734068 140251198892032 replay_runner.py:36] Average training steps per second: 335.63
I0828 10:50:23.987863 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -494.20
INFO:tensorflow:Starting iteration 27

Steps executed: 201 Episode length: 149 Return: -189.4694235107352806
INFO:tensorflow:Average training steps per second: 350.94
I0828 10:50:29.993628 140251198892032 replay_runner.py:36] Average training steps per second: 350.94
I0828 10:50:30.107656 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.26
INFO:tensorflow:Starting iteration 28

Steps executed: 261 Episode length: 129 Return: -73.28601886026848406
INFO:tensorflow:Average training steps per second: 327.35
I0828 10:50:36.428143 140251198892032 replay_runner.py:36] Average training steps per second: 327.35
I0828 10:50:36.563716 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.54
INFO:tensorflow:Starting iteration 29

Steps executed: 201 Episode length: 78 Return: -760.24246775217882406
INFO:tensorflow:Average training steps per second: 328.95
I0828 10:50:42.680114 140251198892032 replay_runner.py:36] Average training steps per second: 328.95

Done fixed training!Episode length: 78 Return: -760.24246775217882406