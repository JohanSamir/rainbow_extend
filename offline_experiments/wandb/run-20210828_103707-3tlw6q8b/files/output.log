Loaded trained dqn in acrobot
Training fixed agent 7, please be patient, may be a while...
I0828 10:37:14.389772 140659155802112 run_experiment.py:549] Creating TrainRunner ...
I0828 10:37:14.399430 140659155802112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:14.399700 140659155802112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:14.399863 140659155802112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:14.400170 140659155802112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:14.400356 140659155802112 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:14.400508 140659155802112 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:37:14.400655 140659155802112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:14.400790 140659155802112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:14.400974 140659155802112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:14.401113 140659155802112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:14.401226 140659155802112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:14.401343 140659155802112 dqn_agent.py:283] 	 seed: 1630147034399367
I0828 10:37:14.404437 140659155802112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:14.404633 140659155802112 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:37:14.404810 140659155802112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:14.404987 140659155802112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:14.405118 140659155802112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:14.405230 140659155802112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:14.405338 140659155802112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:14.405441 140659155802112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:14.405545 140659155802112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:14.443618 140659155802112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:14.890313 140659155802112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:14.903335 140659155802112 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:37:14.911485 140659155802112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:14.911736 140659155802112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:14.911896 140659155802112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:14.912034 140659155802112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:14.912126 140659155802112 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:14.912203 140659155802112 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:37:14.912314 140659155802112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:14.912508 140659155802112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:14.912592 140659155802112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:14.912714 140659155802112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:14.912808 140659155802112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:14.912930 140659155802112 dqn_agent.py:283] 	 seed: 1630147034911436
I0828 10:37:14.915797 140659155802112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:14.915999 140659155802112 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:37:14.916130 140659155802112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:14.916258 140659155802112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:14.916489 140659155802112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:14.916623 140659155802112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:14.916747 140659155802112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:14.916865 140659155802112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:14.916980 140659155802112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:14.949980 140659155802112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:14.974799 140659155802112 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:37:14.975088 140659155802112 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 154.01
I0828 10:37:21.468255 140659155802112 replay_runner.py:36] Average training steps per second: 154.01
Steps executed: 256 Episode length: 256 Return: -255.0
I0828 10:37:22.635537 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.00
INFO:tensorflow:Starting iteration 1
I0828 10:37:22.892068 140659155802112 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 202.02

Steps executed: 324 Episode length: 158 Return: -157.0
I0828 10:37:28.087734 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.00
INFO:tensorflow:Starting iteration 2

Steps executed: 265 Episode length: 140 Return: -139.0
INFO:tensorflow:Average training steps per second: 210.15
I0828 10:37:33.074752 140659155802112 replay_runner.py:36] Average training steps per second: 210.15
I0828 10:37:33.279519 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.50
INFO:tensorflow:Starting iteration 3

Steps executed: 269 Episode length: 83 Return: -82.0.0
INFO:tensorflow:Average training steps per second: 195.63
I0828 10:37:38.615586 140659155802112 replay_runner.py:36] Average training steps per second: 195.63
I0828 10:37:38.833225 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.67
INFO:tensorflow:Starting iteration 4
I0828 10:37:39.070638 140659155802112 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 197.45

Steps executed: 214 Episode length: 86 Return: -85.0.0
I0828 10:37:44.308954 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.00
INFO:tensorflow:Starting iteration 5

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 195.61
I0828 10:37:49.649488 140659155802112 replay_runner.py:36] Average training steps per second: 195.61
I0828 10:37:50.057308 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6

Steps executed: 208 Episode length: 88 Return: -87.0.0
INFO:tensorflow:Average training steps per second: 196.96
I0828 10:37:55.377050 140659155802112 replay_runner.py:36] Average training steps per second: 196.96
I0828 10:37:55.554963 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.00
INFO:tensorflow:Starting iteration 7

Steps executed: 312 Episode length: 127 Return: -126.0
INFO:tensorflow:Average training steps per second: 193.38
I0828 10:38:00.976948 140659155802112 replay_runner.py:36] Average training steps per second: 193.38
I0828 10:38:01.248790 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.00
INFO:tensorflow:Starting iteration 8

Steps executed: 262 Episode length: 122 Return: -121.0
INFO:tensorflow:Average training steps per second: 196.36
I0828 10:38:06.583282 140659155802112 replay_runner.py:36] Average training steps per second: 196.36
I0828 10:38:06.814220 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.00
INFO:tensorflow:Starting iteration 9
I0828 10:38:07.071489 140659155802112 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 196.88

Steps executed: 500 Episode length: 500 Return: -500.0
I0828 10:38:12.558736 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 10

Steps executed: 287 Episode length: 96 Return: -95.0.0
INFO:tensorflow:Average training steps per second: 194.30
I0828 10:38:17.954631 140659155802112 replay_runner.py:36] Average training steps per second: 194.30
I0828 10:38:18.191183 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.67
INFO:tensorflow:Starting iteration 11

Steps executed: 206 Episode length: 111 Return: -110.0
INFO:tensorflow:Average training steps per second: 194.54
I0828 10:38:23.583101 140659155802112 replay_runner.py:36] Average training steps per second: 194.54
I0828 10:38:23.764736 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.00
INFO:tensorflow:Starting iteration 12

Steps executed: 221 Episode length: 80 Return: -79.0.0
INFO:tensorflow:Average training steps per second: 194.84
I0828 10:38:29.127111 140659155802112 replay_runner.py:36] Average training steps per second: 194.84
I0828 10:38:29.309811 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.67
INFO:tensorflow:Starting iteration 13
I0828 10:38:29.553771 140659155802112 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 198.19

Steps executed: 229 Episode length: 84 Return: -83.0.0
I0828 10:38:34.797061 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.33
INFO:tensorflow:Starting iteration 14

Steps executed: 260 Episode length: 74 Return: -73.0.0
INFO:tensorflow:Average training steps per second: 193.28
I0828 10:38:40.216893 140659155802112 replay_runner.py:36] Average training steps per second: 193.28
I0828 10:38:40.440655 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.67
INFO:tensorflow:Starting iteration 15

Steps executed: 247 Episode length: 121 Return: -120.0
INFO:tensorflow:Average training steps per second: 193.82
I0828 10:38:45.829274 140659155802112 replay_runner.py:36] Average training steps per second: 193.82
I0828 10:38:46.031587 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.50
INFO:tensorflow:Starting iteration 16

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 195.41
I0828 10:38:51.402793 140659155802112 replay_runner.py:36] Average training steps per second: 195.41
I0828 10:38:51.812239 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 17

Steps executed: 231 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Average training steps per second: 200.69
I0828 10:38:57.054327 140659155802112 replay_runner.py:36] Average training steps per second: 200.69
I0828 10:38:57.236192 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.00
INFO:tensorflow:Starting iteration 18

Steps executed: 241 Episode length: 110 Return: -109.0
INFO:tensorflow:Average training steps per second: 195.51
I0828 10:39:02.575765 140659155802112 replay_runner.py:36] Average training steps per second: 195.51
I0828 10:39:02.762938 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.50
INFO:tensorflow:Starting iteration 19

Steps executed: 218 Episode length: 117 Return: -116.0
INFO:tensorflow:Average training steps per second: 200.40
I0828 10:39:07.995627 140659155802112 replay_runner.py:36] Average training steps per second: 200.40
I0828 10:39:08.174471 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.00
INFO:tensorflow:Starting iteration 20

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 201.62
I0828 10:39:13.378176 140659155802112 replay_runner.py:36] Average training steps per second: 201.62
I0828 10:39:13.759819 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 21
I0828 10:39:13.994382 140659155802112 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 195.79
I0828 10:39:19.102417 140659155802112 replay_runner.py:36] Average training steps per second: 195.79
I0828 10:39:19.506201 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 22

Steps executed: 251 Episode length: 84 Return: -83.0.0
INFO:tensorflow:Average training steps per second: 201.02
I0828 10:39:24.719823 140659155802112 replay_runner.py:36] Average training steps per second: 201.02
I0828 10:39:24.922753 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.67
INFO:tensorflow:Starting iteration 23

Steps executed: 279 Episode length: 100 Return: -99.00
INFO:tensorflow:Average training steps per second: 203.05
I0828 10:39:30.085424 140659155802112 replay_runner.py:36] Average training steps per second: 203.05
I0828 10:39:30.305159 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.50
INFO:tensorflow:Starting iteration 24

Steps executed: 267 Episode length: 89 Return: -88.000
INFO:tensorflow:Average training steps per second: 206.19
I0828 10:39:35.392933 140659155802112 replay_runner.py:36] Average training steps per second: 206.19
I0828 10:39:35.604018 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.00
INFO:tensorflow:Starting iteration 25

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 199.48
I0828 10:39:40.858323 140659155802112 replay_runner.py:36] Average training steps per second: 199.48
I0828 10:39:41.251375 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 26

Steps executed: 204 Episode length: 70 Return: -69.0.0
INFO:tensorflow:Average training steps per second: 198.33
I0828 10:39:46.519344 140659155802112 replay_runner.py:36] Average training steps per second: 198.33
I0828 10:39:46.689406 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -67.00
INFO:tensorflow:Starting iteration 27

Steps executed: 250 Episode length: 93 Return: -92.0.0
INFO:tensorflow:Average training steps per second: 199.74
I0828 10:39:51.911143 140659155802112 replay_runner.py:36] Average training steps per second: 199.74
I0828 10:39:52.112715 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.33
INFO:tensorflow:Starting iteration 28

Steps executed: 228 Episode length: 97 Return: -96.0.0
INFO:tensorflow:Average training steps per second: 195.40
I0828 10:39:57.469631 140659155802112 replay_runner.py:36] Average training steps per second: 195.40
I0828 10:39:57.650774 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.00
INFO:tensorflow:Starting iteration 29
I0828 10:39:57.882935 140659155802112 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 201.71

Done fixed training!Episode length: 63 Return: -62.0.0
I0828 10:40:03.022883 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.00