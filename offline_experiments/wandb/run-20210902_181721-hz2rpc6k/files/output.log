I0902 18:17:27.991987 140110082734080 run_experiment.py:549] Creating TrainRunner ...
I0902 18:17:28.000285 140110082734080 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:17:28.000517 140110082734080 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:17:28.000647 140110082734080 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:17:28.000724 140110082734080 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:17:28.000793 140110082734080 dqn_agent.py:275] 	 update_period: 4
I0902 18:17:28.000858 140110082734080 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:17:28.000941 140110082734080 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:17:28.001047 140110082734080 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:17:28.001121 140110082734080 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:17:28.001199 140110082734080 dqn_agent.py:280] 	 optimizer: adam
I0902 18:17:28.001273 140110082734080 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:17:28.001346 140110082734080 dqn_agent.py:283] 	 seed: 1630606648000235
I0902 18:17:28.003081 140110082734080 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:17:28.003200 140110082734080 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:17:28.003277 140110082734080 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:17:28.003342 140110082734080 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:17:28.003400 140110082734080 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:17:28.003454 140110082734080 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:17:28.003579 140110082734080 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:17:28.003812 140110082734080 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:17:28.003949 140110082734080 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:17:28.030710 140110082734080 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 18:17:28.283107 140110082734080 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 18:17:28.292929 140110082734080 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:17:28.299969 140110082734080 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:17:28.300109 140110082734080 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:17:28.300182 140110082734080 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:17:28.300245 140110082734080 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:17:28.300341 140110082734080 dqn_agent.py:275] 	 update_period: 4
I0902 18:17:28.300438 140110082734080 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:17:28.300510 140110082734080 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:17:28.300575 140110082734080 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:17:28.300634 140110082734080 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:17:28.300702 140110082734080 dqn_agent.py:280] 	 optimizer: adam
I0902 18:17:28.300771 140110082734080 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:17:28.300839 140110082734080 dqn_agent.py:283] 	 seed: 1630606648299937
I0902 18:17:28.302305 140110082734080 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:17:28.302414 140110082734080 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:17:28.302483 140110082734080 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:17:28.302552 140110082734080 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:17:28.302609 140110082734080 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:17:28.302706 140110082734080 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:17:28.302943 140110082734080 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:17:28.303155 140110082734080 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:17:28.303242 140110082734080 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:17:28.323873 140110082734080 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 18:17:28.340384 140110082734080 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:17:28.340577 140110082734080 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
Steps executed: 223 Episode length: 93 Return: -552.90030873078511
INFO:tensorflow:Average training steps per second: 262.71
I0902 18:17:32.147283 140110082734080 replay_runner.py:36] Average training steps per second: 262.71
I0902 18:17:32.956219 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -599.95
INFO:tensorflow:Starting iteration 1

Steps executed: 257 Episode length: 105 Return: -388.96017222138784
INFO:tensorflow:Average training steps per second: 353.85
I0902 18:17:39.253714 140110082734080 replay_runner.py:36] Average training steps per second: 353.85
I0902 18:17:39.395881 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -396.70
INFO:tensorflow:Starting iteration 2

Steps executed: 247 Episode length: 111 Return: -308.67664836276374
INFO:tensorflow:Average training steps per second: 368.44
I0902 18:17:45.319095 140110082734080 replay_runner.py:36] Average training steps per second: 368.44
I0902 18:17:45.446037 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.17
INFO:tensorflow:Starting iteration 3
I0902 18:17:48.804060 140110082734080 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 362.55

Steps executed: 219 Episode length: 219 Return: -85.159190997322654
I0902 18:17:51.696273 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.16
INFO:tensorflow:Starting iteration 4
I0902 18:17:54.800113 140110082734080 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 344.62

Steps executed: 1000 Episode length: 1000 Return: -77.43513912608137
I0902 18:17:59.322578 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.44
INFO:tensorflow:Starting iteration 5

Steps executed: 1000 Episode length: 1000 Return: -112.91503806503255
INFO:tensorflow:Average training steps per second: 314.79
I0902 18:18:05.757357 140110082734080 replay_runner.py:36] Average training steps per second: 314.79
I0902 18:18:07.395044 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.92
INFO:tensorflow:Starting iteration 6

Steps executed: 700 Episode length: 700 Return: -280.0186938184054255
INFO:tensorflow:Average training steps per second: 308.55
I0902 18:18:13.899504 140110082734080 replay_runner.py:36] Average training steps per second: 308.55
I0902 18:18:14.634520 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.02
INFO:tensorflow:Starting iteration 7
I0902 18:18:17.857818 140110082734080 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 313.45

Steps executed: 1000 Episode length: 1000 Return: -331.37405484439284
I0902 18:18:22.919164 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.37
INFO:tensorflow:Starting iteration 8

Steps executed: 326 Episode length: 326 Return: -214.1160523634994284
INFO:tensorflow:Average training steps per second: 315.59
I0902 18:18:29.284933 140110082734080 replay_runner.py:36] Average training steps per second: 315.59
I0902 18:18:29.618939 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -214.12
INFO:tensorflow:Starting iteration 9
I0902 18:18:32.773236 140110082734080 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 331.91

Steps executed: 787 Episode length: 787 Return: -333.0823084027360384
I0902 18:18:37.108207 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.08
INFO:tensorflow:Starting iteration 10
I0902 18:18:40.303502 140110082734080 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 332.14

Steps executed: 800 Episode length: 800 Return: -344.9877071446841384
I0902 18:18:44.560108 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.99
INFO:tensorflow:Starting iteration 11
I0902 18:18:47.798763 140110082734080 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 321.06

Steps executed: 1000 Episode length: 1000 Return: -223.22855850860944
I0902 18:18:52.889732 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.23
INFO:tensorflow:Starting iteration 12

Steps executed: 359 Episode length: 359 Return: -384.1978447827202944
INFO:tensorflow:Average training steps per second: 313.16
I0902 18:18:59.279851 140110082734080 replay_runner.py:36] Average training steps per second: 313.16
I0902 18:18:59.596629 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -384.20
INFO:tensorflow:Starting iteration 13
I0902 18:19:02.855596 140110082734080 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 340.19

Steps executed: 1000 Episode length: 1000 Return: -164.98758602922683
I0902 18:19:07.640577 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.99
INFO:tensorflow:Starting iteration 14
I0902 18:19:11.050145 140110082734080 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 339.07

Steps executed: 1000 Episode length: 1000 Return: -148.18520860707625
I0902 18:19:16.091917 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.19
INFO:tensorflow:Starting iteration 15
I0902 18:19:19.530756 140110082734080 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 348.80

Steps executed: 1000 Episode length: 1000 Return: -100.48638773186629
I0902 18:19:24.857997 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.49
INFO:tensorflow:Starting iteration 16
I0902 18:19:28.206602 140110082734080 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 349.97

Steps executed: 915 Episode length: 915 Return: -463.9699394169599629
I0902 18:19:32.594978 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -463.97
INFO:tensorflow:Starting iteration 17
I0902 18:19:35.965160 140110082734080 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 339.71

Steps executed: 1000 Episode length: 1000 Return: -145.68489370718257
I0902 18:19:41.610888 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.68
INFO:tensorflow:Starting iteration 18
I0902 18:19:44.868460 140110082734080 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 321.24
I0902 18:19:47.981722 140110082734080 replay_runner.py:36] Average training steps per second: 321.24

Steps executed: 366 Episode length: 366 Return: -344.5972807440636257
INFO:tensorflow:Starting iteration 19

Steps executed: 311 Episode length: 311 Return: -434.7754162628094257
INFO:tensorflow:Average training steps per second: 324.87
I0902 18:19:54.634475 140110082734080 replay_runner.py:36] Average training steps per second: 324.87
I0902 18:19:54.940839 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -434.78
INFO:tensorflow:Starting iteration 20

Steps executed: 273 Episode length: 273 Return: -65.54772931041063257
INFO:tensorflow:Average training steps per second: 330.88
I0902 18:20:01.307424 140110082734080 replay_runner.py:36] Average training steps per second: 330.88
I0902 18:20:01.554781 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.55
INFO:tensorflow:Starting iteration 21

Steps executed: 140 Episode length: 50 Return: -133.04669234262243257
INFO:tensorflow:Average training steps per second: 338.10
I0902 18:20:07.863949 140110082734080 replay_runner.py:36] Average training steps per second: 338.10

Steps executed: 231 Episode length: 91 Return: -225.62688137242418257
INFO:tensorflow:Starting iteration 22

Steps executed: 206 Episode length: 100 Return: -201.1317553485575357
INFO:tensorflow:Average training steps per second: 362.51
I0902 18:20:14.127226 140110082734080 replay_runner.py:36] Average training steps per second: 362.51
I0902 18:20:14.259730 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.02
INFO:tensorflow:Starting iteration 23

Steps executed: 437 Episode length: 311 Return: -48.16890442003804657
INFO:tensorflow:Average training steps per second: 356.69
I0902 18:20:20.539361 140110082734080 replay_runner.py:36] Average training steps per second: 356.69
I0902 18:20:20.961419 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.78
INFO:tensorflow:Starting iteration 24

Steps executed: 228 Episode length: 65 Return: -598.35690645743286657
INFO:tensorflow:Average training steps per second: 356.59
I0902 18:20:27.251337 140110082734080 replay_runner.py:36] Average training steps per second: 356.59
I0902 18:20:27.385115 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -533.21
INFO:tensorflow:Starting iteration 25

Steps executed: 362 Episode length: 210 Return: -30.37234166744524657
INFO:tensorflow:Average training steps per second: 359.45
I0902 18:20:33.655074 140110082734080 replay_runner.py:36] Average training steps per second: 359.45
I0902 18:20:33.879344 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -219.03
INFO:tensorflow:Starting iteration 26
I0902 18:20:37.370125 140110082734080 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 360.56

Steps executed: 285 Episode length: 87 Return: -156.02047514363053657
I0902 18:20:40.296257 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.66
INFO:tensorflow:Starting iteration 27

Steps executed: 297 Episode length: 185 Return: -553.4940538101262657
INFO:tensorflow:Average training steps per second: 342.22
I0902 18:20:46.643513 140110082734080 replay_runner.py:36] Average training steps per second: 342.22
I0902 18:20:46.824744 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -382.90
INFO:tensorflow:Starting iteration 28

Steps executed: 208 Episode length: 141 Return: -166.0593373625843657
INFO:tensorflow:Average training steps per second: 340.10
I0902 18:20:53.166801 140110082734080 replay_runner.py:36] Average training steps per second: 340.10
I0902 18:20:53.298882 140110082734080 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.39
INFO:tensorflow:Starting iteration 29

Steps executed: 231 Episode length: 113 Return: -659.8016628760848657
INFO:tensorflow:Average training steps per second: 342.47
I0902 18:20:59.619787 140110082734080 replay_runner.py:36] Average training steps per second: 342.47

Done fixed training!Episode length: 113 Return: -659.8016628760848657