I0828 10:34:07.541733 140160266885120 run_experiment.py:549] Creating TrainRunner ...
I0828 10:34:07.550039 140160266885120 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:34:07.550351 140160266885120 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:34:07.550610 140160266885120 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:34:07.550739 140160266885120 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:34:07.550895 140160266885120 dqn_agent.py:275] 	 update_period: 4
I0828 10:34:07.551167 140160266885120 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:34:07.551277 140160266885120 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:34:07.551364 140160266885120 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:34:07.551461 140160266885120 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:34:07.551549 140160266885120 dqn_agent.py:280] 	 optimizer: adam
I0828 10:34:07.551657 140160266885120 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:34:07.551758 140160266885120 dqn_agent.py:283] 	 seed: 1630146847549983
I0828 10:34:07.554607 140160266885120 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:34:07.554815 140160266885120 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:34:07.554958 140160266885120 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:34:07.555047 140160266885120 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:34:07.555126 140160266885120 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:34:07.555198 140160266885120 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:34:07.555309 140160266885120 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:34:07.555439 140160266885120 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:34:07.555569 140160266885120 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:34:07.587934 140160266885120 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:34:07.984797 140160266885120 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:34:07.996598 140160266885120 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:34:08.004598 140160266885120 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:34:08.004781 140160266885120 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:34:08.004866 140160266885120 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:34:08.004934 140160266885120 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:34:08.004997 140160266885120 dqn_agent.py:275] 	 update_period: 4
I0828 10:34:08.005096 140160266885120 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:34:08.005176 140160266885120 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:34:08.005276 140160266885120 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:34:08.005355 140160266885120 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:34:08.005432 140160266885120 dqn_agent.py:280] 	 optimizer: adam
I0828 10:34:08.005492 140160266885120 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:34:08.005549 140160266885120 dqn_agent.py:283] 	 seed: 1630146848004553
I0828 10:34:08.007515 140160266885120 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:34:08.007733 140160266885120 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:34:08.007838 140160266885120 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:34:08.007923 140160266885120 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:34:08.008070 140160266885120 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:34:08.008178 140160266885120 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:34:08.008317 140160266885120 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:34:08.008424 140160266885120 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:34:08.008564 140160266885120 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:34:08.073889 140160266885120 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:34:08.093405 140160266885120 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:34:08.093679 140160266885120 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in acrobot
Training fixed agent 4, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 147.01
I0828 10:34:14.896327 140160266885120 replay_runner.py:36] Average training steps per second: 147.01
Steps executed: 500 Episode length: 500 Return: -500.0
I0828 10:34:16.326893 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1
I0828 10:34:16.550425 140160266885120 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 204.60
I0828 10:34:21.438300 140160266885120 replay_runner.py:36] Average training steps per second: 204.60
I0828 10:34:21.852037 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 2

Steps executed: 99 Episode length: 99 Return: -98.00.0
INFO:tensorflow:Average training steps per second: 199.23

Steps executed: 237 Episode length: 138 Return: -137.0
I0828 10:34:27.302938 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.50
INFO:tensorflow:Starting iteration 3

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 191.03
I0828 10:34:32.764769 140160266885120 replay_runner.py:36] Average training steps per second: 191.03
I0828 10:34:33.198601 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 4
I0828 10:34:33.454084 140160266885120 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 204.23
I0828 10:34:38.350983 140160266885120 replay_runner.py:36] Average training steps per second: 204.23
I0828 10:34:38.795267 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 5
I0828 10:34:39.045594 140160266885120 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 193.36
I0828 10:34:44.217706 140160266885120 replay_runner.py:36] Average training steps per second: 193.36
I0828 10:34:44.621419 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6

Steps executed: 220 Episode length: 220 Return: -219.0
INFO:tensorflow:Average training steps per second: 197.42
I0828 10:34:49.928073 140160266885120 replay_runner.py:36] Average training steps per second: 197.42
I0828 10:34:50.128585 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -219.00
INFO:tensorflow:Starting iteration 7
I0828 10:34:50.370000 140160266885120 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 198.12

Steps executed: 281 Episode length: 92 Return: -91.0.0
I0828 10:34:55.645442 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.67
INFO:tensorflow:Starting iteration 8
I0828 10:34:55.884081 140160266885120 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 191.38

Steps executed: 500 Episode length: 500 Return: -500.0
I0828 10:35:01.539206 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 9

Steps executed: 234 Episode length: 79 Return: -78.0.0
INFO:tensorflow:Average training steps per second: 202.69
I0828 10:35:06.723740 140160266885120 replay_runner.py:36] Average training steps per second: 202.69
I0828 10:35:06.944137 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.00
INFO:tensorflow:Starting iteration 10

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 193.41
I0828 10:35:12.370273 140160266885120 replay_runner.py:36] Average training steps per second: 193.41
I0828 10:35:12.779152 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 11
I0828 10:35:13.017946 140160266885120 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 193.56
I0828 10:35:18.184522 140160266885120 replay_runner.py:36] Average training steps per second: 193.56
I0828 10:35:18.616545 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 12
I0828 10:35:18.867435 140160266885120 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 202.47
I0828 10:35:23.806782 140160266885120 replay_runner.py:36] Average training steps per second: 202.47
I0828 10:35:24.233345 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 13

Steps executed: 123 Episode length: 123 Return: -122.0
INFO:tensorflow:Average training steps per second: 193.13

Steps executed: 293 Episode length: 170 Return: -169.0
I0828 10:35:29.881417 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.50
INFO:tensorflow:Starting iteration 14

Steps executed: 122 Episode length: 122 Return: -121.0
INFO:tensorflow:Average training steps per second: 198.64
I0828 10:35:35.160522 140160266885120 replay_runner.py:36] Average training steps per second: 198.64
I0828 10:35:35.383443 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.50
INFO:tensorflow:Starting iteration 15


Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 192.68
I0828 10:35:40.826549 140160266885120 replay_runner.py:36] Average training steps per second: 192.68
I0828 10:35:41.243164 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 16

Steps executed: 212 Episode length: 106 Return: -105.0
INFO:tensorflow:Average training steps per second: 191.94
I0828 10:35:46.691273 140160266885120 replay_runner.py:36] Average training steps per second: 191.94
I0828 10:35:46.858775 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.00
INFO:tensorflow:Starting iteration 17

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 199.09
I0828 10:35:52.114289 140160266885120 replay_runner.py:36] Average training steps per second: 199.09
I0828 10:35:52.559942 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 18
I0828 10:35:52.803825 140160266885120 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 195.48
I0828 10:35:57.920372 140160266885120 replay_runner.py:36] Average training steps per second: 195.48
I0828 10:35:58.298027 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 19

Steps executed: 210 Episode length: 100 Return: -99.00
INFO:tensorflow:Average training steps per second: 195.09
I0828 10:36:03.654085 140160266885120 replay_runner.py:36] Average training steps per second: 195.09
I0828 10:36:03.829236 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.00
INFO:tensorflow:Starting iteration 20

Steps executed: 203 Episode length: 101 Return: -100.0
INFO:tensorflow:Average training steps per second: 205.36
I0828 10:36:08.943548 140160266885120 replay_runner.py:36] Average training steps per second: 205.36
I0828 10:36:09.112498 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.50
INFO:tensorflow:Starting iteration 21

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 195.91
I0828 10:36:14.455353 140160266885120 replay_runner.py:36] Average training steps per second: 195.91
I0828 10:36:14.840502 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 22

Steps executed: 284 Episode length: 101 Return: -100.0
INFO:tensorflow:Average training steps per second: 203.30
I0828 10:36:19.996972 140160266885120 replay_runner.py:36] Average training steps per second: 203.30
I0828 10:36:20.233062 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.67
INFO:tensorflow:Starting iteration 23

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 205.82
I0828 10:36:25.341673 140160266885120 replay_runner.py:36] Average training steps per second: 205.82
I0828 10:36:25.737767 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 24

Steps executed: 238 Episode length: 71 Return: -70.0.0
INFO:tensorflow:Average training steps per second: 204.61
I0828 10:36:30.858305 140160266885120 replay_runner.py:36] Average training steps per second: 204.61
I0828 10:36:31.044903 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.33
INFO:tensorflow:Starting iteration 25

Steps executed: 242 Episode length: 80 Return: -79.0.0
INFO:tensorflow:Average training steps per second: 203.74
I0828 10:36:36.189073 140160266885120 replay_runner.py:36] Average training steps per second: 203.74
I0828 10:36:36.401155 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.67
INFO:tensorflow:Starting iteration 26

Steps executed: 164 Episode length: 87 Return: -86.0.0
INFO:tensorflow:Average training steps per second: 195.88

Steps executed: 263 Episode length: 99 Return: -98.0.0
I0828 10:36:41.961471 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.67
INFO:tensorflow:Starting iteration 27

Steps executed: 216 Episode length: 116 Return: -115.0
INFO:tensorflow:Average training steps per second: 199.71
I0828 10:36:47.190341 140160266885120 replay_runner.py:36] Average training steps per second: 199.71
I0828 10:36:47.376856 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.00
INFO:tensorflow:Starting iteration 28

Steps executed: 265 Episode length: 120 Return: -119.0
INFO:tensorflow:Average training steps per second: 200.28
I0828 10:36:52.618888 140160266885120 replay_runner.py:36] Average training steps per second: 200.28
I0828 10:36:52.863321 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.33
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 193.71
I0828 10:36:58.322360 140160266885120 replay_runner.py:36] Average training steps per second: 193.71
I0828 10:36:58.734740 140160266885120 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00