Loaded trained dqn in acrobot
Training fixed agent 1, please be patient, may be a while...
I0901 23:53:55.034454 140268994136064 run_experiment.py:549] Creating TrainRunner ...
I0901 23:53:55.043866 140268994136064 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:53:55.044199 140268994136064 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:53:55.044384 140268994136064 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:53:55.044543 140268994136064 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:53:55.044676 140268994136064 dqn_agent.py:275] 	 update_period: 4
I0901 23:53:55.044775 140268994136064 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:53:55.044899 140268994136064 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:53:55.045019 140268994136064 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:53:55.045133 140268994136064 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:53:55.045251 140268994136064 dqn_agent.py:280] 	 optimizer: adam
I0901 23:53:55.045365 140268994136064 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:53:55.045476 140268994136064 dqn_agent.py:283] 	 seed: 1630540435043799
I0901 23:53:55.048824 140268994136064 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:53:55.049054 140268994136064 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 23:53:55.049206 140268994136064 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:53:55.049354 140268994136064 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:53:55.049483 140268994136064 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:53:55.049616 140268994136064 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:53:55.049716 140268994136064 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:53:55.049791 140268994136064 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:53:55.049856 140268994136064 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:53:55.090309 140268994136064 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:53:55.516277 140268994136064 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:53:55.548373 140268994136064 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:53:55.557422 140268994136064 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:53:55.557666 140268994136064 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:53:55.557791 140268994136064 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:53:55.557886 140268994136064 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:53:55.558017 140268994136064 dqn_agent.py:275] 	 update_period: 4
I0901 23:53:55.558209 140268994136064 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:53:55.558316 140268994136064 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:53:55.558417 140268994136064 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:53:55.558508 140268994136064 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:53:55.558662 140268994136064 dqn_agent.py:280] 	 optimizer: adam
I0901 23:53:55.558763 140268994136064 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:53:55.558900 140268994136064 dqn_agent.py:283] 	 seed: 1630540435557349
I0901 23:53:55.562017 140268994136064 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:53:55.562263 140268994136064 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 23:53:55.562453 140268994136064 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:53:55.562702 140268994136064 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:53:55.562826 140268994136064 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:53:55.563010 140268994136064 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:53:55.563163 140268994136064 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:53:55.563283 140268994136064 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:53:55.563391 140268994136064 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:53:55.601022 140268994136064 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:53:55.624445 140268994136064 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:53:55.624664 140268994136064 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 147.53
I0901 23:54:02.403216 140268994136064 replay_runner.py:36] Average training steps per second: 147.53
Steps executed: 500 Episode length: 500 Return: -500.0
I0901 23:54:03.919177 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1

Steps executed: 229 Episode length: 136 Return: -135.0
INFO:tensorflow:Average training steps per second: 195.93
I0901 23:54:09.272564 140268994136064 replay_runner.py:36] Average training steps per second: 195.93
I0901 23:54:09.482763 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.50
INFO:tensorflow:Starting iteration 2
I0901 23:54:09.728595 140268994136064 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 200.95

Steps executed: 500 Episode length: 500 Return: -500.0
I0901 23:54:15.124891 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 3

Steps executed: 319 Episode length: 120 Return: -119.0
INFO:tensorflow:Average training steps per second: 204.59
I0901 23:54:20.253668 140268994136064 replay_runner.py:36] Average training steps per second: 204.59
I0901 23:54:20.526595 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.33
INFO:tensorflow:Starting iteration 4

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 193.17
I0901 23:54:25.947870 140268994136064 replay_runner.py:36] Average training steps per second: 193.17
I0901 23:54:26.413864 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 5
I0901 23:54:26.641220 140268994136064 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 202.82
I0901 23:54:31.572006 140268994136064 replay_runner.py:36] Average training steps per second: 202.82
I0901 23:54:32.023888 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6
I0901 23:54:32.278813 140268994136064 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 199.66
I0901 23:54:37.287669 140268994136064 replay_runner.py:36] Average training steps per second: 199.66
I0901 23:54:37.706714 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7
I0901 23:54:37.974088 140268994136064 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 196.52
I0901 23:54:43.063092 140268994136064 replay_runner.py:36] Average training steps per second: 196.52
I0901 23:54:43.506803 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 8

Steps executed: 116 Episode length: 116 Return: -115.0
INFO:tensorflow:Average training steps per second: 203.97

Steps executed: 608 Episode length: 492 Return: -491.0
I0901 23:54:49.149625 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -303.00
INFO:tensorflow:Starting iteration 9

Steps executed: 233 Episode length: 80 Return: -79.0.0
INFO:tensorflow:Average training steps per second: 198.32
I0901 23:54:54.420845 140268994136064 replay_runner.py:36] Average training steps per second: 198.32
I0901 23:54:54.641327 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.67
INFO:tensorflow:Starting iteration 10

Steps executed: 253 Episode length: 133 Return: -132.0
INFO:tensorflow:Average training steps per second: 200.47
I0901 23:54:59.870937 140268994136064 replay_runner.py:36] Average training steps per second: 200.47
I0901 23:55:00.075217 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.50
INFO:tensorflow:Starting iteration 11

Steps executed: 269 Episode length: 76 Return: -75.0.0
INFO:tensorflow:Average training steps per second: 195.90
I0901 23:55:05.416060 140268994136064 replay_runner.py:36] Average training steps per second: 195.90
I0901 23:55:05.641596 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.67
INFO:tensorflow:Starting iteration 12

Steps executed: 165 Episode length: 86 Return: -85.0.0
INFO:tensorflow:Average training steps per second: 200.44
I0901 23:55:10.917087 140268994136064 replay_runner.py:36] Average training steps per second: 200.44

Steps executed: 318 Episode length: 153 Return: -152.0
INFO:tensorflow:Starting iteration 13

Steps executed: 222 Episode length: 111 Return: -110.0
INFO:tensorflow:Average training steps per second: 190.95
I0901 23:55:16.656482 140268994136064 replay_runner.py:36] Average training steps per second: 190.95
I0901 23:55:16.843838 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.00
INFO:tensorflow:Starting iteration 14

Steps executed: 258 Episode length: 112 Return: -111.0
INFO:tensorflow:Average training steps per second: 199.30
I0901 23:55:22.103229 140268994136064 replay_runner.py:36] Average training steps per second: 199.30
I0901 23:55:22.325618 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.00
INFO:tensorflow:Starting iteration 15

Steps executed: 243 Episode length: 98 Return: -97.0.0
INFO:tensorflow:Average training steps per second: 193.88
I0901 23:55:27.730068 140268994136064 replay_runner.py:36] Average training steps per second: 193.88
I0901 23:55:27.927452 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.00
INFO:tensorflow:Starting iteration 16

Steps executed: 101 Episode length: 101 Return: -100.0
INFO:tensorflow:Average training steps per second: 196.95

Steps executed: 259 Episode length: 72 Return: -71.0.0
I0901 23:55:33.472645 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.33
INFO:tensorflow:Starting iteration 17
I0901 23:55:33.729009 140268994136064 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 189.48
I0901 23:55:39.006968 140268994136064 replay_runner.py:36] Average training steps per second: 189.48
I0901 23:55:39.206265 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.00
INFO:tensorflow:Starting iteration 18


Steps executed: 391 Episode length: 205 Return: -204.0
INFO:tensorflow:Average training steps per second: 198.05
I0901 23:55:44.497487 140268994136064 replay_runner.py:36] Average training steps per second: 198.05
I0901 23:55:44.838586 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.33
INFO:tensorflow:Starting iteration 19

Steps executed: 299 Episode length: 119 Return: -118.0
INFO:tensorflow:Average training steps per second: 203.84
I0901 23:55:49.996701 140268994136064 replay_runner.py:36] Average training steps per second: 203.84
I0901 23:55:50.231553 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.67
INFO:tensorflow:Starting iteration 20
I0901 23:55:50.457752 140268994136064 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 202.34
I0901 23:55:55.400319 140268994136064 replay_runner.py:36] Average training steps per second: 202.34

Steps executed: 221 Episode length: 119 Return: -118.0
INFO:tensorflow:Starting iteration 21

Steps executed: 208 Episode length: 113 Return: -112.0
INFO:tensorflow:Average training steps per second: 200.86
I0901 23:56:00.821791 140268994136064 replay_runner.py:36] Average training steps per second: 200.86
I0901 23:56:00.992943 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.00
INFO:tensorflow:Starting iteration 22

Steps executed: 254 Episode length: 86 Return: -85.0.0
INFO:tensorflow:Average training steps per second: 201.80
I0901 23:56:06.195208 140268994136064 replay_runner.py:36] Average training steps per second: 201.80
I0901 23:56:06.421634 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.67
INFO:tensorflow:Starting iteration 23

Steps executed: 249 Episode length: 63 Return: -62.0.0
INFO:tensorflow:Average training steps per second: 199.21
I0901 23:56:11.681984 140268994136064 replay_runner.py:36] Average training steps per second: 199.21
I0901 23:56:11.911574 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.00
INFO:tensorflow:Starting iteration 24

Steps executed: 277 Episode length: 92 Return: -91.0.0
INFO:tensorflow:Average training steps per second: 204.48
I0901 23:56:17.032812 140268994136064 replay_runner.py:36] Average training steps per second: 204.48
I0901 23:56:17.280231 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.33
INFO:tensorflow:Starting iteration 25

Steps executed: 259 Episode length: 108 Return: -107.0
INFO:tensorflow:Average training steps per second: 198.15
I0901 23:56:22.571951 140268994136064 replay_runner.py:36] Average training steps per second: 198.15
I0901 23:56:22.779972 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.33
INFO:tensorflow:Starting iteration 26

Steps executed: 271 Episode length: 112 Return: -111.0
INFO:tensorflow:Average training steps per second: 198.72
I0901 23:56:28.049854 140268994136064 replay_runner.py:36] Average training steps per second: 198.72
I0901 23:56:28.286623 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.33
INFO:tensorflow:Starting iteration 27
I0901 23:56:28.531531 140268994136064 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 204.20

Steps executed: 251 Episode length: 99 Return: -98.0.0
I0901 23:56:33.634046 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.67
INFO:tensorflow:Starting iteration 28

Steps executed: 333 Episode length: 199 Return: -198.0
INFO:tensorflow:Average training steps per second: 201.18
I0901 23:56:38.827635 140268994136064 replay_runner.py:36] Average training steps per second: 201.18
I0901 23:56:39.102368 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.00
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 107 Return: -106.0
INFO:tensorflow:Average training steps per second: 207.50
I0901 23:56:44.159620 140268994136064 replay_runner.py:36] Average training steps per second: 207.50
I0901 23:56:44.323009 140268994136064 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.50