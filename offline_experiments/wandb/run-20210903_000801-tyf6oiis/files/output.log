I0903 00:08:07.319418 139735608805376 run_experiment.py:549] Creating TrainRunner ...
I0903 00:08:07.326522 139735608805376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:08:07.326641 139735608805376 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:08:07.326714 139735608805376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:08:07.326780 139735608805376 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:08:07.326869 139735608805376 dqn_agent.py:275] 	 update_period: 4
I0903 00:08:07.326940 139735608805376 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:08:07.327010 139735608805376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:08:07.327098 139735608805376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:08:07.327192 139735608805376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:08:07.327356 139735608805376 dqn_agent.py:280] 	 optimizer: adam
I0903 00:08:07.327516 139735608805376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:08:07.327607 139735608805376 dqn_agent.py:283] 	 seed: 1630627687326492
I0903 00:08:07.329597 139735608805376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:08:07.329839 139735608805376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:08:07.329966 139735608805376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:08:07.330051 139735608805376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:08:07.330127 139735608805376 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:08:07.330200 139735608805376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:08:07.330318 139735608805376 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:08:07.330419 139735608805376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:08:07.330536 139735608805376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:08:07.355755 139735608805376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:07.893438 139735608805376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:07.903010 139735608805376 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:08:07.908752 139735608805376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:08:07.908886 139735608805376 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:08:07.908983 139735608805376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:08:07.909084 139735608805376 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:08:07.909156 139735608805376 dqn_agent.py:275] 	 update_period: 4
I0903 00:08:07.909219 139735608805376 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:08:07.909302 139735608805376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:08:07.909402 139735608805376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:08:07.909537 139735608805376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:08:07.909694 139735608805376 dqn_agent.py:280] 	 optimizer: adam
I0903 00:08:07.909851 139735608805376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:08:07.909986 139735608805376 dqn_agent.py:283] 	 seed: 1630627687908724
I0903 00:08:07.912509 139735608805376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:08:07.912647 139735608805376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:08:07.912739 139735608805376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:08:07.912826 139735608805376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:08:07.912894 139735608805376 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:08:07.912967 139735608805376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:08:07.913061 139735608805376 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:08:07.913125 139735608805376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:08:07.913199 139735608805376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:08:07.934066 139735608805376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:07.948147 139735608805376 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:08:07.948302 139735608805376 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 251.09
I0903 00:08:11.931237 139735608805376 replay_runner.py:36] Average training steps per second: 251.09
I0903 00:08:12.795570 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -20.35
Steps executed: 209 Episode length: 209 Return: -20.34562521841275
INFO:tensorflow:Starting iteration 1

Steps executed: 305 Episode length: 149 Return: -333.5953713004752
INFO:tensorflow:Average training steps per second: 332.31
I0903 00:08:19.097693 139735608805376 replay_runner.py:36] Average training steps per second: 332.31
I0903 00:08:19.317023 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -415.89
INFO:tensorflow:Starting iteration 2
I0903 00:08:22.575718 139735608805376 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 329.38
I0903 00:08:25.612202 139735608805376 replay_runner.py:36] Average training steps per second: 329.38

Steps executed: 340 Episode length: 188 Return: -331.17862758409165
INFO:tensorflow:Starting iteration 3

Steps executed: 309 Episode length: 141 Return: -120.84353034308225
INFO:tensorflow:Average training steps per second: 319.37
I0903 00:08:32.217379 139735608805376 replay_runner.py:36] Average training steps per second: 319.37
I0903 00:08:32.430105 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.12
INFO:tensorflow:Starting iteration 4
I0903 00:08:35.696560 139735608805376 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 341.15

Steps executed: 1000 Episode length: 1000 Return: 7.761324962222155
I0903 00:08:41.355367 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: 7.76
INFO:tensorflow:Starting iteration 5

Steps executed: 447 Episode length: 447 Return: -228.79228724881781
INFO:tensorflow:Average training steps per second: 312.47
I0903 00:08:47.841514 139735608805376 replay_runner.py:36] Average training steps per second: 312.47
I0903 00:08:48.264431 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.79
INFO:tensorflow:Starting iteration 6
I0903 00:08:51.579852 139735608805376 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 316.39

Steps executed: 1000 Episode length: 1000 Return: -36.58485572686849
I0903 00:08:56.288217 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -36.58
INFO:tensorflow:Starting iteration 7
I0903 00:08:59.448068 139735608805376 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 306.73

Steps executed: 733 Episode length: 733 Return: -328.211389156601449
I0903 00:09:03.497978 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.21
INFO:tensorflow:Starting iteration 8

Steps executed: 636 Episode length: 636 Return: -302.614353637532139
INFO:tensorflow:Average training steps per second: 321.00
I0903 00:09:09.836760 139735608805376 replay_runner.py:36] Average training steps per second: 321.00
I0903 00:09:10.803329 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -302.61
INFO:tensorflow:Starting iteration 9
I0903 00:09:14.136648 139735608805376 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 326.32

Steps executed: 285 Episode length: 285 Return: -180.513298414653269
I0903 00:09:17.450127 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.51
INFO:tensorflow:Starting iteration 10
I0903 00:09:20.792506 139735608805376 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 339.49

Steps executed: 1000 Episode length: 1000 Return: -111.90358456999728
I0903 00:09:26.006718 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.90
INFO:tensorflow:Starting iteration 11
I0903 00:09:29.309139 139735608805376 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 330.13

Steps executed: 1000 Episode length: 1000 Return: -108.43449334940723
I0903 00:09:34.274816 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.43
INFO:tensorflow:Starting iteration 12

Steps executed: 356 Episode length: 356 Return: -314.5834219164105423
INFO:tensorflow:Average training steps per second: 324.88
I0903 00:09:40.695907 139735608805376 replay_runner.py:36] Average training steps per second: 324.88
I0903 00:09:41.050717 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.58
INFO:tensorflow:Starting iteration 13
I0903 00:09:44.331176 139735608805376 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 317.93

Steps executed: 1000 Episode length: 1000 Return: -180.77100876593943
I0903 00:09:49.697911 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.77
INFO:tensorflow:Starting iteration 14

Steps executed: 477 Episode length: 477 Return: -1215.424119027676643
INFO:tensorflow:Average training steps per second: 316.16
I0903 00:09:56.149618 139735608805376 replay_runner.py:36] Average training steps per second: 316.16
I0903 00:09:56.636175 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -1215.42
INFO:tensorflow:Starting iteration 15

Steps executed: 317 Episode length: 317 Return: -324.8450442073919643
INFO:tensorflow:Average training steps per second: 317.26
I0903 00:10:03.137384 139735608805376 replay_runner.py:36] Average training steps per second: 317.26
I0903 00:10:03.437690 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -324.85
INFO:tensorflow:Starting iteration 16

Steps executed: 179 Episode length: 179 Return: -380.9545477155775643
INFO:tensorflow:Average training steps per second: 323.08

Steps executed: 1179 Episode length: 1000 Return: -133.47805679661877
I0903 00:10:12.519937 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.22
INFO:tensorflow:Starting iteration 17

Steps executed: 253 Episode length: 253 Return: -140.3178794408124277
INFO:tensorflow:Average training steps per second: 352.76
I0903 00:10:18.818583 139735608805376 replay_runner.py:36] Average training steps per second: 352.76
I0903 00:10:19.020883 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.32
INFO:tensorflow:Starting iteration 18
I0903 00:10:22.487897 139735608805376 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 337.71

Steps executed: 1000 Episode length: 1000 Return: -112.40483172526089
I0903 00:10:27.875589 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.40
INFO:tensorflow:Starting iteration 19

Steps executed: 351 Episode length: 157 Return: -136.9457448412614289
INFO:tensorflow:Average training steps per second: 351.36
I0903 00:10:34.136247 139735608805376 replay_runner.py:36] Average training steps per second: 351.36
I0903 00:10:34.348290 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.79
INFO:tensorflow:Starting iteration 20

Steps executed: 326 Episode length: 140 Return: -281.8843150989338589
INFO:tensorflow:Average training steps per second: 383.42
I0903 00:10:40.457160 139735608805376 replay_runner.py:36] Average training steps per second: 383.42
I0903 00:10:40.676077 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.33
INFO:tensorflow:Starting iteration 21

Steps executed: 211 Episode length: 211 Return: -26.71516641260660789
INFO:tensorflow:Average training steps per second: 386.08
I0903 00:10:46.878479 139735608805376 replay_runner.py:36] Average training steps per second: 386.08
I0903 00:10:47.012119 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -26.72
INFO:tensorflow:Starting iteration 22
I0903 00:10:50.648442 139735608805376 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 377.84
I0903 00:10:53.295350 139735608805376 replay_runner.py:36] Average training steps per second: 377.84

Steps executed: 253 Episode length: 125 Return: -284.5630463834885489
INFO:tensorflow:Starting iteration 23
I0903 00:10:57.006441 139735608805376 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 363.77

Steps executed: 208 Episode length: 76 Return: -456.92618603472635489
I0903 00:10:59.847383 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -402.36
INFO:tensorflow:Starting iteration 24

Steps executed: 320 Episode length: 137 Return: -295.6667711474861489
INFO:tensorflow:Average training steps per second: 350.94
I0903 00:11:06.236860 139735608805376 replay_runner.py:36] Average training steps per second: 350.94
I0903 00:11:06.400751 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.81
INFO:tensorflow:Starting iteration 25

Steps executed: 201 Episode length: 146 Return: -252.8490610323047289
INFO:tensorflow:Average training steps per second: 344.35
I0903 00:11:12.822424 139735608805376 replay_runner.py:36] Average training steps per second: 344.35
I0903 00:11:12.922947 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.04
INFO:tensorflow:Starting iteration 26

Steps executed: 190 Episode length: 62 Return: -364.32812921043213689
INFO:tensorflow:Average training steps per second: 345.18
I0903 00:11:19.320159 139735608805376 replay_runner.py:36] Average training steps per second: 345.18

Steps executed: 310 Episode length: 120 Return: -413.4218962301175689
INFO:tensorflow:Starting iteration 27
I0903 00:11:22.882250 139735608805376 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 335.78

Steps executed: 271 Episode length: 78 Return: -445.84039453327506689
I0903 00:11:25.996713 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -380.72
INFO:tensorflow:Starting iteration 28

Steps executed: 325 Episode length: 130 Return: -370.9405126362233389
INFO:tensorflow:Average training steps per second: 325.81
I0903 00:11:32.463320 139735608805376 replay_runner.py:36] Average training steps per second: 325.81
I0903 00:11:32.626738 139735608805376 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.90
INFO:tensorflow:Starting iteration 29

Steps executed: 221 Episode length: 54 Return: -380.82454447367473389
INFO:tensorflow:Average training steps per second: 343.40
I0903 00:11:38.947698 139735608805376 replay_runner.py:36] Average training steps per second: 343.40

Done fixed training!Episode length: 54 Return: -380.82454447367473389