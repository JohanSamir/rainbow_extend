WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0828 01:10:58.131365 139941007411200 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0828 01:10:58.701532 139941007411200 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 01:10:58.702483 139941007411200 dqn_agent.py:272] 	 gamma: 0.990000
I0828 01:10:58.702541 139941007411200 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 01:10:58.702585 139941007411200 dqn_agent.py:274] 	 min_replay_history: 500
I0828 01:10:58.702636 139941007411200 dqn_agent.py:275] 	 update_period: 4
I0828 01:10:58.702690 139941007411200 dqn_agent.py:276] 	 target_update_period: 100
I0828 01:10:58.702736 139941007411200 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 01:10:58.702778 139941007411200 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 01:10:58.702842 139941007411200 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 01:10:58.703008 139941007411200 dqn_agent.py:280] 	 optimizer: adam
I0828 01:10:58.703085 139941007411200 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 01:10:58.703161 139941007411200 dqn_agent.py:283] 	 seed: 1630113058701479
I0828 01:10:58.704527 139941007411200 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 01:10:58.704639 139941007411200 circular_replay_buffer.py:156] 	 observation_shape: (2, 1)
I0828 01:10:58.704704 139941007411200 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 01:10:58.704759 139941007411200 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 01:10:58.704809 139941007411200 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 01:10:58.704855 139941007411200 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 01:10:58.704935 139941007411200 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 01:10:58.705002 139941007411200 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 01:10:58.705048 139941007411200 circular_replay_buffer.py:163] 	 gamma: 0.990000
Training agent 2, please be patient, may be a while...
I0828 01:11:00.131335 139941007411200 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 01:11:00.607664 139941007411200 run_experiment.py:516] Beginning training...
I0828 01:11:00.607878 139941007411200 run_experiment.py:447] Starting iteration 0
Steps executed: 600 Episode length: 600 Return: -600.0

Steps executed: 1200 Episode length: 600 Return: -600.0
W0828 01:11:05.407771 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:11:05.408101 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 124800 Episode length: 600 Return: -600.0
I0828 01:11:37.867032 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:11:42.423676 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:11:42.424005 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 123600 Episode length: 600 Return: -600.0
I0828 01:12:14.217559 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:12:18.707548 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:12:18.707826 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 120000 Episode length: 600 Return: -600.0
I0828 01:12:49.321783 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:12:53.848854 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:12:53.849133 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 123600 Episode length: 600 Return: -600.0
I0828 01:13:24.404225 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:13:28.910635 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:13:28.911125 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 120000 Episode length: 600 Return: -600.0
I0828 01:13:59.414158 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:14:03.916876 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:14:03.917201 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 125400 Episode length: 600 Return: -600.0
I0828 01:14:36.183166 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00
I0828 01:14:36.227022 139941007411200 run_experiment.py:447] Starting iteration 6

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:14:40.897915 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:14:40.898359 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 125400 Episode length: 600 Return: -600.0
I0828 01:15:10.411812 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00
I0828 01:15:10.453658 139941007411200 run_experiment.py:447] Starting iteration 7

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:15:14.869382 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:15:14.869690 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 120000 Episode length: 600 Return: -600.0
I0828 01:15:45.340916 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:15:49.913789 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:15:49.914081 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 122400 Episode length: 600 Return: -600.0
I0828 01:16:20.902837 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:16:25.469395 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:16:25.469786 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 120600 Episode length: 600 Return: -600.0
I0828 01:16:55.469060 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:17:00.066639 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:17:00.067195 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 124800 Episode length: 600 Return: -600.0
I0828 01:17:30.612962 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:17:35.088298 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:17:35.088569 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 125400 Episode length: 600 Return: -600.0
I0828 01:18:06.636845 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00
I0828 01:18:06.691988 139941007411200 run_experiment.py:447] Starting iteration 12

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:18:11.407688 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:18:11.408004 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 121800 Episode length: 600 Return: -600.0
I0828 01:18:41.700083 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:18:46.360803 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:18:46.361148 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 118800 Episode length: 600 Return: -600.0
I0828 01:19:16.435410 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0


Steps executed: 1200 Episode length: 600 Return: -600.0.0
W0828 01:19:20.924469 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:19:20.924775 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 118200 Episode length: 600 Return: -600.0

Steps executed: 125400 Episode length: 600 Return: -600.0
I0828 01:19:54.859977 139941007411200 run_experiment.py:447] Starting iteration 15

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:19:59.308735 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:19:59.309017 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 119400 Episode length: 600 Return: -600.0
I0828 01:20:30.058384 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:20:34.581921 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:20:34.582217 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 117000 Episode length: 600 Return: -600.0
I0828 01:21:04.814356 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00


Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:21:09.330219 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:21:09.330589 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 122400 Episode length: 600 Return: -600.0
I0828 01:21:39.498605 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:21:43.970840 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:21:43.971157 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 121200 Episode length: 600 Return: -600.0
I0828 01:22:16.156883 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:22:20.857982 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:22:20.858276 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00














Steps executed: 120000 Episode length: 600 Return: -600.0
I0828 01:22:50.338460 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:22:54.878102 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:22:54.878429 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 125400 Episode length: 600 Return: -600.0
I0828 01:23:27.105987 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00
I0828 01:23:27.169994 139941007411200 run_experiment.py:447] Starting iteration 21

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:23:31.636496 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:23:31.636828 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 120600 Episode length: 600 Return: -600.0
I0828 01:24:02.665536 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00


Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:24:04.973732 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 01:24:07.304191 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:24:07.304515 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 121200 Episode length: 600 Return: -600.0
I0828 01:24:38.629666 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00


Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:24:41.008167 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 01:24:43.347935 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:24:43.348235 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 120600 Episode length: 600 Return: -600.0
I0828 01:25:14.236401 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:25:18.728918 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:25:18.729204 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 121800 Episode length: 600 Return: -600.0
I0828 01:25:50.171342 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:25:54.722727 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:25:54.723233 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 120600 Episode length: 600 Return: -600.0
I0828 01:26:26.738255 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:26:31.267766 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:26:31.268260 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 123600 Episode length: 600 Return: -600.0
I0828 01:27:02.000384 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:27:06.703025 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:27:06.703351 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 122400 Episode length: 600 Return: -600.0
I0828 01:27:38.397866 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 545 Episode length: 545 Return: -545.00.0
W0828 01:27:42.719194 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:27:42.719512 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -572.50
















Steps executed: 125400 Episode length: 600 Return: -600.0
I0828 01:28:13.650461 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00
I0828 01:28:13.720415 139941007411200 run_experiment.py:447] Starting iteration 29

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 01:28:18.183559 139941007411200 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 01:28:18.183876 139941007411200 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Done training!: 125400 Episode length: 600 Return: -600.0
I0828 01:28:48.304951 139941007411200 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00