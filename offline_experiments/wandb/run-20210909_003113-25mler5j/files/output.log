WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0909 00:31:18.024171 139945412024320 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0909 00:31:18.074173 139945412024320 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0909 00:31:18.074973 139945412024320 dqn_agent.py:272] 	 gamma: 0.990000
I0909 00:31:18.075031 139945412024320 dqn_agent.py:273] 	 update_horizon: 1.000000
I0909 00:31:18.075089 139945412024320 dqn_agent.py:274] 	 min_replay_history: 500
I0909 00:31:18.075138 139945412024320 dqn_agent.py:275] 	 update_period: 4
I0909 00:31:18.075186 139945412024320 dqn_agent.py:276] 	 target_update_period: 100
I0909 00:31:18.075237 139945412024320 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0909 00:31:18.075281 139945412024320 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0909 00:31:18.075406 139945412024320 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0909 00:31:18.075472 139945412024320 dqn_agent.py:280] 	 optimizer: adam
I0909 00:31:18.075526 139945412024320 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0909 00:31:18.075583 139945412024320 dqn_agent.py:283] 	 seed: 1631147478074112
I0909 00:31:18.076992 139945412024320 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0909 00:31:18.077130 139945412024320 circular_replay_buffer.py:156] 	 observation_shape: (2, 1)
I0909 00:31:18.077201 139945412024320 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0909 00:31:18.077261 139945412024320 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0909 00:31:18.077315 139945412024320 circular_replay_buffer.py:159] 	 stack_size: 1
I0909 00:31:18.077383 139945412024320 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0909 00:31:18.077482 139945412024320 circular_replay_buffer.py:161] 	 batch_size: 128
I0909 00:31:18.077552 139945412024320 circular_replay_buffer.py:162] 	 update_horizon: 1
I0909 00:31:18.077626 139945412024320 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0909 00:31:19.261940 139945412024320 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0909 00:31:19.326190 139945412024320 run_experiment.py:516] Beginning training...
I0909 00:31:19.326347 139945412024320 run_experiment.py:447] Starting iteration 0
Training agent 2, please be patient, may be a while...
W0909 00:31:21.254737 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
Steps executed: 600 Episode length: 600 Return: -600.0

Steps executed: 944 Episode length: 344 Return: -344.0
W0909 00:31:24.763873 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:31:24.764209 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -514.67















Steps executed: 119400 Episode length: 600 Return: -600.0
I0909 00:31:55.040809 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00


Steps executed: 600 Episode length: 600 Return: -600.00.0

Steps executed: 359 Episode length: 359 Return: -359.00.0
W0909 00:31:59.539983 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:31:59.540321 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -600.00














Steps executed: 120426 Episode length: 600 Return: -600.0
I0909 00:32:28.872198 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -559.04


Steps executed: 328 Episode length: 328 Return: -328.00.0

Steps executed: 928 Episode length: 600 Return: -600.00.0

Steps executed: 5211 Episode length: 166 Return: -166.0.0
W0909 00:32:34.577784 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:32:34.578154 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -509.33















Steps executed: 122562 Episode length: 166 Return: -166.0
I0909 00:33:06.646228 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.96

Steps executed: 125091 Episode length: 165 Return: -165.0

Steps executed: 600 Episode length: 600 Return: -600.05.0
W0909 00:33:11.153557 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:33:11.153885 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 123000 Episode length: 600 Return: -600.0
I0909 00:33:40.689925 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0909 00:33:45.189113 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:33:45.189485 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 124800 Episode length: 600 Return: -600.0
I0909 00:34:14.409541 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 532 Episode length: 532 Return: -532.00.0
W0909 00:34:18.543451 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:34:18.543784 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -549.50















Steps executed: 121084 Episode length: 600 Return: -600.0
I0909 00:34:48.872986 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -599.44

Steps executed: 125284 Episode length: 600 Return: -600.0

Steps executed: 591 Episode length: 591 Return: -591.00.0
W0909 00:34:52.673931 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:34:52.674282 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -504.50















Steps executed: 123000 Episode length: 600 Return: -600.0
I0909 00:35:22.506619 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00
I0909 00:35:22.549783 139945412024320 run_experiment.py:447] Starting iteration 7

Steps executed: 336 Episode length: 336 Return: -336.00.0
W0909 00:35:24.392557 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 794 Episode length: 303 Return: -303.00.0
W0909 00:35:26.510315 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:35:26.511492 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -264.50















Steps executed: 119400 Episode length: 600 Return: -600.0
I0909 00:35:57.547463 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0
W0909 00:35:58.263197 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:35:59.321666 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 575 Episode length: 111 Return: -111.00.0
W0909 00:36:00.789294 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:36:01.258784 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:36:01.898383 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:36:01.898760 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -191.17















Steps executed: 118200 Episode length: 600 Return: -600.0
I0909 00:36:32.062245 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0
W0909 00:36:32.668680 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:36:33.314733 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 499 Episode length: 168 Return: -168.00.0
W0909 00:36:34.825168 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:36:35.381096 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:36:35.935602 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:36:35.935940 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -172.50















Steps executed: 120000 Episode length: 600 Return: -600.0
I0909 00:37:05.703490 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0
W0909 00:37:06.687632 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:37:07.515307 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 636 Episode length: 171 Return: -171.00.0
W0909 00:37:08.763118 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:37:09.475109 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:37:10.094357 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:37:10.094682 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -192.17















Steps executed: 121979 Episode length: 600 Return: -600.0
I0909 00:37:39.291732 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -548.38
I0909 00:37:39.341568 139945412024320 run_experiment.py:447] Starting iteration 11

Steps executed: 185 Episode length: 185 Return: -185.00.0
W0909 00:37:40.634547 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:37:41.223906 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 777 Episode length: 275 Return: -275.00.0
W0909 00:37:42.990326 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:37:43.655454 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:37:43.655752 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -190.67















Steps executed: 121891 Episode length: 600 Return: -600.0
I0909 00:38:13.510210 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.16
I0909 00:38:13.561402 139945412024320 run_experiment.py:447] Starting iteration 12
W0909 00:38:13.907316 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 230 Episode length: 137 Return: -137.00.0
W0909 00:38:14.921771 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:38:15.698403 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 730 Episode length: 156 Return: -156.00.0
W0909 00:38:16.824278 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:38:17.419308 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:38:17.419618 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -147.43















Steps executed: 123935 Episode length: 126 Return: -126.0
I0909 00:38:46.627048 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.81
I0909 00:38:46.679354 139945412024320 run_experiment.py:447] Starting iteration 13
W0909 00:38:47.276411 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:38:48.135773 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 384 Episode length: 225 Return: -225.00.0
W0909 00:38:49.148792 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:38:49.579058 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:38:49.992486 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:38:50.443493 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:38:50.443967 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -143.14
















Steps executed: 124455 Episode length: 115 Return: -115.0
I0909 00:39:20.833433 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.20
I0909 00:39:20.887490 139945412024320 run_experiment.py:447] Starting iteration 14
W0909 00:39:21.314621 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:39:21.740546 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:39:22.166991 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 457 Episode length: 114 Return: -114.00.0
W0909 00:39:22.994393 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:39:23.513999 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:39:23.960203 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 949 Episode length: 123 Return: -123.00.0
W0909 00:39:24.851779 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:39:24.852116 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -118.56














Steps executed: 118618 Episode length: 116 Return: -116.0
I0909 00:39:54.290376 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -272.16

Steps executed: 116 Episode length: 116 Return: -116.00.0
W0909 00:39:54.785439 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:39:55.524141 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 669 Episode length: 164 Return: -164.00.0
W0909 00:39:56.840589 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:39:57.398258 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:39:57.829333 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:39:58.248282 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:39:58.248613 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -149.14















Steps executed: 118079 Episode length: 114 Return: -114.0
I0909 00:40:28.714623 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.66

Steps executed: 125044 Episode length: 600 Return: -600.0
W0909 00:40:29.185942 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:40:29.618051 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:40:30.005801 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 563 Episode length: 113 Return: -113.00.0
W0909 00:40:30.867576 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:40:31.228215 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:40:31.571316 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:40:31.961046 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:40:32.305436 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:40:32.622207 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:40:32.622498 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -102.70















Steps executed: 117846 Episode length: 90 Return: -90.0.0
I0909 00:41:02.572487 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.81

Steps executed: 125091 Episode length: 92 Return: -92.0.0
W0909 00:41:03.192037 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:41:03.762259 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:41:04.331913 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 539 Episode length: 84 Return: -84.0.00.0
W0909 00:41:05.215447 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:41:05.743784 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:41:06.181955 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:41:06.730734 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:41:06.731116 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -135.75















Steps executed: 120287 Episode length: 152 Return: -152.0
I0909 00:41:36.244676 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.88

Steps executed: 125121 Episode length: 153 Return: -153.0
W0909 00:41:37.293826 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:41:37.822296 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 722 Episode length: 155 Return: -155.03.0
W0909 00:41:38.966380 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:41:39.309173 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:41:40.204211 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:41:40.204766 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -175.67















Steps executed: 124196 Episode length: 600 Return: -600.0
I0909 00:42:09.580353 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -453.15
I0909 00:42:09.636069 139945412024320 run_experiment.py:447] Starting iteration 19

Steps executed: 282 Episode length: 98 Return: -98.0.00.0
W0909 00:42:10.689331 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:42:11.426826 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 811 Episode length: 168 Return: -168.00.0
W0909 00:42:12.678723 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:42:13.148999 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:42:13.645807 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:42:13.646119 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -152.14















Steps executed: 123244 Episode length: 600 Return: -600.0
I0909 00:42:43.212346 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.85
I0909 00:42:43.270848 139945412024320 run_experiment.py:447] Starting iteration 20
W0909 00:42:43.884607 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:42:44.316618 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 382 Episode length: 100 Return: -100.00.0
W0909 00:42:45.455163 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:42:46.075406 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 944 Episode length: 96 Return: -96.0.00.0
W0909 00:42:46.815154 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:42:47.223443 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:42:47.223730 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -131.50















Steps executed: 125142 Episode length: 146 Return: -146.0
I0909 00:43:17.054499 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.51
I0909 00:43:17.114113 139945412024320 run_experiment.py:447] Starting iteration 21
W0909 00:43:17.523953 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:43:18.022473 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:43:18.443844 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 439 Episode length: 88 Return: -88.0.06.0
W0909 00:43:19.348181 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:43:19.755189 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:43:20.172853 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 1158 Episode length: 86 Return: -86.006.0
W0909 00:43:20.911055 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:43:20.911357 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -112.00















Steps executed: 123818 Episode length: 116 Return: -116.0
I0909 00:43:51.247399 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.83
I0909 00:43:51.310187 139945412024320 run_experiment.py:447] Starting iteration 22
W0909 00:43:51.919068 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 422 Episode length: 116 Return: -116.02.0
W0909 00:43:52.917757 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:43:53.351876 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:43:53.988333 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:43:54.391898 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 923 Episode length: 111 Return: -111.02.0
W0909 00:43:55.221462 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:43:55.221754 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -129.12















Steps executed: 124255 Episode length: 90 Return: -90.0.0
I0909 00:44:25.519316 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.07
I0909 00:44:25.578579 139945412024320 run_experiment.py:447] Starting iteration 23
W0909 00:44:26.003890 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:44:26.440620 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 460 Episode length: 125 Return: -125.09.0
W0909 00:44:27.304467 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:44:27.728626 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:44:28.164028 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:44:28.483487 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 975 Episode length: 89 Return: -89.0.09.0
W0909 00:44:29.243025 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:44:29.557262 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:44:29.557592 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -106.10














Steps executed: 119021 Episode length: 113 Return: -113.0
I0909 00:44:58.976345 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.72

Steps executed: 117 Episode length: 117 Return: -117.05.0
W0909 00:44:59.508891 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:44:59.944690 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:45:00.364599 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 577 Episode length: 113 Return: -113.05.0
W0909 00:45:01.225255 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:45:01.632936 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:45:02.033286 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:45:02.453319 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:45:02.961548 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:45:02.961859 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -115.89















Steps executed: 120464 Episode length: 171 Return: -171.0
I0909 00:45:32.458864 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.71
I0909 00:45:32.524108 139945412024320 run_experiment.py:447] Starting iteration 25

Steps executed: 208 Episode length: 107 Return: -107.04.0
W0909 00:45:33.303866 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:45:33.720194 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:45:34.120012 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:45:34.432974 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 722 Episode length: 105 Return: -105.04.0
W0909 00:45:35.211972 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:45:35.567915 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:45:35.897711 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:45:36.297251 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:45:36.297581 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -101.40















Steps executed: 123718 Episode length: 600 Return: -600.0
I0909 00:46:05.914477 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.67
I0909 00:46:05.976579 139945412024320 run_experiment.py:447] Starting iteration 26
W0909 00:46:06.395388 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:46:06.789511 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 433 Episode length: 105 Return: -105.09.0
W0909 00:46:07.594787 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:46:08.094626 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:46:08.550892 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 919 Episode length: 111 Return: -111.09.0
W0909 00:46:09.403880 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:46:09.851632 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:46:09.851954 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -115.44















Steps executed: 125242 Episode length: 600 Return: -600.0
I0909 00:46:39.339440 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.79
I0909 00:46:39.402298 139945412024320 run_experiment.py:447] Starting iteration 27
W0909 00:46:40.669418 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 576 Episode length: 118 Return: -118.00.0
W0909 00:46:41.543836 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:46:42.016680 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:46:42.446187 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:46:42.894852 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:46:43.311790 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:46:43.312102 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -149.57
















Steps executed: 122588 Episode length: 111 Return: -111.0
I0909 00:47:14.175220 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.51
I0909 00:47:14.239237 139945412024320 run_experiment.py:447] Starting iteration 28
W0909 00:47:14.642895 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:47:15.053489 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 317 Episode length: 99 Return: -99.0.00.0
W0909 00:47:15.864931 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:47:16.300142 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:47:16.639989 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:47:16.953922 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 846 Episode length: 117 Return: -117.00.0
W0909 00:47:17.821150 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:47:18.225493 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:47:18.225825 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -106.70















Steps executed: 122859 Episode length: 155 Return: -155.0
I0909 00:47:48.337590 139945412024320 run_experiment.py:428] Average undiscounted return per evaluation episode: -222.28
I0909 00:47:48.403713 139945412024320 run_experiment.py:447] Starting iteration 29
W0909 00:47:49.001302 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 376 Episode length: 113 Return: -113.06.0
W0909 00:47:49.810612 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:47:50.139793 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:47:50.558386 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 835 Episode length: 258 Return: -258.06.0
W0909 00:47:51.992858 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0909 00:47:52.303892 139945412024320 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0909 00:47:52.304191 139945412024320 run_experiment.py:406] Average undiscounted return per training episode: -129.38















Steps executed: 118124 Episode length: 114 Return: -114.0

Done training!: 125019 Episode length: 109 Return: -109.0