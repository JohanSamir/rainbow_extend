Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0902 17:50:51.020082 140182397114368 run_experiment.py:549] Creating TrainRunner ...
I0902 17:50:51.032080 140182397114368 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:50:51.032353 140182397114368 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:50:51.032629 140182397114368 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:50:51.032826 140182397114368 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:50:51.032927 140182397114368 dqn_agent.py:275] 	 update_period: 4
I0902 17:50:51.033170 140182397114368 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:50:51.033316 140182397114368 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:50:51.033402 140182397114368 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:50:51.033570 140182397114368 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:50:51.033875 140182397114368 dqn_agent.py:280] 	 optimizer: adam
I0902 17:50:51.034225 140182397114368 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:50:51.034426 140182397114368 dqn_agent.py:283] 	 seed: 1630605051032032
I0902 17:50:51.037594 140182397114368 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:50:51.037795 140182397114368 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:50:51.037914 140182397114368 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:50:51.038024 140182397114368 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:50:51.038120 140182397114368 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:50:51.038200 140182397114368 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:50:51.038288 140182397114368 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:50:51.038369 140182397114368 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:50:51.038473 140182397114368 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:50:51.080047 140182397114368 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:50:51.499790 140182397114368 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:50:51.536061 140182397114368 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 17:50:51.546388 140182397114368 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:50:51.546627 140182397114368 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:50:51.546821 140182397114368 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:50:51.546902 140182397114368 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:50:51.546959 140182397114368 dqn_agent.py:275] 	 update_period: 4
I0902 17:50:51.547142 140182397114368 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:50:51.547291 140182397114368 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:50:51.547402 140182397114368 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:50:51.547488 140182397114368 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:50:51.547590 140182397114368 dqn_agent.py:280] 	 optimizer: adam
I0902 17:50:51.547868 140182397114368 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:50:51.547968 140182397114368 dqn_agent.py:283] 	 seed: 1630605051546335
I0902 17:50:51.550179 140182397114368 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:50:51.550311 140182397114368 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:50:51.550393 140182397114368 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:50:51.550472 140182397114368 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:50:51.550553 140182397114368 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:50:51.550616 140182397114368 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:50:51.550682 140182397114368 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:50:51.550765 140182397114368 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:50:51.550839 140182397114368 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:50:51.583580 140182397114368 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=2.000000
I0902 17:50:51.623861 140182397114368 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 17:50:51.624234 140182397114368 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 168.39
I0902 17:50:57.563280 140182397114368 replay_runner.py:36] Average training steps per second: 168.39
Steps executed: 207 Episode length: 79 Return: -319.0268681170545
I0902 17:50:58.753345 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -337.48
INFO:tensorflow:Starting iteration 1

Steps executed: 200 Episode length: 116 Return: -240.64347542618032
INFO:tensorflow:Average training steps per second: 225.80
I0902 17:51:07.534622 140182397114368 replay_runner.py:36] Average training steps per second: 225.80
I0902 17:51:07.699943 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -240.09
INFO:tensorflow:Starting iteration 2

Steps executed: 288 Episode length: 111 Return: -152.87320955869936
INFO:tensorflow:Average training steps per second: 227.13
I0902 17:51:16.249145 140182397114368 replay_runner.py:36] Average training steps per second: 227.13
I0902 17:51:16.466248 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.84
INFO:tensorflow:Starting iteration 3

Steps executed: 323 Episode length: 127 Return: -243.57882524815116
INFO:tensorflow:Average training steps per second: 230.47
I0902 17:51:25.148841 140182397114368 replay_runner.py:36] Average training steps per second: 230.47
I0902 17:51:25.395733 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.61
INFO:tensorflow:Starting iteration 4

Steps executed: 259 Episode length: 73 Return: -236.798621821241146
INFO:tensorflow:Average training steps per second: 231.14
I0902 17:51:33.964509 140182397114368 replay_runner.py:36] Average training steps per second: 231.14
I0902 17:51:34.175729 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.28
INFO:tensorflow:Starting iteration 5

Steps executed: 277 Episode length: 100 Return: -288.60100197091326
INFO:tensorflow:Average training steps per second: 222.78
I0902 17:51:43.051501 140182397114368 replay_runner.py:36] Average training steps per second: 222.78
I0902 17:51:43.274886 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.08
INFO:tensorflow:Starting iteration 6

Steps executed: 230 Episode length: 142 Return: -298.19371743449676
INFO:tensorflow:Average training steps per second: 221.88
I0902 17:51:52.150375 140182397114368 replay_runner.py:36] Average training steps per second: 221.88
I0902 17:51:52.332981 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.08
INFO:tensorflow:Starting iteration 7

Steps executed: 226 Episode length: 133 Return: -285.43176029175146
INFO:tensorflow:Average training steps per second: 225.72
I0902 17:52:00.965787 140182397114368 replay_runner.py:36] Average training steps per second: 225.72
I0902 17:52:01.146871 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.71
INFO:tensorflow:Starting iteration 8

Steps executed: 214 Episode length: 100 Return: -99.369138547929424
INFO:tensorflow:Average training steps per second: 224.86
I0902 17:52:09.777183 140182397114368 replay_runner.py:36] Average training steps per second: 224.86
I0902 17:52:09.945351 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.19
INFO:tensorflow:Starting iteration 9

Steps executed: 260 Episode length: 120 Return: -216.61196135507532
INFO:tensorflow:Average training steps per second: 225.48
I0902 17:52:18.792551 140182397114368 replay_runner.py:36] Average training steps per second: 225.48
I0902 17:52:19.018259 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -251.12
INFO:tensorflow:Starting iteration 10

Steps executed: 334 Episode length: 167 Return: -337.02270855307415
INFO:tensorflow:Average training steps per second: 227.14
I0902 17:52:27.717622 140182397114368 replay_runner.py:36] Average training steps per second: 227.14
I0902 17:52:28.020200 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.05
INFO:tensorflow:Starting iteration 11

Steps executed: 283 Episode length: 155 Return: -397.65093676802565
INFO:tensorflow:Average training steps per second: 225.37
I0902 17:52:36.819175 140182397114368 replay_runner.py:36] Average training steps per second: 225.37
I0902 17:52:37.081655 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -357.31
INFO:tensorflow:Starting iteration 12

Steps executed: 288 Episode length: 112 Return: -287.07059275215043
INFO:tensorflow:Average training steps per second: 227.17
I0902 17:52:45.838902 140182397114368 replay_runner.py:36] Average training steps per second: 227.17
I0902 17:52:46.078099 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -363.80
INFO:tensorflow:Starting iteration 13

Steps executed: 314 Episode length: 223 Return: -659.24239626437613
INFO:tensorflow:Average training steps per second: 227.61
I0902 17:52:54.860443 140182397114368 replay_runner.py:36] Average training steps per second: 227.61
I0902 17:52:55.136893 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -489.45
INFO:tensorflow:Starting iteration 14

Steps executed: 278 Episode length: 92 Return: -320.594295509918363
INFO:tensorflow:Average training steps per second: 228.65
I0902 17:53:03.798975 140182397114368 replay_runner.py:36] Average training steps per second: 228.65
I0902 17:53:04.017868 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.60
INFO:tensorflow:Starting iteration 15

Steps executed: 270 Episode length: 153 Return: -630.37960312779964
INFO:tensorflow:Average training steps per second: 249.27
I0902 17:53:12.190431 140182397114368 replay_runner.py:36] Average training steps per second: 249.27
I0902 17:53:12.462209 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -463.39
INFO:tensorflow:Starting iteration 16

Steps executed: 248 Episode length: 248 Return: -693.37265838278264
INFO:tensorflow:Average training steps per second: 239.02
I0902 17:53:20.940578 140182397114368 replay_runner.py:36] Average training steps per second: 239.02
I0902 17:53:21.191567 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -693.37
INFO:tensorflow:Starting iteration 17

Steps executed: 277 Episode length: 113 Return: -257.41717875558544
INFO:tensorflow:Average training steps per second: 222.38
I0902 17:53:30.008724 140182397114368 replay_runner.py:36] Average training steps per second: 222.38
I0902 17:53:30.264931 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.06
INFO:tensorflow:Starting iteration 18

Steps executed: 192 Episode length: 192 Return: -415.54953433624337
INFO:tensorflow:Average training steps per second: 241.94
I0902 17:53:38.610955 140182397114368 replay_runner.py:36] Average training steps per second: 241.94

Steps executed: 375 Episode length: 183 Return: -710.71662257737927
INFO:tensorflow:Starting iteration 19

Steps executed: 291 Episode length: 291 Return: -502.90447515386927
INFO:tensorflow:Average training steps per second: 239.98
I0902 17:53:47.327605 140182397114368 replay_runner.py:36] Average training steps per second: 239.98
I0902 17:53:47.662826 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.90
INFO:tensorflow:Starting iteration 20

Steps executed: 424 Episode length: 257 Return: -347.70245266682637
INFO:tensorflow:Average training steps per second: 226.55
I0902 17:53:56.340669 140182397114368 replay_runner.py:36] Average training steps per second: 226.55
I0902 17:53:56.790430 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -506.01
INFO:tensorflow:Starting iteration 21

Steps executed: 201 Episode length: 201 Return: -716.72104045309727
INFO:tensorflow:Average training steps per second: 225.81
I0902 17:54:05.575579 140182397114368 replay_runner.py:36] Average training steps per second: 225.81
I0902 17:54:05.768627 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -716.72
INFO:tensorflow:Starting iteration 22

Steps executed: 303 Episode length: 184 Return: -750.53859974947457
INFO:tensorflow:Average training steps per second: 228.43
I0902 17:54:14.380278 140182397114368 replay_runner.py:36] Average training steps per second: 228.43
I0902 17:54:14.668743 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -607.81
INFO:tensorflow:Starting iteration 23
I0902 17:54:18.961732 140182397114368 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 233.79

Steps executed: 497 Episode length: 318 Return: -867.14872467597897
I0902 17:54:23.731245 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -526.73
INFO:tensorflow:Starting iteration 24
I0902 17:54:28.130066 140182397114368 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 223.57

Steps executed: 510 Episode length: 510 Return: -713.21660846997197
I0902 17:54:33.755781 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -713.22
INFO:tensorflow:Starting iteration 25

Steps executed: 453 Episode length: 272 Return: -340.71516374719297
INFO:tensorflow:Average training steps per second: 218.36
I0902 17:54:42.672195 140182397114368 replay_runner.py:36] Average training steps per second: 218.36
I0902 17:54:43.172102 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -481.37
INFO:tensorflow:Starting iteration 26

Steps executed: 292 Episode length: 94 Return: -375.268582438781557
INFO:tensorflow:Average training steps per second: 223.87
I0902 17:54:52.034623 140182397114368 replay_runner.py:36] Average training steps per second: 223.87
I0902 17:54:52.299052 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -509.05
INFO:tensorflow:Starting iteration 27
I0902 17:54:56.721619 140182397114368 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 221.00

Steps executed: 413 Episode length: 221 Return: -592.86461252202827
I0902 17:55:01.660704 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -604.57
INFO:tensorflow:Starting iteration 28

Steps executed: 238 Episode length: 238 Return: -674.78317003452637
INFO:tensorflow:Average training steps per second: 229.94
I0902 17:55:10.106848 140182397114368 replay_runner.py:36] Average training steps per second: 229.94
I0902 17:55:10.361076 140182397114368 run_experiment.py:428] Average undiscounted return per evaluation episode: -674.78
INFO:tensorflow:Starting iteration 29

Steps executed: 343 Episode length: 158 Return: -186.20459481445835
INFO:tensorflow:Average training steps per second: 225.81
I0902 17:55:19.063041 140182397114368 replay_runner.py:36] Average training steps per second: 225.81

Done fixed training!Episode length: 158 Return: -186.20459481445835