Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0902 00:34:49.268668 139825600018432 run_experiment.py:549] Creating TrainRunner ...
I0902 00:34:49.277107 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:34:49.277252 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:34:49.277336 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:34:49.277413 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:34:49.277529 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0902 00:34:49.277644 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:34:49.277734 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:34:49.277813 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:34:49.277893 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:34:49.277963 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:34:49.278054 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:34:49.278161 139825600018432 dqn_agent.py:283] 	 seed: 1630542889277068
I0902 00:34:49.279897 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:34:49.280027 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:34:49.280112 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:34:49.280177 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:34:49.280235 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:34:49.280306 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:34:49.280363 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:34:49.280445 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:34:49.280514 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:34:49.306297 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:34:49.561460 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:34:49.570627 139825600018432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:34:49.577363 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:34:49.577495 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:34:49.577560 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:34:49.577648 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:34:49.577724 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0902 00:34:49.577791 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:34:49.577949 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:34:49.578162 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:34:49.578289 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:34:49.578404 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:34:49.578487 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:34:49.578609 139825600018432 dqn_agent.py:283] 	 seed: 1630542889577334
I0902 00:34:49.580845 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:34:49.580971 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:34:49.581072 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:34:49.581175 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:34:49.581238 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:34:49.581294 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:34:49.581379 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:34:49.581451 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:34:49.581520 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:34:49.601784 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:34:49.618195 139825600018432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:34:49.618378 139825600018432 replay_runner.py:41] Starting iteration 0
Steps executed: 249 Episode length: 249 Return: -496.56430163440194
INFO:tensorflow:Average training steps per second: 251.97
I0902 00:34:53.587188 139825600018432 replay_runner.py:36] Average training steps per second: 251.97
I0902 00:34:54.421417 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -496.56
INFO:tensorflow:Starting iteration 1
I0902 00:34:57.758160 139825600018432 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 325.92

Steps executed: 414 Episode length: 250 Return: -503.93769029066284
I0902 00:35:01.087980 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -363.65
INFO:tensorflow:Starting iteration 2

Steps executed: 264 Episode length: 91 Return: -459.728157304325984
INFO:tensorflow:Average training steps per second: 324.44
I0902 00:35:07.443217 139825600018432 replay_runner.py:36] Average training steps per second: 324.44
I0902 00:35:07.624792 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.69
INFO:tensorflow:Starting iteration 3

Steps executed: 256 Episode length: 111 Return: -233.19954338323043
INFO:tensorflow:Average training steps per second: 328.66
I0902 00:35:14.010301 139825600018432 replay_runner.py:36] Average training steps per second: 328.66
I0902 00:35:14.151061 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.60
INFO:tensorflow:Starting iteration 4

Steps executed: 334 Episode length: 183 Return: -426.28251829318833
INFO:tensorflow:Average training steps per second: 328.40
I0902 00:35:20.594053 139825600018432 replay_runner.py:36] Average training steps per second: 328.40
I0902 00:35:20.832291 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -383.38
INFO:tensorflow:Starting iteration 5

Steps executed: 260 Episode length: 66 Return: -607.454408911043433
INFO:tensorflow:Average training steps per second: 324.01
I0902 00:35:27.293502 139825600018432 replay_runner.py:36] Average training steps per second: 324.01
I0902 00:35:27.460896 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -542.26
INFO:tensorflow:Starting iteration 6

Steps executed: 803 Episode length: 803 Return: -550.50783130694793
INFO:tensorflow:Average training steps per second: 331.49
I0902 00:35:33.876002 139825600018432 replay_runner.py:36] Average training steps per second: 331.49
I0902 00:35:35.080982 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.51
INFO:tensorflow:Starting iteration 7

Steps executed: 343 Episode length: 343 Return: 233.414779634757343
INFO:tensorflow:Average training steps per second: 316.48
I0902 00:35:41.633392 139825600018432 replay_runner.py:36] Average training steps per second: 316.48
I0902 00:35:41.989107 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: 233.41
INFO:tensorflow:Starting iteration 8
I0902 00:35:45.275547 139825600018432 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 320.93

Steps executed: 970 Episode length: 970 Return: -717.23606783964243
I0902 00:35:50.208767 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -717.24
INFO:tensorflow:Starting iteration 9

Steps executed: 423 Episode length: 423 Return: -400.16489356108633
INFO:tensorflow:Average training steps per second: 329.71
I0902 00:35:56.611647 139825600018432 replay_runner.py:36] Average training steps per second: 329.71
I0902 00:35:56.980809 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.16
INFO:tensorflow:Starting iteration 10

Steps executed: 513 Episode length: 513 Return: -902.64072575780533
INFO:tensorflow:Average training steps per second: 327.95
I0902 00:36:03.383175 139825600018432 replay_runner.py:36] Average training steps per second: 327.95
I0902 00:36:03.887173 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -902.64
INFO:tensorflow:Starting iteration 11
I0902 00:36:07.294064 139825600018432 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 335.89

Steps executed: 929 Episode length: 929 Return: -430.14209207459294
I0902 00:36:11.939878 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -430.14
INFO:tensorflow:Starting iteration 12

Steps executed: 114 Episode length: 53 Return: -420.154462195225794
INFO:tensorflow:Average training steps per second: 339.22

Steps executed: 1114 Episode length: 1000 Return: -105.36662127402137
I0902 00:36:20.555245 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -271.87
INFO:tensorflow:Starting iteration 13
I0902 00:36:23.948288 139825600018432 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 336.95

Steps executed: 635 Episode length: 635 Return: -628.1864134378815137
I0902 00:36:27.737905 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -628.19
INFO:tensorflow:Starting iteration 14

Steps executed: 237 Episode length: 93 Return: -732.84862892535182437
INFO:tensorflow:Average training steps per second: 325.32
I0902 00:36:34.152272 139825600018432 replay_runner.py:36] Average training steps per second: 325.32
I0902 00:36:34.296366 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -437.63
INFO:tensorflow:Starting iteration 15

Steps executed: 60 Episode length: 60 Return: -154.902487326927182437
INFO:tensorflow:Average training steps per second: 324.97

Steps executed: 1060 Episode length: 1000 Return: -653.71794160397697
I0902 00:36:42.841795 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -404.31
INFO:tensorflow:Starting iteration 16

Steps executed: 248 Episode length: 53 Return: -418.44850735774942697
INFO:tensorflow:Average training steps per second: 342.88
I0902 00:36:49.161476 139825600018432 replay_runner.py:36] Average training steps per second: 342.88
I0902 00:36:49.295928 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -495.61
INFO:tensorflow:Starting iteration 17

Steps executed: 242 Episode length: 102 Return: -166.4289610865181497
INFO:tensorflow:Average training steps per second: 337.66
I0902 00:36:55.732345 139825600018432 replay_runner.py:36] Average training steps per second: 337.66
I0902 00:36:55.877566 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -150.42
INFO:tensorflow:Starting iteration 18

Steps executed: 261 Episode length: 62 Return: -118.28627756564333497
INFO:tensorflow:Average training steps per second: 339.40
I0902 00:37:02.292722 139825600018432 replay_runner.py:36] Average training steps per second: 339.40
I0902 00:37:02.441525 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.76
INFO:tensorflow:Starting iteration 19

Steps executed: 238 Episode length: 102 Return: -669.5610533275692497
INFO:tensorflow:Average training steps per second: 340.23
I0902 00:37:08.841991 139825600018432 replay_runner.py:36] Average training steps per second: 340.23
I0902 00:37:08.997318 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -407.61
INFO:tensorflow:Starting iteration 20
I0902 00:37:12.448546 139825600018432 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 336.32
I0902 00:37:15.422224 139825600018432 replay_runner.py:36] Average training steps per second: 336.32

Steps executed: 263 Episode length: 77 Return: -575.47223718369676497
INFO:tensorflow:Starting iteration 21

Steps executed: 217 Episode length: 94 Return: -274.89161491953866497
INFO:tensorflow:Average training steps per second: 332.61
I0902 00:37:21.972631 139825600018432 replay_runner.py:36] Average training steps per second: 332.61
I0902 00:37:22.097943 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -450.47
INFO:tensorflow:Starting iteration 22

Steps executed: 333 Episode length: 146 Return: -442.1609376198069497
INFO:tensorflow:Average training steps per second: 336.64
I0902 00:37:28.504172 139825600018432 replay_runner.py:36] Average training steps per second: 336.64
I0902 00:37:28.672653 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.45
INFO:tensorflow:Starting iteration 23

Steps executed: 206 Episode length: 60 Return: -126.09919614429492497
INFO:tensorflow:Average training steps per second: 346.61
I0902 00:37:34.958662 139825600018432 replay_runner.py:36] Average training steps per second: 346.61
I0902 00:37:35.055911 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.81
INFO:tensorflow:Starting iteration 24

Steps executed: 130 Episode length: 56 Return: -460.85479110136462497
INFO:tensorflow:Average training steps per second: 346.63

Steps executed: 206 Episode length: 76 Return: -378.64440624882182497
I0902 00:37:41.449291 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -469.12
INFO:tensorflow:Starting iteration 25

Steps executed: 259 Episode length: 112 Return: -499.8479101954798797
INFO:tensorflow:Average training steps per second: 329.51
I0902 00:37:47.905077 139825600018432 replay_runner.py:36] Average training steps per second: 329.51
I0902 00:37:48.051334 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -599.31
INFO:tensorflow:Starting iteration 26

Steps executed: 221 Episode length: 74 Return: -508.03857243742328797
INFO:tensorflow:Average training steps per second: 330.26
I0902 00:37:54.469308 139825600018432 replay_runner.py:36] Average training steps per second: 330.26
I0902 00:37:54.595371 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -551.27
INFO:tensorflow:Starting iteration 27

Steps executed: 248 Episode length: 86 Return: -487.32423555926898797
INFO:tensorflow:Average training steps per second: 338.08
I0902 00:38:00.782812 139825600018432 replay_runner.py:36] Average training steps per second: 338.08
I0902 00:38:00.922316 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -552.43
INFO:tensorflow:Starting iteration 28

Steps executed: 244 Episode length: 48 Return: -400.66387597555272797
INFO:tensorflow:Average training steps per second: 332.50
I0902 00:38:07.259084 139825600018432 replay_runner.py:36] Average training steps per second: 332.50
I0902 00:38:07.394482 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -334.02
INFO:tensorflow:Starting iteration 29

Steps executed: 319 Episode length: 121 Return: -607.3243662602026797
INFO:tensorflow:Average training steps per second: 329.82
I0902 00:38:13.677022 139825600018432 replay_runner.py:36] Average training steps per second: 329.82

Done fixed training!Episode length: 121 Return: -607.3243662602026797