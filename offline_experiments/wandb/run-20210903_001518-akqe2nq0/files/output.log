I0903 00:15:24.132889 139803223304192 run_experiment.py:549] Creating TrainRunner ...
I0903 00:15:24.140896 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:15:24.141035 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:15:24.141127 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:15:24.141196 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:15:24.141258 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0903 00:15:24.141344 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:15:24.141443 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:15:24.141530 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:15:24.141608 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:15:24.141679 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0903 00:15:24.141754 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:15:24.141828 139803223304192 dqn_agent.py:283] 	 seed: 1630628124140858
I0903 00:15:24.144109 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:15:24.144276 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:15:24.144483 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:15:24.144665 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:15:24.144830 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:15:24.144931 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:15:24.145064 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:15:24.145156 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:15:24.145258 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:15:24.169739 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:15:24.439218 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:15:24.449092 139803223304192 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:15:24.456415 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:15:24.456564 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:15:24.456637 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:15:24.456699 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:15:24.456757 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0903 00:15:24.456855 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:15:24.456966 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:15:24.457034 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:15:24.457105 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:15:24.457181 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0903 00:15:24.457250 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:15:24.457324 139803223304192 dqn_agent.py:283] 	 seed: 1630628124456376
I0903 00:15:24.458634 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:15:24.458737 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:15:24.458800 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:15:24.458856 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:15:24.458907 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:15:24.458996 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:15:24.459059 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:15:24.459117 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:15:24.459185 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:15:24.480392 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:15:24.494224 139803223304192 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:15:24.494390 139803223304192 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
Steps executed: 225 Episode length: 109 Return: -316.12665219303653
INFO:tensorflow:Average training steps per second: 251.26
I0903 00:15:28.474472 139803223304192 replay_runner.py:36] Average training steps per second: 251.26
I0903 00:15:29.268693 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -620.70
INFO:tensorflow:Starting iteration 1

Steps executed: 174 Episode length: 95 Return: -396.016264878999753
INFO:tensorflow:Average training steps per second: 331.86
I0903 00:15:35.632203 139803223304192 replay_runner.py:36] Average training steps per second: 331.86

Steps executed: 315 Episode length: 141 Return: -426.36296491061717
INFO:tensorflow:Starting iteration 2

Steps executed: 257 Episode length: 257 Return: -482.09622439163817
INFO:tensorflow:Average training steps per second: 326.12
I0903 00:15:42.019024 139803223304192 replay_runner.py:36] Average training steps per second: 326.12
I0903 00:15:42.202950 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -482.10
INFO:tensorflow:Starting iteration 3

Steps executed: 312 Episode length: 312 Return: -341.73306422817177
INFO:tensorflow:Average training steps per second: 320.12
I0903 00:15:48.542343 139803223304192 replay_runner.py:36] Average training steps per second: 320.12
I0903 00:15:48.795090 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.73
INFO:tensorflow:Starting iteration 4
I0903 00:15:52.169857 139803223304192 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 333.05
I0903 00:15:55.172699 139803223304192 replay_runner.py:36] Average training steps per second: 333.05

Steps executed: 260 Episode length: 162 Return: -654.07091048913827
INFO:tensorflow:Starting iteration 5

Steps executed: 92 Episode length: 92 Return: -362.5782254571445827
INFO:tensorflow:Average training steps per second: 332.81
I0903 00:16:01.759796 139803223304192 replay_runner.py:36] Average training steps per second: 332.81

Steps executed: 1092 Episode length: 1000 Return: -903.7556278424495
INFO:tensorflow:Starting iteration 6
I0903 00:16:06.944260 139803223304192 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 334.75

Steps executed: 204 Episode length: 77 Return: -462.3277711247894495
I0903 00:16:10.047441 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -402.35
INFO:tensorflow:Starting iteration 7

Steps executed: 391 Episode length: 391 Return: -149.697154930230825
INFO:tensorflow:Average training steps per second: 326.03
I0903 00:16:16.527127 139803223304192 replay_runner.py:36] Average training steps per second: 326.03
I0903 00:16:16.860815 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.70
INFO:tensorflow:Starting iteration 8

Steps executed: 264 Episode length: 174 Return: -451.293141776513325
INFO:tensorflow:Average training steps per second: 322.68
I0903 00:16:23.404524 139803223304192 replay_runner.py:36] Average training steps per second: 322.68
I0903 00:16:23.572760 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -537.03
INFO:tensorflow:Starting iteration 9

Steps executed: 230 Episode length: 57 Return: -156.7692608152589725
INFO:tensorflow:Average training steps per second: 333.09
I0903 00:16:29.920663 139803223304192 replay_runner.py:36] Average training steps per second: 333.09
I0903 00:16:30.063325 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.39
INFO:tensorflow:Starting iteration 10

Steps executed: 258 Episode length: 124 Return: -758.695005782755625
INFO:tensorflow:Average training steps per second: 334.47
I0903 00:16:36.447162 139803223304192 replay_runner.py:36] Average training steps per second: 334.47
I0903 00:16:36.607436 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -709.70
INFO:tensorflow:Starting iteration 11

Steps executed: 324 Episode length: 324 Return: -471.816076310534875
INFO:tensorflow:Average training steps per second: 330.08
I0903 00:16:42.996530 139803223304192 replay_runner.py:36] Average training steps per second: 330.08
I0903 00:16:43.275985 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -471.82
INFO:tensorflow:Starting iteration 12

Steps executed: 449 Episode length: 449 Return: -712.576813791904375
INFO:tensorflow:Average training steps per second: 319.62
I0903 00:16:49.789272 139803223304192 replay_runner.py:36] Average training steps per second: 319.62
I0903 00:16:50.195667 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -712.58
INFO:tensorflow:Starting iteration 13

Steps executed: 211 Episode length: 87 Return: -629.2553451845386675
INFO:tensorflow:Average training steps per second: 313.47
I0903 00:16:56.717459 139803223304192 replay_runner.py:36] Average training steps per second: 313.47
I0903 00:16:56.845996 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -709.79
INFO:tensorflow:Starting iteration 14

Steps executed: 427 Episode length: 231 Return: -324.413134840637275
INFO:tensorflow:Average training steps per second: 329.59
I0903 00:17:03.205220 139803223304192 replay_runner.py:36] Average training steps per second: 329.59
I0903 00:17:03.511897 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.67
INFO:tensorflow:Starting iteration 15

Steps executed: 221 Episode length: 56 Return: -325.4547560972711575
INFO:tensorflow:Average training steps per second: 323.30
I0903 00:17:09.977524 139803223304192 replay_runner.py:36] Average training steps per second: 323.30
I0903 00:17:10.097983 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.10
INFO:tensorflow:Starting iteration 16

Steps executed: 293 Episode length: 126 Return: -426.157341892682045
INFO:tensorflow:Average training steps per second: 318.33
I0903 00:17:16.558343 139803223304192 replay_runner.py:36] Average training steps per second: 318.33
I0903 00:17:16.773046 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -724.41
INFO:tensorflow:Starting iteration 17

Steps executed: 246 Episode length: 54 Return: -211.1788640658017545
INFO:tensorflow:Average training steps per second: 322.00
I0903 00:17:23.264441 139803223304192 replay_runner.py:36] Average training steps per second: 322.00
I0903 00:17:23.420763 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.98
INFO:tensorflow:Starting iteration 18

Steps executed: 254 Episode length: 125 Return: -205.562221721518225
INFO:tensorflow:Average training steps per second: 316.27
I0903 00:17:29.945182 139803223304192 replay_runner.py:36] Average training steps per second: 316.27
I0903 00:17:30.121032 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.32
INFO:tensorflow:Starting iteration 19
I0903 00:17:33.439378 139803223304192 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 327.60

Steps executed: 252 Episode length: 115 Return: -502.714380500011625
I0903 00:17:36.664183 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -523.05
INFO:tensorflow:Starting iteration 20

Steps executed: 253 Episode length: 72 Return: -580.8435704010558625
INFO:tensorflow:Average training steps per second: 320.56
I0903 00:17:43.111134 139803223304192 replay_runner.py:36] Average training steps per second: 320.56
I0903 00:17:43.272584 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -445.99
INFO:tensorflow:Starting iteration 21

Steps executed: 247 Episode length: 50 Return: -439.4757349544332235
INFO:tensorflow:Average training steps per second: 317.15
I0903 00:17:49.747408 139803223304192 replay_runner.py:36] Average training steps per second: 317.15
I0903 00:17:49.900892 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -443.28
INFO:tensorflow:Starting iteration 22

Steps executed: 236 Episode length: 84 Return: -510.9482507073023535
INFO:tensorflow:Average training steps per second: 318.74
I0903 00:17:56.343746 139803223304192 replay_runner.py:36] Average training steps per second: 318.74
I0903 00:17:56.501000 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -415.53
INFO:tensorflow:Starting iteration 23

Steps executed: 262 Episode length: 69 Return: -487.1805622331424635
INFO:tensorflow:Average training steps per second: 330.96
I0903 00:18:02.861483 139803223304192 replay_runner.py:36] Average training steps per second: 330.96
I0903 00:18:03.042235 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -538.83
INFO:tensorflow:Starting iteration 24

Steps executed: 228 Episode length: 78 Return: -464.0622932848932635
INFO:tensorflow:Average training steps per second: 329.39
I0903 00:18:09.506753 139803223304192 replay_runner.py:36] Average training steps per second: 329.39
I0903 00:18:09.650416 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -481.90
INFO:tensorflow:Starting iteration 25

Steps executed: 258 Episode length: 66 Return: -617.8108334854356635
INFO:tensorflow:Average training steps per second: 334.48
I0903 00:18:16.035296 139803223304192 replay_runner.py:36] Average training steps per second: 334.48
I0903 00:18:16.211268 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.22
INFO:tensorflow:Starting iteration 26

Steps executed: 283 Episode length: 85 Return: -781.1295328522094635
INFO:tensorflow:Average training steps per second: 349.42
I0903 00:18:22.514755 139803223304192 replay_runner.py:36] Average training steps per second: 349.42
I0903 00:18:22.711992 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -599.35
INFO:tensorflow:Starting iteration 27

Steps executed: 249 Episode length: 57 Return: -466.7949657117642335
INFO:tensorflow:Average training steps per second: 355.73
I0903 00:18:29.010269 139803223304192 replay_runner.py:36] Average training steps per second: 355.73
I0903 00:18:29.168049 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -523.01
INFO:tensorflow:Starting iteration 28

Steps executed: 202 Episode length: 61 Return: -576.3473752224493335
INFO:tensorflow:Average training steps per second: 358.78
I0903 00:18:35.470881 139803223304192 replay_runner.py:36] Average training steps per second: 358.78
I0903 00:18:35.611004 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -645.98
INFO:tensorflow:Starting iteration 29

Steps executed: 202 Episode length: 55 Return: -358.9342844634893335
INFO:tensorflow:Average training steps per second: 364.98
I0903 00:18:41.914789 139803223304192 replay_runner.py:36] Average training steps per second: 364.98

Done fixed training!Episode length: 55 Return: -358.9342844634893335