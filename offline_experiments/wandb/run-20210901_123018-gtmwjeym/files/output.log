Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0901 12:30:25.146520 140536266098688 run_experiment.py:549] Creating TrainRunner ...
I0901 12:30:25.159933 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:30:25.160210 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:30:25.160706 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:30:25.160970 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:30:25.161483 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 12:30:25.161605 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:30:25.161853 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:30:25.161963 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:30:25.162093 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:30:25.162185 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 12:30:25.162302 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:30:25.162406 140536266098688 dqn_agent.py:283] 	 seed: 1630499425159862
I0901 12:30:25.164667 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:30:25.164789 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:30:25.164885 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:30:25.164951 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:30:25.165010 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:30:25.165096 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:30:25.165155 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:30:25.165365 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:30:25.165498 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:30:25.383244 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:30:25.787001 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:30:25.802975 140536266098688 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:30:25.811013 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:30:25.811311 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:30:25.811451 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:30:25.811572 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:30:25.811684 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 12:30:25.811799 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:30:25.811920 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:30:25.812104 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:30:25.812247 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:30:25.812625 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 12:30:25.812849 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:30:25.813024 140536266098688 dqn_agent.py:283] 	 seed: 1630499425810956
I0901 12:30:25.816538 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:30:25.816777 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:30:25.817071 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:30:25.817259 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:30:25.817364 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:30:25.817444 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:30:25.817531 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:30:25.817604 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:30:25.817706 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:30:25.848644 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:30:25.872548 140536266098688 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:30:25.873354 140536266098688 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 157.98
I0901 12:30:32.203778 140536266098688 replay_runner.py:36] Average training steps per second: 157.98
Steps executed: 205 Episode length: 110 Return: -320.9780304240251
I0901 12:30:33.496615 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -249.56
INFO:tensorflow:Starting iteration 1

Steps executed: 309 Episode length: 110 Return: -586.39482877047234
INFO:tensorflow:Average training steps per second: 222.27
I0901 12:30:42.428243 140536266098688 replay_runner.py:36] Average training steps per second: 222.27
I0901 12:30:42.727653 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -503.52
INFO:tensorflow:Starting iteration 2
I0901 12:30:46.935219 140536266098688 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 229.23
I0901 12:30:51.298341 140536266098688 replay_runner.py:36] Average training steps per second: 229.23

Steps executed: 252 Episode length: 104 Return: -256.20823685323024
INFO:tensorflow:Starting iteration 3

Steps executed: 219 Episode length: 118 Return: -73.233567742260194
INFO:tensorflow:Average training steps per second: 232.95
I0901 12:31:00.082923 140536266098688 replay_runner.py:36] Average training steps per second: 232.95
I0901 12:31:00.291638 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -318.02
INFO:tensorflow:Starting iteration 4
I0901 12:31:04.589246 140536266098688 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 229.95

Steps executed: 204 Episode length: 90 Return: -720.928356429745284
I0901 12:31:09.127156 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -399.88
INFO:tensorflow:Starting iteration 5

Steps executed: 425 Episode length: 312 Return: 205.416426920703467
INFO:tensorflow:Average training steps per second: 230.04
I0901 12:31:17.898047 140536266098688 replay_runner.py:36] Average training steps per second: 230.04
I0901 12:31:18.416821 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: 36.78
INFO:tensorflow:Starting iteration 6
I0901 12:31:22.576505 140536266098688 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 233.45

Steps executed: 215 Episode length: 125 Return: -433.43877953387585
I0901 12:31:27.083647 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -580.29
INFO:tensorflow:Starting iteration 7

Steps executed: 425 Episode length: 425 Return: 180.013157635808575
INFO:tensorflow:Average training steps per second: 233.89
I0901 12:31:35.741399 140536266098688 replay_runner.py:36] Average training steps per second: 233.89
I0901 12:31:36.495512 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: 180.01
INFO:tensorflow:Starting iteration 8
I0901 12:31:40.707524 140536266098688 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 227.97

Steps executed: 255 Episode length: 132 Return: -10.981274507186576
I0901 12:31:45.327935 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.57
INFO:tensorflow:Starting iteration 9

Steps executed: 284 Episode length: 185 Return: 14.6976989830776866
INFO:tensorflow:Average training steps per second: 223.20
I0901 12:31:54.153292 140536266098688 replay_runner.py:36] Average training steps per second: 223.20
I0901 12:31:54.440955 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.81
INFO:tensorflow:Starting iteration 10
I0901 12:31:58.668291 140536266098688 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 221.50

Steps executed: 293 Episode length: 96 Return: -304.406479447388452
I0901 12:32:03.416987 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.11
INFO:tensorflow:Starting iteration 11

Steps executed: 206 Episode length: 85 Return: -315.818440206734207
INFO:tensorflow:Average training steps per second: 215.22
I0901 12:32:12.464166 140536266098688 replay_runner.py:36] Average training steps per second: 215.22
I0901 12:32:12.655605 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.55
INFO:tensorflow:Starting iteration 12

Steps executed: 290 Episode length: 106 Return: -124.93435505818097
INFO:tensorflow:Average training steps per second: 221.16
I0901 12:32:21.552447 140536266098688 replay_runner.py:36] Average training steps per second: 221.16
I0901 12:32:21.843382 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.87
INFO:tensorflow:Starting iteration 13

Steps executed: 257 Episode length: 182 Return: -151.01268928914516
INFO:tensorflow:Average training steps per second: 220.93
I0901 12:32:30.703965 140536266098688 replay_runner.py:36] Average training steps per second: 220.93
I0901 12:32:30.949743 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.37
INFO:tensorflow:Starting iteration 14

Steps executed: 228 Episode length: 93 Return: -193.196612357384156
INFO:tensorflow:Average training steps per second: 229.34
I0901 12:32:39.575166 140536266098688 replay_runner.py:36] Average training steps per second: 229.34
I0901 12:32:39.793983 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.30
INFO:tensorflow:Starting iteration 15

Steps executed: 211 Episode length: 84 Return: -200.215936116420476
INFO:tensorflow:Average training steps per second: 223.82
I0901 12:32:48.647645 140536266098688 replay_runner.py:36] Average training steps per second: 223.82
I0901 12:32:48.810074 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.52
INFO:tensorflow:Starting iteration 16

Steps executed: 259 Episode length: 84 Return: -319.084397291860266
INFO:tensorflow:Average training steps per second: 222.37
I0901 12:32:57.729168 140536266098688 replay_runner.py:36] Average training steps per second: 222.37
I0901 12:32:57.952579 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -318.81
INFO:tensorflow:Starting iteration 17

Steps executed: 375 Episode length: 196 Return: -351.27429791383756
INFO:tensorflow:Average training steps per second: 224.66
I0901 12:33:06.688715 140536266098688 replay_runner.py:36] Average training steps per second: 224.66
I0901 12:33:07.046845 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -294.25
INFO:tensorflow:Starting iteration 18

Steps executed: 255 Episode length: 90 Return: -329.476863961434556
INFO:tensorflow:Average training steps per second: 218.74
I0901 12:33:16.045799 140536266098688 replay_runner.py:36] Average training steps per second: 218.74
I0901 12:33:16.253707 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -157.14
INFO:tensorflow:Starting iteration 19

Steps executed: 244 Episode length: 121 Return: -366.51189668148335
INFO:tensorflow:Average training steps per second: 224.99
I0901 12:33:24.894452 140536266098688 replay_runner.py:36] Average training steps per second: 224.99
I0901 12:33:25.115193 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -355.28
INFO:tensorflow:Starting iteration 20

Steps executed: 240 Episode length: 240 Return: -199.77702161701086
INFO:tensorflow:Average training steps per second: 222.54
I0901 12:33:34.030217 140536266098688 replay_runner.py:36] Average training steps per second: 222.54
I0901 12:33:34.282908 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.78
INFO:tensorflow:Starting iteration 21

Steps executed: 247 Episode length: 76 Return: -367.690111602474646
INFO:tensorflow:Average training steps per second: 226.03
I0901 12:33:42.909814 140536266098688 replay_runner.py:36] Average training steps per second: 226.03
I0901 12:33:43.110213 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.24
INFO:tensorflow:Starting iteration 22

Steps executed: 254 Episode length: 105 Return: -727.83539380857446
INFO:tensorflow:Average training steps per second: 234.95
I0901 12:33:51.826462 140536266098688 replay_runner.py:36] Average training steps per second: 234.95
I0901 12:33:52.055186 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -565.09
INFO:tensorflow:Starting iteration 23

Steps executed: 215 Episode length: 87 Return: -854.859041280129946
INFO:tensorflow:Average training steps per second: 232.96
I0901 12:34:00.816618 140536266098688 replay_runner.py:36] Average training steps per second: 232.96
I0901 12:34:01.026259 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -622.31
INFO:tensorflow:Starting iteration 24

Steps executed: 474 Episode length: 303 Return: -287.20486182342778
INFO:tensorflow:Average training steps per second: 229.99
I0901 12:34:09.541237 140536266098688 replay_runner.py:36] Average training steps per second: 229.99
I0901 12:34:10.020976 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.03
INFO:tensorflow:Starting iteration 25

Steps executed: 250 Episode length: 106 Return: -421.55973354469718
INFO:tensorflow:Average training steps per second: 225.87
I0901 12:34:18.941014 140536266098688 replay_runner.py:36] Average training steps per second: 225.87
I0901 12:34:19.161261 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.61
INFO:tensorflow:Starting iteration 26

Steps executed: 247 Episode length: 74 Return: -514.966802140641618
INFO:tensorflow:Average training steps per second: 220.91
I0901 12:34:28.005640 140536266098688 replay_runner.py:36] Average training steps per second: 220.91
I0901 12:34:28.231480 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -514.36
INFO:tensorflow:Starting iteration 27

Steps executed: 284 Episode length: 132 Return: -296.05911238422993
INFO:tensorflow:Average training steps per second: 226.54
I0901 12:34:37.046525 140536266098688 replay_runner.py:36] Average training steps per second: 226.54
I0901 12:34:37.289668 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.01
INFO:tensorflow:Starting iteration 28

Steps executed: 307 Episode length: 141 Return: -135.56205077406685
INFO:tensorflow:Average training steps per second: 221.61
I0901 12:34:45.983315 140536266098688 replay_runner.py:36] Average training steps per second: 221.61
I0901 12:34:46.279572 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.35
INFO:tensorflow:Starting iteration 29

Steps executed: 218 Episode length: 62 Return: -447.523284777176065
INFO:tensorflow:Average training steps per second: 219.72
I0901 12:34:55.171613 140536266098688 replay_runner.py:36] Average training steps per second: 219.72

Done fixed training!Episode length: 62 Return: -447.523284777176065