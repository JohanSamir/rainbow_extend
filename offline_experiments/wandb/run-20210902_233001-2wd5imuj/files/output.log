I0902 23:30:07.996787 139926926592000 run_experiment.py:549] Creating TrainRunner ...
I0902 23:30:08.008800 139926926592000 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:30:08.009093 139926926592000 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:30:08.009235 139926926592000 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:30:08.009365 139926926592000 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:30:08.009573 139926926592000 dqn_agent.py:275] 	 update_period: 4
I0902 23:30:08.009694 139926926592000 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:30:08.009780 139926926592000 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:30:08.009890 139926926592000 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:30:08.009993 139926926592000 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:30:08.010085 139926926592000 dqn_agent.py:280] 	 optimizer: adam
I0902 23:30:08.010161 139926926592000 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:30:08.010214 139926926592000 dqn_agent.py:283] 	 seed: 1630625408008685
I0902 23:30:08.013068 139926926592000 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:30:08.013292 139926926592000 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:30:08.013478 139926926592000 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:30:08.013674 139926926592000 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:30:08.013822 139926926592000 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:30:08.013920 139926926592000 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:30:08.014012 139926926592000 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:30:08.014112 139926926592000 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:30:08.014261 139926926592000 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0902 23:30:09.912142 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:10.330275 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:10.347135 139926926592000 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:30:10.355820 139926926592000 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:30:10.356031 139926926592000 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:30:10.356121 139926926592000 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:30:10.356193 139926926592000 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:30:10.356279 139926926592000 dqn_agent.py:275] 	 update_period: 4
I0902 23:30:10.356393 139926926592000 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:30:10.356451 139926926592000 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:30:10.356582 139926926592000 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:30:10.356753 139926926592000 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:30:10.356867 139926926592000 dqn_agent.py:280] 	 optimizer: adam
I0902 23:30:10.356945 139926926592000 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:30:10.357046 139926926592000 dqn_agent.py:283] 	 seed: 1630625410355760
I0902 23:30:10.360171 139926926592000 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:30:10.360480 139926926592000 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:30:10.360726 139926926592000 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:30:10.360905 139926926592000 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:30:10.361046 139926926592000 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:30:10.361198 139926926592000 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:30:10.361346 139926926592000 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:30:10.361597 139926926592000 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:30:10.361733 139926926592000 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:30:10.394486 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:10.416715 139926926592000 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:30:10.417060 139926926592000 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 165.41
I0902 23:30:16.462783 139926926592000 replay_runner.py:36] Average training steps per second: 165.41
Steps executed: 223 Episode length: 94 Return: -385.915114785910855
I0902 23:30:17.644999 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -305.63
INFO:tensorflow:Starting iteration 1

Steps executed: 288 Episode length: 115 Return: -267.29719372498695
INFO:tensorflow:Average training steps per second: 223.54
I0902 23:30:26.382615 139926926592000 replay_runner.py:36] Average training steps per second: 223.54
I0902 23:30:26.651034 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.52
INFO:tensorflow:Starting iteration 2

Steps executed: 127 Episode length: 127 Return: -184.07137615243713
INFO:tensorflow:Average training steps per second: 224.06

Steps executed: 307 Episode length: 180 Return: -390.11673204053005
I0902 23:30:35.849543 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.09
INFO:tensorflow:Starting iteration 3
I0902 23:30:40.102994 139926926592000 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 231.71

Steps executed: 1000 Episode length: 1000 Return: -101.56876669321885
I0902 23:30:47.928156 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.57
INFO:tensorflow:Starting iteration 4
I0902 23:30:52.150513 139926926592000 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 236.31

Steps executed: 1000 Episode length: 1000 Return: -338.84970096785446
I0902 23:31:00.276027 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.85
INFO:tensorflow:Starting iteration 5
I0902 23:31:04.381578 139926926592000 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 222.77

Steps executed: 1000 Episode length: 1000 Return: -130.26044342775346
I0902 23:31:11.365795 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.26
INFO:tensorflow:Starting iteration 6
I0902 23:31:15.723903 139926926592000 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 232.61
I0902 23:31:20.023738 139926926592000 replay_runner.py:36] Average training steps per second: 232.61

Steps executed: 1000 Episode length: 1000 Return: -133.49332817487666
INFO:tensorflow:Starting iteration 7
I0902 23:31:26.207020 139926926592000 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 240.26

Steps executed: 1000 Episode length: 1000 Return: -279.64113793018294
I0902 23:31:32.871039 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.64
INFO:tensorflow:Starting iteration 8

Steps executed: 101 Episode length: 101 Return: -45.13888064899211494
INFO:tensorflow:Average training steps per second: 229.26

Steps executed: 1101 Episode length: 1000 Return: -276.96414826471647
I0902 23:31:45.345276 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.05
INFO:tensorflow:Starting iteration 9
I0902 23:31:49.494374 139926926592000 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 227.86

Steps executed: 283 Episode length: 283 Return: -401.5136856619259647
I0902 23:31:54.190787 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -401.51
INFO:tensorflow:Starting iteration 10
I0902 23:31:58.523497 139926926592000 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 217.11
I0902 23:32:03.129886 139926926592000 replay_runner.py:36] Average training steps per second: 217.11

Steps executed: 667 Episode length: 667 Return: -358.9587330180671647
INFO:tensorflow:Starting iteration 11
I0902 23:32:08.433469 139926926592000 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 216.84

Steps executed: 1000 Episode length: 1000 Return: -129.22669484614447
I0902 23:32:16.091426 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.23
INFO:tensorflow:Starting iteration 12
I0902 23:32:20.439184 139926926592000 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 217.02

Steps executed: 837 Episode length: 837 Return: -291.9231869905179347
I0902 23:32:26.896743 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -291.92
INFO:tensorflow:Starting iteration 13

Steps executed: 159 Episode length: 159 Return: -56.20876168302881347
INFO:tensorflow:Average training steps per second: 219.09
I0902 23:32:35.783905 139926926592000 replay_runner.py:36] Average training steps per second: 219.09

Steps executed: 1159 Episode length: 1000 Return: -152.15821863707268
INFO:tensorflow:Starting iteration 14
I0902 23:32:42.489230 139926926592000 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 215.60

Steps executed: 677 Episode length: 677 Return: -362.2679110016790768
I0902 23:32:48.870077 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -362.27
INFO:tensorflow:Starting iteration 15
I0902 23:32:53.241631 139926926592000 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 217.15
I0902 23:32:57.847437 139926926592000 replay_runner.py:36] Average training steps per second: 217.15

Steps executed: 319 Episode length: 145 Return: -97.31949390587727468
INFO:tensorflow:Starting iteration 16

Steps executed: 279 Episode length: 279 Return: -287.3612518719586468
INFO:tensorflow:Average training steps per second: 217.56
I0902 23:33:07.113593 139926926592000 replay_runner.py:36] Average training steps per second: 217.56
I0902 23:33:07.468406 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.36
INFO:tensorflow:Starting iteration 17
I0902 23:33:11.787743 139926926592000 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 223.57

Steps executed: 339 Episode length: 339 Return: -517.7711487726586468
I0902 23:33:16.698701 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -517.77
INFO:tensorflow:Starting iteration 18

Steps executed: 209 Episode length: 209 Return: -441.6900266324824468
INFO:tensorflow:Average training steps per second: 221.13
I0902 23:33:25.521357 139926926592000 replay_runner.py:36] Average training steps per second: 221.13
I0902 23:33:25.720823 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -441.69
INFO:tensorflow:Starting iteration 19

Steps executed: 255 Episode length: 100 Return: -757.7767704295873468
INFO:tensorflow:Average training steps per second: 214.89
I0902 23:33:34.696555 139926926592000 replay_runner.py:36] Average training steps per second: 214.89
I0902 23:33:34.935821 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -619.13
INFO:tensorflow:Starting iteration 20

Steps executed: 364 Episode length: 364 Return: -219.6602713439169768
INFO:tensorflow:Average training steps per second: 227.80
I0902 23:33:43.692295 139926926592000 replay_runner.py:36] Average training steps per second: 227.80
I0902 23:33:44.141129 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -219.66
INFO:tensorflow:Starting iteration 21

Steps executed: 239 Episode length: 239 Return: -290.7585353590839768
INFO:tensorflow:Average training steps per second: 226.73
I0902 23:33:52.809676 139926926592000 replay_runner.py:36] Average training steps per second: 226.73
I0902 23:33:53.077862 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.76
INFO:tensorflow:Starting iteration 22
I0902 23:33:57.414543 139926926592000 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 222.07

Steps executed: 451 Episode length: 451 Return: -445.6579801787644368
I0902 23:34:02.765460 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -445.66
INFO:tensorflow:Starting iteration 23

Steps executed: 421 Episode length: 421 Return: -720.6946143685853368
INFO:tensorflow:Average training steps per second: 226.48
I0902 23:34:11.502346 139926926592000 replay_runner.py:36] Average training steps per second: 226.48
I0902 23:34:12.245699 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -720.69
INFO:tensorflow:Starting iteration 24

Steps executed: 436 Episode length: 436 Return: -585.1548498207906368
INFO:tensorflow:Average training steps per second: 232.95
I0902 23:34:20.821198 139926926592000 replay_runner.py:36] Average training steps per second: 232.95
I0902 23:34:21.693616 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -585.15
INFO:tensorflow:Starting iteration 25
I0902 23:34:25.896118 139926926592000 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 226.27

Steps executed: 217 Episode length: 217 Return: -57.50356056111693468
I0902 23:34:30.566853 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.50
INFO:tensorflow:Starting iteration 26
I0902 23:34:34.804913 139926926592000 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 232.96

Steps executed: 1000 Episode length: 1000 Return: 30.9149142378970168
I0902 23:34:42.146847 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: 30.91
INFO:tensorflow:Starting iteration 27

Steps executed: 338 Episode length: 146 Return: -962.6688566136086368
INFO:tensorflow:Average training steps per second: 222.20
I0902 23:34:50.981798 139926926592000 replay_runner.py:36] Average training steps per second: 222.20
I0902 23:34:51.307548 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -630.04
INFO:tensorflow:Starting iteration 28

Steps executed: 160 Episode length: 160 Return: -304.3598844528015368
INFO:tensorflow:Average training steps per second: 223.12
I0902 23:34:59.979836 139926926592000 replay_runner.py:36] Average training steps per second: 223.12

Steps executed: 481 Episode length: 321 Return: -501.2814647394133368
INFO:tensorflow:Starting iteration 29

Steps executed: 203 Episode length: 203 Return: -217.6705030864867368
INFO:tensorflow:Average training steps per second: 232.16
I0902 23:35:09.192116 139926926592000 replay_runner.py:36] Average training steps per second: 232.16

Done fixed training!Episode length: 203 Return: -217.6705030864867368