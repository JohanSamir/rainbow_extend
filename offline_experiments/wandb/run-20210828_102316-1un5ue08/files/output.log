Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0828 10:23:22.714902 140214119393280 run_experiment.py:549] Creating TrainRunner ...
I0828 10:23:22.725238 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:23:22.725544 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:23:22.725659 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:23:22.725774 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:23:22.725860 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:23:22.725985 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:23:22.726073 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:23:22.726169 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:23:22.726242 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:23:22.726325 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:23:22.726380 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:23:22.726472 140214119393280 dqn_agent.py:283] 	 seed: 1630146202725178
I0828 10:23:22.729659 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:23:22.729917 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:23:22.730220 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:23:22.730347 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:23:22.730431 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:23:22.730504 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:23:22.730610 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:23:22.730727 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:23:22.730932 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:23:22.767901 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:23.150498 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:23.165228 140214119393280 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:23:23.172472 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:23:23.172716 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:23:23.172928 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:23:23.173109 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:23:23.173200 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:23:23.173305 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:23:23.173490 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:23:23.173595 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:23:23.173652 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:23:23.173704 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:23:23.173755 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:23:23.173805 140214119393280 dqn_agent.py:283] 	 seed: 1630146203172428
I0828 10:23:23.176676 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:23:23.176854 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:23:23.177005 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:23:23.177141 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:23:23.177286 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:23:23.177423 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:23:23.177607 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:23:23.177729 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:23:23.177873 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:23:23.509776 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:23.532155 140214119393280 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:23:23.532492 140214119393280 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 166.59
I0828 10:23:29.535427 140214119393280 replay_runner.py:36] Average training steps per second: 166.59
I0828 10:23:30.691897 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.93
Steps executed: 214 Episode length: 59 Return: -101.39726627501128
INFO:tensorflow:Starting iteration 1

Steps executed: 247 Episode length: 67 Return: -564.31591093342218
INFO:tensorflow:Average training steps per second: 224.63
I0828 10:23:39.444903 140214119393280 replay_runner.py:36] Average training steps per second: 224.63
I0828 10:23:39.655523 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -521.82
INFO:tensorflow:Starting iteration 2
I0828 10:23:43.973191 140214119393280 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 225.52
I0828 10:23:48.407642 140214119393280 replay_runner.py:36] Average training steps per second: 225.52

Steps executed: 206 Episode length: 66 Return: -456.96612739462478
INFO:tensorflow:Starting iteration 3

Steps executed: 206 Episode length: 60 Return: -566.96025396175018
INFO:tensorflow:Average training steps per second: 222.59
I0828 10:23:57.442009 140214119393280 replay_runner.py:36] Average training steps per second: 222.59
I0828 10:23:57.619400 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -691.03
INFO:tensorflow:Starting iteration 4
I0828 10:24:01.967791 140214119393280 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 225.69

Steps executed: 417 Episode length: 222 Return: -1607.4172784631746
I0828 10:24:06.854936 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -966.71
INFO:tensorflow:Starting iteration 5

Steps executed: 212 Episode length: 94 Return: -755.075396827060966
INFO:tensorflow:Average training steps per second: 224.69
I0828 10:24:15.636309 140214119393280 replay_runner.py:36] Average training steps per second: 224.69
I0828 10:24:15.833972 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -772.08
INFO:tensorflow:Starting iteration 6

Steps executed: 270 Episode length: 82 Return: -815.490365889107766
INFO:tensorflow:Average training steps per second: 241.21
I0828 10:24:24.298791 140214119393280 replay_runner.py:36] Average training steps per second: 241.21
I0828 10:24:24.510380 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -573.28
INFO:tensorflow:Starting iteration 7
I0828 10:24:28.606529 140214119393280 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 238.84

Steps executed: 380 Episode length: 186 Return: -1456.4828158567473
I0828 10:24:33.145395 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -906.34
INFO:tensorflow:Starting iteration 8

Steps executed: 325 Episode length: 152 Return: -913.28176808187973
INFO:tensorflow:Average training steps per second: 256.65
I0828 10:24:41.167501 140214119393280 replay_runner.py:36] Average training steps per second: 256.65
I0828 10:24:41.422031 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -658.22
INFO:tensorflow:Starting iteration 9

Steps executed: 248 Episode length: 87 Return: -181.971914572099763
INFO:tensorflow:Average training steps per second: 223.81
I0828 10:24:50.063877 140214119393280 replay_runner.py:36] Average training steps per second: 223.81
I0828 10:24:50.212502 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.91
INFO:tensorflow:Starting iteration 10

Steps executed: 250 Episode length: 56 Return: -130.895550348017253
INFO:tensorflow:Average training steps per second: 226.05
I0828 10:24:58.883511 140214119393280 replay_runner.py:36] Average training steps per second: 226.05
I0828 10:24:59.070026 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.13
INFO:tensorflow:Starting iteration 11

Steps executed: 287 Episode length: 97 Return: -462.564148998882353
INFO:tensorflow:Average training steps per second: 226.12
I0828 10:25:07.758764 140214119393280 replay_runner.py:36] Average training steps per second: 226.12
I0828 10:25:08.016254 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -520.54
INFO:tensorflow:Starting iteration 12

Steps executed: 202 Episode length: 71 Return: -547.724491604532853
INFO:tensorflow:Average training steps per second: 226.61
I0828 10:25:16.775636 140214119393280 replay_runner.py:36] Average training steps per second: 226.61
I0828 10:25:16.964140 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -558.64
INFO:tensorflow:Starting iteration 13

Steps executed: 219 Episode length: 72 Return: -170.667517648460583
INFO:tensorflow:Average training steps per second: 223.22
I0828 10:25:25.836807 140214119393280 replay_runner.py:36] Average training steps per second: 223.22
I0828 10:25:25.974235 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.31
INFO:tensorflow:Starting iteration 14


Steps executed: 223 Episode length: 87 Return: 21.12762611526861253
INFO:tensorflow:Average training steps per second: 222.69
I0828 10:25:34.856411 140214119393280 replay_runner.py:36] Average training steps per second: 222.69
I0828 10:25:35.002394 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.32
INFO:tensorflow:Starting iteration 15

Steps executed: 247 Episode length: 247 Return: -2203.2393735410453
INFO:tensorflow:Average training steps per second: 232.98
I0828 10:25:43.477899 140214119393280 replay_runner.py:36] Average training steps per second: 232.98
I0828 10:25:43.785939 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -2203.24
INFO:tensorflow:Starting iteration 16

Steps executed: 217 Episode length: 68 Return: -550.089955257062733
INFO:tensorflow:Average training steps per second: 230.37
I0828 10:25:52.455626 140214119393280 replay_runner.py:36] Average training steps per second: 230.37
I0828 10:25:52.643805 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -599.13
INFO:tensorflow:Starting iteration 17

Steps executed: 237 Episode length: 60 Return: -133.297615416429983
INFO:tensorflow:Average training steps per second: 224.33
I0828 10:26:01.341318 140214119393280 replay_runner.py:36] Average training steps per second: 224.33
I0828 10:26:01.500499 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.20
INFO:tensorflow:Starting iteration 18

Steps executed: 265 Episode length: 96 Return: -596.341923484936783
INFO:tensorflow:Average training steps per second: 226.44
I0828 10:26:10.295443 140214119393280 replay_runner.py:36] Average training steps per second: 226.44
I0828 10:26:10.545194 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -523.62
INFO:tensorflow:Starting iteration 19

Steps executed: 519 Episode length: 382 Return: -4680.7325244362823
INFO:tensorflow:Average training steps per second: 228.71
I0828 10:26:19.316927 140214119393280 replay_runner.py:36] Average training steps per second: 228.71
I0828 10:26:20.088756 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -2696.36
INFO:tensorflow:Starting iteration 20
I0828 10:26:24.477574 140214119393280 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 224.02

Steps executed: 221 Episode length: 100 Return: -649.27832124275473
I0828 10:26:29.155968 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -736.37
INFO:tensorflow:Starting iteration 21

Steps executed: 205 Episode length: 59 Return: -110.289314575873723
INFO:tensorflow:Average training steps per second: 229.37
I0828 10:26:37.905571 140214119393280 replay_runner.py:36] Average training steps per second: 229.37
I0828 10:26:38.044461 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.28
INFO:tensorflow:Starting iteration 22

Steps executed: 52 Episode length: 52 Return: -383.7761173276709723
INFO:tensorflow:Average training steps per second: 232.22
I0828 10:26:46.759882 140214119393280 replay_runner.py:36] Average training steps per second: 232.22

Steps executed: 237 Episode length: 59 Return: -510.087797232292943
INFO:tensorflow:Starting iteration 23

Steps executed: 218 Episode length: 67 Return: -605.046227602943243
INFO:tensorflow:Average training steps per second: 231.86
I0828 10:26:55.656372 140214119393280 replay_runner.py:36] Average training steps per second: 231.86
I0828 10:26:55.847963 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -680.28
INFO:tensorflow:Starting iteration 24

Steps executed: 277 Episode length: 85 Return: -959.855252925098453
INFO:tensorflow:Average training steps per second: 233.39
I0828 10:27:04.492974 140214119393280 replay_runner.py:36] Average training steps per second: 233.39
I0828 10:27:04.745492 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -592.00
INFO:tensorflow:Starting iteration 25

Steps executed: 330 Episode length: 330 Return: -2492.4028860310163
INFO:tensorflow:Average training steps per second: 233.30
I0828 10:27:13.394876 140214119393280 replay_runner.py:36] Average training steps per second: 233.30
I0828 10:27:13.974387 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -2492.40
INFO:tensorflow:Starting iteration 26

Steps executed: 290 Episode length: 185 Return: -1556.1139715420068
INFO:tensorflow:Average training steps per second: 246.30
I0828 10:27:22.457014 140214119393280 replay_runner.py:36] Average training steps per second: 246.30
I0828 10:27:22.735871 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -1136.37
INFO:tensorflow:Starting iteration 27

Steps executed: 50 Episode length: 50 Return: -70.03461047139979068
INFO:tensorflow:Average training steps per second: 253.27

Steps executed: 276 Episode length: 87 Return: -136.169053840395668
I0828 10:27:31.142842 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.00
INFO:tensorflow:Starting iteration 28

Steps executed: 261 Episode length: 261 Return: -2383.2650291416085
INFO:tensorflow:Average training steps per second: 246.27
I0828 10:27:39.566796 140214119393280 replay_runner.py:36] Average training steps per second: 246.27
I0828 10:27:39.882283 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -2383.27
INFO:tensorflow:Starting iteration 29

Steps executed: 237 Episode length: 96 Return: -934.016341699297485
INFO:tensorflow:Average training steps per second: 245.28
I0828 10:27:48.271911 140214119393280 replay_runner.py:36] Average training steps per second: 245.28

Done fixed training!Episode length: 96 Return: -934.016341699297485