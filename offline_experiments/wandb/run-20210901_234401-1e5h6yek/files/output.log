I0901 23:44:07.933806 140149719906304 run_experiment.py:549] Creating TrainRunner ...
I0901 23:44:07.945138 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:44:07.945402 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:44:07.945535 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:44:07.945633 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:44:07.945726 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0901 23:44:07.945815 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:44:07.945927 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:44:07.946018 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:44:07.946107 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:44:07.946221 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0901 23:44:07.946319 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:44:07.946413 140149719906304 dqn_agent.py:283] 	 seed: 1630539847945076
I0901 23:44:07.949419 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:44:07.949613 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:44:07.949760 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:44:07.949880 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:44:07.950029 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:44:07.950182 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:44:07.950300 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:44:07.950500 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:44:07.950636 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:44:09.369825 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0901 23:44:09.741127 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:44:09.755675 140149719906304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:44:09.764998 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:44:09.765225 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:44:09.765323 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:44:09.765406 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:44:09.765493 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0901 23:44:09.765576 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:44:09.765724 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:44:09.765856 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:44:09.765946 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:44:09.766281 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0901 23:44:09.766500 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:44:09.766658 140149719906304 dqn_agent.py:283] 	 seed: 1630539849764944
I0901 23:44:09.769572 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:44:09.769771 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:44:09.769935 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:44:09.770069 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:44:09.770302 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:44:09.770480 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:44:09.770737 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:44:09.771219 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:44:09.771428 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:44:09.807043 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:44:09.830735 140149719906304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:44:09.830990 140149719906304 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 156.67
I0901 23:44:16.214224 140149719906304 replay_runner.py:36] Average training steps per second: 156.67
I0901 23:44:17.449497 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.28
Steps executed: 265 Episode length: 107 Return: -277.79269869091553
INFO:tensorflow:Starting iteration 1
I0901 23:44:21.731305 140149719906304 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 226.62
I0901 23:44:26.144242 140149719906304 replay_runner.py:36] Average training steps per second: 226.62

Steps executed: 267 Episode length: 121 Return: -215.70432550423376
INFO:tensorflow:Starting iteration 2

Steps executed: 221 Episode length: 221 Return: -270.45043218691256
INFO:tensorflow:Average training steps per second: 245.20
I0901 23:44:34.643640 140149719906304 replay_runner.py:36] Average training steps per second: 245.20
I0901 23:44:34.891178 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.45
INFO:tensorflow:Starting iteration 3
I0901 23:44:39.125059 140149719906304 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 244.40

Steps executed: 1000 Episode length: 1000 Return: -151.2899360789474
I0901 23:44:46.664426 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.29
INFO:tensorflow:Starting iteration 4
I0901 23:44:50.901243 140149719906304 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 223.93

Steps executed: 1000 Episode length: 1000 Return: -37.06187129603795
I0901 23:45:00.048466 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.06
INFO:tensorflow:Starting iteration 5
I0901 23:45:04.405456 140149719906304 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 224.98

Steps executed: 1000 Episode length: 1000 Return: -117.06580344538486
I0901 23:45:12.715113 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.07
INFO:tensorflow:Starting iteration 6

Steps executed: 90 Episode length: 90 Return: -46.8600082721338138486
INFO:tensorflow:Average training steps per second: 217.68

Steps executed: 724 Episode length: 634 Return: -164.6123563195881486
I0901 23:45:22.965237 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.74
INFO:tensorflow:Starting iteration 7
I0901 23:45:27.350329 140149719906304 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 222.03

Steps executed: 1000 Episode length: 1000 Return: -107.45347930066174
I0901 23:45:34.214552 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.45
INFO:tensorflow:Starting iteration 8

Steps executed: 491 Episode length: 491 Return: -205.0165150296009574
INFO:tensorflow:Average training steps per second: 218.37
I0901 23:45:43.177781 140149719906304 replay_runner.py:36] Average training steps per second: 218.37
I0901 23:45:43.983704 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.02
INFO:tensorflow:Starting iteration 9

Steps executed: 308 Episode length: 308 Return: -397.9442420785461574
INFO:tensorflow:Average training steps per second: 220.57
I0901 23:45:53.076335 140149719906304 replay_runner.py:36] Average training steps per second: 220.57
I0901 23:45:53.479543 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -397.94
INFO:tensorflow:Starting iteration 10

Steps executed: 616 Episode length: 452 Return: -330.4137400687647574
INFO:tensorflow:Average training steps per second: 222.90
I0901 23:46:02.325686 140149719906304 replay_runner.py:36] Average training steps per second: 222.90
I0901 23:46:03.365361 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.98
INFO:tensorflow:Starting iteration 11
I0901 23:46:07.358495 140149719906304 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 221.42

Steps executed: 1000 Episode length: 1000 Return: -132.36160052407654
I0901 23:46:14.279653 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.36
INFO:tensorflow:Starting iteration 12
I0901 23:46:18.516771 140149719906304 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 221.19

Steps executed: 1000 Episode length: 1000 Return: -218.31936218695114
I0901 23:46:27.417396 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.32
INFO:tensorflow:Starting iteration 13
I0901 23:46:31.792864 140149719906304 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 226.27

Steps executed: 516 Episode length: 358 Return: -233.6875221730917614
I0901 23:46:36.788357 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -251.44
INFO:tensorflow:Starting iteration 14

Steps executed: 262 Episode length: 262 Return: -276.5660392217671414
INFO:tensorflow:Average training steps per second: 222.00
I0901 23:46:45.649614 140149719906304 replay_runner.py:36] Average training steps per second: 222.00
I0901 23:46:45.947280 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.57
INFO:tensorflow:Starting iteration 15

Steps executed: 295 Episode length: 123 Return: -143.4660623775668414
INFO:tensorflow:Average training steps per second: 225.48
I0901 23:46:54.731111 140149719906304 replay_runner.py:36] Average training steps per second: 225.48
I0901 23:46:55.004081 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.44
INFO:tensorflow:Starting iteration 16

Steps executed: 78 Episode length: 78 Return: -25.8963753771554228414
INFO:tensorflow:Average training steps per second: 219.11
I0901 23:47:03.817836 140149719906304 replay_runner.py:36] Average training steps per second: 219.11

Steps executed: 455 Episode length: 377 Return: -287.8286911979945414
INFO:tensorflow:Starting iteration 17

Steps executed: 241 Episode length: 151 Return: -237.1280086666991514
INFO:tensorflow:Average training steps per second: 222.08
I0901 23:47:13.270061 140149719906304 replay_runner.py:36] Average training steps per second: 222.08
I0901 23:47:13.471992 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.22
INFO:tensorflow:Starting iteration 18

Steps executed: 321 Episode length: 140 Return: -168.8270355984344614
INFO:tensorflow:Average training steps per second: 224.32
I0901 23:47:22.158616 140149719906304 replay_runner.py:36] Average training steps per second: 224.32
I0901 23:47:22.426647 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.68
INFO:tensorflow:Starting iteration 19

Steps executed: 286 Episode length: 178 Return: -326.8511121183235614
INFO:tensorflow:Average training steps per second: 227.57
I0901 23:47:31.002305 140149719906304 replay_runner.py:36] Average training steps per second: 227.57
I0901 23:47:31.270427 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -612.67
INFO:tensorflow:Starting iteration 20

Steps executed: 233 Episode length: 233 Return: -326.8153663401981614
INFO:tensorflow:Average training steps per second: 240.22
I0901 23:47:39.645978 140149719906304 replay_runner.py:36] Average training steps per second: 240.22
I0901 23:47:39.910717 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.82
INFO:tensorflow:Starting iteration 21
I0901 23:47:44.110722 140149719906304 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 238.95
I0901 23:47:48.296011 140149719906304 replay_runner.py:36] Average training steps per second: 238.95

Steps executed: 264 Episode length: 124 Return: -122.3208029671566214
INFO:tensorflow:Starting iteration 22

Steps executed: 207 Episode length: 98 Return: -135.99468859286265714
INFO:tensorflow:Average training steps per second: 227.50
I0901 23:47:57.328861 140149719906304 replay_runner.py:36] Average training steps per second: 227.50
I0901 23:47:57.492510 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.74
INFO:tensorflow:Starting iteration 23
I0901 23:48:01.797276 140149719906304 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 218.73
I0901 23:48:06.369561 140149719906304 replay_runner.py:36] Average training steps per second: 218.73

Steps executed: 294 Episode length: 99 Return: -333.42098267096163714
INFO:tensorflow:Starting iteration 24
I0901 23:48:11.000331 140149719906304 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 230.43
I0901 23:48:15.340441 140149719906304 replay_runner.py:36] Average training steps per second: 230.43

Steps executed: 452 Episode length: 452 Return: -359.0278486051164714
INFO:tensorflow:Starting iteration 25

Steps executed: 264 Episode length: 139 Return: -107.4887895465147714
INFO:tensorflow:Average training steps per second: 227.13
I0901 23:48:24.980969 140149719906304 replay_runner.py:36] Average training steps per second: 227.13
I0901 23:48:25.196281 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.18
INFO:tensorflow:Starting iteration 26

Steps executed: 215 Episode length: 136 Return: -457.8425443628524414
INFO:tensorflow:Average training steps per second: 223.27
I0901 23:48:34.117391 140149719906304 replay_runner.py:36] Average training steps per second: 223.27
I0901 23:48:34.314741 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -354.49
INFO:tensorflow:Starting iteration 27

Steps executed: 276 Episode length: 129 Return: -212.2233311563522614
INFO:tensorflow:Average training steps per second: 226.48
I0901 23:48:42.946590 140149719906304 replay_runner.py:36] Average training steps per second: 226.48
I0901 23:48:43.203922 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -181.73
INFO:tensorflow:Starting iteration 28

Steps executed: 242 Episode length: 142 Return: -443.8420595892089314
INFO:tensorflow:Average training steps per second: 224.12
I0901 23:48:51.800471 140149719906304 replay_runner.py:36] Average training steps per second: 224.12
I0901 23:48:52.031968 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.83
INFO:tensorflow:Starting iteration 29

Steps executed: 268 Episode length: 132 Return: -514.6573633489425314
INFO:tensorflow:Average training steps per second: 223.23
I0901 23:49:00.904535 140149719906304 replay_runner.py:36] Average training steps per second: 223.23

Done fixed training!Episode length: 132 Return: -514.6573633489425314