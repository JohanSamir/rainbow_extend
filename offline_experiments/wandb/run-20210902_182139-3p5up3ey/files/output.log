Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0902 18:21:44.833511 140284730537984 run_experiment.py:549] Creating TrainRunner ...
I0902 18:21:44.841112 140284730537984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:21:44.841247 140284730537984 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:21:44.841358 140284730537984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:21:44.841433 140284730537984 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:21:44.841504 140284730537984 dqn_agent.py:275] 	 update_period: 4
I0902 18:21:44.841579 140284730537984 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:21:44.841655 140284730537984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:21:44.841756 140284730537984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:21:44.841876 140284730537984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:21:44.841959 140284730537984 dqn_agent.py:280] 	 optimizer: adam
I0902 18:21:44.842026 140284730537984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:21:44.842127 140284730537984 dqn_agent.py:283] 	 seed: 1630606904841079
I0902 18:21:44.844216 140284730537984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:21:44.844354 140284730537984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:21:44.844489 140284730537984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:21:44.844558 140284730537984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:21:44.844615 140284730537984 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:21:44.844715 140284730537984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:21:44.844807 140284730537984 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:21:44.844892 140284730537984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:21:44.844960 140284730537984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:21:44.872991 140284730537984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:45.121485 140284730537984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:45.132716 140284730537984 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:21:45.138505 140284730537984 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:21:45.138628 140284730537984 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:21:45.138694 140284730537984 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:21:45.138750 140284730537984 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:21:45.138811 140284730537984 dqn_agent.py:275] 	 update_period: 4
I0902 18:21:45.138878 140284730537984 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:21:45.138973 140284730537984 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:21:45.139058 140284730537984 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:21:45.139107 140284730537984 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:21:45.139183 140284730537984 dqn_agent.py:280] 	 optimizer: adam
I0902 18:21:45.139247 140284730537984 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:21:45.139303 140284730537984 dqn_agent.py:283] 	 seed: 1630606905138477
I0902 18:21:45.141215 140284730537984 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:21:45.141419 140284730537984 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:21:45.141579 140284730537984 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:21:45.141688 140284730537984 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:21:45.141766 140284730537984 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:21:45.141840 140284730537984 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:21:45.141992 140284730537984 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:21:45.142127 140284730537984 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:21:45.142207 140284730537984 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:21:45.163669 140284730537984 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:45.177948 140284730537984 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:21:45.178100 140284730537984 replay_runner.py:41] Starting iteration 0
Steps executed: 238 Episode length: 90 Return: -385.036262831331676
INFO:tensorflow:Average training steps per second: 253.64
I0902 18:21:49.120895 140284730537984 replay_runner.py:36] Average training steps per second: 253.64
I0902 18:21:49.920278 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.87
INFO:tensorflow:Starting iteration 1

Steps executed: 234 Episode length: 117 Return: -211.68298244707438
INFO:tensorflow:Average training steps per second: 362.17
I0902 18:21:56.032557 140284730537984 replay_runner.py:36] Average training steps per second: 362.17
I0902 18:21:56.159229 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.63
INFO:tensorflow:Starting iteration 2

Steps executed: 272 Episode length: 107 Return: -25.523656291756453
INFO:tensorflow:Average training steps per second: 350.77
I0902 18:22:02.507837 140284730537984 replay_runner.py:36] Average training steps per second: 350.77
I0902 18:22:02.665659 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -62.21
INFO:tensorflow:Starting iteration 3

Steps executed: 1000 Episode length: 1000 Return: -146.30665609620098
INFO:tensorflow:Average training steps per second: 338.87
I0902 18:22:08.996978 140284730537984 replay_runner.py:36] Average training steps per second: 338.87
I0902 18:22:10.392033 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.31
INFO:tensorflow:Starting iteration 4
I0902 18:22:13.701657 140284730537984 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 336.42
I0902 18:22:16.674464 140284730537984 replay_runner.py:36] Average training steps per second: 336.42

Steps executed: 1000 Episode length: 1000 Return: -118.89325685109851
INFO:tensorflow:Starting iteration 5
I0902 18:22:21.430074 140284730537984 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 343.20

Steps executed: 1000 Episode length: 1000 Return: -87.336144405733451
I0902 18:22:27.142181 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.34
INFO:tensorflow:Starting iteration 6
I0902 18:22:30.434132 140284730537984 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 340.06

Steps executed: 1000 Episode length: 1000 Return: -359.51551348461161
I0902 18:22:34.787641 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.52
INFO:tensorflow:Starting iteration 7

Steps executed: 1000 Episode length: 1000 Return: -320.06173934924751
INFO:tensorflow:Average training steps per second: 337.25
I0902 18:22:40.983864 140284730537984 replay_runner.py:36] Average training steps per second: 337.25
I0902 18:22:42.454190 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -320.06
INFO:tensorflow:Starting iteration 8
I0902 18:22:45.729934 140284730537984 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 334.97

Steps executed: 1000 Episode length: 1000 Return: -237.80017999006531
I0902 18:22:50.235379 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.80
INFO:tensorflow:Starting iteration 9
I0902 18:22:53.593755 140284730537984 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 355.20

Steps executed: 691 Episode length: 691 Return: -355.9271823949320631
I0902 18:22:57.306484 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -355.93
INFO:tensorflow:Starting iteration 10
I0902 18:23:00.708645 140284730537984 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 345.68

Steps executed: 796 Episode length: 796 Return: -471.9657516813917631
I0902 18:23:04.988740 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -471.97
INFO:tensorflow:Starting iteration 11
I0902 18:23:08.345308 140284730537984 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 344.93
I0902 18:23:11.244755 140284730537984 replay_runner.py:36] Average training steps per second: 344.93

Steps executed: 1000 Episode length: 1000 Return: -259.48822763217341
INFO:tensorflow:Starting iteration 12
I0902 18:23:16.258522 140284730537984 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 338.84

Steps executed: 1000 Episode length: 1000 Return: -132.58313687037668
I0902 18:23:21.110886 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.58
INFO:tensorflow:Starting iteration 13
I0902 18:23:24.552483 140284730537984 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 328.47

Steps executed: 802 Episode length: 802 Return: -149.7533954713371768
I0902 18:23:29.114693 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.75
INFO:tensorflow:Starting iteration 14

Steps executed: 350 Episode length: 350 Return: -210.1799613818555768
INFO:tensorflow:Average training steps per second: 320.57
I0902 18:23:35.572217 140284730537984 replay_runner.py:36] Average training steps per second: 320.57
I0902 18:23:35.953195 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.18
INFO:tensorflow:Starting iteration 15

Steps executed: 331 Episode length: 167 Return: 12.830615494585388768
INFO:tensorflow:Average training steps per second: 331.07
I0902 18:23:42.227609 140284730537984 replay_runner.py:36] Average training steps per second: 331.07
I0902 18:23:42.444095 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -12.87
INFO:tensorflow:Starting iteration 16
I0902 18:23:45.723498 140284730537984 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 335.64

Steps executed: 1000 Episode length: 1000 Return: -69.407522678693858
I0902 18:23:51.055288 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.41
INFO:tensorflow:Starting iteration 17

Steps executed: 458 Episode length: 458 Return: -324.7239534407542658
INFO:tensorflow:Average training steps per second: 324.56
I0902 18:23:57.330092 140284730537984 replay_runner.py:36] Average training steps per second: 324.56
I0902 18:23:57.836408 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -324.72
INFO:tensorflow:Starting iteration 18

Steps executed: 207 Episode length: 207 Return: 36.199154378377585658
INFO:tensorflow:Average training steps per second: 326.55
I0902 18:24:04.156049 140284730537984 replay_runner.py:36] Average training steps per second: 326.55
I0902 18:24:04.300991 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: 36.20
INFO:tensorflow:Starting iteration 19

Steps executed: 237 Episode length: 112 Return: 30.955696101157997558
INFO:tensorflow:Average training steps per second: 345.79
I0902 18:24:10.550397 140284730537984 replay_runner.py:36] Average training steps per second: 345.79
I0902 18:24:10.679947 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -63.69
INFO:tensorflow:Starting iteration 20

Steps executed: 428 Episode length: 428 Return: -283.2760226993001458
INFO:tensorflow:Average training steps per second: 329.50
I0902 18:24:17.073562 140284730537984 replay_runner.py:36] Average training steps per second: 329.50
I0902 18:24:17.645899 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.28
INFO:tensorflow:Starting iteration 21

Steps executed: 484 Episode length: 294 Return: -350.8964006699247358
INFO:tensorflow:Average training steps per second: 321.21
I0902 18:24:24.072016 140284730537984 replay_runner.py:36] Average training steps per second: 321.21
I0902 18:24:24.422563 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.91
INFO:tensorflow:Starting iteration 22

Steps executed: 132 Episode length: 132 Return: -48.79113456725398458
INFO:tensorflow:Average training steps per second: 315.60
I0902 18:24:30.729598 140284730537984 replay_runner.py:36] Average training steps per second: 315.60

Steps executed: 280 Episode length: 148 Return: -128.9118731901983258
INFO:tensorflow:Starting iteration 23
I0902 18:24:34.038941 140284730537984 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 326.21

Steps executed: 897 Episode length: 897 Return: -153.3404473464057258
I0902 18:24:39.357044 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.34
INFO:tensorflow:Starting iteration 24
I0902 18:24:42.560159 140284730537984 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 315.80

Steps executed: 1000 Episode length: 1000 Return: -85.497891055124488
I0902 18:24:48.439981 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.50
INFO:tensorflow:Starting iteration 25
I0902 18:24:51.737732 140284730537984 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 318.60
I0902 18:24:54.876833 140284730537984 replay_runner.py:36] Average training steps per second: 318.60

Steps executed: 224 Episode length: 224 Return: -561.8440318697502488
INFO:tensorflow:Starting iteration 26
I0902 18:24:58.074240 140284730537984 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 323.04

Steps executed: 1000 Episode length: 1000 Return: -66.070772539778868
I0902 18:25:03.419716 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -66.07
INFO:tensorflow:Starting iteration 27
I0902 18:25:06.686952 140284730537984 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 334.08

Steps executed: 1000 Episode length: 1000 Return: -135.45999005289348
I0902 18:25:11.905203 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.46
INFO:tensorflow:Starting iteration 28

Steps executed: 282 Episode length: 111 Return: -100.0966579285363248
INFO:tensorflow:Average training steps per second: 399.21
I0902 18:25:17.758752 140284730537984 replay_runner.py:36] Average training steps per second: 399.21
I0902 18:25:17.900859 140284730537984 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.77
INFO:tensorflow:Starting iteration 29
I0902 18:25:21.009797 140284730537984 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 396.61

Steps executed: 1000 Episode length: 1000 Return: -59.422184902626448

Done fixed training! Episode length: 1000 Return: -59.422184902626448