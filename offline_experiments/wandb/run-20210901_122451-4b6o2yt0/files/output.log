Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0901 12:24:58.203691 140298343233536 run_experiment.py:549] Creating TrainRunner ...
I0901 12:24:58.214988 140298343233536 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:24:58.215288 140298343233536 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:24:58.215619 140298343233536 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:24:58.215806 140298343233536 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:24:58.216049 140298343233536 dqn_agent.py:275] 	 update_period: 4
I0901 12:24:58.216166 140298343233536 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:24:58.216355 140298343233536 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:24:58.216480 140298343233536 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:24:58.216612 140298343233536 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:24:58.216705 140298343233536 dqn_agent.py:280] 	 optimizer: adam
I0901 12:24:58.216798 140298343233536 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:24:58.216996 140298343233536 dqn_agent.py:283] 	 seed: 1630499098214912
I0901 12:24:58.219756 140298343233536 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:24:58.219945 140298343233536 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:24:58.220049 140298343233536 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:24:58.220166 140298343233536 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:24:58.220253 140298343233536 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:24:58.220332 140298343233536 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:24:58.220419 140298343233536 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:24:58.220505 140298343233536 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:24:58.220736 140298343233536 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:24:58.446447 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:24:58.853087 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:24:58.867645 140298343233536 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:24:58.877583 140298343233536 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:24:58.877859 140298343233536 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:24:58.878031 140298343233536 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:24:58.878216 140298343233536 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:24:58.878339 140298343233536 dqn_agent.py:275] 	 update_period: 4
I0901 12:24:58.878466 140298343233536 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:24:58.878582 140298343233536 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:24:58.878699 140298343233536 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:24:58.878801 140298343233536 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:24:58.878916 140298343233536 dqn_agent.py:280] 	 optimizer: adam
I0901 12:24:58.878998 140298343233536 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:24:58.879070 140298343233536 dqn_agent.py:283] 	 seed: 1630499098877528
I0901 12:24:58.881552 140298343233536 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:24:58.881719 140298343233536 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:24:58.881941 140298343233536 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:24:58.882089 140298343233536 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:24:58.882200 140298343233536 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:24:58.882292 140298343233536 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:24:58.882620 140298343233536 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:24:58.882763 140298343233536 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:24:58.882899 140298343233536 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:24:58.912505 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:24:58.932225 140298343233536 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:24:58.932421 140298343233536 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 157.81
I0901 12:25:05.269411 140298343233536 replay_runner.py:36] Average training steps per second: 157.81
Steps executed: 233 Episode length: 81 Return: -592.5770668413991
I0901 12:25:06.477537 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -668.47
INFO:tensorflow:Starting iteration 1

Steps executed: 290 Episode length: 148 Return: -102.93798323279172
INFO:tensorflow:Average training steps per second: 224.29
I0901 12:25:15.261592 140298343233536 replay_runner.py:36] Average training steps per second: 224.29
I0901 12:25:15.551704 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.25
INFO:tensorflow:Starting iteration 2

Steps executed: 252 Episode length: 89 Return: -751.050564570189172
INFO:tensorflow:Average training steps per second: 227.60
I0901 12:25:24.126047 140298343233536 replay_runner.py:36] Average training steps per second: 227.60
I0901 12:25:24.416793 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -707.71
INFO:tensorflow:Starting iteration 3

Steps executed: 230 Episode length: 143 Return: -557.34761081592552
INFO:tensorflow:Average training steps per second: 217.23
I0901 12:25:33.253770 140298343233536 replay_runner.py:36] Average training steps per second: 217.23
I0901 12:25:33.512670 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -644.96
INFO:tensorflow:Starting iteration 4

Steps executed: 313 Episode length: 158 Return: 0.0019112900046707182
INFO:tensorflow:Average training steps per second: 215.19
I0901 12:25:42.431657 140298343233536 replay_runner.py:36] Average training steps per second: 215.19
I0901 12:25:42.717586 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.53
INFO:tensorflow:Starting iteration 5
I0901 12:25:47.089290 140298343233536 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 214.37

Steps executed: 230 Episode length: 230 Return: -71.71086723695232182
I0901 12:25:52.037325 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.71
INFO:tensorflow:Starting iteration 6

Steps executed: 332 Episode length: 210 Return: -515.1533216913333682
INFO:tensorflow:Average training steps per second: 212.88
I0901 12:26:01.246995 140298343233536 replay_runner.py:36] Average training steps per second: 212.88
I0901 12:26:01.626703 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -481.60
INFO:tensorflow:Starting iteration 7
I0901 12:26:05.930098 140298343233536 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 244.05

Steps executed: 220 Episode length: 115 Return: -289.6222012195447982
I0901 12:26:10.240596 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.33
INFO:tensorflow:Starting iteration 8

Steps executed: 234 Episode length: 116 Return: -74.69848882059455982
INFO:tensorflow:Average training steps per second: 215.30
I0901 12:26:19.376022 140298343233536 replay_runner.py:36] Average training steps per second: 215.30
I0901 12:26:19.598588 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.20
INFO:tensorflow:Starting iteration 9

Steps executed: 262 Episode length: 155 Return: -162.4640944264721982
INFO:tensorflow:Average training steps per second: 213.03
I0901 12:26:28.434416 140298343233536 replay_runner.py:36] Average training steps per second: 213.03
I0901 12:26:28.664375 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.67
INFO:tensorflow:Starting iteration 10

Steps executed: 301 Episode length: 132 Return: -109.2877489387414982
INFO:tensorflow:Average training steps per second: 211.73
I0901 12:26:37.710474 140298343233536 replay_runner.py:36] Average training steps per second: 211.73
I0901 12:26:38.001219 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.90
INFO:tensorflow:Starting iteration 11

Steps executed: 282 Episode length: 126 Return: -100.4986777402907982
INFO:tensorflow:Average training steps per second: 215.73
I0901 12:26:46.557298 140298343233536 replay_runner.py:36] Average training steps per second: 215.73
I0901 12:26:46.816366 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.95
INFO:tensorflow:Starting iteration 12

Steps executed: 283 Episode length: 170 Return: -248.0437622176427582
INFO:tensorflow:Average training steps per second: 199.52
I0901 12:26:56.604310 140298343233536 replay_runner.py:36] Average training steps per second: 199.52
I0901 12:26:56.868511 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.51
INFO:tensorflow:Starting iteration 13

Steps executed: 225 Episode length: 225 Return: -82.98732252890067582
INFO:tensorflow:Average training steps per second: 213.43
I0901 12:27:05.959604 140298343233536 replay_runner.py:36] Average training steps per second: 213.43
I0901 12:27:06.213417 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.99
INFO:tensorflow:Starting iteration 14

Steps executed: 289 Episode length: 289 Return: 217.87084404646887582
INFO:tensorflow:Average training steps per second: 215.00
I0901 12:27:15.283251 140298343233536 replay_runner.py:36] Average training steps per second: 215.00
I0901 12:27:15.715013 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: 217.87
INFO:tensorflow:Starting iteration 15

Steps executed: 319 Episode length: 147 Return: -81.25767855676168582
INFO:tensorflow:Average training steps per second: 212.83
I0901 12:27:24.905563 140298343233536 replay_runner.py:36] Average training steps per second: 212.83
I0901 12:27:25.208552 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.00
INFO:tensorflow:Starting iteration 16

Steps executed: 189 Episode length: 189 Return: -195.1101617907221582
INFO:tensorflow:Average training steps per second: 220.06

Steps executed: 419 Episode length: 230 Return: -131.6381393537191782
I0901 12:27:34.639301 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.37
INFO:tensorflow:Starting iteration 17

Steps executed: 473 Episode length: 277 Return: -105.2548281666705282
INFO:tensorflow:Average training steps per second: 211.03
I0901 12:27:43.887966 140298343233536 replay_runner.py:36] Average training steps per second: 211.03
I0901 12:27:44.446098 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.91
INFO:tensorflow:Starting iteration 18

Steps executed: 202 Episode length: 202 Return: -69.67920960741253282
INFO:tensorflow:Average training steps per second: 227.48
I0901 12:27:53.239231 140298343233536 replay_runner.py:36] Average training steps per second: 227.48
I0901 12:27:53.428600 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.68
INFO:tensorflow:Starting iteration 19
I0901 12:27:57.782623 140298343233536 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 224.39
I0901 12:28:02.239496 140298343233536 replay_runner.py:36] Average training steps per second: 224.39

Steps executed: 259 Episode length: 78 Return: -294.38652893430924282
INFO:tensorflow:Starting iteration 20

Steps executed: 266 Episode length: 85 Return: -107.78421323300223282
INFO:tensorflow:Average training steps per second: 223.13
I0901 12:28:11.323224 140298343233536 replay_runner.py:36] Average training steps per second: 223.13
I0901 12:28:11.523508 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.37
INFO:tensorflow:Starting iteration 21

Steps executed: 146 Episode length: 69 Return: -350.52900416802623282
INFO:tensorflow:Average training steps per second: 230.00
I0901 12:28:20.027023 140298343233536 replay_runner.py:36] Average training steps per second: 230.00

Steps executed: 262 Episode length: 116 Return: -89.51666910795929282
INFO:tensorflow:Starting iteration 22
I0901 12:28:24.483783 140298343233536 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 233.87

Steps executed: 272 Episode length: 87 Return: -216.69500184299898282
I0901 12:28:29.030175 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.36
INFO:tensorflow:Starting iteration 23

Steps executed: 351 Episode length: 199 Return: -152.1592103792514882
INFO:tensorflow:Average training steps per second: 224.06
I0901 12:28:37.588694 140298343233536 replay_runner.py:36] Average training steps per second: 224.06
I0901 12:28:37.898310 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.81
INFO:tensorflow:Starting iteration 24

Steps executed: 221 Episode length: 88 Return: -139.16448349306103882
INFO:tensorflow:Average training steps per second: 221.96
I0901 12:28:46.764536 140298343233536 replay_runner.py:36] Average training steps per second: 221.96
I0901 12:28:46.945712 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.04
INFO:tensorflow:Starting iteration 25

Steps executed: 269 Episode length: 141 Return: -274.4434069414222882
INFO:tensorflow:Average training steps per second: 217.40
I0901 12:28:55.959829 140298343233536 replay_runner.py:36] Average training steps per second: 217.40
I0901 12:28:56.208298 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -252.46
INFO:tensorflow:Starting iteration 26

Steps executed: 298 Episode length: 228 Return: -202.8507183423682282
INFO:tensorflow:Average training steps per second: 219.01
I0901 12:29:05.159431 140298343233536 replay_runner.py:36] Average training steps per second: 219.01
I0901 12:29:05.440245 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.51
INFO:tensorflow:Starting iteration 27

Steps executed: 238 Episode length: 93 Return: -107.68433706313907282
INFO:tensorflow:Average training steps per second: 223.37
I0901 12:29:14.300155 140298343233536 replay_runner.py:36] Average training steps per second: 223.37
I0901 12:29:14.497602 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.71
INFO:tensorflow:Starting iteration 28

Steps executed: 400 Episode length: 294 Return: 201.96820487588083682
INFO:tensorflow:Average training steps per second: 216.57
I0901 12:29:23.420966 140298343233536 replay_runner.py:36] Average training steps per second: 216.57
I0901 12:29:23.919892 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -5.59
INFO:tensorflow:Starting iteration 29

Steps executed: 272 Episode length: 186 Return: -151.5518358565543682
INFO:tensorflow:Average training steps per second: 216.55
I0901 12:29:32.876090 140298343233536 replay_runner.py:36] Average training steps per second: 216.55

Done fixed training!Episode length: 186 Return: -151.5518358565543682