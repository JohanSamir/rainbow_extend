I0902 00:23:20.128295 140252174653440 run_experiment.py:549] Creating TrainRunner ...
I0902 00:23:20.135901 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:23:20.136022 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:23:20.136078 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:23:20.136149 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:23:20.136242 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0902 00:23:20.136301 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:23:20.136353 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:23:20.136407 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:23:20.136491 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:23:20.136575 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0902 00:23:20.136641 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:23:20.136720 140252174653440 dqn_agent.py:283] 	 seed: 1630542200135867
I0902 00:23:20.138602 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:23:20.138723 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:23:20.138816 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:23:20.138921 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:23:20.139157 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:23:20.139252 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:23:20.139348 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:23:20.139464 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:23:20.139551 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:23:20.166071 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:23:20.416698 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:23:20.428011 140252174653440 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:23:20.435276 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:23:20.435433 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:23:20.435514 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:23:20.435616 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:23:20.435682 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0902 00:23:20.435809 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:23:20.435971 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:23:20.436093 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:23:20.436170 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:23:20.436321 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0902 00:23:20.436436 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:23:20.436532 140252174653440 dqn_agent.py:283] 	 seed: 1630542200435237
I0902 00:23:20.438891 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:23:20.439002 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:23:20.439096 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:23:20.439159 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:23:20.439224 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:23:20.439280 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:23:20.439332 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:23:20.439383 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:23:20.439433 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:23:20.461340 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:23:20.479853 140252174653440 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:23:20.480013 140252174653440 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 254.56
I0902 00:23:24.408480 140252174653440 replay_runner.py:36] Average training steps per second: 254.56
I0902 00:23:25.214146 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -501.32
Steps executed: 238 Episode length: 135 Return: -412.74539193160444
INFO:tensorflow:Starting iteration 1

Steps executed: 304 Episode length: 148 Return: -280.19609118135934
INFO:tensorflow:Average training steps per second: 356.51
I0902 00:23:31.192313 140252174653440 replay_runner.py:36] Average training steps per second: 356.51
I0902 00:23:31.375266 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -382.95
INFO:tensorflow:Starting iteration 2

Steps executed: 226 Episode length: 102 Return: -386.32081010946036
INFO:tensorflow:Average training steps per second: 346.22
I0902 00:23:37.604612 140252174653440 replay_runner.py:36] Average training steps per second: 346.22
I0902 00:23:37.719685 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.18
INFO:tensorflow:Starting iteration 3

Steps executed: 432 Episode length: 432 Return: -131.88841511039476
INFO:tensorflow:Average training steps per second: 338.09
I0902 00:23:43.881237 140252174653440 replay_runner.py:36] Average training steps per second: 338.09
I0902 00:23:44.456394 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.89
INFO:tensorflow:Starting iteration 4
I0902 00:23:47.710536 140252174653440 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 328.17

Steps executed: 1000 Episode length: 1000 Return: -71.30140668682638
I0902 00:23:54.098027 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.30
INFO:tensorflow:Starting iteration 5
I0902 00:23:57.326507 140252174653440 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 321.93

Steps executed: 1000 Episode length: 1000 Return: -71.29373481087234
I0902 00:24:03.544611 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.29
INFO:tensorflow:Starting iteration 6
I0902 00:24:06.980255 140252174653440 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 362.53

Steps executed: 1000 Episode length: 1000 Return: -177.17793359378032
I0902 00:24:11.740876 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.18
INFO:tensorflow:Starting iteration 7
I0902 00:24:15.158540 140252174653440 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 355.31

Steps executed: 1000 Episode length: 1000 Return: -75.394352969656642
I0902 00:24:20.276319 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.39
INFO:tensorflow:Starting iteration 8
I0902 00:24:23.664018 140252174653440 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 336.32

Steps executed: 1000 Episode length: 1000 Return: -84.226043135010642
I0902 00:24:28.720777 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.23
INFO:tensorflow:Starting iteration 9
I0902 00:24:32.117278 140252174653440 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 350.32

Steps executed: 1000 Episode length: 1000 Return: -105.44759131168792
I0902 00:24:37.681278 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.45
INFO:tensorflow:Starting iteration 10
I0902 00:24:40.926613 140252174653440 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 346.20

Steps executed: 594 Episode length: 594 Return: -205.7643231802018492
I0902 00:24:44.446829 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.76
INFO:tensorflow:Starting iteration 11

Steps executed: 275 Episode length: 275 Return: -784.9666099649661492
INFO:tensorflow:Average training steps per second: 344.21
I0902 00:24:50.710260 140252174653440 replay_runner.py:36] Average training steps per second: 344.21
I0902 00:24:50.925012 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -784.97
INFO:tensorflow:Starting iteration 12
I0902 00:24:54.389957 140252174653440 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 355.56

Steps executed: 1000 Episode length: 1000 Return: -8.1606528509079812
I0902 00:24:59.178809 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -8.16
INFO:tensorflow:Starting iteration 13
I0902 00:25:02.607496 140252174653440 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 360.36

Steps executed: 1000 Episode length: 1000 Return: -87.742738131408052
I0902 00:25:06.647311 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.74
INFO:tensorflow:Starting iteration 14
I0902 00:25:10.095053 140252174653440 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 338.17

Steps executed: 1000 Episode length: 1000 Return: -150.63096926775773
I0902 00:25:14.948709 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -150.63
INFO:tensorflow:Starting iteration 15

Steps executed: 208 Episode length: 208 Return: -109.7929265293582573
INFO:tensorflow:Average training steps per second: 341.30
I0902 00:25:21.317152 140252174653440 replay_runner.py:36] Average training steps per second: 341.30
I0902 00:25:21.451079 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.79
INFO:tensorflow:Starting iteration 16

Steps executed: 329 Episode length: 134 Return: -221.7861711963554573
INFO:tensorflow:Average training steps per second: 346.02
I0902 00:25:27.738892 140252174653440 replay_runner.py:36] Average training steps per second: 346.02
I0902 00:25:27.946354 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.92
INFO:tensorflow:Starting iteration 17
I0902 00:25:31.353452 140252174653440 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 331.57
I0902 00:25:34.369660 140252174653440 replay_runner.py:36] Average training steps per second: 331.57

Steps executed: 263 Episode length: 202 Return: -484.6356237093333573
INFO:tensorflow:Starting iteration 18

Steps executed: 302 Episode length: 302 Return: -57.92149098396993573
INFO:tensorflow:Average training steps per second: 324.96
I0902 00:25:40.801079 140252174653440 replay_runner.py:36] Average training steps per second: 324.96
I0902 00:25:41.063614 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.92
INFO:tensorflow:Starting iteration 19

Steps executed: 251 Episode length: 119 Return: -175.1485944833048673
INFO:tensorflow:Average training steps per second: 311.21
I0902 00:25:47.496909 140252174653440 replay_runner.py:36] Average training steps per second: 311.21
I0902 00:25:47.651624 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.58
INFO:tensorflow:Starting iteration 20

Steps executed: 214 Episode length: 116 Return: -196.4164155258689673
INFO:tensorflow:Average training steps per second: 327.42
I0902 00:25:53.925327 140252174653440 replay_runner.py:36] Average training steps per second: 327.42
I0902 00:25:54.079678 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.74
INFO:tensorflow:Starting iteration 21

Steps executed: 317 Episode length: 317 Return: -43.65488375328142673
INFO:tensorflow:Average training steps per second: 342.66
I0902 00:26:00.340463 140252174653440 replay_runner.py:36] Average training steps per second: 342.66
I0902 00:26:00.645891 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -43.65
INFO:tensorflow:Starting iteration 22

Steps executed: 214 Episode length: 108 Return: -220.2577269802722573
INFO:tensorflow:Average training steps per second: 333.85
I0902 00:26:07.286379 140252174653440 replay_runner.py:36] Average training steps per second: 333.85
I0902 00:26:07.425326 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.85
INFO:tensorflow:Starting iteration 23

Steps executed: 172 Episode length: 172 Return: -448.6197239850075773
INFO:tensorflow:Average training steps per second: 334.83
I0902 00:26:13.798961 140252174653440 replay_runner.py:36] Average training steps per second: 334.83

Steps executed: 476 Episode length: 304 Return: -256.3485810600674373
INFO:tensorflow:Starting iteration 24
I0902 00:26:17.570428 140252174653440 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 328.98

Steps executed: 323 Episode length: 225 Return: -249.9699533103226773
I0902 00:26:20.843757 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.43
INFO:tensorflow:Starting iteration 25
I0902 00:26:24.203080 140252174653440 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 337.00

Steps executed: 1000 Episode length: 1000 Return: 116.837405864822593
I0902 00:26:28.829213 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: 116.84
INFO:tensorflow:Starting iteration 26

Steps executed: 59 Episode length: 59 Return: -104.016657017178222593
INFO:tensorflow:Average training steps per second: 325.94

Steps executed: 956 Episode length: 897 Return: -93.81538094280235593
I0902 00:26:37.693250 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.92
INFO:tensorflow:Starting iteration 27

Steps executed: 176 Episode length: 176 Return: -481.4646950620179593
INFO:tensorflow:Average training steps per second: 325.48
I0902 00:26:44.135560 140252174653440 replay_runner.py:36] Average training steps per second: 325.48

Steps executed: 317 Episode length: 141 Return: -1081.994519995412593
INFO:tensorflow:Starting iteration 28

Steps executed: 290 Episode length: 121 Return: -683.1702864262097493
INFO:tensorflow:Average training steps per second: 331.63
I0902 00:26:50.707777 140252174653440 replay_runner.py:36] Average training steps per second: 331.63
I0902 00:26:50.866820 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -321.37
INFO:tensorflow:Starting iteration 29

Steps executed: 271 Episode length: 271 Return: -461.5323511592817493
INFO:tensorflow:Average training steps per second: 347.34
I0902 00:26:56.963868 140252174653440 replay_runner.py:36] Average training steps per second: 347.34

Done fixed training!Episode length: 271 Return: -461.5323511592817493