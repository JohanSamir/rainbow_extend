Loaded trained dqn in acrobot
Training fixed agent 7, please be patient, may be a while...
I0902 23:49:39.213902 140527680751616 run_experiment.py:549] Creating TrainRunner ...
I0902 23:49:39.224261 140527680751616 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:49:39.224534 140527680751616 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:49:39.224641 140527680751616 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:49:39.224755 140527680751616 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:49:39.224866 140527680751616 dqn_agent.py:275] 	 update_period: 4
I0902 23:49:39.224946 140527680751616 dqn_agent.py:276] 	 target_update_period: 100
I0902 23:49:39.224994 140527680751616 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:49:39.225047 140527680751616 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:49:39.225094 140527680751616 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:49:39.225140 140527680751616 dqn_agent.py:280] 	 optimizer: adam
I0902 23:49:39.225187 140527680751616 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:49:39.225236 140527680751616 dqn_agent.py:283] 	 seed: 1630626579224094
I0902 23:49:39.227543 140527680751616 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:49:39.227698 140527680751616 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0902 23:49:39.227782 140527680751616 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:49:39.227839 140527680751616 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:49:39.227914 140527680751616 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:49:39.227963 140527680751616 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:49:39.228010 140527680751616 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:49:39.228056 140527680751616 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:49:39.228102 140527680751616 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:49:39.261858 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:49:39.670897 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:49:39.684618 140527680751616 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:49:39.694073 140527680751616 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:49:39.694270 140527680751616 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:49:39.694375 140527680751616 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:49:39.694526 140527680751616 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:49:39.694622 140527680751616 dqn_agent.py:275] 	 update_period: 4
I0902 23:49:39.695219 140527680751616 dqn_agent.py:276] 	 target_update_period: 100
I0902 23:49:39.695340 140527680751616 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:49:39.695418 140527680751616 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:49:39.695489 140527680751616 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:49:39.695564 140527680751616 dqn_agent.py:280] 	 optimizer: adam
I0902 23:49:39.695635 140527680751616 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:49:39.695704 140527680751616 dqn_agent.py:283] 	 seed: 1630626579694022
I0902 23:49:39.722215 140527680751616 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:49:39.722480 140527680751616 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0902 23:49:39.722582 140527680751616 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:49:39.722671 140527680751616 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:49:39.722752 140527680751616 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:49:39.722879 140527680751616 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:49:39.722963 140527680751616 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:49:39.723038 140527680751616 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:49:39.723114 140527680751616 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:49:39.754132 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:49:39.778349 140527680751616 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:49:39.778548 140527680751616 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 143.54
I0902 23:49:46.745601 140527680751616 replay_runner.py:36] Average training steps per second: 143.54
Steps executed: 500 Episode length: 500 Return: -500.0
I0902 23:49:48.609501 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1

Steps executed: 287 Episode length: 138 Return: -137.0
INFO:tensorflow:Average training steps per second: 198.29
I0902 23:49:53.944948 140527680751616 replay_runner.py:36] Average training steps per second: 198.29
I0902 23:49:54.192357 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.50
INFO:tensorflow:Starting iteration 2

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 198.31
I0902 23:49:59.477807 140527680751616 replay_runner.py:36] Average training steps per second: 198.31
I0902 23:49:59.887602 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 3

Steps executed: 324 Episode length: 169 Return: -168.0
INFO:tensorflow:Average training steps per second: 196.42
I0902 23:50:05.206634 140527680751616 replay_runner.py:36] Average training steps per second: 196.42
I0902 23:50:05.473725 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.00
INFO:tensorflow:Starting iteration 4

Steps executed: 234 Episode length: 132 Return: -131.0
INFO:tensorflow:Average training steps per second: 208.64
I0902 23:50:10.498793 140527680751616 replay_runner.py:36] Average training steps per second: 208.64
I0902 23:50:10.709616 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.00
INFO:tensorflow:Starting iteration 5

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 195.03
I0902 23:50:16.086476 140527680751616 replay_runner.py:36] Average training steps per second: 195.03
I0902 23:50:16.476463 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6
I0902 23:50:16.713543 140527680751616 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 198.86
I0902 23:50:21.742482 140527680751616 replay_runner.py:36] Average training steps per second: 198.86
I0902 23:50:22.179199 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7

Steps executed: 236 Episode length: 236 Return: -235.0
INFO:tensorflow:Average training steps per second: 199.72
I0902 23:50:27.429088 140527680751616 replay_runner.py:36] Average training steps per second: 199.72
I0902 23:50:27.628187 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.00
INFO:tensorflow:Starting iteration 8
I0902 23:50:27.870535 140527680751616 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 194.04

Steps executed: 500 Episode length: 500 Return: -500.0
I0902 23:50:33.423826 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 9
I0902 23:50:33.659996 140527680751616 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 199.03
I0902 23:50:38.684717 140527680751616 replay_runner.py:36] Average training steps per second: 199.03
I0902 23:50:39.153044 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 10

Steps executed: 292 Episode length: 194 Return: -193.0
INFO:tensorflow:Average training steps per second: 202.75
I0902 23:50:44.339112 140527680751616 replay_runner.py:36] Average training steps per second: 202.75
I0902 23:50:44.571966 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.00
INFO:tensorflow:Starting iteration 11

Steps executed: 209 Episode length: 92 Return: -91.0.0
INFO:tensorflow:Average training steps per second: 193.40
I0902 23:50:49.983539 140527680751616 replay_runner.py:36] Average training steps per second: 193.40
I0902 23:50:50.152556 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.50
INFO:tensorflow:Starting iteration 12

Steps executed: 269 Episode length: 76 Return: -75.0.0
INFO:tensorflow:Average training steps per second: 201.34
I0902 23:50:55.367829 140527680751616 replay_runner.py:36] Average training steps per second: 201.34
I0902 23:50:55.585862 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.67
INFO:tensorflow:Starting iteration 13

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 197.06
I0902 23:51:00.899948 140527680751616 replay_runner.py:36] Average training steps per second: 197.06
I0902 23:51:01.312835 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 14

Steps executed: 329 Episode length: 206 Return: -205.0
INFO:tensorflow:Average training steps per second: 197.61
I0902 23:51:06.623596 140527680751616 replay_runner.py:36] Average training steps per second: 197.61
I0902 23:51:06.907933 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.50
INFO:tensorflow:Starting iteration 15

Steps executed: 255 Episode length: 118 Return: -117.0
INFO:tensorflow:Average training steps per second: 193.44
I0902 23:51:12.318833 140527680751616 replay_runner.py:36] Average training steps per second: 193.44
I0902 23:51:12.529878 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.00
INFO:tensorflow:Starting iteration 16

Steps executed: 247 Episode length: 130 Return: -129.0
INFO:tensorflow:Average training steps per second: 198.96
I0902 23:51:17.794032 140527680751616 replay_runner.py:36] Average training steps per second: 198.96
I0902 23:51:17.992927 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.50
INFO:tensorflow:Starting iteration 17
I0902 23:51:18.226195 140527680751616 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 198.14
I0902 23:51:23.273746 140527680751616 replay_runner.py:36] Average training steps per second: 198.14

Steps executed: 227 Episode length: 70 Return: -69.0.0
INFO:tensorflow:Starting iteration 18

Steps executed: 229 Episode length: 63 Return: -62.0.0
INFO:tensorflow:Average training steps per second: 196.59
I0902 23:51:28.799252 140527680751616 replay_runner.py:36] Average training steps per second: 196.59
I0902 23:51:28.996842 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.33
INFO:tensorflow:Starting iteration 19

Steps executed: 259 Episode length: 71 Return: -70.0.0
INFO:tensorflow:Average training steps per second: 198.05
I0902 23:51:34.291734 140527680751616 replay_runner.py:36] Average training steps per second: 198.05
I0902 23:51:34.516197 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.33
INFO:tensorflow:Starting iteration 20

Steps executed: 263 Episode length: 81 Return: -80.0.0
INFO:tensorflow:Average training steps per second: 199.23
I0902 23:51:39.782063 140527680751616 replay_runner.py:36] Average training steps per second: 199.23
I0902 23:51:40.000447 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.67
INFO:tensorflow:Starting iteration 21
I0902 23:51:40.242003 140527680751616 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 198.45

Steps executed: 225 Episode length: 106 Return: -105.0
I0902 23:51:45.490220 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.50
INFO:tensorflow:Starting iteration 22

Steps executed: 247 Episode length: 76 Return: -75.0.0
INFO:tensorflow:Average training steps per second: 196.86
I0902 23:51:50.813453 140527680751616 replay_runner.py:36] Average training steps per second: 196.86
I0902 23:51:51.019385 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.33
INFO:tensorflow:Starting iteration 23

Steps executed: 200 Episode length: 93 Return: -92.0.0
INFO:tensorflow:Average training steps per second: 201.85
I0902 23:51:56.214756 140527680751616 replay_runner.py:36] Average training steps per second: 201.85
I0902 23:51:56.446162 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.00
INFO:tensorflow:Starting iteration 24

Steps executed: 265 Episode length: 88 Return: -87.0.0
INFO:tensorflow:Average training steps per second: 204.44
I0902 23:52:01.579161 140527680751616 replay_runner.py:36] Average training steps per second: 204.44
I0902 23:52:01.797040 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.33
INFO:tensorflow:Starting iteration 25

Steps executed: 230 Episode length: 140 Return: -139.0
INFO:tensorflow:Average training steps per second: 202.92
I0902 23:52:06.970212 140527680751616 replay_runner.py:36] Average training steps per second: 202.92
I0902 23:52:07.147714 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.00
INFO:tensorflow:Starting iteration 26

Steps executed: 249 Episode length: 89 Return: -88.0.0
INFO:tensorflow:Average training steps per second: 200.40
I0902 23:52:12.370894 140527680751616 replay_runner.py:36] Average training steps per second: 200.40
I0902 23:52:12.572812 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.00
INFO:tensorflow:Starting iteration 27

Steps executed: 274 Episode length: 102 Return: -101.0
INFO:tensorflow:Average training steps per second: 195.30
I0902 23:52:17.940885 140527680751616 replay_runner.py:36] Average training steps per second: 195.30
I0902 23:52:18.178002 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.33
INFO:tensorflow:Starting iteration 28

Steps executed: 214 Episode length: 63 Return: -62.0.0
INFO:tensorflow:Average training steps per second: 203.51
I0902 23:52:23.333616 140527680751616 replay_runner.py:36] Average training steps per second: 203.51
I0902 23:52:23.508962 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.33
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 74 Return: -73.0.0
INFO:tensorflow:Average training steps per second: 190.75
I0902 23:52:28.996962 140527680751616 replay_runner.py:36] Average training steps per second: 190.75
I0902 23:52:29.188523 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.00