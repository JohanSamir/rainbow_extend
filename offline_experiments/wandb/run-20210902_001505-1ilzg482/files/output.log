I0902 00:15:11.879422 140413705484288 run_experiment.py:549] Creating TrainRunner ...
I0902 00:15:11.889607 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:15:11.889958 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:15:11.890100 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:15:11.890205 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:15:11.890285 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0902 00:15:11.890389 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:15:11.890483 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:15:11.890588 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:15:11.890800 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:15:11.891072 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0902 00:15:11.891286 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:15:11.891755 140413705484288 dqn_agent.py:283] 	 seed: 1630541711889538
I0902 00:15:11.895015 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:15:11.895222 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:15:11.895355 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:15:11.895424 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:15:11.895577 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:15:11.895806 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:15:11.895912 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:15:11.896091 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:15:11.896190 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:15:11.931908 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:12.482510 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:12.504306 140413705484288 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:15:12.525477 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:15:12.525764 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:15:12.525902 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:15:12.525990 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:15:12.526092 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0902 00:15:12.526170 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:15:12.526223 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:15:12.526275 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:15:12.526327 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:15:12.526378 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0902 00:15:12.526433 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:15:12.526485 140413705484288 dqn_agent.py:283] 	 seed: 1630541712525403
I0902 00:15:12.530928 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:15:12.531226 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:15:12.531428 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:15:12.531611 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:15:12.531708 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:15:12.531783 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:15:12.531863 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:15:12.531932 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:15:12.532191 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:15:12.566819 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:12.591096 140413705484288 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:15:12.592079 140413705484288 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 169.72
I0902 00:15:18.484622 140413705484288 replay_runner.py:36] Average training steps per second: 169.72
Steps executed: 233 Episode length: 95 Return: -264.70407660853425
I0902 00:15:19.718569 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.99
INFO:tensorflow:Starting iteration 1

Steps executed: 263 Episode length: 144 Return: -492.52548792832204
INFO:tensorflow:Average training steps per second: 227.18
I0902 00:15:28.377807 140413705484288 replay_runner.py:36] Average training steps per second: 227.18
I0902 00:15:28.607638 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -416.55
INFO:tensorflow:Starting iteration 2

Steps executed: 158 Episode length: 158 Return: -300.99951183193593
INFO:tensorflow:Average training steps per second: 226.58

Steps executed: 321 Episode length: 163 Return: -315.82011247740314
I0902 00:15:37.646805 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.41
INFO:tensorflow:Starting iteration 3

Steps executed: 392 Episode length: 252 Return: -549.47998353091374
INFO:tensorflow:Average training steps per second: 227.45
I0902 00:15:46.261729 140413705484288 replay_runner.py:36] Average training steps per second: 227.45
I0902 00:15:46.696580 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -305.01
INFO:tensorflow:Starting iteration 4
I0902 00:15:50.983090 140413705484288 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 231.47

Steps executed: 495 Episode length: 495 Return: -335.33197674263647
I0902 00:15:56.079180 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -335.33
INFO:tensorflow:Starting iteration 5
I0902 00:16:00.385524 140413705484288 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 235.64

Steps executed: 729 Episode length: 729 Return: -290.56829872912437
I0902 00:16:06.163470 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.57
INFO:tensorflow:Starting iteration 6
I0902 00:16:10.620270 140413705484288 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 225.31

Steps executed: 536 Episode length: 536 Return: -298.19736227221337
I0902 00:16:16.107441 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -298.20
INFO:tensorflow:Starting iteration 7
I0902 00:16:20.480738 140413705484288 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 229.70

Steps executed: 852 Episode length: 852 Return: -234.23644940055274
I0902 00:16:26.938783 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.24
INFO:tensorflow:Starting iteration 8
I0902 00:16:31.267982 140413705484288 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 240.56

Steps executed: 839 Episode length: 839 Return: -364.58042557837854
I0902 00:16:38.407851 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.58
INFO:tensorflow:Starting iteration 9

Steps executed: 656 Episode length: 656 Return: -192.15234765666025
INFO:tensorflow:Average training steps per second: 247.24
I0902 00:16:46.718922 140413705484288 replay_runner.py:36] Average training steps per second: 247.24
I0902 00:16:47.771497 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.15
INFO:tensorflow:Starting iteration 10
I0902 00:16:52.062312 140413705484288 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 252.48

Steps executed: 1000 Episode length: 1000 Return: -94.23636864242998
I0902 00:16:59.305265 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.24
INFO:tensorflow:Starting iteration 11
I0902 00:17:03.433422 140413705484288 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 249.39

Steps executed: 1000 Episode length: 1000 Return: -125.15062556847205
I0902 00:17:11.030248 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.15
INFO:tensorflow:Starting iteration 12
I0902 00:17:15.104470 140413705484288 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 251.97

Steps executed: 1000 Episode length: 1000 Return: -33.415786076460885
I0902 00:17:21.828392 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -33.42
INFO:tensorflow:Starting iteration 13

Steps executed: 219 Episode length: 219 Return: -34.93864035998797885
INFO:tensorflow:Average training steps per second: 251.75
I0902 00:17:29.854665 140413705484288 replay_runner.py:36] Average training steps per second: 251.75
I0902 00:17:30.074372 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -34.94
INFO:tensorflow:Starting iteration 14
I0902 00:17:34.125402 140413705484288 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 260.00
I0902 00:17:37.971923 140413705484288 replay_runner.py:36] Average training steps per second: 260.00

Steps executed: 312 Episode length: 312 Return: -159.7165309345312885
INFO:tensorflow:Starting iteration 15
I0902 00:17:42.314203 140413705484288 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 253.06

Steps executed: 350 Episode length: 216 Return: 2.0384503008284014885
I0902 00:17:46.601380 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -299.61
INFO:tensorflow:Starting iteration 16

Steps executed: 228 Episode length: 228 Return: -181.9661818046475385
INFO:tensorflow:Average training steps per second: 276.35
I0902 00:17:54.144501 140413705484288 replay_runner.py:36] Average training steps per second: 276.35
I0902 00:17:54.351166 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -181.97
INFO:tensorflow:Starting iteration 17

Steps executed: 315 Episode length: 159 Return: -107.3771743958835785
INFO:tensorflow:Average training steps per second: 303.74
I0902 00:18:01.380456 140413705484288 replay_runner.py:36] Average training steps per second: 303.74
I0902 00:18:01.581954 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.45
INFO:tensorflow:Starting iteration 18

Steps executed: 235 Episode length: 235 Return: -330.4108342734357485
INFO:tensorflow:Average training steps per second: 304.28
I0902 00:18:08.428941 140413705484288 replay_runner.py:36] Average training steps per second: 304.28
I0902 00:18:08.621803 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -330.41
INFO:tensorflow:Starting iteration 19
I0902 00:18:12.171696 140413705484288 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 318.20
I0902 00:18:15.314900 140413705484288 replay_runner.py:36] Average training steps per second: 318.20

Steps executed: 506 Episode length: 506 Return: -44.98540295304441485
INFO:tensorflow:Starting iteration 20

Steps executed: 258 Episode length: 80 Return: -156.62745094327878385
INFO:tensorflow:Average training steps per second: 322.90
I0902 00:18:22.554301 140413705484288 replay_runner.py:36] Average training steps per second: 322.90
I0902 00:18:22.682308 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.43
INFO:tensorflow:Starting iteration 21

Steps executed: 315 Episode length: 134 Return: -249.5371960387638885
INFO:tensorflow:Average training steps per second: 293.72
I0902 00:18:29.440409 140413705484288 replay_runner.py:36] Average training steps per second: 293.72
I0902 00:18:29.609643 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.80
INFO:tensorflow:Starting iteration 22
I0902 00:18:32.953756 140413705484288 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 313.85

Steps executed: 226 Episode length: 226 Return: -416.3972697802838885
I0902 00:18:36.307940 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -416.40
INFO:tensorflow:Starting iteration 23

Steps executed: 249 Episode length: 93 Return: -338.32419861031812385
INFO:tensorflow:Average training steps per second: 319.54
I0902 00:18:42.828811 140413705484288 replay_runner.py:36] Average training steps per second: 319.54
I0902 00:18:42.951118 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.83
INFO:tensorflow:Starting iteration 24

Steps executed: 308 Episode length: 138 Return: -397.8479609084881385
INFO:tensorflow:Average training steps per second: 313.86
I0902 00:18:49.267317 140413705484288 replay_runner.py:36] Average training steps per second: 313.86
I0902 00:18:49.421056 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.53
INFO:tensorflow:Starting iteration 25

Steps executed: 236 Episode length: 53 Return: -99.159968527940422385
INFO:tensorflow:Average training steps per second: 307.49
I0902 00:18:55.781600 140413705484288 replay_runner.py:36] Average training steps per second: 307.49
I0902 00:18:55.878407 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.75
INFO:tensorflow:Starting iteration 26
I0902 00:18:59.046326 140413705484288 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 312.35
I0902 00:19:02.248241 140413705484288 replay_runner.py:36] Average training steps per second: 312.35

Steps executed: 244 Episode length: 109 Return: -131.8549812936543985
INFO:tensorflow:Starting iteration 27

Steps executed: 322 Episode length: 147 Return: -337.5630992991491485
INFO:tensorflow:Average training steps per second: 315.63
I0902 00:19:08.658277 140413705484288 replay_runner.py:36] Average training steps per second: 315.63
I0902 00:19:08.849350 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -322.18
INFO:tensorflow:Starting iteration 28

Steps executed: 281 Episode length: 151 Return: -320.8242142798848485
INFO:tensorflow:Average training steps per second: 324.68
I0902 00:19:15.036379 140413705484288 replay_runner.py:36] Average training steps per second: 324.68
I0902 00:19:15.208228 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -383.93
INFO:tensorflow:Starting iteration 29

Steps executed: 231 Episode length: 113 Return: -163.4848609359000385
INFO:tensorflow:Average training steps per second: 334.24
I0902 00:19:21.287898 140413705484288 replay_runner.py:36] Average training steps per second: 334.24

Done fixed training!Episode length: 113 Return: -163.4848609359000385