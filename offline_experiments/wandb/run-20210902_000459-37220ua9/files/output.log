Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0902 00:05:06.250553 140183943698432 run_experiment.py:549] Creating TrainRunner ...
I0902 00:05:06.261703 140183943698432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:05:06.261911 140183943698432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:05:06.261988 140183943698432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:05:06.262064 140183943698432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:05:06.262169 140183943698432 dqn_agent.py:275] 	 update_period: 4
I0902 00:05:06.262273 140183943698432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:05:06.262334 140183943698432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:05:06.262459 140183943698432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:05:06.262550 140183943698432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:05:06.262718 140183943698432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:05:06.262818 140183943698432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:05:06.262919 140183943698432 dqn_agent.py:283] 	 seed: 1630541106261647
I0902 00:05:06.266200 140183943698432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:05:06.266417 140183943698432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:05:06.266609 140183943698432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:05:06.266775 140183943698432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:05:06.266897 140183943698432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:05:06.267032 140183943698432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:05:06.267147 140183943698432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:05:06.267243 140183943698432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:05:06.267347 140183943698432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:05:06.305170 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:06.659414 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:06.673926 140183943698432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:05:06.684173 140183943698432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:05:06.684416 140183943698432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:05:06.684549 140183943698432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:05:06.684639 140183943698432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:05:06.684717 140183943698432 dqn_agent.py:275] 	 update_period: 4
I0902 00:05:06.684794 140183943698432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:05:06.684867 140183943698432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:05:06.684967 140183943698432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:05:06.685023 140183943698432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:05:06.685088 140183943698432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:05:06.685167 140183943698432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:05:06.685233 140183943698432 dqn_agent.py:283] 	 seed: 1630541106684095
I0902 00:05:06.686856 140183943698432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:05:06.687009 140183943698432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:05:06.687102 140183943698432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:05:06.687212 140183943698432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:05:06.687312 140183943698432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:05:06.687408 140183943698432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:05:06.687478 140183943698432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:05:06.687587 140183943698432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:05:06.687678 140183943698432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:05:06.715711 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:05:06.741134 140183943698432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:05:06.751902 140183943698432 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 163.88
I0902 00:05:12.859482 140183943698432 replay_runner.py:36] Average training steps per second: 163.88
Steps executed: 281 Episode length: 134 Return: -898.19406320947812
I0902 00:05:14.220084 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -972.12
INFO:tensorflow:Starting iteration 1

Steps executed: 256 Episode length: 72 Return: -492.849569108947982
INFO:tensorflow:Average training steps per second: 224.13
I0902 00:05:23.133007 140183943698432 replay_runner.py:36] Average training steps per second: 224.13
I0902 00:05:23.342868 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -461.35
INFO:tensorflow:Starting iteration 2

Steps executed: 233 Episode length: 136 Return: -477.33949413796364
INFO:tensorflow:Average training steps per second: 229.07
I0902 00:05:32.126426 140183943698432 replay_runner.py:36] Average training steps per second: 229.07
I0902 00:05:32.348392 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -465.28
INFO:tensorflow:Starting iteration 3

Steps executed: 213 Episode length: 213 Return: -267.30763566117194
INFO:tensorflow:Average training steps per second: 225.45
I0902 00:05:40.997421 140183943698432 replay_runner.py:36] Average training steps per second: 225.45
I0902 00:05:41.203058 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -267.31
INFO:tensorflow:Starting iteration 4
I0902 00:05:45.553198 140183943698432 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 244.59
I0902 00:05:49.642078 140183943698432 replay_runner.py:36] Average training steps per second: 244.59

Steps executed: 335 Episode length: 335 Return: -245.27308034451653
INFO:tensorflow:Starting iteration 5
I0902 00:05:54.338169 140183943698432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 228.29

Steps executed: 725 Episode length: 725 Return: -407.76080404214253
I0902 00:06:00.300000 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -407.76
INFO:tensorflow:Starting iteration 6

Steps executed: 389 Episode length: 203 Return: -162.62379675725446
INFO:tensorflow:Average training steps per second: 231.53
I0902 00:06:08.899363 140183943698432 replay_runner.py:36] Average training steps per second: 231.53
I0902 00:06:09.338923 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.17
INFO:tensorflow:Starting iteration 7
I0902 00:06:13.651487 140183943698432 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 223.22

Steps executed: 211 Episode length: 148 Return: -173.15918278848193
I0902 00:06:18.315010 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.02
INFO:tensorflow:Starting iteration 8

Steps executed: 250 Episode length: 250 Return: -184.99532711019168
INFO:tensorflow:Average training steps per second: 221.19
I0902 00:06:27.181586 140183943698432 replay_runner.py:36] Average training steps per second: 221.19
I0902 00:06:27.489418 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.00
INFO:tensorflow:Starting iteration 9

Steps executed: 637 Episode length: 637 Return: -425.03798991633338
INFO:tensorflow:Average training steps per second: 214.94
I0902 00:06:36.443199 140183943698432 replay_runner.py:36] Average training steps per second: 214.94
I0902 00:06:38.075722 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -425.04
INFO:tensorflow:Starting iteration 10
I0902 00:06:42.322518 140183943698432 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 219.86

Steps executed: 832 Episode length: 832 Return: -283.56244479047528
I0902 00:06:48.821018 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.56
INFO:tensorflow:Starting iteration 11
I0902 00:06:53.147820 140183943698432 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 221.39

Steps executed: 477 Episode length: 477 Return: -243.11720391219393
I0902 00:06:58.523044 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.12
INFO:tensorflow:Starting iteration 12

Steps executed: 230 Episode length: 230 Return: -131.44115909216583
INFO:tensorflow:Average training steps per second: 220.59
I0902 00:07:07.483952 140183943698432 replay_runner.py:36] Average training steps per second: 220.59
I0902 00:07:07.788054 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.44
INFO:tensorflow:Starting iteration 13
I0902 00:07:12.191546 140183943698432 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 220.80

Steps executed: 1000 Episode length: 1000 Return: -103.13426000376084
I0902 00:07:19.723157 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.13
INFO:tensorflow:Starting iteration 14
I0902 00:07:24.121239 140183943698432 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 223.57

Steps executed: 258 Episode length: 133 Return: -493.1556186020676584
I0902 00:07:28.858494 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -656.24
INFO:tensorflow:Starting iteration 15

Steps executed: 337 Episode length: 151 Return: -453.6440311046409384
INFO:tensorflow:Average training steps per second: 217.98
I0902 00:07:37.820278 140183943698432 replay_runner.py:36] Average training steps per second: 217.98
I0902 00:07:38.139163 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.32
INFO:tensorflow:Starting iteration 16

Steps executed: 203 Episode length: 88 Return: -112.73468380117146384
INFO:tensorflow:Average training steps per second: 224.99
I0902 00:07:46.865317 140183943698432 replay_runner.py:36] Average training steps per second: 224.99
I0902 00:07:47.025639 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.59
INFO:tensorflow:Starting iteration 17

Steps executed: 269 Episode length: 269 Return: -212.9721044322347384
INFO:tensorflow:Average training steps per second: 226.86
I0902 00:07:55.727993 140183943698432 replay_runner.py:36] Average training steps per second: 226.86
I0902 00:07:56.096046 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.97
INFO:tensorflow:Starting iteration 18

Steps executed: 230 Episode length: 148 Return: -173.8787862469095384
INFO:tensorflow:Average training steps per second: 227.21
I0902 00:08:04.713057 140183943698432 replay_runner.py:36] Average training steps per second: 227.21
I0902 00:08:04.908019 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.45
INFO:tensorflow:Starting iteration 19

Steps executed: 236 Episode length: 110 Return: -880.2092596795362384
INFO:tensorflow:Average training steps per second: 235.44
I0902 00:08:13.541331 140183943698432 replay_runner.py:36] Average training steps per second: 235.44
I0902 00:08:13.760132 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -665.71
INFO:tensorflow:Starting iteration 20

Steps executed: 214 Episode length: 54 Return: -94.222871029389946384
INFO:tensorflow:Average training steps per second: 222.14
I0902 00:08:22.662881 140183943698432 replay_runner.py:36] Average training steps per second: 222.14
I0902 00:08:22.826033 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.25
INFO:tensorflow:Starting iteration 21

Steps executed: 256 Episode length: 195 Return: -127.9021872647189284
INFO:tensorflow:Average training steps per second: 221.06
I0902 00:08:31.783694 140183943698432 replay_runner.py:36] Average training steps per second: 221.06
I0902 00:08:32.047849 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.21
INFO:tensorflow:Starting iteration 22

Steps executed: 248 Episode length: 64 Return: -160.96586478673544684
INFO:tensorflow:Average training steps per second: 227.75
I0902 00:08:40.875102 140183943698432 replay_runner.py:36] Average training steps per second: 227.75
I0902 00:08:41.072726 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.73
INFO:tensorflow:Starting iteration 23

Steps executed: 218 Episode length: 52 Return: -147.27035444234863684
INFO:tensorflow:Average training steps per second: 234.65
I0902 00:08:49.735660 140183943698432 replay_runner.py:36] Average training steps per second: 234.65
I0902 00:08:49.901884 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -240.71
INFO:tensorflow:Starting iteration 24
I0902 00:08:54.288158 140183943698432 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 237.32

Steps executed: 239 Episode length: 239 Return: -92.45672164179702684
I0902 00:08:58.730655 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.46
INFO:tensorflow:Starting iteration 25

Steps executed: 210 Episode length: 210 Return: -137.2744884515242384
INFO:tensorflow:Average training steps per second: 227.77
I0902 00:09:07.488749 140183943698432 replay_runner.py:36] Average training steps per second: 227.77
I0902 00:09:07.729983 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.27
INFO:tensorflow:Starting iteration 26
I0902 00:09:12.055791 140183943698432 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 228.48
I0902 00:09:16.432938 140183943698432 replay_runner.py:36] Average training steps per second: 228.48

Steps executed: 217 Episode length: 217 Return: -309.0127129183669384
INFO:tensorflow:Starting iteration 27

Steps executed: 235 Episode length: 66 Return: -511.64900240814194384
INFO:tensorflow:Average training steps per second: 223.67
I0902 00:09:25.524299 140183943698432 replay_runner.py:36] Average training steps per second: 223.67
I0902 00:09:25.737736 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -536.59
INFO:tensorflow:Starting iteration 28
I0902 00:09:30.357239 140183943698432 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 223.20

Steps executed: 237 Episode length: 83 Return: -425.01392638482764784
I0902 00:09:35.048458 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.31
INFO:tensorflow:Starting iteration 29

Steps executed: 311 Episode length: 120 Return: -232.3084454496135484
INFO:tensorflow:Average training steps per second: 226.20
I0902 00:09:43.847275 140183943698432 replay_runner.py:36] Average training steps per second: 226.20

Done fixed training!Episode length: 120 Return: -232.3084454496135484