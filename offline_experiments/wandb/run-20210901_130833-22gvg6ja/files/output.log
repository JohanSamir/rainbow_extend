Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0901 13:08:38.845475 139683016574976 run_experiment.py:549] Creating TrainRunner ...
I0901 13:08:38.852991 139683016574976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:08:38.853144 139683016574976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:08:38.853234 139683016574976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:08:38.853297 139683016574976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:08:38.853351 139683016574976 dqn_agent.py:275] 	 update_period: 4
I0901 13:08:38.853432 139683016574976 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:08:38.853518 139683016574976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:08:38.853580 139683016574976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:08:38.853632 139683016574976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:08:38.853701 139683016574976 dqn_agent.py:280] 	 optimizer: adam
I0901 13:08:38.853785 139683016574976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:08:38.853870 139683016574976 dqn_agent.py:283] 	 seed: 1630501718852953
I0901 13:08:38.855630 139683016574976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:08:38.855743 139683016574976 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:08:38.855820 139683016574976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:08:38.855887 139683016574976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:08:38.855952 139683016574976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:08:38.856029 139683016574976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:08:38.856096 139683016574976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:08:38.856181 139683016574976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:08:38.856253 139683016574976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:08:38.948059 139683016574976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:39.165935 139683016574976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:39.173212 139683016574976 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:08:39.178696 139683016574976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:08:39.178807 139683016574976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:08:39.178857 139683016574976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:08:39.178907 139683016574976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:08:39.178969 139683016574976 dqn_agent.py:275] 	 update_period: 4
I0901 13:08:39.179031 139683016574976 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:08:39.179090 139683016574976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:08:39.179174 139683016574976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:08:39.179239 139683016574976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:08:39.179289 139683016574976 dqn_agent.py:280] 	 optimizer: adam
I0901 13:08:39.179361 139683016574976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:08:39.179423 139683016574976 dqn_agent.py:283] 	 seed: 1630501719178671
I0901 13:08:39.180693 139683016574976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:08:39.180789 139683016574976 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:08:39.180839 139683016574976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:08:39.180943 139683016574976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:08:39.180995 139683016574976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:08:39.181053 139683016574976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:08:39.181128 139683016574976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:08:39.181189 139683016574976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:08:39.181251 139683016574976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:08:39.198327 139683016574976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:08:39.209456 139683016574976 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:08:39.209583 139683016574976 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 264.46
I0901 13:08:42.991066 139683016574976 replay_runner.py:36] Average training steps per second: 264.46
I0901 13:08:44.102102 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -222.33
Steps executed: 258 Episode length: 139 Return: -49.44320133863247
INFO:tensorflow:Starting iteration 1

Steps executed: 95 Episode length: 95 Return: -1.42098936227166927
INFO:tensorflow:Average training steps per second: 325.78

Steps executed: 300 Episode length: 110 Return: -165.93128734429257
I0901 13:08:50.665449 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -66.03
INFO:tensorflow:Starting iteration 2

Steps executed: 255 Episode length: 166 Return: -220.11987178245937
INFO:tensorflow:Average training steps per second: 326.92
I0901 13:08:56.991392 139683016574976 replay_runner.py:36] Average training steps per second: 326.92
I0901 13:08:57.151768 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -476.83
INFO:tensorflow:Starting iteration 3

Steps executed: 288 Episode length: 93 Return: -224.605258816578981
INFO:tensorflow:Average training steps per second: 323.90
I0901 13:09:03.496580 139683016574976 replay_runner.py:36] Average training steps per second: 323.90
I0901 13:09:03.662722 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.16
INFO:tensorflow:Starting iteration 4

Steps executed: 265 Episode length: 108 Return: -68.562032788307651
INFO:tensorflow:Average training steps per second: 324.37
I0901 13:09:10.065601 139683016574976 replay_runner.py:36] Average training steps per second: 324.37
I0901 13:09:10.231313 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.95
INFO:tensorflow:Starting iteration 5

Steps executed: 171 Episode length: 171 Return: -0.26912061229160145
INFO:tensorflow:Average training steps per second: 330.76

Steps executed: 306 Episode length: 135 Return: -64.1344684776777145
I0901 13:09:16.804486 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -32.20
INFO:tensorflow:Starting iteration 6

Steps executed: 259 Episode length: 142 Return: -105.735488429405445
INFO:tensorflow:Average training steps per second: 335.87
I0901 13:09:23.186028 139683016574976 replay_runner.py:36] Average training steps per second: 335.87
I0901 13:09:23.340403 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -55.28
INFO:tensorflow:Starting iteration 7

Steps executed: 327 Episode length: 327 Return: 160.6996604181941345
INFO:tensorflow:Average training steps per second: 341.60
I0901 13:09:29.717291 139683016574976 replay_runner.py:36] Average training steps per second: 341.60
I0901 13:09:30.040962 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: 160.70
INFO:tensorflow:Starting iteration 8

Steps executed: 203 Episode length: 119 Return: -6.59503731437109845
INFO:tensorflow:Average training steps per second: 321.34
I0901 13:09:36.566275 139683016574976 replay_runner.py:36] Average training steps per second: 321.34
I0901 13:09:36.684621 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -46.74
INFO:tensorflow:Starting iteration 9

Steps executed: 309 Episode length: 115 Return: -51.3893100382571365
INFO:tensorflow:Average training steps per second: 340.50
I0901 13:09:43.065952 139683016574976 replay_runner.py:36] Average training steps per second: 340.50
I0901 13:09:43.243482 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.95
INFO:tensorflow:Starting iteration 10

Steps executed: 227 Episode length: 227 Return: -106.355217479428765
INFO:tensorflow:Average training steps per second: 351.22
I0901 13:09:49.564784 139683016574976 replay_runner.py:36] Average training steps per second: 351.22
I0901 13:09:49.729908 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.36
INFO:tensorflow:Starting iteration 11

Steps executed: 246 Episode length: 142 Return: -63.2276537415978755
INFO:tensorflow:Average training steps per second: 347.15
I0901 13:09:56.106720 139683016574976 replay_runner.py:36] Average training steps per second: 347.15
I0901 13:09:56.274282 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.20
INFO:tensorflow:Starting iteration 12

Steps executed: 239 Episode length: 118 Return: -142.844487611229455
INFO:tensorflow:Average training steps per second: 354.73
I0901 13:10:02.572776 139683016574976 replay_runner.py:36] Average training steps per second: 354.73
I0901 13:10:02.711985 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.03
INFO:tensorflow:Starting iteration 13
I0901 13:10:06.234011 139683016574976 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 355.69

Steps executed: 353 Episode length: 243 Return: -199.058833059312355
I0901 13:10:09.300956 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.63
INFO:tensorflow:Starting iteration 14

Steps executed: 293 Episode length: 193 Return: -194.813676428998065
INFO:tensorflow:Average training steps per second: 347.07
I0901 13:10:15.630790 139683016574976 replay_runner.py:36] Average training steps per second: 347.07
I0901 13:10:15.827662 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.89
INFO:tensorflow:Starting iteration 15

Steps executed: 275 Episode length: 82 Return: -41.26209537313672285
INFO:tensorflow:Average training steps per second: 340.80
I0901 13:10:22.231261 139683016574976 replay_runner.py:36] Average training steps per second: 340.80
I0901 13:10:22.384305 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.08
INFO:tensorflow:Starting iteration 16
I0901 13:10:25.826958 139683016574976 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 351.40

Steps executed: 273 Episode length: 155 Return: -154.586767777658635
I0901 13:10:28.825572 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.13
INFO:tensorflow:Starting iteration 17

Steps executed: 287 Episode length: 182 Return: -160.506566915655365
INFO:tensorflow:Average training steps per second: 368.41
I0901 13:10:35.035753 139683016574976 replay_runner.py:36] Average training steps per second: 368.41
I0901 13:10:35.224609 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -157.33
INFO:tensorflow:Starting iteration 18

Steps executed: 441 Episode length: 310 Return: -164.385907013779845
INFO:tensorflow:Average training steps per second: 373.66
I0901 13:10:41.443458 139683016574976 replay_runner.py:36] Average training steps per second: 373.66
I0901 13:10:41.762746 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.65
INFO:tensorflow:Starting iteration 19
I0901 13:10:45.284842 139683016574976 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 371.47

Steps executed: 1000 Episode length: 1000 Return: -84.50107870707264
I0901 13:10:49.893261 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.50
INFO:tensorflow:Starting iteration 20

Steps executed: 316 Episode length: 142 Return: -174.519891461644744
INFO:tensorflow:Average training steps per second: 363.19
I0901 13:10:56.007316 139683016574976 replay_runner.py:36] Average training steps per second: 363.19
I0901 13:10:56.230446 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.43
INFO:tensorflow:Starting iteration 21
I0901 13:10:59.628765 139683016574976 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 380.88

Steps executed: 1000 Episode length: 1000 Return: -48.65001155541612
I0901 13:11:04.853884 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -48.65
INFO:tensorflow:Starting iteration 22
I0901 13:11:07.915809 139683016574976 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 317.57

Steps executed: 1000 Episode length: 1000 Return: -63.606680492141265
I0901 13:11:12.902363 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -63.61
INFO:tensorflow:Starting iteration 23
I0901 13:11:15.941347 139683016574976 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 315.95

Steps executed: 409 Episode length: 222 Return: -165.0483647147376665
I0901 13:11:19.415192 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.22
INFO:tensorflow:Starting iteration 24
I0901 13:11:22.557240 139683016574976 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 319.78
I0901 13:11:25.684603 139683016574976 replay_runner.py:36] Average training steps per second: 319.78

Steps executed: 1000 Episode length: 1000 Return: -93.498241826018475
INFO:tensorflow:Starting iteration 25

Steps executed: 750 Episode length: 623 Return: -202.8809652757548475
INFO:tensorflow:Average training steps per second: 324.67
I0901 13:11:33.322573 139683016574976 replay_runner.py:36] Average training steps per second: 324.67
I0901 13:11:34.211794 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.86
INFO:tensorflow:Starting iteration 26

Steps executed: 252 Episode length: 252 Return: -184.3084833324281575
INFO:tensorflow:Average training steps per second: 335.88
I0901 13:11:40.555135 139683016574976 replay_runner.py:36] Average training steps per second: 335.88
I0901 13:11:40.743393 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.31
INFO:tensorflow:Starting iteration 27
I0901 13:11:44.047879 139683016574976 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 354.43

Steps executed: 719 Episode length: 719 Return: -169.2894252866227575
I0901 13:11:47.865066 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.29
INFO:tensorflow:Starting iteration 28

Steps executed: 650 Episode length: 503 Return: -210.3537186253429475
INFO:tensorflow:Average training steps per second: 348.77
I0901 13:11:53.957098 139683016574976 replay_runner.py:36] Average training steps per second: 348.77
I0901 13:11:54.598719 139683016574976 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.42
INFO:tensorflow:Starting iteration 29
I0901 13:11:58.019251 139683016574976 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 346.90

Steps executed: 1000 Episode length: 1000 Return: -126.00776300991872

Done fixed training! Episode length: 1000 Return: -126.00776300991872