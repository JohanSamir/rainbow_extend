Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0901 12:46:16.178682 139809518303232 run_experiment.py:549] Creating TrainRunner ...
I0901 12:46:16.191151 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:46:16.191349 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:46:16.191432 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:46:16.191494 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:46:16.191550 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 12:46:16.191604 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:46:16.191666 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:46:16.191720 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:46:16.191772 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:46:16.191823 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 12:46:16.191874 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:46:16.192179 139809518303232 dqn_agent.py:283] 	 seed: 1630500376191064
I0901 12:46:16.195863 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:46:16.196055 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:46:16.196166 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:46:16.196269 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:46:16.196527 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:46:16.196689 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:46:16.196784 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:46:16.196998 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:46:16.197106 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:46:16.237473 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:46:16.643872 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:46:16.658342 139809518303232 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:46:16.688237 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:46:16.688555 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:46:16.688734 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:46:16.688879 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:46:16.688995 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 12:46:16.689126 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:46:16.689255 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:46:16.689416 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:46:16.689755 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:46:16.690008 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 12:46:16.690217 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:46:16.690373 139809518303232 dqn_agent.py:283] 	 seed: 1630500376688159
I0901 12:46:16.693405 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:46:16.693596 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:46:16.693934 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:46:16.694105 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:46:16.694221 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:46:16.694344 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:46:16.694540 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:46:16.694899 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:46:16.695102 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:46:16.730530 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:46:16.754656 139809518303232 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:46:16.754881 139809518303232 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 160.72
I0901 12:46:22.977007 139809518303232 replay_runner.py:36] Average training steps per second: 160.72
Steps executed: 226 Episode length: 93 Return: -617.868178685704307
I0901 12:46:24.250390 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -398.78
INFO:tensorflow:Starting iteration 1

Steps executed: 270 Episode length: 79 Return: -268.905233607413757
INFO:tensorflow:Average training steps per second: 217.01
I0901 12:46:33.159730 139809518303232 replay_runner.py:36] Average training steps per second: 217.01
I0901 12:46:33.395930 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -402.98
INFO:tensorflow:Starting iteration 2

Steps executed: 266 Episode length: 171 Return: -176.60389489552549
INFO:tensorflow:Average training steps per second: 210.73
I0901 12:46:42.527428 139809518303232 replay_runner.py:36] Average training steps per second: 210.73
I0901 12:46:42.788042 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.66
INFO:tensorflow:Starting iteration 3
I0901 12:46:47.182969 139809518303232 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 213.63

Steps executed: 271 Episode length: 138 Return: -218.62267637246515
I0901 12:46:52.136564 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.89
INFO:tensorflow:Starting iteration 4

Steps executed: 282 Episode length: 158 Return: -224.00570969106635
INFO:tensorflow:Average training steps per second: 218.02
I0901 12:47:01.099499 139809518303232 replay_runner.py:36] Average training steps per second: 218.02
I0901 12:47:01.375215 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.69
INFO:tensorflow:Starting iteration 5

Steps executed: 341 Episode length: 258 Return: 140.154063375658755
INFO:tensorflow:Average training steps per second: 215.31
I0901 12:47:10.458489 139809518303232 replay_runner.py:36] Average training steps per second: 215.31
I0901 12:47:10.841277 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -60.42
INFO:tensorflow:Starting iteration 6

Steps executed: 160 Episode length: 80 Return: 13.65576906908985755
INFO:tensorflow:Average training steps per second: 217.57
I0901 12:47:19.816337 139809518303232 replay_runner.py:36] Average training steps per second: 217.57

Steps executed: 260 Episode length: 100 Return: -457.53859343643765
INFO:tensorflow:Starting iteration 7

Steps executed: 273 Episode length: 133 Return: -568.04863796502675
INFO:tensorflow:Average training steps per second: 223.91
I0901 12:47:28.905700 139809518303232 replay_runner.py:36] Average training steps per second: 223.91
I0901 12:47:29.191184 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -606.80
INFO:tensorflow:Starting iteration 8

Steps executed: 218 Episode length: 65 Return: -176.585786882039945
INFO:tensorflow:Average training steps per second: 225.07
I0901 12:47:37.932219 139809518303232 replay_runner.py:36] Average training steps per second: 225.07
I0901 12:47:38.093585 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -292.15
INFO:tensorflow:Starting iteration 9

Steps executed: 287 Episode length: 139 Return: -179.97404050716935
INFO:tensorflow:Average training steps per second: 222.45
I0901 12:47:46.845237 139809518303232 replay_runner.py:36] Average training steps per second: 222.45
I0901 12:47:47.114746 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.04
INFO:tensorflow:Starting iteration 10

Steps executed: 127 Episode length: 127 Return: -116.00557963179092
INFO:tensorflow:Average training steps per second: 222.20
I0901 12:47:56.023063 139809518303232 replay_runner.py:36] Average training steps per second: 222.20

Steps executed: 256 Episode length: 129 Return: -359.60209552600922
INFO:tensorflow:Starting iteration 11

Steps executed: 251 Episode length: 251 Return: -37.362525305941892
INFO:tensorflow:Average training steps per second: 220.08
I0901 12:48:05.082436 139809518303232 replay_runner.py:36] Average training steps per second: 220.08
I0901 12:48:05.410890 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.36
INFO:tensorflow:Starting iteration 12
I0901 12:48:09.821468 139809518303232 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 221.25

Steps executed: 299 Episode length: 197 Return: -545.14079852942592
I0901 12:48:14.656095 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -495.57
INFO:tensorflow:Starting iteration 13

Steps executed: 287 Episode length: 120 Return: -263.56424318654452
INFO:tensorflow:Average training steps per second: 217.27
I0901 12:48:23.702795 139809518303232 replay_runner.py:36] Average training steps per second: 217.27
I0901 12:48:23.992318 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.82
INFO:tensorflow:Starting iteration 14

Steps executed: 285 Episode length: 178 Return: -320.65838987127842
INFO:tensorflow:Average training steps per second: 222.81
I0901 12:48:32.885882 139809518303232 replay_runner.py:36] Average training steps per second: 222.81
I0901 12:48:33.157340 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -317.91
INFO:tensorflow:Starting iteration 15

Steps executed: 332 Episode length: 151 Return: -120.47582471845232
INFO:tensorflow:Average training steps per second: 221.67
I0901 12:48:41.945576 139809518303232 replay_runner.py:36] Average training steps per second: 221.67
I0901 12:48:42.224773 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.46
INFO:tensorflow:Starting iteration 16

Steps executed: 270 Episode length: 72 Return: -286.090069909366662
INFO:tensorflow:Average training steps per second: 222.12
I0901 12:48:50.944514 139809518303232 replay_runner.py:36] Average training steps per second: 222.12
I0901 12:48:51.163552 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.71
INFO:tensorflow:Starting iteration 17

Steps executed: 203 Episode length: 76 Return: -578.225156930150862
INFO:tensorflow:Average training steps per second: 219.75
I0901 12:49:00.114106 139809518303232 replay_runner.py:36] Average training steps per second: 219.75
I0901 12:49:00.293821 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -519.85
INFO:tensorflow:Starting iteration 18

Steps executed: 226 Episode length: 80 Return: -526.042668842021892
INFO:tensorflow:Average training steps per second: 219.39
I0901 12:49:09.264093 139809518303232 replay_runner.py:36] Average training steps per second: 219.39
I0901 12:49:09.464427 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -649.17
INFO:tensorflow:Starting iteration 19

Steps executed: 245 Episode length: 81 Return: -725.481819524084962
INFO:tensorflow:Average training steps per second: 223.40
I0901 12:49:18.367333 139809518303232 replay_runner.py:36] Average training steps per second: 223.40
I0901 12:49:18.569083 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -630.23
INFO:tensorflow:Starting iteration 20

Steps executed: 224 Episode length: 161 Return: -361.65987171511546
INFO:tensorflow:Average training steps per second: 228.62
I0901 12:49:27.234240 139809518303232 replay_runner.py:36] Average training steps per second: 228.62
I0901 12:49:27.445837 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.91
INFO:tensorflow:Starting iteration 21
I0901 12:49:31.725441 139809518303232 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 221.72

Steps executed: 270 Episode length: 103 Return: -761.68925424698856
I0901 12:49:36.453868 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.15
INFO:tensorflow:Starting iteration 22

Steps executed: 239 Episode length: 59 Return: -488.059739728844656
INFO:tensorflow:Average training steps per second: 219.18
I0901 12:49:45.349150 139809518303232 replay_runner.py:36] Average training steps per second: 219.18
I0901 12:49:45.561017 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -484.71
INFO:tensorflow:Starting iteration 23

Steps executed: 246 Episode length: 81 Return: -637.805860510514456
INFO:tensorflow:Average training steps per second: 218.11
I0901 12:49:54.535714 139809518303232 replay_runner.py:36] Average training steps per second: 218.11
I0901 12:49:54.744097 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -722.06
INFO:tensorflow:Starting iteration 24

Steps executed: 202 Episode length: 64 Return: -563.714757336116756
INFO:tensorflow:Average training steps per second: 224.18
I0901 12:50:03.508024 139809518303232 replay_runner.py:36] Average training steps per second: 224.18
I0901 12:50:03.670777 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -568.91
INFO:tensorflow:Starting iteration 25

Steps executed: 225 Episode length: 52 Return: -355.970163504873856
INFO:tensorflow:Average training steps per second: 209.67
I0901 12:50:12.639242 139809518303232 replay_runner.py:36] Average training steps per second: 209.67
I0901 12:50:12.825283 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -450.24
INFO:tensorflow:Starting iteration 26

Steps executed: 204 Episode length: 65 Return: -324.511209435088746
INFO:tensorflow:Average training steps per second: 224.09
I0901 12:50:21.556851 139809518303232 replay_runner.py:36] Average training steps per second: 224.09
I0901 12:50:21.724470 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -384.19
INFO:tensorflow:Starting iteration 27

Steps executed: 220 Episode length: 109 Return: 34.7682345910903346
INFO:tensorflow:Average training steps per second: 214.48
I0901 12:50:30.737128 139809518303232 replay_runner.py:36] Average training steps per second: 214.48
I0901 12:50:30.899411 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.73
INFO:tensorflow:Starting iteration 28

Steps executed: 252 Episode length: 83 Return: -688.319781174907746
INFO:tensorflow:Average training steps per second: 214.02
I0901 12:50:39.864871 139809518303232 replay_runner.py:36] Average training steps per second: 214.02
I0901 12:50:40.094719 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -522.79
INFO:tensorflow:Starting iteration 29

Steps executed: 205 Episode length: 59 Return: -426.152238346596166
INFO:tensorflow:Average training steps per second: 211.86
I0901 12:50:49.156813 139809518303232 replay_runner.py:36] Average training steps per second: 211.86

Done fixed training!Episode length: 59 Return: -426.152238346596166