Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 12:40:44.470644 140315766171648 run_experiment.py:549] Creating TrainRunner ...
I0901 12:40:44.482426 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:40:44.482712 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:40:44.482902 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:40:44.483155 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:40:44.483302 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 12:40:44.483424 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:40:44.483536 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:40:44.483659 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:40:44.483772 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:40:44.483874 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 12:40:44.483986 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:40:44.484096 140315766171648 dqn_agent.py:283] 	 seed: 1630500044482361
I0901 12:40:44.487535 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:40:44.487847 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:40:44.488189 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:40:44.488523 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:40:44.488694 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:40:44.488815 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:40:44.488935 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:40:44.489270 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:40:44.489506 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:40:44.566884 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:40:44.998548 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:40:45.013245 140315766171648 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:40:45.022928 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:40:45.023214 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:40:45.023362 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:40:45.023533 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:40:45.023878 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 12:40:45.024049 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:40:45.024147 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:40:45.024311 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:40:45.024449 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:40:45.024534 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 12:40:45.024652 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:40:45.024726 140315766171648 dqn_agent.py:283] 	 seed: 1630500045022861
I0901 12:40:45.027961 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:40:45.028139 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:40:45.028237 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:40:45.028312 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:40:45.028369 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:40:45.028427 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:40:45.028527 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:40:45.028670 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:40:45.029056 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:40:45.063037 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:40:45.084613 140315766171648 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:40:45.084899 140315766171648 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 149.06
I0901 12:40:51.794431 140315766171648 replay_runner.py:36] Average training steps per second: 149.06
Steps executed: 265 Episode length: 84 Return: -405.119228407593887
I0901 12:40:53.091936 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -334.84
INFO:tensorflow:Starting iteration 1

Steps executed: 117 Episode length: 117 Return: -211.63760006460337
INFO:tensorflow:Average training steps per second: 212.54

Steps executed: 258 Episode length: 141 Return: -211.64440715384547
I0901 12:41:02.343002 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.64
INFO:tensorflow:Starting iteration 2

Steps executed: 300 Episode length: 118 Return: -238.32894346232158
INFO:tensorflow:Average training steps per second: 216.50
I0901 12:41:11.250914 140315766171648 replay_runner.py:36] Average training steps per second: 216.50
I0901 12:41:11.518454 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.69
INFO:tensorflow:Starting iteration 3

Steps executed: 275 Episode length: 138 Return: -217.89082358403228
INFO:tensorflow:Average training steps per second: 215.65
I0901 12:41:20.455988 140315766171648 replay_runner.py:36] Average training steps per second: 215.65
I0901 12:41:20.719746 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.16
INFO:tensorflow:Starting iteration 4

Steps executed: 400 Episode length: 276 Return: -316.98319696522456
INFO:tensorflow:Average training steps per second: 219.67
I0901 12:41:29.576847 140315766171648 replay_runner.py:36] Average training steps per second: 219.67
I0901 12:41:29.999817 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.93
INFO:tensorflow:Starting iteration 5

Steps executed: 242 Episode length: 107 Return: -177.76398695369332
INFO:tensorflow:Average training steps per second: 209.36
I0901 12:41:39.185600 140315766171648 replay_runner.py:36] Average training steps per second: 209.36
I0901 12:41:39.399533 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.12
INFO:tensorflow:Starting iteration 6

Steps executed: 75 Episode length: 75 Return: -372.7996660258276632
INFO:tensorflow:Average training steps per second: 214.42

Steps executed: 254 Episode length: 68 Return: -380.609801785679052
I0901 12:41:48.693134 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -388.87
INFO:tensorflow:Starting iteration 7

Steps executed: 209 Episode length: 81 Return: -182.996355710800862
INFO:tensorflow:Average training steps per second: 208.92
I0901 12:41:57.896383 140315766171648 replay_runner.py:36] Average training steps per second: 208.92
I0901 12:41:58.076225 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.07
INFO:tensorflow:Starting iteration 8

Steps executed: 218 Episode length: 129 Return: -210.41075468605283
INFO:tensorflow:Average training steps per second: 209.52
I0901 12:42:07.236003 140315766171648 replay_runner.py:36] Average training steps per second: 209.52
I0901 12:42:07.429225 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.98
INFO:tensorflow:Starting iteration 9
I0901 12:42:11.888232 140315766171648 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 210.82

Steps executed: 227 Episode length: 105 Return: -166.79156808830697
I0901 12:42:16.870925 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.88
INFO:tensorflow:Starting iteration 10

Steps executed: 239 Episode length: 75 Return: -260.126023793585667
INFO:tensorflow:Average training steps per second: 213.28
I0901 12:42:25.829170 140315766171648 replay_runner.py:36] Average training steps per second: 213.28
I0901 12:42:26.021651 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.06
INFO:tensorflow:Starting iteration 11

Steps executed: 466 Episode length: 466 Return: -458.89663122665087
INFO:tensorflow:Average training steps per second: 209.85
I0901 12:42:35.222110 140315766171648 replay_runner.py:36] Average training steps per second: 209.85
I0901 12:42:36.050230 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -458.90
INFO:tensorflow:Starting iteration 12

Steps executed: 114 Episode length: 114 Return: -43.662906978281257
INFO:tensorflow:Average training steps per second: 210.18

Steps executed: 1114 Episode length: 1000 Return: 8.181154168739884
I0901 12:42:49.677432 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -17.74
INFO:tensorflow:Starting iteration 13

Steps executed: 98 Episode length: 98 Return: -209.7290590350542884
INFO:tensorflow:Average training steps per second: 215.71

Steps executed: 1098 Episode length: 1000 Return: -20.66805593670133
I0901 12:43:01.777343 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.20
INFO:tensorflow:Starting iteration 14

Steps executed: 319 Episode length: 319 Return: -143.654483373651373
INFO:tensorflow:Average training steps per second: 214.31
I0901 12:43:10.795860 140315766171648 replay_runner.py:36] Average training steps per second: 214.31
I0901 12:43:11.234927 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.65
INFO:tensorflow:Starting iteration 15

Steps executed: 256 Episode length: 129 Return: -114.361085297733133
INFO:tensorflow:Average training steps per second: 224.20
I0901 12:43:19.907261 140315766171648 replay_runner.py:36] Average training steps per second: 224.20
I0901 12:43:20.107843 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.78
INFO:tensorflow:Starting iteration 16

Steps executed: 308 Episode length: 124 Return: -622.201779724721633
INFO:tensorflow:Average training steps per second: 217.78
I0901 12:43:29.092902 140315766171648 replay_runner.py:36] Average training steps per second: 217.78
I0901 12:43:29.395653 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.20
INFO:tensorflow:Starting iteration 17

Steps executed: 300 Episode length: 145 Return: -402.034339397204353
INFO:tensorflow:Average training steps per second: 215.83
I0901 12:43:38.089242 140315766171648 replay_runner.py:36] Average training steps per second: 215.83
I0901 12:43:38.350668 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.82
INFO:tensorflow:Starting iteration 18

Steps executed: 200 Episode length: 74 Return: -124.6730512351873653
INFO:tensorflow:Average training steps per second: 212.28
I0901 12:43:47.446764 140315766171648 replay_runner.py:36] Average training steps per second: 212.28
I0901 12:43:47.615240 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -322.33
INFO:tensorflow:Starting iteration 19

Steps executed: 265 Episode length: 69 Return: -275.1241887605793653
INFO:tensorflow:Average training steps per second: 212.65
I0901 12:43:56.753968 140315766171648 replay_runner.py:36] Average training steps per second: 212.65
I0901 12:43:57.018544 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -635.52
INFO:tensorflow:Starting iteration 20

Steps executed: 288 Episode length: 89 Return: -547.6967266811234653
INFO:tensorflow:Average training steps per second: 216.16
I0901 12:44:05.958477 140315766171648 replay_runner.py:36] Average training steps per second: 216.16
I0901 12:44:06.225081 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -501.39
INFO:tensorflow:Starting iteration 21

Steps executed: 211 Episode length: 70 Return: -162.4972745585024553
INFO:tensorflow:Average training steps per second: 223.35
I0901 12:44:15.167359 140315766171648 replay_runner.py:36] Average training steps per second: 223.35
I0901 12:44:15.323176 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.38
INFO:tensorflow:Starting iteration 22

Steps executed: 278 Episode length: 90 Return: -412.0289212747533753
INFO:tensorflow:Average training steps per second: 224.24
I0901 12:44:24.156490 140315766171648 replay_runner.py:36] Average training steps per second: 224.24
I0901 12:44:24.373511 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -413.64
INFO:tensorflow:Starting iteration 23

Steps executed: 241 Episode length: 50 Return: -348.4326439614657753
INFO:tensorflow:Average training steps per second: 222.84
I0901 12:44:33.324616 140315766171648 replay_runner.py:36] Average training steps per second: 222.84
I0901 12:44:33.541888 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -498.80
INFO:tensorflow:Starting iteration 24

Steps executed: 204 Episode length: 84 Return: -735.0860195422737753
INFO:tensorflow:Average training steps per second: 219.43
I0901 12:44:42.269983 140315766171648 replay_runner.py:36] Average training steps per second: 219.43
I0901 12:44:42.449550 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -565.34
INFO:tensorflow:Starting iteration 25

Steps executed: 232 Episode length: 57 Return: -487.5244406714837753
INFO:tensorflow:Average training steps per second: 215.52
I0901 12:44:51.588182 140315766171648 replay_runner.py:36] Average training steps per second: 215.52
I0901 12:44:51.800355 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -429.68
INFO:tensorflow:Starting iteration 26
I0901 12:44:56.318510 140315766171648 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 213.45

Steps executed: 229 Episode length: 73 Return: -375.9146112584643353
I0901 12:45:01.239494 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -416.46
INFO:tensorflow:Starting iteration 27

Steps executed: 266 Episode length: 83 Return: -766.1315311534318353
INFO:tensorflow:Average training steps per second: 220.55
I0901 12:45:10.163411 140315766171648 replay_runner.py:36] Average training steps per second: 220.55
I0901 12:45:10.414702 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -603.34
INFO:tensorflow:Starting iteration 28

Steps executed: 219 Episode length: 72 Return: -620.3814258053711353
INFO:tensorflow:Average training steps per second: 209.19
I0901 12:45:19.731832 140315766171648 replay_runner.py:36] Average training steps per second: 209.19
I0901 12:45:19.942809 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -696.82
INFO:tensorflow:Starting iteration 29
I0901 12:45:24.469327 140315766171648 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 213.82

Steps executed: 203 Episode length: 82 Return: -425.8362524966865453

Done fixed training!Episode length: 82 Return: -425.8362524966865453