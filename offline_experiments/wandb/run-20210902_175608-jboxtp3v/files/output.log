Loaded trained dqn in cartpole
Training fixed agent 8, please be patient, may be a while...
I0902 17:56:15.249105 140512094517248 run_experiment.py:549] Creating TrainRunner ...
I0902 17:56:15.258125 140512094517248 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:56:15.258349 140512094517248 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:56:15.258464 140512094517248 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:56:15.258596 140512094517248 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:56:15.258678 140512094517248 dqn_agent.py:275] 	 update_period: 4
I0902 17:56:15.258774 140512094517248 dqn_agent.py:276] 	 target_update_period: 100
I0902 17:56:15.258844 140512094517248 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:56:15.258922 140512094517248 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:56:15.259007 140512094517248 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:56:15.259080 140512094517248 dqn_agent.py:280] 	 optimizer: adam
I0902 17:56:15.259159 140512094517248 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:56:15.259332 140512094517248 dqn_agent.py:283] 	 seed: 1630605375258069
I0902 17:56:15.262456 140512094517248 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:56:15.262658 140512094517248 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0902 17:56:15.262763 140512094517248 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:56:15.262850 140512094517248 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:56:15.262933 140512094517248 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:56:15.263010 140512094517248 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:56:15.263135 140512094517248 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:56:15.263214 140512094517248 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:56:15.263295 140512094517248 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:56:15.295461 140512094517248 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.312500
I0902 17:56:15.792263 140512094517248 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.312500
I0902 17:56:15.806644 140512094517248 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 17:56:15.814550 140512094517248 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:56:15.814718 140512094517248 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:56:15.814791 140512094517248 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:56:15.814852 140512094517248 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:56:15.814920 140512094517248 dqn_agent.py:275] 	 update_period: 4
I0902 17:56:15.814972 140512094517248 dqn_agent.py:276] 	 target_update_period: 100
I0902 17:56:15.815062 140512094517248 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:56:15.815117 140512094517248 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:56:15.815277 140512094517248 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:56:15.815364 140512094517248 dqn_agent.py:280] 	 optimizer: adam
I0902 17:56:15.815463 140512094517248 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:56:15.815574 140512094517248 dqn_agent.py:283] 	 seed: 1630605375814508
I0902 17:56:15.818620 140512094517248 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:56:15.818804 140512094517248 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0902 17:56:15.818909 140512094517248 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:56:15.818997 140512094517248 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:56:15.819114 140512094517248 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:56:15.819456 140512094517248 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:56:15.819651 140512094517248 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:56:15.819795 140512094517248 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:56:15.819941 140512094517248 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:56:15.856396 140512094517248 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.312500
I0902 17:56:15.880069 140512094517248 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 17:56:15.880682 140512094517248 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 149.51
I0902 17:56:22.569857 140512094517248 replay_runner.py:36] Average training steps per second: 149.51
Steps executed: 205 Episode length: 91 Return: 91.0
I0902 17:56:23.699242 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 51.25
INFO:tensorflow:Starting iteration 1

Steps executed: 206 Episode length: 103 Return: 103.0
INFO:tensorflow:Average training steps per second: 199.49
I0902 17:56:28.911711 140512094517248 replay_runner.py:36] Average training steps per second: 199.49
I0902 17:56:29.063790 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 103.00
INFO:tensorflow:Starting iteration 2

Steps executed: 200 Episode length: 15 Return: 15.0.0
INFO:tensorflow:Average training steps per second: 194.00
I0902 17:56:34.484056 140512094517248 replay_runner.py:36] Average training steps per second: 194.00
I0902 17:56:34.620985 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 15.38
INFO:tensorflow:Starting iteration 3

Steps executed: 209 Episode length: 10 Return: 10.0.0
INFO:tensorflow:Average training steps per second: 202.04
I0902 17:56:39.745185 140512094517248 replay_runner.py:36] Average training steps per second: 202.04
I0902 17:56:39.890423 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.50
INFO:tensorflow:Starting iteration 4

Steps executed: 148 Episode length: 9 Return: 9.0.0.0
INFO:tensorflow:Average training steps per second: 206.10

Steps executed: 203 Episode length: 10 Return: 10.0.0
I0902 17:56:45.062300 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.23
INFO:tensorflow:Starting iteration 5
I0902 17:56:45.248776 140512094517248 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 204.21
I0902 17:56:50.146142 140512094517248 replay_runner.py:36] Average training steps per second: 204.21
I0902 17:56:50.264750 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.62
INFO:tensorflow:Starting iteration 6

Steps executed: 202 Episode length: 12 Return: 12.0.0
INFO:tensorflow:Average training steps per second: 205.26
I0902 17:56:55.371565 140512094517248 replay_runner.py:36] Average training steps per second: 205.26
I0902 17:56:55.498579 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.41
INFO:tensorflow:Starting iteration 7


Steps executed: 200 Episode length: 10 Return: 10.0.0
INFO:tensorflow:Average training steps per second: 204.60
I0902 17:57:00.632242 140512094517248 replay_runner.py:36] Average training steps per second: 204.60
I0902 17:57:00.797603 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.52
INFO:tensorflow:Starting iteration 8

Steps executed: 204 Episode length: 11 Return: 11.0.0
INFO:tensorflow:Average training steps per second: 198.92
I0902 17:57:06.001957 140512094517248 replay_runner.py:36] Average training steps per second: 198.92
I0902 17:57:06.143128 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.27
INFO:tensorflow:Starting iteration 9

Steps executed: 201 Episode length: 10 Return: 10.0.0
INFO:tensorflow:Average training steps per second: 196.63
I0902 17:57:11.443783 140512094517248 replay_runner.py:36] Average training steps per second: 196.63
I0902 17:57:11.587448 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.57
INFO:tensorflow:Starting iteration 10

Steps executed: 200 Episode length: 10 Return: 10.0.0
INFO:tensorflow:Average training steps per second: 198.53
I0902 17:57:16.817448 140512094517248 replay_runner.py:36] Average training steps per second: 198.53
I0902 17:57:16.959760 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.52
INFO:tensorflow:Starting iteration 11

Steps executed: 202 Episode length: 8 Return: 8.0.0.0
INFO:tensorflow:Average training steps per second: 193.41
I0902 17:57:22.308709 140512094517248 replay_runner.py:36] Average training steps per second: 193.41
I0902 17:57:22.454219 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.18
INFO:tensorflow:Starting iteration 12

Steps executed: 202 Episode length: 9 Return: 9.0.0.0
INFO:tensorflow:Average training steps per second: 197.36
I0902 17:57:27.713578 140512094517248 replay_runner.py:36] Average training steps per second: 197.36
I0902 17:57:27.857180 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.18
INFO:tensorflow:Starting iteration 13
I0902 17:57:28.061631 140512094517248 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 193.36
I0902 17:57:33.233762 140512094517248 replay_runner.py:36] Average training steps per second: 193.36

Steps executed: 227 Episode length: 75 Return: 75.0.0
INFO:tensorflow:Starting iteration 14

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 193.05
I0902 17:57:38.760523 140512094517248 replay_runner.py:36] Average training steps per second: 193.05
I0902 17:57:38.895890 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 15
I0902 17:57:39.096283 140512094517248 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 200.46
I0902 17:57:44.085506 140512094517248 replay_runner.py:36] Average training steps per second: 200.46
I0902 17:57:44.215246 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 16
I0902 17:57:44.391577 140512094517248 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 194.18

Steps executed: 394 Episode length: 200 Return: 200.0
I0902 17:57:49.799978 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 197.00
INFO:tensorflow:Starting iteration 17
I0902 17:57:49.978936 140512094517248 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 191.03
I0902 17:57:55.214144 140512094517248 replay_runner.py:36] Average training steps per second: 191.03

Steps executed: 370 Episode length: 200 Return: 200.0
INFO:tensorflow:Starting iteration 18

Steps executed: 348 Episode length: 186 Return: 186.0
INFO:tensorflow:Average training steps per second: 193.26
I0902 17:58:00.837361 140512094517248 replay_runner.py:36] Average training steps per second: 193.26
I0902 17:58:01.072572 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 174.00
INFO:tensorflow:Starting iteration 19

Steps executed: 316 Episode length: 162 Return: 162.0
INFO:tensorflow:Average training steps per second: 199.38
I0902 17:58:06.278083 140512094517248 replay_runner.py:36] Average training steps per second: 199.38
I0902 17:58:06.497756 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 158.00
INFO:tensorflow:Starting iteration 20

Steps executed: 316 Episode length: 141 Return: 141.0
INFO:tensorflow:Average training steps per second: 194.57
I0902 17:58:11.835252 140512094517248 replay_runner.py:36] Average training steps per second: 194.57
I0902 17:58:12.045174 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 158.00
INFO:tensorflow:Starting iteration 21

Steps executed: 326 Episode length: 172 Return: 172.0
INFO:tensorflow:Average training steps per second: 192.54
I0902 17:58:17.410822 140512094517248 replay_runner.py:36] Average training steps per second: 192.54
I0902 17:58:17.643236 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 163.00
INFO:tensorflow:Starting iteration 22

Steps executed: 303 Episode length: 155 Return: 155.0
INFO:tensorflow:Average training steps per second: 198.38
I0902 17:58:22.880424 140512094517248 replay_runner.py:36] Average training steps per second: 198.38
I0902 17:58:23.085307 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 151.50
INFO:tensorflow:Starting iteration 23

Steps executed: 335 Episode length: 172 Return: 172.0
INFO:tensorflow:Average training steps per second: 196.06
I0902 17:58:28.381079 140512094517248 replay_runner.py:36] Average training steps per second: 196.06
I0902 17:58:28.602767 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 167.50
INFO:tensorflow:Starting iteration 24

Steps executed: 313 Episode length: 155 Return: 155.0
INFO:tensorflow:Average training steps per second: 196.62
I0902 17:58:33.876457 140512094517248 replay_runner.py:36] Average training steps per second: 196.62
I0902 17:58:34.090376 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 156.50
INFO:tensorflow:Starting iteration 25

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 193.47
I0902 17:58:39.447532 140512094517248 replay_runner.py:36] Average training steps per second: 193.47
I0902 17:58:39.585837 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26
I0902 17:58:39.781849 140512094517248 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 191.94
I0902 17:58:44.992043 140512094517248 replay_runner.py:36] Average training steps per second: 191.94
I0902 17:58:45.130753 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 27
I0902 17:58:45.314094 140512094517248 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 197.47
I0902 17:58:50.378587 140512094517248 replay_runner.py:36] Average training steps per second: 197.47
I0902 17:58:50.515583 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 28
I0902 17:58:50.710621 140512094517248 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 197.36
I0902 17:58:55.777783 140512094517248 replay_runner.py:36] Average training steps per second: 197.36
I0902 17:58:55.908220 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 202.92
I0902 17:59:01.027682 140512094517248 replay_runner.py:36] Average training steps per second: 202.92
I0902 17:59:01.158983 140512094517248 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00