I0901 13:26:49.931359 140315766171648 run_experiment.py:549] Creating TrainRunner ...
I0901 13:26:49.939611 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:26:49.939795 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:26:49.939871 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:26:49.939935 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:26:49.940031 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 13:26:49.940087 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:26:49.940190 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:26:49.940247 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:26:49.940299 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:26:49.940374 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 13:26:49.940491 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:26:49.940563 140315766171648 dqn_agent.py:283] 	 seed: 1630502809939566
I0901 13:26:49.942303 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:26:49.942416 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:26:49.942489 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:26:49.942551 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:26:49.942623 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:26:49.942684 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:26:49.942768 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:26:49.942866 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:26:49.942951 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:26:50.951208 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:26:51.226746 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:26:51.237551 140315766171648 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:26:51.244446 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:26:51.244582 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:26:51.244653 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:26:51.244717 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:26:51.244793 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 13:26:51.244882 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:26:51.244958 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:26:51.245068 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:26:51.245121 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:26:51.245199 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 13:26:51.245252 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:26:51.245315 140315766171648 dqn_agent.py:283] 	 seed: 1630502811244416
I0901 13:26:51.246740 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:26:51.246853 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:26:51.246924 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:26:51.246987 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:26:51.247042 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:26:51.247113 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:26:51.247196 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:26:51.247265 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:26:51.247340 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:26:51.267513 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:26:51.282175 140315766171648 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:26:51.282333 140315766171648 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 257.16
I0901 13:26:55.171196 140315766171648 replay_runner.py:36] Average training steps per second: 257.16
Steps executed: 292 Episode length: 146 Return: -344.9806524183114
I0901 13:26:55.965807 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.02
INFO:tensorflow:Starting iteration 1

Steps executed: 230 Episode length: 131 Return: -200.79700596758485
INFO:tensorflow:Average training steps per second: 347.45
I0901 13:27:01.985328 140315766171648 replay_runner.py:36] Average training steps per second: 347.45
I0901 13:27:02.106418 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -150.94
INFO:tensorflow:Starting iteration 2

Steps executed: 215 Episode length: 126 Return: -371.24269025600086
INFO:tensorflow:Average training steps per second: 369.93
I0901 13:27:07.961057 140315766171648 replay_runner.py:36] Average training steps per second: 369.93
I0901 13:27:08.075464 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.12
INFO:tensorflow:Starting iteration 3

Steps executed: 305 Episode length: 180 Return: 29.1679709100716623
INFO:tensorflow:Average training steps per second: 364.76
I0901 13:27:13.937556 140315766171648 replay_runner.py:36] Average training steps per second: 364.76
I0901 13:27:14.101573 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.63
INFO:tensorflow:Starting iteration 4

Steps executed: 231 Episode length: 231 Return: -76.438838757511353
INFO:tensorflow:Average training steps per second: 364.35
I0901 13:27:19.948778 140315766171648 replay_runner.py:36] Average training steps per second: 364.35
I0901 13:27:20.106597 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.44
INFO:tensorflow:Starting iteration 5

Steps executed: 221 Episode length: 83 Return: -223.309670390456063
INFO:tensorflow:Average training steps per second: 368.70
I0901 13:27:25.990041 140315766171648 replay_runner.py:36] Average training steps per second: 368.70
I0901 13:27:26.092985 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.11
INFO:tensorflow:Starting iteration 6

Steps executed: 289 Episode length: 153 Return: -204.12630781439053
INFO:tensorflow:Average training steps per second: 370.66
I0901 13:27:31.973379 140315766171648 replay_runner.py:36] Average training steps per second: 370.66
I0901 13:27:32.139463 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -247.69
INFO:tensorflow:Starting iteration 7

Steps executed: 209 Episode length: 88 Return: -364.577120968605773
INFO:tensorflow:Average training steps per second: 363.31
I0901 13:27:38.098004 140315766171648 replay_runner.py:36] Average training steps per second: 363.31
I0901 13:27:38.196451 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.03
INFO:tensorflow:Starting iteration 8

Steps executed: 257 Episode length: 130 Return: -343.05747781623417
INFO:tensorflow:Average training steps per second: 364.67
I0901 13:27:44.139795 140315766171648 replay_runner.py:36] Average training steps per second: 364.67
I0901 13:27:44.278279 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.37
INFO:tensorflow:Starting iteration 9

Steps executed: 267 Episode length: 125 Return: -326.48082971240035
INFO:tensorflow:Average training steps per second: 364.82
I0901 13:27:50.238319 140315766171648 replay_runner.py:36] Average training steps per second: 364.82
I0901 13:27:50.390576 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.50
INFO:tensorflow:Starting iteration 10

Steps executed: 307 Episode length: 116 Return: -316.75833534185375
INFO:tensorflow:Average training steps per second: 361.39
I0901 13:27:56.370893 140315766171648 replay_runner.py:36] Average training steps per second: 361.39
I0901 13:27:56.499630 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.62
INFO:tensorflow:Starting iteration 11

Steps executed: 315 Episode length: 139 Return: -276.53083954109146
INFO:tensorflow:Average training steps per second: 370.58
I0901 13:28:02.375835 140315766171648 replay_runner.py:36] Average training steps per second: 370.58
I0901 13:28:02.529939 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.96
INFO:tensorflow:Starting iteration 12

Steps executed: 374 Episode length: 223 Return: -285.96401119120094
INFO:tensorflow:Average training steps per second: 378.50
I0901 13:28:08.346747 140315766171648 replay_runner.py:36] Average training steps per second: 378.50
I0901 13:28:08.563698 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -357.25
INFO:tensorflow:Starting iteration 13

Steps executed: 215 Episode length: 73 Return: -144.033647923251834
INFO:tensorflow:Average training steps per second: 363.61
I0901 13:28:14.590224 140315766171648 replay_runner.py:36] Average training steps per second: 363.61
I0901 13:28:14.671370 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.03
INFO:tensorflow:Starting iteration 14

Steps executed: 231 Episode length: 52 Return: -115.887879064018911
INFO:tensorflow:Average training steps per second: 356.13
I0901 13:28:20.722764 140315766171648 replay_runner.py:36] Average training steps per second: 356.13
I0901 13:28:20.825703 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.41
INFO:tensorflow:Starting iteration 15

Steps executed: 223 Episode length: 86 Return: -269.476357143119441
INFO:tensorflow:Average training steps per second: 356.93
I0901 13:28:26.939514 140315766171648 replay_runner.py:36] Average training steps per second: 356.93
I0901 13:28:27.025130 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.12
INFO:tensorflow:Starting iteration 16

Steps executed: 226 Episode length: 114 Return: -183.68234565704697
INFO:tensorflow:Average training steps per second: 358.27
I0901 13:28:32.978858 140315766171648 replay_runner.py:36] Average training steps per second: 358.27
I0901 13:28:33.095975 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -239.21
INFO:tensorflow:Starting iteration 17

Steps executed: 248 Episode length: 53 Return: -94.4169709599394567
INFO:tensorflow:Average training steps per second: 365.33
I0901 13:28:39.030491 140315766171648 replay_runner.py:36] Average training steps per second: 365.33
I0901 13:28:39.139051 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.02
INFO:tensorflow:Starting iteration 18

Steps executed: 207 Episode length: 126 Return: -363.21275965752346
INFO:tensorflow:Average training steps per second: 362.16
I0901 13:28:45.056448 140315766171648 replay_runner.py:36] Average training steps per second: 362.16
I0901 13:28:45.161868 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.26
INFO:tensorflow:Starting iteration 19

Steps executed: 204 Episode length: 65 Return: 1.066758335214856946
INFO:tensorflow:Average training steps per second: 361.16
I0901 13:28:51.143789 140315766171648 replay_runner.py:36] Average training steps per second: 361.16
I0901 13:28:51.216949 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.58
INFO:tensorflow:Starting iteration 20

Steps executed: 463 Episode length: 339 Return: -389.65877045909543
INFO:tensorflow:Average training steps per second: 354.24
I0901 13:28:57.231237 140315766171648 replay_runner.py:36] Average training steps per second: 354.24
I0901 13:28:57.619585 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -298.01
INFO:tensorflow:Starting iteration 21

Steps executed: 206 Episode length: 57 Return: -124.062875886454663
INFO:tensorflow:Average training steps per second: 359.01
I0901 13:29:03.500372 140315766171648 replay_runner.py:36] Average training steps per second: 359.01
I0901 13:29:03.580280 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.19
INFO:tensorflow:Starting iteration 22

Steps executed: 302 Episode length: 169 Return: -568.86439108615793
INFO:tensorflow:Average training steps per second: 355.98
I0901 13:29:09.561261 140315766171648 replay_runner.py:36] Average training steps per second: 355.98
I0901 13:29:09.734619 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -482.26
INFO:tensorflow:Starting iteration 23

Steps executed: 208 Episode length: 208 Return: -65.234584656294543
INFO:tensorflow:Average training steps per second: 363.78
I0901 13:29:15.570733 140315766171648 replay_runner.py:36] Average training steps per second: 363.78
I0901 13:29:15.698775 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.23
INFO:tensorflow:Starting iteration 24

Steps executed: 248 Episode length: 87 Return: -121.493723874013843
INFO:tensorflow:Average training steps per second: 371.40
I0901 13:29:21.498039 140315766171648 replay_runner.py:36] Average training steps per second: 371.40
I0901 13:29:21.613992 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -383.57
INFO:tensorflow:Starting iteration 25

Steps executed: 213 Episode length: 62 Return: -254.252587552449173
INFO:tensorflow:Average training steps per second: 372.77
I0901 13:29:27.413959 140315766171648 replay_runner.py:36] Average training steps per second: 372.77
I0901 13:29:27.511745 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.94
INFO:tensorflow:Starting iteration 26

Steps executed: 250 Episode length: 104 Return: -856.73728748950743
INFO:tensorflow:Average training steps per second: 393.58
I0901 13:29:33.153200 140315766171648 replay_runner.py:36] Average training steps per second: 393.58
I0901 13:29:33.268491 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -613.13
INFO:tensorflow:Starting iteration 27

Steps executed: 223 Episode length: 68 Return: -474.250223620703543
INFO:tensorflow:Average training steps per second: 392.25
I0901 13:29:38.927204 140315766171648 replay_runner.py:36] Average training steps per second: 392.25
I0901 13:29:39.037148 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -551.96
INFO:tensorflow:Starting iteration 28

Steps executed: 201 Episode length: 78 Return: -754.588757565486843
INFO:tensorflow:Average training steps per second: 407.37
I0901 13:29:44.607177 140315766171648 replay_runner.py:36] Average training steps per second: 407.37
I0901 13:29:44.701070 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -605.46
INFO:tensorflow:Starting iteration 29

Steps executed: 236 Episode length: 86 Return: -341.964522351040843
INFO:tensorflow:Average training steps per second: 415.65
I0901 13:29:49.985068 140315766171648 replay_runner.py:36] Average training steps per second: 415.65

Done fixed training!Episode length: 86 Return: -341.964522351040843