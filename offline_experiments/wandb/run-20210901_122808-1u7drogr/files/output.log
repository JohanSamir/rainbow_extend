Loaded trained dqn in cartpole
Training fixed agent 9, please be patient, may be a while...
I0901 12:28:14.987519 140162147342336 run_experiment.py:549] Creating TrainRunner ...
I0901 12:28:14.997760 140162147342336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:28:14.998024 140162147342336 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:28:14.998204 140162147342336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:28:14.998383 140162147342336 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:28:14.998527 140162147342336 dqn_agent.py:275] 	 update_period: 4
I0901 12:28:14.998749 140162147342336 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:28:14.998888 140162147342336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:28:14.999083 140162147342336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:28:14.999218 140162147342336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:28:14.999338 140162147342336 dqn_agent.py:280] 	 optimizer: adam
I0901 12:28:14.999457 140162147342336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:28:14.999588 140162147342336 dqn_agent.py:283] 	 seed: 1630499294997692
I0901 12:28:15.002941 140162147342336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:28:15.003159 140162147342336 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:28:15.003376 140162147342336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:28:15.003525 140162147342336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:28:15.003659 140162147342336 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:28:15.003820 140162147342336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:28:15.003945 140162147342336 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:28:15.004062 140162147342336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:28:15.004189 140162147342336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:28:15.083068 140162147342336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:28:15.624474 140162147342336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:28:15.639585 140162147342336 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:28:15.647594 140162147342336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:28:15.647806 140162147342336 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:28:15.647912 140162147342336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:28:15.648022 140162147342336 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:28:15.648113 140162147342336 dqn_agent.py:275] 	 update_period: 4
I0901 12:28:15.648208 140162147342336 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:28:15.648454 140162147342336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:28:15.648580 140162147342336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:28:15.648676 140162147342336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:28:15.648776 140162147342336 dqn_agent.py:280] 	 optimizer: adam
I0901 12:28:15.648863 140162147342336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:28:15.648951 140162147342336 dqn_agent.py:283] 	 seed: 1630499295647542
I0901 12:28:15.651245 140162147342336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:28:15.651432 140162147342336 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:28:15.651536 140162147342336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:28:15.651637 140162147342336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:28:15.651913 140162147342336 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:28:15.652001 140162147342336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:28:15.652129 140162147342336 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:28:15.652218 140162147342336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:28:15.652304 140162147342336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:28:15.680934 140162147342336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:28:15.703363 140162147342336 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:28:15.703721 140162147342336 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 147.16
I0901 12:28:22.499752 140162147342336 replay_runner.py:36] Average training steps per second: 147.16
Steps executed: 206 Episode length: 9 Return: 9.0.0
I0901 12:28:23.583470 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.36
INFO:tensorflow:Starting iteration 1

Steps executed: 205 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 200.58
I0901 12:28:28.738730 140162147342336 replay_runner.py:36] Average training steps per second: 200.58
I0901 12:28:28.872512 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.32
INFO:tensorflow:Starting iteration 2
I0901 12:28:29.067105 140162147342336 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 206.23
I0901 12:28:33.916546 140162147342336 replay_runner.py:36] Average training steps per second: 206.23
I0901 12:28:34.069669 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.62
INFO:tensorflow:Starting iteration 3


Steps executed: 202 Episode length: 52 Return: 52.0
INFO:tensorflow:Average training steps per second: 194.55
I0901 12:28:39.398469 140162147342336 replay_runner.py:36] Average training steps per second: 194.55
I0901 12:28:39.531157 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 50.50
INFO:tensorflow:Starting iteration 4

Steps executed: 68 Episode length: 68 Return: 68.00
INFO:tensorflow:Average training steps per second: 197.41

Steps executed: 225 Episode length: 55 Return: 55.0
I0901 12:28:44.929404 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 56.25
INFO:tensorflow:Starting iteration 5

Steps executed: 204 Episode length: 18 Return: 18.0
INFO:tensorflow:Average training steps per second: 190.53
I0901 12:28:50.371595 140162147342336 replay_runner.py:36] Average training steps per second: 190.53
I0901 12:28:50.521739 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 20.40
INFO:tensorflow:Starting iteration 6

Steps executed: 231 Episode length: 67 Return: 67.0
INFO:tensorflow:Average training steps per second: 188.83
I0901 12:28:56.005228 140162147342336 replay_runner.py:36] Average training steps per second: 188.83
I0901 12:28:56.172351 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 57.75
INFO:tensorflow:Starting iteration 7

Steps executed: 203 Episode length: 15 Return: 15.0
INFO:tensorflow:Average training steps per second: 192.25
I0901 12:29:01.570280 140162147342336 replay_runner.py:36] Average training steps per second: 192.25
I0901 12:29:01.723359 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 15.62
INFO:tensorflow:Starting iteration 8
I0901 12:29:01.919538 140162147342336 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 190.54
I0901 12:29:07.168083 140162147342336 replay_runner.py:36] Average training steps per second: 190.54
I0901 12:29:07.309251 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 12.35
INFO:tensorflow:Starting iteration 9


Steps executed: 209 Episode length: 15 Return: 15.0
INFO:tensorflow:Average training steps per second: 188.36
I0901 12:29:12.805772 140162147342336 replay_runner.py:36] Average training steps per second: 188.36
I0901 12:29:12.960437 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 13.93
INFO:tensorflow:Starting iteration 10

Steps executed: 201 Episode length: 11 Return: 11.0
INFO:tensorflow:Average training steps per second: 193.71
I0901 12:29:18.319947 140162147342336 replay_runner.py:36] Average training steps per second: 193.71
I0901 12:29:18.458050 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 11.82
INFO:tensorflow:Starting iteration 11

Steps executed: 386 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 187.01
I0901 12:29:23.992686 140162147342336 replay_runner.py:36] Average training steps per second: 187.01
I0901 12:29:24.252195 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 193.00
INFO:tensorflow:Starting iteration 12

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 195.17
I0901 12:29:29.559998 140162147342336 replay_runner.py:36] Average training steps per second: 195.17
I0901 12:29:29.717828 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 13
I0901 12:29:29.913697 140162147342336 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 193.77
I0901 12:29:35.074899 140162147342336 replay_runner.py:36] Average training steps per second: 193.77
I0901 12:29:35.212342 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 14

Steps executed: 325 Episode length: 169 Return: 169.0
INFO:tensorflow:Average training steps per second: 194.66
I0901 12:29:40.541211 140162147342336 replay_runner.py:36] Average training steps per second: 194.66
I0901 12:29:40.761676 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 162.50
INFO:tensorflow:Starting iteration 15

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 191.52
I0901 12:29:46.178220 140162147342336 replay_runner.py:36] Average training steps per second: 191.52
I0901 12:29:46.318419 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 16
I0901 12:29:46.510231 140162147342336 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 193.24
I0901 12:29:51.685653 140162147342336 replay_runner.py:36] Average training steps per second: 193.24
I0901 12:29:51.822232 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 17
I0901 12:29:52.011513 140162147342336 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 194.96
I0901 12:29:57.141151 140162147342336 replay_runner.py:36] Average training steps per second: 194.96
I0901 12:29:57.277054 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 18

Steps executed: 295 Episode length: 157 Return: 157.0
INFO:tensorflow:Average training steps per second: 191.74
I0901 12:30:02.685365 140162147342336 replay_runner.py:36] Average training steps per second: 191.74
I0901 12:30:02.888686 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 147.50
INFO:tensorflow:Starting iteration 19

Steps executed: 281 Episode length: 146 Return: 146.0
INFO:tensorflow:Average training steps per second: 194.15
I0901 12:30:08.224128 140162147342336 replay_runner.py:36] Average training steps per second: 194.15
I0901 12:30:08.414441 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 140.50
INFO:tensorflow:Starting iteration 20

Steps executed: 303 Episode length: 152 Return: 152.0
INFO:tensorflow:Average training steps per second: 195.54
I0901 12:30:13.722873 140162147342336 replay_runner.py:36] Average training steps per second: 195.54
I0901 12:30:13.932291 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 151.50
INFO:tensorflow:Starting iteration 21
I0901 12:30:14.110461 140162147342336 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 194.16

Steps executed: 346 Episode length: 167 Return: 167.0
I0901 12:30:19.505849 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 173.00
INFO:tensorflow:Starting iteration 22

Steps executed: 346 Episode length: 177 Return: 177.0
INFO:tensorflow:Average training steps per second: 190.77
I0901 12:30:24.940700 140162147342336 replay_runner.py:36] Average training steps per second: 190.77
I0901 12:30:25.193466 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 173.00
INFO:tensorflow:Starting iteration 23

Steps executed: 326 Episode length: 168 Return: 168.0
INFO:tensorflow:Average training steps per second: 194.33
I0901 12:30:30.534428 140162147342336 replay_runner.py:36] Average training steps per second: 194.33
I0901 12:30:30.775742 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 163.00
INFO:tensorflow:Starting iteration 24

Steps executed: 289 Episode length: 146 Return: 146.0
INFO:tensorflow:Average training steps per second: 188.49
I0901 12:30:36.262582 140162147342336 replay_runner.py:36] Average training steps per second: 188.49
I0901 12:30:36.465660 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 144.50
INFO:tensorflow:Starting iteration 25

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 194.58
I0901 12:30:41.799960 140162147342336 replay_runner.py:36] Average training steps per second: 194.58
I0901 12:30:41.949771 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26
I0901 12:30:42.130979 140162147342336 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 191.60
I0901 12:30:47.350565 140162147342336 replay_runner.py:36] Average training steps per second: 191.60
I0901 12:30:47.481375 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 27
I0901 12:30:47.669877 140162147342336 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 198.13
I0901 12:30:52.717696 140162147342336 replay_runner.py:36] Average training steps per second: 198.13
I0901 12:30:52.850059 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 28
I0901 12:30:53.036137 140162147342336 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 201.20
I0901 12:30:58.006774 140162147342336 replay_runner.py:36] Average training steps per second: 201.20
I0901 12:30:58.134828 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 29
I0901 12:30:58.314247 140162147342336 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 197.29

Done fixed training!Episode length: 200 Return: 200.0
I0901 12:31:03.516020 140162147342336 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00