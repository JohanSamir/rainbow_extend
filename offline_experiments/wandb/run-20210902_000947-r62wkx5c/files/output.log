Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0902 00:09:53.649342 139752435963904 run_experiment.py:549] Creating TrainRunner ...
I0902 00:09:53.659536 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:09:53.659722 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:09:53.659817 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:09:53.659899 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:09:53.659986 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0902 00:09:53.660050 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:09:53.660168 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:09:53.660230 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:09:53.660284 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:09:53.660403 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0902 00:09:53.660475 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:09:53.660549 139752435963904 dqn_agent.py:283] 	 seed: 1630541393659490
I0902 00:09:53.663950 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:09:53.664169 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:09:53.664270 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:09:53.664351 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:09:53.664415 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:09:53.664476 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:09:53.664587 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:09:53.664777 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:09:53.664923 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:09:53.704099 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:09:54.081916 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:09:54.094813 139752435963904 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:09:54.103662 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:09:54.103863 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:09:54.103956 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:09:54.104027 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:09:54.104113 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0902 00:09:54.104180 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:09:54.104307 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:09:54.104401 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:09:54.104467 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:09:54.104570 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0902 00:09:54.104638 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:09:54.104699 139752435963904 dqn_agent.py:283] 	 seed: 1630541394103620
I0902 00:09:54.107694 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:09:54.107980 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:09:54.108103 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:09:54.108193 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:09:54.108330 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:09:54.108535 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:09:54.108674 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:09:54.108804 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:09:54.108937 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:09:54.183128 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:09:54.205217 139752435963904 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:09:54.205537 139752435963904 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 161.97
I0902 00:10:00.379882 139752435963904 replay_runner.py:36] Average training steps per second: 161.97
I0902 00:10:01.903722 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -355.51
Steps executed: 203 Episode length: 103 Return: -311.9320424487835
INFO:tensorflow:Starting iteration 1

Steps executed: 269 Episode length: 124 Return: -399.66306007783277
INFO:tensorflow:Average training steps per second: 229.37
I0902 00:10:10.649158 139752435963904 replay_runner.py:36] Average training steps per second: 229.37
I0902 00:10:10.880955 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.21
INFO:tensorflow:Starting iteration 2

Steps executed: 330 Episode length: 155 Return: -340.44152237816627
INFO:tensorflow:Average training steps per second: 223.09
I0902 00:10:19.524800 139752435963904 replay_runner.py:36] Average training steps per second: 223.09
I0902 00:10:19.817687 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -347.80
INFO:tensorflow:Starting iteration 3

Steps executed: 315 Episode length: 135 Return: -501.59078656350927
INFO:tensorflow:Average training steps per second: 225.01
I0902 00:10:28.650909 139752435963904 replay_runner.py:36] Average training steps per second: 225.01
I0902 00:10:28.944441 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -494.65
INFO:tensorflow:Starting iteration 4

Steps executed: 207 Episode length: 55 Return: -102.558299397453587
INFO:tensorflow:Average training steps per second: 225.87
I0902 00:10:37.699483 139752435963904 replay_runner.py:36] Average training steps per second: 225.87
I0902 00:10:37.875422 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -354.16
INFO:tensorflow:Starting iteration 5
I0902 00:10:42.064291 139752435963904 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 231.55

Steps executed: 1000 Episode length: 1000 Return: -40.08368190608088
I0902 00:10:49.873381 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -40.08
INFO:tensorflow:Starting iteration 6
I0902 00:10:54.269877 139752435963904 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 229.60

Steps executed: 656 Episode length: 656 Return: -521.650764179177388
I0902 00:10:59.763102 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -521.65
INFO:tensorflow:Starting iteration 7
I0902 00:11:04.030496 139752435963904 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 224.95

Steps executed: 804 Episode length: 804 Return: -370.858659238253388
I0902 00:11:10.213177 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -370.86
INFO:tensorflow:Starting iteration 8
I0902 00:11:14.658824 139752435963904 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 218.40

Steps executed: 1000 Episode length: 1000 Return: -262.8767263380745
I0902 00:11:22.086819 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.88
INFO:tensorflow:Starting iteration 9

Steps executed: 311 Episode length: 311 Return: -212.060983187797865
INFO:tensorflow:Average training steps per second: 226.65
I0902 00:11:30.820266 139752435963904 replay_runner.py:36] Average training steps per second: 226.65
I0902 00:11:31.168798 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.06
INFO:tensorflow:Starting iteration 10

Steps executed: 318 Episode length: 318 Return: -337.399096856328865
INFO:tensorflow:Average training steps per second: 223.61
I0902 00:11:39.953013 139752435963904 replay_runner.py:36] Average training steps per second: 223.61
I0902 00:11:40.319613 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -337.40
INFO:tensorflow:Starting iteration 11
I0902 00:11:44.582180 139752435963904 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 223.73
I0902 00:11:49.052447 139752435963904 replay_runner.py:36] Average training steps per second: 223.73

Steps executed: 1000 Episode length: 1000 Return: -293.05495974707384
INFO:tensorflow:Starting iteration 12

Steps executed: 370 Episode length: 370 Return: -187.4412376503623384
INFO:tensorflow:Average training steps per second: 236.88
I0902 00:12:00.194013 139752435963904 replay_runner.py:36] Average training steps per second: 236.88
I0902 00:12:00.765590 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.44
INFO:tensorflow:Starting iteration 13
I0902 00:12:05.044496 139752435963904 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 232.00
I0902 00:12:09.355569 139752435963904 replay_runner.py:36] Average training steps per second: 232.00

Steps executed: 932 Episode length: 932 Return: -451.6727813003830684
INFO:tensorflow:Starting iteration 14
I0902 00:12:16.184989 139752435963904 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 230.02

Steps executed: 529 Episode length: 529 Return: -420.0714421921104684
I0902 00:12:21.773992 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -420.07
INFO:tensorflow:Starting iteration 15
I0902 00:12:26.015579 139752435963904 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 233.33

Steps executed: 1000 Episode length: 1000 Return: -113.19703253526355
I0902 00:12:33.035871 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.20
INFO:tensorflow:Starting iteration 16

Steps executed: 337 Episode length: 155 Return: -107.1600404500639355
INFO:tensorflow:Average training steps per second: 223.33
I0902 00:12:41.896456 139752435963904 replay_runner.py:36] Average training steps per second: 223.33
I0902 00:12:42.216688 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.48
INFO:tensorflow:Starting iteration 17

Steps executed: 237 Episode length: 237 Return: -486.2024155419989655
INFO:tensorflow:Average training steps per second: 224.80
I0902 00:12:50.914322 139752435963904 replay_runner.py:36] Average training steps per second: 224.80
I0902 00:12:51.174639 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -486.20
INFO:tensorflow:Starting iteration 18

Steps executed: 307 Episode length: 145 Return: -109.5246092761702855
INFO:tensorflow:Average training steps per second: 221.83
I0902 00:13:00.066507 139752435963904 replay_runner.py:36] Average training steps per second: 221.83
I0902 00:13:00.328155 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -257.42
INFO:tensorflow:Starting iteration 19

Steps executed: 112 Episode length: 112 Return: -209.7950527501527655
INFO:tensorflow:Average training steps per second: 220.97

Steps executed: 1112 Episode length: 1000 Return: -258.12918993944125
I0902 00:13:12.749842 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.96
INFO:tensorflow:Starting iteration 20

Steps executed: 126 Episode length: 126 Return: -101.6961764646623725
INFO:tensorflow:Average training steps per second: 229.18

Steps executed: 362 Episode length: 236 Return: -355.8682591923048725
I0902 00:13:21.929402 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.78
INFO:tensorflow:Starting iteration 21

Steps executed: 227 Episode length: 227 Return: -121.5466370137790525
INFO:tensorflow:Average training steps per second: 227.05
I0902 00:13:30.696919 139752435963904 replay_runner.py:36] Average training steps per second: 227.05
I0902 00:13:30.959336 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.55
INFO:tensorflow:Starting iteration 22

Steps executed: 302 Episode length: 180 Return: -78.76697371806536525
INFO:tensorflow:Average training steps per second: 233.99
I0902 00:13:39.624594 139752435963904 replay_runner.py:36] Average training steps per second: 233.99
I0902 00:13:39.881963 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.54
INFO:tensorflow:Starting iteration 23

Steps executed: 268 Episode length: 268 Return: -136.8545785971597325
INFO:tensorflow:Average training steps per second: 228.12
I0902 00:13:48.765319 139752435963904 replay_runner.py:36] Average training steps per second: 228.12
I0902 00:13:49.103977 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.85
INFO:tensorflow:Starting iteration 24
I0902 00:13:53.520646 139752435963904 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 223.17

Steps executed: 237 Episode length: 237 Return: -59.26216573074112325
I0902 00:13:58.304493 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -59.26
INFO:tensorflow:Starting iteration 25

Steps executed: 255 Episode length: 71 Return: -206.00760695415676425
INFO:tensorflow:Average training steps per second: 224.45
I0902 00:14:07.093554 139752435963904 replay_runner.py:36] Average training steps per second: 224.45
I0902 00:14:07.310544 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -319.10
INFO:tensorflow:Starting iteration 26
I0902 00:14:11.627810 139752435963904 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 220.24

Steps executed: 328 Episode length: 163 Return: -61.88317121351965825
I0902 00:14:16.484263 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.51
INFO:tensorflow:Starting iteration 27

Steps executed: 204 Episode length: 111 Return: -295.8139690059161825
INFO:tensorflow:Average training steps per second: 226.74
I0902 00:14:25.286015 139752435963904 replay_runner.py:36] Average training steps per second: 226.74
I0902 00:14:25.481989 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.14
INFO:tensorflow:Starting iteration 28
I0902 00:14:29.645890 139752435963904 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 218.19

Steps executed: 209 Episode length: 150 Return: -82.20902912813321825
I0902 00:14:34.440865 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.33
INFO:tensorflow:Starting iteration 29

Steps executed: 437 Episode length: 324 Return: 219.95304565823528825
INFO:tensorflow:Average training steps per second: 230.62
I0902 00:14:43.112087 139752435963904 replay_runner.py:36] Average training steps per second: 230.62

Done fixed training!Episode length: 324 Return: 219.95304565823528825