I0828 10:47:10.627211 139779140274176 run_experiment.py:549] Creating TrainRunner ...
I0828 10:47:10.634529 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:47:10.634660 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:47:10.634733 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:47:10.634874 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:47:10.634933 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:47:10.634991 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:47:10.635182 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:47:10.635250 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:47:10.635311 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:47:10.635372 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:47:10.635447 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:47:10.635504 139779140274176 dqn_agent.py:283] 	 seed: 1630147630634497
I0828 10:47:10.637566 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:47:10.637689 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:47:10.637780 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:47:10.637857 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:47:10.637928 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:47:10.637995 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:47:10.638060 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:47:10.638136 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:47:10.638206 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:47:10.663971 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:10.923096 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:10.932641 139779140274176 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:47:10.940076 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:47:10.940247 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:47:10.940354 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:47:10.940414 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:47:10.940469 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:47:10.940521 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:47:10.940697 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:47:10.940832 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:47:10.940919 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:47:10.941013 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:47:10.941090 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:47:10.941152 139779140274176 dqn_agent.py:283] 	 seed: 1630147630940039
I0828 10:47:10.942733 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:47:10.942898 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:47:10.943060 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:47:10.943147 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:47:10.943215 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:47:10.943341 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:47:10.943464 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:47:10.943559 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:47:10.943683 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:47:10.963814 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:47:10.979333 139779140274176 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:47:10.979537 139779140274176 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 254.78
I0828 10:47:14.904726 139779140274176 replay_runner.py:36] Average training steps per second: 254.78
I0828 10:47:15.713930 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -340.46
Steps executed: 245 Episode length: 157 Return: -318.882340888699
INFO:tensorflow:Starting iteration 1
I0828 10:47:19.158031 139779140274176 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 346.17
I0828 10:47:22.047079 139779140274176 replay_runner.py:36] Average training steps per second: 346.17

Steps executed: 248 Episode length: 248 Return: 210.52833991531764
INFO:tensorflow:Starting iteration 2
I0828 10:47:25.624874 139779140274176 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 327.45
I0828 10:47:28.679187 139779140274176 replay_runner.py:36] Average training steps per second: 327.45

Steps executed: 261 Episode length: 144 Return: -161.28223853547007
INFO:tensorflow:Starting iteration 3
I0828 10:47:32.206040 139779140274176 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 347.18

Steps executed: 943 Episode length: 943 Return: -266.38105689790237
I0828 10:47:36.676516 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.38
INFO:tensorflow:Starting iteration 4

Steps executed: 1000 Episode length: 1000 Return: -126.39191366360457
INFO:tensorflow:Average training steps per second: 344.16
I0828 10:47:42.973255 139779140274176 replay_runner.py:36] Average training steps per second: 344.16
I0828 10:47:44.107513 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.39
INFO:tensorflow:Starting iteration 5
I0828 10:47:47.532590 139779140274176 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 367.60

Steps executed: 1000 Episode length: 1000 Return: -156.36024891495705
I0828 10:47:53.029770 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.36
INFO:tensorflow:Starting iteration 6
I0828 10:47:56.378571 139779140274176 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 352.98

Steps executed: 1000 Episode length: 1000 Return: -136.92064513826378
I0828 10:48:00.888142 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.92
INFO:tensorflow:Starting iteration 7

Steps executed: 834 Episode length: 834 Return: -347.5033761397351378
INFO:tensorflow:Average training steps per second: 346.00
I0828 10:48:07.081331 139779140274176 replay_runner.py:36] Average training steps per second: 346.00
I0828 10:48:08.416563 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -347.50
INFO:tensorflow:Starting iteration 8
I0828 10:48:11.694389 139779140274176 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 356.87

Steps executed: 701 Episode length: 701 Return: -294.2193452363267378
I0828 10:48:15.335631 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -294.22
INFO:tensorflow:Starting iteration 9
I0828 10:48:18.708147 139779140274176 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 360.77

Steps executed: 1000 Episode length: 1000 Return: -347.05652309160945
I0828 10:48:22.934952 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -347.06
INFO:tensorflow:Starting iteration 10

Steps executed: 321 Episode length: 321 Return: -296.6619415066104945
INFO:tensorflow:Average training steps per second: 342.34
I0828 10:48:29.169967 139779140274176 replay_runner.py:36] Average training steps per second: 342.34
I0828 10:48:29.480309 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.66
INFO:tensorflow:Starting iteration 11

Steps executed: 714 Episode length: 714 Return: -309.0913730568317445
INFO:tensorflow:Average training steps per second: 363.58
I0828 10:48:35.668720 139779140274176 replay_runner.py:36] Average training steps per second: 363.58
I0828 10:48:36.590640 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.09
INFO:tensorflow:Starting iteration 12

Steps executed: 1000 Episode length: 1000 Return: -195.97474742096955
INFO:tensorflow:Average training steps per second: 350.80
I0828 10:48:42.875114 139779140274176 replay_runner.py:36] Average training steps per second: 350.80
I0828 10:48:44.592521 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.97
INFO:tensorflow:Starting iteration 13
I0828 10:48:48.041970 139779140274176 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 359.66

Steps executed: 1000 Episode length: 1000 Return: -162.02808100089777
I0828 10:48:53.789512 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.03
INFO:tensorflow:Starting iteration 14
I0828 10:48:57.004886 139779140274176 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 337.00

Steps executed: 1000 Episode length: 1000 Return: -175.10308157518472
I0828 10:49:02.834928 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.10
INFO:tensorflow:Starting iteration 15

Steps executed: 573 Episode length: 573 Return: -93.05087499302161472
INFO:tensorflow:Average training steps per second: 309.12
I0828 10:49:09.221749 139779140274176 replay_runner.py:36] Average training steps per second: 309.12
I0828 10:49:10.149741 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.05
INFO:tensorflow:Starting iteration 16

Steps executed: 272 Episode length: 272 Return: -523.3158282893991472
INFO:tensorflow:Average training steps per second: 314.08
I0828 10:49:16.282717 139779140274176 replay_runner.py:36] Average training steps per second: 314.08
I0828 10:49:16.504736 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -523.32
INFO:tensorflow:Starting iteration 17
I0828 10:49:19.621278 139779140274176 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 326.48

Steps executed: 371 Episode length: 371 Return: -203.6688371014781472
I0828 10:49:23.160786 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.67
INFO:tensorflow:Starting iteration 18

Steps executed: 273 Episode length: 273 Return: -314.7252373419481472
INFO:tensorflow:Average training steps per second: 334.27
I0828 10:49:29.385786 139779140274176 replay_runner.py:36] Average training steps per second: 334.27
I0828 10:49:29.633647 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.73
INFO:tensorflow:Starting iteration 19

Steps executed: 340 Episode length: 188 Return: -187.7493337182235572
INFO:tensorflow:Average training steps per second: 332.47
I0828 10:49:35.943477 139779140274176 replay_runner.py:36] Average training steps per second: 332.47
I0828 10:49:36.162279 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -150.08
INFO:tensorflow:Starting iteration 20
I0828 10:49:39.444668 139779140274176 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 341.17
I0828 10:49:42.375998 139779140274176 replay_runner.py:36] Average training steps per second: 341.17

Steps executed: 295 Episode length: 295 Return: -602.1452700564665572
INFO:tensorflow:Starting iteration 21
I0828 10:49:46.069163 139779140274176 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 341.73

Steps executed: 204 Episode length: 204 Return: -246.0315634122193672
I0828 10:49:49.158277 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -246.03
INFO:tensorflow:Starting iteration 22

Steps executed: 139 Episode length: 139 Return: -129.1728922451244272
INFO:tensorflow:Average training steps per second: 350.68
I0828 10:49:55.417975 139779140274176 replay_runner.py:36] Average training steps per second: 350.68

Steps executed: 1099 Episode length: 960 Return: 208.9391188949343272
INFO:tensorflow:Starting iteration 23

Steps executed: 438 Episode length: 438 Return: -73.64504526350893272
INFO:tensorflow:Average training steps per second: 316.33
I0828 10:50:03.523454 139779140274176 replay_runner.py:36] Average training steps per second: 316.33
I0828 10:50:04.133227 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.65
INFO:tensorflow:Starting iteration 24
I0828 10:50:07.329194 139779140274176 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 324.43

Steps executed: 727 Episode length: 727 Return: -116.0602134406371272
I0828 10:50:12.016520 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.06
INFO:tensorflow:Starting iteration 25

Steps executed: 288 Episode length: 150 Return: -571.1220319466288272
INFO:tensorflow:Average training steps per second: 342.83
I0828 10:50:18.400749 139779140274176 replay_runner.py:36] Average training steps per second: 342.83
I0828 10:50:18.559474 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.38
INFO:tensorflow:Starting iteration 26
I0828 10:50:21.909011 139779140274176 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 339.76

Steps executed: 754 Episode length: 591 Return: -494.9002370626951772
I0828 10:50:25.674684 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.40
INFO:tensorflow:Starting iteration 27

Steps executed: 227 Episode length: 131 Return: -112.7745554522359672
INFO:tensorflow:Average training steps per second: 347.73
I0828 10:50:31.792693 139779140274176 replay_runner.py:36] Average training steps per second: 347.73
I0828 10:50:31.902370 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.40
INFO:tensorflow:Starting iteration 28

Steps executed: 233 Episode length: 233 Return: -473.8924964987394372
INFO:tensorflow:Average training steps per second: 363.69
I0828 10:50:37.952727 139779140274176 replay_runner.py:36] Average training steps per second: 363.69
I0828 10:50:38.105504 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -473.89
INFO:tensorflow:Starting iteration 29

Steps executed: 242 Episode length: 53 Return: -135.67157346775283372
INFO:tensorflow:Average training steps per second: 342.40
I0828 10:50:44.296292 139779140274176 replay_runner.py:36] Average training steps per second: 342.40

Done fixed training!Episode length: 53 Return: -135.67157346775283372