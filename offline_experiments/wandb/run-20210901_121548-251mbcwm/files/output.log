Loaded trained dqn in acrobot
Training fixed agent 1, please be patient, may be a while...
I0901 12:15:55.509802 140583573075968 run_experiment.py:549] Creating TrainRunner ...
I0901 12:15:55.519291 140583573075968 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:15:55.519531 140583573075968 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:15:55.519676 140583573075968 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:15:55.519774 140583573075968 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:15:55.519856 140583573075968 dqn_agent.py:275] 	 update_period: 4
I0901 12:15:55.519940 140583573075968 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:15:55.520020 140583573075968 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:15:55.520104 140583573075968 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:15:55.520273 140583573075968 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:15:55.520367 140583573075968 dqn_agent.py:280] 	 optimizer: adam
I0901 12:15:55.520449 140583573075968 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:15:55.520529 140583573075968 dqn_agent.py:283] 	 seed: 1630498555519217
I0901 12:15:55.523042 140583573075968 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:15:55.523228 140583573075968 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 12:15:55.523361 140583573075968 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:15:55.523466 140583573075968 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:15:55.523561 140583573075968 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:15:55.523648 140583573075968 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:15:55.523734 140583573075968 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:15:55.523821 140583573075968 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:15:55.523946 140583573075968 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:15:55.580798 140583573075968 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:15:56.013656 140583573075968 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:15:56.040206 140583573075968 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:15:56.050171 140583573075968 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:15:56.052005 140583573075968 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:15:56.052222 140583573075968 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:15:56.052366 140583573075968 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:15:56.052538 140583573075968 dqn_agent.py:275] 	 update_period: 4
I0901 12:15:56.052601 140583573075968 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:15:56.052663 140583573075968 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:15:56.052717 140583573075968 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:15:56.052850 140583573075968 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:15:56.052970 140583573075968 dqn_agent.py:280] 	 optimizer: adam
I0901 12:15:56.053078 140583573075968 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:15:56.053182 140583573075968 dqn_agent.py:283] 	 seed: 1630498556050093
I0901 12:15:56.055808 140583573075968 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:15:56.055979 140583573075968 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 12:15:56.056067 140583573075968 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:15:56.056136 140583573075968 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:15:56.056195 140583573075968 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:15:56.056303 140583573075968 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:15:56.056414 140583573075968 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:15:56.056504 140583573075968 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:15:56.056591 140583573075968 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:15:56.090664 140583573075968 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:15:56.112770 140583573075968 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:15:56.113116 140583573075968 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 143.06
I0901 12:16:03.103545 140583573075968 replay_runner.py:36] Average training steps per second: 143.06
Steps executed: 216 Episode length: 216 Return: -215.0
I0901 12:16:04.323901 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.00
INFO:tensorflow:Starting iteration 1

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 194.39
I0901 12:16:09.703849 140583573075968 replay_runner.py:36] Average training steps per second: 194.39
I0901 12:16:10.117342 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 2
I0901 12:16:10.373182 140583573075968 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 185.46
I0901 12:16:15.765624 140583573075968 replay_runner.py:36] Average training steps per second: 185.46
I0901 12:16:16.192912 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 3

Steps executed: 352 Episode length: 169 Return: -168.0
INFO:tensorflow:Average training steps per second: 189.33
I0901 12:16:21.723621 140583573075968 replay_runner.py:36] Average training steps per second: 189.33
I0901 12:16:22.042605 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.33
INFO:tensorflow:Starting iteration 4

Steps executed: 207 Episode length: 207 Return: -206.0
INFO:tensorflow:Average training steps per second: 187.10
I0901 12:16:27.647212 140583573075968 replay_runner.py:36] Average training steps per second: 187.10
I0901 12:16:27.823604 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.00
INFO:tensorflow:Starting iteration 5
I0901 12:16:28.066083 140583573075968 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 192.70

Steps executed: 239 Episode length: 101 Return: -100.0
I0901 12:16:33.470485 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.50
INFO:tensorflow:Starting iteration 6
I0901 12:16:33.724487 140583573075968 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 187.09

Steps executed: 500 Episode length: 500 Return: -500.0
I0901 12:16:39.498929 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7

Steps executed: 232 Episode length: 232 Return: -231.0
INFO:tensorflow:Average training steps per second: 191.87
I0901 12:16:44.953442 140583573075968 replay_runner.py:36] Average training steps per second: 191.87
I0901 12:16:45.160694 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.00
INFO:tensorflow:Starting iteration 8

Steps executed: 236 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Average training steps per second: 187.57
I0901 12:16:50.741040 140583573075968 replay_runner.py:36] Average training steps per second: 187.57
I0901 12:16:50.934435 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.67
INFO:tensorflow:Starting iteration 9

Steps executed: 260 Episode length: 71 Return: -70.0.0
INFO:tensorflow:Average training steps per second: 185.62
I0901 12:16:56.561064 140583573075968 replay_runner.py:36] Average training steps per second: 185.62
I0901 12:16:56.789721 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.67
INFO:tensorflow:Starting iteration 10

Steps executed: 255 Episode length: 84 Return: -83.0.0
INFO:tensorflow:Average training steps per second: 188.20
I0901 12:17:02.332367 140583573075968 replay_runner.py:36] Average training steps per second: 188.20
I0901 12:17:02.562081 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.00
INFO:tensorflow:Starting iteration 11

Steps executed: 206 Episode length: 101 Return: -100.0
INFO:tensorflow:Average training steps per second: 192.21
I0901 12:17:08.011384 140583573075968 replay_runner.py:36] Average training steps per second: 192.21
I0901 12:17:08.208614 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.00
INFO:tensorflow:Starting iteration 12

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 190.17
I0901 12:17:13.695861 140583573075968 replay_runner.py:36] Average training steps per second: 190.17
I0901 12:17:14.126725 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 13
I0901 12:17:14.368617 140583573075968 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 189.32

Steps executed: 258 Episode length: 76 Return: -75.0.0
I0901 12:17:19.892966 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.00
INFO:tensorflow:Starting iteration 14
I0901 12:17:20.148447 140583573075968 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 184.43

Steps executed: 289 Episode length: 123 Return: -122.0
I0901 12:17:25.846472 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.33
INFO:tensorflow:Starting iteration 15
I0901 12:17:26.098902 140583573075968 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 191.97
I0901 12:17:31.308379 140583573075968 replay_runner.py:36] Average training steps per second: 191.97

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Starting iteration 16

Steps executed: 287 Episode length: 107 Return: -106.0
INFO:tensorflow:Average training steps per second: 194.17
I0901 12:17:37.126157 140583573075968 replay_runner.py:36] Average training steps per second: 194.17
I0901 12:17:37.382731 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.67
INFO:tensorflow:Starting iteration 17

Steps executed: 234 Episode length: 132 Return: -131.0
INFO:tensorflow:Average training steps per second: 187.15
I0901 12:17:42.971490 140583573075968 replay_runner.py:36] Average training steps per second: 187.15
I0901 12:17:43.202602 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.00
INFO:tensorflow:Starting iteration 18

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 191.21
I0901 12:17:48.683739 140583573075968 replay_runner.py:36] Average training steps per second: 191.21
I0901 12:17:49.112633 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 19
I0901 12:17:49.340339 140583573075968 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 184.49
I0901 12:17:54.761107 140583573075968 replay_runner.py:36] Average training steps per second: 184.49
I0901 12:17:55.208490 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 20

Steps executed: 266 Episode length: 118 Return: -117.0
INFO:tensorflow:Average training steps per second: 196.76
I0901 12:18:00.528033 140583573075968 replay_runner.py:36] Average training steps per second: 196.76
I0901 12:18:00.774615 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.67
INFO:tensorflow:Starting iteration 21

Steps executed: 224 Episode length: 153 Return: -152.0
INFO:tensorflow:Average training steps per second: 189.09
I0901 12:18:06.297467 140583573075968 replay_runner.py:36] Average training steps per second: 189.09
I0901 12:18:06.490608 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.00
INFO:tensorflow:Starting iteration 22

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 190.35
I0901 12:18:11.994693 140583573075968 replay_runner.py:36] Average training steps per second: 190.35
I0901 12:18:12.444565 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 23

Steps executed: 262 Episode length: 95 Return: -94.0.0
INFO:tensorflow:Average training steps per second: 200.92
I0901 12:18:17.671901 140583573075968 replay_runner.py:36] Average training steps per second: 200.92
I0901 12:18:17.896993 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.33
INFO:tensorflow:Starting iteration 24

Steps executed: 64 Episode length: 64 Return: -63.00.0
INFO:tensorflow:Average training steps per second: 190.08
I0901 12:18:23.410301 140583573075968 replay_runner.py:36] Average training steps per second: 190.08

Steps executed: 265 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Starting iteration 25

Steps executed: 146 Episode length: 73 Return: -72.0.0
INFO:tensorflow:Average training steps per second: 184.63
I0901 12:18:29.310848 140583573075968 replay_runner.py:36] Average training steps per second: 184.63

Steps executed: 266 Episode length: 120 Return: -119.0
INFO:tensorflow:Starting iteration 26

Steps executed: 243 Episode length: 80 Return: -79.0.0
INFO:tensorflow:Average training steps per second: 196.59
I0901 12:18:34.911045 140583573075968 replay_runner.py:36] Average training steps per second: 196.59
I0901 12:18:35.120929 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.00
INFO:tensorflow:Starting iteration 27

Steps executed: 271 Episode length: 120 Return: -119.0
INFO:tensorflow:Average training steps per second: 195.98
I0901 12:18:40.449275 140583573075968 replay_runner.py:36] Average training steps per second: 195.98
I0901 12:18:40.664877 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.33
INFO:tensorflow:Starting iteration 28
I0901 12:18:40.905883 140583573075968 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 210.51
I0901 12:18:45.656692 140583573075968 replay_runner.py:36] Average training steps per second: 210.51

Steps executed: 256 Episode length: 96 Return: -95.0.0
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 63 Return: -62.0.0
INFO:tensorflow:Average training steps per second: 200.57
I0901 12:18:51.090706 140583573075968 replay_runner.py:36] Average training steps per second: 200.57
I0901 12:18:51.253086 140583573075968 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.00