Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0901 13:05:05.999601 140536266098688 run_experiment.py:549] Creating TrainRunner ...
I0901 13:05:06.009186 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:05:06.009393 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:05:06.009491 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:05:06.009577 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:05:06.009655 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 13:05:06.009752 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:05:06.009831 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:05:06.009883 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:05:06.009951 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:05:06.010039 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 13:05:06.010162 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:05:06.010247 140536266098688 dqn_agent.py:283] 	 seed: 1630501506009105
I0901 13:05:06.012962 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:05:06.013153 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:05:06.013480 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:05:06.013585 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:05:06.013659 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:05:06.013752 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:05:06.013904 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:05:06.014029 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:05:06.014162 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:05:06.046950 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:05:06.368525 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:05:06.378834 140536266098688 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:05:06.387972 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:05:06.388164 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:05:06.388345 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:05:06.388426 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:05:06.388486 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 13:05:06.388544 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:05:06.388751 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:05:06.388912 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:05:06.389004 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:05:06.389087 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 13:05:06.389173 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:05:06.389260 140536266098688 dqn_agent.py:283] 	 seed: 1630501506387928
I0901 13:05:06.391158 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:05:06.391304 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:05:06.391458 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:05:06.391544 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:05:06.391614 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:05:06.391686 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:05:06.391755 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:05:06.391816 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:05:06.391971 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:05:06.421297 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:05:06.438975 140536266098688 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:05:06.439189 140536266098688 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 195.28
I0901 13:05:11.560137 140536266098688 replay_runner.py:36] Average training steps per second: 195.28
Steps executed: 223 Episode length: 135 Return: -367.55516725789846
I0901 13:05:12.446688 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -512.81
INFO:tensorflow:Starting iteration 1

Steps executed: 212 Episode length: 95 Return: -767.218814309533605
INFO:tensorflow:Average training steps per second: 283.59
I0901 13:05:19.870337 140536266098688 replay_runner.py:36] Average training steps per second: 283.59
I0901 13:05:20.023275 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -525.99
INFO:tensorflow:Starting iteration 2

Steps executed: 250 Episode length: 131 Return: -418.45006023096188
INFO:tensorflow:Average training steps per second: 279.10
I0901 13:05:27.412654 140536266098688 replay_runner.py:36] Average training steps per second: 279.10
I0901 13:05:27.585870 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.83
INFO:tensorflow:Starting iteration 3

Steps executed: 243 Episode length: 114 Return: -180.89583882179198
INFO:tensorflow:Average training steps per second: 281.93
I0901 13:05:34.914443 140536266098688 replay_runner.py:36] Average training steps per second: 281.93
I0901 13:05:35.075055 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.61
INFO:tensorflow:Starting iteration 4

Steps executed: 236 Episode length: 118 Return: -296.11354379213776
INFO:tensorflow:Average training steps per second: 289.85
I0901 13:05:42.296898 140536266098688 replay_runner.py:36] Average training steps per second: 289.85
I0901 13:05:42.443190 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -247.67
INFO:tensorflow:Starting iteration 5

Steps executed: 171 Episode length: 171 Return: 29.0607822388539976
INFO:tensorflow:Average training steps per second: 293.39
I0901 13:05:49.545761 140536266098688 replay_runner.py:36] Average training steps per second: 293.39

Steps executed: 402 Episode length: 231 Return: -127.48100846335433
INFO:tensorflow:Starting iteration 6

Steps executed: 224 Episode length: 90 Return: -321.528112262828873
INFO:tensorflow:Average training steps per second: 310.05
I0901 13:05:56.693286 140536266098688 replay_runner.py:36] Average training steps per second: 310.05
I0901 13:05:56.819834 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.71
INFO:tensorflow:Starting iteration 7

Steps executed: 244 Episode length: 70 Return: -175.339832416121573
INFO:tensorflow:Average training steps per second: 313.29
I0901 13:06:03.602813 140536266098688 replay_runner.py:36] Average training steps per second: 313.29
I0901 13:06:03.737858 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -318.16
INFO:tensorflow:Starting iteration 8

Steps executed: 267 Episode length: 143 Return: -149.22941046488938
INFO:tensorflow:Average training steps per second: 306.87
I0901 13:06:10.526962 140536266098688 replay_runner.py:36] Average training steps per second: 306.87
I0901 13:06:10.710591 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.60
INFO:tensorflow:Starting iteration 9

Steps executed: 220 Episode length: 119 Return: -275.33782145105576
INFO:tensorflow:Average training steps per second: 301.73
I0901 13:06:17.558327 140536266098688 replay_runner.py:36] Average training steps per second: 301.73
I0901 13:06:17.691598 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.16
INFO:tensorflow:Starting iteration 10

Steps executed: 227 Episode length: 65 Return: -369.950279235121976
INFO:tensorflow:Average training steps per second: 309.44
I0901 13:06:24.334205 140536266098688 replay_runner.py:36] Average training steps per second: 309.44
I0901 13:06:24.439940 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -376.05
INFO:tensorflow:Starting iteration 11

Steps executed: 222 Episode length: 79 Return: -273.007849073937926
INFO:tensorflow:Average training steps per second: 308.09
I0901 13:06:31.091751 140536266098688 replay_runner.py:36] Average training steps per second: 308.09
I0901 13:06:31.201309 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.29
INFO:tensorflow:Starting iteration 12

Steps executed: 215 Episode length: 57 Return: -370.588852126670926
INFO:tensorflow:Average training steps per second: 296.00
I0901 13:06:37.969649 140536266098688 replay_runner.py:36] Average training steps per second: 296.00
I0901 13:06:38.130017 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.43
INFO:tensorflow:Starting iteration 13

Steps executed: 243 Episode length: 72 Return: -59.5527520222528875
INFO:tensorflow:Average training steps per second: 312.76
I0901 13:06:44.765716 140536266098688 replay_runner.py:36] Average training steps per second: 312.76
I0901 13:06:44.900229 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -240.24
INFO:tensorflow:Starting iteration 14

Steps executed: 290 Episode length: 130 Return: -466.99399776602235
INFO:tensorflow:Average training steps per second: 311.41
I0901 13:06:51.511310 140536266098688 replay_runner.py:36] Average training steps per second: 311.41
I0901 13:06:51.693407 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -373.42
INFO:tensorflow:Starting iteration 15
I0901 13:06:55.067049 140536266098688 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 312.04

Steps executed: 238 Episode length: 54 Return: -378.733240563844965
I0901 13:06:58.405252 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.76
INFO:tensorflow:Starting iteration 16

Steps executed: 278 Episode length: 104 Return: -267.57821206347335
INFO:tensorflow:Average training steps per second: 308.59
I0901 13:07:05.025608 140536266098688 replay_runner.py:36] Average training steps per second: 308.59
I0901 13:07:05.166375 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.44
INFO:tensorflow:Starting iteration 17

Steps executed: 253 Episode length: 73 Return: -5.35256063743999325
INFO:tensorflow:Average training steps per second: 313.19
I0901 13:07:11.722242 140536266098688 replay_runner.py:36] Average training steps per second: 313.19
I0901 13:07:11.860253 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.34
INFO:tensorflow:Starting iteration 18

Steps executed: 235 Episode length: 75 Return: -291.613775348949525
INFO:tensorflow:Average training steps per second: 308.60
I0901 13:07:18.479719 140536266098688 replay_runner.py:36] Average training steps per second: 308.60
I0901 13:07:18.604362 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.21
INFO:tensorflow:Starting iteration 19

Steps executed: 245 Episode length: 87 Return: -122.439499449043385
INFO:tensorflow:Average training steps per second: 308.93
I0901 13:07:25.198682 140536266098688 replay_runner.py:36] Average training steps per second: 308.93
I0901 13:07:25.322894 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.95
INFO:tensorflow:Starting iteration 20

Steps executed: 127 Episode length: 74 Return: -76.3142349743665385
INFO:tensorflow:Average training steps per second: 313.68
I0901 13:07:31.873823 140536266098688 replay_runner.py:36] Average training steps per second: 313.68

Steps executed: 278 Episode length: 88 Return: -264.844331382096385
INFO:tensorflow:Starting iteration 21

Steps executed: 243 Episode length: 96 Return: -183.586402733409285
INFO:tensorflow:Average training steps per second: 307.22
I0901 13:07:38.633842 140536266098688 replay_runner.py:36] Average training steps per second: 307.22
I0901 13:07:38.759097 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.17
INFO:tensorflow:Starting iteration 22

Steps executed: 216 Episode length: 54 Return: -61.7517409534971055
INFO:tensorflow:Average training steps per second: 315.91
I0901 13:07:45.326000 140536266098688 replay_runner.py:36] Average training steps per second: 315.91
I0901 13:07:45.435408 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.07
INFO:tensorflow:Starting iteration 23

Steps executed: 210 Episode length: 59 Return: -260.153837344733455
INFO:tensorflow:Average training steps per second: 320.23
I0901 13:07:51.966771 140536266098688 replay_runner.py:36] Average training steps per second: 320.23
I0901 13:07:52.074427 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -362.83
INFO:tensorflow:Starting iteration 24

Steps executed: 261 Episode length: 63 Return: -538.051202593775175
INFO:tensorflow:Average training steps per second: 311.19
I0901 13:07:58.646167 140536266098688 replay_runner.py:36] Average training steps per second: 311.19
I0901 13:07:58.791072 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -452.68
INFO:tensorflow:Starting iteration 25

Steps executed: 260 Episode length: 82 Return: -716.371393874869175
INFO:tensorflow:Average training steps per second: 315.80
I0901 13:08:05.275916 140536266098688 replay_runner.py:36] Average training steps per second: 315.80
I0901 13:08:05.440565 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -537.18
INFO:tensorflow:Starting iteration 26

Steps executed: 210 Episode length: 60 Return: -311.398912597648175
INFO:tensorflow:Average training steps per second: 349.05
I0901 13:08:11.624548 140536266098688 replay_runner.py:36] Average training steps per second: 349.05
I0901 13:08:11.742022 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -595.89
INFO:tensorflow:Starting iteration 27

Steps executed: 240 Episode length: 57 Return: -226.670154007360035
INFO:tensorflow:Average training steps per second: 354.65
I0901 13:08:18.020698 140536266098688 replay_runner.py:36] Average training steps per second: 354.65
I0901 13:08:18.144402 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.23
INFO:tensorflow:Starting iteration 28

Steps executed: 270 Episode length: 104 Return: -514.81748199142575
INFO:tensorflow:Average training steps per second: 326.77
I0901 13:08:24.584770 140536266098688 replay_runner.py:36] Average training steps per second: 326.77
I0901 13:08:24.732977 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -433.57
INFO:tensorflow:Starting iteration 29

Steps executed: 274 Episode length: 79 Return: -731.264972498152475
INFO:tensorflow:Average training steps per second: 340.59
I0901 13:08:30.985923 140536266098688 replay_runner.py:36] Average training steps per second: 340.59

Done fixed training!Episode length: 79 Return: -731.264972498152475