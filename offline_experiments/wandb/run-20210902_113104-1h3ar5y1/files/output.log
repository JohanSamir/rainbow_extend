Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0902 11:31:09.530309 140642277193728 run_experiment.py:549] Creating TrainRunner ...
I0902 11:31:09.538342 140642277193728 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 11:31:09.538480 140642277193728 dqn_agent.py:272] 	 gamma: 0.990000
I0902 11:31:09.538561 140642277193728 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 11:31:09.538628 140642277193728 dqn_agent.py:274] 	 min_replay_history: 500
I0902 11:31:09.538689 140642277193728 dqn_agent.py:275] 	 update_period: 4
I0902 11:31:09.538754 140642277193728 dqn_agent.py:276] 	 target_update_period: 300
I0902 11:31:09.538846 140642277193728 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 11:31:09.538933 140642277193728 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 11:31:09.539013 140642277193728 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 11:31:09.539100 140642277193728 dqn_agent.py:280] 	 optimizer: adam
I0902 11:31:09.539174 140642277193728 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 11:31:09.539256 140642277193728 dqn_agent.py:283] 	 seed: 1630582269538308
I0902 11:31:09.541132 140642277193728 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 11:31:09.541243 140642277193728 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 11:31:09.541318 140642277193728 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 11:31:09.541426 140642277193728 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 11:31:09.541487 140642277193728 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 11:31:09.541562 140642277193728 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 11:31:09.541622 140642277193728 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 11:31:09.541697 140642277193728 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 11:31:09.541763 140642277193728 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 11:31:09.697966 140642277193728 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:09.953136 140642277193728 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:09.962213 140642277193728 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 11:31:09.967697 140642277193728 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 11:31:09.967828 140642277193728 dqn_agent.py:272] 	 gamma: 0.990000
I0902 11:31:09.967917 140642277193728 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 11:31:09.967982 140642277193728 dqn_agent.py:274] 	 min_replay_history: 500
I0902 11:31:09.968080 140642277193728 dqn_agent.py:275] 	 update_period: 4
I0902 11:31:09.968137 140642277193728 dqn_agent.py:276] 	 target_update_period: 300
I0902 11:31:09.968190 140642277193728 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 11:31:09.968266 140642277193728 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 11:31:09.968351 140642277193728 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 11:31:09.968421 140642277193728 dqn_agent.py:280] 	 optimizer: adam
I0902 11:31:09.968471 140642277193728 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 11:31:09.968529 140642277193728 dqn_agent.py:283] 	 seed: 1630582269967672
I0902 11:31:09.969971 140642277193728 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 11:31:09.970079 140642277193728 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 11:31:09.970165 140642277193728 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 11:31:09.970231 140642277193728 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 11:31:09.970288 140642277193728 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 11:31:09.970363 140642277193728 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 11:31:09.970428 140642277193728 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 11:31:09.970506 140642277193728 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 11:31:09.970567 140642277193728 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 11:31:10.002078 140642277193728 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:10.020521 140642277193728 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 11:31:10.020775 140642277193728 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 207.62
I0902 11:31:14.837384 140642277193728 replay_runner.py:36] Average training steps per second: 207.62
Steps executed: 229 Episode length: 114 Return: -182.86465102475222
I0902 11:31:15.702664 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.09
INFO:tensorflow:Starting iteration 1

Steps executed: 260 Episode length: 103 Return: -521.40244151005326
INFO:tensorflow:Average training steps per second: 360.67
I0902 11:31:21.501020 140642277193728 replay_runner.py:36] Average training steps per second: 360.67
I0902 11:31:21.659025 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -482.00
INFO:tensorflow:Starting iteration 2

Steps executed: 208 Episode length: 208 Return: -365.98680975298316
INFO:tensorflow:Average training steps per second: 361.41
I0902 11:31:27.479863 140642277193728 replay_runner.py:36] Average training steps per second: 361.41
I0902 11:31:27.621479 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -365.99
INFO:tensorflow:Starting iteration 3

Steps executed: 268 Episode length: 268 Return: -185.41728649924838
INFO:tensorflow:Average training steps per second: 347.40
I0902 11:31:33.846144 140642277193728 replay_runner.py:36] Average training steps per second: 347.40
I0902 11:31:34.066404 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.42
INFO:tensorflow:Starting iteration 4

Steps executed: 545 Episode length: 545 Return: -220.56169175341884
INFO:tensorflow:Average training steps per second: 347.59
I0902 11:31:40.367162 140642277193728 replay_runner.py:36] Average training steps per second: 347.59
I0902 11:31:41.095132 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.56
INFO:tensorflow:Starting iteration 5

Steps executed: 501 Episode length: 501 Return: -143.79549392611625
INFO:tensorflow:Average training steps per second: 353.77
I0902 11:31:47.407047 140642277193728 replay_runner.py:36] Average training steps per second: 353.77
I0902 11:31:47.948380 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.80
INFO:tensorflow:Starting iteration 6

Steps executed: 311 Episode length: 311 Return: -412.15249056480585
INFO:tensorflow:Average training steps per second: 367.74
I0902 11:31:54.194759 140642277193728 replay_runner.py:36] Average training steps per second: 367.74
I0902 11:31:54.523251 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -412.15
INFO:tensorflow:Starting iteration 7
I0902 11:31:57.958688 140642277193728 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 351.37
I0902 11:32:00.804918 140642277193728 replay_runner.py:36] Average training steps per second: 351.37

Steps executed: 408 Episode length: 408 Return: -201.33510386256165
INFO:tensorflow:Starting iteration 8

Steps executed: 356 Episode length: 356 Return: -353.30212380677244
INFO:tensorflow:Average training steps per second: 327.42
I0902 11:32:07.701026 140642277193728 replay_runner.py:36] Average training steps per second: 327.42
I0902 11:32:08.063627 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -353.30
INFO:tensorflow:Starting iteration 9

Steps executed: 518 Episode length: 518 Return: -479.85908456202374
INFO:tensorflow:Average training steps per second: 332.42
I0902 11:32:14.404587 140642277193728 replay_runner.py:36] Average training steps per second: 332.42
I0902 11:32:15.029875 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -479.86
INFO:tensorflow:Starting iteration 10
I0902 11:32:18.352823 140642277193728 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 345.46

Steps executed: 1000 Episode length: 1000 Return: -225.33364911663642
I0902 11:32:22.531326 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.33
INFO:tensorflow:Starting iteration 11

Steps executed: 510 Episode length: 337 Return: -343.8641795742506742
INFO:tensorflow:Average training steps per second: 352.71
I0902 11:32:28.789383 140642277193728 replay_runner.py:36] Average training steps per second: 352.71
I0902 11:32:29.216614 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.47
INFO:tensorflow:Starting iteration 12

Steps executed: 292 Episode length: 292 Return: -168.5848920059562242
INFO:tensorflow:Average training steps per second: 343.78
I0902 11:32:35.543898 140642277193728 replay_runner.py:36] Average training steps per second: 343.78
I0902 11:32:35.782717 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.58
INFO:tensorflow:Starting iteration 13
I0902 11:32:39.218728 140642277193728 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 340.13

Steps executed: 1000 Episode length: 1000 Return: 86.8632908085402142
I0902 11:32:43.846771 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: 86.86
INFO:tensorflow:Starting iteration 14

Steps executed: 318 Episode length: 318 Return: -104.9418779957142142
INFO:tensorflow:Average training steps per second: 345.70
I0902 11:32:50.234603 140642277193728 replay_runner.py:36] Average training steps per second: 345.70
I0902 11:32:50.505662 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.94
INFO:tensorflow:Starting iteration 15

Steps executed: 479 Episode length: 479 Return: 220.21944452677738142
INFO:tensorflow:Average training steps per second: 336.60
I0902 11:32:56.863144 140642277193728 replay_runner.py:36] Average training steps per second: 336.60
I0902 11:32:57.426578 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: 220.22
INFO:tensorflow:Starting iteration 16

Steps executed: 1000 Episode length: 1000 Return: -121.17315168677061
INFO:tensorflow:Average training steps per second: 337.52
I0902 11:33:03.759252 140642277193728 replay_runner.py:36] Average training steps per second: 337.52
I0902 11:33:05.304534 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.17
INFO:tensorflow:Starting iteration 17

Steps executed: 208 Episode length: 208 Return: -302.6536344773625061
INFO:tensorflow:Average training steps per second: 315.69
I0902 11:33:11.790043 140642277193728 replay_runner.py:36] Average training steps per second: 315.69
I0902 11:33:11.933220 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -302.65
INFO:tensorflow:Starting iteration 18

Steps executed: 449 Episode length: 449 Return: -406.0036452429844061
INFO:tensorflow:Average training steps per second: 325.69
I0902 11:33:18.243674 140642277193728 replay_runner.py:36] Average training steps per second: 325.69
I0902 11:33:18.856928 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.00
INFO:tensorflow:Starting iteration 19

Steps executed: 118 Episode length: 118 Return: -184.5615997417164461
INFO:tensorflow:Average training steps per second: 324.50
I0902 11:33:25.222218 140642277193728 replay_runner.py:36] Average training steps per second: 324.50

Steps executed: 455 Episode length: 337 Return: -205.8115805488972461
INFO:tensorflow:Starting iteration 20
I0902 11:33:28.901350 140642277193728 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 344.26

Steps executed: 741 Episode length: 741 Return: -311.1821087964339461
I0902 11:33:32.748629 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.18
INFO:tensorflow:Starting iteration 21

Steps executed: 208 Episode length: 208 Return: -388.4296699667211461
INFO:tensorflow:Average training steps per second: 337.91
I0902 11:33:39.048790 140642277193728 replay_runner.py:36] Average training steps per second: 337.91
I0902 11:33:39.219442 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -388.43
INFO:tensorflow:Starting iteration 22

Steps executed: 271 Episode length: 113 Return: -995.2101396907462461
INFO:tensorflow:Average training steps per second: 347.44
I0902 11:33:45.525962 140642277193728 replay_runner.py:36] Average training steps per second: 347.44
I0902 11:33:45.706018 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -528.95
INFO:tensorflow:Starting iteration 23
I0902 11:33:49.188301 140642277193728 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 369.73

Steps executed: 301 Episode length: 301 Return: -253.2668660364551461
I0902 11:33:52.210343 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.27
INFO:tensorflow:Starting iteration 24

Steps executed: 315 Episode length: 315 Return: 287.53194443781141461
INFO:tensorflow:Average training steps per second: 363.37
I0902 11:33:58.492782 140642277193728 replay_runner.py:36] Average training steps per second: 363.37
I0902 11:33:58.792090 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: 287.53
INFO:tensorflow:Starting iteration 25

Steps executed: 535 Episode length: 535 Return: -575.0443204976141461
INFO:tensorflow:Average training steps per second: 342.51
I0902 11:34:05.201236 140642277193728 replay_runner.py:36] Average training steps per second: 342.51
I0902 11:34:05.812779 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -575.04
INFO:tensorflow:Starting iteration 26

Steps executed: 279 Episode length: 150 Return: -169.7741547142144461
INFO:tensorflow:Average training steps per second: 335.72
I0902 11:34:12.196811 140642277193728 replay_runner.py:36] Average training steps per second: 335.72
I0902 11:34:12.380882 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.73
INFO:tensorflow:Starting iteration 27

Steps executed: 254 Episode length: 59 Return: -565.16715115461829461
INFO:tensorflow:Average training steps per second: 339.13
I0902 11:34:18.700167 140642277193728 replay_runner.py:36] Average training steps per second: 339.13
I0902 11:34:18.883088 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -412.72
INFO:tensorflow:Starting iteration 28

Steps executed: 537 Episode length: 343 Return: -347.7256453822350361
INFO:tensorflow:Average training steps per second: 352.94
I0902 11:34:25.094246 140642277193728 replay_runner.py:36] Average training steps per second: 352.94
I0902 11:34:25.842051 140642277193728 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.22
INFO:tensorflow:Starting iteration 29

Steps executed: 234 Episode length: 234 Return: -229.7711676368119861
INFO:tensorflow:Average training steps per second: 361.84
I0902 11:34:32.022953 140642277193728 replay_runner.py:36] Average training steps per second: 361.84

Done fixed training!Episode length: 234 Return: -229.7711676368119861