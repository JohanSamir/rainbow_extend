Loaded trained dqn in acrobot
Training fixed agent 7, please be patient, may be a while...
I0828 10:24:48.665680 140659155802112 run_experiment.py:549] Creating TrainRunner ...
I0828 10:24:48.675909 140659155802112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:24:48.676163 140659155802112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:24:48.676311 140659155802112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:24:48.676486 140659155802112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:24:48.676593 140659155802112 dqn_agent.py:275] 	 update_period: 4
I0828 10:24:48.676710 140659155802112 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:24:48.676810 140659155802112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:24:48.676946 140659155802112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:24:48.677059 140659155802112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:24:48.677182 140659155802112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:24:48.677377 140659155802112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:24:48.677486 140659155802112 dqn_agent.py:283] 	 seed: 1630146288675841
I0828 10:24:48.680317 140659155802112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:24:48.680519 140659155802112 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:24:48.680656 140659155802112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:24:48.680766 140659155802112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:24:48.680865 140659155802112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:24:48.680957 140659155802112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:24:48.681046 140659155802112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:24:48.681138 140659155802112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:24:48.681224 140659155802112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:24:48.719579 140659155802112 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:24:49.142390 140659155802112 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:24:49.172194 140659155802112 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:24:49.180834 140659155802112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:24:49.181008 140659155802112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:24:49.181084 140659155802112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:24:49.181146 140659155802112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:24:49.181211 140659155802112 dqn_agent.py:275] 	 update_period: 4
I0828 10:24:49.181278 140659155802112 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:24:49.181385 140659155802112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:24:49.181532 140659155802112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:24:49.181612 140659155802112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:24:49.181713 140659155802112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:24:49.181769 140659155802112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:24:49.181822 140659155802112 dqn_agent.py:283] 	 seed: 1630146289180793
I0828 10:24:49.184168 140659155802112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:24:49.184422 140659155802112 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:24:49.184583 140659155802112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:24:49.184692 140659155802112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:24:49.184950 140659155802112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:24:49.185149 140659155802112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:24:49.185322 140659155802112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:24:49.185406 140659155802112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:24:49.185489 140659155802112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:24:49.215550 140659155802112 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:24:49.236273 140659155802112 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:24:49.236571 140659155802112 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 152.53
I0828 10:24:55.792787 140659155802112 replay_runner.py:36] Average training steps per second: 152.53
I0828 10:24:57.340321 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1
I0828 10:24:57.580272 140659155802112 replay_runner.py:41] Starting iteration 1
Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 196.74
I0828 10:25:02.663526 140659155802112 replay_runner.py:36] Average training steps per second: 196.74
I0828 10:25:03.068127 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 2
I0828 10:25:03.314862 140659155802112 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 194.68
I0828 10:25:08.452175 140659155802112 replay_runner.py:36] Average training steps per second: 194.68
I0828 10:25:08.861390 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 3

Steps executed: 234 Episode length: 111 Return: -110.0
INFO:tensorflow:Average training steps per second: 200.49
I0828 10:25:14.086948 140659155802112 replay_runner.py:36] Average training steps per second: 200.49
I0828 10:25:14.297972 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.00
INFO:tensorflow:Starting iteration 4
I0828 10:25:14.552160 140659155802112 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 191.79
I0828 10:25:19.766685 140659155802112 replay_runner.py:36] Average training steps per second: 191.79

Steps executed: 635 Episode length: 500 Return: -500.0
INFO:tensorflow:Starting iteration 5

Steps executed: 610 Episode length: 444 Return: -443.0
INFO:tensorflow:Average training steps per second: 191.38
I0828 10:25:25.771938 140659155802112 replay_runner.py:36] Average training steps per second: 191.38
I0828 10:25:26.285750 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.33
INFO:tensorflow:Starting iteration 6

Steps executed: 241 Episode length: 97 Return: -96.0.0
INFO:tensorflow:Average training steps per second: 195.45
I0828 10:25:31.633018 140659155802112 replay_runner.py:36] Average training steps per second: 195.45
I0828 10:25:31.827980 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.50
INFO:tensorflow:Starting iteration 7

Steps executed: 283 Episode length: 185 Return: -184.0
INFO:tensorflow:Average training steps per second: 193.62
I0828 10:25:37.237240 140659155802112 replay_runner.py:36] Average training steps per second: 193.62
I0828 10:25:37.465657 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.50
INFO:tensorflow:Starting iteration 8

Steps executed: 407 Episode length: 407 Return: -406.0
INFO:tensorflow:Average training steps per second: 195.21
I0828 10:25:42.836232 140659155802112 replay_runner.py:36] Average training steps per second: 195.21
I0828 10:25:43.184895 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.00
INFO:tensorflow:Starting iteration 9
I0828 10:25:43.411563 140659155802112 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 197.38

Steps executed: 500 Episode length: 500 Return: -500.0
I0828 10:25:48.923859 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 10

Steps executed: 339 Episode length: 339 Return: -338.0
INFO:tensorflow:Average training steps per second: 196.90
I0828 10:25:54.245032 140659155802112 replay_runner.py:36] Average training steps per second: 196.90
I0828 10:25:54.526482 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.00
INFO:tensorflow:Starting iteration 11

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 197.91
I0828 10:25:59.827379 140659155802112 replay_runner.py:36] Average training steps per second: 197.91
I0828 10:26:00.248394 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 12
I0828 10:26:00.495552 140659155802112 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 194.79
I0828 10:26:05.629795 140659155802112 replay_runner.py:36] Average training steps per second: 194.79
I0828 10:26:06.052135 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 13
I0828 10:26:06.299526 140659155802112 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 197.74
I0828 10:26:11.357262 140659155802112 replay_runner.py:36] Average training steps per second: 197.74
I0828 10:26:11.777281 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 14
I0828 10:26:12.018301 140659155802112 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 195.97
I0828 10:26:17.121732 140659155802112 replay_runner.py:36] Average training steps per second: 195.97
I0828 10:26:17.549781 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 15
I0828 10:26:17.796648 140659155802112 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 193.37
I0828 10:26:22.968678 140659155802112 replay_runner.py:36] Average training steps per second: 193.37
I0828 10:26:23.393461 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 16
I0828 10:26:23.634068 140659155802112 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 195.91
I0828 10:26:28.738989 140659155802112 replay_runner.py:36] Average training steps per second: 195.91
I0828 10:26:29.172297 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 17
I0828 10:26:29.425837 140659155802112 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 196.89
I0828 10:26:34.505228 140659155802112 replay_runner.py:36] Average training steps per second: 196.89
I0828 10:26:34.918508 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 18
I0828 10:26:35.157675 140659155802112 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 193.97
I0828 10:26:40.313762 140659155802112 replay_runner.py:36] Average training steps per second: 193.97
I0828 10:26:40.729251 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 19
I0828 10:26:40.959707 140659155802112 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 198.11
I0828 10:26:46.007759 140659155802112 replay_runner.py:36] Average training steps per second: 198.11
I0828 10:26:46.427597 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 20
I0828 10:26:46.680503 140659155802112 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 195.40
I0828 10:26:51.798640 140659155802112 replay_runner.py:36] Average training steps per second: 195.40
I0828 10:26:52.213938 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 21
I0828 10:26:52.442821 140659155802112 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 194.14
I0828 10:26:57.594398 140659155802112 replay_runner.py:36] Average training steps per second: 194.14
I0828 10:26:58.008965 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 22
I0828 10:26:58.263988 140659155802112 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 200.89
I0828 10:27:03.242416 140659155802112 replay_runner.py:36] Average training steps per second: 200.89
I0828 10:27:03.661473 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 23
I0828 10:27:03.903672 140659155802112 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 196.29
I0828 10:27:08.998716 140659155802112 replay_runner.py:36] Average training steps per second: 196.29
I0828 10:27:09.401736 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 24
I0828 10:27:09.652761 140659155802112 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 201.28
I0828 10:27:14.621325 140659155802112 replay_runner.py:36] Average training steps per second: 201.28
I0828 10:27:15.048283 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 25
I0828 10:27:15.295340 140659155802112 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 205.84
I0828 10:27:20.153736 140659155802112 replay_runner.py:36] Average training steps per second: 205.84
I0828 10:27:20.551257 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 26
I0828 10:27:20.777176 140659155802112 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 204.06
I0828 10:27:25.678040 140659155802112 replay_runner.py:36] Average training steps per second: 204.06
I0828 10:27:26.037044 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 27
I0828 10:27:26.298997 140659155802112 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 215.89
I0828 10:27:30.933578 140659155802112 replay_runner.py:36] Average training steps per second: 215.89
I0828 10:27:31.316694 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 28
I0828 10:27:31.575314 140659155802112 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 201.27
I0828 10:27:36.544390 140659155802112 replay_runner.py:36] Average training steps per second: 201.27
I0828 10:27:36.923475 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 206.07
I0828 10:27:42.016529 140659155802112 replay_runner.py:36] Average training steps per second: 206.07
I0828 10:27:42.428753 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00