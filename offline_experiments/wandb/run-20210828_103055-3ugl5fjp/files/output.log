Loaded trained dqn in acrobot
Training fixed agent 7, please be patient, may be a while...
I0828 10:31:02.016622 140659155802112 run_experiment.py:549] Creating TrainRunner ...
I0828 10:31:02.026314 140659155802112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:31:02.026576 140659155802112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:31:02.026721 140659155802112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:31:02.026897 140659155802112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:31:02.027071 140659155802112 dqn_agent.py:275] 	 update_period: 4
I0828 10:31:02.027215 140659155802112 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:31:02.027369 140659155802112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:31:02.027482 140659155802112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:31:02.027585 140659155802112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:31:02.027684 140659155802112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:31:02.027836 140659155802112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:31:02.027961 140659155802112 dqn_agent.py:283] 	 seed: 1630146662026256
I0828 10:31:02.030931 140659155802112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:31:02.031150 140659155802112 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:31:02.031718 140659155802112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:31:02.032134 140659155802112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:31:02.032306 140659155802112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:31:02.032455 140659155802112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:31:02.032576 140659155802112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:31:02.033277 140659155802112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:31:02.033637 140659155802112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:31:02.071365 140659155802112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:31:02.885939 140659155802112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:31:02.900968 140659155802112 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:31:02.917498 140659155802112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:31:02.917752 140659155802112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:31:02.918076 140659155802112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:31:02.918356 140659155802112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:31:02.918595 140659155802112 dqn_agent.py:275] 	 update_period: 4
I0828 10:31:02.919464 140659155802112 dqn_agent.py:276] 	 target_update_period: 100
I0828 10:31:02.919824 140659155802112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:31:02.920188 140659155802112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:31:02.920655 140659155802112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:31:02.920981 140659155802112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:31:02.921245 140659155802112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:31:02.921570 140659155802112 dqn_agent.py:283] 	 seed: 1630146662917443
I0828 10:31:02.925627 140659155802112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:31:02.926091 140659155802112 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 10:31:02.926464 140659155802112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:31:02.927190 140659155802112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:31:02.927566 140659155802112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:31:02.927829 140659155802112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:31:02.928166 140659155802112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:31:02.928617 140659155802112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:31:02.928812 140659155802112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:31:02.963157 140659155802112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:31:02.983960 140659155802112 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:31:02.984245 140659155802112 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 148.05
I0828 10:31:09.738926 140659155802112 replay_runner.py:36] Average training steps per second: 148.05
Steps executed: 500 Episode length: 500 Return: -500.0
I0828 10:31:11.136352 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1
I0828 10:31:11.390998 140659155802112 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 197.82
I0828 10:31:16.446531 140659155802112 replay_runner.py:36] Average training steps per second: 197.82
I0828 10:31:16.859172 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 2
I0828 10:31:17.100100 140659155802112 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 201.21
I0828 10:31:22.070417 140659155802112 replay_runner.py:36] Average training steps per second: 201.21
I0828 10:31:22.509318 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 3
I0828 10:31:22.736685 140659155802112 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 194.21

Steps executed: 284 Episode length: 178 Return: -177.0
I0828 10:31:28.128815 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.00
INFO:tensorflow:Starting iteration 4
I0828 10:31:28.373713 140659155802112 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 198.46
I0828 10:31:33.413010 140659155802112 replay_runner.py:36] Average training steps per second: 198.46

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Starting iteration 5

Steps executed: 241 Episode length: 89 Return: -88.0.0
INFO:tensorflow:Average training steps per second: 199.96
I0828 10:31:39.128478 140659155802112 replay_runner.py:36] Average training steps per second: 199.96
I0828 10:31:39.346837 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.33
INFO:tensorflow:Starting iteration 6

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 191.20
I0828 10:31:44.831853 140659155802112 replay_runner.py:36] Average training steps per second: 191.20
I0828 10:31:45.241416 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7
I0828 10:31:45.484198 140659155802112 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 201.22
I0828 10:31:50.454360 140659155802112 replay_runner.py:36] Average training steps per second: 201.22
I0828 10:31:50.890134 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 8
I0828 10:31:51.137277 140659155802112 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 195.62
I0828 10:31:56.249905 140659155802112 replay_runner.py:36] Average training steps per second: 195.62
I0828 10:31:56.646508 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 9
I0828 10:31:56.888637 140659155802112 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 194.86
I0828 10:32:02.021014 140659155802112 replay_runner.py:36] Average training steps per second: 194.86
I0828 10:32:02.448492 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 10
I0828 10:32:02.686450 140659155802112 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 203.58
I0828 10:32:07.599116 140659155802112 replay_runner.py:36] Average training steps per second: 203.58
I0828 10:32:08.038492 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 11

Steps executed: 276 Episode length: 120 Return: -119.0
INFO:tensorflow:Average training steps per second: 191.33
I0828 10:32:13.602974 140659155802112 replay_runner.py:36] Average training steps per second: 191.33
I0828 10:32:13.838255 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.00
INFO:tensorflow:Starting iteration 12

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 194.57
I0828 10:32:19.219175 140659155802112 replay_runner.py:36] Average training steps per second: 194.57
I0828 10:32:19.662988 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 13
I0828 10:32:19.925503 140659155802112 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 198.99
I0828 10:32:24.951666 140659155802112 replay_runner.py:36] Average training steps per second: 198.99
I0828 10:32:25.358967 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 14
I0828 10:32:25.597080 140659155802112 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 190.07
I0828 10:32:30.858762 140659155802112 replay_runner.py:36] Average training steps per second: 190.07
I0828 10:32:31.256921 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 15
I0828 10:32:31.493580 140659155802112 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 204.04
I0828 10:32:36.394932 140659155802112 replay_runner.py:36] Average training steps per second: 204.04
I0828 10:32:36.807073 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 16
I0828 10:32:37.050847 140659155802112 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 200.47
I0828 10:32:42.039559 140659155802112 replay_runner.py:36] Average training steps per second: 200.47
I0828 10:32:42.479874 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 17
I0828 10:32:42.713022 140659155802112 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 202.30
I0828 10:32:47.656744 140659155802112 replay_runner.py:36] Average training steps per second: 202.30
I0828 10:32:48.043113 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 18
I0828 10:32:48.287413 140659155802112 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 190.08
I0828 10:32:53.548887 140659155802112 replay_runner.py:36] Average training steps per second: 190.08
I0828 10:32:53.954989 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 19
I0828 10:32:54.189476 140659155802112 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 199.97
I0828 10:32:59.190814 140659155802112 replay_runner.py:36] Average training steps per second: 199.97
I0828 10:32:59.602382 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 20

Steps executed: 206 Episode length: 206 Return: -205.0
INFO:tensorflow:Average training steps per second: 197.96
I0828 10:33:04.898049 140659155802112 replay_runner.py:36] Average training steps per second: 197.96
I0828 10:33:05.073411 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.00
INFO:tensorflow:Starting iteration 21
I0828 10:33:05.315202 140659155802112 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 205.32

Steps executed: 500 Episode length: 500 Return: -500.0
I0828 10:33:10.601791 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 22
I0828 10:33:10.846430 140659155802112 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 201.17
I0828 10:33:15.817747 140659155802112 replay_runner.py:36] Average training steps per second: 201.17
I0828 10:33:16.186026 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 23
I0828 10:33:16.405651 140659155802112 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 199.17
I0828 10:33:21.426727 140659155802112 replay_runner.py:36] Average training steps per second: 199.17
I0828 10:33:21.859049 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 24
I0828 10:33:22.106872 140659155802112 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 209.72
I0828 10:33:26.875597 140659155802112 replay_runner.py:36] Average training steps per second: 209.72
I0828 10:33:27.267262 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 25
I0828 10:33:27.504437 140659155802112 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 201.07
I0828 10:33:32.478154 140659155802112 replay_runner.py:36] Average training steps per second: 201.07
I0828 10:33:32.873006 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 26
I0828 10:33:33.191692 140659155802112 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 200.27
I0828 10:33:38.185661 140659155802112 replay_runner.py:36] Average training steps per second: 200.27
I0828 10:33:38.598308 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 27
I0828 10:33:38.846827 140659155802112 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 205.96
I0828 10:33:43.702771 140659155802112 replay_runner.py:36] Average training steps per second: 205.96
I0828 10:33:44.091045 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 28
I0828 10:33:44.322274 140659155802112 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 196.25
I0828 10:33:49.418290 140659155802112 replay_runner.py:36] Average training steps per second: 196.25
I0828 10:33:49.817145 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 198.65
I0828 10:33:55.083849 140659155802112 replay_runner.py:36] Average training steps per second: 198.65
I0828 10:33:55.482725 140659155802112 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00