error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
Training agent 2, please be patient, may be a while...
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0827 22:19:10.439341 140402814629888 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0827 22:19:10.492105 140402814629888 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0827 22:19:10.493092 140402814629888 dqn_agent.py:272] 	 gamma: 0.990000
I0827 22:19:10.493173 140402814629888 dqn_agent.py:273] 	 update_horizon: 1.000000
I0827 22:19:10.493236 140402814629888 dqn_agent.py:274] 	 min_replay_history: 500
I0827 22:19:10.493292 140402814629888 dqn_agent.py:275] 	 update_period: 4
I0827 22:19:10.493372 140402814629888 dqn_agent.py:276] 	 target_update_period: 100
I0827 22:19:10.493505 140402814629888 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0827 22:19:10.493564 140402814629888 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0827 22:19:10.493628 140402814629888 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0827 22:19:10.493700 140402814629888 dqn_agent.py:280] 	 optimizer: adam
I0827 22:19:10.493769 140402814629888 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0827 22:19:10.493847 140402814629888 dqn_agent.py:283] 	 seed: 1630102750492046
I0827 22:19:10.495388 140402814629888 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0827 22:19:10.495521 140402814629888 circular_replay_buffer.py:156] 	 observation_shape: (2, 1)
I0827 22:19:10.495595 140402814629888 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0827 22:19:10.495671 140402814629888 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0827 22:19:10.495731 140402814629888 circular_replay_buffer.py:159] 	 stack_size: 1
I0827 22:19:10.495837 140402814629888 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0827 22:19:10.495905 140402814629888 circular_replay_buffer.py:161] 	 batch_size: 128
I0827 22:19:10.495978 140402814629888 circular_replay_buffer.py:162] 	 update_horizon: 1
I0827 22:19:10.496039 140402814629888 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0827 22:19:11.728425 140402814629888 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0827 22:19:11.794284 140402814629888 run_experiment.py:516] Beginning training...
I0827 22:19:11.794440 140402814629888 run_experiment.py:447] Starting iteration 0
W0827 22:19:13.833639 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
Steps executed: 600 Episode length: 600 Return: -600.0

Steps executed: 873 Episode length: 273 Return: -273.0
W0827 22:19:17.548273 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:19:17.548606 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -491.00
error: Choose a correct Normalization Moduleurn: -600.0
error: Choose a correct Normalization Module















Steps executed: 118800 Episode length: 600 Return: -600.0
I0827 22:19:51.756611 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:19:56.669657 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:19:56.670048 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 124800 Episode length: 600 Return: -600.0
I0827 22:20:30.222255 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:20:35.212105 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:20:35.212441 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00


















Steps executed: 124800 Episode length: 600 Return: -600.0
I0827 22:21:10.518947 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:21:15.455379 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:21:15.456010 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 121800 Episode length: 600 Return: -600.0
I0827 22:21:49.484103 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 348 Episode length: 348 Return: -348.00.0

Steps executed: 948 Episode length: 600 Return: -600.00.0
W0827 22:21:55.581257 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:21:55.581572 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -482.33

















Steps executed: 120000 Episode length: 600 Return: -600.0
I0827 22:22:29.981846 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:22:34.760057 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:22:34.760377 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 124200 Episode length: 600 Return: -600.0
I0827 22:23:09.014890 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:23:14.019124 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:23:14.019475 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 122400 Episode length: 600 Return: -600.0
I0827 22:23:47.698134 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:23:52.593238 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:23:52.594040 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 118800 Episode length: 600 Return: -600.0
I0827 22:24:26.315358 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:24:31.354568 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:24:31.354925 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 121800 Episode length: 600 Return: -600.0
I0827 22:25:05.580604 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:25:10.421151 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:25:10.421470 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00


















Steps executed: 124200 Episode length: 600 Return: -600.0
I0827 22:25:45.130496 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:25:50.212289 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:25:50.212844 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 121800 Episode length: 600 Return: -600.0
I0827 22:26:23.883238 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:26:28.617697 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:26:28.618204 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 118800 Episode length: 600 Return: -600.0
I0827 22:27:02.886448 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0
W0827 22:27:05.362591 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 849 Episode length: 249 Return: -249.00.0
W0827 22:27:07.332060 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:27:07.332568 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -364.00
















Steps executed: 119330 Episode length: 600 Return: -600.0
I0827 22:27:40.910074 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -586.73

Steps executed: 125561 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:27:45.196812 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:27:45.197237 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -520.00
















Steps executed: 120121 Episode length: 600 Return: -600.0
I0827 22:28:18.869123 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.46

Steps executed: 125113 Episode length: 263 Return: -263.0

Steps executed: 600 Episode length: 600 Return: -600.03.0
W0827 22:28:23.844420 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:28:23.844982 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 123321 Episode length: 166 Return: -166.0
I0827 22:28:57.615192 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -418.19

Steps executed: 125039 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:29:01.929150 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:29:01.929728 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -532.00

















Steps executed: 123600 Episode length: 600 Return: -600.0
I0827 22:29:35.804748 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:29:40.246826 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:29:40.247338 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -536.50

















Steps executed: 121200 Episode length: 600 Return: -600.0
I0827 22:30:14.504297 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:30:19.259472 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:30:19.259806 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 121200 Episode length: 600 Return: -600.0
I0827 22:30:52.750674 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:30:57.639710 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:30:57.640154 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -577.00

















Steps executed: 123600 Episode length: 600 Return: -600.0
I0827 22:31:32.124047 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:31:37.051163 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:31:37.051711 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 122271 Episode length: 222 Return: -222.0
I0827 22:32:10.686100 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.02

Steps executed: 125297 Episode length: 322 Return: -322.0


Steps executed: 1200 Episode length: 600 Return: -600.0.0
W0827 22:32:15.842886 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:32:15.843494 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 118800 Episode length: 600 Return: -600.0
I0827 22:32:51.328691 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:32:56.191640 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:32:56.191984 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 119400 Episode length: 600 Return: -600.0
I0827 22:33:31.425411 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:33:36.416078 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:33:36.416416 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 123000 Episode length: 600 Return: -600.0
I0827 22:34:10.332857 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:34:15.125374 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:34:15.125881 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 125400 Episode length: 600 Return: -600.0
I0827 22:34:47.804622 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00
I0827 22:34:47.884916 140402814629888 run_experiment.py:447] Starting iteration 24

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:34:52.881314 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:34:52.881718 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 121800 Episode length: 600 Return: -600.0
I0827 22:35:27.028956 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:35:31.792352 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:35:31.792882 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 120000 Episode length: 600 Return: -600.0

Steps executed: 125400 Episode length: 600 Return: -600.0
I0827 22:36:05.997440 140402814629888 run_experiment.py:447] Starting iteration 26

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:36:10.763861 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:36:10.764200 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -581.50

















Steps executed: 122225 Episode length: 600 Return: -600.0
I0827 22:36:45.232207 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -599.16

Steps executed: 125225 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:36:50.215970 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:36:50.216276 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 123000 Episode length: 600 Return: -600.0
I0827 22:37:24.664499 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:37:28.972505 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:37:28.972834 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -510.00

















Steps executed: 123600 Episode length: 600 Return: -600.0
I0827 22:38:02.599652 140402814629888 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0827 22:38:07.481080 140402814629888 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0827 22:38:07.481414 140402814629888 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 119400 Episode length: 600 Return: -600.0

Done training!: 125400 Episode length: 600 Return: -600.0