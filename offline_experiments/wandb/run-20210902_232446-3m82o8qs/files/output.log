I0902 23:24:53.145692 140099460519936 run_experiment.py:549] Creating TrainRunner ...
I0902 23:24:53.155871 140099460519936 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:24:53.156146 140099460519936 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:24:53.156256 140099460519936 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:24:53.156390 140099460519936 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:24:53.156521 140099460519936 dqn_agent.py:275] 	 update_period: 4
I0902 23:24:53.156643 140099460519936 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:24:53.156797 140099460519936 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:24:53.156919 140099460519936 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:24:53.157079 140099460519936 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:24:53.157294 140099460519936 dqn_agent.py:280] 	 optimizer: adam
I0902 23:24:53.157603 140099460519936 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:24:53.157878 140099460519936 dqn_agent.py:283] 	 seed: 1630625093155797
I0902 23:24:53.162338 140099460519936 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:24:53.162626 140099460519936 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:24:53.162827 140099460519936 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:24:53.163024 140099460519936 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:24:53.163244 140099460519936 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:24:53.163361 140099460519936 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:24:53.163438 140099460519936 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:24:53.163554 140099460519936 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:24:53.163651 140099460519936 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0902 23:24:54.712758 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:24:55.079924 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:24:55.093777 140099460519936 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:24:55.102743 140099460519936 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:24:55.103092 140099460519936 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:24:55.103225 140099460519936 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:24:55.103379 140099460519936 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:24:55.103570 140099460519936 dqn_agent.py:275] 	 update_period: 4
I0902 23:24:55.103728 140099460519936 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:24:55.103824 140099460519936 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:24:55.103899 140099460519936 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:24:55.103976 140099460519936 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:24:55.104152 140099460519936 dqn_agent.py:280] 	 optimizer: adam
I0902 23:24:55.104363 140099460519936 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:24:55.104491 140099460519936 dqn_agent.py:283] 	 seed: 1630625095102676
I0902 23:24:55.106755 140099460519936 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:24:55.106943 140099460519936 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:24:55.107061 140099460519936 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:24:55.107139 140099460519936 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:24:55.107252 140099460519936 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:24:55.107325 140099460519936 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:24:55.107380 140099460519936 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:24:55.107434 140099460519936 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:24:55.107499 140099460519936 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:24:55.149367 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:24:55.198611 140099460519936 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:24:55.198814 140099460519936 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 171.84
I0902 23:25:01.018498 140099460519936 replay_runner.py:36] Average training steps per second: 171.84
Steps executed: 257 Episode length: 145 Return: -372.4136973737439
I0902 23:25:02.559846 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -317.26
INFO:tensorflow:Starting iteration 1

Steps executed: 413 Episode length: 242 Return: -362.1775565963599
INFO:tensorflow:Average training steps per second: 242.23
I0902 23:25:10.983468 140099460519936 replay_runner.py:36] Average training steps per second: 242.23
I0902 23:25:11.366587 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -343.65
INFO:tensorflow:Starting iteration 2

Steps executed: 336 Episode length: 189 Return: -361.35302087804325
INFO:tensorflow:Average training steps per second: 224.86
I0902 23:25:20.113041 140099460519936 replay_runner.py:36] Average training steps per second: 224.86
I0902 23:25:20.444164 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.57
INFO:tensorflow:Starting iteration 3
I0902 23:25:24.737207 140099460519936 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 236.46

Steps executed: 272 Episode length: 154 Return: -48.912338605272415
I0902 23:25:29.243552 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.54
INFO:tensorflow:Starting iteration 4
I0902 23:25:33.594674 140099460519936 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 228.82

Steps executed: 1000 Episode length: 1000 Return: -112.06304394216119
I0902 23:25:41.012899 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.06
INFO:tensorflow:Starting iteration 5
I0902 23:25:45.382580 140099460519936 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 228.01

Steps executed: 1000 Episode length: 1000 Return: -143.03509850275256
I0902 23:25:51.962716 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.04
INFO:tensorflow:Starting iteration 6
I0902 23:25:56.340548 140099460519936 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 227.65

Steps executed: 1000 Episode length: 1000 Return: -183.12642461532876
I0902 23:26:03.701279 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -183.13
INFO:tensorflow:Starting iteration 7
I0902 23:26:08.133769 140099460519936 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 223.82

Steps executed: 1000 Episode length: 1000 Return: -402.46328981510986
I0902 23:26:14.678395 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -402.46
INFO:tensorflow:Starting iteration 8
I0902 23:26:19.043245 140099460519936 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 219.12

Steps executed: 1000 Episode length: 1000 Return: -171.51993178795067
I0902 23:26:25.699772 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.52
INFO:tensorflow:Starting iteration 9

Steps executed: 497 Episode length: 356 Return: -403.9883305119309067
INFO:tensorflow:Average training steps per second: 224.44
I0902 23:26:34.482867 140099460519936 replay_runner.py:36] Average training steps per second: 224.44
I0902 23:26:35.114886 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.43
INFO:tensorflow:Starting iteration 10
I0902 23:26:39.403579 140099460519936 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 221.93

Steps executed: 1000 Episode length: 1000 Return: -245.51597973253867
I0902 23:26:48.114408 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.52
INFO:tensorflow:Starting iteration 11
I0902 23:26:52.290385 140099460519936 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 220.48

Steps executed: 1000 Episode length: 1000 Return: -214.82451731890828
I0902 23:26:59.094590 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -214.82
INFO:tensorflow:Starting iteration 12
I0902 23:27:03.321355 140099460519936 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 219.48

Steps executed: 1000 Episode length: 1000 Return: -238.09155318978318
I0902 23:27:11.704342 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -238.09
INFO:tensorflow:Starting iteration 13
I0902 23:27:16.106366 140099460519936 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 223.21

Steps executed: 1000 Episode length: 1000 Return: -141.54140788443418
I0902 23:27:24.723312 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.54
INFO:tensorflow:Starting iteration 14
I0902 23:27:29.168802 140099460519936 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 223.74

Steps executed: 393 Episode length: 393 Return: -604.9822829127977418
I0902 23:27:34.184451 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -604.98
INFO:tensorflow:Starting iteration 15
I0902 23:27:38.513436 140099460519936 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 220.84

Steps executed: 578 Episode length: 578 Return: -286.9725004775990618
I0902 23:27:44.145168 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -286.97
INFO:tensorflow:Starting iteration 16
I0902 23:27:48.388964 140099460519936 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 233.30

Steps executed: 1000 Episode length: 1000 Return: -12.287107959875089
I0902 23:27:54.958141 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -12.29
INFO:tensorflow:Starting iteration 17

Steps executed: 138 Episode length: 138 Return: -660.4725489342688089
INFO:tensorflow:Average training steps per second: 229.65

Steps executed: 994 Episode length: 856 Return: -121.7183611662375189
I0902 23:28:06.184501 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -391.10
INFO:tensorflow:Starting iteration 18

Steps executed: 244 Episode length: 119 Return: -451.9710880977027189
INFO:tensorflow:Average training steps per second: 229.29
I0902 23:28:14.913135 140099460519936 replay_runner.py:36] Average training steps per second: 229.29
I0902 23:28:15.152001 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -339.20
INFO:tensorflow:Starting iteration 19
I0902 23:28:19.414565 140099460519936 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 216.43

Steps executed: 511 Episode length: 511 Return: -468.7921673012948589
I0902 23:28:24.824601 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -468.79
INFO:tensorflow:Starting iteration 20
I0902 23:28:29.200340 140099460519936 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 226.29
I0902 23:28:33.619939 140099460519936 replay_runner.py:36] Average training steps per second: 226.29

Steps executed: 266 Episode length: 266 Return: -299.4667935213723589
INFO:tensorflow:Starting iteration 21

Steps executed: 144 Episode length: 144 Return: -160.6172216677190689
INFO:tensorflow:Average training steps per second: 231.09
I0902 23:28:42.582212 140099460519936 replay_runner.py:36] Average training steps per second: 231.09

Steps executed: 577 Episode length: 433 Return: -663.6922168974085689
INFO:tensorflow:Starting iteration 22
I0902 23:28:48.025245 140099460519936 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 231.31

Steps executed: 1000 Episode length: 1000 Return: -33.509464695802954
I0902 23:28:55.360703 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -33.51
INFO:tensorflow:Starting iteration 23

Steps executed: 280 Episode length: 280 Return: -108.1199123601562954
INFO:tensorflow:Average training steps per second: 222.33
I0902 23:29:04.195592 140099460519936 replay_runner.py:36] Average training steps per second: 222.33
I0902 23:29:04.542765 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.12
INFO:tensorflow:Starting iteration 24
I0902 23:29:08.856738 140099460519936 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 227.59

Steps executed: 533 Episode length: 533 Return: 226.05250921261872954
I0902 23:29:14.282744 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: 226.05
INFO:tensorflow:Starting iteration 25
I0902 23:29:18.624406 140099460519936 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 224.40

Steps executed: 555 Episode length: 555 Return: 181.84590481897317954
I0902 23:29:24.227711 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: 181.85
INFO:tensorflow:Starting iteration 26
I0902 23:29:28.623013 140099460519936 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 223.46

Steps executed: 1000 Episode length: 1000 Return: 3.19061909388591364
I0902 23:29:38.084422 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: 3.19
INFO:tensorflow:Starting iteration 27
I0902 23:29:42.492703 140099460519936 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 226.97

Steps executed: 1000 Episode length: 1000 Return: 70.8992606742223564
I0902 23:29:51.647153 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: 70.90
INFO:tensorflow:Starting iteration 28
I0902 23:29:56.047248 140099460519936 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 225.13

Steps executed: 1000 Episode length: 1000 Return: 80.7513908569715564
I0902 23:30:03.415562 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: 80.75
INFO:tensorflow:Starting iteration 29
I0902 23:30:07.617918 140099460519936 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 217.17

Steps executed: 1000 Episode length: 1000 Return: -53.837551458690634

Done fixed training! Episode length: 1000 Return: -53.837551458690634