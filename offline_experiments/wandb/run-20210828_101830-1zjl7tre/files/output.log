Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0828 10:18:37.046202 140220309850112 run_experiment.py:549] Creating TrainRunner ...
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0828 10:18:37.046780 140220309850112 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0828 10:18:37.123073 140220309850112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:18:37.124136 140220309850112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:18:37.124210 140220309850112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:18:37.124296 140220309850112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:18:37.124376 140220309850112 dqn_agent.py:275] 	 update_period: 4
I0828 10:18:37.124437 140220309850112 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:18:37.124558 140220309850112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:18:37.124618 140220309850112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:18:37.124692 140220309850112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:18:37.124746 140220309850112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:18:37.124822 140220309850112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:18:37.124881 140220309850112 dqn_agent.py:283] 	 seed: 1630145917123021
I0828 10:18:37.126590 140220309850112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:18:37.126719 140220309850112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:18:37.126789 140220309850112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:18:37.126850 140220309850112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:18:37.126912 140220309850112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:18:37.126983 140220309850112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:18:37.127053 140220309850112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:18:37.127155 140220309850112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:18:37.127222 140220309850112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:18:38.502890 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=10.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:18:38.871383 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=10.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:18:38.883280 140220309850112 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:18:38.887526 140220309850112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:18:38.887661 140220309850112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:18:38.887750 140220309850112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:18:38.887820 140220309850112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:18:38.887883 140220309850112 dqn_agent.py:275] 	 update_period: 4
I0828 10:18:38.887951 140220309850112 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:18:38.888014 140220309850112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:18:38.888102 140220309850112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:18:38.888177 140220309850112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:18:38.888238 140220309850112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:18:38.888309 140220309850112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:18:38.888382 140220309850112 dqn_agent.py:283] 	 seed: 1630145918887493
I0828 10:18:38.890007 140220309850112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:18:38.890137 140220309850112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:18:38.890218 140220309850112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:18:38.890288 140220309850112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:18:38.890352 140220309850112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:18:38.890414 140220309850112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:18:38.890476 140220309850112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:18:38.890552 140220309850112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:18:38.890625 140220309850112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:18:38.909703 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=10.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:18:38.922188 140220309850112 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:18:38.922347 140220309850112 replay_runner.py:41] Starting iteration 0
Steps executed: 282 Episode length: 89 Return: -106.34624415370587
INFO:tensorflow:Average training steps per second: 172.46
I0828 10:18:44.721269 140220309850112 replay_runner.py:36] Average training steps per second: 172.46
I0828 10:18:45.690547 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.48
INFO:tensorflow:Starting iteration 1
I0828 10:18:49.861429 140220309850112 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 213.78

Steps executed: 242 Episode length: 81 Return: -202.09335190974184
I0828 10:18:54.754847 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -181.98
INFO:tensorflow:Starting iteration 2

Steps executed: 208 Episode length: 79 Return: -538.85857167308264
INFO:tensorflow:Average training steps per second: 214.91
I0828 10:19:03.720334 140220309850112 replay_runner.py:36] Average training steps per second: 214.91
I0828 10:19:03.908985 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.92
INFO:tensorflow:Starting iteration 3

Steps executed: 221 Episode length: 102 Return: -1019.3068056160648
INFO:tensorflow:Average training steps per second: 217.58
I0828 10:19:12.819976 140220309850112 replay_runner.py:36] Average training steps per second: 217.58
I0828 10:19:13.027601 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -616.10
INFO:tensorflow:Starting iteration 4

Steps executed: 219 Episode length: 76 Return: -456.889286607109748
INFO:tensorflow:Average training steps per second: 219.28
I0828 10:19:21.855468 140220309850112 replay_runner.py:36] Average training steps per second: 219.28
I0828 10:19:22.049983 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -604.37
INFO:tensorflow:Starting iteration 5

Steps executed: 281 Episode length: 84 Return: -471.677360321371448
INFO:tensorflow:Average training steps per second: 216.49
I0828 10:19:30.918391 140220309850112 replay_runner.py:36] Average training steps per second: 216.49
I0828 10:19:31.118301 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -387.97
INFO:tensorflow:Starting iteration 6

Steps executed: 235 Episode length: 235 Return: -408.18700076636986
INFO:tensorflow:Average training steps per second: 217.66
I0828 10:19:39.982816 140220309850112 replay_runner.py:36] Average training steps per second: 217.66
I0828 10:19:40.225501 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -408.19
INFO:tensorflow:Starting iteration 7

Steps executed: 271 Episode length: 76 Return: -433.251066146484376
INFO:tensorflow:Average training steps per second: 218.23
I0828 10:19:49.074696 140220309850112 replay_runner.py:36] Average training steps per second: 218.23
I0828 10:19:49.277040 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -384.18
INFO:tensorflow:Starting iteration 8

Steps executed: 378 Episode length: 183 Return: -1239.6729865369664
INFO:tensorflow:Average training steps per second: 218.81
I0828 10:19:58.101773 140220309850112 replay_runner.py:36] Average training steps per second: 218.81
I0828 10:19:58.475170 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -633.26
INFO:tensorflow:Starting iteration 9

Steps executed: 203 Episode length: 72 Return: -622.017732857302344
INFO:tensorflow:Average training steps per second: 219.94
I0828 10:20:07.236304 140220309850112 replay_runner.py:36] Average training steps per second: 219.94
I0828 10:20:07.418233 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.66
INFO:tensorflow:Starting iteration 10

Steps executed: 270 Episode length: 79 Return: -187.601872654200067
INFO:tensorflow:Average training steps per second: 218.58
I0828 10:20:16.088424 140220309850112 replay_runner.py:36] Average training steps per second: 218.58
I0828 10:20:16.308613 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.84
INFO:tensorflow:Starting iteration 11
I0828 10:20:20.439906 140220309850112 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 222.83
I0828 10:20:24.928055 140220309850112 replay_runner.py:36] Average training steps per second: 222.83

Steps executed: 261 Episode length: 107 Return: -334.95312240976506
INFO:tensorflow:Starting iteration 12

Steps executed: 209 Episode length: 66 Return: -136.601242662766106
INFO:tensorflow:Average training steps per second: 222.81
I0828 10:20:33.941191 140220309850112 replay_runner.py:36] Average training steps per second: 222.81
I0828 10:20:34.081880 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.77
INFO:tensorflow:Starting iteration 13

Steps executed: 243 Episode length: 58 Return: -496.756737161982366
INFO:tensorflow:Average training steps per second: 225.61
I0828 10:20:42.735073 140220309850112 replay_runner.py:36] Average training steps per second: 225.61
I0828 10:20:42.954996 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -494.63
INFO:tensorflow:Starting iteration 14

Steps executed: 217 Episode length: 72 Return: -743.320431064680766
INFO:tensorflow:Average training steps per second: 223.74
I0828 10:20:51.681138 140220309850112 replay_runner.py:36] Average training steps per second: 223.74
I0828 10:20:51.881942 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -666.11
INFO:tensorflow:Starting iteration 15

Steps executed: 208 Episode length: 55 Return: -124.279019987674966
INFO:tensorflow:Average training steps per second: 225.83
I0828 10:21:00.598810 140220309850112 replay_runner.py:36] Average training steps per second: 225.83
I0828 10:21:00.742192 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.43
INFO:tensorflow:Starting iteration 16

Steps executed: 264 Episode length: 73 Return: -745.500131167024866
INFO:tensorflow:Average training steps per second: 224.22
I0828 10:21:09.481857 140220309850112 replay_runner.py:36] Average training steps per second: 224.22
I0828 10:21:09.724307 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -593.50
INFO:tensorflow:Starting iteration 17

Steps executed: 215 Episode length: 107 Return: -540.77311735369846
INFO:tensorflow:Average training steps per second: 224.71
I0828 10:21:18.427586 140220309850112 replay_runner.py:36] Average training steps per second: 224.71
I0828 10:21:18.648990 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -673.75
INFO:tensorflow:Starting iteration 18

Steps executed: 248 Episode length: 59 Return: -105.559030307455096
INFO:tensorflow:Average training steps per second: 242.48
I0828 10:21:27.037326 140220309850112 replay_runner.py:36] Average training steps per second: 242.48
I0828 10:21:27.184183 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.62
INFO:tensorflow:Starting iteration 19

Steps executed: 256 Episode length: 66 Return: -142.881588914313376
INFO:tensorflow:Average training steps per second: 271.22
I0828 10:21:34.824599 140220309850112 replay_runner.py:36] Average training steps per second: 271.22
I0828 10:21:35.040506 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.30
INFO:tensorflow:Starting iteration 20

Steps executed: 260 Episode length: 78 Return: -720.593519250483876
INFO:tensorflow:Average training steps per second: 241.03
I0828 10:21:42.990157 140220309850112 replay_runner.py:36] Average training steps per second: 241.03
I0828 10:21:43.197503 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -598.56
INFO:tensorflow:Starting iteration 21

Steps executed: 272 Episode length: 82 Return: -132.588795004721456
INFO:tensorflow:Average training steps per second: 229.35
I0828 10:21:51.712603 140220309850112 replay_runner.py:36] Average training steps per second: 229.35
I0828 10:21:51.912421 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.99
INFO:tensorflow:Starting iteration 22

Steps executed: 251 Episode length: 62 Return: -531.173852754991966
INFO:tensorflow:Average training steps per second: 228.30
I0828 10:22:00.553489 140220309850112 replay_runner.py:36] Average training steps per second: 228.30
I0828 10:22:00.760808 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -454.05
INFO:tensorflow:Starting iteration 23
I0828 10:22:05.113455 140220309850112 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 229.56

Steps executed: 333 Episode length: 166 Return: -1135.9630547792588
I0828 10:22:09.825557 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -1136.82
INFO:tensorflow:Starting iteration 24

Steps executed: 216 Episode length: 77 Return: -384.922423349703658
INFO:tensorflow:Average training steps per second: 227.96
I0828 10:22:18.394835 140220309850112 replay_runner.py:36] Average training steps per second: 227.96
I0828 10:22:18.615882 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -690.39
INFO:tensorflow:Starting iteration 25
I0828 10:22:22.786275 140220309850112 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 226.25
I0828 10:22:27.206360 140220309850112 replay_runner.py:36] Average training steps per second: 226.25

Steps executed: 253 Episode length: 61 Return: -555.727029798443758
INFO:tensorflow:Starting iteration 26

Steps executed: 202 Episode length: 55 Return: -416.914179847327438
INFO:tensorflow:Average training steps per second: 233.53
I0828 10:22:35.944515 140220309850112 replay_runner.py:36] Average training steps per second: 233.53
I0828 10:22:36.135749 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -672.49
INFO:tensorflow:Starting iteration 27

Steps executed: 285 Episode length: 207 Return: -1520.9677891996446
INFO:tensorflow:Average training steps per second: 233.41
I0828 10:22:44.794327 140220309850112 replay_runner.py:36] Average training steps per second: 233.41
I0828 10:22:45.095402 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -1013.25
INFO:tensorflow:Starting iteration 28

Steps executed: 232 Episode length: 59 Return: -470.452150133592176
INFO:tensorflow:Average training steps per second: 232.06
I0828 10:22:53.791444 140220309850112 replay_runner.py:36] Average training steps per second: 232.06
I0828 10:22:53.998416 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -455.29
INFO:tensorflow:Starting iteration 29

Steps executed: 232 Episode length: 232 Return: -1494.3122323823827
INFO:tensorflow:Average training steps per second: 234.85
I0828 10:23:02.663610 140220309850112 replay_runner.py:36] Average training steps per second: 234.85

Done fixed training!Episode length: 232 Return: -1494.3122323823827