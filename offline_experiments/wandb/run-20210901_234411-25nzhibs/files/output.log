Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0901 23:44:17.854155 139825600018432 run_experiment.py:549] Creating TrainRunner ...
I0901 23:44:17.865415 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:44:17.865697 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:44:17.865886 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:44:17.866091 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:44:17.866207 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0901 23:44:17.866484 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:44:17.866591 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:44:17.866700 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:44:17.866858 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:44:17.866950 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0901 23:44:17.867036 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:44:17.867132 139825600018432 dqn_agent.py:283] 	 seed: 1630539857865335
I0901 23:44:17.870437 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:44:17.870577 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:44:17.870655 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:44:17.870718 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:44:17.870776 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:44:17.870863 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:44:17.870954 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:44:17.871017 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:44:17.871073 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:44:19.335831 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:44:19.713806 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:44:19.730259 139825600018432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:44:19.739576 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:44:19.739892 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:44:19.740132 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:44:19.740311 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:44:19.740449 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0901 23:44:19.740565 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:44:19.740670 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:44:19.740782 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:44:19.741051 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:44:19.741216 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0901 23:44:19.741362 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:44:19.741508 139825600018432 dqn_agent.py:283] 	 seed: 1630539859739506
I0901 23:44:19.744835 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:44:19.745019 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:44:19.745178 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:44:19.745277 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:44:19.745361 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:44:19.745460 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:44:19.745620 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:44:19.745732 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:44:19.745838 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:44:19.778417 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:44:19.801887 139825600018432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:44:19.802260 139825600018432 replay_runner.py:41] Starting iteration 0
Steps executed: 285 Episode length: 140 Return: -536.7463805201066
INFO:tensorflow:Average training steps per second: 160.15
I0901 23:44:26.046808 139825600018432 replay_runner.py:36] Average training steps per second: 160.15
I0901 23:44:27.336345 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -503.70
INFO:tensorflow:Starting iteration 1

Steps executed: 350 Episode length: 169 Return: -402.74305185628244
INFO:tensorflow:Average training steps per second: 233.89
I0901 23:44:35.733039 139825600018432 replay_runner.py:36] Average training steps per second: 233.89
I0901 23:44:36.077448 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -403.72
INFO:tensorflow:Starting iteration 2

Steps executed: 267 Episode length: 149 Return: -253.13505752226763
INFO:tensorflow:Average training steps per second: 236.50
I0901 23:44:44.475702 139825600018432 replay_runner.py:36] Average training steps per second: 236.50
I0901 23:44:44.716625 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -323.60
INFO:tensorflow:Starting iteration 3
I0901 23:44:49.059429 139825600018432 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 230.92

Steps executed: 450 Episode length: 450 Return: -281.58432270820253
I0901 23:44:54.328413 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.58
INFO:tensorflow:Starting iteration 4
I0901 23:44:58.672151 139825600018432 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 226.23
I0901 23:45:03.093490 139825600018432 replay_runner.py:36] Average training steps per second: 226.23

Steps executed: 1000 Episode length: 1000 Return: -145.27322967827098
INFO:tensorflow:Starting iteration 5
I0901 23:45:10.048561 139825600018432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 222.89

Steps executed: 1000 Episode length: 1000 Return: -161.41774175374215
I0901 23:45:17.316408 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.42
INFO:tensorflow:Starting iteration 6
I0901 23:45:21.660794 139825600018432 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 223.14

Steps executed: 1000 Episode length: 1000 Return: -252.50040146677318
I0901 23:45:28.176410 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -252.50
INFO:tensorflow:Starting iteration 7
I0901 23:45:32.554460 139825600018432 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 223.56

Steps executed: 1000 Episode length: 1000 Return: -261.53199513078588
I0901 23:45:39.661514 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.53
INFO:tensorflow:Starting iteration 8
I0901 23:45:43.887854 139825600018432 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 223.41

Steps executed: 724 Episode length: 724 Return: -444.6333811342700588
I0901 23:45:50.500404 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -444.63
INFO:tensorflow:Starting iteration 9
I0901 23:45:54.842804 139825600018432 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 223.69

Steps executed: 1000 Episode length: 1000 Return: -187.63332810130672
I0901 23:46:01.923416 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.63
INFO:tensorflow:Starting iteration 10
I0901 23:46:06.218868 139825600018432 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 222.43

Steps executed: 1000 Episode length: 1000 Return: -223.65745973617615
I0901 23:46:12.772945 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.66
INFO:tensorflow:Starting iteration 11
I0901 23:46:17.169201 139825600018432 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 224.79

Steps executed: 1000 Episode length: 1000 Return: -213.59815066037032
I0901 23:46:25.103868 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.60
INFO:tensorflow:Starting iteration 12
I0901 23:46:29.409741 139825600018432 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 224.43
I0901 23:46:33.866491 139825600018432 replay_runner.py:36] Average training steps per second: 224.43

Steps executed: 1000 Episode length: 1000 Return: -183.56894325463034
INFO:tensorflow:Starting iteration 13
I0901 23:46:42.649711 139825600018432 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 219.97
I0901 23:46:47.196134 139825600018432 replay_runner.py:36] Average training steps per second: 219.97

Steps executed: 1000 Episode length: 1000 Return: -80.627868217499924
INFO:tensorflow:Starting iteration 14

Steps executed: 205 Episode length: 205 Return: -442.9066826943286524
INFO:tensorflow:Average training steps per second: 240.57
I0901 23:46:58.719306 139825600018432 replay_runner.py:36] Average training steps per second: 240.57
I0901 23:46:58.930314 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -442.91
INFO:tensorflow:Starting iteration 15
I0901 23:47:03.445198 139825600018432 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 239.63

Steps executed: 1000 Episode length: 1000 Return: -90.270768074097224
I0901 23:47:10.944200 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.27
INFO:tensorflow:Starting iteration 16
I0901 23:47:15.210756 139825600018432 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 227.00

Steps executed: 880 Episode length: 880 Return: 133.65506956980218224
I0901 23:47:21.526432 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: 133.66
INFO:tensorflow:Starting iteration 17
I0901 23:47:25.759834 139825600018432 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 232.00

Steps executed: 803 Episode length: 803 Return: -118.6690760134444724
I0901 23:47:31.717171 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.67
INFO:tensorflow:Starting iteration 18

Steps executed: 298 Episode length: 138 Return: -752.3149088747208724
INFO:tensorflow:Average training steps per second: 231.84
I0901 23:47:40.237731 139825600018432 replay_runner.py:36] Average training steps per second: 231.84
I0901 23:47:40.528395 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -357.85
INFO:tensorflow:Starting iteration 19

Steps executed: 244 Episode length: 170 Return: -581.8524456885406724
INFO:tensorflow:Average training steps per second: 234.12
I0901 23:47:49.043757 139825600018432 replay_runner.py:36] Average training steps per second: 234.12
I0901 23:47:49.260267 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -367.32
INFO:tensorflow:Starting iteration 20
I0901 23:47:53.624773 139825600018432 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 228.54

Steps executed: 510 Episode length: 510 Return: -400.6612817391801424
I0901 23:47:58.904057 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.66
INFO:tensorflow:Starting iteration 21

Steps executed: 200 Episode length: 147 Return: -356.4113115351539424
INFO:tensorflow:Average training steps per second: 220.88
I0901 23:48:07.735544 139825600018432 replay_runner.py:36] Average training steps per second: 220.88
I0901 23:48:07.931124 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.07
INFO:tensorflow:Starting iteration 22
I0901 23:48:12.281430 139825600018432 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 220.69

Steps executed: 843 Episode length: 843 Return: 192.29461061628949424
I0901 23:48:19.418542 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: 192.29
INFO:tensorflow:Starting iteration 23

Steps executed: 138 Episode length: 138 Return: -64.07936722383822424
INFO:tensorflow:Average training steps per second: 224.79

Steps executed: 1138 Episode length: 1000 Return: 87.5747740772259724
I0901 23:48:31.174387 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: 11.75
INFO:tensorflow:Starting iteration 24
I0901 23:48:35.560521 139825600018432 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 226.44

Steps executed: 421 Episode length: 421 Return: 0.4019976925360566624
I0901 23:48:40.736933 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: 0.40
INFO:tensorflow:Starting iteration 25

Steps executed: 299 Episode length: 165 Return: -55.10360069987525724
INFO:tensorflow:Average training steps per second: 220.39
I0901 23:48:49.626041 139825600018432 replay_runner.py:36] Average training steps per second: 220.39
I0901 23:48:49.927784 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.52
INFO:tensorflow:Starting iteration 26
I0901 23:48:54.269255 139825600018432 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 227.81

Steps executed: 327 Episode length: 327 Return: -77.54072035243601724
I0901 23:48:59.166795 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.54
INFO:tensorflow:Starting iteration 27
I0901 23:49:03.516759 139825600018432 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 229.99

Steps executed: 1000 Episode length: 1000 Return: -4.0141053040944366
I0901 23:49:11.694072 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -4.01
INFO:tensorflow:Starting iteration 28
I0901 23:49:16.000647 139825600018432 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 226.78
I0901 23:49:20.410591 139825600018432 replay_runner.py:36] Average training steps per second: 226.78

Steps executed: 289 Episode length: 122 Return: -87.85173196106206566
INFO:tensorflow:Starting iteration 29

Steps executed: 337 Episode length: 168 Return: -5.516500228026672566
INFO:tensorflow:Average training steps per second: 219.71
I0901 23:49:29.813232 139825600018432 replay_runner.py:36] Average training steps per second: 219.71

Done fixed training!Episode length: 168 Return: -5.516500228026672566