I0905 16:41:57.120679 140199535331328 run_experiment.py:549] Creating TrainRunner ...
I0905 16:41:57.127899 140199535331328 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:41:57.128038 140199535331328 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:41:57.128123 140199535331328 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:41:57.128200 140199535331328 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:41:57.128272 140199535331328 dqn_agent.py:275] 	 update_period: 4
I0905 16:41:57.128376 140199535331328 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:41:57.128455 140199535331328 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:41:57.128568 140199535331328 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:41:57.128701 140199535331328 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:41:57.128795 140199535331328 dqn_agent.py:280] 	 optimizer: adam
I0905 16:41:57.128896 140199535331328 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:41:57.128993 140199535331328 dqn_agent.py:283] 	 seed: 1630860117127864
I0905 16:41:57.130698 140199535331328 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:41:57.130813 140199535331328 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:41:57.130899 140199535331328 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:41:57.130970 140199535331328 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:41:57.131058 140199535331328 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:41:57.131146 140199535331328 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:41:57.131283 140199535331328 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:41:57.131382 140199535331328 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:41:57.131463 140199535331328 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:41:58.417694 140199535331328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0905 16:41:59.268084 140199535331328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:41:59.280223 140199535331328 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:41:59.286562 140199535331328 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:41:59.286758 140199535331328 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:41:59.286870 140199535331328 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:41:59.286957 140199535331328 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:41:59.287033 140199535331328 dqn_agent.py:275] 	 update_period: 4
I0905 16:41:59.287105 140199535331328 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:41:59.287284 140199535331328 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:41:59.287523 140199535331328 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:41:59.287744 140199535331328 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:41:59.288059 140199535331328 dqn_agent.py:280] 	 optimizer: adam
I0905 16:41:59.288172 140199535331328 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:41:59.288249 140199535331328 dqn_agent.py:283] 	 seed: 1630860119286500
I0905 16:41:59.291208 140199535331328 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:41:59.291441 140199535331328 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:41:59.291595 140199535331328 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:41:59.291803 140199535331328 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:41:59.291954 140199535331328 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:41:59.292114 140199535331328 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:41:59.292242 140199535331328 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:41:59.292378 140199535331328 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:41:59.292510 140199535331328 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:41:59.317819 140199535331328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:41:59.340697 140199535331328 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:41:59.341441 140199535331328 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 199.55
I0905 16:42:04.352927 140199535331328 replay_runner.py:36] Average training steps per second: 199.55
Steps executed: 252 Episode length: 97 Return: -296.215375386098734
I0905 16:42:05.060811 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -317.36
INFO:tensorflow:Starting iteration 1

Steps executed: 253 Episode length: 106 Return: -314.82925574008334
INFO:tensorflow:Average training steps per second: 286.07
I0905 16:42:12.401630 140199535331328 replay_runner.py:36] Average training steps per second: 286.07
I0905 16:42:12.620709 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.55
INFO:tensorflow:Starting iteration 2
I0905 16:42:16.335618 140199535331328 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 243.37
I0905 16:42:20.445172 140199535331328 replay_runner.py:36] Average training steps per second: 243.37

Steps executed: 324 Episode length: 324 Return: -1341.5157356354098
INFO:tensorflow:Starting iteration 3
I0905 16:42:24.957555 140199535331328 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 237.14

Steps executed: 1000 Episode length: 1000 Return: -101.71191552349312
I0905 16:42:32.543998 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.71
INFO:tensorflow:Starting iteration 4
I0905 16:42:36.603378 140199535331328 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 234.84

Steps executed: 537 Episode length: 537 Return: -327.4917492418418312
I0905 16:42:41.759657 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.49
INFO:tensorflow:Starting iteration 5
I0905 16:42:45.816465 140199535331328 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 228.46

Steps executed: 1000 Episode length: 1000 Return: -198.64347540631392
I0905 16:42:52.310510 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -198.64
INFO:tensorflow:Starting iteration 6
I0905 16:42:56.245788 140199535331328 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 243.12

Steps executed: 851 Episode length: 851 Return: -779.0507001683916392
I0905 16:43:02.650133 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -779.05
INFO:tensorflow:Starting iteration 7
I0905 16:43:06.775115 140199535331328 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 250.49

Steps executed: 898 Episode length: 898 Return: -565.6450672084222392
I0905 16:43:12.797353 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -565.65
INFO:tensorflow:Starting iteration 8
I0905 16:43:16.954976 140199535331328 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 252.01

Steps executed: 704 Episode length: 704 Return: -1656.481231516425692
I0905 16:43:22.292839 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -1656.48
INFO:tensorflow:Starting iteration 9
I0905 16:43:26.444227 140199535331328 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 250.33

Steps executed: 577 Episode length: 577 Return: -315.0398922940536392
I0905 16:43:31.563441 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -315.04
INFO:tensorflow:Starting iteration 10
I0905 16:43:35.513667 140199535331328 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 248.41

Steps executed: 1000 Episode length: 1000 Return: -218.68718849744013
I0905 16:43:41.769685 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.69
INFO:tensorflow:Starting iteration 11
I0905 16:43:45.804339 140199535331328 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 229.33

Steps executed: 667 Episode length: 667 Return: -338.5644440005221413
I0905 16:43:51.353718 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.56
INFO:tensorflow:Starting iteration 12
I0905 16:43:55.352624 140199535331328 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 239.56

Steps executed: 1000 Episode length: 1000 Return: -126.63875133098057
I0905 16:44:02.902479 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.64
INFO:tensorflow:Starting iteration 13
I0905 16:44:07.250239 140199535331328 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 247.52

Steps executed: 1000 Episode length: 1000 Return: -153.21274954261085
I0905 16:44:13.583836 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.21
INFO:tensorflow:Starting iteration 14

Steps executed: 685 Episode length: 685 Return: -237.4263225152563285
INFO:tensorflow:Average training steps per second: 256.56
I0905 16:44:21.734473 140199535331328 replay_runner.py:36] Average training steps per second: 256.56
I0905 16:44:23.167384 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.43
INFO:tensorflow:Starting iteration 15

Steps executed: 312 Episode length: 312 Return: -139.4526102637239285
INFO:tensorflow:Average training steps per second: 255.27
I0905 16:44:31.326239 140199535331328 replay_runner.py:36] Average training steps per second: 255.27
I0905 16:44:31.641735 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.45
INFO:tensorflow:Starting iteration 16

Steps executed: 258 Episode length: 125 Return: -325.0784383875721285
INFO:tensorflow:Average training steps per second: 235.27
I0905 16:44:40.061490 140199535331328 replay_runner.py:36] Average training steps per second: 235.27
I0905 16:44:40.279106 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -328.97
INFO:tensorflow:Starting iteration 17
I0905 16:44:44.034494 140199535331328 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 225.32

Steps executed: 538 Episode length: 538 Return: -396.4783109319156485
I0905 16:44:49.469950 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -396.48
INFO:tensorflow:Starting iteration 18

Steps executed: 540 Episode length: 387 Return: -124.7287661804641485
INFO:tensorflow:Average training steps per second: 239.59
I0905 16:44:57.604230 140199535331328 replay_runner.py:36] Average training steps per second: 239.59
I0905 16:44:58.462311 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.00
INFO:tensorflow:Starting iteration 19

Steps executed: 138 Episode length: 138 Return: -74.97301369671533485
INFO:tensorflow:Average training steps per second: 243.84

Steps executed: 719 Episode length: 581 Return: -138.8616421890371885
I0905 16:45:07.695790 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.92
INFO:tensorflow:Starting iteration 20

Steps executed: 400 Episode length: 400 Return: 10.227833878795906885
INFO:tensorflow:Average training steps per second: 244.55
I0905 16:45:15.904357 140199535331328 replay_runner.py:36] Average training steps per second: 244.55
I0905 16:45:16.498274 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: 10.23
INFO:tensorflow:Starting iteration 21
I0905 16:45:20.720543 140199535331328 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 245.00

Steps executed: 1000 Episode length: 1000 Return: -96.341988166719255
I0905 16:45:27.998975 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.34
INFO:tensorflow:Starting iteration 22
I0905 16:45:32.063529 140199535331328 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 247.32
I0905 16:45:36.107424 140199535331328 replay_runner.py:36] Average training steps per second: 247.32

Steps executed: 1000 Episode length: 1000 Return: 50.6708409350491855
INFO:tensorflow:Starting iteration 23

Steps executed: 451 Episode length: 451 Return: -61.57888532836621855
INFO:tensorflow:Average training steps per second: 231.12
I0905 16:45:47.727972 140199535331328 replay_runner.py:36] Average training steps per second: 231.12
I0905 16:45:48.630688 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.58
INFO:tensorflow:Starting iteration 24
I0905 16:45:52.558354 140199535331328 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 229.68

Steps executed: 1000 Episode length: 1000 Return: -118.07155335276651
I0905 16:46:00.306772 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.07
INFO:tensorflow:Starting iteration 25

Steps executed: 448 Episode length: 294 Return: 282.45338366994497651
INFO:tensorflow:Average training steps per second: 229.78
I0905 16:46:08.686504 140199535331328 replay_runner.py:36] Average training steps per second: 229.78
I0905 16:46:09.207499 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: 144.38
INFO:tensorflow:Starting iteration 26
I0905 16:46:13.067261 140199535331328 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 226.66

Steps executed: 1000 Episode length: 1000 Return: -35.830818546669946
I0905 16:46:19.815916 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: -35.83
INFO:tensorflow:Starting iteration 27
I0905 16:46:23.821624 140199535331328 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 250.98

Steps executed: 1000 Episode length: 1000 Return: 33.3226037395557946
I0905 16:46:31.579346 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: 33.32
INFO:tensorflow:Starting iteration 28
I0905 16:46:35.364589 140199535331328 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 228.70

Steps executed: 1000 Episode length: 1000 Return: 43.6879083108552946
I0905 16:46:43.337327 140199535331328 run_experiment.py:428] Average undiscounted return per evaluation episode: 43.69
INFO:tensorflow:Starting iteration 29
I0905 16:46:47.505809 140199535331328 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 266.11

Steps executed: 325 Episode length: 325 Return: -625.4595980497452946

Done fixed training!Episode length: 325 Return: -625.4595980497452946