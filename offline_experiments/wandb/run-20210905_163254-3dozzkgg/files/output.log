I0905 16:33:02.015562 140334269278208 run_experiment.py:549] Creating TrainRunner ...
I0905 16:33:02.037129 140334269278208 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:33:02.037709 140334269278208 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:33:02.037941 140334269278208 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:33:02.038100 140334269278208 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:33:02.038223 140334269278208 dqn_agent.py:275] 	 update_period: 4
I0905 16:33:02.038333 140334269278208 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:33:02.038445 140334269278208 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:33:02.038835 140334269278208 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:33:02.039181 140334269278208 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:33:02.039461 140334269278208 dqn_agent.py:280] 	 optimizer: adam
I0905 16:33:02.039734 140334269278208 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:33:02.039902 140334269278208 dqn_agent.py:283] 	 seed: 1630859582037032
I0905 16:33:02.044676 140334269278208 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:33:02.045324 140334269278208 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:33:02.045596 140334269278208 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:33:02.045705 140334269278208 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:33:02.045788 140334269278208 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:33:02.045866 140334269278208 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:33:02.045941 140334269278208 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:33:02.046020 140334269278208 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:33:02.046307 140334269278208 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:33:04.897880 140334269278208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:05.584726 140334269278208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:05.602087 140334269278208 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:33:05.636401 140334269278208 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:33:05.637161 140334269278208 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:33:05.637672 140334269278208 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:33:05.638428 140334269278208 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:33:05.638683 140334269278208 dqn_agent.py:275] 	 update_period: 4
I0905 16:33:05.638987 140334269278208 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:33:05.640984 140334269278208 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:33:05.641222 140334269278208 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:33:05.641459 140334269278208 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:33:05.641739 140334269278208 dqn_agent.py:280] 	 optimizer: adam
I0905 16:33:05.642233 140334269278208 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:33:05.642371 140334269278208 dqn_agent.py:283] 	 seed: 1630859585636247
I0905 16:33:05.648813 140334269278208 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:33:05.649734 140334269278208 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:33:05.651718 140334269278208 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:33:05.652654 140334269278208 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:33:05.653282 140334269278208 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:33:05.654186 140334269278208 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:33:05.654740 140334269278208 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:33:05.654959 140334269278208 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:33:05.656018 140334269278208 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:33:05.712383 140334269278208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:05.759887 140334269278208 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:33:05.760744 140334269278208 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 109.00
I0905 16:33:14.936001 140334269278208 replay_runner.py:36] Average training steps per second: 109.00
Steps executed: 309 Episode length: 124 Return: -303.5876768913175
I0905 16:33:16.868436 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -339.40
INFO:tensorflow:Starting iteration 1

Steps executed: 233 Episode length: 140 Return: -361.9659584341707
INFO:tensorflow:Average training steps per second: 165.36
I0905 16:33:27.972333 140334269278208 replay_runner.py:36] Average training steps per second: 165.36
I0905 16:33:28.243065 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.60
INFO:tensorflow:Starting iteration 2
I0905 16:33:33.692902 140334269278208 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 166.23

Steps executed: 336 Episode length: 159 Return: -527.77521670658136
I0905 16:33:40.153170 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -439.76
INFO:tensorflow:Starting iteration 3
I0905 16:33:45.437314 140334269278208 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 182.00

Steps executed: 1000 Episode length: 1000 Return: -1896.3099651517293
I0905 16:33:54.088814 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -1896.31
INFO:tensorflow:Starting iteration 4
I0905 16:33:59.123445 140334269278208 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 157.32
I0905 16:34:05.481170 140334269278208 replay_runner.py:36] Average training steps per second: 157.32

Steps executed: 1000 Episode length: 1000 Return: -56.772584653437423
INFO:tensorflow:Starting iteration 5
I0905 16:34:15.043832 140334269278208 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 165.49

Steps executed: 1000 Episode length: 1000 Return: -37.356096251377443
I0905 16:34:24.879415 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.36
INFO:tensorflow:Starting iteration 6
I0905 16:34:29.741709 140334269278208 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 187.85

Steps executed: 904 Episode length: 904 Return: -283.3043402282854443
I0905 16:34:37.602250 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.30
INFO:tensorflow:Starting iteration 7
I0905 16:34:42.891030 140334269278208 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 198.01

Steps executed: 364 Episode length: 364 Return: -454.1280912790104543
I0905 16:34:48.558354 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -454.13
INFO:tensorflow:Starting iteration 8

Steps executed: 193 Episode length: 193 Return: -263.9435573541734543
INFO:tensorflow:Average training steps per second: 176.73

Steps executed: 643 Episode length: 450 Return: -424.1760767758949643
I0905 16:35:00.561439 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.06
INFO:tensorflow:Starting iteration 9
I0905 16:35:05.683906 140334269278208 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 167.67
I0905 16:35:11.649364 140334269278208 replay_runner.py:36] Average training steps per second: 167.67

Steps executed: 382 Episode length: 220 Return: -138.8025231940411543
INFO:tensorflow:Starting iteration 10
I0905 16:35:17.355106 140334269278208 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 154.24

Steps executed: 232 Episode length: 232 Return: -106.0958023384563543
I0905 16:35:24.321261 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.10
INFO:tensorflow:Starting iteration 11
I0905 16:35:28.937384 140334269278208 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 163.17

Steps executed: 857 Episode length: 857 Return: -197.4183259256049343
I0905 16:35:37.801766 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.42
INFO:tensorflow:Starting iteration 12

Steps executed: 464 Episode length: 464 Return: -240.3408593523762743
INFO:tensorflow:Average training steps per second: 176.77
I0905 16:35:48.483372 140334269278208 replay_runner.py:36] Average training steps per second: 176.77
I0905 16:35:49.505647 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -240.34
INFO:tensorflow:Starting iteration 13

Steps executed: 253 Episode length: 63 Return: -207.39474170341117143
INFO:tensorflow:Average training steps per second: 187.38
I0905 16:35:59.153914 140334269278208 replay_runner.py:36] Average training steps per second: 187.38
I0905 16:35:59.410532 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.26
INFO:tensorflow:Starting iteration 14
I0905 16:36:04.212894 140334269278208 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 186.78

Steps executed: 923 Episode length: 923 Return: -278.0477230204405743
I0905 16:36:12.467996 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -278.05
INFO:tensorflow:Starting iteration 15
I0905 16:36:16.993515 140334269278208 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 217.72

Steps executed: 1000 Episode length: 1000 Return: -145.91381143364753
I0905 16:36:25.156032 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.91
INFO:tensorflow:Starting iteration 16
I0905 16:36:29.129492 140334269278208 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 286.02

Steps executed: 1000 Episode length: 1000 Return: -16.323550803016758
I0905 16:36:35.186990 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -16.32
INFO:tensorflow:Starting iteration 17
I0905 16:36:38.361279 140334269278208 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 374.83

Steps executed: 1000 Episode length: 1000 Return: -100.07467588461242
I0905 16:36:42.373570 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.07
INFO:tensorflow:Starting iteration 18
I0905 16:36:45.385480 140334269278208 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 386.85

Steps executed: 1000 Episode length: 1000 Return: -138.90334809799745
I0905 16:36:49.662997 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.90
INFO:tensorflow:Starting iteration 19
I0905 16:36:52.829853 140334269278208 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 381.09

Steps executed: 601 Episode length: 601 Return: -82.58571466985629745
I0905 16:36:56.289498 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.59
INFO:tensorflow:Starting iteration 20

Steps executed: 113 Episode length: 113 Return: -255.5282932686216745
INFO:tensorflow:Average training steps per second: 378.48

Steps executed: 574 Episode length: 461 Return: -46.73443022102582745
I0905 16:37:02.618260 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.13
INFO:tensorflow:Starting iteration 21

Steps executed: 295 Episode length: 164 Return: 2.8274377326064837545
INFO:tensorflow:Average training steps per second: 396.84
I0905 16:37:08.310004 140334269278208 replay_runner.py:36] Average training steps per second: 396.84
I0905 16:37:08.434282 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.98
INFO:tensorflow:Starting iteration 22

Steps executed: 257 Episode length: 135 Return: -134.1165592750366745
INFO:tensorflow:Average training steps per second: 400.64
I0905 16:37:14.116404 140334269278208 replay_runner.py:36] Average training steps per second: 400.64
I0905 16:37:14.219285 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.17
INFO:tensorflow:Starting iteration 23

Steps executed: 287 Episode length: 287 Return: 253.39241650604586745
INFO:tensorflow:Average training steps per second: 381.19
I0905 16:37:19.940823 140334269278208 replay_runner.py:36] Average training steps per second: 381.19
I0905 16:37:20.153723 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: 253.39
INFO:tensorflow:Starting iteration 24

Steps executed: 185 Episode length: 132 Return: -204.3036798656491745
INFO:tensorflow:Average training steps per second: 388.48

Steps executed: 718 Episode length: 533 Return: -569.7945054425155745
I0905 16:37:26.580490 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.43
INFO:tensorflow:Starting iteration 25

Steps executed: 55 Episode length: 55 Return: -135.131522633490655745
INFO:tensorflow:Average training steps per second: 395.26

Steps executed: 320 Episode length: 128 Return: -335.5082098599965345
I0905 16:37:32.455164 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.85
INFO:tensorflow:Starting iteration 26

Steps executed: 213 Episode length: 112 Return: -186.9947163336655445
INFO:tensorflow:Average training steps per second: 385.50
I0905 16:37:38.164631 140334269278208 replay_runner.py:36] Average training steps per second: 385.50
I0905 16:37:38.243270 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.97
INFO:tensorflow:Starting iteration 27

Steps executed: 246 Episode length: 246 Return: -141.6155050878112445
INFO:tensorflow:Average training steps per second: 393.48
I0905 16:37:43.904067 140334269278208 replay_runner.py:36] Average training steps per second: 393.48
I0905 16:37:44.057371 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.62
INFO:tensorflow:Starting iteration 28

Steps executed: 133 Episode length: 133 Return: -177.0895679478239445
INFO:tensorflow:Average training steps per second: 383.36

Steps executed: 1108 Episode length: 975 Return: -521.980795791122545
I0905 16:37:51.646111 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -349.54
INFO:tensorflow:Starting iteration 29

Steps executed: 297 Episode length: 148 Return: 19.996246655572108545
INFO:tensorflow:Average training steps per second: 395.89
I0905 16:37:57.305658 140334269278208 replay_runner.py:36] Average training steps per second: 395.89

Done fixed training!Episode length: 148 Return: 19.996246655572108545