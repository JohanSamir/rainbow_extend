I0903 00:00:48.101416 140006414895104 run_experiment.py:549] Creating TrainRunner ...
I0903 00:00:48.109275 140006414895104 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:00:48.109421 140006414895104 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:00:48.109496 140006414895104 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:00:48.109557 140006414895104 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:00:48.109613 140006414895104 dqn_agent.py:275] 	 update_period: 4
I0903 00:00:48.109691 140006414895104 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:00:48.109788 140006414895104 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:00:48.109921 140006414895104 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:00:48.110083 140006414895104 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:00:48.110180 140006414895104 dqn_agent.py:280] 	 optimizer: adam
I0903 00:00:48.110260 140006414895104 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:00:48.110383 140006414895104 dqn_agent.py:283] 	 seed: 1630627248109240
I0903 00:00:48.113049 140006414895104 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:00:48.113175 140006414895104 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:00:48.113254 140006414895104 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:00:48.113320 140006414895104 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:00:48.113378 140006414895104 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:00:48.113461 140006414895104 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:00:48.113517 140006414895104 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:00:48.113570 140006414895104 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:00:48.113621 140006414895104 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:00:48.138101 140006414895104 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:00:48.405741 140006414895104 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:00:48.414096 140006414895104 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:00:48.420670 140006414895104 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:00:48.420920 140006414895104 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:00:48.421087 140006414895104 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:00:48.421284 140006414895104 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:00:48.421423 140006414895104 dqn_agent.py:275] 	 update_period: 4
I0903 00:00:48.421666 140006414895104 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:00:48.421768 140006414895104 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:00:48.421862 140006414895104 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:00:48.421954 140006414895104 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:00:48.422041 140006414895104 dqn_agent.py:280] 	 optimizer: adam
I0903 00:00:48.422126 140006414895104 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:00:48.422219 140006414895104 dqn_agent.py:283] 	 seed: 1630627248420630
I0903 00:00:48.423643 140006414895104 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:00:48.423761 140006414895104 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:00:48.423860 140006414895104 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:00:48.423926 140006414895104 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:00:48.423986 140006414895104 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:00:48.424070 140006414895104 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:00:48.424141 140006414895104 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:00:48.424218 140006414895104 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:00:48.424287 140006414895104 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:00:48.442620 140006414895104 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:00:48.457324 140006414895104 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:00:48.457474 140006414895104 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
Steps executed: 240 Episode length: 135 Return: -361.7304500694886
INFO:tensorflow:Average training steps per second: 247.40
I0903 00:00:52.499595 140006414895104 replay_runner.py:36] Average training steps per second: 247.40
I0903 00:00:53.393663 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -446.17
INFO:tensorflow:Starting iteration 1

Steps executed: 281 Episode length: 135 Return: -386.30664691468473
INFO:tensorflow:Average training steps per second: 311.42
I0903 00:00:59.847249 140006414895104 replay_runner.py:36] Average training steps per second: 311.42
I0903 00:01:00.031590 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -429.78
INFO:tensorflow:Starting iteration 2
I0903 00:01:03.229204 140006414895104 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 335.61
I0903 00:01:06.209261 140006414895104 replay_runner.py:36] Average training steps per second: 335.61

Steps executed: 281 Episode length: 173 Return: -429.81109013490293
INFO:tensorflow:Starting iteration 3

Steps executed: 350 Episode length: 193 Return: -168.61117112462233
INFO:tensorflow:Average training steps per second: 341.35
I0903 00:01:12.726216 140006414895104 replay_runner.py:36] Average training steps per second: 341.35
I0903 00:01:12.953173 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.96
INFO:tensorflow:Starting iteration 4
I0903 00:01:16.414356 140006414895104 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 329.85

Steps executed: 1000 Episode length: 1000 Return: -119.22453217955291
I0903 00:01:22.153281 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.22
INFO:tensorflow:Starting iteration 5
I0903 00:01:25.604543 140006414895104 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 339.07

Steps executed: 1000 Episode length: 1000 Return: -290.29303682504246
I0903 00:01:30.822536 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.29
INFO:tensorflow:Starting iteration 6
I0903 00:01:34.214679 140006414895104 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 330.77

Steps executed: 1000 Episode length: 1000 Return: -154.88314291183926
I0903 00:01:39.132531 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.88
INFO:tensorflow:Starting iteration 7
I0903 00:01:42.404697 140006414895104 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 307.39

Steps executed: 1000 Episode length: 1000 Return: -243.59724855651826
I0903 00:01:47.081998 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.60
INFO:tensorflow:Starting iteration 8

Steps executed: 408 Episode length: 408 Return: -251.4745262581111826
INFO:tensorflow:Average training steps per second: 313.10
I0903 00:01:53.585282 140006414895104 replay_runner.py:36] Average training steps per second: 313.10
I0903 00:01:53.987321 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -251.47
INFO:tensorflow:Starting iteration 9

Steps executed: 641 Episode length: 641 Return: -268.5169333342751826
INFO:tensorflow:Average training steps per second: 318.74
I0903 00:02:00.385217 140006414895104 replay_runner.py:36] Average training steps per second: 318.74
I0903 00:02:01.279487 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.52
INFO:tensorflow:Starting iteration 10

Steps executed: 302 Episode length: 302 Return: -125.6099425506968126
INFO:tensorflow:Average training steps per second: 321.74
I0903 00:02:07.726485 140006414895104 replay_runner.py:36] Average training steps per second: 321.74
I0903 00:02:07.958407 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.61
INFO:tensorflow:Starting iteration 11

Steps executed: 413 Episode length: 413 Return: -178.6494536585144626
INFO:tensorflow:Average training steps per second: 339.61
I0903 00:02:14.273695 140006414895104 replay_runner.py:36] Average training steps per second: 339.61
I0903 00:02:14.735771 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.65
INFO:tensorflow:Starting iteration 12

Steps executed: 637 Episode length: 637 Return: -246.7631487647645726
INFO:tensorflow:Average training steps per second: 346.96
I0903 00:02:21.082078 140006414895104 replay_runner.py:36] Average training steps per second: 346.96
I0903 00:02:22.120688 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -246.76
INFO:tensorflow:Starting iteration 13
I0903 00:02:25.610594 140006414895104 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 322.65

Steps executed: 1000 Episode length: 1000 Return: -151.10695497987595
I0903 00:02:30.564820 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.11
INFO:tensorflow:Starting iteration 14

Steps executed: 634 Episode length: 634 Return: -293.7229854591838695
INFO:tensorflow:Average training steps per second: 345.40
I0903 00:02:36.887916 140006414895104 replay_runner.py:36] Average training steps per second: 345.40
I0903 00:02:37.730997 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.72
INFO:tensorflow:Starting iteration 15
I0903 00:02:41.245575 140006414895104 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 335.85

Steps executed: 1000 Episode length: 1000 Return: -128.91884166350715
I0903 00:02:46.517919 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.92
INFO:tensorflow:Starting iteration 16
I0903 00:02:50.020902 140006414895104 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 330.30

Steps executed: 1000 Episode length: 1000 Return: -138.94533640150777
I0903 00:02:55.131649 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.95
INFO:tensorflow:Starting iteration 17
I0903 00:02:58.566133 140006414895104 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 325.72

Steps executed: 1000 Episode length: 1000 Return: -105.82514083981324
I0903 00:03:05.009746 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.83
INFO:tensorflow:Starting iteration 18
I0903 00:03:08.401638 140006414895104 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 325.43

Steps executed: 1000 Episode length: 1000 Return: -159.65643029433105
I0903 00:03:13.228029 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.66
INFO:tensorflow:Starting iteration 19

Steps executed: 378 Episode length: 378 Return: -32.72804079152439105
INFO:tensorflow:Average training steps per second: 307.50
I0903 00:03:19.641812 140006414895104 replay_runner.py:36] Average training steps per second: 307.50
I0903 00:03:20.047642 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -32.73
INFO:tensorflow:Starting iteration 20
I0903 00:03:23.307585 140006414895104 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 317.33

Steps executed: 437 Episode length: 437 Return: -98.39727336682158105
I0903 00:03:27.067287 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.40
INFO:tensorflow:Starting iteration 21

Steps executed: 238 Episode length: 116 Return: -630.4466426453587105
INFO:tensorflow:Average training steps per second: 299.95
I0903 00:03:33.648155 140006414895104 replay_runner.py:36] Average training steps per second: 299.95
I0903 00:03:33.811420 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -542.87
INFO:tensorflow:Starting iteration 22
I0903 00:03:37.082616 140006414895104 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 323.26

Steps executed: 258 Episode length: 258 Return: 291.09710408661795105
I0903 00:03:40.395111 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: 291.10
INFO:tensorflow:Starting iteration 23
I0903 00:03:43.820457 140006414895104 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 320.58

Steps executed: 1000 Episode length: 1000 Return: 27.1729913659484985
I0903 00:03:48.921261 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: 27.17
INFO:tensorflow:Starting iteration 24

Steps executed: 248 Episode length: 111 Return: -348.4942098045042585
INFO:tensorflow:Average training steps per second: 321.54
I0903 00:03:55.491286 140006414895104 replay_runner.py:36] Average training steps per second: 321.54
I0903 00:03:55.630562 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.52
INFO:tensorflow:Starting iteration 25
I0903 00:03:58.972630 140006414895104 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 317.78

Steps executed: 323 Episode length: 323 Return: -582.9991020609909585
I0903 00:04:02.410149 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -583.00
INFO:tensorflow:Starting iteration 26

Steps executed: 381 Episode length: 381 Return: -402.3641599621102585
INFO:tensorflow:Average training steps per second: 317.26
I0903 00:04:08.814629 140006414895104 replay_runner.py:36] Average training steps per second: 317.26
I0903 00:04:09.152737 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -402.36
INFO:tensorflow:Starting iteration 27

Steps executed: 650 Episode length: 567 Return: -324.4981912392508585
INFO:tensorflow:Average training steps per second: 306.91
I0903 00:04:15.662421 140006414895104 replay_runner.py:36] Average training steps per second: 306.91
I0903 00:04:16.455473 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.33
INFO:tensorflow:Starting iteration 28

Steps executed: 339 Episode length: 150 Return: -123.3925288924188285
INFO:tensorflow:Average training steps per second: 340.45
I0903 00:04:22.580711 140006414895104 replay_runner.py:36] Average training steps per second: 340.45
I0903 00:04:22.799758 140006414895104 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.05
INFO:tensorflow:Starting iteration 29
I0903 00:04:25.905136 140006414895104 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 336.07

Steps executed: 1000 Episode length: 1000 Return: -4.9085863613178875

Done fixed training! Episode length: 1000 Return: -4.9085863613178875