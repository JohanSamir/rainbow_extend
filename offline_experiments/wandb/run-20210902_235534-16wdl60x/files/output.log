Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0902 23:55:40.712257 139803223304192 run_experiment.py:549] Creating TrainRunner ...
I0902 23:55:40.720874 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:55:40.721049 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:55:40.721437 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:55:40.721622 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:55:40.721735 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0902 23:55:40.721816 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:55:40.721945 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:55:40.722127 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:55:40.722297 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:55:40.722410 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0902 23:55:40.722548 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:55:40.722652 139803223304192 dqn_agent.py:283] 	 seed: 1630626940720823
I0902 23:55:40.725749 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:55:40.725985 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:55:40.726261 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:55:40.726461 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:55:40.726573 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:55:40.726699 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:55:40.726820 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:55:40.727045 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:55:40.727201 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:55:40.765542 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:55:41.171112 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:55:41.565617 139803223304192 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:55:41.575309 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:55:41.575514 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:55:41.575904 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:55:41.576036 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:55:41.576143 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0902 23:55:41.576256 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:55:41.576393 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:55:41.576601 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:55:41.576708 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:55:41.576928 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0902 23:55:41.577090 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:55:41.577191 139803223304192 dqn_agent.py:283] 	 seed: 1630626941575224
I0902 23:55:41.579693 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:55:41.579877 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:55:41.580049 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:55:41.580252 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:55:41.580451 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:55:41.580612 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:55:41.580743 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:55:41.580884 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:55:41.580980 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:55:41.614150 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:55:41.636738 139803223304192 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:55:41.637096 139803223304192 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 164.20
I0902 23:55:47.727809 139803223304192 replay_runner.py:36] Average training steps per second: 164.20
Steps executed: 221 Episode length: 121 Return: -272.0815876166864
I0902 23:55:48.917422 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -475.25
INFO:tensorflow:Starting iteration 1

Steps executed: 342 Episode length: 146 Return: -531.65626207601377
INFO:tensorflow:Average training steps per second: 235.50
I0902 23:55:57.383400 139803223304192 replay_runner.py:36] Average training steps per second: 235.50
I0902 23:55:57.705716 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -486.68
INFO:tensorflow:Starting iteration 2
I0902 23:56:02.031642 139803223304192 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 226.17

Steps executed: 369 Episode length: 232 Return: -255.00659173674194
I0902 23:56:06.863133 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -240.62
INFO:tensorflow:Starting iteration 3
I0902 23:56:11.231629 139803223304192 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 227.82
I0902 23:56:15.621335 139803223304192 replay_runner.py:36] Average training steps per second: 227.82

Steps executed: 579 Episode length: 579 Return: -312.90193330118814
INFO:tensorflow:Starting iteration 4

Steps executed: 433 Episode length: 433 Return: -30.781242616359563
INFO:tensorflow:Average training steps per second: 225.33
I0902 23:56:25.265340 139803223304192 replay_runner.py:36] Average training steps per second: 225.33
I0902 23:56:26.055356 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -30.78
INFO:tensorflow:Starting iteration 5
I0902 23:56:30.370771 139803223304192 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 219.87

Steps executed: 1000 Episode length: 1000 Return: -166.6237094167975
I0902 23:56:37.879237 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.62
INFO:tensorflow:Starting iteration 6
I0902 23:56:42.169473 139803223304192 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 214.81

Steps executed: 1000 Episode length: 1000 Return: -142.11727231907972
I0902 23:56:49.790063 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.12
INFO:tensorflow:Starting iteration 7
I0902 23:56:54.194669 139803223304192 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 223.83

Steps executed: 1000 Episode length: 1000 Return: -169.46636734495792
I0902 23:57:00.833718 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.47
INFO:tensorflow:Starting iteration 8

Steps executed: 583 Episode length: 583 Return: -299.3936826890406592
INFO:tensorflow:Average training steps per second: 218.87
I0902 23:57:09.714276 139803223304192 replay_runner.py:36] Average training steps per second: 218.87
I0902 23:57:10.587715 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -299.39
INFO:tensorflow:Starting iteration 9
I0902 23:57:14.881777 139803223304192 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 221.81

Steps executed: 1000 Episode length: 1000 Return: -130.01265379533982
I0902 23:57:21.321519 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.01
INFO:tensorflow:Starting iteration 10
I0902 23:57:25.425935 139803223304192 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 226.74

Steps executed: 1000 Episode length: 1000 Return: -64.689871701574892
I0902 23:57:33.254894 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -64.69
INFO:tensorflow:Starting iteration 11

Steps executed: 239 Episode length: 152 Return: -244.4181780905323692
INFO:tensorflow:Average training steps per second: 228.24
I0902 23:57:41.944653 139803223304192 replay_runner.py:36] Average training steps per second: 228.24
I0902 23:57:42.154028 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.79
INFO:tensorflow:Starting iteration 12
I0902 23:57:46.389597 139803223304192 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 235.79

Steps executed: 458 Episode length: 458 Return: -230.3252253346352692
I0902 23:57:51.428469 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.33
INFO:tensorflow:Starting iteration 13
I0902 23:57:55.559036 139803223304192 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 234.73

Steps executed: 1000 Episode length: 1000 Return: -170.20217177081372
I0902 23:58:01.870991 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.20
INFO:tensorflow:Starting iteration 14

Steps executed: 344 Episode length: 344 Return: -380.2612446680261372
INFO:tensorflow:Average training steps per second: 249.61
I0902 23:58:09.998850 139803223304192 replay_runner.py:36] Average training steps per second: 249.61
I0902 23:58:10.449926 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -380.26
INFO:tensorflow:Starting iteration 15

Steps executed: 304 Episode length: 161 Return: -243.5955799264795372
INFO:tensorflow:Average training steps per second: 252.41
I0902 23:58:18.500729 139803223304192 replay_runner.py:36] Average training steps per second: 252.41
I0902 23:58:18.760053 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.78
INFO:tensorflow:Starting iteration 16
I0902 23:58:22.855486 139803223304192 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 252.08

Steps executed: 362 Episode length: 362 Return: -26.17489575100418672
I0902 23:58:27.267770 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -26.17
INFO:tensorflow:Starting iteration 17

Steps executed: 268 Episode length: 199 Return: -73.32558988676128672
INFO:tensorflow:Average training steps per second: 252.28
I0902 23:58:35.367873 139803223304192 replay_runner.py:36] Average training steps per second: 252.28
I0902 23:58:35.589160 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -181.63
INFO:tensorflow:Starting iteration 18

Steps executed: 311 Episode length: 157 Return: -108.5718391568888672
INFO:tensorflow:Average training steps per second: 264.58
I0902 23:58:43.334813 139803223304192 replay_runner.py:36] Average training steps per second: 264.58
I0902 23:58:43.582059 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.91
INFO:tensorflow:Starting iteration 19
I0902 23:58:47.561175 139803223304192 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 275.46

Steps executed: 1000 Episode length: 1000 Return: -49.169320322301092
I0902 23:58:54.730765 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -49.17
INFO:tensorflow:Starting iteration 20

Steps executed: 282 Episode length: 176 Return: -42.71014449910538092
INFO:tensorflow:Average training steps per second: 284.68
I0902 23:59:02.053749 139803223304192 replay_runner.py:36] Average training steps per second: 284.68
I0902 23:59:02.254392 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -64.37
INFO:tensorflow:Starting iteration 21

Steps executed: 631 Episode length: 631 Return: -333.1303998095739392
INFO:tensorflow:Average training steps per second: 303.74
I0902 23:59:09.221763 139803223304192 replay_runner.py:36] Average training steps per second: 303.74
I0902 23:59:10.519873 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.13
INFO:tensorflow:Starting iteration 22

Steps executed: 339 Episode length: 210 Return: -56.44402550462488692
INFO:tensorflow:Average training steps per second: 316.64
I0902 23:59:17.294403 139803223304192 replay_runner.py:36] Average training steps per second: 316.64
I0902 23:59:17.573530 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -39.53
INFO:tensorflow:Starting iteration 23

Steps executed: 234 Episode length: 54 Return: -308.86614898287892892
INFO:tensorflow:Average training steps per second: 312.00
I0902 23:59:24.308548 139803223304192 replay_runner.py:36] Average training steps per second: 312.00
I0902 23:59:24.472019 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.99
INFO:tensorflow:Starting iteration 24

Steps executed: 283 Episode length: 144 Return: -138.2519912190524892
INFO:tensorflow:Average training steps per second: 316.19
I0902 23:59:31.165849 139803223304192 replay_runner.py:36] Average training steps per second: 316.19
I0902 23:59:31.376550 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.48
INFO:tensorflow:Starting iteration 25

Steps executed: 202 Episode length: 202 Return: -329.4022086715350592
INFO:tensorflow:Average training steps per second: 336.26
I0902 23:59:37.823266 139803223304192 replay_runner.py:36] Average training steps per second: 336.26
I0902 23:59:38.000212 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.40
INFO:tensorflow:Starting iteration 26

Steps executed: 300 Episode length: 135 Return: -496.3293402102214592
INFO:tensorflow:Average training steps per second: 342.82
I0902 23:59:44.448414 139803223304192 replay_runner.py:36] Average training steps per second: 342.82
I0902 23:59:44.660583 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -654.98
INFO:tensorflow:Starting iteration 27
I0902 23:59:48.222308 139803223304192 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 342.98


Steps executed: 1126 Episode length: 1000 Return: 47.7833451729685952
I0902 23:59:53.971663 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.48
INFO:tensorflow:Starting iteration 28

Steps executed: 404 Episode length: 266 Return: -223.5431346764060852
INFO:tensorflow:Average training steps per second: 301.91
I0903 00:00:00.456658 139803223304192 replay_runner.py:36] Average training steps per second: 301.91
I0903 00:00:00.760160 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.97
INFO:tensorflow:Starting iteration 29
I0903 00:00:03.921657 139803223304192 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 299.67
I0903 00:00:07.258945 139803223304192 replay_runner.py:36] Average training steps per second: 299.67


Done fixed training!Episode length: 216 Return: -309.7625328034348552