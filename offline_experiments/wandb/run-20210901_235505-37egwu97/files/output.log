Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0901 23:55:11.996032 139929824643072 run_experiment.py:549] Creating TrainRunner ...
I0901 23:55:12.009907 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:55:12.010164 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:55:12.010271 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:55:12.010355 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:55:12.010431 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0901 23:55:12.010574 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:55:12.010684 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:55:12.010818 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:55:12.010944 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:55:12.011061 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0901 23:55:12.011154 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:55:12.011258 139929824643072 dqn_agent.py:283] 	 seed: 1630540512009828
I0901 23:55:12.013922 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:55:12.014088 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:55:12.014185 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:55:12.014247 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:55:12.014299 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:55:12.014349 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:55:12.014398 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:55:12.014445 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:55:12.014491 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:55:12.060211 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:55:12.465878 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:55:12.499516 139929824643072 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:55:12.509188 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:55:12.509464 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:55:12.509629 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:55:12.509758 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:55:12.509871 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0901 23:55:12.510032 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:55:12.510285 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:55:12.510424 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:55:12.510541 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:55:12.510680 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0901 23:55:12.510796 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:55:12.510906 139929824643072 dqn_agent.py:283] 	 seed: 1630540512509128
I0901 23:55:12.513607 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:55:12.513784 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:55:12.513910 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:55:12.514067 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:55:12.514299 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:55:12.514437 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:55:12.514555 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:55:12.514666 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:55:12.514800 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:55:12.545724 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:55:12.567513 139929824643072 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:55:12.567804 139929824643072 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 161.64
I0901 23:55:18.754657 139929824643072 replay_runner.py:36] Average training steps per second: 161.64
Steps executed: 262 Episode length: 142 Return: -224.3005934444208
I0901 23:55:20.020744 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.68
INFO:tensorflow:Starting iteration 1

Steps executed: 231 Episode length: 134 Return: -371.4779100688938
INFO:tensorflow:Average training steps per second: 224.88
I0901 23:55:28.823905 139929824643072 replay_runner.py:36] Average training steps per second: 224.88
I0901 23:55:29.017571 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -395.20
INFO:tensorflow:Starting iteration 2

Steps executed: 302 Episode length: 302 Return: -515.1944904734804
INFO:tensorflow:Average training steps per second: 212.38
I0901 23:55:38.163561 139929824643072 replay_runner.py:36] Average training steps per second: 212.38
I0901 23:55:38.578014 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -515.19
INFO:tensorflow:Starting iteration 3
I0901 23:55:42.824675 139929824643072 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 219.72

Steps executed: 632 Episode length: 632 Return: -309.74935537954946
I0901 23:55:48.991874 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.75
INFO:tensorflow:Starting iteration 4
I0901 23:55:53.037641 139929824643072 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 223.83

Steps executed: 1000 Episode length: 1000 Return: -120.38044347302299
I0901 23:56:00.024185 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.38
INFO:tensorflow:Starting iteration 5
I0901 23:56:04.426415 139929824643072 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 220.92

Steps executed: 1000 Episode length: 1000 Return: -68.212584780164829
I0901 23:56:11.397425 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.21
INFO:tensorflow:Starting iteration 6
I0901 23:56:15.680253 139929824643072 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 220.89

Steps executed: 1000 Episode length: 1000 Return: -47.324163792632469
I0901 23:56:23.151054 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -47.32
INFO:tensorflow:Starting iteration 7
I0901 23:56:27.465525 139929824643072 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 222.26

Steps executed: 338 Episode length: 145 Return: -88.40314832129982469
I0901 23:56:32.316687 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.68
INFO:tensorflow:Starting iteration 8
I0901 23:56:36.493675 139929824643072 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 228.14

Steps executed: 1000 Episode length: 1000 Return: -163.93560336687128
I0901 23:56:43.269992 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.94
INFO:tensorflow:Starting iteration 9
I0901 23:56:47.469790 139929824643072 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 232.42

Steps executed: 1000 Episode length: 1000 Return: -68.933302770972088
I0901 23:56:55.607368 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.93
INFO:tensorflow:Starting iteration 10
I0901 23:56:59.908560 139929824643072 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 231.10

Steps executed: 254 Episode length: 254 Return: -169.3349310912738088
I0901 23:57:04.500823 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.33
INFO:tensorflow:Starting iteration 11
I0901 23:57:08.841513 139929824643072 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 224.11

Steps executed: 1000 Episode length: 1000 Return: -140.56075767556516
I0901 23:57:17.649159 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.56
INFO:tensorflow:Starting iteration 12
I0901 23:57:21.994763 139929824643072 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 218.34

Steps executed: 1000 Episode length: 1000 Return: -124.24964693727796
I0901 23:57:29.054430 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.25
INFO:tensorflow:Starting iteration 13
I0901 23:57:33.479687 139929824643072 replay_runner.py:41] Starting iteration 13

Steps executed: 1000 Episode length: 1000 Return: -151.78414834648515
I0901 23:57:40.931833 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.78
INFO:tensorflow:Starting iteration 14

Steps executed: 170 Episode length: 170 Return: -427.4632062281800715
INFO:tensorflow:Average training steps per second: 224.35

Steps executed: 1170 Episode length: 1000 Return: -202.04961743360212
I0901 23:57:52.709092 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.76
INFO:tensorflow:Starting iteration 15

Steps executed: 282 Episode length: 282 Return: -67.17972913673430212
INFO:tensorflow:Average training steps per second: 217.70
I0901 23:58:01.575285 139929824643072 replay_runner.py:36] Average training steps per second: 217.70
I0901 23:58:01.921646 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -67.18
INFO:tensorflow:Starting iteration 16

Steps executed: 270 Episode length: 270 Return: -185.1420096357332712
INFO:tensorflow:Average training steps per second: 222.51
I0901 23:58:10.869510 139929824643072 replay_runner.py:36] Average training steps per second: 222.51
I0901 23:58:11.200296 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.14
INFO:tensorflow:Starting iteration 17
I0901 23:58:15.467776 139929824643072 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 222.18
I0901 23:58:19.968896 139929824643072 replay_runner.py:36] Average training steps per second: 222.18

Steps executed: 221 Episode length: 221 Return: -103.0420940572246212
INFO:tensorflow:Starting iteration 18

Steps executed: 103 Episode length: 103 Return: -54.66873342513450512
INFO:tensorflow:Average training steps per second: 222.24
I0901 23:58:29.120899 139929824643072 replay_runner.py:36] Average training steps per second: 222.24

Steps executed: 533 Episode length: 430 Return: -82.32105152855475512
INFO:tensorflow:Starting iteration 19

Steps executed: 333 Episode length: 333 Return: -126.3375456129917212
INFO:tensorflow:Average training steps per second: 216.13
I0901 23:58:38.933561 139929824643072 replay_runner.py:36] Average training steps per second: 216.13
I0901 23:58:39.401540 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.34
INFO:tensorflow:Starting iteration 20
I0901 23:58:43.647858 139929824643072 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 229.37
I0901 23:58:48.008104 139929824643072 replay_runner.py:36] Average training steps per second: 229.37

Steps executed: 295 Episode length: 194 Return: -118.2432081292595712
INFO:tensorflow:Starting iteration 21

Steps executed: 322 Episode length: 136 Return: -74.24592520590286712
INFO:tensorflow:Average training steps per second: 223.05
I0901 23:58:57.105656 139929824643072 replay_runner.py:36] Average training steps per second: 223.05
I0901 23:58:57.424565 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -421.58
INFO:tensorflow:Starting iteration 22

Steps executed: 123 Episode length: 123 Return: -81.61889996018766712
INFO:tensorflow:Average training steps per second: 231.55
I0901 23:59:05.957774 139929824643072 replay_runner.py:36] Average training steps per second: 231.55

Steps executed: 336 Episode length: 213 Return: -388.8096854724435712
INFO:tensorflow:Starting iteration 23

Steps executed: 331 Episode length: 171 Return: -487.7205488043897512
INFO:tensorflow:Average training steps per second: 224.66
I0901 23:59:14.947131 139929824643072 replay_runner.py:36] Average training steps per second: 224.66
I0901 23:59:15.299769 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.11
INFO:tensorflow:Starting iteration 24
I0901 23:59:19.692736 139929824643072 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 220.53

Steps executed: 527 Episode length: 404 Return: -529.7900171010018512
I0901 23:59:24.991118 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -282.98
INFO:tensorflow:Starting iteration 25

Steps executed: 149 Episode length: 149 Return: -452.8665277190464512
INFO:tensorflow:Average training steps per second: 213.82
I0901 23:59:34.047368 139929824643072 replay_runner.py:36] Average training steps per second: 213.82

Steps executed: 333 Episode length: 184 Return: -822.2517113491939512
INFO:tensorflow:Starting iteration 26
I0901 23:59:38.545235 139929824643072 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 234.02

Steps executed: 366 Episode length: 177 Return: -34.99543081597143512
I0901 23:59:43.181737 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -14.90
INFO:tensorflow:Starting iteration 27

Steps executed: 267 Episode length: 144 Return: -119.6002985009082812
INFO:tensorflow:Average training steps per second: 241.51
I0901 23:59:51.495170 139929824643072 replay_runner.py:36] Average training steps per second: 241.51
I0901 23:59:51.741563 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -419.37
INFO:tensorflow:Starting iteration 28

Steps executed: 50 Episode length: 50 Return: -394.542376036517882812
INFO:tensorflow:Average training steps per second: 240.24
I0902 00:00:00.373883 139929824643072 replay_runner.py:36] Average training steps per second: 240.24

Steps executed: 262 Episode length: 125 Return: -768.9076595423535812
INFO:tensorflow:Starting iteration 29

Steps executed: 281 Episode length: 143 Return: -21.75657683824639812
INFO:tensorflow:Average training steps per second: 228.69
I0902 00:00:09.148612 139929824643072 replay_runner.py:36] Average training steps per second: 228.69

Done fixed training!Episode length: 143 Return: -21.75657683824639812