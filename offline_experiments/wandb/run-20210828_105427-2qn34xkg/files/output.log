Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0828 10:54:33.347419 139779140274176 run_experiment.py:549] Creating TrainRunner ...
I0828 10:54:33.355056 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:54:33.355175 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:54:33.355251 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:54:33.355356 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:54:33.355414 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:54:33.355470 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:54:33.355562 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:54:33.355628 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:54:33.355697 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:54:33.355784 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:54:33.355884 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:54:33.355933 139779140274176 dqn_agent.py:283] 	 seed: 1630148073355024
I0828 10:54:33.357716 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:54:33.357911 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:54:33.358016 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:54:33.358086 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:54:33.358157 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:54:33.358235 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:54:33.358303 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:54:33.358357 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:54:33.358409 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:54:33.381962 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:33.627612 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:33.637212 139779140274176 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:54:33.644479 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:54:33.644696 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:54:33.644819 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:54:33.644956 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:54:33.645048 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:54:33.645124 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:54:33.645212 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:54:33.645298 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:54:33.645353 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:54:33.645438 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:54:33.645524 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:54:33.645581 139779140274176 dqn_agent.py:283] 	 seed: 1630148073644437
I0828 10:54:33.647267 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:54:33.647408 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:54:33.647498 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:54:33.647570 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:54:33.647642 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:54:33.647703 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:54:33.647789 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:54:33.647855 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:54:33.647952 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:54:33.670522 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:33.685565 139779140274176 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:54:33.685715 139779140274176 replay_runner.py:41] Starting iteration 0
Steps executed: 215 Episode length: 81 Return: -603.59196568217325
INFO:tensorflow:Average training steps per second: 237.40
I0828 10:54:37.898231 139779140274176 replay_runner.py:36] Average training steps per second: 237.40
I0828 10:54:38.629495 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -601.41
INFO:tensorflow:Starting iteration 1

Steps executed: 321 Episode length: 154 Return: -539.2721952048794
INFO:tensorflow:Average training steps per second: 325.86
I0828 10:54:45.077941 139779140274176 replay_runner.py:36] Average training steps per second: 325.86
I0828 10:54:45.251606 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -588.03
INFO:tensorflow:Starting iteration 2

Steps executed: 282 Episode length: 116 Return: -640.2012437842269
INFO:tensorflow:Average training steps per second: 323.23
I0828 10:54:51.607887 139779140274176 replay_runner.py:36] Average training steps per second: 323.23
I0828 10:54:51.757758 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -668.62
INFO:tensorflow:Starting iteration 3

Steps executed: 286 Episode length: 120 Return: -633.1506407636701
INFO:tensorflow:Average training steps per second: 325.33
I0828 10:54:58.089086 139779140274176 replay_runner.py:36] Average training steps per second: 325.33
I0828 10:54:58.241510 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -518.92
INFO:tensorflow:Starting iteration 4

Steps executed: 297 Episode length: 186 Return: -338.9030076098903
INFO:tensorflow:Average training steps per second: 331.74
I0828 10:55:04.591056 139779140274176 replay_runner.py:36] Average training steps per second: 331.74
I0828 10:55:04.769837 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -476.85
INFO:tensorflow:Starting iteration 5
I0828 10:55:08.111636 139779140274176 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 325.95

Steps executed: 338 Episode length: 150 Return: -279.57856476550594
I0828 10:55:11.357281 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.38
INFO:tensorflow:Starting iteration 6

Steps executed: 202 Episode length: 202 Return: -290.72228579782825
INFO:tensorflow:Average training steps per second: 331.36
I0828 10:55:17.694190 139779140274176 replay_runner.py:36] Average training steps per second: 331.36
I0828 10:55:17.805960 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.72
INFO:tensorflow:Starting iteration 7

Steps executed: 217 Episode length: 217 Return: -78.758188717609955
INFO:tensorflow:Average training steps per second: 327.98
I0828 10:55:24.118246 139779140274176 replay_runner.py:36] Average training steps per second: 327.98
I0828 10:55:24.239961 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.76
INFO:tensorflow:Starting iteration 8

Steps executed: 300 Episode length: 143 Return: -86.663835260642575
INFO:tensorflow:Average training steps per second: 323.57
I0828 10:55:30.599486 139779140274176 replay_runner.py:36] Average training steps per second: 323.57
I0828 10:55:30.762374 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.14
INFO:tensorflow:Starting iteration 9
I0828 10:55:33.996082 139779140274176 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 314.91
I0828 10:55:37.171955 139779140274176 replay_runner.py:36] Average training steps per second: 314.91

Steps executed: 200 Episode length: 200 Return: -239.27553963318172
INFO:tensorflow:Starting iteration 10

Steps executed: 335 Episode length: 165 Return: -291.29064637106812
INFO:tensorflow:Average training steps per second: 313.94
I0828 10:55:43.751542 139779140274176 replay_runner.py:36] Average training steps per second: 313.94
I0828 10:55:43.921164 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.66
INFO:tensorflow:Starting iteration 11

Steps executed: 379 Episode length: 183 Return: -200.78250367391314
INFO:tensorflow:Average training steps per second: 319.81
I0828 10:55:50.282932 139779140274176 replay_runner.py:36] Average training steps per second: 319.81
I0828 10:55:50.500927 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.23
INFO:tensorflow:Starting iteration 12

Steps executed: 279 Episode length: 128 Return: -219.25097890169654
INFO:tensorflow:Average training steps per second: 318.38
I0828 10:55:56.890322 139779140274176 replay_runner.py:36] Average training steps per second: 318.38
I0828 10:55:57.024723 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -313.81
INFO:tensorflow:Starting iteration 13
I0828 10:56:00.269279 139779140274176 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 323.05
I0828 10:56:03.365082 139779140274176 replay_runner.py:36] Average training steps per second: 323.05

Steps executed: 338 Episode length: 142 Return: -46.287999084805588
INFO:tensorflow:Starting iteration 14

Steps executed: 424 Episode length: 276 Return: 239.159518465041465
INFO:tensorflow:Average training steps per second: 316.38
I0828 10:56:09.948746 139779140274176 replay_runner.py:36] Average training steps per second: 316.38
I0828 10:56:10.238326 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -27.03
INFO:tensorflow:Starting iteration 15

Steps executed: 237 Episode length: 237 Return: -246.45757010715204
INFO:tensorflow:Average training steps per second: 321.94
I0828 10:56:16.637808 139779140274176 replay_runner.py:36] Average training steps per second: 321.94
I0828 10:56:16.768669 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -246.46
INFO:tensorflow:Starting iteration 16

Steps executed: 332 Episode length: 152 Return: -266.39327855511154
INFO:tensorflow:Average training steps per second: 326.37
I0828 10:56:23.155031 139779140274176 replay_runner.py:36] Average training steps per second: 326.37
I0828 10:56:23.322363 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.42
INFO:tensorflow:Starting iteration 17
I0828 10:56:26.611472 139779140274176 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 323.37

Steps executed: 294 Episode length: 153 Return: -84.873022560508164
I0828 10:56:29.857659 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.67
INFO:tensorflow:Starting iteration 18

Steps executed: 279 Episode length: 181 Return: -290.57346671171484
INFO:tensorflow:Average training steps per second: 318.98
I0828 10:56:36.282052 139779140274176 replay_runner.py:36] Average training steps per second: 318.98
I0828 10:56:36.419101 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -291.95
INFO:tensorflow:Starting iteration 19

Steps executed: 361 Episode length: 196 Return: -42.060622175310464
INFO:tensorflow:Average training steps per second: 321.94
I0828 10:56:42.833806 139779140274176 replay_runner.py:36] Average training steps per second: 321.94
I0828 10:56:43.037122 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -52.76
INFO:tensorflow:Starting iteration 20

Steps executed: 241 Episode length: 128 Return: -277.41234408303393
INFO:tensorflow:Average training steps per second: 326.52
I0828 10:56:49.419460 139779140274176 replay_runner.py:36] Average training steps per second: 326.52
I0828 10:56:49.526183 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.55
INFO:tensorflow:Starting iteration 21

Steps executed: 233 Episode length: 99 Return: -298.134686575340283
INFO:tensorflow:Average training steps per second: 323.11
I0828 10:56:55.914254 139779140274176 replay_runner.py:36] Average training steps per second: 323.11
I0828 10:56:56.018032 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.53
INFO:tensorflow:Starting iteration 22

Steps executed: 273 Episode length: 120 Return: -82.138648574037493
INFO:tensorflow:Average training steps per second: 324.17
I0828 10:57:02.395286 139779140274176 replay_runner.py:36] Average training steps per second: 324.17
I0828 10:57:02.533018 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.99
INFO:tensorflow:Starting iteration 23

Steps executed: 251 Episode length: 153 Return: -203.51647301287034
INFO:tensorflow:Average training steps per second: 320.69
I0828 10:57:08.936915 139779140274176 replay_runner.py:36] Average training steps per second: 320.69
I0828 10:57:09.070763 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.81
INFO:tensorflow:Starting iteration 24
I0828 10:57:12.381291 139779140274176 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 322.39

Steps executed: 238 Episode length: 134 Return: -294.23260973805446
I0828 10:57:15.610338 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.32
INFO:tensorflow:Starting iteration 25

Steps executed: 288 Episode length: 144 Return: -53.401602128354548
INFO:tensorflow:Average training steps per second: 331.36
I0828 10:57:21.919988 139779140274176 replay_runner.py:36] Average training steps per second: 331.36
I0828 10:57:22.081299 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.82
INFO:tensorflow:Starting iteration 26

Steps executed: 336 Episode length: 208 Return: -124.85130298059059
INFO:tensorflow:Average training steps per second: 343.85
I0828 10:57:28.161153 139779140274176 replay_runner.py:36] Average training steps per second: 343.85
I0828 10:57:28.349472 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.07
INFO:tensorflow:Starting iteration 27

Steps executed: 302 Episode length: 145 Return: -119.39594944681726
INFO:tensorflow:Average training steps per second: 362.49
I0828 10:57:34.261547 139779140274176 replay_runner.py:36] Average training steps per second: 362.49
I0828 10:57:34.398221 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.71
INFO:tensorflow:Starting iteration 28

Steps executed: 342 Episode length: 210 Return: -40.015468635660552
INFO:tensorflow:Average training steps per second: 362.87
I0828 10:57:40.140624 139779140274176 replay_runner.py:36] Average training steps per second: 362.87
I0828 10:57:40.311631 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.49
INFO:tensorflow:Starting iteration 29
I0828 10:57:43.250248 139779140274176 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 403.14

Steps executed: 231 Episode length: 138 Return: -312.81764877082355

Done fixed training!Episode length: 138 Return: -312.81764877082355