Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0901 12:34:40.880950 139803418769408 run_experiment.py:549] Creating TrainRunner ...
I0901 12:34:40.892909 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:34:40.893172 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:34:40.893600 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:34:40.893778 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:34:40.894026 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 12:34:40.894265 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:34:40.894384 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:34:40.894460 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:34:40.894593 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:34:40.894723 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 12:34:40.895194 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:34:40.895349 139803418769408 dqn_agent.py:283] 	 seed: 1630499680892841
I0901 12:34:40.899059 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:34:40.899295 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:34:40.899462 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:34:40.899606 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:34:40.899712 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:34:40.899782 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:34:40.899847 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:34:40.899909 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:34:40.899983 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:34:40.957883 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:34:41.351877 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:34:41.365495 139803418769408 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:34:41.395636 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:34:41.395840 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:34:41.395932 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:34:41.396108 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:34:41.396196 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 12:34:41.396263 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:34:41.396421 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:34:41.396538 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:34:41.396695 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:34:41.396764 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 12:34:41.396876 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:34:41.397044 139803418769408 dqn_agent.py:283] 	 seed: 1630499681395583
I0901 12:34:41.399305 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:34:41.399446 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:34:41.399557 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:34:41.399621 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:34:41.399695 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:34:41.399752 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:34:41.399835 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:34:41.399891 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:34:41.399943 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:34:41.429605 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:34:41.451097 139803418769408 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:34:41.451309 139803418769408 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 161.34
I0901 12:34:47.649428 139803418769408 replay_runner.py:36] Average training steps per second: 161.34
Steps executed: 254 Episode length: 254 Return: -33.498691820442204
I0901 12:34:48.928023 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -33.50
INFO:tensorflow:Starting iteration 1

Steps executed: 208 Episode length: 118 Return: -188.77699076572094
INFO:tensorflow:Average training steps per second: 212.11
I0901 12:34:57.959577 139803418769408 replay_runner.py:36] Average training steps per second: 212.11
I0901 12:34:58.152404 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -437.23
INFO:tensorflow:Starting iteration 2

Steps executed: 314 Episode length: 161 Return: -554.58093967028254
INFO:tensorflow:Average training steps per second: 212.24
I0901 12:35:07.225317 139803418769408 replay_runner.py:36] Average training steps per second: 212.24
I0901 12:35:07.570820 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.13
INFO:tensorflow:Starting iteration 3

Steps executed: 168 Episode length: 85 Return: -58.6420353531739664
INFO:tensorflow:Average training steps per second: 205.64

Steps executed: 241 Episode length: 73 Return: -216.206936071799824
I0901 12:35:16.646006 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.40
INFO:tensorflow:Starting iteration 4

Steps executed: 203 Episode length: 89 Return: -298.241940247285894
INFO:tensorflow:Average training steps per second: 208.20
I0901 12:35:25.790269 139803418769408 replay_runner.py:36] Average training steps per second: 208.20
I0901 12:35:25.993984 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.88
INFO:tensorflow:Starting iteration 5

Steps executed: 433 Episode length: 433 Return: -367.68754398268237
INFO:tensorflow:Average training steps per second: 215.52
I0901 12:35:35.066170 139803418769408 replay_runner.py:36] Average training steps per second: 215.52
I0901 12:35:36.022502 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -367.69
INFO:tensorflow:Starting iteration 6

Steps executed: 400 Episode length: 232 Return: -30.904401418288842
INFO:tensorflow:Average training steps per second: 209.59
I0901 12:35:45.228844 139803418769408 replay_runner.py:36] Average training steps per second: 209.59
I0901 12:35:45.674019 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.85
INFO:tensorflow:Starting iteration 7

Steps executed: 220 Episode length: 112 Return: -136.41221929948966
INFO:tensorflow:Average training steps per second: 209.26
I0901 12:35:54.917930 139803418769408 replay_runner.py:36] Average training steps per second: 209.26
I0901 12:35:55.118377 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.67
INFO:tensorflow:Starting iteration 8

Steps executed: 121 Episode length: 121 Return: -55.622662706254346
INFO:tensorflow:Average training steps per second: 204.09

Steps executed: 406 Episode length: 285 Return: -175.04504533534606
I0901 12:36:04.914080 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.33
INFO:tensorflow:Starting iteration 9

Steps executed: 149 Episode length: 149 Return: -53.028826162346946
INFO:tensorflow:Average training steps per second: 209.95

Steps executed: 1149 Episode length: 1000 Return: -84.08019374676427
I0901 12:36:16.602996 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.55
INFO:tensorflow:Starting iteration 10

Steps executed: 249 Episode length: 112 Return: -167.348357921012437
INFO:tensorflow:Average training steps per second: 211.02
I0901 12:36:25.707398 139803418769408 replay_runner.py:36] Average training steps per second: 211.02
I0901 12:36:25.957430 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.34
INFO:tensorflow:Starting iteration 11
I0901 12:36:30.401786 139803418769408 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 217.55

Steps executed: 233 Episode length: 233 Return: -186.018587888971357
I0901 12:36:35.290214 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.02
INFO:tensorflow:Starting iteration 12
I0901 12:36:39.761800 139803418769408 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 214.03

Steps executed: 525 Episode length: 525 Return: -133.219302307643777
I0901 12:36:45.218586 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.22
INFO:tensorflow:Starting iteration 13
I0901 12:36:49.592771 139803418769408 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 212.89

Steps executed: 1000 Episode length: 1000 Return: -57.280780309026476
I0901 12:36:58.062971 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.28
INFO:tensorflow:Starting iteration 14
I0901 12:37:02.406609 139803418769408 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 218.03

Steps executed: 236 Episode length: 236 Return: -85.87806283204176476
I0901 12:37:07.256541 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.88
INFO:tensorflow:Starting iteration 15

Steps executed: 406 Episode length: 406 Return: -195.2723810248397276
INFO:tensorflow:Average training steps per second: 216.78
I0901 12:37:15.955519 139803418769408 replay_runner.py:36] Average training steps per second: 216.78
I0901 12:37:16.530971 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.27
INFO:tensorflow:Starting iteration 16

Steps executed: 620 Episode length: 519 Return: -536.1401668077029276
INFO:tensorflow:Average training steps per second: 212.52
I0901 12:37:25.603239 139803418769408 replay_runner.py:36] Average training steps per second: 212.52
I0901 12:37:26.454471 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -444.31
INFO:tensorflow:Starting iteration 17

Steps executed: 268 Episode length: 151 Return: -215.3622808182052576
INFO:tensorflow:Average training steps per second: 217.03
I0901 12:37:35.517301 139803418769408 replay_runner.py:36] Average training steps per second: 217.03
I0901 12:37:35.784277 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.13
INFO:tensorflow:Starting iteration 18
I0901 12:37:40.190576 139803418769408 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 220.80

Steps executed: 1000 Episode length: 1000 Return: -44.240723508603776
I0901 12:37:47.052846 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -44.24
INFO:tensorflow:Starting iteration 19
I0901 12:37:51.399023 139803418769408 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 228.10

Steps executed: 1000 Episode length: 1000 Return: -40.962919130837376
I0901 12:37:58.093652 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -40.96
INFO:tensorflow:Starting iteration 20
I0901 12:38:02.590786 139803418769408 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 217.78

Steps executed: 1000 Episode length: 1000 Return: -109.59869046935346
I0901 12:38:09.526278 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.60
INFO:tensorflow:Starting iteration 21
I0901 12:38:13.860570 139803418769408 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 212.48
I0901 12:38:18.567455 139803418769408 replay_runner.py:36] Average training steps per second: 212.48

Steps executed: 297 Episode length: 297 Return: -229.9439013777145346
INFO:tensorflow:Starting iteration 22
I0901 12:38:23.326293 139803418769408 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 214.11

Steps executed: 1000 Episode length: 1000 Return: -61.698410514348756
I0901 12:38:31.241561 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.70
INFO:tensorflow:Starting iteration 23

Steps executed: 638 Episode length: 638 Return: -168.0031654062157156
INFO:tensorflow:Average training steps per second: 214.44
I0901 12:38:39.888133 139803418769408 replay_runner.py:36] Average training steps per second: 214.44
I0901 12:38:40.959438 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.00
INFO:tensorflow:Starting iteration 24
I0901 12:38:45.096482 139803418769408 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 212.14

Steps executed: 1000 Episode length: 1000 Return: -53.503533558566876
I0901 12:38:53.769505 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -53.50
INFO:tensorflow:Starting iteration 25
I0901 12:38:58.088504 139803418769408 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 212.80

Steps executed: 448 Episode length: 448 Return: -269.5235939905539876
I0901 12:39:03.507963 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.52
INFO:tensorflow:Starting iteration 26
I0901 12:39:07.926268 139803418769408 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 215.10

Steps executed: 1000 Episode length: 1000 Return: -50.197891768589246
I0901 12:39:15.149541 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -50.20
INFO:tensorflow:Starting iteration 27
I0901 12:39:19.375720 139803418769408 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 217.98

Steps executed: 738 Episode length: 738 Return: -120.0769137536871746
I0901 12:39:25.869934 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.08
INFO:tensorflow:Starting iteration 28
I0901 12:39:29.917658 139803418769408 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 212.43

Steps executed: 1000 Episode length: 1000 Return: -95.354154424240446
I0901 12:39:37.901423 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.35
INFO:tensorflow:Starting iteration 29
I0901 12:39:42.395875 139803418769408 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 215.30

Steps executed: 1000 Episode length: 1000 Return: -81.019243172438856

Done fixed training! Episode length: 1000 Return: -81.019243172438856