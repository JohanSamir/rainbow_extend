Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0903 00:08:02.336893 139803223304192 run_experiment.py:549] Creating TrainRunner ...
I0903 00:08:02.347113 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:08:02.347231 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:08:02.347304 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:08:02.347362 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:08:02.347449 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0903 00:08:02.347516 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:08:02.347609 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:08:02.347712 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:08:02.347815 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:08:02.347970 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0903 00:08:02.348105 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:08:02.348212 139803223304192 dqn_agent.py:283] 	 seed: 1630627682347062
I0903 00:08:02.351197 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:08:02.351348 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:08:02.351481 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:08:02.351605 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:08:02.351750 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:08:02.351861 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:08:02.352017 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:08:02.352162 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:08:02.352275 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:08:02.387643 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:02.625469 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:02.633759 139803223304192 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:08:02.639510 139803223304192 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:08:02.639623 139803223304192 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:08:02.639688 139803223304192 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:08:02.639742 139803223304192 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:08:02.639792 139803223304192 dqn_agent.py:275] 	 update_period: 4
I0903 00:08:02.639857 139803223304192 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:08:02.639914 139803223304192 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:08:02.639992 139803223304192 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:08:02.640061 139803223304192 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:08:02.640139 139803223304192 dqn_agent.py:280] 	 optimizer: adam
I0903 00:08:02.640192 139803223304192 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:08:02.640253 139803223304192 dqn_agent.py:283] 	 seed: 1630627682639485
I0903 00:08:02.641566 139803223304192 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:08:02.641670 139803223304192 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:08:02.641733 139803223304192 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:08:02.641791 139803223304192 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:08:02.641842 139803223304192 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:08:02.641898 139803223304192 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:08:02.641973 139803223304192 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:08:02.642036 139803223304192 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:08:02.642112 139803223304192 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:08:02.659845 139803223304192 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:08:02.672735 139803223304192 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:08:02.672892 139803223304192 replay_runner.py:41] Starting iteration 0
Steps executed: 286 Episode length: 169 Return: -374.1714115676375
INFO:tensorflow:Average training steps per second: 240.15
I0903 00:08:06.837110 139803223304192 replay_runner.py:36] Average training steps per second: 240.15
I0903 00:08:07.590131 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -358.94
INFO:tensorflow:Starting iteration 1
I0903 00:08:10.880606 139803223304192 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 320.62
I0903 00:08:13.999917 139803223304192 replay_runner.py:36] Average training steps per second: 320.62

Steps executed: 244 Episode length: 126 Return: -775.50018767142265
INFO:tensorflow:Starting iteration 2

Steps executed: 231 Episode length: 231 Return: -226.52826225673837
INFO:tensorflow:Average training steps per second: 317.39
I0903 00:08:20.541276 139803223304192 replay_runner.py:36] Average training steps per second: 317.39
I0903 00:08:20.729901 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.53
INFO:tensorflow:Starting iteration 3

Steps executed: 351 Episode length: 351 Return: -100.29015342014678
INFO:tensorflow:Average training steps per second: 327.51
I0903 00:08:26.978249 139803223304192 replay_runner.py:36] Average training steps per second: 327.51
I0903 00:08:27.377356 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.29
INFO:tensorflow:Starting iteration 4
I0903 00:08:30.566851 139803223304192 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 316.90

Steps executed: 1000 Episode length: 1000 Return: -215.7618712426382
I0903 00:08:35.797772 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.76
INFO:tensorflow:Starting iteration 5
I0903 00:08:39.225703 139803223304192 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 335.11

Steps executed: 1000 Episode length: 1000 Return: -94.63265133930337
I0903 00:08:43.494730 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.63
INFO:tensorflow:Starting iteration 6
I0903 00:08:47.003703 139803223304192 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 342.73

Steps executed: 1000 Episode length: 1000 Return: -48.64943357915247
I0903 00:08:51.406471 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -48.65
INFO:tensorflow:Starting iteration 7
I0903 00:08:54.936663 139803223304192 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 363.93

Steps executed: 893 Episode length: 893 Return: -314.582402402938447
I0903 00:08:58.538779 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.58
INFO:tensorflow:Starting iteration 8
I0903 00:09:02.027727 139803223304192 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 352.66

Steps executed: 986 Episode length: 986 Return: -431.564707728925957
I0903 00:09:06.388564 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -431.56
INFO:tensorflow:Starting iteration 9

Steps executed: 586 Episode length: 586 Return: -180.734885557718657
INFO:tensorflow:Average training steps per second: 348.20
I0903 00:09:12.735567 139803223304192 replay_runner.py:36] Average training steps per second: 348.20
I0903 00:09:13.445067 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.73
INFO:tensorflow:Starting iteration 10

Steps executed: 278 Episode length: 170 Return: -179.129668141073477
INFO:tensorflow:Average training steps per second: 338.67
I0903 00:09:19.812365 139803223304192 replay_runner.py:36] Average training steps per second: 338.67
I0903 00:09:19.957865 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.60
INFO:tensorflow:Starting iteration 11

Steps executed: 1000 Episode length: 1000 Return: -314.66458220306816
INFO:tensorflow:Average training steps per second: 332.50
I0903 00:09:26.286630 139803223304192 replay_runner.py:36] Average training steps per second: 332.50
I0903 00:09:27.853889 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.66
INFO:tensorflow:Starting iteration 12
I0903 00:09:31.210254 139803223304192 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 340.43

Steps executed: 416 Episode length: 416 Return: -139.4289328655237816
I0903 00:09:34.584626 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.43
INFO:tensorflow:Starting iteration 13

Steps executed: 226 Episode length: 226 Return: -228.7470782415991816
INFO:tensorflow:Average training steps per second: 335.13
I0903 00:09:40.911774 139803223304192 replay_runner.py:36] Average training steps per second: 335.13
I0903 00:09:41.058926 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.75
INFO:tensorflow:Starting iteration 14
I0903 00:09:44.325493 139803223304192 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 318.58

Steps executed: 751 Episode length: 751 Return: -230.2096733552184616
I0903 00:09:49.075711 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.21
INFO:tensorflow:Starting iteration 15

Steps executed: 317 Episode length: 203 Return: -16.82531014573487516
INFO:tensorflow:Average training steps per second: 326.48
I0903 00:09:55.351698 139803223304192 replay_runner.py:36] Average training steps per second: 326.48
I0903 00:09:55.579638 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.61
INFO:tensorflow:Starting iteration 16

Steps executed: 214 Episode length: 214 Return: -370.5006413481347616
INFO:tensorflow:Average training steps per second: 329.11
I0903 00:10:01.919885 139803223304192 replay_runner.py:36] Average training steps per second: 329.11
I0903 00:10:02.084514 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -370.50
INFO:tensorflow:Starting iteration 17
I0903 00:10:05.390912 139803223304192 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 323.56

Steps executed: 390 Episode length: 390 Return: -275.3723696715063616
I0903 00:10:08.905225 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -275.37
INFO:tensorflow:Starting iteration 18

Steps executed: 287 Episode length: 134 Return: -92.28399733192065616
INFO:tensorflow:Average training steps per second: 339.09
I0903 00:10:15.173121 139803223304192 replay_runner.py:36] Average training steps per second: 339.09
I0903 00:10:15.369313 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -31.58
INFO:tensorflow:Starting iteration 19

Steps executed: 293 Episode length: 293 Return: 25.871282857208286616
INFO:tensorflow:Average training steps per second: 329.31
I0903 00:10:21.817959 139803223304192 replay_runner.py:36] Average training steps per second: 329.31
I0903 00:10:22.094458 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: 25.87
INFO:tensorflow:Starting iteration 20
I0903 00:10:25.485645 139803223304192 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 337.88

Steps executed: 462 Episode length: 307 Return: -101.8542953164426616
I0903 00:10:28.844430 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.46
INFO:tensorflow:Starting iteration 21

Steps executed: 94 Episode length: 94 Return: -190.986470333558526616
INFO:tensorflow:Average training steps per second: 331.95

Steps executed: 1094 Episode length: 1000 Return: 9.65524305777495616
I0903 00:10:37.356440 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.67
INFO:tensorflow:Starting iteration 22

Steps executed: 286 Episode length: 145 Return: -63.86257720046888416
INFO:tensorflow:Average training steps per second: 307.01
I0903 00:10:43.840484 139803223304192 replay_runner.py:36] Average training steps per second: 307.01
I0903 00:10:44.009093 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.54
INFO:tensorflow:Starting iteration 23
I0903 00:10:47.238457 139803223304192 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 303.75
I0903 00:10:50.531021 139803223304192 replay_runner.py:36] Average training steps per second: 303.75

Steps executed: 229 Episode length: 102 Return: -235.9983412513272216
INFO:tensorflow:Starting iteration 24

Steps executed: 220 Episode length: 57 Return: -153.30913022286872216
INFO:tensorflow:Average training steps per second: 307.68
I0903 00:10:57.125151 139803223304192 replay_runner.py:36] Average training steps per second: 307.68
I0903 00:10:57.262295 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.83
INFO:tensorflow:Starting iteration 25

Steps executed: 220 Episode length: 119 Return: -269.9468369339257416
INFO:tensorflow:Average training steps per second: 312.78
I0903 00:11:03.701723 139803223304192 replay_runner.py:36] Average training steps per second: 312.78
I0903 00:11:03.830518 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.80
INFO:tensorflow:Starting iteration 26

Steps executed: 214 Episode length: 53 Return: -95.997223597190912816
INFO:tensorflow:Average training steps per second: 298.74
I0903 00:11:10.454182 139803223304192 replay_runner.py:36] Average training steps per second: 298.74
I0903 00:11:10.576097 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.08
INFO:tensorflow:Starting iteration 27
I0903 00:11:13.867376 139803223304192 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 302.21

Steps executed: 1000 Episode length: 1000 Return: -31.255874520755967
I0903 00:11:19.587826 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -31.26
INFO:tensorflow:Starting iteration 28

Steps executed: 254 Episode length: 108 Return: -375.7026142511451967
INFO:tensorflow:Average training steps per second: 335.24
I0903 00:11:26.024131 139803223304192 replay_runner.py:36] Average training steps per second: 335.24
I0903 00:11:26.140302 139803223304192 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.52
INFO:tensorflow:Starting iteration 29

Steps executed: 217 Episode length: 83 Return: -758.69191201791181967
INFO:tensorflow:Average training steps per second: 339.68
I0903 00:11:32.514163 139803223304192 replay_runner.py:36] Average training steps per second: 339.68

Done fixed training!Episode length: 83 Return: -758.69191201791181967