Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0902 23:50:59.864150 139926926592000 run_experiment.py:549] Creating TrainRunner ...
I0902 23:50:59.874638 139926926592000 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:50:59.874835 139926926592000 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:50:59.874922 139926926592000 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:50:59.874984 139926926592000 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:50:59.875039 139926926592000 dqn_agent.py:275] 	 update_period: 4
I0902 23:50:59.875128 139926926592000 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:50:59.875282 139926926592000 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:50:59.875349 139926926592000 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:50:59.875431 139926926592000 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:50:59.875523 139926926592000 dqn_agent.py:280] 	 optimizer: adam
I0902 23:50:59.875582 139926926592000 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:50:59.875633 139926926592000 dqn_agent.py:283] 	 seed: 1630626659874585
I0902 23:50:59.879405 139926926592000 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:50:59.879653 139926926592000 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:50:59.879782 139926926592000 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:50:59.879894 139926926592000 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:50:59.879996 139926926592000 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:50:59.880162 139926926592000 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:50:59.880266 139926926592000 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:50:59.880398 139926926592000 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:50:59.880598 139926926592000 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:50:59.919202 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:51:00.300104 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:51:00.336663 139926926592000 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:51:00.381910 139926926592000 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:51:00.382173 139926926592000 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:51:00.382332 139926926592000 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:51:00.382456 139926926592000 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:51:00.382626 139926926592000 dqn_agent.py:275] 	 update_period: 4
I0902 23:51:00.382761 139926926592000 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:51:00.382856 139926926592000 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:51:00.382970 139926926592000 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:51:00.383114 139926926592000 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:51:00.383240 139926926592000 dqn_agent.py:280] 	 optimizer: adam
I0902 23:51:00.383345 139926926592000 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:51:00.383440 139926926592000 dqn_agent.py:283] 	 seed: 1630626660381831
I0902 23:51:00.385843 139926926592000 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:51:00.386047 139926926592000 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:51:00.386172 139926926592000 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:51:00.386334 139926926592000 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:51:00.386491 139926926592000 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:51:00.386642 139926926592000 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:51:00.386780 139926926592000 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:51:00.386937 139926926592000 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:51:00.387093 139926926592000 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:51:00.419169 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:51:00.439795 139926926592000 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:51:00.439998 139926926592000 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 160.40
I0902 23:51:06.674676 139926926592000 replay_runner.py:36] Average training steps per second: 160.40
Steps executed: 267 Episode length: 89 Return: -39.690433319711738
I0902 23:51:08.340421 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.10
INFO:tensorflow:Starting iteration 1

Steps executed: 229 Episode length: 136 Return: -354.87436789585445
INFO:tensorflow:Average training steps per second: 225.49
I0902 23:51:17.136500 139926926592000 replay_runner.py:36] Average training steps per second: 225.49
I0902 23:51:17.335534 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -379.75
INFO:tensorflow:Starting iteration 2

Steps executed: 329 Episode length: 202 Return: -425.97869785059065
INFO:tensorflow:Average training steps per second: 215.44
I0902 23:51:26.407411 139926926592000 replay_runner.py:36] Average training steps per second: 215.44
I0902 23:51:26.734925 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -474.10
INFO:tensorflow:Starting iteration 3
I0902 23:51:30.995934 139926926592000 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 219.54

Steps executed: 239 Episode length: 239 Return: -373.62797201648357
I0902 23:51:35.867704 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -373.63
INFO:tensorflow:Starting iteration 4

Steps executed: 680 Episode length: 506 Return: -266.44445959259847
INFO:tensorflow:Average training steps per second: 222.72
I0902 23:51:44.656388 139926926592000 replay_runner.py:36] Average training steps per second: 222.72
I0902 23:51:45.620254 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.41
INFO:tensorflow:Starting iteration 5
I0902 23:51:49.857287 139926926592000 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 218.76

Steps executed: 1000 Episode length: 1000 Return: -184.91229547436035
I0902 23:51:56.724405 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.91
INFO:tensorflow:Starting iteration 6
I0902 23:52:00.986883 139926926592000 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 219.60

Steps executed: 926 Episode length: 926 Return: -189.2114313625043035
I0902 23:52:08.282326 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.21
INFO:tensorflow:Starting iteration 7
I0902 23:52:12.694119 139926926592000 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 215.50

Steps executed: 897 Episode length: 897 Return: -207.1772290336452335
I0902 23:52:20.368144 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.18
INFO:tensorflow:Starting iteration 8

Steps executed: 454 Episode length: 454 Return: -761.4709836317934335
INFO:tensorflow:Average training steps per second: 212.00
I0902 23:52:29.186732 139926926592000 replay_runner.py:36] Average training steps per second: 212.00
I0902 23:52:30.006210 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -761.47
INFO:tensorflow:Starting iteration 9
I0902 23:52:34.153329 139926926592000 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 218.62
I0902 23:52:38.727881 139926926592000 replay_runner.py:36] Average training steps per second: 218.62

Steps executed: 510 Episode length: 510 Return: -236.3995638921467235
INFO:tensorflow:Starting iteration 10
I0902 23:52:44.050664 139926926592000 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 226.68

Steps executed: 1000 Episode length: 1000 Return: -324.57465526445736
I0902 23:52:52.560574 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -324.57
INFO:tensorflow:Starting iteration 11

Steps executed: 83 Episode length: 83 Return: -584.750194818685445736
INFO:tensorflow:Average training steps per second: 222.57

Steps executed: 916 Episode length: 833 Return: 215.86337299883587736
I0902 23:53:02.877648 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.44
INFO:tensorflow:Starting iteration 12
I0902 23:53:07.115372 139926926592000 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 222.83

Steps executed: 1000 Episode length: 1000 Return: -203.55065861880013
I0902 23:53:13.960525 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.55
INFO:tensorflow:Starting iteration 13
I0902 23:53:18.307316 139926926592000 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 216.21

Steps executed: 907 Episode length: 907 Return: -211.2242948033265313
I0902 23:53:25.441495 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.22
INFO:tensorflow:Starting iteration 14

Steps executed: 290 Episode length: 290 Return: -124.0480137729448713
INFO:tensorflow:Average training steps per second: 214.31
I0902 23:53:34.409160 139926926592000 replay_runner.py:36] Average training steps per second: 214.31
I0902 23:53:34.733842 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.05
INFO:tensorflow:Starting iteration 15
I0902 23:53:39.066973 139926926592000 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 213.15

Steps executed: 249 Episode length: 85 Return: -381.53610615977236613
I0902 23:53:44.043421 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.69
INFO:tensorflow:Starting iteration 16

Steps executed: 424 Episode length: 424 Return: -521.1262418627982613
INFO:tensorflow:Average training steps per second: 219.32
I0902 23:53:52.880417 139926926592000 replay_runner.py:36] Average training steps per second: 219.32
I0902 23:53:53.614537 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -521.13
INFO:tensorflow:Starting iteration 17

Steps executed: 206 Episode length: 54 Return: -252.11762208841562613
INFO:tensorflow:Average training steps per second: 214.58
I0902 23:54:02.504738 139926926592000 replay_runner.py:36] Average training steps per second: 214.58
I0902 23:54:02.702139 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -322.76
INFO:tensorflow:Starting iteration 18

Steps executed: 306 Episode length: 209 Return: -825.4755686104918613
INFO:tensorflow:Average training steps per second: 217.16
I0902 23:54:11.693659 139926926592000 replay_runner.py:36] Average training steps per second: 217.16
I0902 23:54:11.987416 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -654.85
INFO:tensorflow:Starting iteration 19

Steps executed: 493 Episode length: 355 Return: -361.7423083960637613
INFO:tensorflow:Average training steps per second: 218.91
I0902 23:54:20.837599 139926926592000 replay_runner.py:36] Average training steps per second: 218.91
I0902 23:54:21.475034 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.99
INFO:tensorflow:Starting iteration 20

Steps executed: 289 Episode length: 149 Return: -69.74834173869954413
INFO:tensorflow:Average training steps per second: 216.17
I0902 23:54:30.310458 139926926592000 replay_runner.py:36] Average training steps per second: 216.17
I0902 23:54:30.602386 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.84
INFO:tensorflow:Starting iteration 21

Steps executed: 176 Episode length: 176 Return: 44.741847629983684413
INFO:tensorflow:Average training steps per second: 210.42

Steps executed: 451 Episode length: 275 Return: -297.9448973347232413
I0902 23:54:40.296190 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.60
INFO:tensorflow:Starting iteration 22

Steps executed: 230 Episode length: 156 Return: -127.9802754559215713
INFO:tensorflow:Average training steps per second: 217.65
I0902 23:54:49.220966 139926926592000 replay_runner.py:36] Average training steps per second: 217.65
I0902 23:54:49.437099 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.35
INFO:tensorflow:Starting iteration 23
I0902 23:54:53.651901 139926926592000 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 215.35

Steps executed: 257 Episode length: 257 Return: 9.6550313547150515713
I0902 23:54:58.587734 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.66
INFO:tensorflow:Starting iteration 24

Steps executed: 294 Episode length: 140 Return: -778.6367043993005713
INFO:tensorflow:Average training steps per second: 211.48
I0902 23:55:07.576355 139926926592000 replay_runner.py:36] Average training steps per second: 211.48
I0902 23:55:07.865591 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -690.06
INFO:tensorflow:Starting iteration 25

Steps executed: 232 Episode length: 137 Return: -240.3284215380905413
INFO:tensorflow:Average training steps per second: 219.03
I0902 23:55:16.680184 139926926592000 replay_runner.py:36] Average training steps per second: 219.03
I0902 23:55:16.894514 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.82
INFO:tensorflow:Starting iteration 26

Steps executed: 253 Episode length: 167 Return: -510.4700796941203413
INFO:tensorflow:Average training steps per second: 211.67
I0902 23:55:25.809230 139926926592000 replay_runner.py:36] Average training steps per second: 211.67
I0902 23:55:26.070015 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -322.58
INFO:tensorflow:Starting iteration 27

Steps executed: 277 Episode length: 166 Return: -301.7948838167066613
INFO:tensorflow:Average training steps per second: 215.17
I0902 23:55:35.001806 139926926592000 replay_runner.py:36] Average training steps per second: 215.17
I0902 23:55:35.285968 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -483.91
INFO:tensorflow:Starting iteration 28

Steps executed: 214 Episode length: 74 Return: -216.33562071882136613
INFO:tensorflow:Average training steps per second: 217.54
I0902 23:55:44.221952 139926926592000 replay_runner.py:36] Average training steps per second: 217.54
I0902 23:55:44.411138 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.34
INFO:tensorflow:Starting iteration 29

Steps executed: 201 Episode length: 50 Return: -424.86351164696386613
INFO:tensorflow:Average training steps per second: 231.41
I0902 23:55:53.033823 139926926592000 replay_runner.py:36] Average training steps per second: 231.41

Done fixed training!Episode length: 50 Return: -424.86351164696386613