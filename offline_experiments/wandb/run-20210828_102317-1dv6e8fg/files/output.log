Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0828 10:23:23.687447 140251198892032 run_experiment.py:549] Creating TrainRunner ...
I0828 10:23:23.699482 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:23:23.699729 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:23:23.699821 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:23:23.699922 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:23:23.700022 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:23:23.700098 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:23:23.700184 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:23:23.700264 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:23:23.700380 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:23:23.700531 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:23:23.700654 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:23:23.700767 140251198892032 dqn_agent.py:283] 	 seed: 1630146203699423
I0828 10:23:23.704020 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:23:23.704239 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:23:23.704401 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:23:23.704489 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:23:23.704667 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:23:23.704861 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:23:23.704968 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:23:23.705109 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:23:23.705183 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:23:23.743990 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:24.420258 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:24.434107 140251198892032 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:23:24.443410 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:23:24.443695 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:23:24.443841 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:23:24.444001 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:23:24.444125 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:23:24.444246 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:23:24.444371 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:23:24.444591 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:23:24.444707 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:23:24.444830 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:23:24.444987 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:23:24.445085 140251198892032 dqn_agent.py:283] 	 seed: 1630146204443352
I0828 10:23:24.447728 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:23:24.447934 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:23:24.448038 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:23:24.448141 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:23:24.448231 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:23:24.448318 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:23:24.448412 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:23:24.448523 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:23:24.448617 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:23:24.479529 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:24.501089 140251198892032 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:23:24.501665 140251198892032 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 161.60
I0828 10:23:30.689995 140251198892032 replay_runner.py:36] Average training steps per second: 161.60
Steps executed: 296 Episode length: 148 Return: -320.79014082936226
I0828 10:23:31.935970 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.14
INFO:tensorflow:Starting iteration 1
I0828 10:23:36.244535 140251198892032 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 220.71

Steps executed: 498 Episode length: 498 Return: -320.82272133050054
I0828 10:23:41.753757 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -320.82
INFO:tensorflow:Starting iteration 2

Steps executed: 239 Episode length: 86 Return: -466.015398095556164
INFO:tensorflow:Average training steps per second: 220.09
I0828 10:23:50.669088 140251198892032 replay_runner.py:36] Average training steps per second: 220.09
I0828 10:23:50.829802 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -441.08
INFO:tensorflow:Starting iteration 3

Steps executed: 259 Episode length: 75 Return: -579.147778117121554
INFO:tensorflow:Average training steps per second: 227.68
I0828 10:23:59.614363 140251198892032 replay_runner.py:36] Average training steps per second: 227.68
I0828 10:23:59.808878 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -503.66
INFO:tensorflow:Starting iteration 4

Steps executed: 228 Episode length: 84 Return: -700.700381693659734
INFO:tensorflow:Average training steps per second: 224.10
I0828 10:24:08.673093 140251198892032 replay_runner.py:36] Average training steps per second: 224.10
I0828 10:24:08.869448 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -687.60
INFO:tensorflow:Starting iteration 5
I0828 10:24:13.202985 140251198892032 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 229.67

Steps executed: 226 Episode length: 88 Return: -597.950854490615134
I0828 10:24:17.718266 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -470.62
INFO:tensorflow:Starting iteration 6

Steps executed: 203 Episode length: 119 Return: -888.47272692486184
INFO:tensorflow:Average training steps per second: 244.99
I0828 10:24:26.118783 140251198892032 replay_runner.py:36] Average training steps per second: 244.99
I0828 10:24:26.303286 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -647.77
INFO:tensorflow:Starting iteration 7

Steps executed: 220 Episode length: 72 Return: -430.994182050679854
INFO:tensorflow:Average training steps per second: 230.87
I0828 10:24:34.803127 140251198892032 replay_runner.py:36] Average training steps per second: 230.87
I0828 10:24:34.988264 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -431.90
INFO:tensorflow:Starting iteration 8

Steps executed: 206 Episode length: 56 Return: -143.330497772819174
INFO:tensorflow:Average training steps per second: 255.23
I0828 10:24:43.055707 140251198892032 replay_runner.py:36] Average training steps per second: 255.23
I0828 10:24:43.170876 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.96
INFO:tensorflow:Starting iteration 9

Steps executed: 262 Episode length: 67 Return: -208.723276367977434
INFO:tensorflow:Average training steps per second: 239.61
I0828 10:24:51.535853 140251198892032 replay_runner.py:36] Average training steps per second: 239.61
I0828 10:24:51.721720 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.37
INFO:tensorflow:Starting iteration 10

Steps executed: 226 Episode length: 82 Return: -680.177778509125134
INFO:tensorflow:Average training steps per second: 224.37
I0828 10:25:00.436692 140251198892032 replay_runner.py:36] Average training steps per second: 224.37
I0828 10:25:00.632797 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -631.76
INFO:tensorflow:Starting iteration 11

Steps executed: 263 Episode length: 70 Return: -321.299398887578434
INFO:tensorflow:Average training steps per second: 225.94
I0828 10:25:09.470314 140251198892032 replay_runner.py:36] Average training steps per second: 225.94
I0828 10:25:09.710850 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.70
INFO:tensorflow:Starting iteration 12

Steps executed: 203 Episode length: 67 Return: -471.916255822720164
INFO:tensorflow:Average training steps per second: 218.70
I0828 10:25:18.641711 140251198892032 replay_runner.py:36] Average training steps per second: 218.70
I0828 10:25:18.835767 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -448.46
INFO:tensorflow:Starting iteration 13

Steps executed: 224 Episode length: 70 Return: -143.894452611207164
INFO:tensorflow:Average training steps per second: 223.29
I0828 10:25:27.678591 140251198892032 replay_runner.py:36] Average training steps per second: 223.29
I0828 10:25:27.826256 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.59
INFO:tensorflow:Starting iteration 14

Steps executed: 259 Episode length: 122 Return: -207.66989278548397
INFO:tensorflow:Average training steps per second: 218.66
I0828 10:25:36.823124 140251198892032 replay_runner.py:36] Average training steps per second: 218.66
I0828 10:25:37.011408 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.19
INFO:tensorflow:Starting iteration 15
I0828 10:25:41.429234 140251198892032 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 218.71

Steps executed: 202 Episode length: 69 Return: -459.862766378147997
I0828 10:25:46.181800 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -448.48
INFO:tensorflow:Starting iteration 16

Steps executed: 218 Episode length: 55 Return: -497.547361043885697
INFO:tensorflow:Average training steps per second: 221.22
I0828 10:25:55.029804 140251198892032 replay_runner.py:36] Average training steps per second: 221.22
I0828 10:25:55.216190 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -585.65
INFO:tensorflow:Starting iteration 17

Steps executed: 227 Episode length: 76 Return: -496.747737251984067
INFO:tensorflow:Average training steps per second: 224.79
I0828 10:26:03.904739 140251198892032 replay_runner.py:36] Average training steps per second: 224.79
I0828 10:26:04.109369 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -532.40
INFO:tensorflow:Starting iteration 18

Steps executed: 250 Episode length: 69 Return: -553.299567868520667
INFO:tensorflow:Average training steps per second: 224.82
I0828 10:26:12.921335 140251198892032 replay_runner.py:36] Average training steps per second: 224.82
I0828 10:26:13.140251 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -494.96
INFO:tensorflow:Starting iteration 19

Steps executed: 219 Episode length: 81 Return: -501.287173349795567
INFO:tensorflow:Average training steps per second: 224.13
I0828 10:26:21.975385 140251198892032 replay_runner.py:36] Average training steps per second: 224.13
I0828 10:26:22.171632 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -439.27
INFO:tensorflow:Starting iteration 20

Steps executed: 267 Episode length: 72 Return: -496.579721873752367
INFO:tensorflow:Average training steps per second: 223.17
I0828 10:26:30.904441 140251198892032 replay_runner.py:36] Average training steps per second: 223.17
I0828 10:26:31.145078 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -443.66
INFO:tensorflow:Starting iteration 21

Steps executed: 240 Episode length: 51 Return: -325.944428171597457
INFO:tensorflow:Average training steps per second: 224.64
I0828 10:26:40.005762 140251198892032 replay_runner.py:36] Average training steps per second: 224.64
I0828 10:26:40.216305 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -374.50
INFO:tensorflow:Starting iteration 22

Steps executed: 262 Episode length: 262 Return: -2050.6388662437225
INFO:tensorflow:Average training steps per second: 224.07
I0828 10:26:48.921691 140251198892032 replay_runner.py:36] Average training steps per second: 224.07
I0828 10:26:49.294070 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -2050.64
INFO:tensorflow:Starting iteration 23

Steps executed: 209 Episode length: 77 Return: -602.989586492728625
INFO:tensorflow:Average training steps per second: 222.91
I0828 10:26:58.191214 140251198892032 replay_runner.py:36] Average training steps per second: 222.91
I0828 10:26:58.409652 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -778.25
INFO:tensorflow:Starting iteration 24

Steps executed: 283 Episode length: 209 Return: -1785.2157507381678
INFO:tensorflow:Average training steps per second: 223.81
I0828 10:27:07.264013 140251198892032 replay_runner.py:36] Average training steps per second: 223.81
I0828 10:27:07.576202 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -1186.76
INFO:tensorflow:Starting iteration 25

Steps executed: 222 Episode length: 102 Return: -624.22530947012828
INFO:tensorflow:Average training steps per second: 227.58
I0828 10:27:16.310836 140251198892032 replay_runner.py:36] Average training steps per second: 227.58
I0828 10:27:16.531515 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -574.65
INFO:tensorflow:Starting iteration 26

Steps executed: 236 Episode length: 72 Return: -93.9914520854523628
INFO:tensorflow:Average training steps per second: 232.55
I0828 10:27:25.063721 140251198892032 replay_runner.py:36] Average training steps per second: 232.55
I0828 10:27:25.228860 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -62.65
INFO:tensorflow:Starting iteration 27
I0828 10:27:29.422420 140251198892032 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 230.08
I0828 10:27:33.769216 140251198892032 replay_runner.py:36] Average training steps per second: 230.08

Steps executed: 261 Episode length: 72 Return: -611.900165434013828
INFO:tensorflow:Starting iteration 28

Steps executed: 225 Episode length: 94 Return: -17.6213662088889388
INFO:tensorflow:Average training steps per second: 237.23
I0828 10:27:42.484643 140251198892032 replay_runner.py:36] Average training steps per second: 237.23
I0828 10:27:42.630396 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.23
INFO:tensorflow:Starting iteration 29

Steps executed: 243 Episode length: 134 Return: -777.59408966455658
INFO:tensorflow:Average training steps per second: 253.67
I0828 10:27:50.853853 140251198892032 replay_runner.py:36] Average training steps per second: 253.67

Done fixed training!Episode length: 134 Return: -777.59408966455658