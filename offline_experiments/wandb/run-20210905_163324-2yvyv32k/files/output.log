I0905 16:33:32.413917 140035672414208 run_experiment.py:549] Creating TrainRunner ...
I0905 16:33:32.445077 140035672414208 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:33:32.445556 140035672414208 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:33:32.445809 140035672414208 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:33:32.447010 140035672414208 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:33:32.447250 140035672414208 dqn_agent.py:275] 	 update_period: 4
I0905 16:33:32.447492 140035672414208 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:33:32.448293 140035672414208 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:33:32.449456 140035672414208 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:33:32.450394 140035672414208 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:33:32.450637 140035672414208 dqn_agent.py:280] 	 optimizer: adam
I0905 16:33:32.450978 140035672414208 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:33:32.451140 140035672414208 dqn_agent.py:283] 	 seed: 1630859612444985
I0905 16:33:32.455489 140035672414208 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:33:32.455798 140035672414208 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:33:32.456425 140035672414208 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:33:32.456809 140035672414208 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:33:32.457554 140035672414208 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:33:32.457702 140035672414208 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:33:32.458222 140035672414208 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:33:32.458918 140035672414208 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:33:32.459159 140035672414208 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:33:35.480063 140035672414208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0905 16:33:36.111600 140035672414208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:36.125561 140035672414208 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:33:36.156553 140035672414208 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:33:36.157478 140035672414208 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:33:36.157910 140035672414208 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:33:36.158292 140035672414208 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:33:36.159232 140035672414208 dqn_agent.py:275] 	 update_period: 4
I0905 16:33:36.159459 140035672414208 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:33:36.159694 140035672414208 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:33:36.159861 140035672414208 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:33:36.160455 140035672414208 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:33:36.160773 140035672414208 dqn_agent.py:280] 	 optimizer: adam
I0905 16:33:36.161408 140035672414208 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:33:36.161778 140035672414208 dqn_agent.py:283] 	 seed: 1630859616156459
I0905 16:33:36.167426 140035672414208 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:33:36.167770 140035672414208 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:33:36.168206 140035672414208 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:33:36.168485 140035672414208 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:33:36.169405 140035672414208 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:33:36.169637 140035672414208 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:33:36.169857 140035672414208 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:33:36.170156 140035672414208 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:33:36.170472 140035672414208 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:33:36.238604 140035672414208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:33:36.273668 140035672414208 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:33:36.274230 140035672414208 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 107.11
I0905 16:33:45.610764 140035672414208 replay_runner.py:36] Average training steps per second: 107.11
Steps executed: 267 Episode length: 118 Return: -259.3899514761589
I0905 16:33:47.424098 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.52
INFO:tensorflow:Starting iteration 1

Steps executed: 268 Episode length: 138 Return: -346.0853927650169
INFO:tensorflow:Average training steps per second: 177.79
I0905 16:33:58.111217 140035672414208 replay_runner.py:36] Average training steps per second: 177.79
I0905 16:33:58.369641 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -339.59
INFO:tensorflow:Starting iteration 2

Steps executed: 110 Episode length: 110 Return: -429.1436621019122
INFO:tensorflow:Average training steps per second: 158.82

Steps executed: 232 Episode length: 122 Return: -303.0191296298151
I0905 16:34:10.173524 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -366.08
INFO:tensorflow:Starting iteration 3

Steps executed: 274 Episode length: 274 Return: -299.1734532735628
INFO:tensorflow:Average training steps per second: 157.59
I0905 16:34:20.801716 140035672414208 replay_runner.py:36] Average training steps per second: 157.59
I0905 16:34:21.286068 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -299.17
INFO:tensorflow:Starting iteration 4

Steps executed: 169 Episode length: 169 Return: -256.1906274177138
INFO:tensorflow:Average training steps per second: 164.80

Steps executed: 1169 Episode length: 1000 Return: -58.716543861227436
I0905 16:34:37.739953 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -157.45
INFO:tensorflow:Starting iteration 5
I0905 16:34:42.609003 140035672414208 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 161.30

Steps executed: 1000 Episode length: 1000 Return: -133.49378423664683
I0905 16:34:52.020207 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.49
INFO:tensorflow:Starting iteration 6
I0905 16:34:57.188947 140035672414208 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 151.67

Steps executed: 1000 Episode length: 1000 Return: -112.60903781098773
I0905 16:35:07.225187 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.61
INFO:tensorflow:Starting iteration 7
I0905 16:35:12.333609 140035672414208 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 164.39

Steps executed: 1000 Episode length: 1000 Return: -110.70302605129692
I0905 16:35:23.304431 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.70
INFO:tensorflow:Starting iteration 8
I0905 16:35:27.736254 140035672414208 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 225.18

Steps executed: 1000 Episode length: 1000 Return: -106.77503889037133
I0905 16:35:35.415956 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.78
INFO:tensorflow:Starting iteration 9
I0905 16:35:39.278885 140035672414208 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 164.40

Steps executed: 684 Episode length: 684 Return: -417.8409715464865733
I0905 16:35:47.521306 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -417.84
INFO:tensorflow:Starting iteration 10
I0905 16:35:52.299721 140035672414208 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 187.49

Steps executed: 682 Episode length: 682 Return: -433.3058438179253733
I0905 16:35:59.058491 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -433.31
INFO:tensorflow:Starting iteration 11

Steps executed: 601 Episode length: 601 Return: -329.7200044443413733
INFO:tensorflow:Average training steps per second: 189.72
I0905 16:36:09.126744 140035672414208 replay_runner.py:36] Average training steps per second: 189.72
I0905 16:36:10.218789 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.72
INFO:tensorflow:Starting iteration 12

Steps executed: 483 Episode length: 418 Return: -362.2650194587594733
INFO:tensorflow:Average training steps per second: 215.03
I0905 16:36:19.500974 140035672414208 replay_runner.py:36] Average training steps per second: 215.03
I0905 16:36:20.137289 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.53
INFO:tensorflow:Starting iteration 13
I0905 16:36:24.572036 140035672414208 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 265.30

Steps executed: 622 Episode length: 622 Return: -582.6517077478444733
I0905 16:36:29.203047 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -582.65
INFO:tensorflow:Starting iteration 14
I0905 16:36:33.016004 140035672414208 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 308.31

Steps executed: 1000 Episode length: 1000 Return: -70.141683247499933
I0905 16:36:38.214033 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.14
INFO:tensorflow:Starting iteration 15
I0905 16:36:41.450117 140035672414208 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 410.92

Steps executed: 849 Episode length: 849 Return: -268.8248186250736933
I0905 16:36:45.054067 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -268.82
INFO:tensorflow:Starting iteration 16
I0905 16:36:48.226533 140035672414208 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 421.09

Steps executed: 546 Episode length: 546 Return: -373.5619850995835933
I0905 16:36:51.279604 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -373.56
INFO:tensorflow:Starting iteration 17

Steps executed: 223 Episode length: 223 Return: -338.4891988004062633
INFO:tensorflow:Average training steps per second: 409.11
I0905 16:36:56.974589 140035672414208 replay_runner.py:36] Average training steps per second: 409.11
I0905 16:36:57.094437 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.49
INFO:tensorflow:Starting iteration 18

Steps executed: 1000 Episode length: 1000 Return: -90.316709569830353
INFO:tensorflow:Average training steps per second: 382.57
I0905 16:37:02.903209 140035672414208 replay_runner.py:36] Average training steps per second: 382.57
I0905 16:37:04.538720 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.32
INFO:tensorflow:Starting iteration 19

Steps executed: 240 Episode length: 118 Return: -117.0002232567498353
INFO:tensorflow:Average training steps per second: 385.66
I0905 16:37:10.237725 140035672414208 replay_runner.py:36] Average training steps per second: 385.66
I0905 16:37:10.346469 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.09
INFO:tensorflow:Starting iteration 20

Steps executed: 246 Episode length: 134 Return: -161.9542999357326553
INFO:tensorflow:Average training steps per second: 421.38
I0905 16:37:15.840260 140035672414208 replay_runner.py:36] Average training steps per second: 421.38
I0905 16:37:15.962407 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.15
INFO:tensorflow:Starting iteration 21
I0905 16:37:19.171611 140035672414208 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 403.53

Steps executed: 1000 Episode length: 1000 Return: -143.62397827555824
I0905 16:37:22.966238 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.62
INFO:tensorflow:Starting iteration 22

Steps executed: 408 Episode length: 262 Return: -237.1596608665569524
INFO:tensorflow:Average training steps per second: 395.45
I0905 16:37:28.642534 140035672414208 replay_runner.py:36] Average training steps per second: 395.45
I0905 16:37:28.900395 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.59
INFO:tensorflow:Starting iteration 23
I0905 16:37:32.082779 140035672414208 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 413.06

Steps executed: 246 Episode length: 115 Return: -202.6496715085833724
I0905 16:37:34.602957 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.87
INFO:tensorflow:Starting iteration 24

Steps executed: 163 Episode length: 105 Return: -223.2930779309076624
INFO:tensorflow:Average training steps per second: 406.33
I0905 16:37:40.256019 140035672414208 replay_runner.py:36] Average training steps per second: 406.33

Steps executed: 305 Episode length: 142 Return: -317.8213391540134624
INFO:tensorflow:Starting iteration 25

Steps executed: 200 Episode length: 139 Return: -103.2405139439978624
INFO:tensorflow:Average training steps per second: 401.89
I0905 16:37:46.012692 140035672414208 replay_runner.py:36] Average training steps per second: 401.89
I0905 16:37:46.100602 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.16
INFO:tensorflow:Starting iteration 26

Steps executed: 555 Episode length: 490 Return: -468.0684530102478624
INFO:tensorflow:Average training steps per second: 389.31
I0905 16:37:51.805792 140035672414208 replay_runner.py:36] Average training steps per second: 389.31
I0905 16:37:52.255903 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -314.86
INFO:tensorflow:Starting iteration 27

Steps executed: 327 Episode length: 162 Return: -159.9560345422151524
INFO:tensorflow:Average training steps per second: 387.34
I0905 16:37:58.001061 140035672414208 replay_runner.py:36] Average training steps per second: 387.34
I0905 16:37:58.162380 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.13
INFO:tensorflow:Starting iteration 28

Steps executed: 252 Episode length: 61 Return: -213.58690767582578424
INFO:tensorflow:Average training steps per second: 391.61
I0905 16:38:03.821244 140035672414208 replay_runner.py:36] Average training steps per second: 391.61
I0905 16:38:03.966656 140035672414208 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.19
INFO:tensorflow:Starting iteration 29

Steps executed: 325 Episode length: 141 Return: -288.9105323788136424
INFO:tensorflow:Average training steps per second: 371.28
I0905 16:38:09.743029 140035672414208 replay_runner.py:36] Average training steps per second: 371.28

Done fixed training!Episode length: 141 Return: -288.9105323788136424