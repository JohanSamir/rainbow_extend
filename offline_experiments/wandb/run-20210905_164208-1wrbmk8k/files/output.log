I0905 16:42:15.087878 140235000764416 run_experiment.py:549] Creating TrainRunner ...
I0905 16:42:15.099081 140235000764416 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:42:15.099248 140235000764416 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:42:15.099323 140235000764416 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:42:15.099385 140235000764416 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:42:15.099441 140235000764416 dqn_agent.py:275] 	 update_period: 4
I0905 16:42:15.099611 140235000764416 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:42:15.099675 140235000764416 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:42:15.099763 140235000764416 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:42:15.099841 140235000764416 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:42:15.099908 140235000764416 dqn_agent.py:280] 	 optimizer: adam
I0905 16:42:15.099977 140235000764416 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:42:15.100044 140235000764416 dqn_agent.py:283] 	 seed: 1630860135099030
I0905 16:42:15.101994 140235000764416 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:42:15.102206 140235000764416 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:42:15.102394 140235000764416 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:42:15.102519 140235000764416 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:42:15.102613 140235000764416 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:42:15.102764 140235000764416 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:42:15.102855 140235000764416 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:42:15.102924 140235000764416 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:42:15.103040 140235000764416 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:42:16.453157 140235000764416 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0905 16:42:17.283045 140235000764416 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:42:17.297526 140235000764416 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:42:17.306208 140235000764416 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:42:17.306516 140235000764416 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:42:17.306714 140235000764416 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:42:17.307131 140235000764416 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:42:17.307291 140235000764416 dqn_agent.py:275] 	 update_period: 4
I0905 16:42:17.307533 140235000764416 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:42:17.307653 140235000764416 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:42:17.307744 140235000764416 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:42:17.307861 140235000764416 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:42:17.308021 140235000764416 dqn_agent.py:280] 	 optimizer: adam
I0905 16:42:17.308125 140235000764416 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:42:17.308552 140235000764416 dqn_agent.py:283] 	 seed: 1630860137306149
I0905 16:42:17.312157 140235000764416 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:42:17.312359 140235000764416 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:42:17.312440 140235000764416 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:42:17.312505 140235000764416 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:42:17.312570 140235000764416 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:42:17.312777 140235000764416 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:42:17.312849 140235000764416 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:42:17.312903 140235000764416 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:42:17.312955 140235000764416 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:42:17.373321 140235000764416 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:42:17.405985 140235000764416 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:42:17.406265 140235000764416 replay_runner.py:41] Starting iteration 0
Steps executed: 204 Episode length: 112 Return: -255.22291029534765
INFO:tensorflow:Average training steps per second: 174.41
I0905 16:42:23.141085 140235000764416 replay_runner.py:36] Average training steps per second: 174.41
I0905 16:42:24.209296 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -318.40
INFO:tensorflow:Starting iteration 1

Steps executed: 162 Episode length: 162 Return: -641.29174600151965
INFO:tensorflow:Average training steps per second: 245.98

Steps executed: 326 Episode length: 164 Return: -587.69659973789755
I0905 16:42:32.746310 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -614.49
INFO:tensorflow:Starting iteration 2
I0905 16:42:36.601841 140235000764416 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 242.32

Steps executed: 202 Episode length: 202 Return: -332.52914589478385
I0905 16:42:40.946818 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.53
INFO:tensorflow:Starting iteration 3
I0905 16:42:44.941822 140235000764416 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 228.07

Steps executed: 1000 Episode length: 1000 Return: -79.44974796633433
I0905 16:42:51.328461 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.45
INFO:tensorflow:Starting iteration 4
I0905 16:42:55.126715 140235000764416 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 232.48

Steps executed: 1000 Episode length: 1000 Return: -134.65881636419294
I0905 16:43:02.554587 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.66
INFO:tensorflow:Starting iteration 5
I0905 16:43:06.530241 140235000764416 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 250.31

Steps executed: 1000 Episode length: 1000 Return: -131.97567038322894
I0905 16:43:12.946954 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.98
INFO:tensorflow:Starting iteration 6
I0905 16:43:17.122968 140235000764416 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 243.05
I0905 16:43:21.237647 140235000764416 replay_runner.py:36] Average training steps per second: 243.05

Steps executed: 1000 Episode length: 1000 Return: -159.79385247008773
INFO:tensorflow:Starting iteration 7
I0905 16:43:27.101018 140235000764416 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 246.01

Steps executed: 1000 Episode length: 1000 Return: -108.29046278046573
I0905 16:43:32.999235 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.29
INFO:tensorflow:Starting iteration 8

Steps executed: 412 Episode length: 412 Return: -373.7231565259624573
INFO:tensorflow:Average training steps per second: 236.69
I0905 16:43:41.359053 140235000764416 replay_runner.py:36] Average training steps per second: 236.69
I0905 16:43:41.927116 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -373.72
INFO:tensorflow:Starting iteration 9

Steps executed: 318 Episode length: 237 Return: 2.5369853946332057573
INFO:tensorflow:Average training steps per second: 230.56
I0905 16:43:50.214389 140235000764416 replay_runner.py:36] Average training steps per second: 230.56
I0905 16:43:50.545365 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -19.83
INFO:tensorflow:Starting iteration 10

Steps executed: 331 Episode length: 182 Return: -31.73558270711584573
INFO:tensorflow:Average training steps per second: 236.17
I0905 16:43:58.655473 140235000764416 replay_runner.py:36] Average training steps per second: 236.17
I0905 16:43:58.970767 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -42.61
INFO:tensorflow:Starting iteration 11
I0905 16:44:02.902714 140235000764416 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 236.53

Steps executed: 1000 Episode length: 1000 Return: -244.46808333492268
I0905 16:44:10.756590 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.47
INFO:tensorflow:Starting iteration 12
I0905 16:44:14.583074 140235000764416 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 223.14
I0905 16:44:19.064896 140235000764416 replay_runner.py:36] Average training steps per second: 223.14

Steps executed: 1000 Episode length: 1000 Return: -136.30591175257203
INFO:tensorflow:Starting iteration 13
I0905 16:44:24.947081 140235000764416 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 223.13

Steps executed: 1000 Episode length: 1000 Return: -122.04038620257906
I0905 16:44:31.803778 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.04
INFO:tensorflow:Starting iteration 14

Steps executed: 246 Episode length: 187 Return: 41.970307806054997906
INFO:tensorflow:Average training steps per second: 230.95
I0905 16:44:39.930813 140235000764416 replay_runner.py:36] Average training steps per second: 230.95
I0905 16:44:40.172779 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -56.08
INFO:tensorflow:Starting iteration 15

Steps executed: 428 Episode length: 428 Return: -28.46746148404747606
INFO:tensorflow:Average training steps per second: 225.57
I0905 16:44:48.215921 140235000764416 replay_runner.py:36] Average training steps per second: 225.57
I0905 16:44:48.912026 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -28.47
INFO:tensorflow:Starting iteration 16
I0905 16:44:52.808357 140235000764416 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 236.14

Steps executed: 1000 Episode length: 1000 Return: -117.15581264347757
I0905 16:45:01.427356 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.16
INFO:tensorflow:Starting iteration 17

Steps executed: 318 Episode length: 318 Return: 10.031250143099072757
INFO:tensorflow:Average training steps per second: 235.78
I0905 16:45:09.720048 140235000764416 replay_runner.py:36] Average training steps per second: 235.78
I0905 16:45:10.186155 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: 10.03
INFO:tensorflow:Starting iteration 18
I0905 16:45:14.246675 140235000764416 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 243.75
I0905 16:45:18.349807 140235000764416 replay_runner.py:36] Average training steps per second: 243.75

Steps executed: 460 Episode length: 460 Return: -168.9521598940742757
INFO:tensorflow:Starting iteration 19
I0905 16:45:23.428458 140235000764416 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 250.89

Steps executed: 1000 Episode length: 1000 Return: -56.620094953256427
I0905 16:45:30.188005 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -56.62
INFO:tensorflow:Starting iteration 20

Steps executed: 306 Episode length: 306 Return: -365.4457760400074427
INFO:tensorflow:Average training steps per second: 242.08
I0905 16:45:38.600642 140235000764416 replay_runner.py:36] Average training steps per second: 242.08
I0905 16:45:39.055001 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -365.45
INFO:tensorflow:Starting iteration 21
I0905 16:45:43.130607 140235000764416 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 233.05

Steps executed: 338 Episode length: 338 Return: -317.3994275605898627
I0905 16:45:48.010962 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -317.40
INFO:tensorflow:Starting iteration 22
I0905 16:45:51.969296 140235000764416 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 230.03

Steps executed: 1000 Episode length: 1000 Return: -97.714834486231237
I0905 16:45:59.021324 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.71
INFO:tensorflow:Starting iteration 23

Steps executed: 142 Episode length: 142 Return: -118.1214535664255237
INFO:tensorflow:Average training steps per second: 220.05

Steps executed: 400 Episode length: 258 Return: -64.08519187627073237
I0905 16:46:07.826837 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.10
INFO:tensorflow:Starting iteration 24

Steps executed: 601 Episode length: 601 Return: -166.2935630179880237
INFO:tensorflow:Average training steps per second: 230.81
I0905 16:46:15.936507 140235000764416 replay_runner.py:36] Average training steps per second: 230.81
I0905 16:46:17.272631 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.29
INFO:tensorflow:Starting iteration 25

Steps executed: 180 Episode length: 180 Return: -430.7505309117120237
INFO:tensorflow:Average training steps per second: 259.21

Steps executed: 1180 Episode length: 1000 Return: -109.14067394207969
I0905 16:46:29.672613 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.95
INFO:tensorflow:Starting iteration 26

Steps executed: 687 Episode length: 507 Return: -142.3132346875003769
INFO:tensorflow:Average training steps per second: 244.72
I0905 16:46:37.550209 140235000764416 replay_runner.py:36] Average training steps per second: 244.72
I0905 16:46:39.101555 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: -35.73
INFO:tensorflow:Starting iteration 27
I0905 16:46:42.802439 140235000764416 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 244.41
I0905 16:46:46.894498 140235000764416 replay_runner.py:36] Average training steps per second: 244.41

Steps executed: 1000 Episode length: 1000 Return: -42.070829641661169
INFO:tensorflow:Starting iteration 28
I0905 16:46:52.923798 140235000764416 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 253.91

Steps executed: 1000 Episode length: 1000 Return: 19.7421202902954329
I0905 16:46:58.854245 140235000764416 run_experiment.py:428] Average undiscounted return per evaluation episode: 19.74
INFO:tensorflow:Starting iteration 29
I0905 16:47:01.752576 140235000764416 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 294.92

Steps executed: 1000 Episode length: 1000 Return: -54.182974151513999

Done fixed training! Episode length: 1000 Return: -54.182974151513999