Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0828 10:32:46.628930 140618562066432 run_experiment.py:549] Creating TrainRunner ...
I0828 10:32:46.639489 140618562066432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:46.639736 140618562066432 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:46.639964 140618562066432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:46.640144 140618562066432 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:46.640345 140618562066432 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:46.640501 140618562066432 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:46.640630 140618562066432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:46.640723 140618562066432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:46.640810 140618562066432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:46.640894 140618562066432 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:46.640974 140618562066432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:46.641047 140618562066432 dqn_agent.py:283] 	 seed: 1630146766639423
I0828 10:32:46.643683 140618562066432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:46.643877 140618562066432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:46.644138 140618562066432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:46.644350 140618562066432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:46.644480 140618562066432 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:46.644677 140618562066432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:46.644800 140618562066432 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:46.644933 140618562066432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:46.645062 140618562066432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:46.681006 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:47.060559 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:47.073926 140618562066432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:32:47.082443 140618562066432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:47.082708 140618562066432 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:47.083050 140618562066432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:47.083207 140618562066432 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:47.083332 140618562066432 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:47.083462 140618562066432 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:47.083573 140618562066432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:47.083648 140618562066432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:47.083740 140618562066432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:47.083853 140618562066432 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:47.083940 140618562066432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:47.084369 140618562066432 dqn_agent.py:283] 	 seed: 1630146767082391
I0828 10:32:47.087587 140618562066432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:47.087787 140618562066432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:47.087920 140618562066432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:47.088049 140618562066432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:47.088165 140618562066432 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:47.088274 140618562066432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:47.088384 140618562066432 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:47.088586 140618562066432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:47.088695 140618562066432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:47.155886 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:47.177226 140618562066432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:32:47.177520 140618562066432 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 158.40
I0828 10:32:53.491619 140618562066432 replay_runner.py:36] Average training steps per second: 158.40
I0828 10:32:54.753244 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -648.63
Steps executed: 203 Episode length: 58 Return: -532.9867808593768
INFO:tensorflow:Starting iteration 1
I0828 10:32:59.025170 140618562066432 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 223.69
I0828 10:33:03.496005 140618562066432 replay_runner.py:36] Average training steps per second: 223.69

Steps executed: 264 Episode length: 87 Return: -112.96699269181215
INFO:tensorflow:Starting iteration 2

Steps executed: 279 Episode length: 92 Return: -451.294341906782963
INFO:tensorflow:Average training steps per second: 222.21
I0828 10:33:12.530382 140618562066432 replay_runner.py:36] Average training steps per second: 222.21
I0828 10:33:12.792357 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -436.65
INFO:tensorflow:Starting iteration 3

Steps executed: 319 Episode length: 152 Return: -842.99397650864163
INFO:tensorflow:Average training steps per second: 223.94
I0828 10:33:21.473448 140618562066432 replay_runner.py:36] Average training steps per second: 223.94
I0828 10:33:21.776369 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -662.50
INFO:tensorflow:Starting iteration 4
I0828 10:33:26.078023 140618562066432 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 233.06

Steps executed: 96 Episode length: 96 Return: -516.7013086068944163

Steps executed: 257 Episode length: 161 Return: -600.71796166242513
INFO:tensorflow:Starting iteration 5
I0828 10:33:34.906636 140618562066432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 225.04
I0828 10:33:39.350898 140618562066432 replay_runner.py:36] Average training steps per second: 225.04

Steps executed: 242 Episode length: 73 Return: -500.636204741855913
INFO:tensorflow:Starting iteration 6

Steps executed: 383 Episode length: 296 Return: -538.73000056629393
INFO:tensorflow:Average training steps per second: 226.26
I0828 10:33:48.244793 140618562066432 replay_runner.py:36] Average training steps per second: 226.26
I0828 10:33:48.669134 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -427.37
INFO:tensorflow:Starting iteration 7

Steps executed: 201 Episode length: 67 Return: -449.902985163342863
INFO:tensorflow:Average training steps per second: 220.89
I0828 10:33:57.452092 140618562066432 replay_runner.py:36] Average training steps per second: 220.89
I0828 10:33:57.621010 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -499.76
INFO:tensorflow:Starting iteration 8

Steps executed: 256 Episode length: 77 Return: -578.148727097807263
INFO:tensorflow:Average training steps per second: 227.26
I0828 10:34:06.193626 140618562066432 replay_runner.py:36] Average training steps per second: 227.26
I0828 10:34:06.422522 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -578.99
INFO:tensorflow:Starting iteration 9

Steps executed: 204 Episode length: 60 Return: -614.640126506449563
INFO:tensorflow:Average training steps per second: 225.72
I0828 10:34:14.946068 140618562066432 replay_runner.py:36] Average training steps per second: 225.72
I0828 10:34:15.125134 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -627.71
INFO:tensorflow:Starting iteration 10

Steps executed: 215 Episode length: 79 Return: -370.477910796192133
INFO:tensorflow:Average training steps per second: 222.28
I0828 10:34:23.863461 140618562066432 replay_runner.py:36] Average training steps per second: 222.28
I0828 10:34:24.076524 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -521.51
INFO:tensorflow:Starting iteration 11

Steps executed: 225 Episode length: 74 Return: -620.105585413285433
INFO:tensorflow:Average training steps per second: 218.00
I0828 10:34:32.904582 140618562066432 replay_runner.py:36] Average training steps per second: 218.00
I0828 10:34:33.118736 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -642.67
INFO:tensorflow:Starting iteration 12

Steps executed: 199 Episode length: 114 Return: -598.86377659535313
INFO:tensorflow:Average training steps per second: 217.36
I0828 10:34:41.970609 140618562066432 replay_runner.py:36] Average training steps per second: 217.36

Steps executed: 471 Episode length: 272 Return: -731.41342878466823
INFO:tensorflow:Starting iteration 13

Steps executed: 228 Episode length: 98 Return: -585.782981488216156
INFO:tensorflow:Average training steps per second: 217.76
I0828 10:34:51.353838 140618562066432 replay_runner.py:36] Average training steps per second: 217.76
I0828 10:34:51.590657 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -810.96
INFO:tensorflow:Starting iteration 14
I0828 10:34:55.918338 140618562066432 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 216.35

Steps executed: 262 Episode length: 116 Return: -563.37097928295196
I0828 10:35:00.821171 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -778.13
INFO:tensorflow:Starting iteration 15

Steps executed: 379 Episode length: 379 Return: -4725.7746958164766
INFO:tensorflow:Average training steps per second: 214.95
I0828 10:35:09.697096 140618562066432 replay_runner.py:36] Average training steps per second: 214.95
I0828 10:35:10.311551 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -4725.77
INFO:tensorflow:Starting iteration 16

Steps executed: 249 Episode length: 118 Return: -873.16069635365697
INFO:tensorflow:Average training steps per second: 218.63
I0828 10:35:19.232594 140618562066432 replay_runner.py:36] Average training steps per second: 218.63
I0828 10:35:19.471650 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -959.57
INFO:tensorflow:Starting iteration 17

Steps executed: 285 Episode length: 87 Return: -573.183672348789787
INFO:tensorflow:Average training steps per second: 219.85
I0828 10:35:28.258752 140618562066432 replay_runner.py:36] Average training steps per second: 219.85
I0828 10:35:28.542099 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -581.40
INFO:tensorflow:Starting iteration 18

Steps executed: 339 Episode length: 163 Return: -1121.5386016920688
INFO:tensorflow:Average training steps per second: 216.60
I0828 10:35:37.494397 140618562066432 replay_runner.py:36] Average training steps per second: 216.60
I0828 10:35:37.857131 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -804.91
INFO:tensorflow:Starting iteration 19
I0828 10:35:42.219706 140618562066432 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 219.97

Steps executed: 315 Episode length: 123 Return: -799.03815976086798
I0828 10:35:47.069917 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -669.57
INFO:tensorflow:Starting iteration 20

Steps executed: 261 Episode length: 151 Return: -828.15149258774678
INFO:tensorflow:Average training steps per second: 222.05
I0828 10:35:55.943909 140618562066432 replay_runner.py:36] Average training steps per second: 222.05
I0828 10:35:56.202443 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -704.73
INFO:tensorflow:Starting iteration 21

Steps executed: 331 Episode length: 133 Return: -971.40212012915138
INFO:tensorflow:Average training steps per second: 221.52
I0828 10:36:05.020089 140618562066432 replay_runner.py:36] Average training steps per second: 221.52
I0828 10:36:05.336987 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -685.57
INFO:tensorflow:Starting iteration 22

Steps executed: 219 Episode length: 85 Return: -446.845714233195668
INFO:tensorflow:Average training steps per second: 220.92
I0828 10:36:14.101047 140618562066432 replay_runner.py:36] Average training steps per second: 220.92
I0828 10:36:14.302644 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -654.37
INFO:tensorflow:Starting iteration 23

Steps executed: 230 Episode length: 74 Return: -503.661635276540848
INFO:tensorflow:Average training steps per second: 221.30
I0828 10:36:23.081257 140618562066432 replay_runner.py:36] Average training steps per second: 221.30
I0828 10:36:23.307919 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -900.29
INFO:tensorflow:Starting iteration 24

Steps executed: 258 Episode length: 76 Return: -464.718341824452448
INFO:tensorflow:Average training steps per second: 230.90
I0828 10:36:31.850646 140618562066432 replay_runner.py:36] Average training steps per second: 230.90
I0828 10:36:32.077749 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -553.59
INFO:tensorflow:Starting iteration 25

Steps executed: 176 Episode length: 84 Return: -446.076730578602948
INFO:tensorflow:Average training steps per second: 226.88
I0828 10:36:40.627049 140618562066432 replay_runner.py:36] Average training steps per second: 226.88

Steps executed: 410 Episode length: 234 Return: -1911.7419116308874
INFO:tensorflow:Starting iteration 26

Steps executed: 215 Episode length: 86 Return: -651.296699996971164
INFO:tensorflow:Average training steps per second: 228.94
I0828 10:36:49.732475 140618562066432 replay_runner.py:36] Average training steps per second: 228.94
I0828 10:36:49.941334 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -752.70
INFO:tensorflow:Starting iteration 27

Steps executed: 288 Episode length: 115 Return: -676.38405744485564
INFO:tensorflow:Average training steps per second: 220.65
I0828 10:36:58.665582 140618562066432 replay_runner.py:36] Average training steps per second: 220.65
I0828 10:36:58.939306 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -585.43
INFO:tensorflow:Starting iteration 28

Steps executed: 278 Episode length: 87 Return: -684.854735461159587
INFO:tensorflow:Average training steps per second: 227.14
I0828 10:37:07.585993 140618562066432 replay_runner.py:36] Average training steps per second: 227.14
I0828 10:37:07.888295 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -984.20
INFO:tensorflow:Starting iteration 29

Steps executed: 242 Episode length: 168 Return: -1376.7184598563351
INFO:tensorflow:Average training steps per second: 241.58
I0828 10:37:16.242697 140618562066432 replay_runner.py:36] Average training steps per second: 241.58

Done fixed training!Episode length: 168 Return: -1376.7184598563351