I0901 23:49:47.599585 139825600018432 run_experiment.py:549] Creating TrainRunner ...
I0901 23:49:47.611847 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:47.612092 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:47.612264 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:47.612412 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:47.612542 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:47.612667 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:47.612786 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:47.612908 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:47.613057 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:47.613246 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:47.613453 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:47.613577 139825600018432 dqn_agent.py:283] 	 seed: 1630540187611785
I0901 23:49:47.616596 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:47.616857 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:47.617008 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:47.617131 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:47.617384 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:47.617546 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:47.617735 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:47.617984 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:47.618249 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0901 23:49:49.541475 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:49.969716 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:49.986468 139825600018432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:49:49.997603 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:49.997787 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:49.997889 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:49.998042 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:49.998163 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:49.998239 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:49.998345 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:49.998425 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:49.998502 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:49.998576 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:49.998696 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:49.998817 139825600018432 dqn_agent.py:283] 	 seed: 1630540189997558
I0901 23:49:50.002275 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:50.002567 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:50.002726 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:50.002909 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:50.003063 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:50.003187 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:50.003320 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:50.003425 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:50.003545 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:49:50.045072 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:50.072124 139825600018432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:49:50.072546 139825600018432 replay_runner.py:41] Starting iteration 0
Steps executed: 148 Episode length: 148 Return: -406.1992626935488
INFO:tensorflow:Average training steps per second: 170.39

Steps executed: 248 Episode length: 100 Return: -274.8842057707863
I0901 23:49:57.236112 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -340.54
INFO:tensorflow:Starting iteration 1

Steps executed: 314 Episode length: 155 Return: -294.45873543375257
INFO:tensorflow:Average training steps per second: 232.33
I0901 23:50:05.856933 139825600018432 replay_runner.py:36] Average training steps per second: 232.33
I0901 23:50:06.156807 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.13
INFO:tensorflow:Starting iteration 2
I0901 23:50:10.522367 139825600018432 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 225.10

Steps executed: 531 Episode length: 531 Return: -354.22804925897547
I0901 23:50:16.187201 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -354.23
INFO:tensorflow:Starting iteration 3
I0901 23:50:20.530526 139825600018432 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 223.36

Steps executed: 1000 Episode length: 1000 Return: -148.48920333627896
I0901 23:50:28.627409 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.49
INFO:tensorflow:Starting iteration 4
I0901 23:50:32.908223 139825600018432 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 234.58

Steps executed: 1000 Episode length: 1000 Return: -122.27621966776499
I0901 23:50:39.871456 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.28
INFO:tensorflow:Starting iteration 5
I0901 23:50:43.988321 139825600018432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 224.53

Steps executed: 1000 Episode length: 1000 Return: -68.796152780856979
I0901 23:50:50.765592 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.80
INFO:tensorflow:Starting iteration 6
I0901 23:50:54.976762 139825600018432 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 227.85

Steps executed: 1000 Episode length: 1000 Return: -149.83980826581439
I0901 23:51:02.471740 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.84
INFO:tensorflow:Starting iteration 7
I0901 23:51:06.705291 139825600018432 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 217.45

Steps executed: 1000 Episode length: 1000 Return: -140.37468446851869
I0901 23:51:14.433763 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.37
INFO:tensorflow:Starting iteration 8
I0901 23:51:18.816220 139825600018432 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 222.06

Steps executed: 1000 Episode length: 1000 Return: -208.07055632469159
I0901 23:51:27.335621 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.07
INFO:tensorflow:Starting iteration 9

Steps executed: 281 Episode length: 281 Return: -285.1994070514291559
INFO:tensorflow:Average training steps per second: 227.03
I0901 23:51:35.828614 139825600018432 replay_runner.py:36] Average training steps per second: 227.03
I0901 23:51:36.189739 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.20
INFO:tensorflow:Starting iteration 10
I0901 23:51:40.594407 139825600018432 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 220.99

Steps executed: 987 Episode length: 987 Return: -550.1273021829774559
I0901 23:51:47.717237 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.13
INFO:tensorflow:Starting iteration 11

Steps executed: 334 Episode length: 334 Return: -197.8449376449700659
INFO:tensorflow:Average training steps per second: 223.79
I0901 23:51:56.434898 139825600018432 replay_runner.py:36] Average training steps per second: 223.79
I0901 23:51:56.850051 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.84
INFO:tensorflow:Starting iteration 12

Steps executed: 264 Episode length: 264 Return: -306.9102937861199559
INFO:tensorflow:Average training steps per second: 229.90
I0901 23:52:05.503795 139825600018432 replay_runner.py:36] Average training steps per second: 229.90
I0901 23:52:05.817975 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -306.91
INFO:tensorflow:Starting iteration 13
I0901 23:52:10.174488 139825600018432 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 226.71

Steps executed: 990 Episode length: 990 Return: -311.8097010464963559
I0901 23:52:16.590460 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.81
INFO:tensorflow:Starting iteration 14
I0901 23:52:21.041974 139825600018432 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 225.77
I0901 23:52:25.471761 139825600018432 replay_runner.py:36] Average training steps per second: 225.77

Steps executed: 379 Episode length: 206 Return: -142.6694905584263659
INFO:tensorflow:Starting iteration 15
I0901 23:52:30.286285 139825600018432 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 222.57
I0901 23:52:34.779621 139825600018432 replay_runner.py:36] Average training steps per second: 222.57

Steps executed: 597 Episode length: 597 Return: -329.3238940020576659
INFO:tensorflow:Starting iteration 16

Steps executed: 201 Episode length: 114 Return: -418.2596028528934759
INFO:tensorflow:Average training steps per second: 223.07
I0901 23:52:44.801405 139825600018432 replay_runner.py:36] Average training steps per second: 223.07
I0901 23:52:44.964292 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.26
INFO:tensorflow:Starting iteration 17
I0901 23:52:49.294229 139825600018432 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 234.92

Steps executed: 330 Episode length: 330 Return: -107.4897978300787459
I0901 23:52:53.981176 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.49
INFO:tensorflow:Starting iteration 18

Steps executed: 380 Episode length: 301 Return: -237.5239646556293459
INFO:tensorflow:Average training steps per second: 235.88
I0901 23:53:02.541675 139825600018432 replay_runner.py:36] Average training steps per second: 235.88
I0901 23:53:02.947623 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.03
INFO:tensorflow:Starting iteration 19
I0901 23:53:07.351868 139825600018432 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 228.47
I0901 23:53:11.729249 139825600018432 replay_runner.py:36] Average training steps per second: 228.47

Steps executed: 368 Episode length: 239 Return: -48.58018588864859259
INFO:tensorflow:Starting iteration 20

Steps executed: 141 Episode length: 141 Return: 25.109305741740513259
INFO:tensorflow:Average training steps per second: 226.59
I0901 23:53:20.898044 139825600018432 replay_runner.py:36] Average training steps per second: 226.59

Steps executed: 572 Episode length: 431 Return: -92.25359073479363259
INFO:tensorflow:Starting iteration 21

Steps executed: 339 Episode length: 208 Return: 25.806086395392853259
INFO:tensorflow:Average training steps per second: 226.09
I0901 23:53:30.682320 139825600018432 replay_runner.py:36] Average training steps per second: 226.09
I0901 23:53:31.002686 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -24.04
INFO:tensorflow:Starting iteration 22

Steps executed: 206 Episode length: 106 Return: -127.0478258939221759
INFO:tensorflow:Average training steps per second: 241.82
I0901 23:53:39.492018 139825600018432 replay_runner.py:36] Average training steps per second: 241.82
I0901 23:53:39.629871 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.25
INFO:tensorflow:Starting iteration 23

Steps executed: 217 Episode length: 57 Return: -94.861137789857181759
INFO:tensorflow:Average training steps per second: 235.03
I0901 23:53:48.132363 139825600018432 replay_runner.py:36] Average training steps per second: 235.03
I0901 23:53:48.273939 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.44
INFO:tensorflow:Starting iteration 24

Steps executed: 260 Episode length: 142 Return: -191.6522356142544259
INFO:tensorflow:Average training steps per second: 233.75
I0901 23:53:56.880036 139825600018432 replay_runner.py:36] Average training steps per second: 233.75
I0901 23:53:57.094067 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.97
INFO:tensorflow:Starting iteration 25
I0901 23:54:01.414558 139825600018432 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 223.10

Steps executed: 284 Episode length: 115 Return: -855.9378458658413559
I0901 23:54:06.153964 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -625.89
INFO:tensorflow:Starting iteration 26

Steps executed: 265 Episode length: 149 Return: -562.6443085372312559
INFO:tensorflow:Average training steps per second: 229.37
I0901 23:54:14.865976 139825600018432 replay_runner.py:36] Average training steps per second: 229.37
I0901 23:54:15.126063 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -587.72
INFO:tensorflow:Starting iteration 27
I0901 23:54:19.497900 139825600018432 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 222.95

Steps executed: 201 Episode length: 88 Return: -181.33186894636037659
I0901 23:54:24.183333 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -334.68
INFO:tensorflow:Starting iteration 28

Steps executed: 250 Episode length: 106 Return: -520.3873841152277659
INFO:tensorflow:Average training steps per second: 229.07
I0901 23:54:32.914240 139825600018432 replay_runner.py:36] Average training steps per second: 229.07
I0901 23:54:33.129566 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -459.42
INFO:tensorflow:Starting iteration 29

Steps executed: 255 Episode length: 77 Return: -703.85816661202243659
INFO:tensorflow:Average training steps per second: 228.03
I0901 23:54:41.788825 139825600018432 replay_runner.py:36] Average training steps per second: 228.03

Done fixed training!Episode length: 77 Return: -703.85816661202243659