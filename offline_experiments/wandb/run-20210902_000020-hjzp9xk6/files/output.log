Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0902 00:00:27.022422 139929824643072 run_experiment.py:549] Creating TrainRunner ...
I0902 00:00:27.034675 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:00:27.034995 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:00:27.035197 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:00:27.035451 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:00:27.035595 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0902 00:00:27.035711 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:00:27.035825 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:00:27.035946 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:00:27.036065 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:00:27.036170 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0902 00:00:27.036280 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:00:27.036406 139929824643072 dqn_agent.py:283] 	 seed: 1630540827034602
I0902 00:00:27.039535 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:00:27.039776 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:00:27.039915 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:00:27.040035 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:00:27.040140 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:00:27.040247 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:00:27.040355 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:00:27.040452 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:00:27.040544 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:00:27.078213 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:00:27.472011 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:00:27.486463 139929824643072 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:00:27.495513 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:00:27.495815 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:00:27.495991 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:00:27.496109 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:00:27.496214 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0902 00:00:27.496337 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:00:27.496521 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:00:27.496691 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:00:27.496857 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:00:27.497020 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0902 00:00:27.497143 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:00:27.497390 139929824643072 dqn_agent.py:283] 	 seed: 1630540827495450
I0902 00:00:27.500550 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:00:27.500852 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:00:27.501223 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:00:27.501437 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:00:27.501595 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:00:27.501733 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:00:27.501856 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:00:27.501978 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:00:27.502146 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:00:27.575327 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:00:27.602857 139929824643072 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:00:27.603190 139929824643072 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.17
I0902 00:00:33.769849 139929824643072 replay_runner.py:36] Average training steps per second: 162.17
Steps executed: 274 Episode length: 138 Return: -344.61486881443386
I0902 00:00:35.092576 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.45
INFO:tensorflow:Starting iteration 1
I0902 00:00:39.329659 139929824643072 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 217.57
I0902 00:00:43.926211 139929824643072 replay_runner.py:36] Average training steps per second: 217.57

Steps executed: 295 Episode length: 128 Return: -245.03961402331726
INFO:tensorflow:Starting iteration 2

Steps executed: 284 Episode length: 127 Return: -240.65428972501016
INFO:tensorflow:Average training steps per second: 220.16
I0902 00:00:53.057491 139929824643072 replay_runner.py:36] Average training steps per second: 220.16
I0902 00:00:53.319897 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.34
INFO:tensorflow:Starting iteration 3

Steps executed: 120 Episode length: 120 Return: -321.73064521027015
INFO:tensorflow:Average training steps per second: 221.08

Steps executed: 577 Episode length: 457 Return: -528.29648946693515
I0902 00:01:02.959191 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -425.01
INFO:tensorflow:Starting iteration 4
I0902 00:01:07.417851 139929824643072 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 225.47

Steps executed: 912 Episode length: 912 Return: -318.52672486139725
I0902 00:01:13.945359 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -318.53
INFO:tensorflow:Starting iteration 5
I0902 00:01:18.300691 139929824643072 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 225.83

Steps executed: 1000 Episode length: 1000 Return: -45.65304126238182
I0902 00:01:26.316020 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -45.65
INFO:tensorflow:Starting iteration 6
I0902 00:01:30.466814 139929824643072 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 220.81

Steps executed: 1000 Episode length: 1000 Return: -71.29457218543767
I0902 00:01:39.649110 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.29
INFO:tensorflow:Starting iteration 7
I0902 00:01:43.622106 139929824643072 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 226.54

Steps executed: 912 Episode length: 912 Return: -433.037464632504577
I0902 00:01:50.644450 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -433.04
INFO:tensorflow:Starting iteration 8

Steps executed: 474 Episode length: 474 Return: -450.165671625153557
INFO:tensorflow:Average training steps per second: 226.53
I0902 00:01:59.266020 139929824643072 replay_runner.py:36] Average training steps per second: 226.53
I0902 00:01:59.913275 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -450.17
INFO:tensorflow:Starting iteration 9
I0902 00:02:04.233670 139929824643072 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 222.00

Steps executed: 1000 Episode length: 1000 Return: -342.96901129858134
I0902 00:02:12.364035 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.97
INFO:tensorflow:Starting iteration 10
I0902 00:02:16.571590 139929824643072 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 221.29

Steps executed: 303 Episode length: 303 Return: -186.3098279232356234
I0902 00:02:21.434958 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.31
INFO:tensorflow:Starting iteration 11
I0902 00:02:25.761039 139929824643072 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 213.64

Steps executed: 1000 Episode length: 1000 Return: -250.42587610215287
I0902 00:02:33.784953 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -250.43
INFO:tensorflow:Starting iteration 12
I0902 00:02:38.122317 139929824643072 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 231.26

Steps executed: 1000 Episode length: 1000 Return: -228.63308842426133
I0902 00:02:45.992608 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.63
INFO:tensorflow:Starting iteration 13
I0902 00:02:50.255605 139929824643072 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 244.42

Steps executed: 842 Episode length: 842 Return: -743.6923917860622133
I0902 00:02:56.391500 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -743.69
INFO:tensorflow:Starting iteration 14
I0902 00:03:00.703003 139929824643072 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 232.12

Steps executed: 308 Episode length: 308 Return: -882.5340832476902133
I0902 00:03:05.460459 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -882.53
INFO:tensorflow:Starting iteration 15
I0902 00:03:09.577926 139929824643072 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 219.26

Steps executed: 1000 Episode length: 1000 Return: -108.96539245306408
I0902 00:03:18.283900 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.97
INFO:tensorflow:Starting iteration 16
I0902 00:03:22.585787 139929824643072 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 223.52
I0902 00:03:27.060430 139929824643072 replay_runner.py:36] Average training steps per second: 223.52

Steps executed: 220 Episode length: 220 Return: -194.9444137439234408
INFO:tensorflow:Starting iteration 17
I0902 00:03:31.563492 139929824643072 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 219.00
I0902 00:03:36.130023 139929824643072 replay_runner.py:36] Average training steps per second: 219.00

Steps executed: 1000 Episode length: 1000 Return: -191.99694541242627
INFO:tensorflow:Starting iteration 18

Steps executed: 174 Episode length: 63 Return: -415.27335018481836427
INFO:tensorflow:Average training steps per second: 219.31

Steps executed: 759 Episode length: 585 Return: -373.8178228993876427
I0902 00:03:49.410396 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.90
INFO:tensorflow:Starting iteration 19

Steps executed: 361 Episode length: 240 Return: 45.161032704098774427
INFO:tensorflow:Average training steps per second: 223.42
I0902 00:03:58.296564 139929824643072 replay_runner.py:36] Average training steps per second: 223.42
I0902 00:03:58.650638 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -6.12
INFO:tensorflow:Starting iteration 20

Steps executed: 390 Episode length: 223 Return: -437.2004256855288427
INFO:tensorflow:Average training steps per second: 222.60
I0902 00:04:07.554905 139929824643072 replay_runner.py:36] Average training steps per second: 222.60
I0902 00:04:07.925935 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -526.11
INFO:tensorflow:Starting iteration 21

Steps executed: 255 Episode length: 57 Return: -128.47085957121348427
INFO:tensorflow:Average training steps per second: 223.71
I0902 00:04:16.794860 139929824643072 replay_runner.py:36] Average training steps per second: 223.71
I0902 00:04:17.072654 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -53.25
INFO:tensorflow:Starting iteration 22

Steps executed: 284 Episode length: 226 Return: -180.2879325749815427
INFO:tensorflow:Average training steps per second: 222.21
I0902 00:04:25.753226 139929824643072 replay_runner.py:36] Average training steps per second: 222.21
I0902 00:04:26.069615 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.53
INFO:tensorflow:Starting iteration 23
I0902 00:04:30.439113 139929824643072 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 222.97

Steps executed: 883 Episode length: 883 Return: -880.2246048943505427
I0902 00:04:37.110470 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -880.22
INFO:tensorflow:Starting iteration 24

Steps executed: 273 Episode length: 161 Return: -363.8291462436822627
INFO:tensorflow:Average training steps per second: 231.75
I0902 00:04:45.776835 139929824643072 replay_runner.py:36] Average training steps per second: 231.75
I0902 00:04:46.029839 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -373.80
INFO:tensorflow:Starting iteration 25
I0902 00:04:50.339238 139929824643072 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 226.22

Steps executed: 632 Episode length: 632 Return: -911.3814846100556627
I0902 00:04:56.306975 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -911.38
INFO:tensorflow:Starting iteration 26

Steps executed: 132 Episode length: 132 Return: -318.4598022738816627
INFO:tensorflow:Average training steps per second: 227.15

Steps executed: 454 Episode length: 322 Return: -364.9321907125978627
I0902 00:05:05.601155 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.70
INFO:tensorflow:Starting iteration 27

Steps executed: 291 Episode length: 151 Return: -477.0416625939575627
INFO:tensorflow:Average training steps per second: 225.24
I0902 00:05:14.327137 139929824643072 replay_runner.py:36] Average training steps per second: 225.24
I0902 00:05:14.597173 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -473.18
INFO:tensorflow:Starting iteration 28

Steps executed: 52 Episode length: 52 Return: -207.207068181728185627
INFO:tensorflow:Average training steps per second: 224.34

Steps executed: 917 Episode length: 865 Return: -160.6666298603851627
I0902 00:05:25.346446 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -183.94
INFO:tensorflow:Starting iteration 29
I0902 00:05:29.730556 139929824643072 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 223.82

Steps executed: 912 Episode length: 912 Return: -1552.825138119068727

Done fixed training!Episode length: 912 Return: -1552.825138119068727