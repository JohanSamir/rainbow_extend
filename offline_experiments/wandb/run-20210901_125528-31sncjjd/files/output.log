Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0901 12:55:34.975728 140536266098688 run_experiment.py:549] Creating TrainRunner ...
I0901 12:55:34.988064 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:55:34.988296 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:55:34.988474 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:55:34.988614 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:55:34.988698 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 12:55:34.988773 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:55:34.988885 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:55:34.988960 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:55:34.989122 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:55:34.989201 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 12:55:34.989273 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:55:34.989324 140536266098688 dqn_agent.py:283] 	 seed: 1630500934988010
I0901 12:55:34.991994 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:55:34.992268 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:55:34.992443 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:55:34.992640 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:55:34.992852 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:55:34.993006 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:55:34.993135 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:55:34.993244 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:55:34.993368 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:55:35.058182 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:55:35.433359 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:55:35.448653 140536266098688 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:55:35.482024 140536266098688 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:55:35.485048 140536266098688 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:55:35.485650 140536266098688 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:55:35.485804 140536266098688 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:55:35.485897 140536266098688 dqn_agent.py:275] 	 update_period: 4
I0901 12:55:35.486013 140536266098688 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:55:35.486212 140536266098688 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:55:35.486365 140536266098688 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:55:35.486530 140536266098688 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:55:35.486827 140536266098688 dqn_agent.py:280] 	 optimizer: adam
I0901 12:55:35.487038 140536266098688 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:55:35.487304 140536266098688 dqn_agent.py:283] 	 seed: 1630500935481948
I0901 12:55:35.490889 140536266098688 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:55:35.491124 140536266098688 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:55:35.491363 140536266098688 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:55:35.491515 140536266098688 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:55:35.491626 140536266098688 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:55:35.491758 140536266098688 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:55:35.491900 140536266098688 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:55:35.492037 140536266098688 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:55:35.492216 140536266098688 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:55:35.556568 140536266098688 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:55:35.610306 140536266098688 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:55:35.610940 140536266098688 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 156.40
I0901 12:55:42.005626 140536266098688 replay_runner.py:36] Average training steps per second: 156.40
Steps executed: 244 Episode length: 66 Return: -113.404996549227125
I0901 12:55:43.216497 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.63
INFO:tensorflow:Starting iteration 1

Steps executed: 255 Episode length: 76 Return: -678.716627594637825
INFO:tensorflow:Average training steps per second: 226.21
I0901 12:55:52.129906 140536266098688 replay_runner.py:36] Average training steps per second: 226.21
I0901 12:55:52.375577 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -578.60
INFO:tensorflow:Starting iteration 2

Steps executed: 235 Episode length: 91 Return: -727.593944505326125
INFO:tensorflow:Average training steps per second: 220.62
I0901 12:56:01.364285 140536266098688 replay_runner.py:36] Average training steps per second: 220.62
I0901 12:56:01.601878 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -624.89
INFO:tensorflow:Starting iteration 3

Steps executed: 96 Episode length: 96 Return: -686.9258369424506125
INFO:tensorflow:Average training steps per second: 216.23

Steps executed: 303 Episode length: 119 Return: -309.78786574820235
I0901 12:56:10.838911 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -542.79
INFO:tensorflow:Starting iteration 4

Steps executed: 325 Episode length: 174 Return: -648.09455925680385
INFO:tensorflow:Average training steps per second: 220.99
I0901 12:56:19.641767 140536266098688 replay_runner.py:36] Average training steps per second: 220.99
I0901 12:56:19.987212 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -607.57
INFO:tensorflow:Starting iteration 5

Steps executed: 286 Episode length: 193 Return: -94.757795923997665
INFO:tensorflow:Average training steps per second: 220.61
I0901 12:56:28.251235 140536266098688 replay_runner.py:36] Average training steps per second: 220.61
I0901 12:56:28.521446 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.21
INFO:tensorflow:Starting iteration 6

Steps executed: 419 Episode length: 261 Return: -4.4844400116736555
INFO:tensorflow:Average training steps per second: 223.10
I0901 12:56:37.381298 140536266098688 replay_runner.py:36] Average training steps per second: 223.10
I0901 12:56:37.852247 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.88
INFO:tensorflow:Starting iteration 7

Steps executed: 219 Episode length: 121 Return: -279.99496710073555
INFO:tensorflow:Average training steps per second: 225.08
I0901 12:56:46.404254 140536266098688 replay_runner.py:36] Average training steps per second: 225.08
I0901 12:56:46.618356 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -465.22
INFO:tensorflow:Starting iteration 8

Steps executed: 274 Episode length: 148 Return: -172.10047678268305
INFO:tensorflow:Average training steps per second: 228.90
I0901 12:56:55.212850 140536266098688 replay_runner.py:36] Average training steps per second: 228.90
I0901 12:56:55.448878 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.10
INFO:tensorflow:Starting iteration 9

Steps executed: 251 Episode length: 132 Return: -194.15099554383215
INFO:tensorflow:Average training steps per second: 220.88
I0901 12:57:04.509515 140536266098688 replay_runner.py:36] Average training steps per second: 220.88
I0901 12:57:04.729267 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.81
INFO:tensorflow:Starting iteration 10

Steps executed: 210 Episode length: 210 Return: -130.04315417694185
INFO:tensorflow:Average training steps per second: 225.01
I0901 12:57:13.514609 140536266098688 replay_runner.py:36] Average training steps per second: 225.01
I0901 12:57:13.729433 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.04
INFO:tensorflow:Starting iteration 11

Steps executed: 272 Episode length: 127 Return: -271.79746876972574
INFO:tensorflow:Average training steps per second: 224.27
I0901 12:57:22.434494 140536266098688 replay_runner.py:36] Average training steps per second: 224.27
I0901 12:57:22.678672 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.08
INFO:tensorflow:Starting iteration 12

Steps executed: 253 Episode length: 98 Return: -373.347151218211764
INFO:tensorflow:Average training steps per second: 223.92
I0901 12:57:31.415787 140536266098688 replay_runner.py:36] Average training steps per second: 223.92
I0901 12:57:31.658008 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.74
INFO:tensorflow:Starting iteration 13

Steps executed: 249 Episode length: 82 Return: -139.691320334632254
INFO:tensorflow:Average training steps per second: 219.90
I0901 12:57:40.559439 140536266098688 replay_runner.py:36] Average training steps per second: 219.90
I0901 12:57:40.764734 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -62.68
INFO:tensorflow:Starting iteration 14

Steps executed: 433 Episode length: 262 Return: 233.798951898698974
INFO:tensorflow:Average training steps per second: 218.09
I0901 12:57:49.539857 140536266098688 replay_runner.py:36] Average training steps per second: 218.09
I0901 12:57:49.984863 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -194.75
INFO:tensorflow:Starting iteration 15

Steps executed: 167 Episode length: 167 Return: -87.859487233002974
INFO:tensorflow:Average training steps per second: 219.88

Steps executed: 318 Episode length: 151 Return: -81.503437889079634
I0901 12:57:59.338223 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.68
INFO:tensorflow:Starting iteration 16

Steps executed: 393 Episode length: 211 Return: -100.99273059894694
INFO:tensorflow:Average training steps per second: 221.48
I0901 12:58:08.043853 140536266098688 replay_runner.py:36] Average training steps per second: 221.48
I0901 12:58:08.442841 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.81
INFO:tensorflow:Starting iteration 17

Steps executed: 262 Episode length: 121 Return: -82.425011533092634
INFO:tensorflow:Average training steps per second: 218.51
I0901 12:58:17.377024 140536266098688 replay_runner.py:36] Average training steps per second: 218.51
I0901 12:58:17.609026 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -31.73
INFO:tensorflow:Starting iteration 18

Steps executed: 290 Episode length: 115 Return: -129.26533903373394
INFO:tensorflow:Average training steps per second: 225.03
I0901 12:58:26.565085 140536266098688 replay_runner.py:36] Average training steps per second: 225.03
I0901 12:58:26.824916 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.72
INFO:tensorflow:Starting iteration 19

Steps executed: 302 Episode length: 148 Return: -94.613563364997384
INFO:tensorflow:Average training steps per second: 232.38
I0901 12:58:35.529664 140536266098688 replay_runner.py:36] Average training steps per second: 232.38
I0901 12:58:35.768496 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.72
INFO:tensorflow:Starting iteration 20

Steps executed: 131 Episode length: 131 Return: -327.22503442960564
INFO:tensorflow:Average training steps per second: 218.19
I0901 12:58:44.747860 140536266098688 replay_runner.py:36] Average training steps per second: 218.19

Steps executed: 296 Episode length: 165 Return: -359.60309135554866
INFO:tensorflow:Starting iteration 21

Steps executed: 347 Episode length: 190 Return: -38.109761888119486
INFO:tensorflow:Average training steps per second: 220.78
I0901 12:58:53.847068 140536266098688 replay_runner.py:36] Average training steps per second: 220.78
I0901 12:58:54.197380 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.53
INFO:tensorflow:Starting iteration 22

Steps executed: 676 Episode length: 676 Return: 146.263634651995746
INFO:tensorflow:Average training steps per second: 215.68
I0901 12:59:03.216071 140536266098688 replay_runner.py:36] Average training steps per second: 215.68
I0901 12:59:04.600884 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: 146.26
INFO:tensorflow:Starting iteration 23

Steps executed: 343 Episode length: 241 Return: -295.11378163822896
INFO:tensorflow:Average training steps per second: 214.91
I0901 12:59:13.634167 140536266098688 replay_runner.py:36] Average training steps per second: 214.91
I0901 12:59:13.990641 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -431.77
INFO:tensorflow:Starting iteration 24

Steps executed: 308 Episode length: 160 Return: -475.76291810336836
INFO:tensorflow:Average training steps per second: 215.45
I0901 12:59:22.885375 140536266098688 replay_runner.py:36] Average training steps per second: 215.45
I0901 12:59:23.180189 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -398.20
INFO:tensorflow:Starting iteration 25

Steps executed: 246 Episode length: 246 Return: -130.69293765530233
INFO:tensorflow:Average training steps per second: 216.35
I0901 12:59:32.244541 140536266098688 replay_runner.py:36] Average training steps per second: 216.35
I0901 12:59:32.500269 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.69
INFO:tensorflow:Starting iteration 26

Steps executed: 299 Episode length: 101 Return: -151.08839198656898
INFO:tensorflow:Average training steps per second: 223.30
I0901 12:59:41.426468 140536266098688 replay_runner.py:36] Average training steps per second: 223.30
I0901 12:59:41.679261 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.67
INFO:tensorflow:Starting iteration 27

Steps executed: 270 Episode length: 95 Return: -466.312686099708238
INFO:tensorflow:Average training steps per second: 224.34
I0901 12:59:50.489972 140536266098688 replay_runner.py:36] Average training steps per second: 224.34
I0901 12:59:50.751041 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -579.53
INFO:tensorflow:Starting iteration 28

Steps executed: 330 Episode length: 330 Return: -121.25607721823555
INFO:tensorflow:Average training steps per second: 219.36
I0901 12:59:59.657629 140536266098688 replay_runner.py:36] Average training steps per second: 219.36
I0901 13:00:00.041492 140536266098688 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.26
INFO:tensorflow:Starting iteration 29

Steps executed: 263 Episode length: 106 Return: -43.608305519424855
INFO:tensorflow:Average training steps per second: 216.54
I0901 13:00:09.013202 140536266098688 replay_runner.py:36] Average training steps per second: 216.54

Done fixed training!Episode length: 106 Return: -43.608305519424855