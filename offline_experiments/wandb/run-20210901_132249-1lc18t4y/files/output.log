I0901 13:22:55.525689 140240877414400 run_experiment.py:549] Creating TrainRunner ...
I0901 13:22:55.532585 140240877414400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:22:55.532700 140240877414400 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:22:55.532755 140240877414400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:22:55.532834 140240877414400 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:22:55.532890 140240877414400 dqn_agent.py:275] 	 update_period: 4
I0901 13:22:55.532941 140240877414400 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:22:55.532989 140240877414400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:22:55.533051 140240877414400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:22:55.533123 140240877414400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:22:55.533245 140240877414400 dqn_agent.py:280] 	 optimizer: adam
I0901 13:22:55.533325 140240877414400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:22:55.533390 140240877414400 dqn_agent.py:283] 	 seed: 1630502575532557
I0901 13:22:55.535072 140240877414400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:22:55.535183 140240877414400 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:22:55.535257 140240877414400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:22:55.535319 140240877414400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:22:55.535374 140240877414400 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:22:55.535444 140240877414400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:22:55.535501 140240877414400 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:22:55.535579 140240877414400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:22:55.535663 140240877414400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:22:55.646458 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:22:55.890383 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:22:55.899439 140240877414400 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:22:55.906012 140240877414400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:22:55.906233 140240877414400 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:22:55.906386 140240877414400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:22:55.906480 140240877414400 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:22:55.906573 140240877414400 dqn_agent.py:275] 	 update_period: 4
I0901 13:22:55.906728 140240877414400 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:22:55.906903 140240877414400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:22:55.907010 140240877414400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:22:55.907125 140240877414400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:22:55.907211 140240877414400 dqn_agent.py:280] 	 optimizer: adam
I0901 13:22:55.907313 140240877414400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:22:55.907410 140240877414400 dqn_agent.py:283] 	 seed: 1630502575905970
I0901 13:22:55.909497 140240877414400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:22:55.909656 140240877414400 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:22:55.909749 140240877414400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:22:55.909830 140240877414400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:22:55.909914 140240877414400 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:22:55.909969 140240877414400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:22:55.910040 140240877414400 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:22:55.910138 140240877414400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:22:55.910217 140240877414400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:22:55.932318 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:22:55.947717 140240877414400 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:22:55.947907 140240877414400 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 223.86
I0901 13:23:00.415624 140240877414400 replay_runner.py:36] Average training steps per second: 223.86
Steps executed: 245 Episode length: 145 Return: -280.05994662700766
I0901 13:23:01.271198 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -272.44
INFO:tensorflow:Starting iteration 1

Steps executed: 310 Episode length: 120 Return: -267.77030296869975
INFO:tensorflow:Average training steps per second: 315.56
I0901 13:23:07.668602 140240877414400 replay_runner.py:36] Average training steps per second: 315.56
I0901 13:23:07.853840 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.80
INFO:tensorflow:Starting iteration 2

Steps executed: 257 Episode length: 132 Return: -208.61662326811023
INFO:tensorflow:Average training steps per second: 314.74
I0901 13:23:14.372257 140240877414400 replay_runner.py:36] Average training steps per second: 314.74
I0901 13:23:14.541672 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -275.43
INFO:tensorflow:Starting iteration 3

Steps executed: 237 Episode length: 109 Return: -333.96954296852795
INFO:tensorflow:Average training steps per second: 318.12
I0901 13:23:21.051333 140240877414400 replay_runner.py:36] Average training steps per second: 318.12
I0901 13:23:21.207760 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -315.34
INFO:tensorflow:Starting iteration 4

Steps executed: 252 Episode length: 127 Return: -2.5910171910124404
INFO:tensorflow:Average training steps per second: 320.69
I0901 13:23:27.786943 140240877414400 replay_runner.py:36] Average training steps per second: 320.69
I0901 13:23:27.942640 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.61
INFO:tensorflow:Starting iteration 5

Steps executed: 216 Episode length: 100 Return: -258.03079187392794
INFO:tensorflow:Average training steps per second: 324.16
I0901 13:23:34.422835 140240877414400 replay_runner.py:36] Average training steps per second: 324.16
I0901 13:23:34.542223 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -240.55
INFO:tensorflow:Starting iteration 6

Steps executed: 138 Episode length: 138 Return: -183.61454068186436
INFO:tensorflow:Average training steps per second: 337.90

Steps executed: 485 Episode length: 347 Return: -92.895771268030176
I0901 13:23:41.496263 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.26
INFO:tensorflow:Starting iteration 7

Steps executed: 724 Episode length: 724 Return: 135.150058661003646
INFO:tensorflow:Average training steps per second: 333.31
I0901 13:23:48.008102 140240877414400 replay_runner.py:36] Average training steps per second: 333.31
I0901 13:23:49.068140 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: 135.15
INFO:tensorflow:Starting iteration 8

Steps executed: 222 Episode length: 71 Return: -185.736104474623754
INFO:tensorflow:Average training steps per second: 322.40
I0901 13:23:55.652834 140240877414400 replay_runner.py:36] Average training steps per second: 322.40
I0901 13:23:55.787105 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -182.06
INFO:tensorflow:Starting iteration 9

Steps executed: 501 Episode length: 501 Return: -192.23837976011646
INFO:tensorflow:Average training steps per second: 324.20
I0901 13:24:02.344607 140240877414400 replay_runner.py:36] Average training steps per second: 324.20
I0901 13:24:02.971754 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.24
INFO:tensorflow:Starting iteration 10
I0901 13:24:06.437068 140240877414400 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 324.05

Steps executed: 362 Episode length: 362 Return: -1050.5467891347736
I0901 13:24:09.902215 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -1050.55
INFO:tensorflow:Starting iteration 11

Steps executed: 557 Episode length: 557 Return: -412.29729419763237
INFO:tensorflow:Average training steps per second: 338.19
I0901 13:24:16.309601 140240877414400 replay_runner.py:36] Average training steps per second: 338.19
I0901 13:24:17.141775 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -412.30
INFO:tensorflow:Starting iteration 12

Steps executed: 333 Episode length: 333 Return: -277.07912160423643
INFO:tensorflow:Average training steps per second: 326.75
I0901 13:24:23.693467 140240877414400 replay_runner.py:36] Average training steps per second: 326.75
I0901 13:24:24.086982 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.08
INFO:tensorflow:Starting iteration 13

Steps executed: 239 Episode length: 239 Return: -445.11443025631644
INFO:tensorflow:Average training steps per second: 333.24
I0901 13:24:30.595271 140240877414400 replay_runner.py:36] Average training steps per second: 333.24
I0901 13:24:30.785002 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -445.11
INFO:tensorflow:Starting iteration 14
I0901 13:24:34.374433 140240877414400 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 336.95

Steps executed: 683 Episode length: 683 Return: -233.56973025468798
I0901 13:24:38.306815 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.57
INFO:tensorflow:Starting iteration 15

Steps executed: 269 Episode length: 269 Return: -194.00794585675878
INFO:tensorflow:Average training steps per second: 343.18
I0901 13:24:44.776238 140240877414400 replay_runner.py:36] Average training steps per second: 343.18
I0901 13:24:44.978941 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -194.01
INFO:tensorflow:Starting iteration 16

Steps executed: 243 Episode length: 116 Return: -770.40125008526938
INFO:tensorflow:Average training steps per second: 339.45
I0901 13:24:51.527182 140240877414400 replay_runner.py:36] Average training steps per second: 339.45
I0901 13:24:51.671463 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -457.55
INFO:tensorflow:Starting iteration 17

Steps executed: 262 Episode length: 138 Return: -793.94451070475078
INFO:tensorflow:Average training steps per second: 330.31
I0901 13:24:58.314398 140240877414400 replay_runner.py:36] Average training steps per second: 330.31
I0901 13:24:58.465405 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -568.04
INFO:tensorflow:Starting iteration 18

Steps executed: 247 Episode length: 65 Return: -161.575244255832628
INFO:tensorflow:Average training steps per second: 331.24
I0901 13:25:05.081636 140240877414400 replay_runner.py:36] Average training steps per second: 331.24
I0901 13:25:05.189745 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.49
INFO:tensorflow:Starting iteration 19

Steps executed: 124 Episode length: 124 Return: -350.72351174830146
INFO:tensorflow:Average training steps per second: 333.62
I0901 13:25:11.750646 140240877414400 replay_runner.py:36] Average training steps per second: 333.62

Steps executed: 224 Episode length: 100 Return: -315.97960886052426
INFO:tensorflow:Starting iteration 20

Steps executed: 278 Episode length: 138 Return: -66.878824922911438
INFO:tensorflow:Average training steps per second: 327.30
I0901 13:25:18.480917 140240877414400 replay_runner.py:36] Average training steps per second: 327.30
I0901 13:25:18.662466 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.92
INFO:tensorflow:Starting iteration 21

Steps executed: 203 Episode length: 137 Return: -430.11259275142168
INFO:tensorflow:Average training steps per second: 326.61
I0901 13:25:25.262032 140240877414400 replay_runner.py:36] Average training steps per second: 326.61
I0901 13:25:25.393537 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -473.68
INFO:tensorflow:Starting iteration 22

Steps executed: 239 Episode length: 77 Return: -492.926170454871268
INFO:tensorflow:Average training steps per second: 327.07
I0901 13:25:32.001957 140240877414400 replay_runner.py:36] Average training steps per second: 327.07
I0901 13:25:32.157561 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -569.61
INFO:tensorflow:Starting iteration 23

Steps executed: 303 Episode length: 113 Return: -382.19665000421423
INFO:tensorflow:Average training steps per second: 319.56
I0901 13:25:38.796334 140240877414400 replay_runner.py:36] Average training steps per second: 319.56
I0901 13:25:38.987074 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -239.31
INFO:tensorflow:Starting iteration 24
I0901 13:25:42.480833 140240877414400 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 318.90

Steps executed: 235 Episode length: 53 Return: -222.952684423354387
I0901 13:25:45.752930 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.58
INFO:tensorflow:Starting iteration 25

Steps executed: 227 Episode length: 115 Return: -275.13568646856976
INFO:tensorflow:Average training steps per second: 318.90
I0901 13:25:52.394090 140240877414400 replay_runner.py:36] Average training steps per second: 318.90
I0901 13:25:52.509919 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -241.36
INFO:tensorflow:Starting iteration 26

Steps executed: 210 Episode length: 70 Return: -189.678685505769986
INFO:tensorflow:Average training steps per second: 312.94
I0901 13:25:59.077820 140240877414400 replay_runner.py:36] Average training steps per second: 312.94
I0901 13:25:59.168097 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -238.44
INFO:tensorflow:Starting iteration 27
I0901 13:26:02.538994 140240877414400 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 307.16

Steps executed: 202 Episode length: 76 Return: -401.403927606977166
I0901 13:26:05.941370 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -671.78
INFO:tensorflow:Starting iteration 28

Steps executed: 543 Episode length: 391 Return: -107.62699198636928
INFO:tensorflow:Average training steps per second: 318.14
I0901 13:26:12.499924 140240877414400 replay_runner.py:36] Average training steps per second: 318.14
I0901 13:26:12.895899 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.60
INFO:tensorflow:Starting iteration 29

Steps executed: 202 Episode length: 107 Return: -474.00430010638878
INFO:tensorflow:Average training steps per second: 333.71
I0901 13:26:19.249398 140240877414400 replay_runner.py:36] Average training steps per second: 333.71

Done fixed training!Episode length: 107 Return: -474.00430010638878