Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0902 18:21:35.260748 140131099109376 run_experiment.py:549] Creating TrainRunner ...
I0902 18:21:35.270037 140131099109376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:21:35.270204 140131099109376 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:21:35.270321 140131099109376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:21:35.270419 140131099109376 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:21:35.270508 140131099109376 dqn_agent.py:275] 	 update_period: 4
I0902 18:21:35.270597 140131099109376 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:21:35.270712 140131099109376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:21:35.270850 140131099109376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:21:35.270962 140131099109376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:21:35.271111 140131099109376 dqn_agent.py:280] 	 optimizer: adam
I0902 18:21:35.271219 140131099109376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:21:35.271316 140131099109376 dqn_agent.py:283] 	 seed: 1630606895269994
I0902 18:21:35.273858 140131099109376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:21:35.274010 140131099109376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:21:35.274126 140131099109376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:21:35.274227 140131099109376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:21:35.274327 140131099109376 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:21:35.274421 140131099109376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:21:35.274524 140131099109376 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:21:35.274646 140131099109376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:21:35.274765 140131099109376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:21:35.309245 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:35.583282 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:35.592335 140131099109376 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:21:35.598702 140131099109376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:21:35.598824 140131099109376 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:21:35.598883 140131099109376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:21:35.598952 140131099109376 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:21:35.599001 140131099109376 dqn_agent.py:275] 	 update_period: 4
I0902 18:21:35.599079 140131099109376 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:21:35.599133 140131099109376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:21:35.599230 140131099109376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:21:35.599283 140131099109376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:21:35.599349 140131099109376 dqn_agent.py:280] 	 optimizer: adam
I0902 18:21:35.599423 140131099109376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:21:35.599484 140131099109376 dqn_agent.py:283] 	 seed: 1630606895598677
I0902 18:21:35.600946 140131099109376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:21:35.601063 140131099109376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:21:35.601136 140131099109376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:21:35.601208 140131099109376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:21:35.601307 140131099109376 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:21:35.601388 140131099109376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:21:35.601465 140131099109376 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:21:35.601552 140131099109376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:21:35.601627 140131099109376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:21:35.623869 140131099109376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000031
I0902 18:21:35.639350 140131099109376 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:21:35.639524 140131099109376 replay_runner.py:41] Starting iteration 0
Steps executed: 270 Episode length: 141 Return: -419.9839710975325
INFO:tensorflow:Average training steps per second: 242.36
I0902 18:21:39.765681 140131099109376 replay_runner.py:36] Average training steps per second: 242.36
I0902 18:21:40.509630 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.60
INFO:tensorflow:Starting iteration 1

Steps executed: 272 Episode length: 163 Return: -437.84986585588225
INFO:tensorflow:Average training steps per second: 367.26
I0902 18:21:46.506491 140131099109376 replay_runner.py:36] Average training steps per second: 367.26
I0902 18:21:46.655173 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.81
INFO:tensorflow:Starting iteration 2
I0902 18:21:49.981837 140131099109376 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 339.96

Steps executed: 308 Episode length: 133 Return: -372.62230071819954
I0902 18:21:53.082827 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -413.68
INFO:tensorflow:Starting iteration 3

Steps executed: 241 Episode length: 241 Return: -450.62393445627805
INFO:tensorflow:Average training steps per second: 331.87
I0902 18:21:59.397317 140131099109376 replay_runner.py:36] Average training steps per second: 331.87
I0902 18:21:59.557411 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -450.62
INFO:tensorflow:Starting iteration 4
I0902 18:22:02.911153 140131099109376 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 346.56

Steps executed: 1000 Episode length: 1000 Return: -109.9838009333197
I0902 18:22:08.471284 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.98
INFO:tensorflow:Starting iteration 5
I0902 18:22:11.795725 140131099109376 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 328.64

Steps executed: 1000 Episode length: 1000 Return: -110.60030604947903
I0902 18:22:16.819608 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.60
INFO:tensorflow:Starting iteration 6
I0902 18:22:20.147238 140131099109376 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 344.93

Steps executed: 1000 Episode length: 1000 Return: -147.08192893691103
I0902 18:22:24.834787 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.08
INFO:tensorflow:Starting iteration 7
I0902 18:22:28.157896 140131099109376 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 357.54

Steps executed: 1000 Episode length: 1000 Return: -110.58198112553572
I0902 18:22:33.586236 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.58
INFO:tensorflow:Starting iteration 8
I0902 18:22:36.885155 140131099109376 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 357.30

Steps executed: 1000 Episode length: 1000 Return: -113.35782693674699
I0902 18:22:41.440606 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.36
INFO:tensorflow:Starting iteration 9
I0902 18:22:44.764451 140131099109376 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 346.89

Steps executed: 1000 Episode length: 1000 Return: -74.452442390798989
I0902 18:22:50.276958 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.45
INFO:tensorflow:Starting iteration 10
I0902 18:22:53.661874 140131099109376 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 352.37

Steps executed: 1000 Episode length: 1000 Return: -195.24411221445226
I0902 18:22:58.154852 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.24
INFO:tensorflow:Starting iteration 11
I0902 18:23:01.570364 140131099109376 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 342.31

Steps executed: 960 Episode length: 960 Return: -616.6769207232394226
I0902 18:23:06.950154 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -616.68
INFO:tensorflow:Starting iteration 12

Steps executed: 74 Episode length: 74 Return: -264.871707208822694226
INFO:tensorflow:Average training steps per second: 336.83

Steps executed: 516 Episode length: 442 Return: -388.3825855956315526
I0902 18:23:13.874098 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.63
INFO:tensorflow:Starting iteration 13
I0902 18:23:17.292946 140131099109376 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 359.80

Steps executed: 1000 Episode length: 1000 Return: -174.82593494225102
I0902 18:23:21.905363 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.83
INFO:tensorflow:Starting iteration 14
I0902 18:23:25.376523 140131099109376 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 353.40

Steps executed: 1000 Episode length: 1000 Return: -77.195620274827052
I0902 18:23:29.607327 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.20
INFO:tensorflow:Starting iteration 15

Steps executed: 349 Episode length: 349 Return: -65.03975004368866052
INFO:tensorflow:Average training steps per second: 330.93
I0902 18:23:36.027911 140131099109376 replay_runner.py:36] Average training steps per second: 330.93
I0902 18:23:36.347224 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.04
INFO:tensorflow:Starting iteration 16

Steps executed: 485 Episode length: 485 Return: -290.5016081797896052
INFO:tensorflow:Average training steps per second: 328.16
I0902 18:23:42.641820 140131099109376 replay_runner.py:36] Average training steps per second: 328.16
I0902 18:23:43.373530 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.50
INFO:tensorflow:Starting iteration 17
I0902 18:23:46.611087 140131099109376 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 328.83

Steps executed: 467 Episode length: 467 Return: -75.92753778962178052
I0902 18:23:50.228142 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.93
INFO:tensorflow:Starting iteration 18

Steps executed: 284 Episode length: 284 Return: -32.83080027600684052
INFO:tensorflow:Average training steps per second: 333.37
I0902 18:23:56.453387 140131099109376 replay_runner.py:36] Average training steps per second: 333.37
I0902 18:23:56.730813 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -32.83
INFO:tensorflow:Starting iteration 19
I0902 18:24:00.080094 140131099109376 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 338.51
I0902 18:24:03.034506 140131099109376 replay_runner.py:36] Average training steps per second: 338.51

Steps executed: 253 Episode length: 253 Return: 0.5610205461346425052
INFO:tensorflow:Starting iteration 20
I0902 18:24:06.667740 140131099109376 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 352.19

Steps executed: 435 Episode length: 435 Return: -20.86247101200275752
I0902 18:24:10.075136 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -20.86
INFO:tensorflow:Starting iteration 21

Steps executed: 323 Episode length: 323 Return: 37.815153543460045752
INFO:tensorflow:Average training steps per second: 326.32
I0902 18:24:16.497210 140131099109376 replay_runner.py:36] Average training steps per second: 326.32
I0902 18:24:16.837617 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: 37.82
INFO:tensorflow:Starting iteration 22
I0902 18:24:20.087490 140131099109376 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 311.36

Steps executed: 603 Episode length: 603 Return: -607.6840982191455752
I0902 18:24:24.358429 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -607.68
INFO:tensorflow:Starting iteration 23
I0902 18:24:27.486978 140131099109376 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 316.92

Steps executed: 1000 Episode length: 1000 Return: -10.834458635693776
I0902 18:24:33.890989 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -10.83
INFO:tensorflow:Starting iteration 24

Steps executed: 215 Episode length: 215 Return: -122.6524297068453476
INFO:tensorflow:Average training steps per second: 354.94
I0902 18:24:40.215242 140131099109376 replay_runner.py:36] Average training steps per second: 354.94
I0902 18:24:40.341072 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.65
INFO:tensorflow:Starting iteration 25
I0902 18:24:43.660443 140131099109376 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 312.33
I0902 18:24:46.862595 140131099109376 replay_runner.py:36] Average training steps per second: 312.33

Steps executed: 529 Episode length: 529 Return: -107.7554355995299676
INFO:tensorflow:Starting iteration 26
I0902 18:24:50.698909 140131099109376 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 322.71

Steps executed: 1000 Episode length: 1000 Return: -106.18462025106784
I0902 18:24:55.749063 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.18
INFO:tensorflow:Starting iteration 27

Steps executed: 428 Episode length: 428 Return: -42.25203387205393784
INFO:tensorflow:Average training steps per second: 326.15
I0902 18:25:01.950831 140131099109376 replay_runner.py:36] Average training steps per second: 326.15
I0902 18:25:02.350114 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -42.25
INFO:tensorflow:Starting iteration 28

Steps executed: 283 Episode length: 134 Return: 55.479448552640152784
INFO:tensorflow:Average training steps per second: 338.48
I0902 18:25:08.362871 140131099109376 replay_runner.py:36] Average training steps per second: 338.48
I0902 18:25:08.508544 140131099109376 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.89
INFO:tensorflow:Starting iteration 29

Steps executed: 227 Episode length: 76 Return: -396.23300430872332784
INFO:tensorflow:Average training steps per second: 343.00
I0902 18:25:14.442323 140131099109376 replay_runner.py:36] Average training steps per second: 343.00

Done fixed training!Episode length: 76 Return: -396.23300430872332784