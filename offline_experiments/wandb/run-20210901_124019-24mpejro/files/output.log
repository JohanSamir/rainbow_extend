Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0901 12:40:26.508044 140240877414400 run_experiment.py:549] Creating TrainRunner ...
I0901 12:40:26.518336 140240877414400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:40:26.518546 140240877414400 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:40:26.518645 140240877414400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:40:26.518727 140240877414400 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:40:26.518806 140240877414400 dqn_agent.py:275] 	 update_period: 4
I0901 12:40:26.518960 140240877414400 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:40:26.519106 140240877414400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:40:26.519182 140240877414400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:40:26.519299 140240877414400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:40:26.519394 140240877414400 dqn_agent.py:280] 	 optimizer: adam
I0901 12:40:26.519482 140240877414400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:40:26.519575 140240877414400 dqn_agent.py:283] 	 seed: 1630500026518280
I0901 12:40:26.522294 140240877414400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:40:26.522461 140240877414400 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:40:26.522553 140240877414400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:40:26.522617 140240877414400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:40:26.522675 140240877414400 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:40:26.522789 140240877414400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:40:26.522981 140240877414400 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:40:26.523265 140240877414400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:40:26.523382 140240877414400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:40:26.597200 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:40:26.979121 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:40:26.992999 140240877414400 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:40:27.023935 140240877414400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:40:27.024329 140240877414400 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:40:27.024441 140240877414400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:40:27.024524 140240877414400 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:40:27.024599 140240877414400 dqn_agent.py:275] 	 update_period: 4
I0901 12:40:27.024672 140240877414400 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:40:27.024871 140240877414400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:40:27.024940 140240877414400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:40:27.025013 140240877414400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:40:27.025084 140240877414400 dqn_agent.py:280] 	 optimizer: adam
I0901 12:40:27.025157 140240877414400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:40:27.025228 140240877414400 dqn_agent.py:283] 	 seed: 1630500027023862
I0901 12:40:27.027488 140240877414400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:40:27.027676 140240877414400 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:40:27.027977 140240877414400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:40:27.028139 140240877414400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:40:27.028238 140240877414400 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:40:27.028337 140240877414400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:40:27.028591 140240877414400 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:40:27.028815 140240877414400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:40:27.028944 140240877414400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:40:27.063809 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:40:27.089644 140240877414400 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:40:27.090077 140240877414400 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 157.57
I0901 12:40:33.436686 140240877414400 replay_runner.py:36] Average training steps per second: 157.57
Steps executed: 256 Episode length: 144 Return: -162.94496030910074
I0901 12:40:34.678400 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.44
INFO:tensorflow:Starting iteration 1

Steps executed: 255 Episode length: 98 Return: -177.766714813759964
INFO:tensorflow:Average training steps per second: 216.18
I0901 12:40:43.809128 140240877414400 replay_runner.py:36] Average training steps per second: 216.18
I0901 12:40:44.034708 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.74
INFO:tensorflow:Starting iteration 2

Steps executed: 236 Episode length: 119 Return: -271.50423716150735
INFO:tensorflow:Average training steps per second: 217.29
I0901 12:40:52.925722 140240877414400 replay_runner.py:36] Average training steps per second: 217.29
I0901 12:40:53.138257 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.60
INFO:tensorflow:Starting iteration 3

Steps executed: 248 Episode length: 160 Return: -548.68274662738535
INFO:tensorflow:Average training steps per second: 220.68
I0901 12:41:01.902744 140240877414400 replay_runner.py:36] Average training steps per second: 220.68
I0901 12:41:02.125980 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -529.00
INFO:tensorflow:Starting iteration 4

Steps executed: 204 Episode length: 130 Return: -278.86435718078354
INFO:tensorflow:Average training steps per second: 214.78
I0901 12:41:11.083365 140240877414400 replay_runner.py:36] Average training steps per second: 214.78
I0901 12:41:11.255089 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -299.21
INFO:tensorflow:Starting iteration 5
I0901 12:41:15.640030 140240877414400 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 217.93

Steps executed: 253 Episode length: 104 Return: -207.27676714255534
I0901 12:41:20.458067 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.29
INFO:tensorflow:Starting iteration 6

Steps executed: 238 Episode length: 80 Return: -49.3687490435586534
INFO:tensorflow:Average training steps per second: 220.32
I0901 12:41:29.287184 140240877414400 replay_runner.py:36] Average training steps per second: 220.32
I0901 12:41:29.485043 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.01
INFO:tensorflow:Starting iteration 7

Steps executed: 223 Episode length: 78 Return: -243.729521456962524
INFO:tensorflow:Average training steps per second: 215.29
I0901 12:41:38.608345 140240877414400 replay_runner.py:36] Average training steps per second: 215.29
I0901 12:41:38.850186 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -291.54
INFO:tensorflow:Starting iteration 8

Steps executed: 264 Episode length: 264 Return: -281.14212744343484
INFO:tensorflow:Average training steps per second: 214.53
I0901 12:41:47.941474 140240877414400 replay_runner.py:36] Average training steps per second: 214.53
I0901 12:41:48.279893 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.14
INFO:tensorflow:Starting iteration 9

Steps executed: 267 Episode length: 162 Return: -174.19341937502378
INFO:tensorflow:Average training steps per second: 211.89
I0901 12:41:57.305226 140240877414400 replay_runner.py:36] Average training steps per second: 211.89
I0901 12:41:57.568753 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.46
INFO:tensorflow:Starting iteration 10

Steps executed: 215 Episode length: 118 Return: 14.3642889024663678
INFO:tensorflow:Average training steps per second: 213.01
I0901 12:42:06.673754 140240877414400 replay_runner.py:36] Average training steps per second: 213.01
I0901 12:42:06.858199 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.63
INFO:tensorflow:Starting iteration 11

Steps executed: 272 Episode length: 80 Return: -259.701106038881167
INFO:tensorflow:Average training steps per second: 211.50
I0901 12:42:16.008896 140240877414400 replay_runner.py:36] Average training steps per second: 211.50
I0901 12:42:16.256859 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.10
INFO:tensorflow:Starting iteration 12

Steps executed: 231 Episode length: 83 Return: -191.183067862533177
INFO:tensorflow:Average training steps per second: 210.94
I0901 12:42:25.405523 140240877414400 replay_runner.py:36] Average training steps per second: 210.94
I0901 12:42:25.583109 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.92
INFO:tensorflow:Starting iteration 13
I0901 12:42:30.017432 140240877414400 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 214.08

Steps executed: 275 Episode length: 275 Return: -33.276671644302657
I0901 12:42:35.065910 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -33.28
INFO:tensorflow:Starting iteration 14

Steps executed: 328 Episode length: 328 Return: -261.66224736299177
INFO:tensorflow:Average training steps per second: 213.55
I0901 12:42:44.159268 140240877414400 replay_runner.py:36] Average training steps per second: 213.55
I0901 12:42:44.586736 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.66
INFO:tensorflow:Starting iteration 15

Steps executed: 223 Episode length: 69 Return: -103.565003484848197
INFO:tensorflow:Average training steps per second: 221.45
I0901 12:42:53.541345 140240877414400 replay_runner.py:36] Average training steps per second: 221.45
I0901 12:42:53.814222 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.65
INFO:tensorflow:Starting iteration 16
I0901 12:42:58.276045 140240877414400 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 221.19

Steps executed: 270 Episode length: 145 Return: -247.82115102668706
I0901 12:43:03.050015 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.51
INFO:tensorflow:Starting iteration 17

Steps executed: 218 Episode length: 146 Return: -500.72040433710186
INFO:tensorflow:Average training steps per second: 219.09
I0901 12:43:12.054224 140240877414400 replay_runner.py:36] Average training steps per second: 219.09
I0901 12:43:12.244967 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.96
INFO:tensorflow:Starting iteration 18

Steps executed: 295 Episode length: 174 Return: -507.69338571704395
INFO:tensorflow:Average training steps per second: 228.93
I0901 12:43:21.053017 140240877414400 replay_runner.py:36] Average training steps per second: 228.93
I0901 12:43:21.309823 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -339.82
INFO:tensorflow:Starting iteration 19

Steps executed: 147 Episode length: 147 Return: -670.03314655987055
INFO:tensorflow:Average training steps per second: 217.98
I0901 12:43:30.271005 140240877414400 replay_runner.py:36] Average training steps per second: 217.98

Steps executed: 319 Episode length: 172 Return: -555.23941462092155
INFO:tensorflow:Starting iteration 20

Steps executed: 238 Episode length: 74 Return: -27.0935396586423855
INFO:tensorflow:Average training steps per second: 220.12
I0901 12:43:39.596977 140240877414400 replay_runner.py:36] Average training steps per second: 220.12
I0901 12:43:39.794185 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.38
INFO:tensorflow:Starting iteration 21
I0901 12:43:44.162571 140240877414400 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 215.22
I0901 12:43:48.809647 140240877414400 replay_runner.py:36] Average training steps per second: 215.22

Steps executed: 208 Episode length: 75 Return: -585.627836400174855
INFO:tensorflow:Starting iteration 22

Steps executed: 219 Episode length: 71 Return: -659.170345531984655
INFO:tensorflow:Average training steps per second: 215.02
I0901 12:43:58.110144 140240877414400 replay_runner.py:36] Average training steps per second: 215.02
I0901 12:43:58.315336 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -622.60
INFO:tensorflow:Starting iteration 23

Steps executed: 254 Episode length: 65 Return: -513.546114520282175
INFO:tensorflow:Average training steps per second: 218.14
I0901 12:44:07.340677 140240877414400 replay_runner.py:36] Average training steps per second: 218.14
I0901 12:44:07.571079 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -519.00
INFO:tensorflow:Starting iteration 24

Steps executed: 202 Episode length: 73 Return: -489.787291409199275
INFO:tensorflow:Average training steps per second: 224.45
I0901 12:44:16.499510 140240877414400 replay_runner.py:36] Average training steps per second: 224.45
I0901 12:44:16.676734 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -524.20
INFO:tensorflow:Starting iteration 25

Steps executed: 235 Episode length: 57 Return: -268.586564710407245
INFO:tensorflow:Average training steps per second: 221.44
I0901 12:44:25.588740 140240877414400 replay_runner.py:36] Average training steps per second: 221.44
I0901 12:44:25.765857 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.57
INFO:tensorflow:Starting iteration 26

Steps executed: 219 Episode length: 87 Return: -357.369503153183925
INFO:tensorflow:Average training steps per second: 215.05
I0901 12:44:34.950261 140240877414400 replay_runner.py:36] Average training steps per second: 215.05
I0901 12:44:35.147127 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -416.69
INFO:tensorflow:Starting iteration 27

Steps executed: 236 Episode length: 72 Return: -480.787676747703545
INFO:tensorflow:Average training steps per second: 220.60
I0901 12:44:44.115398 140240877414400 replay_runner.py:36] Average training steps per second: 220.60
I0901 12:44:44.330909 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -410.69
INFO:tensorflow:Starting iteration 28

Steps executed: 227 Episode length: 80 Return: -472.770443953122145
INFO:tensorflow:Average training steps per second: 216.04
I0901 12:44:53.413671 140240877414400 replay_runner.py:36] Average training steps per second: 216.04
I0901 12:44:53.640800 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -415.39
INFO:tensorflow:Starting iteration 29

Steps executed: 195 Episode length: 63 Return: -352.709549224423145
INFO:tensorflow:Average training steps per second: 211.35

Steps executed: 281 Episode length: 86 Return: -740.517601403737645

Done fixed training!Episode length: 86 Return: -740.517601403737645