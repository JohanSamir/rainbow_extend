I0901 23:49:31.937981 139965167532032 run_experiment.py:549] Creating TrainRunner ...
I0901 23:49:31.949166 139965167532032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:31.949421 139965167532032 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:31.949529 139965167532032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:31.949627 139965167532032 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:31.949755 139965167532032 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:31.949869 139965167532032 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:31.949992 139965167532032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:31.950158 139965167532032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:31.950267 139965167532032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:31.950379 139965167532032 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:31.950514 139965167532032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:31.950654 139965167532032 dqn_agent.py:283] 	 seed: 1630540171949094
I0901 23:49:31.954544 139965167532032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:31.954772 139965167532032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:31.954934 139965167532032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:31.955078 139965167532032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:31.955228 139965167532032 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:31.955338 139965167532032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:31.955449 139965167532032 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:31.955731 139965167532032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:31.955939 139965167532032 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0901 23:49:33.735560 139965167532032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:34.139803 139965167532032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:34.154471 139965167532032 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:49:34.162542 139965167532032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:49:34.162875 139965167532032 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:49:34.163095 139965167532032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:49:34.163246 139965167532032 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:49:34.163394 139965167532032 dqn_agent.py:275] 	 update_period: 4
I0901 23:49:34.163502 139965167532032 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:49:34.163587 139965167532032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:49:34.163699 139965167532032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:49:34.163796 139965167532032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:49:34.163900 139965167532032 dqn_agent.py:280] 	 optimizer: adam
I0901 23:49:34.164161 139965167532032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:49:34.164372 139965167532032 dqn_agent.py:283] 	 seed: 1630540174162479
I0901 23:49:34.167577 139965167532032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:49:34.167782 139965167532032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:49:34.167922 139965167532032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:49:34.168097 139965167532032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:49:34.168245 139965167532032 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:49:34.168471 139965167532032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:49:34.168747 139965167532032 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:49:34.168918 139965167532032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:49:34.169080 139965167532032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:49:34.199163 139965167532032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:49:34.222028 139965167532032 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:49:34.222527 139965167532032 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 161.94
I0901 23:49:40.397806 139965167532032 replay_runner.py:36] Average training steps per second: 161.94
Steps executed: 308 Episode length: 135 Return: -259.1232399244592
I0901 23:49:41.706131 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.63
INFO:tensorflow:Starting iteration 1

Steps executed: 326 Episode length: 182 Return: -423.3334201994959
INFO:tensorflow:Average training steps per second: 224.01
I0901 23:49:50.550167 139965167532032 replay_runner.py:36] Average training steps per second: 224.01
I0901 23:49:50.858341 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -411.84
INFO:tensorflow:Starting iteration 2
I0901 23:49:55.121160 139965167532032 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 228.14

Steps executed: 294 Episode length: 144 Return: -203.09155869561735
I0901 23:49:59.766068 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.08
INFO:tensorflow:Starting iteration 3
I0901 23:50:04.153708 139965167532032 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 230.22

Steps executed: 1000 Episode length: 1000 Return: -131.236803924175
I0901 23:50:11.211925 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.24
INFO:tensorflow:Starting iteration 4
I0901 23:50:15.575801 139965167532032 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 229.26

Steps executed: 1000 Episode length: 1000 Return: -184.18887538040588
I0901 23:50:24.606185 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.19
INFO:tensorflow:Starting iteration 5
I0901 23:50:28.831015 139965167532032 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 236.44

Steps executed: 725 Episode length: 725 Return: -614.7282064032164588
I0901 23:50:34.484927 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -614.73
INFO:tensorflow:Starting iteration 6
I0901 23:50:38.694421 139965167532032 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 246.36

Steps executed: 1000 Episode length: 1000 Return: -338.89549641091778
I0901 23:50:45.142283 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.90
INFO:tensorflow:Starting iteration 7
I0901 23:50:49.496824 139965167532032 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 244.92

Steps executed: 661 Episode length: 661 Return: -805.5118360157945778
I0901 23:50:55.041929 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -805.51
INFO:tensorflow:Starting iteration 8
I0901 23:50:59.342869 139965167532032 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 239.21

Steps executed: 1000 Episode length: 1000 Return: -179.02025254536449
I0901 23:51:05.759745 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.02
INFO:tensorflow:Starting iteration 9

Steps executed: 239 Episode length: 239 Return: -349.4414067285428649
INFO:tensorflow:Average training steps per second: 230.19
I0901 23:51:14.567921 139965167532032 replay_runner.py:36] Average training steps per second: 230.19
I0901 23:51:14.828932 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -349.44
INFO:tensorflow:Starting iteration 10
I0901 23:51:19.211267 139965167532032 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 222.92

Steps executed: 521 Episode length: 521 Return: -1366.659858006427449
I0901 23:51:24.737062 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -1366.66
INFO:tensorflow:Starting iteration 11
I0901 23:51:29.020974 139965167532032 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 224.59

Steps executed: 1000 Episode length: 1000 Return: -273.90254302272194
I0901 23:51:36.380855 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.90
INFO:tensorflow:Starting iteration 12
I0901 23:51:40.783375 139965167532032 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 228.01

Steps executed: 1000 Episode length: 1000 Return: -230.21801310528875
I0901 23:51:48.690355 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.22
INFO:tensorflow:Starting iteration 13
I0901 23:51:53.035423 139965167532032 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 224.60

Steps executed: 1000 Episode length: 1000 Return: -90.508407905508015
I0901 23:52:01.107312 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.51
INFO:tensorflow:Starting iteration 14
I0901 23:52:05.443067 139965167532032 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 226.20

Steps executed: 1000 Episode length: 1000 Return: -121.13543846910069
I0901 23:52:13.527322 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.14
INFO:tensorflow:Starting iteration 15
I0901 23:52:17.841628 139965167532032 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 221.47

Steps executed: 457 Episode length: 457 Return: -375.5648176896817069
I0901 23:52:23.256542 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -375.56
INFO:tensorflow:Starting iteration 16
I0901 23:52:27.742317 139965167532032 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 222.06

Steps executed: 1000 Episode length: 1000 Return: -9.8613395156650699
I0901 23:52:35.250445 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -9.86
INFO:tensorflow:Starting iteration 17
I0901 23:52:39.590264 139965167532032 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 221.85

Steps executed: 516 Episode length: 391 Return: -139.6224132630426799
I0901 23:52:44.895096 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.76
INFO:tensorflow:Starting iteration 18
I0901 23:52:49.254902 139965167532032 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 236.40
I0901 23:52:53.485550 139965167532032 replay_runner.py:36] Average training steps per second: 236.40

Steps executed: 399 Episode length: 399 Return: -66.79029981535018799
INFO:tensorflow:Starting iteration 19
I0901 23:52:58.390490 139965167532032 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 235.86

Steps executed: 1000 Episode length: 1000 Return: -87.490744802229249
I0901 23:53:05.585593 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.49
INFO:tensorflow:Starting iteration 20
I0901 23:53:09.978637 139965167532032 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 234.20
I0901 23:53:14.249115 139965167532032 replay_runner.py:36] Average training steps per second: 234.20

Steps executed: 224 Episode length: 224 Return: -448.4376938522155249
INFO:tensorflow:Starting iteration 21

Steps executed: 261 Episode length: 261 Return: 227.58536788435944249
INFO:tensorflow:Average training steps per second: 231.67
I0901 23:53:23.280853 139965167532032 replay_runner.py:36] Average training steps per second: 231.67
I0901 23:53:23.668524 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: 227.59
INFO:tensorflow:Starting iteration 22
I0901 23:53:28.172269 139965167532032 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 238.13

Steps executed: 1000 Episode length: 1000 Return: -330.71159263956099
I0901 23:53:35.285511 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -330.71
INFO:tensorflow:Starting iteration 23
I0901 23:53:39.584002 139965167532032 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 238.03

Steps executed: 1000 Episode length: 1000 Return: -65.985878809757499
I0901 23:53:47.898728 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.99
INFO:tensorflow:Starting iteration 24

Steps executed: 396 Episode length: 396 Return: -720.7251667091965499
INFO:tensorflow:Average training steps per second: 233.98
I0901 23:53:56.502054 139965167532032 replay_runner.py:36] Average training steps per second: 233.98
I0901 23:53:57.093821 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -720.73
INFO:tensorflow:Starting iteration 25

Steps executed: 274 Episode length: 274 Return: -81.72167490650835499
INFO:tensorflow:Average training steps per second: 231.88
I0901 23:54:05.669829 139965167532032 replay_runner.py:36] Average training steps per second: 231.88
I0901 23:54:06.005143 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.72
INFO:tensorflow:Starting iteration 26

Steps executed: 580 Episode length: 426 Return: -173.7185665644933399
INFO:tensorflow:Average training steps per second: 226.98
I0901 23:54:14.756640 139965167532032 replay_runner.py:36] Average training steps per second: 226.98
I0901 23:54:15.618193 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -289.83
INFO:tensorflow:Starting iteration 27

Steps executed: 92 Episode length: 92 Return: -937.365162103606333399
INFO:tensorflow:Average training steps per second: 222.69

Steps executed: 599 Episode length: 507 Return: -92.54267140928181399
I0901 23:54:25.673235 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -514.95
INFO:tensorflow:Starting iteration 28
I0901 23:54:30.057156 139965167532032 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 226.94

Steps executed: 203 Episode length: 75 Return: -563.21241209534942399
I0901 23:54:34.641826 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -669.85
INFO:tensorflow:Starting iteration 29

Steps executed: 224 Episode length: 120 Return: -714.9408429027602399
INFO:tensorflow:Average training steps per second: 230.42
I0901 23:54:43.411442 139965167532032 replay_runner.py:36] Average training steps per second: 230.42

Done fixed training!Episode length: 120 Return: -714.9408429027602399