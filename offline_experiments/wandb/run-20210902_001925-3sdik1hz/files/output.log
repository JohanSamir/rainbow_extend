Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0902 00:19:30.971277 139965167532032 run_experiment.py:549] Creating TrainRunner ...
I0902 00:19:30.979633 139965167532032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:19:30.979763 139965167532032 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:19:30.979816 139965167532032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:19:30.979908 139965167532032 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:19:30.979955 139965167532032 dqn_agent.py:275] 	 update_period: 4
I0902 00:19:30.980006 139965167532032 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:19:30.980055 139965167532032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:19:30.980107 139965167532032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:19:30.980182 139965167532032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:19:30.980294 139965167532032 dqn_agent.py:280] 	 optimizer: adam
I0902 00:19:30.980356 139965167532032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:19:30.980425 139965167532032 dqn_agent.py:283] 	 seed: 1630541970979598
I0902 00:19:30.982526 139965167532032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:19:30.982650 139965167532032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:19:30.982731 139965167532032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:19:30.982821 139965167532032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:19:30.982943 139965167532032 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:19:30.983037 139965167532032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:19:30.983114 139965167532032 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:19:30.983190 139965167532032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:19:30.983270 139965167532032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:19:31.008630 139965167532032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:31.253295 139965167532032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:31.261971 139965167532032 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:19:31.268644 139965167532032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:19:31.268778 139965167532032 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:19:31.268851 139965167532032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:19:31.268914 139965167532032 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:19:31.268971 139965167532032 dqn_agent.py:275] 	 update_period: 4
I0902 00:19:31.269049 139965167532032 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:19:31.269143 139965167532032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:19:31.269231 139965167532032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:19:31.269330 139965167532032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:19:31.269408 139965167532032 dqn_agent.py:280] 	 optimizer: adam
I0902 00:19:31.269477 139965167532032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:19:31.269562 139965167532032 dqn_agent.py:283] 	 seed: 1630541971268610
I0902 00:19:31.271028 139965167532032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:19:31.271139 139965167532032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:19:31.271213 139965167532032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:19:31.271280 139965167532032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:19:31.271346 139965167532032 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:19:31.271451 139965167532032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:19:31.271533 139965167532032 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:19:31.271618 139965167532032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:19:31.271708 139965167532032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:19:31.291525 139965167532032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:31.306390 139965167532032 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:19:31.306606 139965167532032 replay_runner.py:41] Starting iteration 0
Steps executed: 258 Episode length: 152 Return: -287.95803436394465
INFO:tensorflow:Average training steps per second: 241.03
I0902 00:19:35.455667 139965167532032 replay_runner.py:36] Average training steps per second: 241.03
I0902 00:19:36.207830 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.75
INFO:tensorflow:Starting iteration 1

Steps executed: 275 Episode length: 116 Return: -351.05037202971903
INFO:tensorflow:Average training steps per second: 351.90
I0902 00:19:42.345578 139965167532032 replay_runner.py:36] Average training steps per second: 351.90
I0902 00:19:42.491517 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -372.30
INFO:tensorflow:Starting iteration 2

Steps executed: 200 Episode length: 200 Return: -167.59720801445116
INFO:tensorflow:Average training steps per second: 353.66
I0902 00:19:48.352312 139965167532032 replay_runner.py:36] Average training steps per second: 353.66
I0902 00:19:48.520754 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.60
INFO:tensorflow:Starting iteration 3

Steps executed: 289 Episode length: 119 Return: -355.91347352565606
INFO:tensorflow:Average training steps per second: 343.76
I0902 00:19:54.789253 139965167532032 replay_runner.py:36] Average training steps per second: 343.76
I0902 00:19:54.957819 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.05
INFO:tensorflow:Starting iteration 4
I0902 00:19:58.368909 139965167532032 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 346.32

Steps executed: 1000 Episode length: 1000 Return: -151.47431075410032
I0902 00:20:03.199253 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.47
INFO:tensorflow:Starting iteration 5
I0902 00:20:06.622303 139965167532032 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 360.47

Steps executed: 1000 Episode length: 1000 Return: -165.93685597241065
I0902 00:20:11.659061 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.94
INFO:tensorflow:Starting iteration 6
I0902 00:20:15.066040 139965167532032 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 352.78

Steps executed: 1000 Episode length: 1000 Return: -134.43366084354378
I0902 00:20:19.709374 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.43
INFO:tensorflow:Starting iteration 7
I0902 00:20:23.115100 139965167532032 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 355.68

Steps executed: 1000 Episode length: 1000 Return: -1076.9924901420916
I0902 00:20:27.366095 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -1076.99
INFO:tensorflow:Starting iteration 8
I0902 00:20:30.757419 139965167532032 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 338.01

Steps executed: 1000 Episode length: 1000 Return: -124.10345179739394
I0902 00:20:35.104199 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.10
INFO:tensorflow:Starting iteration 9

Steps executed: 889 Episode length: 726 Return: -334.4466355944159794
INFO:tensorflow:Average training steps per second: 330.54
I0902 00:20:41.450930 139965167532032 replay_runner.py:36] Average training steps per second: 330.54
I0902 00:20:42.282006 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -281.22
INFO:tensorflow:Starting iteration 10
I0902 00:20:45.502274 139965167532032 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 317.60

Steps executed: 965 Episode length: 965 Return: -356.2753626407215494
I0902 00:20:50.832846 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -356.28
INFO:tensorflow:Starting iteration 11

Steps executed: 1000 Episode length: 1000 Return: -94.119222300724134
INFO:tensorflow:Average training steps per second: 337.69
I0902 00:20:57.178909 139965167532032 replay_runner.py:36] Average training steps per second: 337.69
I0902 00:20:58.426713 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.12
INFO:tensorflow:Starting iteration 12

Steps executed: 219 Episode length: 219 Return: -1021.961373003227834
INFO:tensorflow:Average training steps per second: 328.51
I0902 00:21:04.695046 139965167532032 replay_runner.py:36] Average training steps per second: 328.51
I0902 00:21:04.854393 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -1021.96
INFO:tensorflow:Starting iteration 13
I0902 00:21:08.045167 139965167532032 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 328.22

Steps executed: 1000 Episode length: 1000 Return: -121.41966114963971
I0902 00:21:13.485154 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.42
INFO:tensorflow:Starting iteration 14
I0902 00:21:16.758243 139965167532032 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 327.80

Steps executed: 1000 Episode length: 1000 Return: -75.820959088733371
I0902 00:21:21.563804 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.82
INFO:tensorflow:Starting iteration 15

Steps executed: 284 Episode length: 145 Return: -324.0236235386509571
INFO:tensorflow:Average training steps per second: 327.15
I0902 00:21:27.843707 139965167532032 replay_runner.py:36] Average training steps per second: 327.15
I0902 00:21:27.993980 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.27
INFO:tensorflow:Starting iteration 16

Steps executed: 597 Episode length: 597 Return: -375.5242414462657571
INFO:tensorflow:Average training steps per second: 319.51
I0902 00:21:34.262662 139965167532032 replay_runner.py:36] Average training steps per second: 319.51
I0902 00:21:35.177876 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -375.52
INFO:tensorflow:Starting iteration 17

Steps executed: 464 Episode length: 464 Return: -34.78175571926016571
INFO:tensorflow:Average training steps per second: 336.80
I0902 00:21:41.460434 139965167532032 replay_runner.py:36] Average training steps per second: 336.80
I0902 00:21:42.062163 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -34.78
INFO:tensorflow:Starting iteration 18
I0902 00:21:45.430006 139965167532032 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 337.55

Steps executed: 1000 Episode length: 1000 Return: -75.978831603838861
I0902 00:21:50.210750 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.98
INFO:tensorflow:Starting iteration 19
I0902 00:21:53.614137 139965167532032 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 337.91

Steps executed: 646 Episode length: 646 Return: -65.69096078615777861
I0902 00:21:57.485525 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.69
INFO:tensorflow:Starting iteration 20

Steps executed: 374 Episode length: 256 Return: -63.71561711680863861
INFO:tensorflow:Average training steps per second: 338.01
I0902 00:22:03.803558 139965167532032 replay_runner.py:36] Average training steps per second: 338.01
I0902 00:22:04.106333 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -411.37
INFO:tensorflow:Starting iteration 21

Steps executed: 262 Episode length: 262 Return: -159.6904717534677861
INFO:tensorflow:Average training steps per second: 335.68
I0902 00:22:10.409384 139965167532032 replay_runner.py:36] Average training steps per second: 335.68
I0902 00:22:10.612820 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.69
INFO:tensorflow:Starting iteration 22
I0902 00:22:13.916682 139965167532032 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 327.13
I0902 00:22:16.973904 139965167532032 replay_runner.py:36] Average training steps per second: 327.13

Steps executed: 267 Episode length: 151 Return: -57.29250066578842361
INFO:tensorflow:Starting iteration 23

Steps executed: 521 Episode length: 521 Return: -35.98116760994192361
INFO:tensorflow:Average training steps per second: 332.47
I0902 00:22:23.406883 139965167532032 replay_runner.py:36] Average training steps per second: 332.47
I0902 00:22:24.199193 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -35.98
INFO:tensorflow:Starting iteration 24

Steps executed: 344 Episode length: 344 Return: -99.66307007380918361
INFO:tensorflow:Average training steps per second: 335.17
I0902 00:22:30.542515 139965167532032 replay_runner.py:36] Average training steps per second: 335.17
I0902 00:22:30.940082 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.66
INFO:tensorflow:Starting iteration 25
I0902 00:22:34.343520 139965167532032 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 337.66

Steps executed: 341 Episode length: 341 Return: -364.4082893779927361
I0902 00:22:37.607433 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.41
INFO:tensorflow:Starting iteration 26

Steps executed: 258 Episode length: 258 Return: -417.4465737002900661
INFO:tensorflow:Average training steps per second: 342.45
I0902 00:22:43.912533 139965167532032 replay_runner.py:36] Average training steps per second: 342.45
I0902 00:22:44.097339 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -417.45
INFO:tensorflow:Starting iteration 27

Steps executed: 370 Episode length: 370 Return: -507.4487055855876661
INFO:tensorflow:Average training steps per second: 342.83
I0902 00:22:50.389691 139965167532032 replay_runner.py:36] Average training steps per second: 342.83
I0902 00:22:50.788608 139965167532032 run_experiment.py:428] Average undiscounted return per evaluation episode: -507.45
INFO:tensorflow:Starting iteration 28

Steps executed: 137 Episode length: 137 Return: -126.9391457406043261
INFO:tensorflow:Average training steps per second: 329.46
I0902 00:22:57.134319 139965167532032 replay_runner.py:36] Average training steps per second: 329.46

Steps executed: 257 Episode length: 120 Return: -104.8919947678697861
INFO:tensorflow:Starting iteration 29

Steps executed: 747 Episode length: 747 Return: -495.6234020315667861
INFO:tensorflow:Average training steps per second: 351.41
I0902 00:23:03.486822 139965167532032 replay_runner.py:36] Average training steps per second: 351.41

Done fixed training!Episode length: 747 Return: -495.6234020315667861