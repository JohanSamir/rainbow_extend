Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0828 10:46:54.234432 140618562066432 run_experiment.py:549] Creating TrainRunner ...
I0828 10:46:54.242052 140618562066432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:46:54.242206 140618562066432 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:46:54.242282 140618562066432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:46:54.242344 140618562066432 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:46:54.242408 140618562066432 dqn_agent.py:275] 	 update_period: 4
I0828 10:46:54.242486 140618562066432 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:46:54.242586 140618562066432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:46:54.242655 140618562066432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:46:54.242719 140618562066432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:46:54.242795 140618562066432 dqn_agent.py:280] 	 optimizer: adam
I0828 10:46:54.242875 140618562066432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:46:54.242942 140618562066432 dqn_agent.py:283] 	 seed: 1630147614242020
I0828 10:46:54.244607 140618562066432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:46:54.244725 140618562066432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:46:54.244801 140618562066432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:46:54.244867 140618562066432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:46:54.244926 140618562066432 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:46:54.244984 140618562066432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:46:54.245055 140618562066432 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:46:54.245109 140618562066432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:46:54.245186 140618562066432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:46:54.270259 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:54.512087 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:54.521840 140618562066432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:46:54.528955 140618562066432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:46:54.529176 140618562066432 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:46:54.529318 140618562066432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:46:54.529459 140618562066432 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:46:54.529579 140618562066432 dqn_agent.py:275] 	 update_period: 4
I0828 10:46:54.529885 140618562066432 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:46:54.529994 140618562066432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:46:54.530072 140618562066432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:46:54.530164 140618562066432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:46:54.530236 140618562066432 dqn_agent.py:280] 	 optimizer: adam
I0828 10:46:54.530401 140618562066432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:46:54.530500 140618562066432 dqn_agent.py:283] 	 seed: 1630147614528921
I0828 10:46:54.532056 140618562066432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:46:54.532178 140618562066432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:46:54.532257 140618562066432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:46:54.532327 140618562066432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:46:54.532392 140618562066432 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:46:54.532461 140618562066432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:46:54.532523 140618562066432 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:46:54.532607 140618562066432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:46:54.532682 140618562066432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:46:54.554209 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:46:54.567386 140618562066432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:46:54.567544 140618562066432 replay_runner.py:41] Starting iteration 0
Steps executed: 281 Episode length: 149 Return: -400.93204956195046
INFO:tensorflow:Average training steps per second: 232.55
I0828 10:46:58.867835 140618562066432 replay_runner.py:36] Average training steps per second: 232.55
I0828 10:46:59.665644 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -428.36
INFO:tensorflow:Starting iteration 1
I0828 10:47:02.866701 140618562066432 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 339.22
I0828 10:47:05.815003 140618562066432 replay_runner.py:36] Average training steps per second: 339.22

Steps executed: 217 Episode length: 109 Return: -267.87090771132356
INFO:tensorflow:Starting iteration 2
I0828 10:47:09.239001 140618562066432 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 353.78

Steps executed: 288 Episode length: 128 Return: -327.07932117737957
I0828 10:47:12.226407 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.76
INFO:tensorflow:Starting iteration 3
I0828 10:47:15.612483 140618562066432 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 332.74

Steps executed: 1000 Episode length: 1000 Return: -113.16353999135937
I0828 10:47:21.085284 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.16
INFO:tensorflow:Starting iteration 4
I0828 10:47:24.504223 140618562066432 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 351.50

Steps executed: 1000 Episode length: 1000 Return: -231.35389325611937
I0828 10:47:29.532316 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.35
INFO:tensorflow:Starting iteration 5
I0828 10:47:32.898355 140618562066432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 338.62

Steps executed: 1000 Episode length: 1000 Return: -179.74929325354563
I0828 10:47:37.433576 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.75
INFO:tensorflow:Starting iteration 6
I0828 10:47:40.824087 140618562066432 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 348.67

Steps executed: 1000 Episode length: 1000 Return: -144.77153821451247
I0828 10:47:45.332547 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.77
INFO:tensorflow:Starting iteration 7
I0828 10:47:48.635666 140618562066432 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 350.23

Steps executed: 974 Episode length: 974 Return: -507.0112989892943547
I0828 10:47:52.735971 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -507.01
INFO:tensorflow:Starting iteration 8

Steps executed: 903 Episode length: 799 Return: -400.2300075881983147
INFO:tensorflow:Average training steps per second: 358.56
I0828 10:47:58.843137 140618562066432 replay_runner.py:36] Average training steps per second: 358.56
I0828 10:48:00.016995 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.98
INFO:tensorflow:Starting iteration 9
I0828 10:48:03.420359 140618562066432 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 376.22

Steps executed: 773 Episode length: 773 Return: -421.6359326137016447
I0828 10:48:07.753893 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -421.64
INFO:tensorflow:Starting iteration 10
I0828 10:48:11.115586 140618562066432 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 382.88

Steps executed: 1000 Episode length: 1000 Return: -246.12878783163147
I0828 10:48:16.431812 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -246.13
INFO:tensorflow:Starting iteration 11

Steps executed: 226 Episode length: 226 Return: -45.66815238125542547
INFO:tensorflow:Average training steps per second: 334.70
I0828 10:48:22.627653 140618562066432 replay_runner.py:36] Average training steps per second: 334.70
I0828 10:48:22.801938 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -45.67
INFO:tensorflow:Starting iteration 12
I0828 10:48:26.138182 140618562066432 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 347.14

Steps executed: 1000 Episode length: 1000 Return: -46.831314680539037
I0828 10:48:30.344964 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -46.83
INFO:tensorflow:Starting iteration 13
I0828 10:48:33.757285 140618562066432 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 357.03

Steps executed: 1000 Episode length: 1000 Return: -61.758019214264717
I0828 10:48:38.648195 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.76
INFO:tensorflow:Starting iteration 14
I0828 10:48:41.996370 140618562066432 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 350.53

Steps executed: 1000 Episode length: 1000 Return: -201.07706989992445
I0828 10:48:46.567803 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.08
INFO:tensorflow:Starting iteration 15
I0828 10:48:49.873628 140618562066432 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 348.58

Steps executed: 1000 Episode length: 1000 Return: -96.815518179606845
I0828 10:48:55.363886 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.82
INFO:tensorflow:Starting iteration 16
I0828 10:48:58.464206 140618562066432 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 309.29

Steps executed: 1000 Episode length: 1000 Return: -52.068799711638285
I0828 10:49:03.201591 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -52.07
INFO:tensorflow:Starting iteration 17

Steps executed: 585 Episode length: 523 Return: -335.6682083008558285
INFO:tensorflow:Average training steps per second: 322.35
I0828 10:49:09.417866 140618562066432 replay_runner.py:36] Average training steps per second: 322.35
I0828 10:49:10.259193 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -304.89
INFO:tensorflow:Starting iteration 18
I0828 10:49:13.212750 140618562066432 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 309.38

Steps executed: 1000 Episode length: 1000 Return: -67.004328137721785
I0828 10:49:18.537559 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -67.00
INFO:tensorflow:Starting iteration 19
I0828 10:49:21.714432 140618562066432 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 320.19

Steps executed: 1000 Episode length: 1000 Return: -41.813561796935455
I0828 10:49:26.585639 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -41.81
INFO:tensorflow:Starting iteration 20

Steps executed: 238 Episode length: 238 Return: -552.0110505242077455
INFO:tensorflow:Average training steps per second: 363.19
I0828 10:49:32.844686 140618562066432 replay_runner.py:36] Average training steps per second: 363.19
I0828 10:49:33.012987 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -552.01
INFO:tensorflow:Starting iteration 21

Steps executed: 857 Episode length: 702 Return: -317.7906192244473755
INFO:tensorflow:Average training steps per second: 369.29
I0828 10:49:39.262236 140618562066432 replay_runner.py:36] Average training steps per second: 369.29
I0828 10:49:40.586385 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.95
INFO:tensorflow:Starting iteration 22

Steps executed: 601 Episode length: 601 Return: -449.0936632261006655
INFO:tensorflow:Average training steps per second: 376.66
I0828 10:49:46.802647 140618562066432 replay_runner.py:36] Average training steps per second: 376.66
I0828 10:49:47.750818 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -449.09
INFO:tensorflow:Starting iteration 23
I0828 10:49:51.275748 140618562066432 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 376.61

Steps executed: 1000 Episode length: 1000 Return: -116.65807538353437
I0828 10:49:55.826160 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.66
INFO:tensorflow:Starting iteration 24

Steps executed: 159 Episode length: 159 Return: 31.055312544099337437
INFO:tensorflow:Average training steps per second: 361.17
I0828 10:50:01.953045 140618562066432 replay_runner.py:36] Average training steps per second: 361.17

Steps executed: 427 Episode length: 268 Return: 262.91845672753937437
INFO:tensorflow:Starting iteration 25
I0828 10:50:05.693851 140618562066432 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 359.87
I0828 10:50:08.472926 140618562066432 replay_runner.py:36] Average training steps per second: 359.87

Steps executed: 366 Episode length: 173 Return: -54.22436864172997437
INFO:tensorflow:Starting iteration 26

Steps executed: 476 Episode length: 287 Return: 243.80856329890503537
INFO:tensorflow:Average training steps per second: 343.13
I0828 10:50:14.994148 140618562066432 replay_runner.py:36] Average training steps per second: 343.13
I0828 10:50:15.330885 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: 5.86
INFO:tensorflow:Starting iteration 27

Steps executed: 199 Episode length: 199 Return: -99.10643028798388537
INFO:tensorflow:Average training steps per second: 367.27

Steps executed: 1199 Episode length: 1000 Return: -34.156080473228797
I0828 10:50:23.737737 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -66.63
INFO:tensorflow:Starting iteration 28

Steps executed: 356 Episode length: 164 Return: -216.1290001502013697
INFO:tensorflow:Average training steps per second: 357.88
I0828 10:50:29.715987 140618562066432 replay_runner.py:36] Average training steps per second: 357.88
I0828 10:50:29.905039 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.28
INFO:tensorflow:Starting iteration 29
I0828 10:50:33.156044 140618562066432 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 330.54

Steps executed: 763 Episode length: 763 Return: 166.08923656051581697

Done fixed training!Episode length: 763 Return: 166.08923656051581697