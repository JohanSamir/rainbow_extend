Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0901 12:19:47.281477 139803418769408 run_experiment.py:549] Creating TrainRunner ...
I0901 12:19:47.293153 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:19:47.293344 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:19:47.293440 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:19:47.293525 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:19:47.293585 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 12:19:47.293643 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:19:47.293696 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:19:47.293753 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:19:47.293854 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:19:47.294136 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 12:19:47.294273 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:19:47.294376 139803418769408 dqn_agent.py:283] 	 seed: 1630498787293102
I0901 12:19:47.297401 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:19:47.297971 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:19:47.298215 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:19:47.298377 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:19:47.298504 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:19:47.298662 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:19:47.298800 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:19:47.298924 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:19:47.299122 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:19:47.367740 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:19:47.741526 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:19:47.775515 139803418769408 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:19:47.785025 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:19:47.785256 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:19:47.785405 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:19:47.785484 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:19:47.785601 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 12:19:47.785749 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:19:47.785920 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:19:47.786062 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:19:47.786229 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:19:47.786458 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 12:19:47.786688 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:19:47.786798 139803418769408 dqn_agent.py:283] 	 seed: 1630498787784972
I0901 12:19:47.789620 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:19:47.789952 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:19:47.790084 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:19:47.790283 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:19:47.790418 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:19:47.790545 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:19:47.790641 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:19:47.790713 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:19:47.790786 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:19:47.821723 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:19:47.842953 139803418769408 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:19:47.843141 139803418769408 replay_runner.py:41] Starting iteration 0
Steps executed: 252 Episode length: 150 Return: -424.8881164553776
INFO:tensorflow:Average training steps per second: 169.06
I0901 12:19:53.758425 139803418769408 replay_runner.py:36] Average training steps per second: 169.06
I0901 12:19:54.982981 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -407.32
INFO:tensorflow:Starting iteration 1

Steps executed: 211 Episode length: 211 Return: -430.5453059311764
INFO:tensorflow:Average training steps per second: 228.34
I0901 12:20:03.598091 139803418769408 replay_runner.py:36] Average training steps per second: 228.34
I0901 12:20:03.810543 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -430.55
INFO:tensorflow:Starting iteration 2

Steps executed: 153 Episode length: 153 Return: -125.13452339513123
INFO:tensorflow:Average training steps per second: 226.55
I0901 12:20:12.577645 139803418769408 replay_runner.py:36] Average training steps per second: 226.55

Steps executed: 303 Episode length: 150 Return: -279.39964283174053
INFO:tensorflow:Starting iteration 3
I0901 12:20:17.167486 139803418769408 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 223.19

Steps executed: 1000 Episode length: 1000 Return: -71.23262924305293
I0901 12:20:25.097988 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.23
INFO:tensorflow:Starting iteration 4
I0901 12:20:29.181250 139803418769408 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 228.98

Steps executed: 1000 Episode length: 1000 Return: -75.42775038404211
I0901 12:20:36.541992 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.43
INFO:tensorflow:Starting iteration 5
I0901 12:20:40.448033 139803418769408 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 220.34

Steps executed: 1000 Episode length: 1000 Return: -199.7260007688944
I0901 12:20:47.707475 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.73
INFO:tensorflow:Starting iteration 6
I0901 12:20:52.063265 139803418769408 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 217.03

Steps executed: 1000 Episode length: 1000 Return: -237.27299065302563
I0901 12:20:58.636467 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.27
INFO:tensorflow:Starting iteration 7

Steps executed: 267 Episode length: 267 Return: -115.2506516769650363
INFO:tensorflow:Average training steps per second: 227.00
I0901 12:21:07.348440 139803418769408 replay_runner.py:36] Average training steps per second: 227.00
I0901 12:21:07.670903 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.25
INFO:tensorflow:Starting iteration 8
I0901 12:21:11.904542 139803418769408 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 225.68
I0901 12:21:16.336177 139803418769408 replay_runner.py:36] Average training steps per second: 225.68

Steps executed: 517 Episode length: 517 Return: -216.0498562037204263
INFO:tensorflow:Starting iteration 9

Steps executed: 256 Episode length: 256 Return: -160.8129820930863663
INFO:tensorflow:Average training steps per second: 224.74
I0901 12:21:25.850726 139803418769408 replay_runner.py:36] Average training steps per second: 224.74
I0901 12:21:26.153314 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.81
INFO:tensorflow:Starting iteration 10
I0901 12:21:30.468509 139803418769408 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 219.44

Steps executed: 366 Episode length: 366 Return: -527.5592364736051663
I0901 12:21:35.600022 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -527.56
INFO:tensorflow:Starting iteration 11

Steps executed: 384 Episode length: 384 Return: -528.0774237834389663
INFO:tensorflow:Average training steps per second: 233.05
I0901 12:21:44.183004 139803418769408 replay_runner.py:36] Average training steps per second: 233.05
I0901 12:21:44.842046 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -528.08
INFO:tensorflow:Starting iteration 12
I0901 12:21:49.090176 139803418769408 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 230.52

Steps executed: 429 Episode length: 429 Return: -155.9514872601206263
I0901 12:21:53.984757 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.95
INFO:tensorflow:Starting iteration 13
I0901 12:21:58.240359 139803418769408 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 238.14

Steps executed: 1000 Episode length: 1000 Return: -177.56945520453505
I0901 12:22:05.425914 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.57
INFO:tensorflow:Starting iteration 14
I0901 12:22:09.542530 139803418769408 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 228.32

Steps executed: 1000 Episode length: 1000 Return: -48.983731425436446
I0901 12:22:17.019236 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -48.98
INFO:tensorflow:Starting iteration 15

Steps executed: 292 Episode length: 292 Return: -199.3092703689897446
INFO:tensorflow:Average training steps per second: 224.86
I0901 12:22:25.774283 139803418769408 replay_runner.py:36] Average training steps per second: 224.86
I0901 12:22:26.077100 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.31
INFO:tensorflow:Starting iteration 16
I0901 12:22:30.503707 139803418769408 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 210.26

Steps executed: 746 Episode length: 746 Return: -145.8834055065245346
I0901 12:22:37.429720 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.88
INFO:tensorflow:Starting iteration 17

Steps executed: 314 Episode length: 314 Return: -568.0868449876833346
INFO:tensorflow:Average training steps per second: 215.88
I0901 12:22:46.442756 139803418769408 replay_runner.py:36] Average training steps per second: 215.88
I0901 12:22:46.852776 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -568.09
INFO:tensorflow:Starting iteration 18

Steps executed: 207 Episode length: 65 Return: -123.40024594732942346
INFO:tensorflow:Average training steps per second: 209.49
I0901 12:22:55.882240 139803418769408 replay_runner.py:36] Average training steps per second: 209.49
I0901 12:22:56.075224 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.44
INFO:tensorflow:Starting iteration 19
I0901 12:23:00.382005 139803418769408 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 218.14

Steps executed: 1000 Episode length: 1000 Return: -20.153475697273933
I0901 12:23:08.056715 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -20.15
INFO:tensorflow:Starting iteration 20

Steps executed: 183 Episode length: 109 Return: -128.3293352464710333
INFO:tensorflow:Average training steps per second: 213.26
I0901 12:23:17.021816 139803418769408 replay_runner.py:36] Average training steps per second: 213.26

Steps executed: 328 Episode length: 145 Return: -210.0914660217762633
INFO:tensorflow:Starting iteration 21

Steps executed: 143 Episode length: 143 Return: -81.46585994424959633
INFO:tensorflow:Average training steps per second: 224.22

Steps executed: 1143 Episode length: 1000 Return: 15.5320992960814633
I0901 12:23:29.531368 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -32.97
INFO:tensorflow:Starting iteration 22

Steps executed: 238 Episode length: 125 Return: -83.72595875827605433
INFO:tensorflow:Average training steps per second: 214.90
I0901 12:23:38.431159 139803418769408 replay_runner.py:36] Average training steps per second: 214.90
I0901 12:23:38.635810 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.51
INFO:tensorflow:Starting iteration 23
I0901 12:23:42.902529 139803418769408 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 217.17

Steps executed: 422 Episode length: 258 Return: -272.1472516444229733
I0901 12:23:48.019492 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.44
INFO:tensorflow:Starting iteration 24

Steps executed: 189 Episode length: 189 Return: -109.8890160200378933
INFO:tensorflow:Average training steps per second: 211.35

Steps executed: 1189 Episode length: 1000 Return: -90.859017221568733
I0901 12:23:59.760335 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.37
INFO:tensorflow:Starting iteration 25

Steps executed: 296 Episode length: 145 Return: -99.47885387676482433
INFO:tensorflow:Average training steps per second: 215.39
I0901 12:24:08.791218 139803418769408 replay_runner.py:36] Average training steps per second: 215.39
I0901 12:24:09.040737 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.58
INFO:tensorflow:Starting iteration 26

Steps executed: 329 Episode length: 180 Return: -262.9000372113268333
INFO:tensorflow:Average training steps per second: 212.87
I0901 12:24:17.999308 139803418769408 replay_runner.py:36] Average training steps per second: 212.87
I0901 12:24:18.343210 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.92
INFO:tensorflow:Starting iteration 27

Steps executed: 243 Episode length: 243 Return: -166.4439192716273333
INFO:tensorflow:Average training steps per second: 223.69
I0901 12:24:27.193127 139803418769408 replay_runner.py:36] Average training steps per second: 223.69
I0901 12:24:27.459136 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.44
INFO:tensorflow:Starting iteration 28

Steps executed: 311 Episode length: 112 Return: -78.70636665206803333
INFO:tensorflow:Average training steps per second: 218.69
I0901 12:24:36.435111 139803418769408 replay_runner.py:36] Average training steps per second: 218.69
I0901 12:24:36.751717 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.23
INFO:tensorflow:Starting iteration 29

Steps executed: 204 Episode length: 67 Return: -156.54484591187347333
INFO:tensorflow:Average training steps per second: 233.47
I0901 12:24:45.418999 139803418769408 replay_runner.py:36] Average training steps per second: 233.47

Done fixed training!Episode length: 67 Return: -156.54484591187347333