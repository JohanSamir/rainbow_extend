I0828 10:54:31.600578 139825303013376 run_experiment.py:549] Creating TrainRunner ...
I0828 10:54:31.608105 139825303013376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:54:31.608267 139825303013376 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:54:31.608355 139825303013376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:54:31.608422 139825303013376 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:54:31.608483 139825303013376 dqn_agent.py:275] 	 update_period: 4
I0828 10:54:31.608542 139825303013376 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:54:31.608621 139825303013376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:54:31.608751 139825303013376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:54:31.608871 139825303013376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:54:31.608962 139825303013376 dqn_agent.py:280] 	 optimizer: adam
I0828 10:54:31.609022 139825303013376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:54:31.609145 139825303013376 dqn_agent.py:283] 	 seed: 1630148071608074
I0828 10:54:31.610962 139825303013376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:54:31.611077 139825303013376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:54:31.611154 139825303013376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:54:31.611218 139825303013376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:54:31.611275 139825303013376 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:54:31.611378 139825303013376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:54:31.611470 139825303013376 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:54:31.611564 139825303013376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:54:31.611654 139825303013376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:54:31.636010 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:31.883918 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:31.893783 139825303013376 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:54:31.932978 139825303013376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:54:31.933118 139825303013376 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:54:31.933193 139825303013376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:54:31.933255 139825303013376 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:54:31.933343 139825303013376 dqn_agent.py:275] 	 update_period: 4
I0828 10:54:31.933454 139825303013376 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:54:31.933517 139825303013376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:54:31.933589 139825303013376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:54:31.933659 139825303013376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:54:31.933729 139825303013376 dqn_agent.py:280] 	 optimizer: adam
I0828 10:54:31.933797 139825303013376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:54:31.933866 139825303013376 dqn_agent.py:283] 	 seed: 1630148071932949
I0828 10:54:31.935374 139825303013376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:54:31.935484 139825303013376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:54:31.935557 139825303013376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:54:31.935661 139825303013376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:54:31.935728 139825303013376 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:54:31.935802 139825303013376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:54:31.935884 139825303013376 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:54:31.935954 139825303013376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:54:31.936027 139825303013376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:54:31.955309 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000010, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:54:31.970141 139825303013376 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:54:31.970297 139825303013376 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 255.08
I0828 10:54:35.890792 139825303013376 replay_runner.py:36] Average training steps per second: 255.08
I0828 10:54:36.769517 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.36
Steps executed: 215 Episode length: 96 Return: -297.925327739691745
INFO:tensorflow:Starting iteration 1
I0828 10:54:40.029058 139825303013376 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 323.05

Steps executed: 419 Episode length: 306 Return: -286.36955863073345
I0828 10:54:43.486829 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.36
INFO:tensorflow:Starting iteration 2

Steps executed: 278 Episode length: 93 Return: -680.099122349350545
INFO:tensorflow:Average training steps per second: 322.01
I0828 10:54:49.755261 139825303013376 replay_runner.py:36] Average training steps per second: 322.01
I0828 10:54:49.916116 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -462.54
INFO:tensorflow:Starting iteration 3

Steps executed: 354 Episode length: 160 Return: -191.68583949159603
INFO:tensorflow:Average training steps per second: 325.43
I0828 10:54:56.229240 139825303013376 replay_runner.py:36] Average training steps per second: 325.43
I0828 10:54:56.454588 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.68
INFO:tensorflow:Starting iteration 4

Steps executed: 300 Episode length: 300 Return: -444.87598156177903
INFO:tensorflow:Average training steps per second: 317.53
I0828 10:55:02.863037 139825303013376 replay_runner.py:36] Average training steps per second: 317.53
I0828 10:55:03.121295 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -444.88
INFO:tensorflow:Starting iteration 5

Steps executed: 310 Episode length: 122 Return: -374.49101737079863
INFO:tensorflow:Average training steps per second: 317.35
I0828 10:55:09.498432 139825303013376 replay_runner.py:36] Average training steps per second: 317.35
I0828 10:55:09.695928 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -441.63
INFO:tensorflow:Starting iteration 6

Steps executed: 366 Episode length: 264 Return: -340.22202255732964
INFO:tensorflow:Average training steps per second: 317.97
I0828 10:55:16.044078 139825303013376 replay_runner.py:36] Average training steps per second: 317.97
I0828 10:55:16.324528 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -490.39
INFO:tensorflow:Starting iteration 7

Steps executed: 324 Episode length: 167 Return: -414.90491404118677
INFO:tensorflow:Average training steps per second: 313.40
I0828 10:55:22.704787 139825303013376 replay_runner.py:36] Average training steps per second: 313.40
I0828 10:55:22.916017 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -416.08
INFO:tensorflow:Starting iteration 8

Steps executed: 175 Episode length: 175 Return: -212.41628286451498
INFO:tensorflow:Average training steps per second: 309.60
I0828 10:55:29.315094 139825303013376 replay_runner.py:36] Average training steps per second: 309.60

Steps executed: 322 Episode length: 147 Return: -502.29750307999168
INFO:tensorflow:Starting iteration 9

Steps executed: 265 Episode length: 148 Return: -419.10497783856198
INFO:tensorflow:Average training steps per second: 312.51
I0828 10:55:35.931092 139825303013376 replay_runner.py:36] Average training steps per second: 312.51
I0828 10:55:36.121431 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -395.35
INFO:tensorflow:Starting iteration 10

Steps executed: 305 Episode length: 155 Return: -231.11187526436672
INFO:tensorflow:Average training steps per second: 314.26
I0828 10:55:42.493417 139825303013376 replay_runner.py:36] Average training steps per second: 314.26
I0828 10:55:42.715092 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.89
INFO:tensorflow:Starting iteration 11

Steps executed: 312 Episode length: 202 Return: -64.243423377825022
INFO:tensorflow:Average training steps per second: 313.11
I0828 10:55:49.095564 139825303013376 replay_runner.py:36] Average training steps per second: 313.11
I0828 10:55:49.306334 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.67
INFO:tensorflow:Starting iteration 12

Steps executed: 262 Episode length: 112 Return: -85.976705280581312
INFO:tensorflow:Average training steps per second: 305.98
I0828 10:55:55.770668 139825303013376 replay_runner.py:36] Average training steps per second: 305.98
I0828 10:55:55.936420 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.90
INFO:tensorflow:Starting iteration 13

Steps executed: 434 Episode length: 265 Return: -206.32980854957148
INFO:tensorflow:Average training steps per second: 311.57
I0828 10:56:02.326570 139825303013376 replay_runner.py:36] Average training steps per second: 311.57
I0828 10:56:02.659997 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -241.38
INFO:tensorflow:Starting iteration 14

Steps executed: 382 Episode length: 241 Return: -33.600825417079488
INFO:tensorflow:Average training steps per second: 311.60
I0828 10:56:09.023158 139825303013376 replay_runner.py:36] Average training steps per second: 311.60
I0828 10:56:09.282807 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.97
INFO:tensorflow:Starting iteration 15

Steps executed: 283 Episode length: 162 Return: -204.96166676544175
INFO:tensorflow:Average training steps per second: 313.07
I0828 10:56:15.647146 139825303013376 replay_runner.py:36] Average training steps per second: 313.07
I0828 10:56:15.822553 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -278.18
INFO:tensorflow:Starting iteration 16

Steps executed: 315 Episode length: 167 Return: -32.306546555903325
INFO:tensorflow:Average training steps per second: 312.08
I0828 10:56:22.233638 139825303013376 replay_runner.py:36] Average training steps per second: 312.08
I0828 10:56:22.450055 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.52
INFO:tensorflow:Starting iteration 17

Steps executed: 223 Episode length: 124 Return: -218.42924715203865
INFO:tensorflow:Average training steps per second: 309.80
I0828 10:56:28.879717 139825303013376 replay_runner.py:36] Average training steps per second: 309.80
I0828 10:56:29.007325 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.14
INFO:tensorflow:Starting iteration 18
I0828 10:56:32.210073 139825303013376 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 305.99
I0828 10:56:35.478463 139825303013376 replay_runner.py:36] Average training steps per second: 305.99

Steps executed: 254 Episode length: 96 Return: -355.171252184909357
INFO:tensorflow:Starting iteration 19

Steps executed: 297 Episode length: 155 Return: -260.46384239938225
INFO:tensorflow:Average training steps per second: 313.90
I0828 10:56:42.026596 139825303013376 replay_runner.py:36] Average training steps per second: 313.90
I0828 10:56:42.195236 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.49
INFO:tensorflow:Starting iteration 20

Steps executed: 249 Episode length: 82 Return: -395.929397849453555
INFO:tensorflow:Average training steps per second: 314.23
I0828 10:56:48.600679 139825303013376 replay_runner.py:36] Average training steps per second: 314.23
I0828 10:56:48.750100 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.23
INFO:tensorflow:Starting iteration 21

Steps executed: 254 Episode length: 136 Return: -274.97209583855306
INFO:tensorflow:Average training steps per second: 310.19
I0828 10:56:55.203900 139825303013376 replay_runner.py:36] Average training steps per second: 310.19
I0828 10:56:55.351830 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.69
INFO:tensorflow:Starting iteration 22

Steps executed: 321 Episode length: 139 Return: -278.89586619237826
INFO:tensorflow:Average training steps per second: 315.17
I0828 10:57:01.763334 139825303013376 replay_runner.py:36] Average training steps per second: 315.17
I0828 10:57:01.974043 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.21
INFO:tensorflow:Starting iteration 23

Steps executed: 307 Episode length: 155 Return: -265.74229035325356
INFO:tensorflow:Average training steps per second: 316.68
I0828 10:57:08.405004 139825303013376 replay_runner.py:36] Average training steps per second: 316.68
I0828 10:57:08.594223 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.65
INFO:tensorflow:Starting iteration 24

Steps executed: 259 Episode length: 151 Return: -251.08189796910065
INFO:tensorflow:Average training steps per second: 310.45
I0828 10:57:15.113864 139825303013376 replay_runner.py:36] Average training steps per second: 310.45
I0828 10:57:15.261999 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -267.20
INFO:tensorflow:Starting iteration 25

Steps executed: 218 Episode length: 102 Return: -259.84403506394715
INFO:tensorflow:Average training steps per second: 330.83
I0828 10:57:21.560501 139825303013376 replay_runner.py:36] Average training steps per second: 330.83
I0828 10:57:21.671424 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.48
INFO:tensorflow:Starting iteration 26

Steps executed: 89 Episode length: 89 Return: -282.2762084092225715
INFO:tensorflow:Average training steps per second: 348.90
I0828 10:57:27.710903 139825303013376 replay_runner.py:36] Average training steps per second: 348.90

Steps executed: 240 Episode length: 151 Return: -1.5098074583370935
INFO:tensorflow:Starting iteration 27
I0828 10:57:31.037021 139825303013376 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 364.06

Steps executed: 308 Episode length: 109 Return: -265.55165123666793
I0828 10:57:33.952499 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -183.09
INFO:tensorflow:Starting iteration 28

Steps executed: 322 Episode length: 133 Return: -61.132777245759753
INFO:tensorflow:Average training steps per second: 357.86
I0828 10:57:39.711215 139825303013376 replay_runner.py:36] Average training steps per second: 357.86
I0828 10:57:39.889000 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.11
INFO:tensorflow:Starting iteration 29

Steps executed: 213 Episode length: 213 Return: -287.56504987028205
INFO:tensorflow:Average training steps per second: 399.49
I0828 10:57:45.361316 139825303013376 replay_runner.py:36] Average training steps per second: 399.49

Done fixed training!Episode length: 213 Return: -287.56504987028205