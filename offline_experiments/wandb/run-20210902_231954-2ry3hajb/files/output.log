Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0902 23:20:01.156366 139900407642112 run_experiment.py:549] Creating TrainRunner ...
I0902 23:20:01.167885 139900407642112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:20:01.168245 139900407642112 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:20:01.168477 139900407642112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:20:01.168666 139900407642112 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:20:01.169114 139900407642112 dqn_agent.py:275] 	 update_period: 4
I0902 23:20:01.169276 139900407642112 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:20:01.169361 139900407642112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:20:01.169440 139900407642112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:20:01.169553 139900407642112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:20:01.169631 139900407642112 dqn_agent.py:280] 	 optimizer: adam
I0902 23:20:01.169749 139900407642112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:20:01.170240 139900407642112 dqn_agent.py:283] 	 seed: 1630624801167803
I0902 23:20:01.173341 139900407642112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:20:01.173502 139900407642112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:20:01.173640 139900407642112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:20:01.173997 139900407642112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:20:01.174123 139900407642112 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:20:01.174396 139900407642112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:20:01.174685 139900407642112 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:20:01.174800 139900407642112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:20:01.174881 139900407642112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:20:01.213218 139900407642112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:20:01.619063 139900407642112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:20:01.633046 139900407642112 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:20:01.658937 139900407642112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:20:01.664399 139900407642112 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:20:01.668580 139900407642112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:20:01.669181 139900407642112 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:20:01.669463 139900407642112 dqn_agent.py:275] 	 update_period: 4
I0902 23:20:01.669906 139900407642112 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:20:01.670074 139900407642112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:20:01.670293 139900407642112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:20:01.670445 139900407642112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:20:01.670682 139900407642112 dqn_agent.py:280] 	 optimizer: adam
I0902 23:20:01.670831 139900407642112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:20:01.670960 139900407642112 dqn_agent.py:283] 	 seed: 1630624801658886
I0902 23:20:01.680390 139900407642112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:20:01.680840 139900407642112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:20:01.680995 139900407642112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:20:01.681089 139900407642112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:20:01.681202 139900407642112 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:20:01.681379 139900407642112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:20:01.681487 139900407642112 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:20:01.681674 139900407642112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:20:01.681891 139900407642112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:20:01.716938 139900407642112 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:20:01.742003 139900407642112 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:20:01.742521 139900407642112 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 164.74
I0902 23:20:07.812864 139900407642112 replay_runner.py:36] Average training steps per second: 164.74
Steps executed: 252 Episode length: 61 Return: -556.5576426390408
I0902 23:20:09.008019 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -552.60
INFO:tensorflow:Starting iteration 1

Steps executed: 275 Episode length: 77 Return: -814.9395511211454
INFO:tensorflow:Average training steps per second: 222.47
I0902 23:20:17.787113 139900407642112 replay_runner.py:36] Average training steps per second: 222.47
I0902 23:20:18.047363 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -648.00
INFO:tensorflow:Starting iteration 2

Steps executed: 200 Episode length: 58 Return: -503.2061802031442
INFO:tensorflow:Average training steps per second: 217.65
I0902 23:20:26.900744 139900407642112 replay_runner.py:36] Average training steps per second: 217.65
I0902 23:20:27.079206 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -625.83
INFO:tensorflow:Starting iteration 3

Steps executed: 237 Episode length: 52 Return: -360.6625225689584
INFO:tensorflow:Average training steps per second: 223.10
I0902 23:20:35.720202 139900407642112 replay_runner.py:36] Average training steps per second: 223.10
I0902 23:20:35.929704 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -428.72
INFO:tensorflow:Starting iteration 4

Steps executed: 219 Episode length: 77 Return: -652.5206226071955
INFO:tensorflow:Average training steps per second: 221.02
I0902 23:20:44.572630 139900407642112 replay_runner.py:36] Average training steps per second: 221.02
I0902 23:20:44.755105 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -655.27
INFO:tensorflow:Starting iteration 5

Steps executed: 244 Episode length: 78 Return: -727.91043180081495
INFO:tensorflow:Average training steps per second: 218.88
I0902 23:20:53.630548 139900407642112 replay_runner.py:36] Average training steps per second: 218.88
I0902 23:20:53.840672 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -522.12
INFO:tensorflow:Starting iteration 6

Steps executed: 238 Episode length: 85 Return: -473.064181671252516
INFO:tensorflow:Average training steps per second: 222.52
I0902 23:21:02.563447 139900407642112 replay_runner.py:36] Average training steps per second: 222.52
I0902 23:21:02.807682 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -847.54
INFO:tensorflow:Starting iteration 7

Steps executed: 222 Episode length: 57 Return: -585.964762592507216
INFO:tensorflow:Average training steps per second: 218.30
I0902 23:21:11.762696 139900407642112 replay_runner.py:36] Average training steps per second: 218.30
I0902 23:21:11.958159 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -704.11
INFO:tensorflow:Starting iteration 8

Steps executed: 153 Episode length: 79 Return: -523.471333176699516
INFO:tensorflow:Average training steps per second: 223.16
I0902 23:21:20.778108 139900407642112 replay_runner.py:36] Average training steps per second: 223.16

Steps executed: 241 Episode length: 88 Return: -592.299885075432616
INFO:tensorflow:Starting iteration 9

Steps executed: 285 Episode length: 122 Return: -899.13223791201056
INFO:tensorflow:Average training steps per second: 214.66
I0902 23:21:30.024071 139900407642112 replay_runner.py:36] Average training steps per second: 214.66
I0902 23:21:30.290006 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -633.68
INFO:tensorflow:Starting iteration 10

Steps executed: 78 Episode length: 78 Return: -500.6438601250610556
INFO:tensorflow:Average training steps per second: 218.48

Steps executed: 291 Episode length: 213 Return: -1806.7918981668966
I0902 23:21:39.162812 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -1153.72
INFO:tensorflow:Starting iteration 11

Steps executed: 315 Episode length: 202 Return: -1370.2935197552422
INFO:tensorflow:Average training steps per second: 229.34
I0902 23:21:47.800005 139900407642112 replay_runner.py:36] Average training steps per second: 229.34
I0902 23:21:48.158624 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -1026.27
INFO:tensorflow:Starting iteration 12

Steps executed: 265 Episode length: 75 Return: -507.440568025715232
INFO:tensorflow:Average training steps per second: 230.57
I0902 23:21:56.578082 139900407642112 replay_runner.py:36] Average training steps per second: 230.57
I0902 23:21:56.828270 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -624.15
INFO:tensorflow:Starting iteration 13
I0902 23:22:01.072274 139900407642112 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 236.56

Steps executed: 361 Episode length: 273 Return: -2588.6084778402392
I0902 23:22:05.703558 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -1537.12
INFO:tensorflow:Starting iteration 14

Steps executed: 399 Episode length: 240 Return: -1747.9772747547809
INFO:tensorflow:Average training steps per second: 225.90
I0902 23:22:14.302798 139900407642112 replay_runner.py:36] Average training steps per second: 225.90
I0902 23:22:14.766783 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -1366.77
INFO:tensorflow:Starting iteration 15

Steps executed: 80 Episode length: 80 Return: -537.4976657131608809
INFO:tensorflow:Average training steps per second: 227.81

Steps executed: 285 Episode length: 125 Return: -882.63836976234729
I0902 23:22:23.473035 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -651.21
INFO:tensorflow:Starting iteration 16

Steps executed: 283 Episode length: 178 Return: -1269.8104651192957
INFO:tensorflow:Average training steps per second: 226.74
I0902 23:22:31.972214 139900407642112 replay_runner.py:36] Average training steps per second: 226.74
I0902 23:22:32.251296 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -1029.00
INFO:tensorflow:Starting iteration 17

Steps executed: 219 Episode length: 122 Return: -844.29096046653847
INFO:tensorflow:Average training steps per second: 222.14
I0902 23:22:41.060660 139900407642112 replay_runner.py:36] Average training steps per second: 222.14
I0902 23:22:41.280849 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -731.98
INFO:tensorflow:Starting iteration 18

Steps executed: 263 Episode length: 80 Return: -425.474065746767657
INFO:tensorflow:Average training steps per second: 222.58
I0902 23:22:50.117755 139900407642112 replay_runner.py:36] Average training steps per second: 222.58
I0902 23:22:50.372677 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -558.04
INFO:tensorflow:Starting iteration 19

Steps executed: 219 Episode length: 90 Return: -725.262168474166587
INFO:tensorflow:Average training steps per second: 219.77
I0902 23:22:59.231045 139900407642112 replay_runner.py:36] Average training steps per second: 219.77
I0902 23:22:59.450633 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -800.01
INFO:tensorflow:Starting iteration 20

Steps executed: 397 Episode length: 289 Return: -2306.8312236276937
INFO:tensorflow:Average training steps per second: 220.04
I0902 23:23:08.394359 139900407642112 replay_runner.py:36] Average training steps per second: 220.04
I0902 23:23:08.973633 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -1522.24
INFO:tensorflow:Starting iteration 21

Steps executed: 241 Episode length: 164 Return: -1141.9856122549487
INFO:tensorflow:Average training steps per second: 220.88
I0902 23:23:17.753376 139900407642112 replay_runner.py:36] Average training steps per second: 220.88
I0902 23:23:17.990084 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -785.55
INFO:tensorflow:Starting iteration 22

Steps executed: 174 Episode length: 174 Return: -1439.6730826625187
INFO:tensorflow:Average training steps per second: 216.67
I0902 23:23:26.926032 139900407642112 replay_runner.py:36] Average training steps per second: 216.67

Steps executed: 264 Episode length: 90 Return: -614.626913890025187
INFO:tensorflow:Starting iteration 23

Steps executed: 354 Episode length: 182 Return: -1082.6167633165405
INFO:tensorflow:Average training steps per second: 214.56
I0902 23:23:36.082340 139900407642112 replay_runner.py:36] Average training steps per second: 214.56
I0902 23:23:36.441611 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -699.90
INFO:tensorflow:Starting iteration 24
I0902 23:23:40.763330 139900407642112 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 218.71

Steps executed: 329 Episode length: 131 Return: -641.45978130974025
I0902 23:23:45.656204 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -638.27
INFO:tensorflow:Starting iteration 25

Steps executed: 259 Episode length: 259 Return: -2387.9835496594025
INFO:tensorflow:Average training steps per second: 220.20
I0902 23:23:54.485169 139900407642112 replay_runner.py:36] Average training steps per second: 220.20
I0902 23:23:54.806247 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -2387.98
INFO:tensorflow:Starting iteration 26
I0902 23:23:58.760674 139900407642112 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 216.49

Steps executed: 204 Episode length: 103 Return: -584.80886438279635
I0902 23:24:03.583621 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -622.27
INFO:tensorflow:Starting iteration 27

Steps executed: 330 Episode length: 201 Return: -1698.1124702981137
INFO:tensorflow:Average training steps per second: 219.39
I0902 23:24:12.370484 139900407642112 replay_runner.py:36] Average training steps per second: 219.39
I0902 23:24:12.731295 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -1232.45
INFO:tensorflow:Starting iteration 28
I0902 23:24:16.944722 139900407642112 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 221.00

Steps executed: 377 Episode length: 297 Return: -2945.6918188528534
I0902 23:24:21.985120 139900407642112 run_experiment.py:428] Average undiscounted return per evaluation episode: -1768.38
INFO:tensorflow:Starting iteration 29

Steps executed: 269 Episode length: 85 Return: -438.782217205627874
INFO:tensorflow:Average training steps per second: 214.92
I0902 23:24:30.746759 139900407642112 replay_runner.py:36] Average training steps per second: 214.92

Done fixed training!Episode length: 85 Return: -438.782217205627874