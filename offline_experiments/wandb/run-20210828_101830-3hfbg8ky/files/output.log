I0828 10:18:36.913774 140251198892032 run_experiment.py:549] Creating TrainRunner ...
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0828 10:18:36.914311 140251198892032 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0828 10:18:36.990375 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:18:36.991485 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:18:36.991577 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:18:36.991685 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:18:36.991776 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:18:36.991834 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:18:36.991925 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:18:36.992037 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:18:36.992145 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:18:36.992218 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:18:36.992289 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:18:36.992358 140251198892032 dqn_agent.py:283] 	 seed: 1630145916990318
I0828 10:18:36.994268 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:18:36.994433 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:18:36.994510 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:18:36.994605 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:18:36.994719 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:18:36.994796 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:18:36.994855 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:18:36.994943 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:18:36.995016 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:18:38.378222 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=10.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0828 10:18:38.744109 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=10.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:18:38.752097 140251198892032 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:18:38.756871 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:18:38.757009 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:18:38.757080 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:18:38.757143 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:18:38.757199 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:18:38.757253 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:18:38.757326 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:18:38.757417 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:18:38.757485 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:18:38.757539 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:18:38.757598 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:18:38.757665 140251198892032 dqn_agent.py:283] 	 seed: 1630145918756840
I0828 10:18:38.759258 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:18:38.759374 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:18:38.759444 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:18:38.759506 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:18:38.759570 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:18:38.759636 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:18:38.759712 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:18:38.759766 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:18:38.759839 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:18:38.779855 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=10.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:18:38.793397 140251198892032 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:18:38.793581 140251198892032 replay_runner.py:41] Starting iteration 0
Steps executed: 261 Episode length: 66 Return: -437.30204173057164
INFO:tensorflow:Average training steps per second: 175.07
I0828 10:18:44.505915 140251198892032 replay_runner.py:36] Average training steps per second: 175.07
I0828 10:18:45.567383 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -366.27
INFO:tensorflow:Starting iteration 1
I0828 10:18:49.736637 140251198892032 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 211.69

Steps executed: 241 Episode length: 67 Return: -378.30510500251506
I0828 10:18:54.675946 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -350.27
INFO:tensorflow:Starting iteration 2

Steps executed: 238 Episode length: 68 Return: -553.33265617010224
INFO:tensorflow:Average training steps per second: 214.19
I0828 10:19:03.611418 140251198892032 replay_runner.py:36] Average training steps per second: 214.19
I0828 10:19:03.813178 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -468.71
INFO:tensorflow:Starting iteration 3

Steps executed: 237 Episode length: 47 Return: -390.81338700466813
INFO:tensorflow:Average training steps per second: 213.97
I0828 10:19:12.738562 140251198892032 replay_runner.py:36] Average training steps per second: 213.97
I0828 10:19:12.954906 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -546.48
INFO:tensorflow:Starting iteration 4

Steps executed: 519 Episode length: 413 Return: -1572.365856182942
INFO:tensorflow:Average training steps per second: 214.84
I0828 10:19:21.855365 140251198892032 replay_runner.py:36] Average training steps per second: 214.84
I0828 10:19:22.575000 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -1138.30
INFO:tensorflow:Starting iteration 5

Steps executed: 208 Episode length: 63 Return: 21.4252004712491984
INFO:tensorflow:Average training steps per second: 211.42
I0828 10:19:31.559222 140251198892032 replay_runner.py:36] Average training steps per second: 211.42
I0828 10:19:31.682531 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.12
INFO:tensorflow:Starting iteration 6

Steps executed: 160 Episode length: 55 Return: -303.77241513944625
INFO:tensorflow:Average training steps per second: 213.21
I0828 10:19:40.540057 140251198892032 replay_runner.py:36] Average training steps per second: 213.21

Steps executed: 227 Episode length: 67 Return: -604.11453749579755
INFO:tensorflow:Starting iteration 7

Steps executed: 291 Episode length: 115 Return: -678.1476766757241
INFO:tensorflow:Average training steps per second: 216.14
I0828 10:19:49.652348 140251198892032 replay_runner.py:36] Average training steps per second: 216.14
I0828 10:19:49.922107 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -624.97
INFO:tensorflow:Starting iteration 8

Steps executed: 260 Episode length: 146 Return: -1117.2736421776876
INFO:tensorflow:Average training steps per second: 217.54
I0828 10:19:58.847065 140251198892032 replay_runner.py:36] Average training steps per second: 217.54
I0828 10:19:59.093210 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -982.64
INFO:tensorflow:Starting iteration 9

Steps executed: 256 Episode length: 82 Return: -465.262043794893426
INFO:tensorflow:Average training steps per second: 215.31
I0828 10:20:08.031979 140251198892032 replay_runner.py:36] Average training steps per second: 215.31
I0828 10:20:08.294027 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -857.19
INFO:tensorflow:Starting iteration 10

Steps executed: 227 Episode length: 85 Return: -172.153925757445886
INFO:tensorflow:Average training steps per second: 216.41
I0828 10:20:17.170682 140251198892032 replay_runner.py:36] Average training steps per second: 216.41
I0828 10:20:17.306060 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.65
INFO:tensorflow:Starting iteration 11

Steps executed: 212 Episode length: 122 Return: -692.42369779764986
INFO:tensorflow:Average training steps per second: 216.96
I0828 10:20:26.055340 140251198892032 replay_runner.py:36] Average training steps per second: 216.96
I0828 10:20:26.260555 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -613.27
INFO:tensorflow:Starting iteration 12

Steps executed: 207 Episode length: 130 Return: -976.17103611936446
INFO:tensorflow:Average training steps per second: 219.64
I0828 10:20:35.097829 140251198892032 replay_runner.py:36] Average training steps per second: 219.64
I0828 10:20:35.295670 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -688.11
INFO:tensorflow:Starting iteration 13

Steps executed: 245 Episode length: 58 Return: -551.955370728350546
INFO:tensorflow:Average training steps per second: 216.31
I0828 10:20:44.122480 140251198892032 replay_runner.py:36] Average training steps per second: 216.31
I0828 10:20:44.326917 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -528.68
INFO:tensorflow:Starting iteration 14

Steps executed: 255 Episode length: 147 Return: -997.55916440847476
INFO:tensorflow:Average training steps per second: 216.74
I0828 10:20:53.250044 140251198892032 replay_runner.py:36] Average training steps per second: 216.74
I0828 10:20:53.501571 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -775.15
INFO:tensorflow:Starting iteration 15

Steps executed: 259 Episode length: 78 Return: -590.012394873231976
INFO:tensorflow:Average training steps per second: 220.86
I0828 10:21:02.344677 140251198892032 replay_runner.py:36] Average training steps per second: 220.86
I0828 10:21:02.582976 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -640.08
INFO:tensorflow:Starting iteration 16

Steps executed: 210 Episode length: 133 Return: -959.28819255963736
INFO:tensorflow:Average training steps per second: 217.86
I0828 10:21:11.461785 140251198892032 replay_runner.py:36] Average training steps per second: 217.86
I0828 10:21:11.665462 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -708.75
INFO:tensorflow:Starting iteration 17

Steps executed: 300 Episode length: 122 Return: -872.64419408473136
INFO:tensorflow:Average training steps per second: 219.33
I0828 10:21:20.553865 140251198892032 replay_runner.py:36] Average training steps per second: 219.33
I0828 10:21:20.824455 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -717.92
INFO:tensorflow:Starting iteration 18
I0828 10:21:25.016636 140251198892032 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 243.03

Steps executed: 274 Episode length: 156 Return: -1093.9456426100273
I0828 10:21:29.358172 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -879.49
INFO:tensorflow:Starting iteration 19

Steps executed: 176 Episode length: 74 Return: -482.694466751024263
INFO:tensorflow:Average training steps per second: 262.38
I0828 10:21:37.091264 140251198892032 replay_runner.py:36] Average training steps per second: 262.38

Steps executed: 265 Episode length: 89 Return: -605.225669048063163
INFO:tensorflow:Starting iteration 20
I0828 10:21:41.097410 140251198892032 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 233.41

Steps executed: 211 Episode length: 104 Return: -716.00571207836723
I0828 10:21:45.565933 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -767.57
INFO:tensorflow:Starting iteration 21

Steps executed: 279 Episode length: 279 Return: -2366.2824249456863
INFO:tensorflow:Average training steps per second: 228.30
I0828 10:21:54.228612 140251198892032 replay_runner.py:36] Average training steps per second: 228.30
I0828 10:21:54.654532 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -2366.28
INFO:tensorflow:Starting iteration 22

Steps executed: 266 Episode length: 113 Return: -744.67070104464463
INFO:tensorflow:Average training steps per second: 220.95
I0828 10:22:03.507276 140251198892032 replay_runner.py:36] Average training steps per second: 220.95
I0828 10:22:03.745645 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -608.84
INFO:tensorflow:Starting iteration 23

Steps executed: 209 Episode length: 99 Return: -581.906116351417573
INFO:tensorflow:Average training steps per second: 222.27
I0828 10:22:12.544701 140251198892032 replay_runner.py:36] Average training steps per second: 222.27
I0828 10:22:12.737877 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -515.70
INFO:tensorflow:Starting iteration 24
I0828 10:22:17.080108 140251198892032 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 225.84

Steps executed: 233 Episode length: 134 Return: -713.35164736080483
I0828 10:22:21.734447 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -703.35
INFO:tensorflow:Starting iteration 25

Steps executed: 290 Episode length: 96 Return: -630.345402459973752
INFO:tensorflow:Average training steps per second: 225.12
I0828 10:22:30.554844 140251198892032 replay_runner.py:36] Average training steps per second: 225.12
I0828 10:22:30.851218 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -951.04
INFO:tensorflow:Starting iteration 26
I0828 10:22:34.992872 140251198892032 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 219.21

Steps executed: 264 Episode length: 68 Return: -557.109446266921252
I0828 10:22:39.778165 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -560.38
INFO:tensorflow:Starting iteration 27

Steps executed: 295 Episode length: 215 Return: -1426.2757129203176
INFO:tensorflow:Average training steps per second: 224.22
I0828 10:22:48.621957 140251198892032 replay_runner.py:36] Average training steps per second: 224.22
I0828 10:22:48.934463 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -909.74
INFO:tensorflow:Starting iteration 28

Steps executed: 297 Episode length: 202 Return: -1580.4327928063612
INFO:tensorflow:Average training steps per second: 223.85
I0828 10:22:57.756942 140251198892032 replay_runner.py:36] Average training steps per second: 223.85
I0828 10:22:58.083660 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -1112.48
INFO:tensorflow:Starting iteration 29

Steps executed: 91 Episode length: 91 Return: -505.2354125478533412
INFO:tensorflow:Average training steps per second: 223.56
I0828 10:23:06.938425 140251198892032 replay_runner.py:36] Average training steps per second: 223.56


Done fixed training!Episode length: 134 Return: -864.98071784823962