Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0901 13:23:41.227575 139809518303232 run_experiment.py:549] Creating TrainRunner ...
I0901 13:23:41.236186 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:23:41.236317 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:23:41.236382 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:23:41.236462 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:23:41.236521 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 13:23:41.236582 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:23:41.236639 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:23:41.236727 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:23:41.236783 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:23:41.236847 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 13:23:41.236926 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:23:41.236992 139809518303232 dqn_agent.py:283] 	 seed: 1630502621236149
I0901 13:23:41.238725 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:23:41.238845 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:23:41.238926 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:23:41.239055 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:23:41.239126 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:23:41.239206 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:23:41.239276 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:23:41.239341 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:23:41.239398 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:23:41.367248 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:23:41.649920 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:23:41.659994 139809518303232 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:23:41.667401 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:23:41.667569 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:23:41.667652 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:23:41.667715 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:23:41.667771 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 13:23:41.667850 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:23:41.668030 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:23:41.668132 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:23:41.668234 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:23:41.668347 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 13:23:41.668430 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:23:41.668508 139809518303232 dqn_agent.py:283] 	 seed: 1630502621667364
I0901 13:23:41.670166 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:23:41.670289 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:23:41.670368 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:23:41.670439 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:23:41.670502 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:23:41.670572 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:23:41.670659 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:23:41.670722 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:23:41.670823 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:23:41.700969 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:23:41.742186 139809518303232 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:23:41.742415 139809518303232 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 234.43
I0901 13:23:46.008282 139809518303232 replay_runner.py:36] Average training steps per second: 234.43
Steps executed: 78 Episode length: 78 Return: -498.86916222504675

Steps executed: 282 Episode length: 89 Return: -634.77693077946324
INFO:tensorflow:Starting iteration 1
I0901 13:23:50.337976 139809518303232 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 331.49
I0901 13:23:53.354947 139809518303232 replay_runner.py:36] Average training steps per second: 331.49

Steps executed: 249 Episode length: 103 Return: -228.8420417113654
INFO:tensorflow:Starting iteration 2

Steps executed: 233 Episode length: 127 Return: -170.64243111720498
INFO:tensorflow:Average training steps per second: 329.77
I0901 13:24:00.050906 139809518303232 replay_runner.py:36] Average training steps per second: 329.77
I0901 13:24:00.197687 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.62
INFO:tensorflow:Starting iteration 3
I0901 13:24:03.784406 139809518303232 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 330.83

Steps executed: 448 Episode length: 286 Return: 252.052395342293274
I0901 13:24:07.173765 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: 18.04
INFO:tensorflow:Starting iteration 4

Steps executed: 205 Episode length: 72 Return: -165.599729377762917
INFO:tensorflow:Average training steps per second: 336.02
I0901 13:24:13.725189 139809518303232 replay_runner.py:36] Average training steps per second: 336.02
I0901 13:24:13.844476 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.49
INFO:tensorflow:Starting iteration 5

Steps executed: 213 Episode length: 213 Return: -595.47619930255047
INFO:tensorflow:Average training steps per second: 318.57
I0901 13:24:20.517341 139809518303232 replay_runner.py:36] Average training steps per second: 318.57
I0901 13:24:20.650021 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -595.48
INFO:tensorflow:Starting iteration 6

Steps executed: 288 Episode length: 108 Return: -648.89423978483967
INFO:tensorflow:Average training steps per second: 318.89
I0901 13:24:27.301255 139809518303232 replay_runner.py:36] Average training steps per second: 318.89
I0901 13:24:27.466435 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -601.18
INFO:tensorflow:Starting iteration 7

Steps executed: 311 Episode length: 215 Return: -277.97343626010036
INFO:tensorflow:Average training steps per second: 307.22
I0901 13:24:34.169092 139809518303232 replay_runner.py:36] Average training steps per second: 307.22
I0901 13:24:34.388554 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -434.30
INFO:tensorflow:Starting iteration 8

Steps executed: 706 Episode length: 608 Return: -203.51365096277885
INFO:tensorflow:Average training steps per second: 290.75
I0901 13:24:41.267786 139809518303232 replay_runner.py:36] Average training steps per second: 290.75
I0901 13:24:42.455292 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.81
INFO:tensorflow:Starting iteration 9

Steps executed: 228 Episode length: 121 Return: -114.84409642986924
INFO:tensorflow:Average training steps per second: 306.59
I0901 13:24:49.227375 139809518303232 replay_runner.py:36] Average training steps per second: 306.59
I0901 13:24:49.347396 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.87
INFO:tensorflow:Starting iteration 10

Steps executed: 303 Episode length: 133 Return: -273.91973943993144
INFO:tensorflow:Average training steps per second: 302.51
I0901 13:24:56.104307 139809518303232 replay_runner.py:36] Average training steps per second: 302.51
I0901 13:24:56.303195 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -313.83
INFO:tensorflow:Starting iteration 11

Steps executed: 216 Episode length: 66 Return: -193.482832271617724
INFO:tensorflow:Average training steps per second: 302.33
I0901 13:25:03.092890 139809518303232 replay_runner.py:36] Average training steps per second: 302.33
I0901 13:25:03.192952 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.32
INFO:tensorflow:Starting iteration 12

Steps executed: 384 Episode length: 384 Return: -188.21353126347503
INFO:tensorflow:Average training steps per second: 308.93
I0901 13:25:09.895696 139809518303232 replay_runner.py:36] Average training steps per second: 308.93
I0901 13:25:10.302793 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.21
INFO:tensorflow:Starting iteration 13

Steps executed: 219 Episode length: 219 Return: -138.13354618255937
INFO:tensorflow:Average training steps per second: 304.26
I0901 13:25:17.058844 139809518303232 replay_runner.py:36] Average training steps per second: 304.26
I0901 13:25:17.227477 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.13
INFO:tensorflow:Starting iteration 14

Steps executed: 249 Episode length: 249 Return: -404.88783289380437
INFO:tensorflow:Average training steps per second: 308.08
I0901 13:25:23.957779 139809518303232 replay_runner.py:36] Average training steps per second: 308.08
I0901 13:25:24.185091 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -404.89
INFO:tensorflow:Starting iteration 15

Steps executed: 308 Episode length: 109 Return: -57.452383962896967
INFO:tensorflow:Average training steps per second: 309.06
I0901 13:25:30.910224 139809518303232 replay_runner.py:36] Average training steps per second: 309.06
I0901 13:25:31.083161 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.85
INFO:tensorflow:Starting iteration 16

Steps executed: 302 Episode length: 302 Return: -1076.6193512422974
INFO:tensorflow:Average training steps per second: 311.06
I0901 13:25:37.750984 139809518303232 replay_runner.py:36] Average training steps per second: 311.06
I0901 13:25:38.023303 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -1076.62
INFO:tensorflow:Starting iteration 17

Steps executed: 287 Episode length: 158 Return: -165.55002637688983
INFO:tensorflow:Average training steps per second: 314.49
I0901 13:25:44.635323 139809518303232 replay_runner.py:36] Average training steps per second: 314.49
I0901 13:25:44.828111 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.35
INFO:tensorflow:Starting iteration 18

Steps executed: 259 Episode length: 127 Return: -174.81111676771255
INFO:tensorflow:Average training steps per second: 306.25
I0901 13:25:51.556338 139809518303232 replay_runner.py:36] Average training steps per second: 306.25
I0901 13:25:51.716836 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.13
INFO:tensorflow:Starting iteration 19

Steps executed: 212 Episode length: 108 Return: -98.960116248022655
INFO:tensorflow:Average training steps per second: 310.20
I0901 13:25:58.259810 139809518303232 replay_runner.py:36] Average training steps per second: 310.20
I0901 13:25:58.395117 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -419.34
INFO:tensorflow:Starting iteration 20

Steps executed: 158 Episode length: 158 Return: 32.8395358561934645
INFO:tensorflow:Average training steps per second: 298.48
I0901 13:26:05.092964 139809518303232 replay_runner.py:36] Average training steps per second: 298.48

Steps executed: 231 Episode length: 73 Return: -49.1336961675401645
INFO:tensorflow:Starting iteration 21

Steps executed: 275 Episode length: 84 Return: -626.050566809787545
INFO:tensorflow:Average training steps per second: 308.00
I0901 13:26:11.863105 139809518303232 replay_runner.py:36] Average training steps per second: 308.00
I0901 13:26:12.035570 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -369.81
INFO:tensorflow:Starting iteration 22

Steps executed: 245 Episode length: 96 Return: -705.092048173963845
INFO:tensorflow:Average training steps per second: 319.36
I0901 13:26:18.461189 139809518303232 replay_runner.py:36] Average training steps per second: 319.36
I0901 13:26:18.605294 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -429.90
INFO:tensorflow:Starting iteration 23

Steps executed: 200 Episode length: 200 Return: -329.82942131859284
INFO:tensorflow:Average training steps per second: 339.26
I0901 13:26:24.692914 139809518303232 replay_runner.py:36] Average training steps per second: 339.26
I0901 13:26:24.815374 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.83
INFO:tensorflow:Starting iteration 24

Steps executed: 258 Episode length: 106 Return: -153.27148949529578
INFO:tensorflow:Average training steps per second: 340.37
I0901 13:26:30.898755 139809518303232 replay_runner.py:36] Average training steps per second: 340.37
I0901 13:26:31.024665 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -305.16
INFO:tensorflow:Starting iteration 25

Steps executed: 257 Episode length: 144 Return: -248.72634877439168
INFO:tensorflow:Average training steps per second: 344.79
I0901 13:26:37.108949 139809518303232 replay_runner.py:36] Average training steps per second: 344.79
I0901 13:26:37.256972 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -272.35
INFO:tensorflow:Starting iteration 26

Steps executed: 547 Episode length: 399 Return: 45.1743618656617574
INFO:tensorflow:Average training steps per second: 374.17
I0901 13:26:42.992163 139809518303232 replay_runner.py:36] Average training steps per second: 374.17
I0901 13:26:43.450381 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.58
INFO:tensorflow:Starting iteration 27

Steps executed: 201 Episode length: 96 Return: -397.606566442401714
INFO:tensorflow:Average training steps per second: 381.26
I0901 13:26:49.314959 139809518303232 replay_runner.py:36] Average training steps per second: 381.26
I0901 13:26:49.429728 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -401.68
INFO:tensorflow:Starting iteration 28
I0901 13:26:52.663777 139809518303232 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 351.28

Steps executed: 301 Episode length: 113 Return: -371.92743481110434
I0901 13:26:55.703656 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -316.70
INFO:tensorflow:Starting iteration 29

Steps executed: 239 Episode length: 239 Return: -184.72335268123345
INFO:tensorflow:Average training steps per second: 342.24
I0901 13:27:01.803050 139809518303232 replay_runner.py:36] Average training steps per second: 342.24

Done fixed training!Episode length: 239 Return: -184.72335268123345