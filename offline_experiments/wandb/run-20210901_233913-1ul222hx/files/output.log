Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0901 23:39:20.421446 140183943698432 run_experiment.py:549] Creating TrainRunner ...
I0901 23:39:20.432978 140183943698432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:39:20.433297 140183943698432 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:39:20.433415 140183943698432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:39:20.433539 140183943698432 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:39:20.433637 140183943698432 dqn_agent.py:275] 	 update_period: 4
I0901 23:39:20.433953 140183943698432 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:39:20.434077 140183943698432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:39:20.434210 140183943698432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:39:20.434288 140183943698432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:39:20.434360 140183943698432 dqn_agent.py:280] 	 optimizer: adam
I0901 23:39:20.434546 140183943698432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:39:20.434725 140183943698432 dqn_agent.py:283] 	 seed: 1630539560432894
I0901 23:39:20.437810 140183943698432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:39:20.437984 140183943698432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:39:20.438085 140183943698432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:39:20.438230 140183943698432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:39:20.438324 140183943698432 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:39:20.438380 140183943698432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:39:20.438434 140183943698432 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:39:20.438534 140183943698432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:39:20.438605 140183943698432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:39:20.471508 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:20.825870 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:20.839019 140183943698432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:39:20.847577 140183943698432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:39:20.847828 140183943698432 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:39:20.848050 140183943698432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:39:20.848226 140183943698432 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:39:20.848331 140183943698432 dqn_agent.py:275] 	 update_period: 4
I0901 23:39:20.848407 140183943698432 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:39:20.848533 140183943698432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:39:20.848649 140183943698432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:39:20.848810 140183943698432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:39:20.848993 140183943698432 dqn_agent.py:280] 	 optimizer: adam
I0901 23:39:20.849110 140183943698432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:39:20.849335 140183943698432 dqn_agent.py:283] 	 seed: 1630539560847529
I0901 23:39:20.852303 140183943698432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:39:20.852456 140183943698432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:39:20.852553 140183943698432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:39:20.852619 140183943698432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:39:20.852677 140183943698432 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:39:20.852764 140183943698432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:39:20.852819 140183943698432 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:39:20.852920 140183943698432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:39:20.853064 140183943698432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:39:20.879486 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:20.899252 140183943698432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:39:20.899456 140183943698432 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 164.18
I0901 23:39:26.990432 140183943698432 replay_runner.py:36] Average training steps per second: 164.18
Steps executed: 256 Episode length: 63 Return: -590.5223345097128
I0901 23:39:28.253236 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -523.54
INFO:tensorflow:Starting iteration 1

Steps executed: 220 Episode length: 59 Return: -548.8317265189906
INFO:tensorflow:Average training steps per second: 217.80
I0901 23:39:37.191215 140183943698432 replay_runner.py:36] Average training steps per second: 217.80
I0901 23:39:37.388952 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -711.38
INFO:tensorflow:Starting iteration 2

Steps executed: 254 Episode length: 82 Return: -770.2593833054815
INFO:tensorflow:Average training steps per second: 218.21
I0901 23:39:46.361345 140183943698432 replay_runner.py:36] Average training steps per second: 218.21
I0901 23:39:46.590999 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -547.32
INFO:tensorflow:Starting iteration 3

Steps executed: 264 Episode length: 81 Return: -762.9572387443149
INFO:tensorflow:Average training steps per second: 218.62
I0901 23:39:55.507384 140183943698432 replay_runner.py:36] Average training steps per second: 218.62
I0901 23:39:55.730762 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -591.93
INFO:tensorflow:Starting iteration 4

Steps executed: 233 Episode length: 56 Return: -510.84847280713103
INFO:tensorflow:Average training steps per second: 211.74
I0901 23:40:04.705137 140183943698432 replay_runner.py:36] Average training steps per second: 211.74
I0901 23:40:04.920122 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -472.41
INFO:tensorflow:Starting iteration 5

Steps executed: 231 Episode length: 54 Return: -479.26389163869106
INFO:tensorflow:Average training steps per second: 226.02
I0901 23:40:13.706968 140183943698432 replay_runner.py:36] Average training steps per second: 226.02
I0901 23:40:13.912106 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -480.94
INFO:tensorflow:Starting iteration 6

Steps executed: 271 Episode length: 135 Return: -820.0202771137969
INFO:tensorflow:Average training steps per second: 219.29
I0901 23:40:22.815547 140183943698432 replay_runner.py:36] Average training steps per second: 219.29
I0901 23:40:23.094836 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -707.96
INFO:tensorflow:Starting iteration 7

Steps executed: 93 Episode length: 93 Return: -570.818759871821869
INFO:tensorflow:Average training steps per second: 218.27
I0901 23:40:32.051599 140183943698432 replay_runner.py:36] Average training steps per second: 218.27

Steps executed: 247 Episode length: 154 Return: -1130.3948238039684
INFO:tensorflow:Starting iteration 8

Steps executed: 206 Episode length: 105 Return: -730.07062905471754
INFO:tensorflow:Average training steps per second: 218.55
I0901 23:40:41.231187 140183943698432 replay_runner.py:36] Average training steps per second: 218.55
I0901 23:40:41.433747 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -759.04
INFO:tensorflow:Starting iteration 9
I0901 23:40:45.760051 140183943698432 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 216.71

Steps executed: 371 Episode length: 371 Return: -3472.0762236697284
I0901 23:40:51.133268 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -3472.08
INFO:tensorflow:Starting iteration 10

Steps executed: 323 Episode length: 128 Return: -916.35705302017188
INFO:tensorflow:Average training steps per second: 229.35
I0901 23:40:59.883280 140183943698432 replay_runner.py:36] Average training steps per second: 229.35
I0901 23:41:00.230620 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -1077.57
INFO:tensorflow:Starting iteration 11

Steps executed: 248 Episode length: 149 Return: -809.69178460617888
INFO:tensorflow:Average training steps per second: 227.74
I0901 23:41:08.938324 140183943698432 replay_runner.py:36] Average training steps per second: 227.74
I0901 23:41:09.173917 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -786.23
INFO:tensorflow:Starting iteration 12

Steps executed: 391 Episode length: 276 Return: -2490.9955706506578
INFO:tensorflow:Average training steps per second: 233.77
I0901 23:41:17.843194 140183943698432 replay_runner.py:36] Average training steps per second: 233.77
I0901 23:41:18.325735 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -1657.45
INFO:tensorflow:Starting iteration 13

Steps executed: 254 Episode length: 84 Return: -633.996383134011278
INFO:tensorflow:Average training steps per second: 226.57
I0901 23:41:26.955984 140183943698432 replay_runner.py:36] Average training steps per second: 226.57
I0901 23:41:27.172757 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -510.10
INFO:tensorflow:Starting iteration 14

Steps executed: 248 Episode length: 76 Return: -504.174449179947948
INFO:tensorflow:Average training steps per second: 231.54
I0901 23:41:35.614832 140183943698432 replay_runner.py:36] Average training steps per second: 231.54
I0901 23:41:35.826379 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -511.92
INFO:tensorflow:Starting iteration 15

Steps executed: 79 Episode length: 79 Return: -443.2833371135112948
INFO:tensorflow:Average training steps per second: 225.90

Steps executed: 324 Episode length: 245 Return: -2373.5618848515418
I0901 23:41:44.739470 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -1408.42
INFO:tensorflow:Starting iteration 16

Steps executed: 213 Episode length: 84 Return: -390.454042048726928
INFO:tensorflow:Average training steps per second: 222.60
I0901 23:41:53.576466 140183943698432 replay_runner.py:36] Average training steps per second: 222.60
I0901 23:41:53.789175 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -639.74
INFO:tensorflow:Starting iteration 17

Steps executed: 294 Episode length: 114 Return: -565.16207792469058
INFO:tensorflow:Average training steps per second: 223.93
I0901 23:42:02.401354 140183943698432 replay_runner.py:36] Average training steps per second: 223.93
I0901 23:42:02.696171 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -561.78
INFO:tensorflow:Starting iteration 18

Steps executed: 223 Episode length: 223 Return: -1442.3162231477838
INFO:tensorflow:Average training steps per second: 217.51
I0901 23:42:11.669955 140183943698432 replay_runner.py:36] Average training steps per second: 217.51
I0901 23:42:11.937112 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -1442.32
INFO:tensorflow:Starting iteration 19
I0901 23:42:16.385475 140183943698432 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 226.46

Steps executed: 208 Episode length: 76 Return: -417.823815741676478
I0901 23:42:21.014729 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -601.92
INFO:tensorflow:Starting iteration 20

Steps executed: 211 Episode length: 102 Return: -573.59578268397428
INFO:tensorflow:Average training steps per second: 222.66
I0901 23:42:29.841876 140183943698432 replay_runner.py:36] Average training steps per second: 222.66
I0901 23:42:30.055556 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -638.54
INFO:tensorflow:Starting iteration 21
I0901 23:42:34.343980 140183943698432 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 226.03

Steps executed: 249 Episode length: 84 Return: -466.229601558325328
I0901 23:42:39.005797 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -484.34
INFO:tensorflow:Starting iteration 22

Steps executed: 265 Episode length: 97 Return: -570.275622946504128
INFO:tensorflow:Average training steps per second: 221.33
I0901 23:42:47.904182 140183943698432 replay_runner.py:36] Average training steps per second: 221.33
I0901 23:42:48.156549 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -554.45
INFO:tensorflow:Starting iteration 23
I0901 23:42:52.539442 140183943698432 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 223.28

Steps executed: 249 Episode length: 249 Return: -1963.9838838685946
I0901 23:42:57.344602 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -1963.98
INFO:tensorflow:Starting iteration 24
I0901 23:43:01.764855 140183943698432 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 223.01
I0901 23:43:06.249431 140183943698432 replay_runner.py:36] Average training steps per second: 223.01

Steps executed: 325 Episode length: 325 Return: -3021.5587195255916
INFO:tensorflow:Starting iteration 25

Steps executed: 240 Episode length: 123 Return: -572.83542991378416
INFO:tensorflow:Average training steps per second: 222.00
I0901 23:43:15.678483 140183943698432 replay_runner.py:36] Average training steps per second: 222.00
I0901 23:43:15.918366 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -687.26
INFO:tensorflow:Starting iteration 26

Steps executed: 244 Episode length: 78 Return: -554.533757965171316
INFO:tensorflow:Average training steps per second: 223.77
I0901 23:43:24.779165 140183943698432 replay_runner.py:36] Average training steps per second: 223.77
I0901 23:43:25.015522 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -528.93
INFO:tensorflow:Starting iteration 27

Steps executed: 248 Episode length: 79 Return: -438.404075170903116
INFO:tensorflow:Average training steps per second: 223.44
I0901 23:43:33.903083 140183943698432 replay_runner.py:36] Average training steps per second: 223.44
I0901 23:43:34.138674 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -571.09
INFO:tensorflow:Starting iteration 28

Steps executed: 232 Episode length: 82 Return: -537.931133404326556
INFO:tensorflow:Average training steps per second: 221.38
I0901 23:43:43.092147 140183943698432 replay_runner.py:36] Average training steps per second: 221.38
I0901 23:43:43.332453 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -674.37
INFO:tensorflow:Starting iteration 29

Steps executed: 344 Episode length: 251 Return: -1902.2860838660647
INFO:tensorflow:Average training steps per second: 227.56
I0901 23:43:52.119341 140183943698432 replay_runner.py:36] Average training steps per second: 227.56

Done fixed training!Episode length: 251 Return: -1902.2860838660647