Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0901 23:39:11.160704 140252174653440 run_experiment.py:549] Creating TrainRunner ...
I0901 23:39:11.170956 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:39:11.171231 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:39:11.171388 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:39:11.171530 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:39:11.171685 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0901 23:39:11.171826 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:39:11.171943 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:39:11.172061 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:39:11.172173 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:39:11.172293 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0901 23:39:11.172406 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:39:11.172512 140252174653440 dqn_agent.py:283] 	 seed: 1630539551170882
I0901 23:39:11.175077 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:39:11.175256 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:39:11.175448 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:39:11.175550 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:39:11.175642 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:39:11.175735 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:39:11.175827 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:39:11.176039 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:39:11.176188 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:39:11.205521 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:11.568666 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:11.585458 140252174653440 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:39:11.597331 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:39:11.597585 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:39:11.597754 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:39:11.597881 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:39:11.598004 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0901 23:39:11.598130 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:39:11.598253 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:39:11.598952 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:39:11.599150 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:39:11.599310 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0901 23:39:11.599649 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:39:11.599781 140252174653440 dqn_agent.py:283] 	 seed: 1630539551597274
I0901 23:39:11.602367 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:39:11.602540 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:39:11.602883 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:39:11.603129 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:39:11.603272 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:39:11.603388 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:39:11.603756 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:39:11.603918 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:39:11.604102 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:39:11.634078 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:11.694824 140252174653440 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:39:11.695086 140252174653440 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 165.43
I0901 23:39:17.740231 140252174653440 replay_runner.py:36] Average training steps per second: 165.43
Steps executed: 259 Episode length: 84 Return: -756.3770440015359
I0901 23:39:18.901340 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -581.20
INFO:tensorflow:Starting iteration 1

Steps executed: 263 Episode length: 64 Return: -611.7671372688096
INFO:tensorflow:Average training steps per second: 225.17
I0901 23:39:27.762382 140252174653440 replay_runner.py:36] Average training steps per second: 225.17
I0901 23:39:28.004019 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -568.83
INFO:tensorflow:Starting iteration 2

Steps executed: 246 Episode length: 67 Return: -478.34738658334595
INFO:tensorflow:Average training steps per second: 221.62
I0901 23:39:36.930192 140252174653440 replay_runner.py:36] Average training steps per second: 221.62
I0901 23:39:37.155836 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -520.35
INFO:tensorflow:Starting iteration 3

Steps executed: 221 Episode length: 65 Return: -619.61942576403495
INFO:tensorflow:Average training steps per second: 223.07
I0901 23:39:46.061977 140252174653440 replay_runner.py:36] Average training steps per second: 223.07
I0901 23:39:46.256739 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -667.58
INFO:tensorflow:Starting iteration 4

Steps executed: 243 Episode length: 78 Return: -684.23369216957587
INFO:tensorflow:Average training steps per second: 223.87
I0901 23:39:55.010152 140252174653440 replay_runner.py:36] Average training steps per second: 223.87
I0901 23:39:55.213628 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -508.03
INFO:tensorflow:Starting iteration 5

Steps executed: 236 Episode length: 81 Return: -710.32676491276917
INFO:tensorflow:Average training steps per second: 215.44
I0901 23:40:04.193665 140252174653440 replay_runner.py:36] Average training steps per second: 215.44
I0901 23:40:04.432929 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -754.05
INFO:tensorflow:Starting iteration 6

Steps executed: 247 Episode length: 54 Return: -393.33808837036264
INFO:tensorflow:Average training steps per second: 227.93
I0901 23:40:13.175254 140252174653440 replay_runner.py:36] Average training steps per second: 227.93
I0901 23:40:13.387844 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -545.69
INFO:tensorflow:Starting iteration 7

Steps executed: 229 Episode length: 56 Return: -420.22644867970916
INFO:tensorflow:Average training steps per second: 217.13
I0901 23:40:22.335072 140252174653440 replay_runner.py:36] Average training steps per second: 217.13
I0901 23:40:22.533625 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -446.97
INFO:tensorflow:Starting iteration 8

Steps executed: 262 Episode length: 142 Return: -704.5092319189136
INFO:tensorflow:Average training steps per second: 220.73
I0901 23:40:31.397855 140252174653440 replay_runner.py:36] Average training steps per second: 220.73
I0901 23:40:31.672194 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -731.19
INFO:tensorflow:Starting iteration 9

Steps executed: 238 Episode length: 79 Return: -524.52138208985926
INFO:tensorflow:Average training steps per second: 217.86
I0901 23:40:40.592901 140252174653440 replay_runner.py:36] Average training steps per second: 217.86
I0901 23:40:40.826338 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -504.29
INFO:tensorflow:Starting iteration 10

Steps executed: 249 Episode length: 78 Return: -427.402282857640562
INFO:tensorflow:Average training steps per second: 220.06
I0901 23:40:49.729837 140252174653440 replay_runner.py:36] Average training steps per second: 220.06
I0901 23:40:49.975812 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -864.67
INFO:tensorflow:Starting iteration 11

Steps executed: 272 Episode length: 77 Return: -590.953626639082642
INFO:tensorflow:Average training steps per second: 227.41
I0901 23:40:58.728426 140252174653440 replay_runner.py:36] Average training steps per second: 227.41
I0901 23:40:58.977987 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -594.33
INFO:tensorflow:Starting iteration 12

Steps executed: 214 Episode length: 117 Return: -797.29576684556732
INFO:tensorflow:Average training steps per second: 226.92
I0901 23:41:07.585965 140252174653440 replay_runner.py:36] Average training steps per second: 226.92
I0901 23:41:07.777947 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -740.22
INFO:tensorflow:Starting iteration 13

Steps executed: 238 Episode length: 83 Return: -499.085770263356952
INFO:tensorflow:Average training steps per second: 229.64
I0901 23:41:16.414729 140252174653440 replay_runner.py:36] Average training steps per second: 229.64
I0901 23:41:16.625581 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -471.62
INFO:tensorflow:Starting iteration 14

Steps executed: 85 Episode length: 85 Return: -712.1088557483017952
INFO:tensorflow:Average training steps per second: 230.92

Steps executed: 352 Episode length: 267 Return: -2172.6811205814265
I0901 23:41:25.623109 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -1442.39
INFO:tensorflow:Starting iteration 15

Steps executed: 217 Episode length: 127 Return: -951.98039897720415
INFO:tensorflow:Average training steps per second: 233.73
I0901 23:41:33.886790 140252174653440 replay_runner.py:36] Average training steps per second: 233.73
I0901 23:41:34.073650 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -783.27
INFO:tensorflow:Starting iteration 16

Steps executed: 277 Episode length: 110 Return: -713.41808323060465
INFO:tensorflow:Average training steps per second: 234.58
I0901 23:41:42.444082 140252174653440 replay_runner.py:36] Average training steps per second: 234.58
I0901 23:41:42.699582 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -591.81
INFO:tensorflow:Starting iteration 17
I0901 23:41:46.995788 140252174653440 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 224.73

Steps executed: 265 Episode length: 85 Return: -627.959273628349525
I0901 23:41:51.701569 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -653.58
INFO:tensorflow:Starting iteration 18

Steps executed: 271 Episode length: 82 Return: -428.811153624325245
INFO:tensorflow:Average training steps per second: 222.20
I0901 23:42:00.542482 140252174653440 replay_runner.py:36] Average training steps per second: 222.20
I0901 23:42:00.803379 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -529.00
INFO:tensorflow:Starting iteration 19
I0901 23:42:05.112949 140252174653440 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 225.95

Steps executed: 237 Episode length: 106 Return: -773.04441537280555
I0901 23:42:09.791431 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -751.23
INFO:tensorflow:Starting iteration 20

Steps executed: 271 Episode length: 86 Return: -483.300237374326235
INFO:tensorflow:Average training steps per second: 226.02
I0901 23:42:18.666223 140252174653440 replay_runner.py:36] Average training steps per second: 226.02
I0901 23:42:18.941534 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -508.12
INFO:tensorflow:Starting iteration 21

Steps executed: 258 Episode length: 160 Return: -908.60949559585675
INFO:tensorflow:Average training steps per second: 223.01
I0901 23:42:27.820996 140252174653440 replay_runner.py:36] Average training steps per second: 223.01
I0901 23:42:28.098158 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -681.02
INFO:tensorflow:Starting iteration 22

Steps executed: 224 Episode length: 80 Return: -399.873179152648455
INFO:tensorflow:Average training steps per second: 227.86
I0901 23:42:36.868530 140252174653440 replay_runner.py:36] Average training steps per second: 227.86
I0901 23:42:37.090006 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -660.13
INFO:tensorflow:Starting iteration 23

Steps executed: 231 Episode length: 77 Return: -559.334459484224255
INFO:tensorflow:Average training steps per second: 218.48
I0901 23:42:45.968534 140252174653440 replay_runner.py:36] Average training steps per second: 218.48
I0901 23:42:46.184621 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -478.60
INFO:tensorflow:Starting iteration 24

Steps executed: 262 Episode length: 186 Return: -953.70370695513725
INFO:tensorflow:Average training steps per second: 224.85
I0901 23:42:54.985142 140252174653440 replay_runner.py:36] Average training steps per second: 224.85
I0901 23:42:55.267959 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -760.64
INFO:tensorflow:Starting iteration 25

Steps executed: 247 Episode length: 157 Return: -1101.9772542555047
INFO:tensorflow:Average training steps per second: 224.55
I0901 23:43:04.099644 140252174653440 replay_runner.py:36] Average training steps per second: 224.55
I0901 23:43:04.350851 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -873.08
INFO:tensorflow:Starting iteration 26
I0901 23:43:08.725124 140252174653440 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 225.24

Steps executed: 558 Episode length: 374 Return: -3535.9943313485397
I0901 23:43:14.081637 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -2359.94
INFO:tensorflow:Starting iteration 27

Steps executed: 280 Episode length: 153 Return: -997.22531670219677
INFO:tensorflow:Average training steps per second: 224.34
I0901 23:43:22.916468 140252174653440 replay_runner.py:36] Average training steps per second: 224.34
I0901 23:43:23.206610 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -983.35
INFO:tensorflow:Starting iteration 28

Steps executed: 396 Episode length: 289 Return: -2885.8702291755167
INFO:tensorflow:Average training steps per second: 227.53
I0901 23:43:32.017916 140252174653440 replay_runner.py:36] Average training steps per second: 227.53
I0901 23:43:32.540896 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -1748.09
INFO:tensorflow:Starting iteration 29
I0901 23:43:36.924870 140252174653440 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 222.80

Steps executed: 270 Episode length: 83 Return: -613.723451765380267

Done fixed training!Episode length: 83 Return: -613.723451765380267