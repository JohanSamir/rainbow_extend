Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0828 10:32:47.114298 140220309850112 run_experiment.py:549] Creating TrainRunner ...
I0828 10:32:47.125726 140220309850112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:47.125910 140220309850112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:47.126017 140220309850112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:47.126082 140220309850112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:47.126159 140220309850112 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:47.126217 140220309850112 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:47.126338 140220309850112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:47.126446 140220309850112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:47.126531 140220309850112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:47.126614 140220309850112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:47.126687 140220309850112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:47.126756 140220309850112 dqn_agent.py:283] 	 seed: 1630146767125667
I0828 10:32:47.130610 140220309850112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:47.130863 140220309850112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:47.130980 140220309850112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:47.131144 140220309850112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:47.131325 140220309850112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:47.131425 140220309850112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:47.131500 140220309850112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:47.131579 140220309850112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:47.131694 140220309850112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:47.166801 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:47.539114 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:47.553909 140220309850112 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:32:47.563099 140220309850112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:47.563349 140220309850112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:47.563466 140220309850112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:47.563532 140220309850112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:47.563617 140220309850112 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:47.564114 140220309850112 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:47.564273 140220309850112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:47.564717 140220309850112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:47.564840 140220309850112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:47.564946 140220309850112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:47.565069 140220309850112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:47.565159 140220309850112 dqn_agent.py:283] 	 seed: 1630146767563053
I0828 10:32:47.568087 140220309850112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:47.568344 140220309850112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:47.568498 140220309850112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:47.568681 140220309850112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:47.568826 140220309850112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:47.568963 140220309850112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:47.569066 140220309850112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:47.569147 140220309850112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:47.569221 140220309850112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:47.622595 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:47.659481 140220309850112 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:32:47.659753 140220309850112 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 170.07
I0828 10:32:53.540190 140220309850112 replay_runner.py:36] Average training steps per second: 170.07
Steps executed: 209 Episode length: 51 Return: -345.47414324695586
I0828 10:32:54.993179 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -626.71
INFO:tensorflow:Starting iteration 1

Steps executed: 236 Episode length: 85 Return: -249.58381097015115
INFO:tensorflow:Average training steps per second: 226.68
I0828 10:33:03.650506 140220309850112 replay_runner.py:36] Average training steps per second: 226.68
I0828 10:33:03.865361 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.51
INFO:tensorflow:Starting iteration 2

Steps executed: 113 Episode length: 56 Return: -562.99345976494945
INFO:tensorflow:Average training steps per second: 226.27

Steps executed: 245 Episode length: 51 Return: -339.80777691253225
I0828 10:33:12.832386 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -506.71
INFO:tensorflow:Starting iteration 3

Steps executed: 225 Episode length: 78 Return: -542.12838682906615
INFO:tensorflow:Average training steps per second: 233.73
I0828 10:33:21.321262 140220309850112 replay_runner.py:36] Average training steps per second: 233.73
I0828 10:33:21.516206 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -602.06
INFO:tensorflow:Starting iteration 4

Steps executed: 241 Episode length: 78 Return: -745.47171517405045
INFO:tensorflow:Average training steps per second: 234.38
I0828 10:33:30.088890 140220309850112 replay_runner.py:36] Average training steps per second: 234.38
I0828 10:33:30.292829 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -717.95
INFO:tensorflow:Starting iteration 5

Steps executed: 60 Episode length: 60 Return: -308.661485889816445
INFO:tensorflow:Average training steps per second: 234.59

Steps executed: 255 Episode length: 64 Return: -653.21400963945115
I0828 10:33:39.050712 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -551.01
INFO:tensorflow:Starting iteration 6

Steps executed: 391 Episode length: 202 Return: -1293.3652453944542
INFO:tensorflow:Average training steps per second: 234.35
I0828 10:33:47.555183 140220309850112 replay_runner.py:36] Average training steps per second: 234.35
I0828 10:33:47.995198 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -1300.57
INFO:tensorflow:Starting iteration 7

Steps executed: 288 Episode length: 132 Return: -632.54638704372235
INFO:tensorflow:Average training steps per second: 232.09
I0828 10:33:56.571073 140220309850112 replay_runner.py:36] Average training steps per second: 232.09
I0828 10:33:56.861793 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -890.94
INFO:tensorflow:Starting iteration 8

Steps executed: 230 Episode length: 79 Return: -685.294695509561835
INFO:tensorflow:Average training steps per second: 244.24
I0828 10:34:05.229887 140220309850112 replay_runner.py:36] Average training steps per second: 244.24
I0828 10:34:05.428722 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -625.98
INFO:tensorflow:Starting iteration 9

Steps executed: 229 Episode length: 54 Return: -433.965306578055335
INFO:tensorflow:Average training steps per second: 223.40
I0828 10:34:14.040999 140220309850112 replay_runner.py:36] Average training steps per second: 223.40
I0828 10:34:14.231417 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -462.84
INFO:tensorflow:Starting iteration 10

Steps executed: 222 Episode length: 81 Return: -753.126082981620835
INFO:tensorflow:Average training steps per second: 223.84
I0828 10:34:22.913376 140220309850112 replay_runner.py:36] Average training steps per second: 223.84
I0828 10:34:23.119720 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -658.87
INFO:tensorflow:Starting iteration 11

Steps executed: 249 Episode length: 55 Return: -490.864585365626335
INFO:tensorflow:Average training steps per second: 224.92
I0828 10:34:31.831509 140220309850112 replay_runner.py:36] Average training steps per second: 224.92
I0828 10:34:32.070971 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -596.35
INFO:tensorflow:Starting iteration 12

Steps executed: 239 Episode length: 147 Return: -736.89350887589225
INFO:tensorflow:Average training steps per second: 229.01
I0828 10:34:40.852114 140220309850112 replay_runner.py:36] Average training steps per second: 229.01
I0828 10:34:41.121056 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -695.07
INFO:tensorflow:Starting iteration 13

Steps executed: 242 Episode length: 64 Return: -514.301113508685845
INFO:tensorflow:Average training steps per second: 230.28
I0828 10:34:49.861809 140220309850112 replay_runner.py:36] Average training steps per second: 230.28
I0828 10:34:50.083733 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -505.15
INFO:tensorflow:Starting iteration 14

Steps executed: 262 Episode length: 67 Return: -568.101994319973845
INFO:tensorflow:Average training steps per second: 226.89
I0828 10:34:58.846966 140220309850112 replay_runner.py:36] Average training steps per second: 226.89
I0828 10:34:59.104326 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -533.19
INFO:tensorflow:Starting iteration 15

Steps executed: 204 Episode length: 63 Return: -523.935141464954545
INFO:tensorflow:Average training steps per second: 229.32
I0828 10:35:07.895184 140220309850112 replay_runner.py:36] Average training steps per second: 229.32
I0828 10:35:08.088969 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -584.49
INFO:tensorflow:Starting iteration 16

Steps executed: 223 Episode length: 70 Return: -496.748746645562645
INFO:tensorflow:Average training steps per second: 231.00
I0828 10:35:16.729424 140220309850112 replay_runner.py:36] Average training steps per second: 231.00
I0828 10:35:16.941167 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -680.03
INFO:tensorflow:Starting iteration 17

Steps executed: 271 Episode length: 76 Return: -822.856208799219345
INFO:tensorflow:Average training steps per second: 233.48
I0828 10:35:25.643489 140220309850112 replay_runner.py:36] Average training steps per second: 233.48
I0828 10:35:25.895592 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -641.05
INFO:tensorflow:Starting iteration 18

Steps executed: 206 Episode length: 72 Return: -486.505147525990345
INFO:tensorflow:Average training steps per second: 233.96
I0828 10:35:34.612143 140220309850112 replay_runner.py:36] Average training steps per second: 233.96
I0828 10:35:34.796447 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -594.10
INFO:tensorflow:Starting iteration 19

Steps executed: 248 Episode length: 70 Return: -494.950546303921565
INFO:tensorflow:Average training steps per second: 225.99
I0828 10:35:43.718369 140220309850112 replay_runner.py:36] Average training steps per second: 225.99
I0828 10:35:43.947304 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -479.23
INFO:tensorflow:Starting iteration 20

Steps executed: 267 Episode length: 69 Return: -685.866285300789999
INFO:tensorflow:Average training steps per second: 230.87
I0828 10:35:52.566335 140220309850112 replay_runner.py:36] Average training steps per second: 230.87
I0828 10:35:52.814995 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -737.69
INFO:tensorflow:Starting iteration 21

Steps executed: 251 Episode length: 53 Return: -495.141427829754269
INFO:tensorflow:Average training steps per second: 239.79
I0828 10:36:01.360738 140220309850112 replay_runner.py:36] Average training steps per second: 239.79
I0828 10:36:01.580639 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -568.11
INFO:tensorflow:Starting iteration 22

Steps executed: 234 Episode length: 58 Return: -513.523646226565269
INFO:tensorflow:Average training steps per second: 242.26
I0828 10:36:10.208158 140220309850112 replay_runner.py:36] Average training steps per second: 242.26
I0828 10:36:10.418486 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -496.98
INFO:tensorflow:Starting iteration 23

Steps executed: 272 Episode length: 76 Return: -679.645153024631769
INFO:tensorflow:Average training steps per second: 246.83
I0828 10:36:18.840674 140220309850112 replay_runner.py:36] Average training steps per second: 246.83
I0828 10:36:19.074906 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -587.43
INFO:tensorflow:Starting iteration 24

Steps executed: 236 Episode length: 57 Return: -403.001286838385869
INFO:tensorflow:Average training steps per second: 249.93
I0828 10:36:27.417668 140220309850112 replay_runner.py:36] Average training steps per second: 249.93
I0828 10:36:27.600366 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -464.16
INFO:tensorflow:Starting iteration 25

Steps executed: 247 Episode length: 72 Return: -675.143305412626239
INFO:tensorflow:Average training steps per second: 240.11
I0828 10:36:36.019261 140220309850112 replay_runner.py:36] Average training steps per second: 240.11
I0828 10:36:36.217900 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -526.54
INFO:tensorflow:Starting iteration 26

Steps executed: 263 Episode length: 75 Return: -728.668333269272259
INFO:tensorflow:Average training steps per second: 239.01
I0828 10:36:44.745329 140220309850112 replay_runner.py:36] Average training steps per second: 239.01
I0828 10:36:44.970751 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -637.64
INFO:tensorflow:Starting iteration 27
I0828 10:36:49.222676 140220309850112 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 238.75

Steps executed: 277 Episode length: 80 Return: -588.174847490096959
I0828 10:36:53.673567 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -593.80
INFO:tensorflow:Starting iteration 28

Steps executed: 291 Episode length: 122 Return: -593.82372987840389
INFO:tensorflow:Average training steps per second: 242.37
I0828 10:37:02.265023 140220309850112 replay_runner.py:36] Average training steps per second: 242.37
I0828 10:37:02.543416 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -734.31
INFO:tensorflow:Starting iteration 29

Steps executed: 208 Episode length: 86 Return: -967.180292146052469
INFO:tensorflow:Average training steps per second: 232.60
I0828 10:37:11.223364 140220309850112 replay_runner.py:36] Average training steps per second: 232.60

Done fixed training!Episode length: 86 Return: -967.180292146052469