Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0903 00:12:25.438328 140310902786048 run_experiment.py:549] Creating TrainRunner ...
I0903 00:12:25.444989 140310902786048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:12:25.445108 140310902786048 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:12:25.445170 140310902786048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:12:25.445252 140310902786048 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:12:25.445305 140310902786048 dqn_agent.py:275] 	 update_period: 4
I0903 00:12:25.445354 140310902786048 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:12:25.445416 140310902786048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:12:25.445508 140310902786048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:12:25.445571 140310902786048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:12:25.445632 140310902786048 dqn_agent.py:280] 	 optimizer: adam
I0903 00:12:25.445700 140310902786048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:12:25.445760 140310902786048 dqn_agent.py:283] 	 seed: 1630627945444961
I0903 00:12:25.447461 140310902786048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:12:25.447574 140310902786048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:12:25.447653 140310902786048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:12:25.447715 140310902786048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:12:25.447776 140310902786048 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:12:25.447846 140310902786048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:12:25.447921 140310902786048 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:12:25.448006 140310902786048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:12:25.448074 140310902786048 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:12:25.469910 140310902786048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:12:25.680350 140310902786048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:12:25.689796 140310902786048 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:12:25.695593 140310902786048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:12:25.695709 140310902786048 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:12:25.695784 140310902786048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:12:25.695857 140310902786048 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:12:25.695914 140310902786048 dqn_agent.py:275] 	 update_period: 4
I0903 00:12:25.695991 140310902786048 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:12:25.696047 140310902786048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:12:25.696124 140310902786048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:12:25.696177 140310902786048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:12:25.696222 140310902786048 dqn_agent.py:280] 	 optimizer: adam
I0903 00:12:25.696266 140310902786048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:12:25.696321 140310902786048 dqn_agent.py:283] 	 seed: 1630627945695569
I0903 00:12:25.697807 140310902786048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:12:25.697920 140310902786048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:12:25.698034 140310902786048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:12:25.698121 140310902786048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:12:25.698180 140310902786048 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:12:25.698259 140310902786048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:12:25.698319 140310902786048 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:12:25.698393 140310902786048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:12:25.698459 140310902786048 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:12:25.715468 140310902786048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:12:25.728269 140310902786048 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:12:25.728428 140310902786048 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 238.69
I0903 00:12:29.918119 140310902786048 replay_runner.py:36] Average training steps per second: 238.69
I0903 00:12:30.726628 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.65
Steps executed: 244 Episode length: 112 Return: -512.52002871137617
INFO:tensorflow:Starting iteration 1
I0903 00:12:33.928048 140310902786048 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 311.69
I0903 00:12:37.136686 140310902786048 replay_runner.py:36] Average training steps per second: 311.69

Steps executed: 376 Episode length: 183 Return: -453.89333160614457
INFO:tensorflow:Starting iteration 2
I0903 00:12:40.619765 140310902786048 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 326.42
I0903 00:12:43.683622 140310902786048 replay_runner.py:36] Average training steps per second: 326.42

Steps executed: 273 Episode length: 146 Return: -160.81332360912867
INFO:tensorflow:Starting iteration 3
I0903 00:12:47.136064 140310902786048 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 319.35
I0903 00:12:50.267718 140310902786048 replay_runner.py:36] Average training steps per second: 319.35

Steps executed: 260 Episode length: 260 Return: -352.89322948902367
INFO:tensorflow:Starting iteration 4

Steps executed: 108 Episode length: 108 Return: -358.73951771388637
INFO:tensorflow:Average training steps per second: 313.86

Steps executed: 508 Episode length: 400 Return: -382.31698915172467
I0903 00:12:57.476334 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -370.53
INFO:tensorflow:Starting iteration 5
I0903 00:13:00.627453 140310902786048 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 320.81

Steps executed: 1000 Episode length: 1000 Return: -15.192260534803918
I0903 00:13:05.846529 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -15.19
INFO:tensorflow:Starting iteration 6
I0903 00:13:09.177247 140310902786048 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 323.61

Steps executed: 1000 Episode length: 1000 Return: -7.6193188019231638
I0903 00:13:14.882229 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -7.62
INFO:tensorflow:Starting iteration 7
I0903 00:13:18.355424 140310902786048 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 353.11

Steps executed: 296 Episode length: 296 Return: -451.9861789533821638
I0903 00:13:21.423536 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -451.99
INFO:tensorflow:Starting iteration 8

Steps executed: 353 Episode length: 270 Return: -750.0971138949285638
INFO:tensorflow:Average training steps per second: 343.24
I0903 00:13:27.870282 140310902786048 replay_runner.py:36] Average training steps per second: 343.24
I0903 00:13:28.133779 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -699.49
INFO:tensorflow:Starting iteration 9
I0903 00:13:31.625425 140310902786048 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 330.01
I0903 00:13:34.655990 140310902786048 replay_runner.py:36] Average training steps per second: 330.01

Steps executed: 551 Episode length: 551 Return: -116.3475968015321238
INFO:tensorflow:Starting iteration 10

Steps executed: 361 Episode length: 361 Return: -119.8597119196988538
INFO:tensorflow:Average training steps per second: 332.11
I0903 00:13:41.765182 140310902786048 replay_runner.py:36] Average training steps per second: 332.11
I0903 00:13:42.119645 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.86
INFO:tensorflow:Starting iteration 11

Steps executed: 240 Episode length: 240 Return: -270.5250625935961538
INFO:tensorflow:Average training steps per second: 319.02
I0903 00:13:48.556972 140310902786048 replay_runner.py:36] Average training steps per second: 319.02
I0903 00:13:48.742569 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -270.53
INFO:tensorflow:Starting iteration 12
I0903 00:13:52.077148 140310902786048 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 330.98

Steps executed: 935 Episode length: 935 Return: -489.7251206505696538
I0903 00:13:57.015501 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -489.73
INFO:tensorflow:Starting iteration 13

Steps executed: 51 Episode length: 51 Return: -179.463788421336696538
INFO:tensorflow:Average training steps per second: 346.30
I0903 00:14:03.364010 140310902786048 replay_runner.py:36] Average training steps per second: 346.30

Steps executed: 257 Episode length: 111 Return: -182.4570089115312638
INFO:tensorflow:Starting iteration 14

Steps executed: 242 Episode length: 53 Return: -361.94837981275347638
INFO:tensorflow:Average training steps per second: 350.18
I0903 00:14:09.882264 140310902786048 replay_runner.py:36] Average training steps per second: 350.18
I0903 00:14:10.021235 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.42
INFO:tensorflow:Starting iteration 15

Steps executed: 219 Episode length: 53 Return: -132.72307370864843638
INFO:tensorflow:Average training steps per second: 368.90
I0903 00:14:16.306184 140310902786048 replay_runner.py:36] Average training steps per second: 368.90
I0903 00:14:16.422798 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.33
INFO:tensorflow:Starting iteration 16

Steps executed: 503 Episode length: 333 Return: -107.7373714037841138
INFO:tensorflow:Average training steps per second: 355.54
I0903 00:14:22.821767 140310902786048 replay_runner.py:36] Average training steps per second: 355.54
I0903 00:14:23.188506 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.74
INFO:tensorflow:Starting iteration 17
I0903 00:14:26.751504 140310902786048 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 353.96

Steps executed: 273 Episode length: 137 Return: -150.5005469465568838
I0903 00:14:29.715158 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.40
INFO:tensorflow:Starting iteration 18

Steps executed: 252 Episode length: 252 Return: -84.24465897634938838
INFO:tensorflow:Average training steps per second: 339.01
I0903 00:14:36.156078 140310902786048 replay_runner.py:36] Average training steps per second: 339.01
I0903 00:14:36.343363 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.24
INFO:tensorflow:Starting iteration 19

Steps executed: 367 Episode length: 367 Return: 240.22904968598888838
INFO:tensorflow:Average training steps per second: 345.46
I0903 00:14:42.718526 140310902786048 replay_runner.py:36] Average training steps per second: 345.46
I0903 00:14:43.041549 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: 240.23
INFO:tensorflow:Starting iteration 20
I0903 00:14:46.489531 140310902786048 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 331.33
I0903 00:14:49.508063 140310902786048 replay_runner.py:36] Average training steps per second: 331.33

Steps executed: 203 Episode length: 203 Return: -385.0088526017288838
INFO:tensorflow:Starting iteration 21

Steps executed: 229 Episode length: 90 Return: -314.11941339519075838
INFO:tensorflow:Average training steps per second: 337.46
I0903 00:14:56.100836 140310902786048 replay_runner.py:36] Average training steps per second: 337.46
I0903 00:14:56.218410 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.79
INFO:tensorflow:Starting iteration 22

Steps executed: 383 Episode length: 330 Return: -124.3885374733296938
INFO:tensorflow:Average training steps per second: 330.09
I0903 00:15:02.713435 140310902786048 replay_runner.py:36] Average training steps per second: 330.09
I0903 00:15:03.010211 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.03
INFO:tensorflow:Starting iteration 23
I0903 00:15:06.449203 140310902786048 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 328.80

Steps executed: 482 Episode length: 482 Return: -1168.041886545388538
I0903 00:15:10.021562 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -1168.04
INFO:tensorflow:Starting iteration 24

Steps executed: 287 Episode length: 128 Return: -114.5286921044145338
INFO:tensorflow:Average training steps per second: 338.82
I0903 00:15:16.411762 140310902786048 replay_runner.py:36] Average training steps per second: 338.82
I0903 00:15:16.572826 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.59
INFO:tensorflow:Starting iteration 25

Steps executed: 234 Episode length: 54 Return: -91.898491804314195338
INFO:tensorflow:Average training steps per second: 344.19
I0903 00:15:22.886340 140310902786048 replay_runner.py:36] Average training steps per second: 344.19
I0903 00:15:22.992373 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.59
INFO:tensorflow:Starting iteration 26

Steps executed: 206 Episode length: 92 Return: -585.00693228875985338
INFO:tensorflow:Average training steps per second: 335.36
I0903 00:15:29.435106 140310902786048 replay_runner.py:36] Average training steps per second: 335.36
I0903 00:15:29.548678 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -415.87
INFO:tensorflow:Starting iteration 27

Steps executed: 270 Episode length: 146 Return: -169.0195829859000638
INFO:tensorflow:Average training steps per second: 335.94
I0903 00:15:35.879573 140310902786048 replay_runner.py:36] Average training steps per second: 335.94
I0903 00:15:36.010798 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -241.16
INFO:tensorflow:Starting iteration 28

Steps executed: 234 Episode length: 133 Return: -585.3369625690757538
INFO:tensorflow:Average training steps per second: 325.40
I0903 00:15:42.214509 140310902786048 replay_runner.py:36] Average training steps per second: 325.40
I0903 00:15:42.350478 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -346.20
INFO:tensorflow:Starting iteration 29

Steps executed: 217 Episode length: 82 Return: -619.02989930653627538
INFO:tensorflow:Average training steps per second: 323.32
I0903 00:15:48.511778 140310902786048 replay_runner.py:36] Average training steps per second: 323.32

Done fixed training!Episode length: 82 Return: -619.02989930653627538