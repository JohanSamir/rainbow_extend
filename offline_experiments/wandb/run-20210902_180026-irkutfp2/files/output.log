Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0902 18:00:33.004150 140216164177920 run_experiment.py:549] Creating TrainRunner ...
I0902 18:00:33.015406 140216164177920 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:00:33.015629 140216164177920 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:00:33.015710 140216164177920 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:00:33.015824 140216164177920 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:00:33.015888 140216164177920 dqn_agent.py:275] 	 update_period: 4
I0902 18:00:33.016047 140216164177920 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:00:33.016119 140216164177920 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:00:33.016207 140216164177920 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:00:33.016290 140216164177920 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:00:33.016394 140216164177920 dqn_agent.py:280] 	 optimizer: adam
I0902 18:00:33.016465 140216164177920 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:00:33.016543 140216164177920 dqn_agent.py:283] 	 seed: 1630605633015351
I0902 18:00:33.019899 140216164177920 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:00:33.020213 140216164177920 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:00:33.020500 140216164177920 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:00:33.020632 140216164177920 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:00:33.020901 140216164177920 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:00:33.021014 140216164177920 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:00:33.021191 140216164177920 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:00:33.021328 140216164177920 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:00:33.021641 140216164177920 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:00:33.059401 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.500000
I0902 18:00:33.432970 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.500000
I0902 18:00:33.448092 140216164177920 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 18:00:33.457052 140216164177920 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 18:00:33.457283 140216164177920 dqn_agent.py:272] 	 gamma: 0.990000
I0902 18:00:33.457459 140216164177920 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 18:00:33.457594 140216164177920 dqn_agent.py:274] 	 min_replay_history: 500
I0902 18:00:33.457672 140216164177920 dqn_agent.py:275] 	 update_period: 4
I0902 18:00:33.457745 140216164177920 dqn_agent.py:276] 	 target_update_period: 300
I0902 18:00:33.457840 140216164177920 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 18:00:33.457920 140216164177920 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 18:00:33.457990 140216164177920 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 18:00:33.458083 140216164177920 dqn_agent.py:280] 	 optimizer: adam
I0902 18:00:33.458151 140216164177920 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 18:00:33.458220 140216164177920 dqn_agent.py:283] 	 seed: 1630605633457002
I0902 18:00:33.461765 140216164177920 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 18:00:33.462054 140216164177920 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 18:00:33.462206 140216164177920 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 18:00:33.462388 140216164177920 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 18:00:33.462541 140216164177920 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 18:00:33.462663 140216164177920 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 18:00:33.462879 140216164177920 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 18:00:33.462984 140216164177920 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 18:00:33.463156 140216164177920 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 18:00:33.538168 140216164177920 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.500000
I0902 18:00:33.562762 140216164177920 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 18:00:33.563004 140216164177920 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 166.96
I0902 18:00:39.552760 140216164177920 replay_runner.py:36] Average training steps per second: 166.96
I0902 18:00:40.812939 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -653.97
Steps executed: 271 Episode length: 79 Return: -616.33668673836625
INFO:tensorflow:Starting iteration 1

Steps executed: 261 Episode length: 90 Return: -318.79463712300325
INFO:tensorflow:Average training steps per second: 222.40
I0902 18:00:49.481192 140216164177920 replay_runner.py:36] Average training steps per second: 222.40
I0902 18:00:49.727043 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -419.83
INFO:tensorflow:Starting iteration 2

Steps executed: 231 Episode length: 117 Return: -445.4580454335296
INFO:tensorflow:Average training steps per second: 219.23
I0902 18:00:58.352001 140216164177920 replay_runner.py:36] Average training steps per second: 219.23
I0902 18:00:58.571565 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -555.98
INFO:tensorflow:Starting iteration 3

Steps executed: 294 Episode length: 116 Return: -477.2410015362613
INFO:tensorflow:Average training steps per second: 221.41
I0902 18:01:07.281413 140216164177920 replay_runner.py:36] Average training steps per second: 221.41
I0902 18:01:07.545670 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -543.77
INFO:tensorflow:Starting iteration 4

Steps executed: 141 Episode length: 141 Return: -699.5813416259552
INFO:tensorflow:Average training steps per second: 220.15

Steps executed: 252 Episode length: 111 Return: -688.5832053208715
I0902 18:01:16.759721 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -694.08
INFO:tensorflow:Starting iteration 5

Steps executed: 414 Episode length: 254 Return: -194.27641514328167
INFO:tensorflow:Average training steps per second: 218.57
I0902 18:01:25.635195 140216164177920 replay_runner.py:36] Average training steps per second: 218.57
I0902 18:01:26.077480 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -437.14
INFO:tensorflow:Starting iteration 6

Steps executed: 596 Episode length: 596 Return: -241.73743067668164
INFO:tensorflow:Average training steps per second: 222.13
I0902 18:01:34.885572 140216164177920 replay_runner.py:36] Average training steps per second: 222.13
I0902 18:01:35.958885 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -241.74
INFO:tensorflow:Starting iteration 7

Steps executed: 440 Episode length: 330 Return: -194.32160515285364
INFO:tensorflow:Average training steps per second: 214.01
I0902 18:01:44.982453 140216164177920 replay_runner.py:36] Average training steps per second: 214.01
I0902 18:01:45.455038 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -439.13
INFO:tensorflow:Starting iteration 8

Steps executed: 218 Episode length: 107 Return: -615.68950454367287
INFO:tensorflow:Average training steps per second: 218.59
I0902 18:01:54.404648 140216164177920 replay_runner.py:36] Average training steps per second: 218.59
I0902 18:01:54.590270 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -477.31
INFO:tensorflow:Starting iteration 9

Steps executed: 284 Episode length: 145 Return: -287.12094370933177
INFO:tensorflow:Average training steps per second: 232.42
I0902 18:02:03.229241 140216164177920 replay_runner.py:36] Average training steps per second: 232.42
I0902 18:02:03.469535 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.40
INFO:tensorflow:Starting iteration 10

Steps executed: 201 Episode length: 102 Return: -661.31605322067827
INFO:tensorflow:Average training steps per second: 225.90
I0902 18:02:12.023978 140216164177920 replay_runner.py:36] Average training steps per second: 225.90
I0902 18:02:12.188254 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -497.53
INFO:tensorflow:Starting iteration 11
I0902 18:02:16.453220 140216164177920 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 221.60

Steps executed: 214 Episode length: 214 Return: -189.25508601017842
I0902 18:02:21.192053 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.26
INFO:tensorflow:Starting iteration 12

Steps executed: 217 Episode length: 217 Return: -324.07035712315127
INFO:tensorflow:Average training steps per second: 222.70
I0902 18:02:30.015031 140216164177920 replay_runner.py:36] Average training steps per second: 222.70
I0902 18:02:30.266126 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -324.07
INFO:tensorflow:Starting iteration 13

Steps executed: 207 Episode length: 207 Return: -6.8857328623632417
INFO:tensorflow:Average training steps per second: 218.30
I0902 18:02:39.195962 140216164177920 replay_runner.py:36] Average training steps per second: 218.30
I0902 18:02:39.397422 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -6.89
INFO:tensorflow:Starting iteration 14

Steps executed: 209 Episode length: 209 Return: -63.524879143832955
INFO:tensorflow:Average training steps per second: 222.71
I0902 18:02:48.217164 140216164177920 replay_runner.py:36] Average training steps per second: 222.71
I0902 18:02:48.413131 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -63.52
INFO:tensorflow:Starting iteration 15

Steps executed: 205 Episode length: 99 Return: -229.226389692935132
INFO:tensorflow:Average training steps per second: 228.48
I0902 18:02:56.909512 140216164177920 replay_runner.py:36] Average training steps per second: 228.48
I0902 18:02:57.082197 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.07
INFO:tensorflow:Starting iteration 16

Steps executed: 338 Episode length: 180 Return: -381.25579501415582
INFO:tensorflow:Average training steps per second: 220.66
I0902 18:03:05.870604 140216164177920 replay_runner.py:36] Average training steps per second: 220.66
I0902 18:03:06.199192 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -451.80
INFO:tensorflow:Starting iteration 17

Steps executed: 272 Episode length: 124 Return: -244.58679840387606
INFO:tensorflow:Average training steps per second: 219.53
I0902 18:03:15.098291 140216164177920 replay_runner.py:36] Average training steps per second: 219.53
I0902 18:03:15.336891 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.10
INFO:tensorflow:Starting iteration 18

Steps executed: 364 Episode length: 207 Return: -273.45721166167556
INFO:tensorflow:Average training steps per second: 213.90
I0902 18:03:24.281249 140216164177920 replay_runner.py:36] Average training steps per second: 213.90
I0902 18:03:24.646464 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.25
INFO:tensorflow:Starting iteration 19

Steps executed: 328 Episode length: 151 Return: -325.85603020587325
INFO:tensorflow:Average training steps per second: 215.14
I0902 18:03:33.660022 140216164177920 replay_runner.py:36] Average training steps per second: 215.14
I0902 18:03:33.980438 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -204.61
INFO:tensorflow:Starting iteration 20
I0902 18:03:38.258343 140216164177920 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 214.26
I0902 18:03:42.925979 140216164177920 replay_runner.py:36] Average training steps per second: 214.26

Steps executed: 216 Episode length: 94 Return: -618.780075822702535
INFO:tensorflow:Starting iteration 21

Steps executed: 281 Episode length: 153 Return: -368.80535410959495
INFO:tensorflow:Average training steps per second: 217.24
I0902 18:03:51.917810 140216164177920 replay_runner.py:36] Average training steps per second: 217.24
I0902 18:03:52.165332 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -418.49
INFO:tensorflow:Starting iteration 22

Steps executed: 336 Episode length: 201 Return: -240.07312768802083
INFO:tensorflow:Average training steps per second: 217.71
I0902 18:04:01.167132 140216164177920 replay_runner.py:36] Average training steps per second: 217.71
I0902 18:04:01.529236 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -360.04
INFO:tensorflow:Starting iteration 23

Steps executed: 339 Episode length: 142 Return: -136.10236783352218
INFO:tensorflow:Average training steps per second: 211.39
I0902 18:04:10.578185 140216164177920 replay_runner.py:36] Average training steps per second: 211.39
I0902 18:04:10.885401 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.15
INFO:tensorflow:Starting iteration 24

Steps executed: 279 Episode length: 90 Return: -468.856474604268425
INFO:tensorflow:Average training steps per second: 216.31
I0902 18:04:19.920537 140216164177920 replay_runner.py:36] Average training steps per second: 216.31
I0902 18:04:20.150563 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -258.71
INFO:tensorflow:Starting iteration 25

Steps executed: 222 Episode length: 129 Return: -341.18156450411435
INFO:tensorflow:Average training steps per second: 215.64
I0902 18:04:29.062754 140216164177920 replay_runner.py:36] Average training steps per second: 215.64
I0902 18:04:29.274662 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -498.99
INFO:tensorflow:Starting iteration 26

Steps executed: 398 Episode length: 252 Return: -47.207016948987945
INFO:tensorflow:Average training steps per second: 216.88
I0902 18:04:38.259710 140216164177920 replay_runner.py:36] Average training steps per second: 216.88
I0902 18:04:38.640842 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -194.28
INFO:tensorflow:Starting iteration 27

Steps executed: 209 Episode length: 95 Return: -421.803870746864165
INFO:tensorflow:Average training steps per second: 218.20
I0902 18:04:47.566567 140216164177920 replay_runner.py:36] Average training steps per second: 218.20
I0902 18:04:47.743349 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -366.34
INFO:tensorflow:Starting iteration 28

Steps executed: 256 Episode length: 135 Return: -327.79457320181032
INFO:tensorflow:Average training steps per second: 217.52
I0902 18:04:56.642646 140216164177920 replay_runner.py:36] Average training steps per second: 217.52
I0902 18:04:56.854697 140216164177920 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.44
INFO:tensorflow:Starting iteration 29

Steps executed: 234 Episode length: 81 Return: -611.796080440625754
INFO:tensorflow:Average training steps per second: 240.41
I0902 18:05:05.232402 140216164177920 replay_runner.py:36] Average training steps per second: 240.41

Done fixed training!Episode length: 81 Return: -611.796080440625754