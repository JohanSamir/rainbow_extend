Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0902 00:15:00.909828 139752435963904 run_experiment.py:549] Creating TrainRunner ...
I0902 00:15:00.920009 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:15:00.920191 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:15:00.920267 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:15:00.920336 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:15:00.920392 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0902 00:15:00.920483 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:15:00.920538 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:15:00.920590 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:15:00.920641 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:15:00.920692 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0902 00:15:00.920743 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:15:00.920794 139752435963904 dqn_agent.py:283] 	 seed: 1630541700919966
I0902 00:15:00.922812 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:15:00.922962 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:15:00.923045 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:15:00.923121 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:15:00.923202 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:15:00.923508 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:15:00.923651 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:15:00.923776 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:15:00.923907 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:15:00.959985 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:01.360950 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:01.374918 139752435963904 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:15:01.383267 139752435963904 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:15:01.383536 139752435963904 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:15:01.383645 139752435963904 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:15:01.383788 139752435963904 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:15:01.383961 139752435963904 dqn_agent.py:275] 	 update_period: 4
I0902 00:15:01.384078 139752435963904 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:15:01.384246 139752435963904 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:15:01.384383 139752435963904 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:15:01.384528 139752435963904 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:15:01.384776 139752435963904 dqn_agent.py:280] 	 optimizer: adam
I0902 00:15:01.384859 139752435963904 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:15:01.384933 139752435963904 dqn_agent.py:283] 	 seed: 1630541701383215
I0902 00:15:01.387966 139752435963904 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:15:01.388233 139752435963904 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:15:01.388369 139752435963904 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:15:01.388653 139752435963904 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:15:01.388809 139752435963904 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:15:01.388893 139752435963904 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:15:01.388993 139752435963904 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:15:01.389111 139752435963904 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:15:01.389219 139752435963904 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:15:01.453671 139752435963904 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:01.476698 139752435963904 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:15:01.476968 139752435963904 replay_runner.py:41] Starting iteration 0
Steps executed: 207 Episode length: 87 Return: -450.34344940786709
INFO:tensorflow:Average training steps per second: 180.74
I0902 00:15:07.010193 139752435963904 replay_runner.py:36] Average training steps per second: 180.74
I0902 00:15:08.149827 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -369.71
INFO:tensorflow:Starting iteration 1

Steps executed: 295 Episode length: 143 Return: -284.01400585691093
INFO:tensorflow:Average training steps per second: 233.77
I0902 00:15:16.669398 139752435963904 replay_runner.py:36] Average training steps per second: 233.77
I0902 00:15:16.945056 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -214.35
INFO:tensorflow:Starting iteration 2

Steps executed: 250 Episode length: 122 Return: -155.77063492658073
INFO:tensorflow:Average training steps per second: 237.04
I0902 00:15:25.693828 139752435963904 replay_runner.py:36] Average training steps per second: 237.04
I0902 00:15:25.924676 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.18
INFO:tensorflow:Starting iteration 3
I0902 00:15:30.189699 139752435963904 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 234.67

Steps executed: 831 Episode length: 831 Return: -107.25659046592764
I0902 00:15:36.447726 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.26
INFO:tensorflow:Starting iteration 4

Steps executed: 288 Episode length: 288 Return: -221.41490971821705
INFO:tensorflow:Average training steps per second: 229.95
I0902 00:15:45.128626 139752435963904 replay_runner.py:36] Average training steps per second: 229.95
I0902 00:15:45.550144 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.41
INFO:tensorflow:Starting iteration 5
I0902 00:15:49.879481 139752435963904 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 227.00

Steps executed: 1000 Episode length: 1000 Return: -68.51164936469593
I0902 00:15:56.950213 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.51
INFO:tensorflow:Starting iteration 6
I0902 00:16:01.286886 139752435963904 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 228.69

Steps executed: 1000 Episode length: 1000 Return: -166.3253186678214
I0902 00:16:09.040159 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.33
INFO:tensorflow:Starting iteration 7
I0902 00:16:13.469530 139752435963904 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 222.91

Steps executed: 1000 Episode length: 1000 Return: -260.7493728865121
I0902 00:16:20.374357 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.75
INFO:tensorflow:Starting iteration 8
I0902 00:16:24.763176 139752435963904 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 222.23

Steps executed: 1000 Episode length: 1000 Return: -114.3202793012735
I0902 00:16:31.984531 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.32
INFO:tensorflow:Starting iteration 9

Steps executed: 75 Episode length: 75 Return: -369.68453548442955735
INFO:tensorflow:Average training steps per second: 230.01

Steps executed: 1075 Episode length: 1000 Return: -74.87063304054881
I0902 00:16:43.893546 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -222.28
INFO:tensorflow:Starting iteration 10
I0902 00:16:48.153039 139752435963904 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 237.68

Steps executed: 785 Episode length: 785 Return: -349.744374378233261
I0902 00:16:54.007561 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -349.74
INFO:tensorflow:Starting iteration 11
I0902 00:16:58.232418 139752435963904 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 246.72

Steps executed: 647 Episode length: 647 Return: -327.540299027502661
I0902 00:17:03.302722 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.54
INFO:tensorflow:Starting iteration 12
I0902 00:17:07.420879 139752435963904 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 247.09

Steps executed: 1000 Episode length: 1000 Return: -1053.3596462242313
I0902 00:17:14.064843 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -1053.36
INFO:tensorflow:Starting iteration 13

Steps executed: 634 Episode length: 445 Return: -235.2700982759917913
INFO:tensorflow:Average training steps per second: 253.51
I0902 00:17:22.166474 139752435963904 replay_runner.py:36] Average training steps per second: 253.51
I0902 00:17:22.884636 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.55
INFO:tensorflow:Starting iteration 14

Steps executed: 205 Episode length: 151 Return: -89.36310553440978913
INFO:tensorflow:Average training steps per second: 249.15
I0902 00:17:30.979690 139752435963904 replay_runner.py:36] Average training steps per second: 249.15
I0902 00:17:31.138619 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.65
INFO:tensorflow:Starting iteration 15
I0902 00:17:35.220084 139752435963904 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 249.53

Steps executed: 326 Episode length: 168 Return: -204.7198531383628213
I0902 00:17:39.517245 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -383.78
INFO:tensorflow:Starting iteration 16

Steps executed: 227 Episode length: 110 Return: -680.2195893258227613
INFO:tensorflow:Average training steps per second: 255.55
I0902 00:17:47.467315 139752435963904 replay_runner.py:36] Average training steps per second: 255.55
I0902 00:17:47.651284 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -413.34
INFO:tensorflow:Starting iteration 17
I0902 00:17:51.546792 139752435963904 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 275.53
I0902 00:17:55.176368 139752435963904 replay_runner.py:36] Average training steps per second: 275.53

Steps executed: 263 Episode length: 157 Return: -178.0062902441656613
INFO:tensorflow:Starting iteration 18

Steps executed: 402 Episode length: 402 Return: -229.4597786740350813
INFO:tensorflow:Average training steps per second: 308.64
I0902 00:18:02.310881 139752435963904 replay_runner.py:36] Average training steps per second: 308.64
I0902 00:18:02.741081 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.46
INFO:tensorflow:Starting iteration 19

Steps executed: 464 Episode length: 464 Return: -70.24103227198492813
INFO:tensorflow:Average training steps per second: 309.06
I0902 00:18:09.593065 139752435963904 replay_runner.py:36] Average training steps per second: 309.06
I0902 00:18:10.252918 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.24
INFO:tensorflow:Starting iteration 20

Steps executed: 218 Episode length: 93 Return: -143.62297045184545213
INFO:tensorflow:Average training steps per second: 330.15
I0902 00:18:16.873780 139752435963904 replay_runner.py:36] Average training steps per second: 330.15
I0902 00:18:16.977614 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.31
INFO:tensorflow:Starting iteration 21
I0902 00:18:20.502274 139752435963904 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 343.68
I0902 00:18:23.412304 139752435963904 replay_runner.py:36] Average training steps per second: 343.68

Steps executed: 310 Episode length: 153 Return: -141.0309345976965613
INFO:tensorflow:Starting iteration 22

Steps executed: 275 Episode length: 106 Return: -80.59815956231071713
INFO:tensorflow:Average training steps per second: 332.17
I0902 00:18:30.048251 139752435963904 replay_runner.py:36] Average training steps per second: 332.17
I0902 00:18:30.190262 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.19
INFO:tensorflow:Starting iteration 23

Steps executed: 258 Episode length: 128 Return: -127.4111549950987513
INFO:tensorflow:Average training steps per second: 329.91
I0902 00:18:36.599620 139752435963904 replay_runner.py:36] Average training steps per second: 329.91
I0902 00:18:36.718389 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.29
INFO:tensorflow:Starting iteration 24

Steps executed: 169 Episode length: 169 Return: -74.26568045099947513
INFO:tensorflow:Average training steps per second: 333.95
I0902 00:18:43.048975 139752435963904 replay_runner.py:36] Average training steps per second: 333.95

Steps executed: 296 Episode length: 127 Return: -734.2434516660601513
INFO:tensorflow:Starting iteration 25

Steps executed: 247 Episode length: 121 Return: -946.4486158251877213
INFO:tensorflow:Average training steps per second: 317.42
I0902 00:18:49.510903 139752435963904 replay_runner.py:36] Average training steps per second: 317.42
I0902 00:18:49.642416 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.53
INFO:tensorflow:Starting iteration 26

Steps executed: 263 Episode length: 121 Return: -154.5104485044811313
INFO:tensorflow:Average training steps per second: 323.61
I0902 00:18:55.841081 139752435963904 replay_runner.py:36] Average training steps per second: 323.61
I0902 00:18:55.965160 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.58
INFO:tensorflow:Starting iteration 27

Steps executed: 274 Episode length: 274 Return: -73.76930397252083313
INFO:tensorflow:Average training steps per second: 316.05
I0902 00:19:02.250136 139752435963904 replay_runner.py:36] Average training steps per second: 316.05
I0902 00:19:02.455396 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.77
INFO:tensorflow:Starting iteration 28

Steps executed: 522 Episode length: 371 Return: -189.7601789020411613
INFO:tensorflow:Average training steps per second: 317.25
I0902 00:19:08.746388 139752435963904 replay_runner.py:36] Average training steps per second: 317.25
I0902 00:19:09.222267 139752435963904 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.97
INFO:tensorflow:Starting iteration 29
I0902 00:19:12.395297 139752435963904 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 332.14

Steps executed: 1000 Episode length: 1000 Return: -12.817359740392655

Done fixed training! Episode length: 1000 Return: -12.817359740392655