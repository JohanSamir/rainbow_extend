Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0901 23:34:38.599477 140183943698432 run_experiment.py:549] Creating TrainRunner ...
I0901 23:34:38.610731 140183943698432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:34:38.611009 140183943698432 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:34:38.611144 140183943698432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:34:38.611231 140183943698432 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:34:38.611415 140183943698432 dqn_agent.py:275] 	 update_period: 4
I0901 23:34:38.611519 140183943698432 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:34:38.611671 140183943698432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:34:38.611778 140183943698432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:34:38.611869 140183943698432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:34:38.611946 140183943698432 dqn_agent.py:280] 	 optimizer: adam
I0901 23:34:38.612044 140183943698432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:34:38.612117 140183943698432 dqn_agent.py:283] 	 seed: 1630539278610674
I0901 23:34:38.614500 140183943698432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:34:38.614733 140183943698432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:34:38.614855 140183943698432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:34:38.614943 140183943698432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:34:38.615029 140183943698432 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:34:38.615090 140183943698432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:34:38.615147 140183943698432 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:34:38.615207 140183943698432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:34:38.615306 140183943698432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:34:38.646947 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:39.009840 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:39.023731 140183943698432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:34:39.032397 140183943698432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:34:39.032618 140183943698432 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:34:39.032699 140183943698432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:34:39.032824 140183943698432 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:34:39.032973 140183943698432 dqn_agent.py:275] 	 update_period: 4
I0901 23:34:39.033133 140183943698432 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:34:39.033401 140183943698432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:34:39.033573 140183943698432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:34:39.033730 140183943698432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:34:39.033887 140183943698432 dqn_agent.py:280] 	 optimizer: adam
I0901 23:34:39.034157 140183943698432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:34:39.034331 140183943698432 dqn_agent.py:283] 	 seed: 1630539279032353
I0901 23:34:39.037666 140183943698432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:34:39.037997 140183943698432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:34:39.038241 140183943698432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:34:39.038410 140183943698432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:34:39.038549 140183943698432 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:34:39.038645 140183943698432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:34:39.038826 140183943698432 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:34:39.038964 140183943698432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:34:39.039112 140183943698432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:34:39.068256 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:39.111267 140183943698432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:34:39.111953 140183943698432 replay_runner.py:41] Starting iteration 0
Steps executed: 112 Episode length: 62 Return: -141.05148716052975
INFO:tensorflow:Average training steps per second: 168.27
I0901 23:34:45.055135 140183943698432 replay_runner.py:36] Average training steps per second: 168.27

Steps executed: 277 Episode length: 91 Return: -81.261339667210629
INFO:tensorflow:Starting iteration 1

Steps executed: 242 Episode length: 58 Return: -107.74792341047936
INFO:tensorflow:Average training steps per second: 221.24
I0901 23:34:55.044853 140183943698432 replay_runner.py:36] Average training steps per second: 221.24
I0901 23:34:55.223481 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.45
INFO:tensorflow:Starting iteration 2

Steps executed: 200 Episode length: 55 Return: -108.53790697196101
INFO:tensorflow:Average training steps per second: 233.76
I0901 23:35:03.870379 140183943698432 replay_runner.py:36] Average training steps per second: 233.76
I0901 23:35:03.996872 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.49
INFO:tensorflow:Starting iteration 3
I0901 23:35:08.270100 140183943698432 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 247.44

Steps executed: 235 Episode length: 89 Return: -178.71129115838432
I0901 23:35:12.434246 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -155.74
INFO:tensorflow:Starting iteration 4

Steps executed: 210 Episode length: 73 Return: 14.4607640896176492
INFO:tensorflow:Average training steps per second: 248.17
I0901 23:35:20.422343 140183943698432 replay_runner.py:36] Average training steps per second: 248.17
I0901 23:35:20.561941 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.26
INFO:tensorflow:Starting iteration 5

Steps executed: 209 Episode length: 87 Return: -135.36713022612568
INFO:tensorflow:Average training steps per second: 232.60
I0901 23:35:28.993243 140183943698432 replay_runner.py:36] Average training steps per second: 232.60
I0901 23:35:29.128540 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.91
INFO:tensorflow:Starting iteration 6

Steps executed: 237 Episode length: 73 Return: -174.82531269944116
INFO:tensorflow:Average training steps per second: 222.90
I0901 23:35:37.908423 140183943698432 replay_runner.py:36] Average training steps per second: 222.90
I0901 23:35:38.069505 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.35
INFO:tensorflow:Starting iteration 7

Steps executed: 245 Episode length: 86 Return: -95.311500555511295
INFO:tensorflow:Average training steps per second: 218.53
I0901 23:35:47.022314 140183943698432 replay_runner.py:36] Average training steps per second: 218.53
I0901 23:35:47.187431 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.38
INFO:tensorflow:Starting iteration 8

Steps executed: 211 Episode length: 71 Return: -122.28124919113588
INFO:tensorflow:Average training steps per second: 223.78
I0901 23:35:56.006058 140183943698432 replay_runner.py:36] Average training steps per second: 223.78
I0901 23:35:56.133890 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.76
INFO:tensorflow:Starting iteration 9

Steps executed: 211 Episode length: 79 Return: -139.83792204546108
INFO:tensorflow:Average training steps per second: 223.53
I0901 23:36:04.927464 140183943698432 replay_runner.py:36] Average training steps per second: 223.53
I0901 23:36:05.070273 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.78
INFO:tensorflow:Starting iteration 10

Steps executed: 274 Episode length: 76 Return: -115.10630089461048
INFO:tensorflow:Average training steps per second: 221.96
I0901 23:36:13.925951 140183943698432 replay_runner.py:36] Average training steps per second: 221.96
I0901 23:36:14.105029 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.27
INFO:tensorflow:Starting iteration 11

Steps executed: 225 Episode length: 52 Return: -120.12577359597958
INFO:tensorflow:Average training steps per second: 224.27
I0901 23:36:22.963280 140183943698432 replay_runner.py:36] Average training steps per second: 224.27
I0901 23:36:23.115478 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.85
INFO:tensorflow:Starting iteration 12

Steps executed: 209 Episode length: 64 Return: -110.28681686564218
INFO:tensorflow:Average training steps per second: 221.77
I0901 23:36:31.923115 140183943698432 replay_runner.py:36] Average training steps per second: 221.77
I0901 23:36:32.060057 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.29
INFO:tensorflow:Starting iteration 13

Steps executed: 260 Episode length: 75 Return: -176.98627596404782
INFO:tensorflow:Average training steps per second: 221.90
I0901 23:36:40.974060 140183943698432 replay_runner.py:36] Average training steps per second: 221.90
I0901 23:36:41.158501 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.59
INFO:tensorflow:Starting iteration 14

Steps executed: 210 Episode length: 64 Return: -111.66084797179647
INFO:tensorflow:Average training steps per second: 217.49
I0901 23:36:50.156642 140183943698432 replay_runner.py:36] Average training steps per second: 217.49
I0901 23:36:50.296248 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.21
INFO:tensorflow:Starting iteration 15

Steps executed: 277 Episode length: 87 Return: -136.09152351898891
INFO:tensorflow:Average training steps per second: 221.03
I0901 23:36:59.173975 140183943698432 replay_runner.py:36] Average training steps per second: 221.03
I0901 23:36:59.352812 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.66
INFO:tensorflow:Starting iteration 16

Steps executed: 209 Episode length: 66 Return: -152.49534110937356
INFO:tensorflow:Average training steps per second: 217.35
I0901 23:37:08.350059 140183943698432 replay_runner.py:36] Average training steps per second: 217.35
I0901 23:37:08.488724 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -157.93
INFO:tensorflow:Starting iteration 17

Steps executed: 224 Episode length: 80 Return: -181.09964383141744
INFO:tensorflow:Average training steps per second: 223.10
I0901 23:37:17.299122 140183943698432 replay_runner.py:36] Average training steps per second: 223.10
I0901 23:37:17.440260 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.03
INFO:tensorflow:Starting iteration 18

Steps executed: 249 Episode length: 55 Return: -99.447324075627733
INFO:tensorflow:Average training steps per second: 224.18
I0901 23:37:26.253655 140183943698432 replay_runner.py:36] Average training steps per second: 224.18
I0901 23:37:26.413008 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.95
INFO:tensorflow:Starting iteration 19

Steps executed: 258 Episode length: 105 Return: -57.73667699660561
INFO:tensorflow:Average training steps per second: 219.89
I0901 23:37:35.260014 140183943698432 replay_runner.py:36] Average training steps per second: 219.89
I0901 23:37:35.433585 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.33
INFO:tensorflow:Starting iteration 20

Steps executed: 243 Episode length: 68 Return: -135.87275796511276
INFO:tensorflow:Average training steps per second: 217.90
I0901 23:37:44.341316 140183943698432 replay_runner.py:36] Average training steps per second: 217.90
I0901 23:37:44.503916 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.37
INFO:tensorflow:Starting iteration 21

Steps executed: 207 Episode length: 59 Return: -154.85514726251176
INFO:tensorflow:Average training steps per second: 220.61
I0901 23:37:53.389158 140183943698432 replay_runner.py:36] Average training steps per second: 220.61
I0901 23:37:53.525501 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.43
INFO:tensorflow:Starting iteration 22

Steps executed: 213 Episode length: 55 Return: -28.104943167632513
INFO:tensorflow:Average training steps per second: 233.81
I0901 23:38:02.221375 140183943698432 replay_runner.py:36] Average training steps per second: 233.81
I0901 23:38:02.348015 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.08
INFO:tensorflow:Starting iteration 23

Steps executed: 240 Episode length: 81 Return: -149.82859229846633
INFO:tensorflow:Average training steps per second: 225.42
I0901 23:38:10.904068 140183943698432 replay_runner.py:36] Average training steps per second: 225.42
I0901 23:38:11.040616 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.06
INFO:tensorflow:Starting iteration 24

Steps executed: 236 Episode length: 71 Return: -134.71211105332167
INFO:tensorflow:Average training steps per second: 234.78
I0901 23:38:19.497273 140183943698432 replay_runner.py:36] Average training steps per second: 234.78
I0901 23:38:19.626145 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.84
INFO:tensorflow:Starting iteration 25

Steps executed: 212 Episode length: 65 Return: -141.01658009113098
INFO:tensorflow:Average training steps per second: 235.66
I0901 23:38:27.908300 140183943698432 replay_runner.py:36] Average training steps per second: 235.66
I0901 23:38:28.027731 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.55
INFO:tensorflow:Starting iteration 26

Steps executed: 252 Episode length: 61 Return: -162.45338838743196
INFO:tensorflow:Average training steps per second: 232.74
I0901 23:38:36.510747 140183943698432 replay_runner.py:36] Average training steps per second: 232.74
I0901 23:38:36.679246 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.89
INFO:tensorflow:Starting iteration 27

Steps executed: 279 Episode length: 83 Return: -123.592461635110717
INFO:tensorflow:Average training steps per second: 221.30
I0901 23:38:45.442984 140183943698432 replay_runner.py:36] Average training steps per second: 221.30
I0901 23:38:45.641717 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.67
INFO:tensorflow:Starting iteration 28

Steps executed: 232 Episode length: 58 Return: -105.132399395605577
INFO:tensorflow:Average training steps per second: 223.89
I0901 23:38:54.404533 140183943698432 replay_runner.py:36] Average training steps per second: 223.89
I0901 23:38:54.546336 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.57
INFO:tensorflow:Starting iteration 29

Steps executed: 223 Episode length: 85 Return: -263.977049449911477
INFO:tensorflow:Average training steps per second: 229.35
I0901 23:39:03.290758 140183943698432 replay_runner.py:36] Average training steps per second: 229.35

Done fixed training!Episode length: 85 Return: -263.977049449911477