Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0902 23:56:13.400140 140457530894336 run_experiment.py:549] Creating TrainRunner ...
I0902 23:56:13.420635 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:56:13.420912 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:56:13.427679 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:56:13.428209 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:56:13.428503 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0902 23:56:13.429107 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:56:13.429632 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:56:13.430224 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:56:13.430661 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:56:13.431078 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0902 23:56:13.431630 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:56:13.432170 140457530894336 dqn_agent.py:283] 	 seed: 1630626973420562
I0902 23:56:13.439430 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:56:13.439627 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:56:13.440478 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:56:13.440615 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:56:13.441236 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:56:13.441606 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:56:13.441721 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:56:13.442167 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:56:13.442523 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:56:13.481074 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:56:13.833353 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:56:13.848007 140457530894336 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:56:13.858233 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:56:13.858552 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:56:13.858784 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:56:13.858924 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:56:13.859037 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0902 23:56:13.859223 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:56:13.859355 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:56:13.859472 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:56:13.859638 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:56:13.859772 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0902 23:56:13.859941 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:56:13.860053 140457530894336 dqn_agent.py:283] 	 seed: 1630626973858148
I0902 23:56:13.892809 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:56:13.893054 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:56:13.893165 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:56:13.893273 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:56:13.893363 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:56:13.893449 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:56:13.893530 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:56:13.893613 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:56:13.893753 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:56:13.923178 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:56:13.943192 140457530894336 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:56:13.943435 140457530894336 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 164.75
I0902 23:56:20.013310 140457530894336 replay_runner.py:36] Average training steps per second: 164.75
Steps executed: 266 Episode length: 91 Return: -472.85252541169552
I0902 23:56:21.260799 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -516.65
INFO:tensorflow:Starting iteration 1

Steps executed: 270 Episode length: 139 Return: -340.1093804370682
INFO:tensorflow:Average training steps per second: 228.84
I0902 23:56:29.983363 140457530894336 replay_runner.py:36] Average training steps per second: 228.84
I0902 23:56:30.271107 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.59
INFO:tensorflow:Starting iteration 2

Steps executed: 314 Episode length: 155 Return: -461.72250409549565
INFO:tensorflow:Average training steps per second: 214.07
I0902 23:56:39.305283 140457530894336 replay_runner.py:36] Average training steps per second: 214.07
I0902 23:56:39.592444 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.76
INFO:tensorflow:Starting iteration 3
I0902 23:56:43.978422 140457530894336 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 221.74

Steps executed: 455 Episode length: 455 Return: -423.61384080900496
I0902 23:56:49.151822 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -423.61
INFO:tensorflow:Starting iteration 4
I0902 23:56:53.416673 140457530894336 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 221.02

Steps executed: 882 Episode length: 882 Return: -358.93332233246144
I0902 23:56:59.667651 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -358.93
INFO:tensorflow:Starting iteration 5

Steps executed: 249 Episode length: 249 Return: 9.49738070773972344
INFO:tensorflow:Average training steps per second: 222.23
I0902 23:57:08.491017 140457530894336 replay_runner.py:36] Average training steps per second: 222.23
I0902 23:57:08.782644 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.50
INFO:tensorflow:Starting iteration 6
I0902 23:57:13.057066 140457530894336 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 224.31

Steps executed: 1000 Episode length: 1000 Return: -102.45499251516561
I0902 23:57:20.023618 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.45
INFO:tensorflow:Starting iteration 7

Steps executed: 296 Episode length: 296 Return: -307.1414927269621661
INFO:tensorflow:Average training steps per second: 225.84
I0902 23:57:28.742774 140457530894336 replay_runner.py:36] Average training steps per second: 225.84
I0902 23:57:29.033883 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.14
INFO:tensorflow:Starting iteration 8

Steps executed: 433 Episode length: 433 Return: -391.9347767205636661
INFO:tensorflow:Average training steps per second: 231.40
I0902 23:57:37.668492 140457530894336 replay_runner.py:36] Average training steps per second: 231.40
I0902 23:57:38.318946 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -391.93
INFO:tensorflow:Starting iteration 9
I0902 23:57:42.593583 140457530894336 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 238.27

Steps executed: 582 Episode length: 582 Return: -195.0727720435218661
I0902 23:57:47.754020 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.07
INFO:tensorflow:Starting iteration 10

Steps executed: 319 Episode length: 319 Return: -226.9200321767890561
INFO:tensorflow:Average training steps per second: 242.87
I0902 23:57:56.143019 140457530894336 replay_runner.py:36] Average training steps per second: 242.87
I0902 23:57:56.590824 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.92
INFO:tensorflow:Starting iteration 11

Steps executed: 293 Episode length: 293 Return: -194.4092129123833461
INFO:tensorflow:Average training steps per second: 251.69
I0902 23:58:04.661043 140457530894336 replay_runner.py:36] Average training steps per second: 251.69
I0902 23:58:05.003776 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -194.41
INFO:tensorflow:Starting iteration 12
I0902 23:58:09.120926 140457530894336 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 250.97

Steps executed: 1000 Episode length: 1000 Return: -301.11508596509221
I0902 23:58:15.606333 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.12
INFO:tensorflow:Starting iteration 13

Steps executed: 307 Episode length: 307 Return: -274.0837669397548721
INFO:tensorflow:Average training steps per second: 252.67
I0902 23:58:23.663175 140457530894336 replay_runner.py:36] Average training steps per second: 252.67
I0902 23:58:24.050583 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.08
INFO:tensorflow:Starting iteration 14

Steps executed: 330 Episode length: 330 Return: -246.7795448979837721
INFO:tensorflow:Average training steps per second: 249.65
I0902 23:58:32.182796 140457530894336 replay_runner.py:36] Average training steps per second: 249.65
I0902 23:58:32.549468 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -246.78
INFO:tensorflow:Starting iteration 15

Steps executed: 230 Episode length: 230 Return: -262.4227055891850621
INFO:tensorflow:Average training steps per second: 258.97
I0902 23:58:40.502562 140457530894336 replay_runner.py:36] Average training steps per second: 258.97
I0902 23:58:40.711369 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.42
INFO:tensorflow:Starting iteration 16

Steps executed: 241 Episode length: 105 Return: -391.1918233245292521
INFO:tensorflow:Average training steps per second: 262.43
I0902 23:58:48.458347 140457530894336 replay_runner.py:36] Average training steps per second: 262.43
I0902 23:58:48.645264 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -723.22
INFO:tensorflow:Starting iteration 17

Steps executed: 257 Episode length: 122 Return: -289.6855518937290521
INFO:tensorflow:Average training steps per second: 264.00
I0902 23:58:56.290053 140457530894336 replay_runner.py:36] Average training steps per second: 264.00
I0902 23:58:56.469223 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.86
INFO:tensorflow:Starting iteration 18
I0902 23:59:00.207830 140457530894336 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 283.37

Steps executed: 488 Episode length: 308 Return: -275.0444938231737521
I0902 23:59:04.138127 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.03
INFO:tensorflow:Starting iteration 19
I0902 23:59:07.691902 140457530894336 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 283.06

Steps executed: 617 Episode length: 617 Return: -129.1551487465430621
I0902 23:59:12.115026 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.16
INFO:tensorflow:Starting iteration 20

Steps executed: 283 Episode length: 283 Return: 1.3914240260658630621
INFO:tensorflow:Average training steps per second: 284.88
I0902 23:59:19.119467 140457530894336 replay_runner.py:36] Average training steps per second: 284.88
I0902 23:59:19.361783 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: 1.39
INFO:tensorflow:Starting iteration 21

Steps executed: 267 Episode length: 126 Return: -157.4083055383446221
INFO:tensorflow:Average training steps per second: 290.79
I0902 23:59:26.214537 140457530894336 replay_runner.py:36] Average training steps per second: 290.79
I0902 23:59:26.376893 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.17
INFO:tensorflow:Starting iteration 22
I0902 23:59:29.810296 140457530894336 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 291.56

Steps executed: 1000 Episode length: 1000 Return: -105.51853458354724
I0902 23:59:35.077441 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.52
INFO:tensorflow:Starting iteration 23
I0902 23:59:38.591918 140457530894336 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 323.38

Steps executed: 238 Episode length: 63 Return: -212.33225198674725324
I0902 23:59:41.807836 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.64
INFO:tensorflow:Starting iteration 24

Steps executed: 219 Episode length: 115 Return: -261.0015730417161424
INFO:tensorflow:Average training steps per second: 309.45
I0902 23:59:48.552885 140457530894336 replay_runner.py:36] Average training steps per second: 309.45
I0902 23:59:48.659757 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.02
INFO:tensorflow:Starting iteration 25

Steps executed: 226 Episode length: 76 Return: -137.28844834010456424
INFO:tensorflow:Average training steps per second: 318.71
I0902 23:59:55.265853 140457530894336 replay_runner.py:36] Average training steps per second: 318.71
I0902 23:59:55.358207 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.08
INFO:tensorflow:Starting iteration 26
I0902 23:59:58.615283 140457530894336 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 306.24

Steps executed: 285 Episode length: 146 Return: -673.3239029182716424
I0903 00:00:02.050867 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -584.64
INFO:tensorflow:Starting iteration 27

Steps executed: 232 Episode length: 232 Return: -559.0961551871475424
INFO:tensorflow:Average training steps per second: 308.40
I0903 00:00:08.409487 140457530894336 replay_runner.py:36] Average training steps per second: 308.40
I0903 00:00:08.550186 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -559.10
INFO:tensorflow:Starting iteration 28

Steps executed: 555 Episode length: 501 Return: 210.19095793861295424
INFO:tensorflow:Average training steps per second: 300.31
I0903 00:00:14.905615 140457530894336 replay_runner.py:36] Average training steps per second: 300.31
I0903 00:00:15.539128 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: 44.85
INFO:tensorflow:Starting iteration 29
I0903 00:00:18.796079 140457530894336 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 328.78
I0903 00:00:21.837969 140457530894336 replay_runner.py:36] Average training steps per second: 328.78


Done fixed training!Episode length: 204 Return: -409.0641472321523424