Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0902 17:46:14.221716 139977662982144 run_experiment.py:549] Creating TrainRunner ...
I0902 17:46:14.235185 139977662982144 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:46:14.235451 139977662982144 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:46:14.235580 139977662982144 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:46:14.235694 139977662982144 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:46:14.236071 139977662982144 dqn_agent.py:275] 	 update_period: 4
I0902 17:46:14.236482 139977662982144 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:46:14.236823 139977662982144 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:46:14.237064 139977662982144 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:46:14.237244 139977662982144 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:46:14.237376 139977662982144 dqn_agent.py:280] 	 optimizer: adam
I0902 17:46:14.237527 139977662982144 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:46:14.237649 139977662982144 dqn_agent.py:283] 	 seed: 1630604774235107
I0902 17:46:14.240941 139977662982144 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:46:14.241184 139977662982144 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:46:14.241545 139977662982144 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:46:14.241711 139977662982144 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:46:14.241881 139977662982144 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:46:14.242052 139977662982144 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:46:14.242173 139977662982144 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:46:14.242290 139977662982144 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:46:14.242399 139977662982144 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:46:14.283208 139977662982144 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=5.000000
I0902 17:46:14.679423 139977662982144 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=5.000000
I0902 17:46:14.693423 139977662982144 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 17:46:15.180146 139977662982144 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 17:46:15.180445 139977662982144 dqn_agent.py:272] 	 gamma: 0.990000
I0902 17:46:15.180868 139977662982144 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 17:46:15.181142 139977662982144 dqn_agent.py:274] 	 min_replay_history: 500
I0902 17:46:15.181589 139977662982144 dqn_agent.py:275] 	 update_period: 4
I0902 17:46:15.181838 139977662982144 dqn_agent.py:276] 	 target_update_period: 300
I0902 17:46:15.181999 139977662982144 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 17:46:15.182291 139977662982144 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 17:46:15.182493 139977662982144 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 17:46:15.182776 139977662982144 dqn_agent.py:280] 	 optimizer: adam
I0902 17:46:15.183306 139977662982144 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 17:46:15.183492 139977662982144 dqn_agent.py:283] 	 seed: 1630604775180077
I0902 17:46:15.187630 139977662982144 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 17:46:15.187894 139977662982144 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 17:46:15.188339 139977662982144 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 17:46:15.188583 139977662982144 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 17:46:15.188804 139977662982144 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 17:46:15.189070 139977662982144 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 17:46:15.189254 139977662982144 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 17:46:15.189546 139977662982144 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 17:46:15.189648 139977662982144 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 17:46:15.229760 139977662982144 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=5.000000
I0902 17:46:15.251160 139977662982144 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 17:46:15.251388 139977662982144 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 161.00
I0902 17:46:21.462878 139977662982144 replay_runner.py:36] Average training steps per second: 161.00
Steps executed: 212 Episode length: 53 Return: -226.20212896096638
I0902 17:46:22.601162 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -401.85
INFO:tensorflow:Starting iteration 1

Steps executed: 217 Episode length: 60 Return: -262.90009543266098
INFO:tensorflow:Average training steps per second: 222.36
I0902 17:46:31.499555 139977662982144 replay_runner.py:36] Average training steps per second: 222.36
I0902 17:46:31.647330 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.61
INFO:tensorflow:Starting iteration 2

Steps executed: 210 Episode length: 76 Return: -338.57311008755346
INFO:tensorflow:Average training steps per second: 217.03
I0902 17:46:40.627350 139977662982144 replay_runner.py:36] Average training steps per second: 217.03
I0902 17:46:40.778533 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.13
INFO:tensorflow:Starting iteration 3

Steps executed: 94 Episode length: 94 Return: -423.918526115868446
INFO:tensorflow:Average training steps per second: 217.85

Steps executed: 240 Episode length: 58 Return: -299.81366503000816
I0902 17:46:49.934168 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -421.05
INFO:tensorflow:Starting iteration 4

Steps executed: 228 Episode length: 84 Return: -460.61342920940314
INFO:tensorflow:Average training steps per second: 224.01
I0902 17:46:58.717514 139977662982144 replay_runner.py:36] Average training steps per second: 224.01
I0902 17:46:58.878929 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.41
INFO:tensorflow:Starting iteration 5

Steps executed: 202 Episode length: 76 Return: -444.06916815020952
INFO:tensorflow:Average training steps per second: 222.48
I0902 17:47:07.725323 139977662982144 replay_runner.py:36] Average training steps per second: 222.48
I0902 17:47:07.856248 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -285.15
INFO:tensorflow:Starting iteration 6

Steps executed: 230 Episode length: 60 Return: -287.17506906697352
INFO:tensorflow:Average training steps per second: 233.28
I0902 17:47:16.248918 139977662982144 replay_runner.py:36] Average training steps per second: 233.28
I0902 17:47:16.375769 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.71
INFO:tensorflow:Starting iteration 7

Steps executed: 209 Episode length: 73 Return: -187.26796424510167
INFO:tensorflow:Average training steps per second: 239.00
I0902 17:47:24.710952 139977662982144 replay_runner.py:36] Average training steps per second: 239.00
I0902 17:47:24.840024 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -301.72
INFO:tensorflow:Starting iteration 8

Steps executed: 211 Episode length: 68 Return: -343.56343082119184
INFO:tensorflow:Average training steps per second: 230.25
I0902 17:47:33.232991 139977662982144 replay_runner.py:36] Average training steps per second: 230.25
I0902 17:47:33.384654 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -222.89
INFO:tensorflow:Starting iteration 9

Steps executed: 169 Episode length: 91 Return: -195.70764039339662
INFO:tensorflow:Average training steps per second: 224.02

Steps executed: 282 Episode length: 113 Return: -116.28810513387825
I0902 17:47:42.216272 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.82
INFO:tensorflow:Starting iteration 10

Steps executed: 318 Episode length: 162 Return: -176.30268775306618
INFO:tensorflow:Average training steps per second: 221.81
I0902 17:47:50.932471 139977662982144 replay_runner.py:36] Average training steps per second: 221.81
I0902 17:47:51.219285 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -147.64
INFO:tensorflow:Starting iteration 11

Steps executed: 141 Episode length: 141 Return: -102.35057383627974
INFO:tensorflow:Average training steps per second: 222.78

Steps executed: 242 Episode length: 101 Return: -151.61693183302194
I0902 17:48:00.296783 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.98
INFO:tensorflow:Starting iteration 12

Steps executed: 264 Episode length: 171 Return: -157.71812433883576
INFO:tensorflow:Average training steps per second: 218.27
I0902 17:48:09.218009 139977662982144 replay_runner.py:36] Average training steps per second: 218.27
I0902 17:48:09.422816 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.92
INFO:tensorflow:Starting iteration 13

Steps executed: 247 Episode length: 84 Return: -148.129593052845426
INFO:tensorflow:Average training steps per second: 217.93
I0902 17:48:18.442933 139977662982144 replay_runner.py:36] Average training steps per second: 217.93
I0902 17:48:18.638062 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.28
INFO:tensorflow:Starting iteration 14

Steps executed: 233 Episode length: 233 Return: -74.897950260295836
INFO:tensorflow:Average training steps per second: 222.55
I0902 17:48:27.487838 139977662982144 replay_runner.py:36] Average training steps per second: 222.55
I0902 17:48:27.718278 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.90
INFO:tensorflow:Starting iteration 15

Steps executed: 222 Episode length: 76 Return: -150.830302075612056
INFO:tensorflow:Average training steps per second: 219.13
I0902 17:48:36.699170 139977662982144 replay_runner.py:36] Average training steps per second: 219.13
I0902 17:48:36.882820 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.91
INFO:tensorflow:Starting iteration 16

Steps executed: 273 Episode length: 142 Return: -202.02725626580002
INFO:tensorflow:Average training steps per second: 221.08
I0902 17:48:45.803251 139977662982144 replay_runner.py:36] Average training steps per second: 221.08
I0902 17:48:46.042681 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.44
INFO:tensorflow:Starting iteration 17

Steps executed: 313 Episode length: 116 Return: -218.36231501890097
INFO:tensorflow:Average training steps per second: 219.29
I0902 17:48:54.906563 139977662982144 replay_runner.py:36] Average training steps per second: 219.29
I0902 17:48:55.153075 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.51
INFO:tensorflow:Starting iteration 18

Steps executed: 282 Episode length: 91 Return: -177.655179442542027
INFO:tensorflow:Average training steps per second: 224.13
I0902 17:49:03.938738 139977662982144 replay_runner.py:36] Average training steps per second: 224.13
I0902 17:49:04.130404 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.44
INFO:tensorflow:Starting iteration 19

Steps executed: 240 Episode length: 240 Return: -206.62659060734308
INFO:tensorflow:Average training steps per second: 220.72
I0902 17:49:13.031505 139977662982144 replay_runner.py:36] Average training steps per second: 220.72
I0902 17:49:13.275335 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.63
INFO:tensorflow:Starting iteration 20

Steps executed: 297 Episode length: 181 Return: -259.40484400247954
INFO:tensorflow:Average training steps per second: 217.89
I0902 17:49:22.280853 139977662982144 replay_runner.py:36] Average training steps per second: 217.89
I0902 17:49:22.580404 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.74
INFO:tensorflow:Starting iteration 21

Steps executed: 207 Episode length: 207 Return: -393.44153453903494
INFO:tensorflow:Average training steps per second: 219.37
I0902 17:49:31.556564 139977662982144 replay_runner.py:36] Average training steps per second: 219.37
I0902 17:49:31.754647 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -393.44
INFO:tensorflow:Starting iteration 22
I0902 17:49:36.168180 139977662982144 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 222.82
I0902 17:49:40.656654 139977662982144 replay_runner.py:36] Average training steps per second: 222.82

Steps executed: 205 Episode length: 110 Return: -353.66046639879914
INFO:tensorflow:Starting iteration 23

Steps executed: 223 Episode length: 71 Return: -174.788084644070534
INFO:tensorflow:Average training steps per second: 220.77
I0902 17:49:49.712238 139977662982144 replay_runner.py:36] Average training steps per second: 220.77
I0902 17:49:49.890537 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.68
INFO:tensorflow:Starting iteration 24
I0902 17:49:54.268113 139977662982144 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 218.05

Steps executed: 229 Episode length: 87 Return: -313.570985721438924
I0902 17:49:59.045931 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.30
INFO:tensorflow:Starting iteration 25

Steps executed: 235 Episode length: 99 Return: -295.780228726127524
INFO:tensorflow:Average training steps per second: 237.79
I0902 17:50:07.624609 139977662982144 replay_runner.py:36] Average training steps per second: 237.79
I0902 17:50:07.775325 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.62
INFO:tensorflow:Starting iteration 26

Steps executed: 251 Episode length: 157 Return: -220.94018279534305
INFO:tensorflow:Average training steps per second: 231.61
I0902 17:50:16.206124 139977662982144 replay_runner.py:36] Average training steps per second: 231.61
I0902 17:50:16.423805 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -248.01
INFO:tensorflow:Starting iteration 27

Steps executed: 237 Episode length: 135 Return: -194.29158318236666
INFO:tensorflow:Average training steps per second: 224.43
I0902 17:50:25.194778 139977662982144 replay_runner.py:36] Average training steps per second: 224.43
I0902 17:50:25.371912 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.65
INFO:tensorflow:Starting iteration 28

Steps executed: 267 Episode length: 92 Return: -380.007047698719536
INFO:tensorflow:Average training steps per second: 238.94
I0902 17:50:33.788714 139977662982144 replay_runner.py:36] Average training steps per second: 238.94
I0902 17:50:33.985647 139977662982144 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.69
INFO:tensorflow:Starting iteration 29
I0902 17:50:38.343623 139977662982144 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 238.69

Steps executed: 324 Episode length: 164 Return: -129.05012749652548

Done fixed training!Episode length: 164 Return: -129.05012749652548