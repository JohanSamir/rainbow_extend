Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0828 10:23:23.910725 139779140274176 run_experiment.py:549] Creating TrainRunner ...
I0828 10:23:23.921433 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:23:23.921628 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:23:23.921741 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:23:23.921808 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:23:23.921884 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:23:23.921969 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:23:23.922032 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:23:23.922105 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:23:23.922194 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:23:23.922263 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:23:23.922332 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:23:23.922407 139779140274176 dqn_agent.py:283] 	 seed: 1630146203921388
I0828 10:23:23.925788 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:23:23.926174 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:23:23.926333 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:23:23.926446 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:23:23.926559 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:23:23.926721 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:23:23.926872 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:23:23.927064 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:23:23.927215 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:23:23.962229 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:24.345201 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:24.359053 139779140274176 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:23:24.368627 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:23:24.368928 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:23:24.369292 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:23:24.369508 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:23:24.369718 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:23:24.369968 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:23:24.370103 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:23:24.370285 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:23:24.370443 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:23:24.370546 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:23:24.370663 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:23:24.370766 139779140274176 dqn_agent.py:283] 	 seed: 1630146204368559
I0828 10:23:24.373809 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:23:24.373994 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:23:24.374162 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:23:24.374291 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:23:24.374400 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:23:24.374536 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:23:24.374650 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:23:24.374751 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:23:24.374887 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:23:24.711678 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:24.733716 139779140274176 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:23:24.734025 139779140274176 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.68
I0828 10:23:30.881182 139779140274176 replay_runner.py:36] Average training steps per second: 162.68
Steps executed: 258 Episode length: 81 Return: -137.43300728645543
I0828 10:23:32.009891 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -127.99
INFO:tensorflow:Starting iteration 1

Steps executed: 236 Episode length: 64 Return: -371.85441914029123
INFO:tensorflow:Average training steps per second: 222.35
I0828 10:23:40.885025 139779140274176 replay_runner.py:36] Average training steps per second: 222.35
I0828 10:23:41.088818 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -609.56
INFO:tensorflow:Starting iteration 2

Steps executed: 248 Episode length: 64 Return: -127.57564889116415
INFO:tensorflow:Average training steps per second: 224.05
I0828 10:23:49.909898 139779140274176 replay_runner.py:36] Average training steps per second: 224.05
I0828 10:23:50.122274 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -141.28
INFO:tensorflow:Starting iteration 3

Steps executed: 244 Episode length: 51 Return: -446.47361548512455
INFO:tensorflow:Average training steps per second: 221.34
I0828 10:23:59.036401 139779140274176 replay_runner.py:36] Average training steps per second: 221.34
I0828 10:23:59.234282 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -531.16
INFO:tensorflow:Starting iteration 4

Steps executed: 231 Episode length: 74 Return: -294.58204931620795
INFO:tensorflow:Average training steps per second: 219.10
I0828 10:24:08.205217 139779140274176 replay_runner.py:36] Average training steps per second: 219.10
I0828 10:24:08.352869 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.73
INFO:tensorflow:Starting iteration 5

Steps executed: 201 Episode length: 67 Return: -528.59177486127945
INFO:tensorflow:Average training steps per second: 225.83
I0828 10:24:17.173779 139779140274176 replay_runner.py:36] Average training steps per second: 225.83
I0828 10:24:17.335811 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -610.46
INFO:tensorflow:Starting iteration 6
I0828 10:24:21.637037 139779140274176 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 238.27
I0828 10:24:25.834696 139779140274176 replay_runner.py:36] Average training steps per second: 238.27

Steps executed: 305 Episode length: 121 Return: -458.7303218018998
INFO:tensorflow:Starting iteration 7

Steps executed: 211 Episode length: 66 Return: -585.88007190007658
INFO:tensorflow:Average training steps per second: 236.75
I0828 10:24:34.413136 139779140274176 replay_runner.py:36] Average training steps per second: 236.75
I0828 10:24:34.567782 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -608.47
INFO:tensorflow:Starting iteration 8

Steps executed: 258 Episode length: 62 Return: -423.93754381331337
INFO:tensorflow:Average training steps per second: 257.62
I0828 10:24:42.597830 139779140274176 replay_runner.py:36] Average training steps per second: 257.62
I0828 10:24:42.834659 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.67
INFO:tensorflow:Starting iteration 9

Steps executed: 206 Episode length: 72 Return: -712.35160268242783
INFO:tensorflow:Average training steps per second: 226.29
I0828 10:24:51.475800 139779140274176 replay_runner.py:36] Average training steps per second: 226.29
I0828 10:24:51.625400 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -521.96
INFO:tensorflow:Starting iteration 10

Steps executed: 240 Episode length: 55 Return: -401.02166638813784
INFO:tensorflow:Average training steps per second: 224.25
I0828 10:25:00.426908 139779140274176 replay_runner.py:36] Average training steps per second: 224.25
I0828 10:25:00.635101 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -496.91
INFO:tensorflow:Starting iteration 11

Steps executed: 235 Episode length: 50 Return: -330.05541232353437
INFO:tensorflow:Average training steps per second: 226.18
I0828 10:25:09.371519 139779140274176 replay_runner.py:36] Average training steps per second: 226.18
I0828 10:25:09.572500 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -527.23
INFO:tensorflow:Starting iteration 12

Steps executed: 202 Episode length: 70 Return: -704.70611337585187
INFO:tensorflow:Average training steps per second: 220.07
I0828 10:25:18.491355 139779140274176 replay_runner.py:36] Average training steps per second: 220.07
I0828 10:25:18.674212 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -654.85
INFO:tensorflow:Starting iteration 13

Steps executed: 235 Episode length: 66 Return: -479.60665107299275
INFO:tensorflow:Average training steps per second: 224.07
I0828 10:25:27.505708 139779140274176 replay_runner.py:36] Average training steps per second: 224.07
I0828 10:25:27.712794 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -503.03
INFO:tensorflow:Starting iteration 14

Steps executed: 342 Episode length: 228 Return: -1532.596539714129
INFO:tensorflow:Average training steps per second: 214.79
I0828 10:25:36.656374 139779140274176 replay_runner.py:36] Average training steps per second: 214.79
I0828 10:25:37.055917 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -1093.43
INFO:tensorflow:Starting iteration 15

Steps executed: 220 Episode length: 64 Return: -489.37422475526466
INFO:tensorflow:Average training steps per second: 222.73
I0828 10:25:45.968349 139779140274176 replay_runner.py:36] Average training steps per second: 222.73
I0828 10:25:46.153531 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -632.25
INFO:tensorflow:Starting iteration 16

Steps executed: 200 Episode length: 63 Return: -533.93336604593016
INFO:tensorflow:Average training steps per second: 223.38
I0828 10:25:55.055979 139779140274176 replay_runner.py:36] Average training steps per second: 223.38
I0828 10:25:55.234470 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -567.10
INFO:tensorflow:Starting iteration 17
I0828 10:25:59.638128 139779140274176 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 225.01

Steps executed: 249 Episode length: 79 Return: -742.78446255726996
I0828 10:26:04.292323 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -590.52
INFO:tensorflow:Starting iteration 18

Steps executed: 228 Episode length: 62 Return: -506.34786735827396
INFO:tensorflow:Average training steps per second: 226.52
I0828 10:26:13.111170 139779140274176 replay_runner.py:36] Average training steps per second: 226.52
I0828 10:26:13.308575 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -445.69
INFO:tensorflow:Starting iteration 19
I0828 10:26:17.690702 139779140274176 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 220.84

Steps executed: 252 Episode length: 59 Return: -574.81754481664615
I0828 10:26:22.442097 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -678.32
INFO:tensorflow:Starting iteration 20

Steps executed: 244 Episode length: 71 Return: -644.73619023567485
INFO:tensorflow:Average training steps per second: 220.85
I0828 10:26:31.375656 139779140274176 replay_runner.py:36] Average training steps per second: 220.85
I0828 10:26:31.585847 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -517.10
INFO:tensorflow:Starting iteration 21

Steps executed: 264 Episode length: 73 Return: -622.82490389563445
INFO:tensorflow:Average training steps per second: 220.53
I0828 10:26:40.482603 139779140274176 replay_runner.py:36] Average training steps per second: 220.53
I0828 10:26:40.701158 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -591.34
INFO:tensorflow:Starting iteration 22

Steps executed: 232 Episode length: 232 Return: -1663.2318961769943
INFO:tensorflow:Average training steps per second: 219.54
I0828 10:26:49.535625 139779140274176 replay_runner.py:36] Average training steps per second: 219.54
I0828 10:26:49.823978 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -1663.23
INFO:tensorflow:Starting iteration 23

Steps executed: 228 Episode length: 67 Return: -626.799780025339643
INFO:tensorflow:Average training steps per second: 226.43
I0828 10:26:58.538767 139779140274176 replay_runner.py:36] Average training steps per second: 226.43
I0828 10:26:58.740252 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -462.13
INFO:tensorflow:Starting iteration 24

Steps executed: 235 Episode length: 51 Return: -367.171803517401433
INFO:tensorflow:Average training steps per second: 224.88
I0828 10:27:07.421405 139779140274176 replay_runner.py:36] Average training steps per second: 224.88
I0828 10:27:07.642149 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -434.25
INFO:tensorflow:Starting iteration 25
I0828 10:27:11.950286 139779140274176 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 223.58

Steps executed: 251 Episode length: 86 Return: -450.970971514169433
I0828 10:27:16.660080 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -527.53
INFO:tensorflow:Starting iteration 26

Steps executed: 337 Episode length: 163 Return: -784.02379091820353
INFO:tensorflow:Average training steps per second: 230.30
I0828 10:27:25.251474 139779140274176 replay_runner.py:36] Average training steps per second: 230.30
I0828 10:27:25.589580 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -934.93
INFO:tensorflow:Starting iteration 27

Steps executed: 192 Episode length: 101 Return: -530.68417540470193
INFO:tensorflow:Average training steps per second: 234.57
I0828 10:27:34.005964 139779140274176 replay_runner.py:36] Average training steps per second: 234.57

Steps executed: 331 Episode length: 139 Return: -981.63734921469633
INFO:tensorflow:Starting iteration 28

Steps executed: 208 Episode length: 105 Return: -747.05405012573583
INFO:tensorflow:Average training steps per second: 231.33
I0828 10:27:42.884675 139779140274176 replay_runner.py:36] Average training steps per second: 231.33
I0828 10:27:43.083849 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -731.26
INFO:tensorflow:Starting iteration 29

Steps executed: 254 Episode length: 107 Return: -729.16477874164463
INFO:tensorflow:Average training steps per second: 244.84
I0828 10:27:51.359179 139779140274176 replay_runner.py:36] Average training steps per second: 244.84

Done fixed training!Episode length: 107 Return: -729.16477874164463