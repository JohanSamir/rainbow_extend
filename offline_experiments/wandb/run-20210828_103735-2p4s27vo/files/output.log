Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0828 10:37:41.552225 140251198892032 run_experiment.py:549] Creating TrainRunner ...
I0828 10:37:41.563527 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:41.563797 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:41.563911 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:41.564068 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:41.564202 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:41.564321 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:37:41.564442 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:41.564551 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:41.564711 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:41.564855 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:41.565105 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:41.565231 140251198892032 dqn_agent.py:283] 	 seed: 1630147061563461
I0828 10:37:41.569425 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:41.569647 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:37:41.569790 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:41.570174 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:41.570360 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:41.570474 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:41.570598 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:41.570695 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:41.570787 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:41.605916 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:41.988957 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:42.005341 140251198892032 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:37:42.013365 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:42.013731 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:42.013971 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:42.014149 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:42.014280 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:42.014395 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:37:42.014549 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:42.014706 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:42.014965 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:42.015061 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:42.015142 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:42.015258 140251198892032 dqn_agent.py:283] 	 seed: 1630147062013298
I0828 10:37:42.018171 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:42.018347 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:37:42.018524 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:42.018611 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:42.018683 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:42.018749 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:42.018846 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:42.018933 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:42.019018 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:42.093579 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:42.117473 140251198892032 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:37:42.117695 140251198892032 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 166.90
I0828 10:37:48.109651 140251198892032 replay_runner.py:36] Average training steps per second: 166.90
Steps executed: 231 Episode length: 83 Return: -741.4124272720169
I0828 10:37:49.382104 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -594.90
INFO:tensorflow:Starting iteration 1

Steps executed: 225 Episode length: 115 Return: -51.856356962168396
INFO:tensorflow:Average training steps per second: 223.57
I0828 10:37:58.240554 140251198892032 replay_runner.py:36] Average training steps per second: 223.57
I0828 10:37:58.472836 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -51.93
INFO:tensorflow:Starting iteration 2

Steps executed: 247 Episode length: 123 Return: -236.16038102621116
INFO:tensorflow:Average training steps per second: 220.48
I0828 10:38:07.293999 140251198892032 replay_runner.py:36] Average training steps per second: 220.48
I0828 10:38:07.550292 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -163.88
INFO:tensorflow:Starting iteration 3

Steps executed: 315 Episode length: 131 Return: -138.67448459139414
INFO:tensorflow:Average training steps per second: 221.82
I0828 10:38:16.367016 140251198892032 replay_runner.py:36] Average training steps per second: 221.82
I0828 10:38:16.702164 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.45
INFO:tensorflow:Starting iteration 4

Steps executed: 206 Episode length: 67 Return: -524.010849408271714
INFO:tensorflow:Average training steps per second: 221.78
I0828 10:38:25.638938 140251198892032 replay_runner.py:36] Average training steps per second: 221.78
I0828 10:38:25.829395 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -512.29
INFO:tensorflow:Starting iteration 5

Steps executed: 209 Episode length: 64 Return: -577.966225499927414
INFO:tensorflow:Average training steps per second: 223.79
I0828 10:38:34.684558 140251198892032 replay_runner.py:36] Average training steps per second: 223.79
I0828 10:38:34.865124 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -591.79
INFO:tensorflow:Starting iteration 6

Steps executed: 359 Episode length: 166 Return: -897.75646516106514
INFO:tensorflow:Average training steps per second: 225.76
I0828 10:38:43.677690 140251198892032 replay_runner.py:36] Average training steps per second: 225.76
I0828 10:38:44.039211 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -655.41
INFO:tensorflow:Starting iteration 7

Steps executed: 215 Episode length: 215 Return: -26.695177194625534
INFO:tensorflow:Average training steps per second: 225.27
I0828 10:38:52.739222 140251198892032 replay_runner.py:36] Average training steps per second: 225.27
I0828 10:38:52.980953 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -26.70
INFO:tensorflow:Starting iteration 8
I0828 10:38:57.132469 140251198892032 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 228.02

Steps executed: 227 Episode length: 104 Return: 57.0028901180804734
I0828 10:39:01.681143 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.28
INFO:tensorflow:Starting iteration 9

Steps executed: 213 Episode length: 80 Return: -680.114248300139934
INFO:tensorflow:Average training steps per second: 223.05
I0828 10:39:10.356860 140251198892032 replay_runner.py:36] Average training steps per second: 223.05
I0828 10:39:10.542985 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -599.67
INFO:tensorflow:Starting iteration 10

Steps executed: 123 Episode length: 123 Return: -868.07838927142674
INFO:tensorflow:Average training steps per second: 221.03
I0828 10:39:19.348257 140251198892032 replay_runner.py:36] Average training steps per second: 221.03

Steps executed: 295 Episode length: 172 Return: -1295.8921663547344
INFO:tensorflow:Starting iteration 11

Steps executed: 244 Episode length: 91 Return: -122.636664985041864
INFO:tensorflow:Average training steps per second: 228.98
I0828 10:39:28.200779 140251198892032 replay_runner.py:36] Average training steps per second: 228.98
I0828 10:39:28.383119 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.76
INFO:tensorflow:Starting iteration 12

Steps executed: 226 Episode length: 51 Return: -86.9793170971631334
INFO:tensorflow:Average training steps per second: 228.60
I0828 10:39:37.104847 140251198892032 replay_runner.py:36] Average training steps per second: 228.60
I0828 10:39:37.281759 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.55
INFO:tensorflow:Starting iteration 13

Steps executed: 219 Episode length: 82 Return: -225.183730722765334
INFO:tensorflow:Average training steps per second: 222.62
I0828 10:39:46.010953 140251198892032 replay_runner.py:36] Average training steps per second: 222.62
I0828 10:39:46.195142 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -278.02
INFO:tensorflow:Starting iteration 14

Steps executed: 272 Episode length: 75 Return: -321.303274069127454
INFO:tensorflow:Average training steps per second: 225.02
I0828 10:39:55.016242 140251198892032 replay_runner.py:36] Average training steps per second: 225.02
I0828 10:39:55.211076 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -347.23
INFO:tensorflow:Starting iteration 15

Steps executed: 228 Episode length: 56 Return: -116.285657267670814
INFO:tensorflow:Average training steps per second: 227.83
I0828 10:40:03.964290 140251198892032 replay_runner.py:36] Average training steps per second: 227.83
I0828 10:40:04.117269 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.69
INFO:tensorflow:Starting iteration 16

Steps executed: 247 Episode length: 64 Return: -344.308014169209214
INFO:tensorflow:Average training steps per second: 219.38
I0828 10:40:12.856065 140251198892032 replay_runner.py:36] Average training steps per second: 219.38
I0828 10:40:13.069412 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.21
INFO:tensorflow:Starting iteration 17
I0828 10:40:17.231354 140251198892032 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 237.86
I0828 10:40:21.436005 140251198892032 replay_runner.py:36] Average training steps per second: 237.86

Steps executed: 248 Episode length: 65 Return: -133.690235386326754
INFO:tensorflow:Starting iteration 18
I0828 10:40:25.909542 140251198892032 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 240.61

Steps executed: 255 Episode length: 86 Return: -181.595817016831454
I0828 10:40:30.245613 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.73
INFO:tensorflow:Starting iteration 19

Steps executed: 276 Episode length: 100 Return: -296.83473207183034
INFO:tensorflow:Average training steps per second: 222.74
I0828 10:40:39.119394 140251198892032 replay_runner.py:36] Average training steps per second: 222.74
I0828 10:40:39.334780 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.07
INFO:tensorflow:Starting iteration 20

Steps executed: 238 Episode length: 135 Return: -795.14770406627734
INFO:tensorflow:Average training steps per second: 213.98
I0828 10:40:48.399648 140251198892032 replay_runner.py:36] Average training steps per second: 213.98
I0828 10:40:48.647869 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -655.42
INFO:tensorflow:Starting iteration 21

Steps executed: 64 Episode length: 64 Return: -641.2755099402849734
INFO:tensorflow:Average training steps per second: 217.70

Steps executed: 201 Episode length: 67 Return: -682.893318601484634
I0828 10:40:57.766258 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -663.43
INFO:tensorflow:Starting iteration 22

Steps executed: 217 Episode length: 75 Return: -459.249184137220764
INFO:tensorflow:Average training steps per second: 220.19
I0828 10:41:06.512174 140251198892032 replay_runner.py:36] Average training steps per second: 220.19
I0828 10:41:06.683875 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -429.61
INFO:tensorflow:Starting iteration 23

Steps executed: 93 Episode length: 93 Return: -730.0619846024750764
INFO:tensorflow:Average training steps per second: 219.28

Steps executed: 485 Episode length: 309 Return: -1786.2124941977409
I0828 10:41:16.310728 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -964.56
INFO:tensorflow:Starting iteration 24

Steps executed: 262 Episode length: 74 Return: -569.807472870465539
INFO:tensorflow:Average training steps per second: 222.38
I0828 10:41:24.958919 140251198892032 replay_runner.py:36] Average training steps per second: 222.38
I0828 10:41:25.218169 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -530.70
INFO:tensorflow:Starting iteration 25

Steps executed: 207 Episode length: 122 Return: -737.37632299370239
INFO:tensorflow:Average training steps per second: 219.01
I0828 10:41:34.134748 140251198892032 replay_runner.py:36] Average training steps per second: 219.01
I0828 10:41:34.343620 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -708.44
INFO:tensorflow:Starting iteration 26

Steps executed: 211 Episode length: 79 Return: -616.016903997832839
INFO:tensorflow:Average training steps per second: 221.05
I0828 10:41:43.191558 140251198892032 replay_runner.py:36] Average training steps per second: 221.05
I0828 10:41:43.380450 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -562.41
INFO:tensorflow:Starting iteration 27

Steps executed: 260 Episode length: 77 Return: -562.274070542883769
INFO:tensorflow:Average training steps per second: 227.50
I0828 10:41:52.155169 140251198892032 replay_runner.py:36] Average training steps per second: 227.50
I0828 10:41:52.379742 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -478.87
INFO:tensorflow:Starting iteration 28

Steps executed: 250 Episode length: 103 Return: -275.25943810730859
INFO:tensorflow:Average training steps per second: 228.17
I0828 10:42:01.148050 140251198892032 replay_runner.py:36] Average training steps per second: 228.17
I0828 10:42:01.356210 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -337.23
INFO:tensorflow:Starting iteration 29

Steps executed: 354 Episode length: 192 Return: -711.39875242116079
INFO:tensorflow:Average training steps per second: 227.02
I0828 10:42:10.212339 140251198892032 replay_runner.py:36] Average training steps per second: 227.02

Done fixed training!Episode length: 192 Return: -711.39875242116079