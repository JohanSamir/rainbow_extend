Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0828 10:37:32.796780 140214119393280 run_experiment.py:549] Creating TrainRunner ...
I0828 10:37:32.807056 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:32.807259 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:32.807461 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:32.807635 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:32.807743 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:32.807819 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:37:32.807999 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:32.808106 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:32.808212 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:32.808305 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:32.808391 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:32.808445 140214119393280 dqn_agent.py:283] 	 seed: 1630147052807005
I0828 10:37:32.811136 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:32.811352 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:37:32.811544 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:32.811694 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:32.811792 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:32.811898 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:32.812015 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:32.812125 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:32.812271 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:32.847240 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:33.188515 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:33.202820 140214119393280 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:37:33.211387 140214119393280 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:37:33.211566 140214119393280 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:37:33.211685 140214119393280 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:37:33.211771 140214119393280 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:37:33.211855 140214119393280 dqn_agent.py:275] 	 update_period: 4
I0828 10:37:33.211933 140214119393280 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:37:33.212020 140214119393280 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:37:33.212105 140214119393280 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:37:33.212237 140214119393280 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:37:33.212387 140214119393280 dqn_agent.py:280] 	 optimizer: adam
I0828 10:37:33.212493 140214119393280 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:37:33.212604 140214119393280 dqn_agent.py:283] 	 seed: 1630147053211341
I0828 10:37:33.215235 140214119393280 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:37:33.215429 140214119393280 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:37:33.215552 140214119393280 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:37:33.215671 140214119393280 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:37:33.215749 140214119393280 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:37:33.215862 140214119393280 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:37:33.215932 140214119393280 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:37:33.215983 140214119393280 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:37:33.216197 140214119393280 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:37:33.245983 140214119393280 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.100000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:37:33.266043 140214119393280 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:37:33.266449 140214119393280 replay_runner.py:41] Starting iteration 0
Steps executed: 72 Episode length: 72 Return: -570.048870429722
INFO:tensorflow:Average training steps per second: 169.43
I0828 10:37:39.168976 140214119393280 replay_runner.py:36] Average training steps per second: 169.43

Steps executed: 260 Episode length: 105 Return: -373.83111294556403
INFO:tensorflow:Starting iteration 1
I0828 10:37:44.746789 140214119393280 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 224.01
I0828 10:37:49.211215 140214119393280 replay_runner.py:36] Average training steps per second: 224.01

Steps executed: 347 Episode length: 151 Return: -1085.2367473626805
INFO:tensorflow:Starting iteration 2

Steps executed: 94 Episode length: 94 Return: -450.5834777700082805
INFO:tensorflow:Average training steps per second: 228.11

Steps executed: 276 Episode length: 84 Return: -399.487199214120445
I0828 10:37:58.573940 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -445.82
INFO:tensorflow:Starting iteration 3

Steps executed: 202 Episode length: 202 Return: -418.74606039616415
INFO:tensorflow:Average training steps per second: 220.49
I0828 10:38:07.488729 140214119393280 replay_runner.py:36] Average training steps per second: 220.49
I0828 10:38:07.717852 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -418.75
INFO:tensorflow:Starting iteration 4
I0828 10:38:12.119637 140214119393280 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 227.52

Steps executed: 214 Episode length: 79 Return: -467.467365268752535
I0828 10:38:16.698580 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -563.24
INFO:tensorflow:Starting iteration 5

Steps executed: 226 Episode length: 95 Return: -416.251661752605355
INFO:tensorflow:Average training steps per second: 225.58
I0828 10:38:25.434313 140214119393280 replay_runner.py:36] Average training steps per second: 225.58
I0828 10:38:25.659387 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -484.14
INFO:tensorflow:Starting iteration 6
I0828 10:38:29.983270 140214119393280 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 226.83

Steps executed: 360 Episode length: 360 Return: -431.85839890816345
I0828 10:38:35.053999 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -431.86
INFO:tensorflow:Starting iteration 7

Steps executed: 397 Episode length: 314 Return: -101.79983873661848
INFO:tensorflow:Average training steps per second: 221.57
I0828 10:38:43.893043 140214119393280 replay_runner.py:36] Average training steps per second: 221.57
I0828 10:38:44.319809 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.47
INFO:tensorflow:Starting iteration 8

Steps executed: 231 Episode length: 53 Return: -170.389956494564798
INFO:tensorflow:Average training steps per second: 229.60
I0828 10:38:53.022915 140214119393280 replay_runner.py:36] Average training steps per second: 229.60
I0828 10:38:53.224438 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.92
INFO:tensorflow:Starting iteration 9

Steps executed: 221 Episode length: 67 Return: -132.782520343755598
INFO:tensorflow:Average training steps per second: 224.32
I0828 10:39:02.048035 140214119393280 replay_runner.py:36] Average training steps per second: 224.32
I0828 10:39:02.189068 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.18
INFO:tensorflow:Starting iteration 10

Steps executed: 295 Episode length: 107 Return: -639.57766642532658
INFO:tensorflow:Average training steps per second: 226.39
I0828 10:39:10.916148 140214119393280 replay_runner.py:36] Average training steps per second: 226.39
I0828 10:39:11.178522 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -513.36
INFO:tensorflow:Starting iteration 11

Steps executed: 289 Episode length: 91 Return: -250.098085882090578
INFO:tensorflow:Average training steps per second: 228.58
I0828 10:39:19.805826 140214119393280 replay_runner.py:36] Average training steps per second: 228.58
I0828 10:39:20.041713 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.97
INFO:tensorflow:Starting iteration 12

Steps executed: 382 Episode length: 184 Return: -927.01314740482888
INFO:tensorflow:Average training steps per second: 230.16
I0828 10:39:28.499115 140214119393280 replay_runner.py:36] Average training steps per second: 230.16
I0828 10:39:28.888558 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -924.78
INFO:tensorflow:Starting iteration 13

Steps executed: 287 Episode length: 101 Return: -678.97965730611958
INFO:tensorflow:Average training steps per second: 229.78
I0828 10:39:37.364248 140214119393280 replay_runner.py:36] Average training steps per second: 229.78
I0828 10:39:37.621557 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -677.94
INFO:tensorflow:Starting iteration 14

Steps executed: 242 Episode length: 91 Return: -632.285798748359568
INFO:tensorflow:Average training steps per second: 229.90
I0828 10:39:46.320843 140214119393280 replay_runner.py:36] Average training steps per second: 229.90
I0828 10:39:46.566981 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -786.99
INFO:tensorflow:Starting iteration 15

Steps executed: 297 Episode length: 132 Return: -279.10641003142746
INFO:tensorflow:Average training steps per second: 228.86
I0828 10:39:55.309129 140214119393280 replay_runner.py:36] Average training steps per second: 228.86
I0828 10:39:55.564648 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -340.12
INFO:tensorflow:Starting iteration 16

Steps executed: 220 Episode length: 69 Return: -627.002664737093346
INFO:tensorflow:Average training steps per second: 228.69
I0828 10:40:04.201943 140214119393280 replay_runner.py:36] Average training steps per second: 228.69
I0828 10:40:04.392318 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -456.32
INFO:tensorflow:Starting iteration 17

Steps executed: 285 Episode length: 94 Return: -482.304354978750556
INFO:tensorflow:Average training steps per second: 223.24
I0828 10:40:13.253529 140214119393280 replay_runner.py:36] Average training steps per second: 223.24
I0828 10:40:13.520734 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -449.54
INFO:tensorflow:Starting iteration 18

Steps executed: 276 Episode length: 126 Return: -398.34095859496864
INFO:tensorflow:Average training steps per second: 236.29
I0828 10:40:21.983681 140214119393280 replay_runner.py:36] Average training steps per second: 236.29
I0828 10:40:22.194274 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.70
INFO:tensorflow:Starting iteration 19
I0828 10:40:26.690828 140214119393280 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 237.59
I0828 10:40:30.900310 140214119393280 replay_runner.py:36] Average training steps per second: 237.59

Steps executed: 229 Episode length: 141 Return: -881.01480775065114
INFO:tensorflow:Starting iteration 20

Steps executed: 261 Episode length: 73 Return: -618.448810062280274
INFO:tensorflow:Average training steps per second: 222.10
I0828 10:40:40.005165 140214119393280 replay_runner.py:36] Average training steps per second: 222.10
I0828 10:40:40.253777 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.11
INFO:tensorflow:Starting iteration 21
I0828 10:40:44.679577 140214119393280 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 220.94

Steps executed: 361 Episode length: 184 Return: -1044.5329617886274
I0828 10:40:49.595124 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -621.39
INFO:tensorflow:Starting iteration 22

Steps executed: 321 Episode length: 321 Return: -529.96381780166084
INFO:tensorflow:Average training steps per second: 230.99
I0828 10:40:58.331753 140214119393280 replay_runner.py:36] Average training steps per second: 230.99
I0828 10:40:58.749170 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -529.96
INFO:tensorflow:Starting iteration 23

Steps executed: 261 Episode length: 80 Return: -471.716987710948054
INFO:tensorflow:Average training steps per second: 225.42
I0828 10:41:07.613505 140214119393280 replay_runner.py:36] Average training steps per second: 225.42
I0828 10:41:07.869566 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -501.15
INFO:tensorflow:Starting iteration 24

Steps executed: 244 Episode length: 141 Return: -171.87091017307294
INFO:tensorflow:Average training steps per second: 221.60
I0828 10:41:16.662089 140214119393280 replay_runner.py:36] Average training steps per second: 221.60
I0828 10:41:16.870594 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -218.66
INFO:tensorflow:Starting iteration 25

Steps executed: 294 Episode length: 95 Return: -795.578908838291854
INFO:tensorflow:Average training steps per second: 222.47
I0828 10:41:25.747236 140214119393280 replay_runner.py:36] Average training steps per second: 222.47
I0828 10:41:26.031152 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -655.41
INFO:tensorflow:Starting iteration 26

Steps executed: 137 Episode length: 137 Return: -205.47738315906997
INFO:tensorflow:Average training steps per second: 218.80
I0828 10:41:34.915834 140214119393280 replay_runner.py:36] Average training steps per second: 218.80

Steps executed: 229 Episode length: 92 Return: -193.744010757513767
INFO:tensorflow:Starting iteration 27

Steps executed: 371 Episode length: 371 Return: -418.06462016519147
INFO:tensorflow:Average training steps per second: 222.91
I0828 10:41:43.918578 140214119393280 replay_runner.py:36] Average training steps per second: 222.91
I0828 10:41:44.476971 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -418.06
INFO:tensorflow:Starting iteration 28
I0828 10:41:48.769861 140214119393280 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 231.73

Steps executed: 215 Episode length: 82 Return: -404.586964014451306
I0828 10:41:53.276222 140214119393280 run_experiment.py:428] Average undiscounted return per evaluation episode: -429.75
INFO:tensorflow:Starting iteration 29

Steps executed: 262 Episode length: 93 Return: -573.456817773060506
INFO:tensorflow:Average training steps per second: 226.64
I0828 10:42:02.125967 140214119393280 replay_runner.py:36] Average training steps per second: 226.64

Done fixed training!Episode length: 93 Return: -573.456817773060506