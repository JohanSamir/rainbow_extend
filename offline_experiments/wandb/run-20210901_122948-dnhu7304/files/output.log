Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0901 12:29:54.918983 139803418769408 run_experiment.py:549] Creating TrainRunner ...
I0901 12:29:54.929704 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:29:54.929902 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:29:54.929982 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:29:54.930044 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:29:54.930100 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 12:29:54.930201 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:29:54.930284 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:29:54.930382 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:29:54.930444 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:29:54.930520 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 12:29:54.930645 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:29:54.930720 139803418769408 dqn_agent.py:283] 	 seed: 1630499394929656
I0901 12:29:54.934152 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:29:54.934452 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:29:54.935037 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:29:54.935317 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:29:54.935534 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:29:54.935762 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:29:54.935917 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:29:54.936036 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:29:54.936144 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:29:55.150588 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:29:55.570191 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:29:55.584867 139803418769408 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:29:55.594528 139803418769408 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:29:55.594808 139803418769408 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:29:55.594922 139803418769408 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:29:55.595010 139803418769408 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:29:55.595101 139803418769408 dqn_agent.py:275] 	 update_period: 4
I0901 12:29:55.595246 139803418769408 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:29:55.595314 139803418769408 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:29:55.595373 139803418769408 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:29:55.595529 139803418769408 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:29:55.595729 139803418769408 dqn_agent.py:280] 	 optimizer: adam
I0901 12:29:55.595821 139803418769408 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:29:55.595906 139803418769408 dqn_agent.py:283] 	 seed: 1630499395594482
I0901 12:29:55.598822 139803418769408 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:29:55.599103 139803418769408 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:29:55.599280 139803418769408 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:29:55.599430 139803418769408 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:29:55.599567 139803418769408 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:29:55.599697 139803418769408 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:29:55.600071 139803418769408 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:29:55.600297 139803418769408 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:29:55.600449 139803418769408 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:29:55.640103 139803418769408 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:29:55.664834 139803418769408 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:29:55.665367 139803418769408 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 160.78
I0901 12:30:01.885310 139803418769408 replay_runner.py:36] Average training steps per second: 160.78
Steps executed: 200 Episode length: 90 Return: -716.58752158066625
I0901 12:30:03.185093 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -658.60
INFO:tensorflow:Starting iteration 1
I0901 12:30:07.517223 139803418769408 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 225.61
I0901 12:30:11.950953 139803418769408 replay_runner.py:36] Average training steps per second: 225.61

Steps executed: 223 Episode length: 130 Return: 25.224834059745163
INFO:tensorflow:Starting iteration 2

Steps executed: 242 Episode length: 102 Return: -204.53073995653798
INFO:tensorflow:Average training steps per second: 222.53
I0901 12:30:20.991743 139803418769408 replay_runner.py:36] Average training steps per second: 222.53
I0901 12:30:21.213536 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.90
INFO:tensorflow:Starting iteration 3

Steps executed: 280 Episode length: 177 Return: -94.146777627125298
INFO:tensorflow:Average training steps per second: 227.48
I0901 12:30:30.135034 139803418769408 replay_runner.py:36] Average training steps per second: 227.48
I0901 12:30:30.413975 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -345.69
INFO:tensorflow:Starting iteration 4

Steps executed: 272 Episode length: 88 Return: -415.915572323846838
INFO:tensorflow:Average training steps per second: 223.61
I0901 12:30:39.356807 139803418769408 replay_runner.py:36] Average training steps per second: 223.61
I0901 12:30:39.584147 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -380.39
INFO:tensorflow:Starting iteration 5

Steps executed: 210 Episode length: 106 Return: -318.84465858665953
INFO:tensorflow:Average training steps per second: 231.14
I0901 12:30:48.076951 139803418769408 replay_runner.py:36] Average training steps per second: 231.14
I0901 12:30:48.260381 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -203.78
INFO:tensorflow:Starting iteration 6
I0901 12:30:52.508083 139803418769408 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 235.91

Steps executed: 211 Episode length: 120 Return: -66.536320849650653
I0901 12:30:56.911100 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -388.11
INFO:tensorflow:Starting iteration 7

Steps executed: 319 Episode length: 134 Return: -78.601036528132473
INFO:tensorflow:Average training steps per second: 232.36
I0901 12:31:05.514685 139803418769408 replay_runner.py:36] Average training steps per second: 232.36
I0901 12:31:05.780329 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.28
INFO:tensorflow:Starting iteration 8

Steps executed: 207 Episode length: 116 Return: -113.39475942871454
INFO:tensorflow:Average training steps per second: 222.59
I0901 12:31:14.497104 139803418769408 replay_runner.py:36] Average training steps per second: 222.59
I0901 12:31:14.689237 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.87
INFO:tensorflow:Starting iteration 9

Steps executed: 229 Episode length: 78 Return: -374.769468357801844
INFO:tensorflow:Average training steps per second: 226.62
I0901 12:31:23.471626 139803418769408 replay_runner.py:36] Average training steps per second: 226.62
I0901 12:31:23.640695 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.57
INFO:tensorflow:Starting iteration 10

Steps executed: 238 Episode length: 83 Return: -343.999310622391244
INFO:tensorflow:Average training steps per second: 232.16
I0901 12:31:32.304655 139803418769408 replay_runner.py:36] Average training steps per second: 232.16
I0901 12:31:32.516187 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -280.97
INFO:tensorflow:Starting iteration 11

Steps executed: 265 Episode length: 93 Return: -45.4491748283540244
INFO:tensorflow:Average training steps per second: 228.96
I0901 12:31:41.164399 139803418769408 replay_runner.py:36] Average training steps per second: 228.96
I0901 12:31:41.379836 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.41
INFO:tensorflow:Starting iteration 12

Steps executed: 229 Episode length: 70 Return: -224.871620666183644
INFO:tensorflow:Average training steps per second: 227.31
I0901 12:31:49.983901 139803418769408 replay_runner.py:36] Average training steps per second: 227.31
I0901 12:31:50.147842 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.99
INFO:tensorflow:Starting iteration 13

Steps executed: 149 Episode length: 66 Return: -171.645999160781344
INFO:tensorflow:Average training steps per second: 222.15
I0901 12:31:58.974594 139803418769408 replay_runner.py:36] Average training steps per second: 222.15

Steps executed: 234 Episode length: 85 Return: -144.261833256953654
INFO:tensorflow:Starting iteration 14

Steps executed: 237 Episode length: 52 Return: -114.101090811732144
INFO:tensorflow:Average training steps per second: 218.84
I0901 12:32:08.136990 139803418769408 replay_runner.py:36] Average training steps per second: 218.84
I0901 12:32:08.309307 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.60
INFO:tensorflow:Starting iteration 15
I0901 12:32:12.722190 139803418769408 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 224.76

Steps executed: 249 Episode length: 114 Return: 9.65991978304232678
I0901 12:32:17.373763 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.05
INFO:tensorflow:Starting iteration 16

Steps executed: 214 Episode length: 57 Return: -155.217670890695848
INFO:tensorflow:Average training steps per second: 219.89
I0901 12:32:26.329833 139803418769408 replay_runner.py:36] Average training steps per second: 219.89
I0901 12:32:26.487825 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -344.60
INFO:tensorflow:Starting iteration 17
I0901 12:32:30.878839 139803418769408 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 223.00

Steps executed: 272 Episode length: 84 Return: -277.065612617202448
I0901 12:32:35.570869 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.29
INFO:tensorflow:Starting iteration 18

Steps executed: 263 Episode length: 90 Return: -484.155114752569967
INFO:tensorflow:Average training steps per second: 223.12
I0901 12:32:44.482996 139803418769408 replay_runner.py:36] Average training steps per second: 223.12
I0901 12:32:44.739623 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -469.29
INFO:tensorflow:Starting iteration 19

Steps executed: 276 Episode length: 89 Return: -242.494676988483967
INFO:tensorflow:Average training steps per second: 219.71
I0901 12:32:53.767229 139803418769408 replay_runner.py:36] Average training steps per second: 219.71
I0901 12:32:53.962759 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.96
INFO:tensorflow:Starting iteration 20
I0901 12:32:58.398665 139803418769408 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 221.22

Steps executed: 222 Episode length: 72 Return: -168.045740949781487
I0901 12:33:03.081421 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -196.22
INFO:tensorflow:Starting iteration 21

Steps executed: 254 Episode length: 62 Return: -245.043049079196967
INFO:tensorflow:Average training steps per second: 220.70
I0901 12:33:12.017946 139803418769408 replay_runner.py:36] Average training steps per second: 220.70
I0901 12:33:12.209024 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.78
INFO:tensorflow:Starting iteration 22
I0901 12:33:16.439543 139803418769408 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 214.94

Steps executed: 354 Episode length: 180 Return: -264.91893679748733
I0901 12:33:21.412220 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.54
INFO:tensorflow:Starting iteration 23

Steps executed: 237 Episode length: 91 Return: -410.406222016822953
INFO:tensorflow:Average training steps per second: 225.57
I0901 12:33:30.231555 139803418769408 replay_runner.py:36] Average training steps per second: 225.57
I0901 12:33:30.433403 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -475.04
INFO:tensorflow:Starting iteration 24

Steps executed: 213 Episode length: 76 Return: -330.922373061064653
INFO:tensorflow:Average training steps per second: 220.56
I0901 12:33:39.362866 139803418769408 replay_runner.py:36] Average training steps per second: 220.56
I0901 12:33:39.513453 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -252.99
INFO:tensorflow:Starting iteration 25

Steps executed: 200 Episode length: 73 Return: 26.16544185622712973
INFO:tensorflow:Average training steps per second: 223.01
I0901 12:33:47.975806 139803418769408 replay_runner.py:36] Average training steps per second: 223.01
I0901 12:33:48.110510 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.29
INFO:tensorflow:Starting iteration 26

Steps executed: 266 Episode length: 86 Return: -189.238248057205963
INFO:tensorflow:Average training steps per second: 226.47
I0901 12:33:56.684634 139803418769408 replay_runner.py:36] Average training steps per second: 226.47
I0901 12:33:56.921430 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.67
INFO:tensorflow:Starting iteration 27

Steps executed: 317 Episode length: 158 Return: -242.27972030562658
INFO:tensorflow:Average training steps per second: 228.18
I0901 12:34:05.562866 139803418769408 replay_runner.py:36] Average training steps per second: 228.18
I0901 12:34:05.834005 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -222.54
INFO:tensorflow:Starting iteration 28

Steps executed: 206 Episode length: 83 Return: -157.162658674821158
INFO:tensorflow:Average training steps per second: 221.34
I0901 12:34:14.646372 139803418769408 replay_runner.py:36] Average training steps per second: 221.34
I0901 12:34:14.823902 139803418769408 run_experiment.py:428] Average undiscounted return per evaluation episode: -266.64
INFO:tensorflow:Starting iteration 29

Steps executed: 263 Episode length: 86 Return: -583.550612584508478
INFO:tensorflow:Average training steps per second: 219.46
I0901 12:34:23.668751 139803418769408 replay_runner.py:36] Average training steps per second: 219.46

Done fixed training!Episode length: 86 Return: -583.550612584508478