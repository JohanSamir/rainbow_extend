I0901 23:44:09.144827 140183943698432 run_experiment.py:549] Creating TrainRunner ...
I0901 23:44:09.154559 140183943698432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:44:09.154769 140183943698432 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:44:09.154856 140183943698432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:44:09.154926 140183943698432 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:44:09.154994 140183943698432 dqn_agent.py:275] 	 update_period: 4
I0901 23:44:09.155090 140183943698432 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:44:09.155234 140183943698432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:44:09.155361 140183943698432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:44:09.155540 140183943698432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:44:09.155694 140183943698432 dqn_agent.py:280] 	 optimizer: adam
I0901 23:44:09.155781 140183943698432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:44:09.155852 140183943698432 dqn_agent.py:283] 	 seed: 1630539849154511
I0901 23:44:09.158058 140183943698432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:44:09.158293 140183943698432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:44:09.158424 140183943698432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:44:09.158546 140183943698432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:44:09.158685 140183943698432 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:44:09.158834 140183943698432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:44:09.158950 140183943698432 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:44:09.159047 140183943698432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:44:09.159143 140183943698432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:44:10.554131 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0901 23:44:10.900602 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:44:10.912647 140183943698432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:44:10.922043 140183943698432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:44:10.922272 140183943698432 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:44:10.922461 140183943698432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:44:10.922579 140183943698432 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:44:10.922681 140183943698432 dqn_agent.py:275] 	 update_period: 4
I0901 23:44:10.922753 140183943698432 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:44:10.922814 140183943698432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:44:10.922894 140183943698432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:44:10.923145 140183943698432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:44:10.923431 140183943698432 dqn_agent.py:280] 	 optimizer: adam
I0901 23:44:10.923618 140183943698432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:44:10.923774 140183943698432 dqn_agent.py:283] 	 seed: 1630539850921997
I0901 23:44:10.926724 140183943698432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:44:10.926911 140183943698432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:44:10.927033 140183943698432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:44:10.927150 140183943698432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:44:10.927261 140183943698432 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:44:10.927402 140183943698432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:44:10.927505 140183943698432 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:44:10.927592 140183943698432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:44:10.927683 140183943698432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:44:10.959074 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:44:10.977934 140183943698432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:44:10.978345 140183943698432 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 156.15
I0901 23:44:17.382685 140183943698432 replay_runner.py:36] Average training steps per second: 156.15
I0901 23:44:18.613090 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.62
Steps executed: 264 Episode length: 129 Return: -340.07194018540997
INFO:tensorflow:Starting iteration 1
I0901 23:44:22.946893 140183943698432 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 224.31
I0901 23:44:27.405488 140183943698432 replay_runner.py:36] Average training steps per second: 224.31

Steps executed: 250 Episode length: 147 Return: -291.22258899647547
INFO:tensorflow:Starting iteration 2
I0901 23:44:31.729027 140183943698432 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 234.98
I0901 23:44:35.985066 140183943698432 replay_runner.py:36] Average training steps per second: 234.98

Steps executed: 314 Episode length: 155 Return: -128.92155038602827
INFO:tensorflow:Starting iteration 3
I0901 23:44:40.432448 140183943698432 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 236.19
I0901 23:44:44.666623 140183943698432 replay_runner.py:36] Average training steps per second: 236.19

Steps executed: 1000 Episode length: 1000 Return: -102.46872721485983
INFO:tensorflow:Starting iteration 4
I0901 23:44:51.829457 140183943698432 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 231.65

Steps executed: 1000 Episode length: 1000 Return: -174.12088915738207
I0901 23:44:58.313287 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.12
INFO:tensorflow:Starting iteration 5
I0901 23:45:02.643176 140183943698432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 228.94

Steps executed: 1000 Episode length: 1000 Return: -105.51953141897675
I0901 23:45:09.741974 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.52
INFO:tensorflow:Starting iteration 6
I0901 23:45:14.147392 140183943698432 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 225.73

Steps executed: 1000 Episode length: 1000 Return: -875.25562100687365
I0901 23:45:21.545154 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -875.26
INFO:tensorflow:Starting iteration 7
I0901 23:45:25.927777 140183943698432 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 227.71

Steps executed: 1000 Episode length: 1000 Return: -205.41216041961265
I0901 23:45:33.769993 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -205.41
INFO:tensorflow:Starting iteration 8
I0901 23:45:38.172492 140183943698432 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 220.98
I0901 23:45:42.698173 140183943698432 replay_runner.py:36] Average training steps per second: 220.98

Steps executed: 1000 Episode length: 1000 Return: -466.65628164498594
INFO:tensorflow:Starting iteration 9
I0901 23:45:49.531574 140183943698432 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 222.56

Steps executed: 852 Episode length: 852 Return: -1540.327222779485594
I0901 23:45:56.603749 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -1540.33
INFO:tensorflow:Starting iteration 10
I0901 23:46:00.993268 140183943698432 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 219.19

Steps executed: 1000 Episode length: 1000 Return: -144.08049434969143
I0901 23:46:07.524829 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.08
INFO:tensorflow:Starting iteration 11

Steps executed: 207 Episode length: 110 Return: -726.6475361760262143
INFO:tensorflow:Average training steps per second: 224.89
I0901 23:46:16.388103 140183943698432 replay_runner.py:36] Average training steps per second: 224.89
I0901 23:46:16.576336 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -398.48
INFO:tensorflow:Starting iteration 12

Steps executed: 280 Episode length: 171 Return: -91.96436323128157143
INFO:tensorflow:Average training steps per second: 224.41
I0901 23:46:25.416481 140183943698432 replay_runner.py:36] Average training steps per second: 224.41
I0901 23:46:25.683265 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.21
INFO:tensorflow:Starting iteration 13
I0901 23:46:30.052572 140183943698432 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 221.51

Steps executed: 1000 Episode length: 1000 Return: -114.41395242984902
I0901 23:46:37.610897 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.41
INFO:tensorflow:Starting iteration 14

Steps executed: 396 Episode length: 396 Return: -235.4504849679786902
INFO:tensorflow:Average training steps per second: 219.97
I0901 23:46:46.526697 140183943698432 replay_runner.py:36] Average training steps per second: 219.97
I0901 23:46:47.252724 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.45
INFO:tensorflow:Starting iteration 15

Steps executed: 345 Episode length: 147 Return: -138.2103437036173902
INFO:tensorflow:Average training steps per second: 232.89
I0901 23:46:55.911716 140183943698432 replay_runner.py:36] Average training steps per second: 232.89
I0901 23:46:56.203539 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.26
INFO:tensorflow:Starting iteration 16
I0901 23:47:00.575660 140183943698432 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 224.95
I0901 23:47:05.021510 140183943698432 replay_runner.py:36] Average training steps per second: 224.95

Steps executed: 1000 Episode length: 1000 Return: -20.517679953649192
INFO:tensorflow:Starting iteration 17
I0901 23:47:11.963979 140183943698432 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 229.87

Steps executed: 1000 Episode length: 1000 Return: -64.221128906161552
I0901 23:47:20.132303 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -64.22
INFO:tensorflow:Starting iteration 18
I0901 23:47:24.421113 140183943698432 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 232.52
I0901 23:47:28.722299 140183943698432 replay_runner.py:36] Average training steps per second: 232.52

Steps executed: 1000 Episode length: 1000 Return: 38.8209134470464652
INFO:tensorflow:Starting iteration 19
I0901 23:47:35.794666 140183943698432 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 228.96

Steps executed: 823 Episode length: 823 Return: -563.3718614174475652
I0901 23:47:41.975372 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -563.37
INFO:tensorflow:Starting iteration 20

Steps executed: 481 Episode length: 312 Return: -36.73167356472469652
INFO:tensorflow:Average training steps per second: 232.75
I0901 23:47:50.539517 140183943698432 replay_runner.py:36] Average training steps per second: 232.75
I0901 23:47:51.105754 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -47.97
INFO:tensorflow:Starting iteration 21

Steps executed: 586 Episode length: 586 Return: -22.28324086480849652
INFO:tensorflow:Average training steps per second: 230.77
I0901 23:47:59.683546 140183943698432 replay_runner.py:36] Average training steps per second: 230.77
I0901 23:48:01.375956 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -22.28
INFO:tensorflow:Starting iteration 22
I0901 23:48:05.750695 140183943698432 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 229.57

Steps executed: 793 Episode length: 793 Return: -361.9351154400243652
I0901 23:48:12.421046 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.94
INFO:tensorflow:Starting iteration 23
I0901 23:48:16.884755 140183943698432 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 222.48

Steps executed: 1000 Episode length: 1000 Return: -4.1976351684753032
I0901 23:48:24.189821 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -4.20
INFO:tensorflow:Starting iteration 24
I0901 23:48:28.630699 140183943698432 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 227.70

Steps executed: 1000 Episode length: 1000 Return: -90.932774087675642
I0901 23:48:35.727666 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.93
INFO:tensorflow:Starting iteration 25
I0901 23:48:40.295085 140183943698432 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 229.80

Steps executed: 756 Episode length: 756 Return: -445.9050814523068342
I0901 23:48:46.850307 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -445.91
INFO:tensorflow:Starting iteration 26
I0901 23:48:51.270361 140183943698432 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 230.48

Steps executed: 550 Episode length: 352 Return: 206.52098235856135342
I0901 23:48:56.290297 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: 109.31
INFO:tensorflow:Starting iteration 27

Steps executed: 338 Episode length: 338 Return: -492.1048625649056642
INFO:tensorflow:Average training steps per second: 220.07
I0901 23:49:05.181827 140183943698432 replay_runner.py:36] Average training steps per second: 220.07
I0901 23:49:05.745468 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -492.10
INFO:tensorflow:Starting iteration 28

Steps executed: 622 Episode length: 473 Return: 236.15744787495686642
INFO:tensorflow:Average training steps per second: 225.83
I0901 23:49:14.494804 140183943698432 replay_runner.py:36] Average training steps per second: 225.83
I0901 23:49:15.303821 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -24.40
INFO:tensorflow:Starting iteration 29

Steps executed: 293 Episode length: 127 Return: -69.17333639364323342
INFO:tensorflow:Average training steps per second: 231.46
I0901 23:49:24.065075 140183943698432 replay_runner.py:36] Average training steps per second: 231.46

Done fixed training!Episode length: 127 Return: -69.17333639364323342