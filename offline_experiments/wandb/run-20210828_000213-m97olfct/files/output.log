error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
Training agent 2, please be patient, may be a while...
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0828 00:02:18.359042 139729596655616 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0828 00:02:18.409892 139729596655616 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 00:02:18.410933 139729596655616 dqn_agent.py:272] 	 gamma: 0.990000
I0828 00:02:18.410999 139729596655616 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 00:02:18.411051 139729596655616 dqn_agent.py:274] 	 min_replay_history: 500
I0828 00:02:18.411110 139729596655616 dqn_agent.py:275] 	 update_period: 4
I0828 00:02:18.411159 139729596655616 dqn_agent.py:276] 	 target_update_period: 100
I0828 00:02:18.411215 139729596655616 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 00:02:18.411267 139729596655616 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 00:02:18.411435 139729596655616 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 00:02:18.411507 139729596655616 dqn_agent.py:280] 	 optimizer: adam
I0828 00:02:18.411585 139729596655616 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 00:02:18.411653 139729596655616 dqn_agent.py:283] 	 seed: 1630108938409833
I0828 00:02:18.413387 139729596655616 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 00:02:18.413524 139729596655616 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0828 00:02:18.413602 139729596655616 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 00:02:18.413665 139729596655616 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 00:02:18.413721 139729596655616 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 00:02:18.413821 139729596655616 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 00:02:18.413880 139729596655616 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 00:02:18.413947 139729596655616 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 00:02:18.414017 139729596655616 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 00:02:19.609058 139729596655616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 00:02:19.700883 139729596655616 run_experiment.py:516] Beginning training...
I0828 00:02:19.701043 139729596655616 run_experiment.py:447] Starting iteration 0
error: Choose a correct Normalization Modulern: -500.0
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
W0828 00:02:20.435205 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
error: Choose a correct Normalization Moduleurn: -199.0
error: Choose a correct Normalization Module
W0828 00:02:22.942271 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:02:23.803858 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:02:23.804248 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -353.67
I0828 00:02:23.804389 139729596655616 run_experiment.py:408] Average training steps per second: 259.07























Steps executed: 123731 Episode length: 141 Return: -140.0
I0828 00:03:12.485378 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.46
I0828 00:03:12.539646 139729596655616 run_experiment.py:447] Starting iteration 1
W0828 00:03:12.942109 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 398 Episode length: 96 Return: -95.0.05.0
W0828 00:03:14.096775 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:03:14.696723 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:03:15.025995 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:03:15.446165 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 825 Episode length: 88 Return: -87.0.05.0
W0828 00:03:16.214752 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:03:16.603696 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:03:16.603982 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -113.44
























Steps executed: 120342 Episode length: 131 Return: -130.0
I0828 00:04:05.888838 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.59

Steps executed: 125032 Episode length: 116 Return: -115.0
W0828 00:04:06.352306 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:04:06.676162 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:04:07.111889 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:04:07.559503 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 516 Episode length: 103 Return: -102.05.0
W0828 00:04:08.340630 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:04:08.705147 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:04:09.012525 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:04:09.370457 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 984 Episode length: 105 Return: -104.05.0
W0828 00:04:10.181725 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:04:10.182008 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -97.36
























Steps executed: 124325 Episode length: 70 Return: -69.0.0
I0828 00:04:58.785635 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.53
I0828 00:04:58.842936 139729596655616 run_experiment.py:447] Starting iteration 3
W0828 00:04:59.287833 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 336 Episode length: 102 Return: -101.00.0
W0828 00:05:00.271364 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:05:00.655963 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:05:01.197261 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 837 Episode length: 134 Return: -133.00.0
W0828 00:05:02.275024 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:05:02.639486 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:05:03.052161 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:05:03.052490 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -113.67
























Steps executed: 125000 Episode length: 500 Return: -500.0
I0828 00:05:50.453512 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
I0828 00:05:50.510512 139729596655616 run_experiment.py:447] Starting iteration 4

Steps executed: 475 Episode length: 239 Return: -238.00.0
W0828 00:05:52.433057 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:05:53.175574 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:05:53.569846 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:05:53.951605 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 148 Episode length: 78 Return: -77.0000.0
W0828 00:05:54.645458 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:05:54.645760 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -150.00
























Steps executed: 123527 Episode length: 157 Return: -156.0
I0828 00:06:43.136883 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.52
I0828 00:06:43.198823 139729596655616 run_experiment.py:447] Starting iteration 5
W0828 00:06:43.764119 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 301 Episode length: 154 Return: -153.00.0
W0828 00:06:44.803689 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:06:45.444942 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:06:45.781106 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 803 Episode length: 127 Return: -126.00.0
W0828 00:06:46.689435 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:06:46.998179 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:06:47.342303 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:06:47.342634 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -118.67























Steps executed: 121235 Episode length: 80 Return: -79.0.0
I0828 00:07:33.844775 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.26
I0828 00:07:33.913637 139729596655616 run_experiment.py:447] Starting iteration 6

Steps executed: 116 Episode length: 116 Return: -115.08.0
W0828 00:07:34.735688 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:07:35.149662 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:07:35.404798 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:07:35.766213 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:07:36.129530 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 540 Episode length: 86 Return: -85.0.08.0
W0828 00:07:36.972272 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:07:37.321619 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:07:37.882384 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:07:38.336673 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:07:38.337054 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -95.82
























Steps executed: 124500 Episode length: 500 Return: -500.0
I0828 00:08:24.771538 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
I0828 00:08:24.839111 139729596655616 run_experiment.py:447] Starting iteration 7
W0828 00:08:25.252668 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:08:25.757732 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 338 Episode length: 110 Return: -109.00.0
W0828 00:08:26.851468 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:08:27.234506 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:08:27.655363 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:08:28.109726 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 933 Episode length: 116 Return: -115.00.0
W0828 00:08:28.909748 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:08:28.910083 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -111.44
























Steps executed: 123778 Episode length: 74 Return: -73.0.0
I0828 00:09:17.553917 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.62
I0828 00:09:17.632201 139729596655616 run_experiment.py:447] Starting iteration 8
W0828 00:09:17.983548 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:09:18.425990 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 355 Episode length: 74 Return: -73.0.00.0
W0828 00:09:19.037016 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:09:19.453505 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:09:19.873846 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:09:20.311478 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 827 Episode length: 136 Return: -135.00.0
W0828 00:09:21.135493 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:09:21.578090 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:09:21.578503 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -100.50
























Steps executed: 122552 Episode length: 104 Return: -103.0
I0828 00:10:09.824917 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.98
I0828 00:10:09.898902 139729596655616 run_experiment.py:447] Starting iteration 9
W0828 00:10:10.175437 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:10:10.466361 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 262 Episode length: 113 Return: -112.06.0
W0828 00:10:11.231358 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:10:11.569883 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:10:12.037073 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 649 Episode length: 89 Return: -88.0.06.0
W0828 00:10:13.073448 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:10:13.416255 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:10:13.852263 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:10:13.852547 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -102.50
























Steps executed: 122857 Episode length: 127 Return: -126.0
I0828 00:11:02.064749 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.86
I0828 00:11:02.139284 139729596655616 run_experiment.py:447] Starting iteration 10

Steps executed: 247 Episode length: 86 Return: -85.0.00.0
W0828 00:11:03.088726 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:11:03.548254 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:11:03.961094 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 764 Episode length: 117 Return: -116.00.0
W0828 00:11:05.072024 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:11:05.367129 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:11:05.763437 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:11:06.206755 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:11:06.207081 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -114.67
























Steps executed: 121415 Episode length: 72 Return: -71.0.0
I0828 00:11:54.393847 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.65

Steps executed: 125013 Episode length: 69 Return: -68.0.0
W0828 00:11:55.345930 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:11:55.843307 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:11:56.246949 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:11:56.596075 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 619 Episode length: 89 Return: -88.0.00.0
W0828 00:11:57.364754 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:11:57.716660 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:11:58.142745 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:11:58.505982 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:11:58.506313 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -112.22























Steps executed: 121591 Episode length: 500 Return: -500.0
I0828 00:12:44.577293 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -383.48
I0828 00:12:44.667108 139729596655616 run_experiment.py:447] Starting iteration 12

Steps executed: 125128 Episode length: 500 Return: -500.0
W0828 00:12:45.597314 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:12:45.906464 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:12:46.804642 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 639 Episode length: 99 Return: -98.0.00.0
W0828 00:12:47.663240 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:12:48.185296 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:12:48.608817 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:12:48.609190 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -124.25
























Steps executed: 121327 Episode length: 72 Return: -71.0.0

Steps executed: 102 Episode length: 102 Return: -101.00.0
I0828 00:13:36.970923 139729596655616 run_experiment.py:447] Starting iteration 13
W0828 00:13:37.378299 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:13:37.663388 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:13:38.139504 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:13:38.588819 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 615 Episode length: 130 Return: -129.00.0
W0828 00:13:39.404278 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:13:39.734374 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:13:40.189374 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:13:40.577376 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 1132 Episode length: 88 Return: -87.000.0
W0828 00:13:41.179487 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:13:41.179820 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -96.27























Steps executed: 124583 Episode length: 500 Return: -500.0
I0828 00:14:27.501305 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.05
I0828 00:14:27.598138 139729596655616 run_experiment.py:447] Starting iteration 14
W0828 00:14:28.294083 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 374 Episode length: 99 Return: -98.0.00.0
W0828 00:14:29.109361 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:14:29.450516 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:14:29.929898 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 850 Episode length: 126 Return: -125.00.0
W0828 00:14:31.076705 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:14:31.707375 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:14:31.707810 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -124.12
























Steps executed: 125018 Episode length: 174 Return: -173.0
I0828 00:15:19.613501 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.76
I0828 00:15:19.704823 139729596655616 run_experiment.py:447] Starting iteration 15
W0828 00:15:20.009066 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:15:20.299140 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:15:20.736297 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 471 Episode length: 106 Return: -105.03.0
W0828 00:15:21.518747 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:15:21.921314 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:15:22.224726 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 916 Episode length: 98 Return: -97.0.03.0
W0828 00:15:23.214777 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:15:24.182617 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:15:24.182999 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -116.10
























Steps executed: 124329 Episode length: 500 Return: -500.0
I0828 00:16:12.152283 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -345.77
I0828 00:16:12.256908 139729596655616 run_experiment.py:447] Starting iteration 16
W0828 00:16:12.637946 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 340 Episode length: 126 Return: -125.00.0
W0828 00:16:13.620589 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:16:14.137456 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:16:14.524900 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:16:14.883435 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 866 Episode length: 123 Return: -122.00.0
W0828 00:16:15.723552 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:16:16.237820 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:16:16.238140 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -110.11
























Steps executed: 125319 Episode length: 500 Return: -500.0
I0828 00:17:03.772782 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -321.65
I0828 00:17:03.877947 139729596655616 run_experiment.py:447] Starting iteration 17
W0828 00:17:04.345365 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 353 Episode length: 234 Return: -233.00.0
W0828 00:17:05.782794 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:17:06.138170 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:17:06.653419 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 833 Episode length: 161 Return: -160.00.0
W0828 00:17:07.672554 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:17:08.019165 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:17:08.019465 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -124.88























Steps executed: 121617 Episode length: 128 Return: -127.0
I0828 00:17:55.024589 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.63

Steps executed: 113 Episode length: 113 Return: -112.04.0
W0828 00:17:55.562329 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:17:55.857051 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:17:56.192269 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:17:56.530230 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:17:56.866329 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 592 Episode length: 141 Return: -140.04.0
W0828 00:17:57.841699 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 934 Episode length: 232 Return: -231.04.0
W0828 00:18:00.672226 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:18:00.672541 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -158.44
























Steps executed: 123776 Episode length: 78 Return: -77.0.0
I0828 00:18:48.650116 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.77
I0828 00:18:48.757919 139729596655616 run_experiment.py:447] Starting iteration 19
W0828 00:18:49.211954 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 307 Episode length: 88 Return: -87.0004.0
W0828 00:18:49.989879 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:18:50.594677 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:18:50.950225 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 797 Episode length: 100 Return: -99.004.0
W0828 00:18:51.974449 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:18:52.437633 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:18:52.944807 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:18:52.945294 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -115.11























Steps executed: 120845 Episode length: 93 Return: -92.0.0
I0828 00:19:39.625792 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -225.02

Steps executed: 125289 Episode length: 500 Return: -500.0
W0828 00:19:40.156360 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:19:40.607123 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:19:40.994205 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:19:41.409460 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 482 Episode length: 80 Return: -79.0.00.0
W0828 00:19:42.210843 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:19:42.886483 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 880 Episode length: 124 Return: -123.00.0
W0828 00:19:44.216001 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:19:44.216315 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -118.67
























Steps executed: 122938 Episode length: 73 Return: -72.0.0
I0828 00:20:33.098932 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.69
I0828 00:20:33.212067 139729596655616 run_experiment.py:447] Starting iteration 21

Steps executed: 197 Episode length: 102 Return: -101.00.0
W0828 00:20:33.931818 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:20:34.553687 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:20:34.930369 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:20:35.247729 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:20:35.593021 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 716 Episode length: 78 Return: -77.0.00.0
W0828 00:20:36.408206 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:20:36.843818 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:20:37.291655 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:20:37.291996 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -108.10
























Steps executed: 122100 Episode length: 71 Return: -70.0.0
I0828 00:21:25.361301 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.82
I0828 00:21:25.479945 139729596655616 run_experiment.py:447] Starting iteration 22

Steps executed: 131 Episode length: 131 Return: -130.00.0
W0828 00:21:26.268258 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:21:26.664170 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:21:26.955367 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:21:27.310935 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 563 Episode length: 77 Return: -76.0.00.0
W0828 00:21:28.360654 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:21:28.665892 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:21:28.939938 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:21:29.278394 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:21:29.278719 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -99.20























Steps executed: 121884 Episode length: 116 Return: -115.0
I0828 00:22:15.620304 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -190.94
I0828 00:22:15.740406 139729596655616 run_experiment.py:447] Starting iteration 23

Steps executed: 192 Episode length: 106 Return: -105.05.0
W0828 00:22:16.480372 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:22:16.883565 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:22:17.375467 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 663 Episode length: 145 Return: -144.05.0
W0828 00:22:18.305220 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:22:18.621894 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:22:19.053574 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:22:19.464449 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.























Steps executed: 121812 Episode length: 125 Return: -124.0
I0828 00:22:19.905833 139729596655616 run_experiment.py:408] Average training steps per second: 259.29
I0828 00:23:05.454336 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.27

Steps executed: 102 Episode length: 102 Return: -101.07.0
W0828 00:23:05.979352 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:23:06.429134 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:23:07.028925 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 469 Episode length: 100 Return: -99.007.0
W0828 00:23:08.576700 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:23:08.907282 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:23:09.331901 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:23:09.669477 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:23:09.669776 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -130.50
























Steps executed: 86 Episode length: 86 Return: -85.0-123.0
I0828 00:23:56.206274 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.62
I0828 00:23:56.329298 139729596655616 run_experiment.py:447] Starting iteration 25
W0828 00:23:56.651383 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:23:56.950126 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:23:57.301450 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:23:57.593716 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 543 Episode length: 125 Return: -124.03.0
W0828 00:23:58.394380 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:23:58.763504 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:23:59.127732 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:23:59.459913 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 360 Episode length: 100 Return: -99.000.0
W0828 00:24:00.569376 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:24:00.569640 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -100.27























Steps executed: 124896 Episode length: 90 Return: -89.000
I0828 00:24:46.607899 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -98.67
I0828 00:24:46.744370 139729596655616 run_experiment.py:447] Starting iteration 26
W0828 00:24:47.217198 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:24:47.604115 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 417 Episode length: 97 Return: -96.0.06.0
W0828 00:24:48.366340 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:24:48.793787 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:24:49.212408 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:24:49.550666 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 991 Episode length: 118 Return: -117.06.0
W0828 00:24:50.562595 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:24:50.998244 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:24:50.998566 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -109.40























Steps executed: 125068 Episode length: 99 Return: -98.0.0
I0828 00:25:36.498883 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.19
I0828 00:25:36.629275 139729596655616 run_experiment.py:447] Starting iteration 27
W0828 00:25:36.941462 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:25:37.262402 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 529 Episode length: 253 Return: -252.00.0
W0828 00:25:38.624982 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:25:38.963541 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:25:39.435419 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:25:39.861156 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 892 Episode length: 132 Return: -131.00.0
W0828 00:25:40.577301 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:25:40.577597 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -114.78























Steps executed: 122316 Episode length: 116 Return: -115.0
I0828 00:26:27.706212 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.44
I0828 00:26:27.839813 139729596655616 run_experiment.py:447] Starting iteration 28

Steps executed: 193 Episode length: 113 Return: -112.00.0
W0828 00:26:28.582592 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:26:29.299632 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:26:29.593475 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:26:29.957026 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 694 Episode length: 134 Return: -133.00.0
W0828 00:26:30.791155 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:26:31.139394 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:26:31.848257 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:26:31.848598 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -116.44























Steps executed: 125081 Episode length: 102 Return: -101.0
I0828 00:27:16.933048 139729596655616 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.71
I0828 00:27:17.075701 139729596655616 run_experiment.py:447] Starting iteration 29
W0828 00:27:17.498364 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:27:17.984426 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 402 Episode length: 89 Return: -88.0.01.0
W0828 00:27:18.653068 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:27:19.168542 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:27:19.744727 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:27:20.087413 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.

Steps executed: 947 Episode length: 89 Return: -88.0.01.0
W0828 00:27:20.758037 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:27:21.149176 139729596655616 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:27:21.149510 139729596655616 run_experiment.py:406] Average undiscounted return per training episode: -103.70






















Steps executed: 121957 Episode length: 80 Return: -79.0.0

Done training!: 125214 Episode length: 500 Return: -500.0