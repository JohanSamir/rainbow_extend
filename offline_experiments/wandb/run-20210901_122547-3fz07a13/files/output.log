Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0901 12:25:53.711942 139809518303232 run_experiment.py:549] Creating TrainRunner ...
I0901 12:25:53.725543 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:25:53.725867 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:25:53.726137 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:25:53.726350 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:25:53.726493 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 12:25:53.726692 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:25:53.726806 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:25:53.726908 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:25:53.727013 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:25:53.727176 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 12:25:53.727260 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:25:53.727361 139809518303232 dqn_agent.py:283] 	 seed: 1630499153725475
I0901 12:25:53.730751 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:25:53.730976 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:25:53.731197 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:25:53.731352 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:25:53.731555 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:25:53.731658 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:25:53.731786 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:25:53.731962 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:25:53.732225 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:25:53.966398 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:54.398566 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:54.412982 139809518303232 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:25:54.422950 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:25:54.423169 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:25:54.423256 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:25:54.423360 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:25:54.423434 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 12:25:54.423497 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:25:54.423562 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:25:54.423621 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:25:54.423733 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:25:54.423795 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 12:25:54.423853 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:25:54.423911 139809518303232 dqn_agent.py:283] 	 seed: 1630499154422893
I0901 12:25:54.426740 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:25:54.427027 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:25:54.427208 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:25:54.427309 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:25:54.427388 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:25:54.427625 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:25:54.428010 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:25:54.428295 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:25:54.428464 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:25:54.464707 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:25:54.488075 139809518303232 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:25:54.488403 139809518303232 replay_runner.py:41] Starting iteration 0
Steps executed: 227 Episode length: 89 Return: -112.71588084632173
INFO:tensorflow:Average training steps per second: 143.51
I0901 12:26:01.456975 139809518303232 replay_runner.py:36] Average training steps per second: 143.51
I0901 12:26:02.733921 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.99
INFO:tensorflow:Starting iteration 1

Steps executed: 252 Episode length: 84 Return: -734.10943626517363
INFO:tensorflow:Average training steps per second: 210.82
I0901 12:26:11.890443 139809518303232 replay_runner.py:36] Average training steps per second: 210.82
I0901 12:26:12.142503 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -678.15
INFO:tensorflow:Starting iteration 2
I0901 12:26:16.642146 139809518303232 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 209.28

Steps executed: 207 Episode length: 95 Return: -708.623553885424566
I0901 12:26:21.617022 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -496.76
INFO:tensorflow:Starting iteration 3

Steps executed: 240 Episode length: 94 Return: -210.039969847527236
INFO:tensorflow:Average training steps per second: 209.15
I0901 12:26:30.852898 139809518303232 replay_runner.py:36] Average training steps per second: 209.15
I0901 12:26:31.088906 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.61
INFO:tensorflow:Starting iteration 4

Steps executed: 260 Episode length: 169 Return: -450.39233712216037
INFO:tensorflow:Average training steps per second: 206.67
I0901 12:26:40.417413 139809518303232 replay_runner.py:36] Average training steps per second: 206.67
I0901 12:26:40.713792 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -583.85
INFO:tensorflow:Starting iteration 5

Steps executed: 268 Episode length: 183 Return: -56.545513095211617
INFO:tensorflow:Average training steps per second: 211.91
I0901 12:26:49.943538 139809518303232 replay_runner.py:36] Average training steps per second: 211.91
I0901 12:26:50.237399 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -381.08
INFO:tensorflow:Starting iteration 6

Steps executed: 253 Episode length: 253 Return: -277.62785312571517
INFO:tensorflow:Average training steps per second: 214.96
I0901 12:27:00.039687 139809518303232 replay_runner.py:36] Average training steps per second: 214.96
I0901 12:27:00.357641 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.63
INFO:tensorflow:Starting iteration 7

Steps executed: 193 Episode length: 103 Return: -193.51771662322917
INFO:tensorflow:Average training steps per second: 215.65
I0901 12:27:09.385234 139809518303232 replay_runner.py:36] Average training steps per second: 215.65

Steps executed: 352 Episode length: 159 Return: -127.27923855877341
INFO:tensorflow:Starting iteration 8

Steps executed: 210 Episode length: 210 Return: -277.13138179012753
INFO:tensorflow:Average training steps per second: 212.34
I0901 12:27:18.877269 139809518303232 replay_runner.py:36] Average training steps per second: 212.34
I0901 12:27:19.081421 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.13
INFO:tensorflow:Starting iteration 9

Steps executed: 242 Episode length: 151 Return: -344.73560173960885
INFO:tensorflow:Average training steps per second: 212.99
I0901 12:27:28.313940 139809518303232 replay_runner.py:36] Average training steps per second: 212.99
I0901 12:27:28.569792 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -525.43
INFO:tensorflow:Starting iteration 10

Steps executed: 119 Episode length: 119 Return: -145.62100477913938
INFO:tensorflow:Average training steps per second: 211.05
I0901 12:27:37.622100 139809518303232 replay_runner.py:36] Average training steps per second: 211.05

Steps executed: 261 Episode length: 142 Return: -26.664951182567828
INFO:tensorflow:Starting iteration 11

Steps executed: 269 Episode length: 119 Return: -209.94740333005623
INFO:tensorflow:Average training steps per second: 213.93
I0901 12:27:47.074147 139809518303232 replay_runner.py:36] Average training steps per second: 213.93
I0901 12:27:47.325754 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -298.17
INFO:tensorflow:Starting iteration 12

Steps executed: 247 Episode length: 114 Return: -274.57943344973411
INFO:tensorflow:Average training steps per second: 224.96
I0901 12:27:56.168238 139809518303232 replay_runner.py:36] Average training steps per second: 224.96
I0901 12:27:56.370430 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -251.80
INFO:tensorflow:Starting iteration 13

Steps executed: 303 Episode length: 140 Return: 22.7509431568943231
INFO:tensorflow:Average training steps per second: 225.65
I0901 12:28:05.197047 139809518303232 replay_runner.py:36] Average training steps per second: 225.65
I0901 12:28:05.461728 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -31.90
INFO:tensorflow:Starting iteration 14

Steps executed: 232 Episode length: 108 Return: -264.35430022328651
INFO:tensorflow:Average training steps per second: 217.31
I0901 12:28:14.462840 139809518303232 replay_runner.py:36] Average training steps per second: 217.31
I0901 12:28:14.656164 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.47
INFO:tensorflow:Starting iteration 15

Steps executed: 220 Episode length: 94 Return: -156.518806003648085
INFO:tensorflow:Average training steps per second: 233.51
I0901 12:28:23.282130 139809518303232 replay_runner.py:36] Average training steps per second: 233.51
I0901 12:28:23.451369 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -233.96
INFO:tensorflow:Starting iteration 16

Steps executed: 248 Episode length: 79 Return: -142.399257342899975
INFO:tensorflow:Average training steps per second: 231.65
I0901 12:28:32.057928 139809518303232 replay_runner.py:36] Average training steps per second: 231.65
I0901 12:28:32.243606 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -125.59
INFO:tensorflow:Starting iteration 17

Steps executed: 241 Episode length: 68 Return: -466.929673325162475
INFO:tensorflow:Average training steps per second: 227.90
I0901 12:28:40.963993 139809518303232 replay_runner.py:36] Average training steps per second: 227.90
I0901 12:28:41.198551 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.26
INFO:tensorflow:Starting iteration 18

Steps executed: 430 Episode length: 355 Return: 191.104251448187885
INFO:tensorflow:Average training steps per second: 223.47
I0901 12:28:50.087771 139809518303232 replay_runner.py:36] Average training steps per second: 223.47
I0901 12:28:50.666374 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.39
INFO:tensorflow:Starting iteration 19
I0901 12:28:55.131331 139809518303232 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 218.91
I0901 12:28:59.700746 139809518303232 replay_runner.py:36] Average training steps per second: 218.91

Steps executed: 229 Episode length: 60 Return: -127.980312362577665
INFO:tensorflow:Starting iteration 20

Steps executed: 259 Episode length: 104 Return: -136.62666201815815
INFO:tensorflow:Average training steps per second: 219.33
I0901 12:29:08.880803 139809518303232 replay_runner.py:36] Average training steps per second: 219.33
I0901 12:29:09.103532 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.81
INFO:tensorflow:Starting iteration 21
I0901 12:29:13.489935 139809518303232 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 223.70

Steps executed: 301 Episode length: 112 Return: -149.55459523347815
I0901 12:29:18.202823 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.97
INFO:tensorflow:Starting iteration 22

Steps executed: 311 Episode length: 311 Return: -551.02184148338945
INFO:tensorflow:Average training steps per second: 222.78
I0901 12:29:27.053525 139809518303232 replay_runner.py:36] Average training steps per second: 222.78
I0901 12:29:27.442364 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -551.02
INFO:tensorflow:Starting iteration 23

Steps executed: 228 Episode length: 170 Return: 8.54384473277008345
INFO:tensorflow:Average training steps per second: 222.11
I0901 12:29:36.434002 139809518303232 replay_runner.py:36] Average training steps per second: 222.11
I0901 12:29:36.624877 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.77
INFO:tensorflow:Starting iteration 24

Steps executed: 256 Episode length: 64 Return: -334.842175178956045
INFO:tensorflow:Average training steps per second: 223.03
I0901 12:29:45.508980 139809518303232 replay_runner.py:36] Average training steps per second: 223.03
I0901 12:29:45.716680 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.81
INFO:tensorflow:Starting iteration 25

Steps executed: 426 Episode length: 239 Return: -55.802319910442145
INFO:tensorflow:Average training steps per second: 227.90
I0901 12:29:54.524037 139809518303232 replay_runner.py:36] Average training steps per second: 227.90
I0901 12:29:54.905797 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.79
INFO:tensorflow:Starting iteration 26
I0901 12:29:59.360582 139809518303232 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 216.25
I0901 12:30:03.985461 139809518303232 replay_runner.py:36] Average training steps per second: 216.25

Steps executed: 260 Episode length: 83 Return: -224.907589668315678
INFO:tensorflow:Starting iteration 27

Steps executed: 288 Episode length: 149 Return: -13.975823451154156
INFO:tensorflow:Average training steps per second: 225.78
I0901 12:30:13.046479 139809518303232 replay_runner.py:36] Average training steps per second: 225.78
I0901 12:30:13.303242 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.37
INFO:tensorflow:Starting iteration 28
I0901 12:30:17.581484 139809518303232 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 218.75
I0901 12:30:22.153828 139809518303232 replay_runner.py:36] Average training steps per second: 218.75

Steps executed: 212 Episode length: 212 Return: -203.29888769715956
INFO:tensorflow:Starting iteration 29

Steps executed: 305 Episode length: 188 Return: -69.926739600521246
INFO:tensorflow:Average training steps per second: 224.78
I0901 12:30:31.232888 139809518303232 replay_runner.py:36] Average training steps per second: 224.78

Done fixed training!Episode length: 188 Return: -69.926739600521246