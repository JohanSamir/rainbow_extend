Loaded trained dqn in acrobot
Training fixed agent 6, please be patient, may be a while...
I0901 23:51:02.908870 140490221283328 run_experiment.py:549] Creating TrainRunner ...
I0901 23:51:02.916386 140490221283328 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:51:02.916718 140490221283328 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:51:02.917037 140490221283328 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:51:02.917166 140490221283328 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:51:02.917277 140490221283328 dqn_agent.py:275] 	 update_period: 4
I0901 23:51:02.917387 140490221283328 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:51:02.917506 140490221283328 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:51:02.917727 140490221283328 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:51:02.917831 140490221283328 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:51:02.918017 140490221283328 dqn_agent.py:280] 	 optimizer: adam
I0901 23:51:02.918193 140490221283328 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:51:02.918380 140490221283328 dqn_agent.py:283] 	 seed: 1630540262916303
I0901 23:51:02.921620 140490221283328 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:51:02.921797 140490221283328 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 23:51:02.921980 140490221283328 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:51:02.922186 140490221283328 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:51:02.922327 140490221283328 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:51:02.922408 140490221283328 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:51:02.922638 140490221283328 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:51:02.922853 140490221283328 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:51:02.923029 140490221283328 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:51:02.960004 140490221283328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:51:03.434634 140490221283328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:51:03.449640 140490221283328 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:51:03.457443 140490221283328 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:51:03.457667 140490221283328 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:51:03.457830 140490221283328 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:51:03.457939 140490221283328 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:51:03.458088 140490221283328 dqn_agent.py:275] 	 update_period: 4
I0901 23:51:03.458354 140490221283328 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:51:03.458511 140490221283328 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:51:03.458613 140490221283328 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:51:03.458836 140490221283328 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:51:03.458944 140490221283328 dqn_agent.py:280] 	 optimizer: adam
I0901 23:51:03.459098 140490221283328 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:51:03.459253 140490221283328 dqn_agent.py:283] 	 seed: 1630540263457361
I0901 23:51:03.461713 140490221283328 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:51:03.461874 140490221283328 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 23:51:03.462031 140490221283328 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:51:03.462180 140490221283328 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:51:03.462474 140490221283328 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:51:03.462620 140490221283328 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:51:03.462754 140490221283328 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:51:03.463029 140490221283328 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:51:03.463223 140490221283328 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:51:03.494572 140490221283328 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:51:03.517762 140490221283328 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:51:03.517973 140490221283328 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 143.94
I0901 23:51:10.465462 140490221283328 replay_runner.py:36] Average training steps per second: 143.94
Steps executed: 500 Episode length: 500 Return: -500.0
I0901 23:51:12.003211 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 1
I0901 23:51:12.248725 140490221283328 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 202.45
I0901 23:51:17.188740 140490221283328 replay_runner.py:36] Average training steps per second: 202.45
I0901 23:51:17.613891 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 2

Steps executed: 267 Episode length: 136 Return: -135.0
INFO:tensorflow:Average training steps per second: 193.31
I0901 23:51:23.016160 140490221283328 replay_runner.py:36] Average training steps per second: 193.31
I0901 23:51:23.246695 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.50
INFO:tensorflow:Starting iteration 3
I0901 23:51:23.487515 140490221283328 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 200.57

Steps executed: 500 Episode length: 500 Return: -500.0
I0901 23:51:28.916541 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 4
I0901 23:51:29.169916 140490221283328 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 195.61
I0901 23:51:34.282765 140490221283328 replay_runner.py:36] Average training steps per second: 195.61
I0901 23:51:34.722656 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 5
I0901 23:51:34.970169 140490221283328 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 193.65
I0901 23:51:40.134701 140490221283328 replay_runner.py:36] Average training steps per second: 193.65
I0901 23:51:40.556513 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 6
I0901 23:51:40.797935 140490221283328 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 192.77
I0901 23:51:45.985965 140490221283328 replay_runner.py:36] Average training steps per second: 192.77
I0901 23:51:46.402528 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7

Steps executed: 592 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 192.97
I0901 23:51:51.819539 140490221283328 replay_runner.py:36] Average training steps per second: 192.97
I0901 23:51:52.325499 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -295.50
INFO:tensorflow:Starting iteration 8

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 193.72
I0901 23:51:57.726502 140490221283328 replay_runner.py:36] Average training steps per second: 193.72
I0901 23:51:58.185837 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 9

Steps executed: 269 Episode length: 89 Return: -88.0.0
INFO:tensorflow:Average training steps per second: 193.37
I0901 23:52:03.611020 140490221283328 replay_runner.py:36] Average training steps per second: 193.37
I0901 23:52:03.829652 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.67
INFO:tensorflow:Starting iteration 10

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 192.55
I0901 23:52:09.260924 140490221283328 replay_runner.py:36] Average training steps per second: 192.55
I0901 23:52:09.703848 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 11
I0901 23:52:09.958643 140490221283328 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 197.03

Steps executed: 307 Episode length: 163 Return: -162.0
I0901 23:52:15.281175 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.50
INFO:tensorflow:Starting iteration 12
I0901 23:52:15.506526 140490221283328 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 190.54
I0901 23:52:20.755267 140490221283328 replay_runner.py:36] Average training steps per second: 190.54

Steps executed: 276 Episode length: 83 Return: -82.0.0
INFO:tensorflow:Starting iteration 13

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 197.06
I0901 23:52:26.284698 140490221283328 replay_runner.py:36] Average training steps per second: 197.06
I0901 23:52:26.702359 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 14

Steps executed: 252 Episode length: 82 Return: -81.0.0
INFO:tensorflow:Average training steps per second: 190.39
I0901 23:52:32.206310 140490221283328 replay_runner.py:36] Average training steps per second: 190.39
I0901 23:52:32.423132 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.00
INFO:tensorflow:Starting iteration 15

Steps executed: 211 Episode length: 107 Return: -106.0
INFO:tensorflow:Average training steps per second: 193.41
I0901 23:52:37.839682 140490221283328 replay_runner.py:36] Average training steps per second: 193.41
I0901 23:52:38.032306 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.50
INFO:tensorflow:Starting iteration 16

Steps executed: 240 Episode length: 123 Return: -122.0
INFO:tensorflow:Average training steps per second: 189.65
I0901 23:52:43.552996 140490221283328 replay_runner.py:36] Average training steps per second: 189.65
I0901 23:52:43.754943 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.00
INFO:tensorflow:Starting iteration 17
I0901 23:52:43.990796 140490221283328 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 197.05
I0901 23:52:49.066342 140490221283328 replay_runner.py:36] Average training steps per second: 197.05

Steps executed: 347 Episode length: 250 Return: -249.0
INFO:tensorflow:Starting iteration 18
I0901 23:52:49.573431 140490221283328 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 198.70
I0901 23:52:54.606502 140490221283328 replay_runner.py:36] Average training steps per second: 198.70
I0901 23:52:54.781302 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.00
INFO:tensorflow:Starting iteration 19


Steps executed: 271 Episode length: 109 Return: -108.0
INFO:tensorflow:Average training steps per second: 195.94
I0901 23:53:00.117605 140490221283328 replay_runner.py:36] Average training steps per second: 195.94
I0901 23:53:00.327627 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.33
INFO:tensorflow:Starting iteration 20

Steps executed: 235 Episode length: 90 Return: -89.0.0
INFO:tensorflow:Average training steps per second: 205.33
I0901 23:53:05.428514 140490221283328 replay_runner.py:36] Average training steps per second: 205.33
I0901 23:53:05.628535 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.33
INFO:tensorflow:Starting iteration 21
I0901 23:53:05.880347 140490221283328 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 201.16
I0901 23:53:10.852670 140490221283328 replay_runner.py:36] Average training steps per second: 201.16

Steps executed: 265 Episode length: 96 Return: -95.0.0
INFO:tensorflow:Starting iteration 22

Steps executed: 263 Episode length: 89 Return: -88.0.0
INFO:tensorflow:Average training steps per second: 191.90
I0901 23:53:16.522411 140490221283328 replay_runner.py:36] Average training steps per second: 191.90
I0901 23:53:16.776267 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.67
INFO:tensorflow:Starting iteration 23

Steps executed: 212 Episode length: 110 Return: -109.0
INFO:tensorflow:Average training steps per second: 200.58
I0901 23:53:22.026884 140490221283328 replay_runner.py:36] Average training steps per second: 200.58
I0901 23:53:22.212914 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.00
INFO:tensorflow:Starting iteration 24

Steps executed: 204 Episode length: 103 Return: -102.0
INFO:tensorflow:Average training steps per second: 190.91
I0901 23:53:27.764375 140490221283328 replay_runner.py:36] Average training steps per second: 190.91
I0901 23:53:27.935971 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.00
INFO:tensorflow:Starting iteration 25
I0901 23:53:28.175971 140490221283328 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 200.67
I0901 23:53:33.159599 140490221283328 replay_runner.py:36] Average training steps per second: 200.67

Steps executed: 276 Episode length: 114 Return: -113.0
INFO:tensorflow:Starting iteration 26

Steps executed: 207 Episode length: 103 Return: -102.0
INFO:tensorflow:Average training steps per second: 203.36
I0901 23:53:38.556396 140490221283328 replay_runner.py:36] Average training steps per second: 203.36
I0901 23:53:38.703915 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.50
INFO:tensorflow:Starting iteration 27

Steps executed: 267 Episode length: 96 Return: -95.0.0
INFO:tensorflow:Average training steps per second: 214.30
I0901 23:53:43.588740 140490221283328 replay_runner.py:36] Average training steps per second: 214.30
I0901 23:53:43.813645 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.00
INFO:tensorflow:Starting iteration 28
I0901 23:53:44.051238 140490221283328 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 196.67
I0901 23:53:49.136278 140490221283328 replay_runner.py:36] Average training steps per second: 196.67
I0901 23:53:49.284614 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.50
INFO:tensorflow:Starting iteration 29


Done fixed training!Episode length: 76 Return: -75.0.0
INFO:tensorflow:Average training steps per second: 199.05
I0901 23:53:54.538420 140490221283328 replay_runner.py:36] Average training steps per second: 199.05
I0901 23:53:54.707818 140490221283328 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.67