Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0902 00:16:02.789375 139929824643072 run_experiment.py:549] Creating TrainRunner ...
I0902 00:16:02.803235 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:16:02.803523 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:16:02.803637 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:16:02.803721 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:16:02.803793 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0902 00:16:02.804118 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:16:02.804227 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:16:02.804331 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:16:02.804476 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:16:02.804756 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0902 00:16:02.804939 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:16:02.805117 139929824643072 dqn_agent.py:283] 	 seed: 1630541762803154
I0902 00:16:02.808061 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:16:02.808266 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:16:02.808414 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:16:02.808557 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:16:02.808678 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:16:02.808756 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:16:02.808825 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:16:02.808909 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:16:02.808994 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:16:02.841481 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:16:03.212027 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:16:03.223727 139929824643072 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:16:03.232139 139929824643072 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:16:03.232388 139929824643072 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:16:03.232523 139929824643072 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:16:03.232612 139929824643072 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:16:03.232694 139929824643072 dqn_agent.py:275] 	 update_period: 4
I0902 00:16:03.232784 139929824643072 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:16:03.232884 139929824643072 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:16:03.233066 139929824643072 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:16:03.233159 139929824643072 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:16:03.233271 139929824643072 dqn_agent.py:280] 	 optimizer: adam
I0902 00:16:03.233356 139929824643072 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:16:03.233430 139929824643072 dqn_agent.py:283] 	 seed: 1630541763232082
I0902 00:16:03.236204 139929824643072 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:16:03.236415 139929824643072 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:16:03.236520 139929824643072 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:16:03.236609 139929824643072 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:16:03.236687 139929824643072 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:16:03.236773 139929824643072 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:16:03.237037 139929824643072 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:16:03.237316 139929824643072 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:16:03.237504 139929824643072 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:16:03.269572 139929824643072 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:16:03.331406 139929824643072 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:16:03.331869 139929824643072 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 165.11
I0902 00:16:09.388808 139929824643072 replay_runner.py:36] Average training steps per second: 165.11
Steps executed: 284 Episode length: 136 Return: -350.00971463871105
I0902 00:16:10.731556 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -317.33
INFO:tensorflow:Starting iteration 1

Steps executed: 341 Episode length: 178 Return: -311.87377107077187
INFO:tensorflow:Average training steps per second: 225.56
I0902 00:16:19.540335 139929824643072 replay_runner.py:36] Average training steps per second: 225.56
I0902 00:16:19.903666 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.68
INFO:tensorflow:Starting iteration 2

Steps executed: 250 Episode length: 250 Return: -436.15597235602777
INFO:tensorflow:Average training steps per second: 218.63
I0902 00:16:28.615032 139929824643072 replay_runner.py:36] Average training steps per second: 218.63
I0902 00:16:28.910943 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -436.16
INFO:tensorflow:Starting iteration 3

Steps executed: 259 Episode length: 259 Return: -501.66643038156593
INFO:tensorflow:Average training steps per second: 228.47
I0902 00:16:37.534333 139929824643072 replay_runner.py:36] Average training steps per second: 228.47
I0902 00:16:37.863818 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -501.67
INFO:tensorflow:Starting iteration 4
I0902 00:16:42.003120 139929824643072 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 246.07

Steps executed: 1000 Episode length: 1000 Return: -42.670299465606185
I0902 00:16:50.415633 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -42.67
INFO:tensorflow:Starting iteration 5
I0902 00:16:54.550713 139929824643072 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 243.32

Steps executed: 1000 Episode length: 1000 Return: -52.889492530346685
I0902 00:17:00.751835 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -52.89
INFO:tensorflow:Starting iteration 6

Steps executed: 679 Episode length: 679 Return: -208.7127418923019685
INFO:tensorflow:Average training steps per second: 245.99
I0902 00:17:08.839954 139929824643072 replay_runner.py:36] Average training steps per second: 245.99
I0902 00:17:10.357739 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -208.71
INFO:tensorflow:Starting iteration 7
I0902 00:17:14.459159 139929824643072 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 242.90

Steps executed: 1000 Episode length: 1000 Return: -52.090244062198124
I0902 00:17:20.701799 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -52.09
INFO:tensorflow:Starting iteration 8
I0902 00:17:24.681381 139929824643072 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 240.69

Steps executed: 698 Episode length: 698 Return: -322.2903812903947124
I0902 00:17:30.679755 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -322.29
INFO:tensorflow:Starting iteration 9
I0902 00:17:34.719202 139929824643072 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 248.96

Steps executed: 270 Episode length: 270 Return: -212.9431272669286624
I0902 00:17:38.997416 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.94
INFO:tensorflow:Starting iteration 10
I0902 00:17:43.015073 139929824643072 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 252.09

Steps executed: 309 Episode length: 309 Return: -176.7047653069476524
I0902 00:17:47.372418 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.70
INFO:tensorflow:Starting iteration 11
I0902 00:17:51.277135 139929824643072 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 272.66

Steps executed: 1000 Episode length: 1000 Return: -91.854328937401524
I0902 00:17:57.536016 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.85
INFO:tensorflow:Starting iteration 12

Steps executed: 423 Episode length: 423 Return: -361.8887429266947624
INFO:tensorflow:Average training steps per second: 317.40
I0902 00:18:04.408892 139929824643072 replay_runner.py:36] Average training steps per second: 317.40
I0902 00:18:04.990463 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.89
INFO:tensorflow:Starting iteration 13
I0902 00:18:08.667444 139929824643072 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 323.92

Steps executed: 1000 Episode length: 1000 Return: -26.139181797012792
I0902 00:18:13.677977 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -26.14
INFO:tensorflow:Starting iteration 14

Steps executed: 191 Episode length: 191 Return: -196.8000360064525792
INFO:tensorflow:Average training steps per second: 328.61
I0902 00:18:20.298045 139929824643072 replay_runner.py:36] Average training steps per second: 328.61

Steps executed: 490 Episode length: 299 Return: -183.7520921572795592
INFO:tensorflow:Starting iteration 15
I0902 00:18:24.120310 139929824643072 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 329.05

Steps executed: 567 Episode length: 567 Return: -267.7690038828222592
I0902 00:18:27.825313 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -267.77
INFO:tensorflow:Starting iteration 16

Steps executed: 320 Episode length: 157 Return: -211.0862147744612492
INFO:tensorflow:Average training steps per second: 310.98
I0902 00:18:34.332988 139929824643072 replay_runner.py:36] Average training steps per second: 310.98
I0902 00:18:34.553971 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.26
INFO:tensorflow:Starting iteration 17
I0902 00:18:37.841390 139929824643072 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 317.99

Steps executed: 611 Episode length: 611 Return: -84.59130828426638492
I0902 00:18:42.102087 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.59
INFO:tensorflow:Starting iteration 18

Steps executed: 139 Episode length: 139 Return: -220.6966769617698792
INFO:tensorflow:Average training steps per second: 310.31

Steps executed: 946 Episode length: 807 Return: -75.74719466795216792
I0902 00:18:50.242548 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.22
INFO:tensorflow:Starting iteration 19
I0902 00:18:53.532603 139929824643072 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 334.96
I0902 00:18:56.518517 139929824643072 replay_runner.py:36] Average training steps per second: 334.96

Steps executed: 349 Episode length: 349 Return: -100.6536385880216792
INFO:tensorflow:Starting iteration 20

Steps executed: 336 Episode length: 336 Return: -253.2507865740089492
INFO:tensorflow:Average training steps per second: 331.69
I0902 00:19:03.087120 139929824643072 replay_runner.py:36] Average training steps per second: 331.69
I0902 00:19:03.348316 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.25
INFO:tensorflow:Starting iteration 21

Steps executed: 300 Episode length: 111 Return: -178.4197491009182492
INFO:tensorflow:Average training steps per second: 330.61
I0902 00:19:09.647494 139929824643072 replay_runner.py:36] Average training steps per second: 330.61
I0902 00:19:09.787316 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.48
INFO:tensorflow:Starting iteration 22

Steps executed: 209 Episode length: 92 Return: -210.86012887298092492
INFO:tensorflow:Average training steps per second: 339.77
I0902 00:19:15.994987 139929824643072 replay_runner.py:36] Average training steps per second: 339.77
I0902 00:19:16.082800 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.03
INFO:tensorflow:Starting iteration 23

Steps executed: 450 Episode length: 450 Return: -348.8558159003935792
INFO:tensorflow:Average training steps per second: 361.37
I0902 00:19:22.027074 139929824643072 replay_runner.py:36] Average training steps per second: 361.37
I0902 00:19:22.409584 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -348.86
INFO:tensorflow:Starting iteration 24

Steps executed: 314 Episode length: 115 Return: -191.0167421346432792
INFO:tensorflow:Average training steps per second: 350.96
I0902 00:19:28.452352 139929824643072 replay_runner.py:36] Average training steps per second: 350.96
I0902 00:19:28.606867 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.15
INFO:tensorflow:Starting iteration 25

Steps executed: 204 Episode length: 204 Return: -169.2204727712994892
INFO:tensorflow:Average training steps per second: 338.77
I0902 00:19:34.857942 139929824643072 replay_runner.py:36] Average training steps per second: 338.77
I0902 00:19:34.990201 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.22
INFO:tensorflow:Starting iteration 26
I0902 00:19:38.263617 139929824643072 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 338.17
I0902 00:19:41.220989 139929824643072 replay_runner.py:36] Average training steps per second: 338.17

Steps executed: 1000 Episode length: 1000 Return: -109.76393213724558
INFO:tensorflow:Starting iteration 27

Steps executed: 406 Episode length: 270 Return: -167.9155122426252358
INFO:tensorflow:Average training steps per second: 336.46
I0902 00:19:49.295922 139929824643072 replay_runner.py:36] Average training steps per second: 336.46
I0902 00:19:49.589253 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.57
INFO:tensorflow:Starting iteration 28

Steps executed: 521 Episode length: 349 Return: -259.9421704303348458
INFO:tensorflow:Average training steps per second: 342.94
I0902 00:19:55.865190 139929824643072 replay_runner.py:36] Average training steps per second: 342.94
I0902 00:19:56.298483 139929824643072 run_experiment.py:428] Average undiscounted return per evaluation episode: -340.78
INFO:tensorflow:Starting iteration 29

Steps executed: 281 Episode length: 112 Return: 44.927148617429454458
INFO:tensorflow:Average training steps per second: 346.35
I0902 00:20:02.628316 139929824643072 replay_runner.py:36] Average training steps per second: 346.35

Done fixed training!Episode length: 112 Return: 44.927148617429454458