Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0902 11:31:17.286709 140305128941568 run_experiment.py:549] Creating TrainRunner ...
I0902 11:31:17.294389 140305128941568 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 11:31:17.294496 140305128941568 dqn_agent.py:272] 	 gamma: 0.990000
I0902 11:31:17.294548 140305128941568 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 11:31:17.294600 140305128941568 dqn_agent.py:274] 	 min_replay_history: 500
I0902 11:31:17.294643 140305128941568 dqn_agent.py:275] 	 update_period: 4
I0902 11:31:17.294697 140305128941568 dqn_agent.py:276] 	 target_update_period: 300
I0902 11:31:17.294742 140305128941568 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 11:31:17.294803 140305128941568 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 11:31:17.294872 140305128941568 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 11:31:17.294979 140305128941568 dqn_agent.py:280] 	 optimizer: adam
I0902 11:31:17.295077 140305128941568 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 11:31:17.295153 140305128941568 dqn_agent.py:283] 	 seed: 1630582277294359
I0902 11:31:17.296844 140305128941568 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 11:31:17.296948 140305128941568 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 11:31:17.297017 140305128941568 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 11:31:17.297077 140305128941568 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 11:31:17.297129 140305128941568 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 11:31:17.297198 140305128941568 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 11:31:17.297269 140305128941568 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 11:31:17.297340 140305128941568 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 11:31:17.297408 140305128941568 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 11:31:17.429956 140305128941568 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:17.708679 140305128941568 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:17.716618 140305128941568 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 11:31:17.721892 140305128941568 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 11:31:17.722019 140305128941568 dqn_agent.py:272] 	 gamma: 0.990000
I0902 11:31:17.722090 140305128941568 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 11:31:17.722166 140305128941568 dqn_agent.py:274] 	 min_replay_history: 500
I0902 11:31:17.722223 140305128941568 dqn_agent.py:275] 	 update_period: 4
I0902 11:31:17.722299 140305128941568 dqn_agent.py:276] 	 target_update_period: 300
I0902 11:31:17.722388 140305128941568 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 11:31:17.722447 140305128941568 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 11:31:17.722509 140305128941568 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 11:31:17.722596 140305128941568 dqn_agent.py:280] 	 optimizer: adam
I0902 11:31:17.722670 140305128941568 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 11:31:17.722760 140305128941568 dqn_agent.py:283] 	 seed: 1630582277721863
I0902 11:31:17.724090 140305128941568 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 11:31:17.724193 140305128941568 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 11:31:17.724263 140305128941568 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 11:31:17.724331 140305128941568 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 11:31:17.724384 140305128941568 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 11:31:17.724429 140305128941568 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 11:31:17.724474 140305128941568 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 11:31:17.724534 140305128941568 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 11:31:17.724596 140305128941568 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 11:31:17.751691 140305128941568 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 11:31:17.766041 140305128941568 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 11:31:17.766182 140305128941568 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 200.49
I0902 11:31:22.754126 140305128941568 replay_runner.py:36] Average training steps per second: 200.49
Steps executed: 243 Episode length: 103 Return: -502.04310684326015
I0902 11:31:23.483329 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -379.15
INFO:tensorflow:Starting iteration 1

Steps executed: 295 Episode length: 194 Return: -429.27596438996414
INFO:tensorflow:Average training steps per second: 333.80
I0902 11:31:29.701405 140305128941568 replay_runner.py:36] Average training steps per second: 333.80
I0902 11:31:29.871731 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -322.64
INFO:tensorflow:Starting iteration 2

Steps executed: 310 Episode length: 127 Return: -409.72329092779674
INFO:tensorflow:Average training steps per second: 335.23
I0902 11:31:36.246390 140305128941568 replay_runner.py:36] Average training steps per second: 335.23
I0902 11:31:36.431868 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.39
INFO:tensorflow:Starting iteration 3
I0902 11:31:39.824970 140305128941568 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 338.41

Steps executed: 1000 Episode length: 1000 Return: -90.84718975609046
I0902 11:31:44.310706 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.85
INFO:tensorflow:Starting iteration 4
I0902 11:31:47.677321 140305128941568 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 316.90

Steps executed: 647 Episode length: 647 Return: -265.664223726950846
I0902 11:31:51.973624 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -265.66
INFO:tensorflow:Starting iteration 5
I0902 11:31:55.292768 140305128941568 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 331.27

Steps executed: 1000 Episode length: 1000 Return: -71.95507900555798
I0902 11:32:00.483872 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.96
INFO:tensorflow:Starting iteration 6
I0902 11:32:03.751598 140305128941568 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 323.32

Steps executed: 1000 Episode length: 1000 Return: -277.2603462967252
I0902 11:32:08.662141 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.26
INFO:tensorflow:Starting iteration 7

Steps executed: 590 Episode length: 393 Return: -295.302101866614462
INFO:tensorflow:Average training steps per second: 322.83
I0902 11:32:15.155007 140305128941568 replay_runner.py:36] Average training steps per second: 322.83
I0902 11:32:15.733640 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.85
INFO:tensorflow:Starting iteration 8

Steps executed: 267 Episode length: 267 Return: -535.507894138333262
INFO:tensorflow:Average training steps per second: 334.63
I0902 11:32:22.115598 140305128941568 replay_runner.py:36] Average training steps per second: 334.63
I0902 11:32:22.297285 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -535.51
INFO:tensorflow:Starting iteration 9
I0902 11:32:25.704985 140305128941568 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 339.14

Steps executed: 586 Episode length: 586 Return: -329.780885387903862
I0902 11:32:29.373559 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.78
INFO:tensorflow:Starting iteration 10

Steps executed: 916 Episode length: 916 Return: -217.925659986970572
INFO:tensorflow:Average training steps per second: 339.32
I0902 11:32:35.776931 140305128941568 replay_runner.py:36] Average training steps per second: 339.32
I0902 11:32:37.126377 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.93
INFO:tensorflow:Starting iteration 11

Steps executed: 445 Episode length: 445 Return: -297.882254698690762
INFO:tensorflow:Average training steps per second: 369.14
I0902 11:32:43.409771 140305128941568 replay_runner.py:36] Average training steps per second: 369.14
I0902 11:32:43.830742 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -297.88
INFO:tensorflow:Starting iteration 12

Steps executed: 263 Episode length: 263 Return: 24.24617185895832762
INFO:tensorflow:Average training steps per second: 335.96
I0902 11:32:50.251554 140305128941568 replay_runner.py:36] Average training steps per second: 335.96
I0902 11:32:50.445115 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: 24.25
INFO:tensorflow:Starting iteration 13

Steps executed: 200 Episode length: 200 Return: -502.944483633535862
INFO:tensorflow:Average training steps per second: 326.60
I0902 11:32:56.866798 140305128941568 replay_runner.py:36] Average training steps per second: 326.60
I0902 11:32:57.011219 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.94
INFO:tensorflow:Starting iteration 14

Steps executed: 765 Episode length: 765 Return: -402.315308698810862
INFO:tensorflow:Average training steps per second: 322.18
I0902 11:33:03.424263 140305128941568 replay_runner.py:36] Average training steps per second: 322.18
I0902 11:33:04.989928 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -402.32
INFO:tensorflow:Starting iteration 15

Steps executed: 486 Episode length: 486 Return: -32.7779826984410162
INFO:tensorflow:Average training steps per second: 316.96
I0902 11:33:11.454576 140305128941568 replay_runner.py:36] Average training steps per second: 316.96
I0902 11:33:12.107675 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -32.78
INFO:tensorflow:Starting iteration 16

Steps executed: 430 Episode length: 246 Return: 53.52151118449302162
INFO:tensorflow:Average training steps per second: 316.09
I0902 11:33:18.504184 140305128941568 replay_runner.py:36] Average training steps per second: 316.09
I0902 11:33:18.808543 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: 46.48
INFO:tensorflow:Starting iteration 17
I0902 11:33:22.096637 140305128941568 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 312.16

Steps executed: 500 Episode length: 500 Return: -194.243152976832162
I0902 11:33:25.943051 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -194.24
INFO:tensorflow:Starting iteration 18

Steps executed: 379 Episode length: 379 Return: -331.026209599517132
INFO:tensorflow:Average training steps per second: 319.09
I0902 11:33:32.363363 140305128941568 replay_runner.py:36] Average training steps per second: 319.09
I0902 11:33:32.863870 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.03
INFO:tensorflow:Starting iteration 19
I0902 11:33:36.182004 140305128941568 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 331.20

Steps executed: 1000 Episode length: 1000 Return: 88.916639452224872
I0902 11:33:41.087345 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: 88.92
INFO:tensorflow:Starting iteration 20

Steps executed: 373 Episode length: 251 Return: -522.010582155145612
INFO:tensorflow:Average training steps per second: 308.71
I0902 11:33:47.652035 140305128941568 replay_runner.py:36] Average training steps per second: 308.71
I0902 11:33:47.931458 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.27
INFO:tensorflow:Starting iteration 21

Steps executed: 568 Episode length: 568 Return: 258.6766903499751612
INFO:tensorflow:Average training steps per second: 330.00
I0902 11:33:54.222791 140305128941568 replay_runner.py:36] Average training steps per second: 330.00
I0902 11:33:54.939356 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: 258.68
INFO:tensorflow:Starting iteration 22
I0902 11:33:58.311002 140305128941568 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 338.42
I0902 11:34:01.266265 140305128941568 replay_runner.py:36] Average training steps per second: 338.42

Steps executed: 287 Episode length: 287 Return: -137.875324673051642
INFO:tensorflow:Starting iteration 23

Steps executed: 522 Episode length: 359 Return: 174.2608616189386362
INFO:tensorflow:Average training steps per second: 347.41
I0902 11:34:07.916605 140305128941568 replay_runner.py:36] Average training steps per second: 347.41
I0902 11:34:08.768745 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: 35.00
INFO:tensorflow:Starting iteration 24
I0902 11:34:12.299902 140305128941568 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 341.47
I0902 11:34:15.228740 140305128941568 replay_runner.py:36] Average training steps per second: 341.47

Steps executed: 355 Episode length: 165 Return: -226.746006642851032
INFO:tensorflow:Starting iteration 25

Steps executed: 207 Episode length: 207 Return: -149.294593981245552
INFO:tensorflow:Average training steps per second: 347.94
I0902 11:34:21.807610 140305128941568 replay_runner.py:36] Average training steps per second: 347.94
I0902 11:34:21.942801 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.29
INFO:tensorflow:Starting iteration 26

Steps executed: 302 Episode length: 302 Return: 20.44096271847358552
INFO:tensorflow:Average training steps per second: 323.40
I0902 11:34:28.441728 140305128941568 replay_runner.py:36] Average training steps per second: 323.40
I0902 11:34:28.655418 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: 20.44
INFO:tensorflow:Starting iteration 27

Steps executed: 361 Episode length: 221 Return: -141.482662387296452
INFO:tensorflow:Average training steps per second: 324.96
I0902 11:34:35.052989 140305128941568 replay_runner.py:36] Average training steps per second: 324.96
I0902 11:34:35.315034 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.55
INFO:tensorflow:Starting iteration 28

Steps executed: 607 Episode length: 607 Return: 157.5303934581222652
INFO:tensorflow:Average training steps per second: 317.79
I0902 11:34:41.492087 140305128941568 replay_runner.py:36] Average training steps per second: 317.79
I0902 11:34:42.253088 140305128941568 run_experiment.py:428] Average undiscounted return per evaluation episode: 157.53
INFO:tensorflow:Starting iteration 29

Steps executed: 251 Episode length: 123 Return: -7.06633952614754462
INFO:tensorflow:Average training steps per second: 313.55
I0902 11:34:48.534726 140305128941568 replay_runner.py:36] Average training steps per second: 313.55

Done fixed training!Episode length: 123 Return: -7.06633952614754462