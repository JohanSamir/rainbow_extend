Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0902 23:51:08.221468 140457530894336 run_experiment.py:549] Creating TrainRunner ...
I0902 23:51:08.233778 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:51:08.234054 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:51:08.234187 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:51:08.234533 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:51:08.234802 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0902 23:51:08.234938 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:51:08.235380 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:51:08.235563 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:51:08.235740 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:51:08.235843 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0902 23:51:08.235920 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:51:08.235995 140457530894336 dqn_agent.py:283] 	 seed: 1630626668233708
I0902 23:51:08.239205 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:51:08.239408 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:51:08.239514 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:51:08.239602 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:51:08.239691 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:51:08.239765 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:51:08.239841 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:51:08.239946 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:51:08.240023 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:51:08.280246 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:51:08.676076 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:51:08.692082 140457530894336 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:51:08.702381 140457530894336 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:51:08.707978 140457530894336 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:51:08.719084 140457530894336 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:51:08.724696 140457530894336 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:51:08.725273 140457530894336 dqn_agent.py:275] 	 update_period: 4
I0902 23:51:08.725489 140457530894336 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:51:08.725628 140457530894336 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:51:08.725747 140457530894336 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:51:08.725987 140457530894336 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:51:08.726142 140457530894336 dqn_agent.py:280] 	 optimizer: adam
I0902 23:51:08.726294 140457530894336 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:51:08.726404 140457530894336 dqn_agent.py:283] 	 seed: 1630626668702304
I0902 23:51:08.729312 140457530894336 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:51:08.729453 140457530894336 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:51:08.729530 140457530894336 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:51:08.729594 140457530894336 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:51:08.729660 140457530894336 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:51:08.729742 140457530894336 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:51:08.729847 140457530894336 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:51:08.730018 140457530894336 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:51:08.730128 140457530894336 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:51:08.762722 140457530894336 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:51:08.784697 140457530894336 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:51:08.784939 140457530894336 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.48
I0902 23:51:14.939713 140457530894336 replay_runner.py:36] Average training steps per second: 162.48
Steps executed: 324 Episode length: 149 Return: -248.47032495692872
I0902 23:51:16.725048 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -302.13
INFO:tensorflow:Starting iteration 1

Steps executed: 223 Episode length: 129 Return: -362.69852946309872
INFO:tensorflow:Average training steps per second: 215.51
I0902 23:51:25.663512 140457530894336 replay_runner.py:36] Average training steps per second: 215.51
I0902 23:51:25.866675 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -399.47
INFO:tensorflow:Starting iteration 2

Steps executed: 207 Episode length: 207 Return: -474.41797777765646
INFO:tensorflow:Average training steps per second: 221.92
I0902 23:51:34.732220 140457530894336 replay_runner.py:36] Average training steps per second: 221.92
I0902 23:51:34.978904 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -474.42
INFO:tensorflow:Starting iteration 3
I0902 23:51:39.369718 140457530894336 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 226.56

Steps executed: 155 Episode length: 155 Return: -228.64808082252011

Steps executed: 562 Episode length: 407 Return: -567.35549800109771
INFO:tensorflow:Starting iteration 4

Steps executed: 342 Episode length: 342 Return: -408.84200325533726
INFO:tensorflow:Average training steps per second: 222.88
I0902 23:51:53.331906 140457530894336 replay_runner.py:36] Average training steps per second: 222.88
I0902 23:51:53.778468 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -408.84
INFO:tensorflow:Starting iteration 5
I0902 23:51:57.887750 140457530894336 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 228.78

Steps executed: 973 Episode length: 973 Return: -116.01681586474866
I0902 23:52:05.657716 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.02
INFO:tensorflow:Starting iteration 6
I0902 23:52:09.797059 140457530894336 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 221.10

Steps executed: 1000 Episode length: 1000 Return: -85.64536714725307
I0902 23:52:17.104361 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.65
INFO:tensorflow:Starting iteration 7
I0902 23:52:21.406138 140457530894336 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 227.04

Steps executed: 903 Episode length: 903 Return: -499.736225740539857
I0902 23:52:27.524252 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -499.74
INFO:tensorflow:Starting iteration 8
I0902 23:52:31.850871 140457530894336 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 227.49

Steps executed: 704 Episode length: 704 Return: -408.590415832944877
I0902 23:52:37.543293 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -408.59
INFO:tensorflow:Starting iteration 9

Steps executed: 581 Episode length: 581 Return: -220.759433497105147
INFO:tensorflow:Average training steps per second: 232.76
I0902 23:52:46.204577 140457530894336 replay_runner.py:36] Average training steps per second: 232.76
I0902 23:52:47.269014 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.76
INFO:tensorflow:Starting iteration 10

Steps executed: 1000 Episode length: 1000 Return: -146.6329879698135
INFO:tensorflow:Average training steps per second: 226.33
I0902 23:52:56.050910 140457530894336 replay_runner.py:36] Average training steps per second: 226.33
I0902 23:52:58.385215 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.63
INFO:tensorflow:Starting iteration 11
I0902 23:53:02.841006 140457530894336 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 226.43

Steps executed: 1000 Episode length: 1000 Return: -161.60494417209824
I0902 23:53:10.310843 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.60
INFO:tensorflow:Starting iteration 12

Steps executed: 344 Episode length: 344 Return: -148.6343373243557324
INFO:tensorflow:Average training steps per second: 225.30
I0902 23:53:18.933231 140457530894336 replay_runner.py:36] Average training steps per second: 225.30
I0902 23:53:19.379643 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.63
INFO:tensorflow:Starting iteration 13
I0902 23:53:23.768840 140457530894336 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 231.27

Steps executed: 232 Episode length: 56 Return: -120.80747831521747324
I0902 23:53:28.298698 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -252.71
INFO:tensorflow:Starting iteration 14

Steps executed: 284 Episode length: 284 Return: -759.9081980113679324
INFO:tensorflow:Average training steps per second: 223.56
I0902 23:53:37.204520 140457530894336 replay_runner.py:36] Average training steps per second: 223.56
I0902 23:53:37.595399 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -759.91
INFO:tensorflow:Starting iteration 15

Steps executed: 234 Episode length: 80 Return: -123.69433793611094424
INFO:tensorflow:Average training steps per second: 221.37
I0902 23:53:46.514927 140457530894336 replay_runner.py:36] Average training steps per second: 221.37
I0902 23:53:46.705644 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.45
INFO:tensorflow:Starting iteration 16

Steps executed: 290 Episode length: 160 Return: -238.2804472164851324
INFO:tensorflow:Average training steps per second: 218.38
I0902 23:53:55.668235 140457530894336 replay_runner.py:36] Average training steps per second: 218.38
I0902 23:53:55.912474 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.28
INFO:tensorflow:Starting iteration 17

Steps executed: 200 Episode length: 200 Return: -278.5975308328151324
INFO:tensorflow:Average training steps per second: 216.16
I0902 23:54:04.919798 140457530894336 replay_runner.py:36] Average training steps per second: 216.16
I0902 23:54:05.119717 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -278.60
INFO:tensorflow:Starting iteration 18

Steps executed: 259 Episode length: 259 Return: -123.3700002273087824
INFO:tensorflow:Average training steps per second: 219.41
I0902 23:54:14.070894 140457530894336 replay_runner.py:36] Average training steps per second: 219.41
I0902 23:54:14.372794 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.37
INFO:tensorflow:Starting iteration 19

Steps executed: 384 Episode length: 196 Return: -601.9945502938214824
INFO:tensorflow:Average training steps per second: 221.91
I0902 23:54:23.200613 140457530894336 replay_runner.py:36] Average training steps per second: 221.91
I0902 23:54:23.575076 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -562.07
INFO:tensorflow:Starting iteration 20
I0902 23:54:27.948749 140457530894336 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 221.41

Steps executed: 239 Episode length: 186 Return: -157.6608357211846424
I0902 23:54:32.714288 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.57
INFO:tensorflow:Starting iteration 21
I0902 23:54:37.139037 140457530894336 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 219.52

Steps executed: 869 Episode length: 869 Return: -485.5825142009507524
I0902 23:54:43.729828 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -485.58
INFO:tensorflow:Starting iteration 22
I0902 23:54:48.132237 140457530894336 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 226.55

Steps executed: 269 Episode length: 128 Return: -180.8278484448834524
I0902 23:54:52.780171 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.84
INFO:tensorflow:Starting iteration 23

Steps executed: 255 Episode length: 69 Return: -259.33185942029322524
INFO:tensorflow:Average training steps per second: 231.69
I0902 23:55:01.445031 140457530894336 replay_runner.py:36] Average training steps per second: 231.69
I0902 23:55:01.640919 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.65
INFO:tensorflow:Starting iteration 24

Steps executed: 271 Episode length: 271 Return: -19.89783973801553424
INFO:tensorflow:Average training steps per second: 231.48
I0902 23:55:10.365020 140457530894336 replay_runner.py:36] Average training steps per second: 231.48
I0902 23:55:10.672451 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -19.90
INFO:tensorflow:Starting iteration 25

Steps executed: 235 Episode length: 85 Return: -517.61810596310243424
INFO:tensorflow:Average training steps per second: 231.36
I0902 23:55:19.276280 140457530894336 replay_runner.py:36] Average training steps per second: 231.36
I0902 23:55:19.476281 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -437.84
INFO:tensorflow:Starting iteration 26

Steps executed: 207 Episode length: 154 Return: -363.6189691693159624
INFO:tensorflow:Average training steps per second: 222.47
I0902 23:55:28.417377 140457530894336 replay_runner.py:36] Average training steps per second: 222.47
I0902 23:55:28.604379 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.54
INFO:tensorflow:Starting iteration 27

Steps executed: 203 Episode length: 132 Return: -180.8570126797007424
INFO:tensorflow:Average training steps per second: 225.88
I0902 23:55:37.393850 140457530894336 replay_runner.py:36] Average training steps per second: 225.88
I0902 23:55:37.550883 140457530894336 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.72
INFO:tensorflow:Starting iteration 28

Steps executed: 114 Episode length: 64 Return: -588.91433750975337424
INFO:tensorflow:Average training steps per second: 229.52
I0902 23:55:46.245847 140457530894336 replay_runner.py:36] Average training steps per second: 229.52

Steps executed: 253 Episode length: 76 Return: -651.98347748420697424
INFO:tensorflow:Starting iteration 29
I0902 23:55:50.679175 140457530894336 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 232.60

Steps executed: 201 Episode length: 61 Return: -19.004703748953564424

Done fixed training!Episode length: 61 Return: -19.004703748953564424