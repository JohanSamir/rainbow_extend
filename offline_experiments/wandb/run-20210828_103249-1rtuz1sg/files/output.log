Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0828 10:32:55.771485 139825303013376 run_experiment.py:549] Creating TrainRunner ...
I0828 10:32:55.784020 139825303013376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:55.784276 139825303013376 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:55.784394 139825303013376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:55.784491 139825303013376 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:55.784651 139825303013376 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:55.785004 139825303013376 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:55.785141 139825303013376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:55.785265 139825303013376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:55.785407 139825303013376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:55.785534 139825303013376 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:55.785638 139825303013376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:55.785733 139825303013376 dqn_agent.py:283] 	 seed: 1630146775783949
I0828 10:32:55.789243 139825303013376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:55.789562 139825303013376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:55.789772 139825303013376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:55.789932 139825303013376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:55.790047 139825303013376 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:55.790176 139825303013376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:55.790285 139825303013376 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:55.790403 139825303013376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:55.790537 139825303013376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:55.829186 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:56.201646 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:56.217586 139825303013376 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:32:56.282393 139825303013376 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:32:56.282702 139825303013376 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:32:56.282837 139825303013376 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:32:56.283009 139825303013376 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:32:56.283245 139825303013376 dqn_agent.py:275] 	 update_period: 4
I0828 10:32:56.283364 139825303013376 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:32:56.283460 139825303013376 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:32:56.283579 139825303013376 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:32:56.283702 139825303013376 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:32:56.283940 139825303013376 dqn_agent.py:280] 	 optimizer: adam
I0828 10:32:56.284044 139825303013376 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:32:56.284119 139825303013376 dqn_agent.py:283] 	 seed: 1630146776282325
I0828 10:32:56.287249 139825303013376 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:32:56.287477 139825303013376 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:32:56.287609 139825303013376 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:32:56.287738 139825303013376 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:32:56.287870 139825303013376 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:32:56.288094 139825303013376 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:32:56.288746 139825303013376 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:32:56.289133 139825303013376 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:32:56.289291 139825303013376 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:32:56.320843 139825303013376 dqn_agent.py:70] Creating Adam optimizer with settings lr=1.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:32:56.342345 139825303013376 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:32:56.342736 139825303013376 replay_runner.py:41] Starting iteration 0
Steps executed: 111 Episode length: 56 Return: -134.73431151070974
INFO:tensorflow:Average training steps per second: 170.41

Steps executed: 263 Episode length: 74 Return: -138.05205962384554
I0828 10:33:03.441674 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.59
INFO:tensorflow:Starting iteration 1

Steps executed: 306 Episode length: 124 Return: -816.4818715723305
INFO:tensorflow:Average training steps per second: 222.76
I0828 10:33:12.212519 139825303013376 replay_runner.py:36] Average training steps per second: 222.76
I0828 10:33:12.539174 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -591.14
INFO:tensorflow:Starting iteration 2

Steps executed: 253 Episode length: 96 Return: -664.942501852785735
INFO:tensorflow:Average training steps per second: 228.92
I0828 10:33:21.168062 139825303013376 replay_runner.py:36] Average training steps per second: 228.92
I0828 10:33:21.432552 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -546.42
INFO:tensorflow:Starting iteration 3

Steps executed: 295 Episode length: 97 Return: -624.199691771166735
INFO:tensorflow:Average training steps per second: 227.60
I0828 10:33:30.116439 139825303013376 replay_runner.py:36] Average training steps per second: 227.60
I0828 10:33:30.390372 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -609.27
INFO:tensorflow:Starting iteration 4

Steps executed: 242 Episode length: 65 Return: -491.835046954688935
INFO:tensorflow:Average training steps per second: 228.13
I0828 10:33:38.991045 139825303013376 replay_runner.py:36] Average training steps per second: 228.13
I0828 10:33:39.207575 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -532.94
INFO:tensorflow:Starting iteration 5

Steps executed: 347 Episode length: 173 Return: -1418.9933411208506
INFO:tensorflow:Average training steps per second: 223.67
I0828 10:33:47.972250 139825303013376 replay_runner.py:36] Average training steps per second: 223.67
I0828 10:33:48.348720 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -1404.36
INFO:tensorflow:Starting iteration 6

Steps executed: 235 Episode length: 89 Return: -659.219685896217906
INFO:tensorflow:Average training steps per second: 224.24
I0828 10:33:57.363587 139825303013376 replay_runner.py:36] Average training steps per second: 224.24
I0828 10:33:57.573211 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -661.80
INFO:tensorflow:Starting iteration 7

Steps executed: 471 Episode length: 321 Return: -962.78614039524438
INFO:tensorflow:Average training steps per second: 229.91
I0828 10:34:06.127211 139825303013376 replay_runner.py:36] Average training steps per second: 229.91
I0828 10:34:06.643325 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -1052.32
INFO:tensorflow:Starting iteration 8

Steps executed: 251 Episode length: 68 Return: -670.623622915822658
INFO:tensorflow:Average training steps per second: 220.34
I0828 10:34:15.271192 139825303013376 replay_runner.py:36] Average training steps per second: 220.34
I0828 10:34:15.487433 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -556.29
INFO:tensorflow:Starting iteration 9

Steps executed: 257 Episode length: 70 Return: -125.869783698219328
INFO:tensorflow:Average training steps per second: 219.88
I0828 10:34:24.288360 139825303013376 replay_runner.py:36] Average training steps per second: 219.88
I0828 10:34:24.458330 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.87
INFO:tensorflow:Starting iteration 10

Steps executed: 280 Episode length: 104 Return: -636.40440393918976
INFO:tensorflow:Average training steps per second: 213.94
I0828 10:34:33.413416 139825303013376 replay_runner.py:36] Average training steps per second: 213.94
I0828 10:34:33.717189 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -978.20
INFO:tensorflow:Starting iteration 11

Steps executed: 225 Episode length: 121 Return: -460.97699507138816
INFO:tensorflow:Average training steps per second: 214.81
I0828 10:34:42.700588 139825303013376 replay_runner.py:36] Average training steps per second: 214.81
I0828 10:34:42.899669 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -476.44
INFO:tensorflow:Starting iteration 12

Steps executed: 99 Episode length: 99 Return: -215.4914039087119816
INFO:tensorflow:Average training steps per second: 219.67

Steps executed: 247 Episode length: 148 Return: -269.79484551682356
I0828 10:34:51.908168 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.64
INFO:tensorflow:Starting iteration 13

Steps executed: 269 Episode length: 269 Return: -2525.3416676776956
INFO:tensorflow:Average training steps per second: 217.82
I0828 10:35:00.818989 139825303013376 replay_runner.py:36] Average training steps per second: 217.82
I0828 10:35:01.182976 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -2525.34
INFO:tensorflow:Starting iteration 14

Steps executed: 238 Episode length: 61 Return: -587.101485494071886
INFO:tensorflow:Average training steps per second: 218.08
I0828 10:35:10.035070 139825303013376 replay_runner.py:36] Average training steps per second: 218.08
I0828 10:35:10.261201 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -586.56
INFO:tensorflow:Starting iteration 15

Steps executed: 211 Episode length: 94 Return: -407.643808891282186
INFO:tensorflow:Average training steps per second: 218.72
I0828 10:35:19.207430 139825303013376 replay_runner.py:36] Average training steps per second: 218.72
I0828 10:35:19.411912 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.55
INFO:tensorflow:Starting iteration 16

Steps executed: 259 Episode length: 104 Return: -569.20408019287966
INFO:tensorflow:Average training steps per second: 217.64
I0828 10:35:28.262413 139825303013376 replay_runner.py:36] Average training steps per second: 217.64
I0828 10:35:28.529278 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -778.06
INFO:tensorflow:Starting iteration 17

Steps executed: 338 Episode length: 146 Return: -996.94084587547126
INFO:tensorflow:Average training steps per second: 217.10
I0828 10:35:37.375130 139825303013376 replay_runner.py:36] Average training steps per second: 217.10
I0828 10:35:37.720712 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -670.96
INFO:tensorflow:Starting iteration 18

Steps executed: 241 Episode length: 98 Return: -806.483130706268526
INFO:tensorflow:Average training steps per second: 214.27
I0828 10:35:46.626528 139825303013376 replay_runner.py:36] Average training steps per second: 214.27
I0828 10:35:46.844092 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -743.35
INFO:tensorflow:Starting iteration 19

Steps executed: 217 Episode length: 143 Return: -987.17621811378486
INFO:tensorflow:Average training steps per second: 215.34
I0828 10:35:55.801654 139825303013376 replay_runner.py:36] Average training steps per second: 215.34
I0828 10:35:56.017757 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -710.34
INFO:tensorflow:Starting iteration 20

Steps executed: 411 Episode length: 217 Return: -1502.9628874167286
INFO:tensorflow:Average training steps per second: 217.62
I0828 10:36:04.847465 139825303013376 replay_runner.py:36] Average training steps per second: 217.62
I0828 10:36:05.278407 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -917.26
INFO:tensorflow:Starting iteration 21
I0828 10:36:09.547070 139825303013376 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 223.61

Steps executed: 303 Episode length: 128 Return: -1323.0411748743688
I0828 10:36:14.293239 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -827.03
INFO:tensorflow:Starting iteration 22

Steps executed: 208 Episode length: 84 Return: -599.009472577159468
INFO:tensorflow:Average training steps per second: 226.76
I0828 10:36:22.918065 139825303013376 replay_runner.py:36] Average training steps per second: 226.76
I0828 10:36:23.134315 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -737.44
INFO:tensorflow:Starting iteration 23

Steps executed: 269 Episode length: 158 Return: -1120.1499104681178
INFO:tensorflow:Average training steps per second: 231.92
I0828 10:36:31.644451 139825303013376 replay_runner.py:36] Average training steps per second: 231.92
I0828 10:36:31.896596 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -937.58
INFO:tensorflow:Starting iteration 24

Steps executed: 273 Episode length: 133 Return: -694.95762793935498
INFO:tensorflow:Average training steps per second: 222.04
I0828 10:36:40.761942 139825303013376 replay_runner.py:36] Average training steps per second: 222.04
I0828 10:36:41.032612 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -869.55
INFO:tensorflow:Starting iteration 25

Steps executed: 244 Episode length: 65 Return: -637.627337849400698
INFO:tensorflow:Average training steps per second: 225.73
I0828 10:36:49.751425 139825303013376 replay_runner.py:36] Average training steps per second: 225.73
I0828 10:36:49.961239 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -564.69
INFO:tensorflow:Starting iteration 26

Steps executed: 266 Episode length: 106 Return: -687.86830469845298
INFO:tensorflow:Average training steps per second: 220.50
I0828 10:36:59.047649 139825303013376 replay_runner.py:36] Average training steps per second: 220.50
I0828 10:36:59.290542 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -563.65
INFO:tensorflow:Starting iteration 27
I0828 10:37:03.562778 139825303013376 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 224.63
I0828 10:37:08.014827 139825303013376 replay_runner.py:36] Average training steps per second: 224.63

Steps executed: 248 Episode length: 77 Return: -382.831910060179413
INFO:tensorflow:Starting iteration 28

Steps executed: 277 Episode length: 160 Return: -1226.3668374949623
INFO:tensorflow:Average training steps per second: 239.18
I0828 10:37:16.697455 139825303013376 replay_runner.py:36] Average training steps per second: 239.18
I0828 10:37:16.975656 139825303013376 run_experiment.py:428] Average undiscounted return per evaluation episode: -882.40
INFO:tensorflow:Starting iteration 29

Steps executed: 322 Episode length: 134 Return: -608.21185287465423
INFO:tensorflow:Average training steps per second: 231.19
I0828 10:37:25.604532 139825303013376 replay_runner.py:36] Average training steps per second: 231.19

Done fixed training!Episode length: 134 Return: -608.21185287465423