I0902 00:27:06.654150 140149719906304 run_experiment.py:549] Creating TrainRunner ...
I0902 00:27:06.666692 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:27:06.666941 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:27:06.667115 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:27:06.667262 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:27:06.667396 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0902 00:27:06.667579 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:27:06.667732 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:27:06.667873 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:27:06.667988 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:27:06.668122 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0902 00:27:06.668233 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:27:06.668363 140149719906304 dqn_agent.py:283] 	 seed: 1630542426666631
I0902 00:27:06.672128 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:27:06.672349 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:27:06.672478 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:27:06.672592 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:27:06.672707 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:27:06.672810 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:27:06.672912 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:27:06.673017 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:27:06.673112 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:27:06.704249 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:27:07.043509 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:27:07.053072 140149719906304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:27:07.059610 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:27:07.059821 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:27:07.059929 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:27:07.060038 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:27:07.060175 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0902 00:27:07.060273 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:27:07.060371 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:27:07.060461 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:27:07.060519 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:27:07.060593 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0902 00:27:07.060667 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:27:07.060736 140149719906304 dqn_agent.py:283] 	 seed: 1630542427059561
I0902 00:27:07.062172 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:27:07.062291 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:27:07.062363 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:27:07.062431 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:27:07.062535 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:27:07.062595 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:27:07.062677 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:27:07.062748 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:27:07.062817 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:27:07.085472 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:27:07.100233 140149719906304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:27:07.100440 140149719906304 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
Steps executed: 241 Episode length: 125 Return: -439.48325583467266
INFO:tensorflow:Average training steps per second: 246.77
I0902 00:27:11.153123 140149719906304 replay_runner.py:36] Average training steps per second: 246.77
I0902 00:27:11.891740 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.00
INFO:tensorflow:Starting iteration 1
I0902 00:27:15.284974 140149719906304 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 352.85
I0902 00:27:18.119328 140149719906304 replay_runner.py:36] Average training steps per second: 352.85

Steps executed: 244 Episode length: 124 Return: -286.51376365593944
INFO:tensorflow:Starting iteration 2

Steps executed: 187 Episode length: 187 Return: -375.30785720520396
INFO:tensorflow:Average training steps per second: 364.19

Steps executed: 395 Episode length: 208 Return: -347.08505596720766
I0902 00:27:24.636315 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.20
INFO:tensorflow:Starting iteration 3

Steps executed: 288 Episode length: 288 Return: -371.14217130799824
INFO:tensorflow:Average training steps per second: 356.85
I0902 00:27:30.775576 140149719906304 replay_runner.py:36] Average training steps per second: 356.85
I0902 00:27:31.045053 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -371.14
INFO:tensorflow:Starting iteration 4

Steps executed: 587 Episode length: 587 Return: -650.41552593473814
INFO:tensorflow:Average training steps per second: 348.26
I0902 00:27:37.362395 140149719906304 replay_runner.py:36] Average training steps per second: 348.26
I0902 00:27:38.102320 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -650.42
INFO:tensorflow:Starting iteration 5
I0902 00:27:41.539231 140149719906304 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 344.55

Steps executed: 818 Episode length: 818 Return: -274.23464455491074
I0902 00:27:46.073029 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.23
INFO:tensorflow:Starting iteration 6
I0902 00:27:49.552985 140149719906304 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 346.34

Steps executed: 1000 Episode length: 1000 Return: -55.575329532236246
I0902 00:27:55.038301 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -55.58
INFO:tensorflow:Starting iteration 7
I0902 00:27:58.364404 140149719906304 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 333.06

Steps executed: 1000 Episode length: 1000 Return: -136.41240291812932
I0902 00:28:03.321359 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -136.41
INFO:tensorflow:Starting iteration 8

Steps executed: 591 Episode length: 591 Return: -193.7951121825527732
INFO:tensorflow:Average training steps per second: 340.64
I0902 00:28:09.592221 140149719906304 replay_runner.py:36] Average training steps per second: 340.64
I0902 00:28:10.309165 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.80
INFO:tensorflow:Starting iteration 9

Steps executed: 665 Episode length: 479 Return: -370.1762387334378732
INFO:tensorflow:Average training steps per second: 345.77
I0902 00:28:16.607929 140149719906304 replay_runner.py:36] Average training steps per second: 345.77
I0902 00:28:17.277054 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.84
INFO:tensorflow:Starting iteration 10
I0902 00:28:20.600410 140149719906304 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 330.27

Steps executed: 1000 Episode length: 1000 Return: -99.156188985652762
I0902 00:28:25.253495 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.16
INFO:tensorflow:Starting iteration 11
I0902 00:28:28.471814 140149719906304 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 336.81

Steps executed: 1000 Episode length: 1000 Return: -166.32023346225395
I0902 00:28:33.818498 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -166.32
INFO:tensorflow:Starting iteration 12
I0902 00:28:37.024325 140149719906304 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 321.07
I0902 00:28:40.139182 140149719906304 replay_runner.py:36] Average training steps per second: 321.07

Steps executed: 376 Episode length: 376 Return: -307.9206362939662595
INFO:tensorflow:Starting iteration 13

Steps executed: 710 Episode length: 710 Return: -438.4914290478348595
INFO:tensorflow:Average training steps per second: 337.23
I0902 00:28:46.743458 140149719906304 replay_runner.py:36] Average training steps per second: 337.23
I0902 00:28:47.894320 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -438.49
INFO:tensorflow:Starting iteration 14
I0902 00:28:51.159967 140149719906304 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 345.32

Steps executed: 1000 Episode length: 1000 Return: -133.31342232847325
I0902 00:28:56.400386 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.31
INFO:tensorflow:Starting iteration 15

Steps executed: 83 Episode length: 83 Return: -133.418477033235447325
INFO:tensorflow:Average training steps per second: 345.98
I0902 00:29:02.564987 140149719906304 replay_runner.py:36] Average training steps per second: 345.98

Steps executed: 225 Episode length: 142 Return: -135.2364640085196225
INFO:tensorflow:Starting iteration 16

Steps executed: 316 Episode length: 122 Return: -757.5812567204873225
INFO:tensorflow:Average training steps per second: 357.29
I0902 00:29:08.927073 140149719906304 replay_runner.py:36] Average training steps per second: 357.29
I0902 00:29:09.127927 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -623.13
INFO:tensorflow:Starting iteration 17

Steps executed: 319 Episode length: 129 Return: -167.2571655168417225
INFO:tensorflow:Average training steps per second: 361.49
I0902 00:29:15.410275 140149719906304 replay_runner.py:36] Average training steps per second: 361.49
I0902 00:29:15.569358 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.50
INFO:tensorflow:Starting iteration 18

Steps executed: 334 Episode length: 176 Return: 13.533685215742878225
INFO:tensorflow:Average training steps per second: 326.94
I0902 00:29:22.004224 140149719906304 replay_runner.py:36] Average training steps per second: 326.94
I0902 00:29:22.175612 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.06
INFO:tensorflow:Starting iteration 19

Steps executed: 220 Episode length: 136 Return: -164.4449140328144725
INFO:tensorflow:Average training steps per second: 326.69
I0902 00:29:28.488679 140149719906304 replay_runner.py:36] Average training steps per second: 326.69
I0902 00:29:28.594879 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.74
INFO:tensorflow:Starting iteration 20
I0902 00:29:31.914226 140149719906304 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 332.88

Steps executed: 234 Episode length: 72 Return: -32.205846539013085625
I0902 00:29:35.040600 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -73.86
INFO:tensorflow:Starting iteration 21

Steps executed: 284 Episode length: 140 Return: -172.3850652698763625
INFO:tensorflow:Average training steps per second: 333.94
I0902 00:29:41.452475 140149719906304 replay_runner.py:36] Average training steps per second: 333.94
I0902 00:29:41.631732 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.29
INFO:tensorflow:Starting iteration 22

Steps executed: 249 Episode length: 53 Return: -282.81071505022262625
INFO:tensorflow:Average training steps per second: 334.78
I0902 00:29:47.995799 140149719906304 replay_runner.py:36] Average training steps per second: 334.78
I0902 00:29:48.139787 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -275.61
INFO:tensorflow:Starting iteration 23

Steps executed: 227 Episode length: 63 Return: -171.32301564166954625
INFO:tensorflow:Average training steps per second: 334.58
I0902 00:29:54.542979 140149719906304 replay_runner.py:36] Average training steps per second: 334.58
I0902 00:29:54.662849 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.07
INFO:tensorflow:Starting iteration 24
I0902 00:29:58.051136 140149719906304 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 328.20

Steps executed: 254 Episode length: 108 Return: 10.503954453371136625
I0902 00:30:01.258500 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.95
INFO:tensorflow:Starting iteration 25

Steps executed: 211 Episode length: 211 Return: -464.4179021318486625
INFO:tensorflow:Average training steps per second: 325.52
I0902 00:30:07.627323 140149719906304 replay_runner.py:36] Average training steps per second: 325.52
I0902 00:30:07.797925 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -464.42
INFO:tensorflow:Starting iteration 26

Steps executed: 227 Episode length: 103 Return: -211.2455572488279425
INFO:tensorflow:Average training steps per second: 325.00
I0902 00:30:14.188049 140149719906304 replay_runner.py:36] Average training steps per second: 325.00
I0902 00:30:14.345042 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -313.12
INFO:tensorflow:Starting iteration 27

Steps executed: 233 Episode length: 100 Return: 3.5022435117078317825
INFO:tensorflow:Average training steps per second: 330.51
I0902 00:30:20.709120 140149719906304 replay_runner.py:36] Average training steps per second: 330.51
I0902 00:30:20.881876 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.48
INFO:tensorflow:Starting iteration 28
I0902 00:30:24.259131 140149719906304 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 336.46

Steps executed: 286 Episode length: 109 Return: -201.6084019032297825
I0902 00:30:27.397425 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -194.10
INFO:tensorflow:Starting iteration 29

Steps executed: 263 Episode length: 124 Return: -430.3732631194186825
INFO:tensorflow:Average training steps per second: 333.44
I0902 00:30:33.708634 140149719906304 replay_runner.py:36] Average training steps per second: 333.44

Done fixed training!Episode length: 124 Return: -430.3732631194186825