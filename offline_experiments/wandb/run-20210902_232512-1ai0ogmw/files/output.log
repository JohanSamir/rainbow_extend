Loaded trained dqn in acrobot
Training fixed agent 7, please be patient, may be a while...
I0902 23:25:19.206575 140527680751616 run_experiment.py:549] Creating TrainRunner ...
I0902 23:25:19.215612 140527680751616 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:25:19.215900 140527680751616 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:25:19.216097 140527680751616 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:25:19.216246 140527680751616 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:25:19.216492 140527680751616 dqn_agent.py:275] 	 update_period: 4
I0902 23:25:19.216651 140527680751616 dqn_agent.py:276] 	 target_update_period: 100
I0902 23:25:19.216795 140527680751616 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:25:19.216867 140527680751616 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:25:19.216947 140527680751616 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:25:19.217067 140527680751616 dqn_agent.py:280] 	 optimizer: adam
I0902 23:25:19.217193 140527680751616 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:25:19.217309 140527680751616 dqn_agent.py:283] 	 seed: 1630625119215534
I0902 23:25:19.220381 140527680751616 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:25:19.220553 140527680751616 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0902 23:25:19.220678 140527680751616 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:25:19.220769 140527680751616 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:25:19.220857 140527680751616 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:25:19.220933 140527680751616 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:25:19.221013 140527680751616 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:25:19.221096 140527680751616 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:25:19.221180 140527680751616 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:25:19.260517 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:25:19.664727 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:25:19.680151 140527680751616 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:25:19.689719 140527680751616 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:25:19.689970 140527680751616 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:25:19.690107 140527680751616 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:25:19.690226 140527680751616 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:25:19.690345 140527680751616 dqn_agent.py:275] 	 update_period: 4
I0902 23:25:19.690463 140527680751616 dqn_agent.py:276] 	 target_update_period: 100
I0902 23:25:19.690620 140527680751616 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:25:19.690848 140527680751616 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:25:19.690973 140527680751616 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:25:19.691153 140527680751616 dqn_agent.py:280] 	 optimizer: adam
I0902 23:25:19.691277 140527680751616 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:25:19.691396 140527680751616 dqn_agent.py:283] 	 seed: 1630625119689651
I0902 23:25:19.723675 140527680751616 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:25:19.723934 140527680751616 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0902 23:25:19.724030 140527680751616 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:25:19.724163 140527680751616 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:25:19.724375 140527680751616 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:25:19.724534 140527680751616 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:25:19.724755 140527680751616 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:25:19.724851 140527680751616 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:25:19.724927 140527680751616 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:25:19.757865 140527680751616 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:25:19.779967 140527680751616 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:25:19.780236 140527680751616 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 148.72
I0902 23:25:26.504763 140527680751616 replay_runner.py:36] Average training steps per second: 148.72
Steps executed: 242 Episode length: 242 Return: -241.0
I0902 23:25:27.779288 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -241.00
INFO:tensorflow:Starting iteration 1

Steps executed: 283 Episode length: 161 Return: -160.0
INFO:tensorflow:Average training steps per second: 204.27
I0902 23:25:32.909700 140527680751616 replay_runner.py:36] Average training steps per second: 204.27
I0902 23:25:33.155877 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.50
INFO:tensorflow:Starting iteration 2

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 200.87
I0902 23:25:38.378217 140527680751616 replay_runner.py:36] Average training steps per second: 200.87
I0902 23:25:38.773019 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 3
I0902 23:25:38.994158 140527680751616 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 203.66
I0902 23:25:43.904581 140527680751616 replay_runner.py:36] Average training steps per second: 203.66
I0902 23:25:44.319418 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 4
I0902 23:25:44.558362 140527680751616 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 202.67
I0902 23:25:49.492922 140527680751616 replay_runner.py:36] Average training steps per second: 202.67
I0902 23:25:49.885469 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 5
I0902 23:25:50.117527 140527680751616 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 201.81

Steps executed: 232 Episode length: 89 Return: -88.0.0
I0902 23:25:55.272402 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.00
INFO:tensorflow:Starting iteration 6

Steps executed: 500 Episode length: 500 Return: -500.0
INFO:tensorflow:Average training steps per second: 198.04
I0902 23:26:00.558311 140527680751616 replay_runner.py:36] Average training steps per second: 198.04
I0902 23:26:00.952824 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 7

Steps executed: 242 Episode length: 159 Return: -158.0
INFO:tensorflow:Average training steps per second: 201.52
I0902 23:26:06.153356 140527680751616 replay_runner.py:36] Average training steps per second: 201.52
I0902 23:26:06.365862 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.00
INFO:tensorflow:Starting iteration 8

Steps executed: 244 Episode length: 100 Return: -99.00
INFO:tensorflow:Average training steps per second: 196.83
I0902 23:26:11.684985 140527680751616 replay_runner.py:36] Average training steps per second: 196.83
I0902 23:26:11.889025 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.33
INFO:tensorflow:Starting iteration 9
I0902 23:26:12.121643 140527680751616 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 200.76
I0902 23:26:17.103278 140527680751616 replay_runner.py:36] Average training steps per second: 200.76

Steps executed: 216 Episode length: 216 Return: -215.0
INFO:tensorflow:Starting iteration 10

Steps executed: 268 Episode length: 70 Return: -69.0.0
INFO:tensorflow:Average training steps per second: 193.45
I0902 23:26:22.696610 140527680751616 replay_runner.py:36] Average training steps per second: 193.45
I0902 23:26:22.927725 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.33
INFO:tensorflow:Starting iteration 11

Steps executed: 247 Episode length: 89 Return: -88.0.0
INFO:tensorflow:Average training steps per second: 204.89
I0902 23:26:28.054467 140527680751616 replay_runner.py:36] Average training steps per second: 204.89
I0902 23:26:28.245784 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -81.33
INFO:tensorflow:Starting iteration 12

Steps executed: 253 Episode length: 77 Return: -76.0.0
INFO:tensorflow:Average training steps per second: 194.57
I0902 23:26:33.626258 140527680751616 replay_runner.py:36] Average training steps per second: 194.57
I0902 23:26:33.830924 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.33
INFO:tensorflow:Starting iteration 13

Steps executed: 290 Episode length: 91 Return: -90.0.0
INFO:tensorflow:Average training steps per second: 200.33
I0902 23:26:39.066625 140527680751616 replay_runner.py:36] Average training steps per second: 200.33
I0902 23:26:39.292731 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -95.67
INFO:tensorflow:Starting iteration 14

Steps executed: 234 Episode length: 157 Return: -156.0
INFO:tensorflow:Average training steps per second: 195.45
I0902 23:26:44.644825 140527680751616 replay_runner.py:36] Average training steps per second: 195.45
I0902 23:26:44.833254 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.00
INFO:tensorflow:Starting iteration 15

Steps executed: 205 Episode length: 105 Return: -104.0
INFO:tensorflow:Average training steps per second: 201.70
I0902 23:26:50.031813 140527680751616 replay_runner.py:36] Average training steps per second: 201.70
I0902 23:26:50.211502 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.50
INFO:tensorflow:Starting iteration 16

Steps executed: 237 Episode length: 97 Return: -96.0.0
INFO:tensorflow:Average training steps per second: 193.59
I0902 23:26:55.720817 140527680751616 replay_runner.py:36] Average training steps per second: 193.59
I0902 23:26:55.930550 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.50
INFO:tensorflow:Starting iteration 17
I0902 23:26:56.172423 140527680751616 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 202.82

Steps executed: 219 Episode length: 99 Return: -98.0.0
I0902 23:27:01.287514 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.50
INFO:tensorflow:Starting iteration 18

Steps executed: 243 Episode length: 90 Return: -89.0.0
INFO:tensorflow:Average training steps per second: 193.41
I0902 23:27:06.694939 140527680751616 replay_runner.py:36] Average training steps per second: 193.41
I0902 23:27:06.913231 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.00
INFO:tensorflow:Starting iteration 19

Steps executed: 211 Episode length: 94 Return: -93.0.0
INFO:tensorflow:Average training steps per second: 201.80
I0902 23:27:12.111352 140527680751616 replay_runner.py:36] Average training steps per second: 201.80
I0902 23:27:12.277866 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.50
INFO:tensorflow:Starting iteration 20

Steps executed: 278 Episode length: 79 Return: -78.0.0
INFO:tensorflow:Average training steps per second: 196.68
I0902 23:27:17.609409 140527680751616 replay_runner.py:36] Average training steps per second: 196.68
I0902 23:27:17.872288 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.67
INFO:tensorflow:Starting iteration 21

Steps executed: 172 Episode length: 89 Return: -88.0.0
INFO:tensorflow:Average training steps per second: 202.52
I0902 23:27:23.064936 140527680751616 replay_runner.py:36] Average training steps per second: 202.52

Steps executed: 278 Episode length: 106 Return: -105.0
INFO:tensorflow:Starting iteration 22

Steps executed: 226 Episode length: 80 Return: -79.0.0
INFO:tensorflow:Average training steps per second: 196.77
I0902 23:27:28.600098 140527680751616 replay_runner.py:36] Average training steps per second: 196.77
I0902 23:27:28.781028 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.33
INFO:tensorflow:Starting iteration 23

Steps executed: 244 Episode length: 84 Return: -83.0.0
INFO:tensorflow:Average training steps per second: 201.00
I0902 23:27:33.996990 140527680751616 replay_runner.py:36] Average training steps per second: 201.00
I0902 23:27:34.189231 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.33
INFO:tensorflow:Starting iteration 24

Steps executed: 92 Episode length: 92 Return: -91.00.0
INFO:tensorflow:Average training steps per second: 204.47
I0902 23:27:39.317889 140527680751616 replay_runner.py:36] Average training steps per second: 204.47

Steps executed: 276 Episode length: 99 Return: -98.0.0
INFO:tensorflow:Starting iteration 25

Steps executed: 206 Episode length: 97 Return: -96.0.0
INFO:tensorflow:Average training steps per second: 197.92
I0902 23:27:44.848067 140527680751616 replay_runner.py:36] Average training steps per second: 197.92
I0902 23:27:44.999728 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.00
INFO:tensorflow:Starting iteration 26

Steps executed: 311 Episode length: 143 Return: -142.0
INFO:tensorflow:Average training steps per second: 205.14
I0902 23:27:50.098376 140527680751616 replay_runner.py:36] Average training steps per second: 205.14
I0902 23:27:50.343007 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.67
INFO:tensorflow:Starting iteration 27

Steps executed: 178 Episode length: 71 Return: -70.0.0
INFO:tensorflow:Average training steps per second: 205.82
I0902 23:27:55.435544 140527680751616 replay_runner.py:36] Average training steps per second: 205.82

Steps executed: 278 Episode length: 100 Return: -99.00
INFO:tensorflow:Starting iteration 28

Steps executed: 231 Episode length: 62 Return: -61.000
INFO:tensorflow:Average training steps per second: 206.88
I0902 23:28:00.685605 140527680751616 replay_runner.py:36] Average training steps per second: 206.88
I0902 23:28:00.871757 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.00
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 73 Return: -72.000
INFO:tensorflow:Average training steps per second: 200.89
I0902 23:28:06.087193 140527680751616 replay_runner.py:36] Average training steps per second: 200.89
I0902 23:28:06.288543 140527680751616 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.00