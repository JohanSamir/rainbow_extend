Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0828 10:23:20.514508 140220309850112 run_experiment.py:549] Creating TrainRunner ...
I0828 10:23:20.525903 140220309850112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:23:20.526159 140220309850112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:23:20.526283 140220309850112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:23:20.526625 140220309850112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:23:20.526810 140220309850112 dqn_agent.py:275] 	 update_period: 4
I0828 10:23:20.526971 140220309850112 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:23:20.527079 140220309850112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:23:20.527212 140220309850112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:23:20.527478 140220309850112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:23:20.527632 140220309850112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:23:20.527894 140220309850112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:23:20.528069 140220309850112 dqn_agent.py:283] 	 seed: 1630146200525834
I0828 10:23:20.530017 140220309850112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:23:20.530170 140220309850112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:23:20.530289 140220309850112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:23:20.530465 140220309850112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:23:20.530622 140220309850112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:23:20.530706 140220309850112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:23:20.530824 140220309850112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:23:20.530924 140220309850112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:23:20.531126 140220309850112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:23:20.566701 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:21.280290 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:21.294952 140220309850112 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:23:21.301819 140220309850112 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:23:21.302036 140220309850112 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:23:21.302243 140220309850112 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:23:21.302422 140220309850112 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:23:21.302535 140220309850112 dqn_agent.py:275] 	 update_period: 4
I0828 10:23:21.302705 140220309850112 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:23:21.302817 140220309850112 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:23:21.302908 140220309850112 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:23:21.302992 140220309850112 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:23:21.303073 140220309850112 dqn_agent.py:280] 	 optimizer: adam
I0828 10:23:21.303156 140220309850112 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:23:21.303280 140220309850112 dqn_agent.py:283] 	 seed: 1630146201301773
I0828 10:23:21.305950 140220309850112 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:23:21.306175 140220309850112 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:23:21.306329 140220309850112 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:23:21.306439 140220309850112 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:23:21.306518 140220309850112 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:23:21.306610 140220309850112 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:23:21.306709 140220309850112 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:23:21.306805 140220309850112 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:23:21.306899 140220309850112 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:23:21.336554 140220309850112 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:21.356554 140220309850112 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:23:21.356853 140220309850112 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 169.42
I0828 10:23:27.259399 140220309850112 replay_runner.py:36] Average training steps per second: 169.42
Steps executed: 215 Episode length: 62 Return: -380.44957016014276
I0828 10:23:28.505774 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -377.33
INFO:tensorflow:Starting iteration 1

Steps executed: 512 Episode length: 359 Return: -678.9023325239659
INFO:tensorflow:Average training steps per second: 226.92
I0828 10:23:37.240313 140220309850112 replay_runner.py:36] Average training steps per second: 226.92
I0828 10:23:37.810764 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -271.10
INFO:tensorflow:Starting iteration 2

Steps executed: 239 Episode length: 67 Return: -554.57182219131356
INFO:tensorflow:Average training steps per second: 230.97
I0828 10:23:46.487850 140220309850112 replay_runner.py:36] Average training steps per second: 230.97
I0828 10:23:46.700790 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -515.32
INFO:tensorflow:Starting iteration 3

Steps executed: 218 Episode length: 69 Return: -141.16768347318492
INFO:tensorflow:Average training steps per second: 230.63
I0828 10:23:55.293989 140220309850112 replay_runner.py:36] Average training steps per second: 230.63
I0828 10:23:55.450214 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.24
INFO:tensorflow:Starting iteration 4

Steps executed: 56 Episode length: 56 Return: -392.141067025602752
INFO:tensorflow:Average training steps per second: 228.14
I0828 10:24:04.226307 140220309850112 replay_runner.py:36] Average training steps per second: 228.14

Steps executed: 213 Episode length: 81 Return: -769.57602158407452
INFO:tensorflow:Starting iteration 5

Steps executed: 206 Episode length: 52 Return: -328.41934865683042
INFO:tensorflow:Average training steps per second: 228.14
I0828 10:24:13.224239 140220309850112 replay_runner.py:36] Average training steps per second: 228.14
I0828 10:24:13.406846 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -596.67
INFO:tensorflow:Starting iteration 6

Steps executed: 272 Episode length: 86 Return: -800.32838988376682
INFO:tensorflow:Average training steps per second: 239.84
I0828 10:24:21.942739 140220309850112 replay_runner.py:36] Average training steps per second: 239.84
I0828 10:24:22.159010 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -575.15
INFO:tensorflow:Starting iteration 7

Steps executed: 131 Episode length: 54 Return: -406.94800058742044
INFO:tensorflow:Average training steps per second: 256.32
I0828 10:24:30.224326 140220309850112 replay_runner.py:36] Average training steps per second: 256.32

Steps executed: 250 Episode length: 57 Return: -402.22165610532044
INFO:tensorflow:Starting iteration 8
I0828 10:24:34.652036 140220309850112 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 254.25

Steps executed: 216 Episode length: 85 Return: -960.17413069305034
I0828 10:24:38.755417 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -677.67
INFO:tensorflow:Starting iteration 9

Steps executed: 272 Episode length: 81 Return: -428.41986242914894
INFO:tensorflow:Average training steps per second: 239.44
I0828 10:24:46.920939 140220309850112 replay_runner.py:36] Average training steps per second: 239.44
I0828 10:24:47.132706 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -431.66
INFO:tensorflow:Starting iteration 10

Steps executed: 218 Episode length: 67 Return: -572.96672364776424
INFO:tensorflow:Average training steps per second: 239.16
I0828 10:24:55.588705 140220309850112 replay_runner.py:36] Average training steps per second: 239.16
I0828 10:24:55.787390 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -666.84
INFO:tensorflow:Starting iteration 11

Steps executed: 121 Episode length: 57 Return: -530.15051003224774
INFO:tensorflow:Average training steps per second: 229.25
I0828 10:25:04.402986 140220309850112 replay_runner.py:36] Average training steps per second: 229.25

Steps executed: 250 Episode length: 72 Return: -578.64211294673714
INFO:tensorflow:Starting iteration 12

Steps executed: 222 Episode length: 67 Return: -583.18231578369164
INFO:tensorflow:Average training steps per second: 234.93
I0828 10:25:13.240190 140220309850112 replay_runner.py:36] Average training steps per second: 234.93
I0828 10:25:13.407506 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -532.81
INFO:tensorflow:Starting iteration 13

Steps executed: 277 Episode length: 81 Return: -748.26058703898564
INFO:tensorflow:Average training steps per second: 226.18
I0828 10:25:22.056004 140220309850112 replay_runner.py:36] Average training steps per second: 226.18
I0828 10:25:22.311633 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -649.33
INFO:tensorflow:Starting iteration 14

Steps executed: 211 Episode length: 60 Return: -133.49544175764649
INFO:tensorflow:Average training steps per second: 221.04
I0828 10:25:31.157760 140220309850112 replay_runner.py:36] Average training steps per second: 221.04
I0828 10:25:31.295545 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.51
INFO:tensorflow:Starting iteration 15

Steps executed: 237 Episode length: 83 Return: -450.88945230213627
INFO:tensorflow:Average training steps per second: 224.70
I0828 10:25:40.125883 140220309850112 replay_runner.py:36] Average training steps per second: 224.70
I0828 10:25:40.332741 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -389.64
INFO:tensorflow:Starting iteration 16

Steps executed: 263 Episode length: 65 Return: -586.77116627083966
INFO:tensorflow:Average training steps per second: 230.34
I0828 10:25:48.920236 140220309850112 replay_runner.py:36] Average training steps per second: 230.34
I0828 10:25:49.151165 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -531.68
INFO:tensorflow:Starting iteration 17

Steps executed: 223 Episode length: 53 Return: -335.32344954223516
INFO:tensorflow:Average training steps per second: 232.86
I0828 10:25:57.775938 140220309850112 replay_runner.py:36] Average training steps per second: 232.86
I0828 10:25:57.968055 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -423.24
INFO:tensorflow:Starting iteration 18

Steps executed: 223 Episode length: 69 Return: -178.11028500769618
INFO:tensorflow:Average training steps per second: 233.72
I0828 10:26:06.657482 140220309850112 replay_runner.py:36] Average training steps per second: 233.72
I0828 10:26:06.804787 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -143.14
INFO:tensorflow:Starting iteration 19

Steps executed: 230 Episode length: 83 Return: -948.68957204795628
INFO:tensorflow:Average training steps per second: 229.68
I0828 10:26:15.462662 140220309850112 replay_runner.py:36] Average training steps per second: 229.68
I0828 10:26:15.667162 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -804.60
INFO:tensorflow:Starting iteration 20

Steps executed: 149 Episode length: 64 Return: -611.93220791687298
INFO:tensorflow:Average training steps per second: 231.21
I0828 10:26:24.333328 140220309850112 replay_runner.py:36] Average training steps per second: 231.21

Steps executed: 210 Episode length: 61 Return: -459.35900460709973
INFO:tensorflow:Starting iteration 21

Steps executed: 262 Episode length: 71 Return: -722.34025599977247
INFO:tensorflow:Average training steps per second: 227.19
I0828 10:26:33.288207 140220309850112 replay_runner.py:36] Average training steps per second: 227.19
I0828 10:26:33.509545 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -619.53
INFO:tensorflow:Starting iteration 22

Steps executed: 250 Episode length: 83 Return: -748.46101118493487
INFO:tensorflow:Average training steps per second: 233.87
I0828 10:26:42.179955 140220309850112 replay_runner.py:36] Average training steps per second: 233.87
I0828 10:26:42.403327 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -794.60
INFO:tensorflow:Starting iteration 23

Steps executed: 312 Episode length: 124 Return: -796.23441168739764
INFO:tensorflow:Average training steps per second: 230.32
I0828 10:26:51.079398 140220309850112 replay_runner.py:36] Average training steps per second: 230.32
I0828 10:26:51.395812 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -1101.51
INFO:tensorflow:Starting iteration 24

Steps executed: 270 Episode length: 74 Return: -516.275020368591154
INFO:tensorflow:Average training steps per second: 233.98
I0828 10:27:00.054479 140220309850112 replay_runner.py:36] Average training steps per second: 233.98
I0828 10:27:00.276781 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -512.91
INFO:tensorflow:Starting iteration 25
I0828 10:27:04.605463 140220309850112 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 232.42

Steps executed: 253 Episode length: 56 Return: -519.310537546065234
I0828 10:27:09.110230 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -522.73
INFO:tensorflow:Starting iteration 26

Steps executed: 209 Episode length: 74 Return: -439.931680281849944
INFO:tensorflow:Average training steps per second: 233.88
I0828 10:27:17.734130 140220309850112 replay_runner.py:36] Average training steps per second: 233.88
I0828 10:27:17.964799 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -584.75
INFO:tensorflow:Starting iteration 27

Steps executed: 229 Episode length: 81 Return: -758.764143731753544
INFO:tensorflow:Average training steps per second: 235.50
I0828 10:27:26.488046 140220309850112 replay_runner.py:36] Average training steps per second: 235.50
I0828 10:27:26.671061 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -674.09
INFO:tensorflow:Starting iteration 28
I0828 10:27:30.841797 140220309850112 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 234.00

Steps executed: 209 Episode length: 78 Return: -375.448216131315244
I0828 10:27:35.294765 140220309850112 run_experiment.py:428] Average undiscounted return per evaluation episode: -457.21
INFO:tensorflow:Starting iteration 29

Steps executed: 207 Episode length: 88 Return: -812.564748155650174
INFO:tensorflow:Average training steps per second: 232.93
I0828 10:27:43.822145 140220309850112 replay_runner.py:36] Average training steps per second: 232.93

Done fixed training!Episode length: 88 Return: -812.564748155650174