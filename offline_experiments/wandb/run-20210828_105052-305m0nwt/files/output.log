I0828 10:50:58.641916 139779140274176 run_experiment.py:549] Creating TrainRunner ...
I0828 10:50:58.650447 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:50:58.650580 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:50:58.650663 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:50:58.650725 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:50:58.650783 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:50:58.650837 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:50:58.650938 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:50:58.651018 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:50:58.651086 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:50:58.651140 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:50:58.651213 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:50:58.651299 139779140274176 dqn_agent.py:283] 	 seed: 1630147858650411
I0828 10:50:58.652907 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:50:58.653021 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:50:58.653100 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:50:58.653163 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:50:58.653221 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:50:58.653280 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:50:58.653342 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:50:58.653421 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:50:58.653488 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:50:58.678863 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:50:58.940030 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:50:58.949788 139779140274176 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:50:58.957861 139779140274176 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:50:58.958000 139779140274176 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:50:58.958132 139779140274176 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:50:58.958213 139779140274176 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:50:58.958271 139779140274176 dqn_agent.py:275] 	 update_period: 4
I0828 10:50:58.958356 139779140274176 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:50:58.958414 139779140274176 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:50:58.958478 139779140274176 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:50:58.958529 139779140274176 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:50:58.958630 139779140274176 dqn_agent.py:280] 	 optimizer: adam
I0828 10:50:58.958770 139779140274176 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:50:58.958860 139779140274176 dqn_agent.py:283] 	 seed: 1630147858957828
I0828 10:50:58.961149 139779140274176 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:50:58.961277 139779140274176 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:50:58.961374 139779140274176 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:50:58.961445 139779140274176 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:50:58.961518 139779140274176 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:50:58.961599 139779140274176 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:50:58.961664 139779140274176 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:50:58.961766 139779140274176 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:50:58.961855 139779140274176 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:50:58.983749 139779140274176 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:50:58.998970 139779140274176 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:50:58.999126 139779140274176 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 243.39
I0828 10:51:03.108019 139779140274176 replay_runner.py:36] Average training steps per second: 243.39
I0828 10:51:04.111879 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -305.51
Steps executed: 504 Episode length: 330 Return: -162.60528533846875
INFO:tensorflow:Starting iteration 1
I0828 10:51:07.534538 139779140274176 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 330.70
I0828 10:51:10.558735 139779140274176 replay_runner.py:36] Average training steps per second: 330.70

Steps executed: 261 Episode length: 147 Return: -199.11607003829134
INFO:tensorflow:Starting iteration 2
I0828 10:51:14.096154 139779140274176 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 333.02
I0828 10:51:17.099264 139779140274176 replay_runner.py:36] Average training steps per second: 333.02

Steps executed: 252 Episode length: 104 Return: -250.25062384610467
INFO:tensorflow:Starting iteration 3
I0828 10:51:20.706649 139779140274176 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 333.02
I0828 10:51:23.709765 139779140274176 replay_runner.py:36] Average training steps per second: 333.02

Steps executed: 247 Episode length: 247 Return: -21.132564446374474
INFO:tensorflow:Starting iteration 4
I0828 10:51:27.298684 139779140274176 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 325.48

Steps executed: 238 Episode length: 109 Return: -307.20455102912365
I0828 10:51:30.522416 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.66
INFO:tensorflow:Starting iteration 5

Steps executed: 252 Episode length: 167 Return: -302.84120473055447
INFO:tensorflow:Average training steps per second: 325.82
I0828 10:51:36.945884 139779140274176 replay_runner.py:36] Average training steps per second: 325.82
I0828 10:51:37.113958 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.59
INFO:tensorflow:Starting iteration 6

Steps executed: 318 Episode length: 150 Return: -218.36642936577562
INFO:tensorflow:Average training steps per second: 327.61
I0828 10:51:43.538503 139779140274176 replay_runner.py:36] Average training steps per second: 327.61
I0828 10:51:43.721959 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -286.29
INFO:tensorflow:Starting iteration 7

Steps executed: 227 Episode length: 126 Return: -240.70658442797182
INFO:tensorflow:Average training steps per second: 329.34
I0828 10:51:50.126654 139779140274176 replay_runner.py:36] Average training steps per second: 329.34
I0828 10:51:50.257259 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -339.32
INFO:tensorflow:Starting iteration 8

Steps executed: 309 Episode length: 115 Return: -258.92744314869032
INFO:tensorflow:Average training steps per second: 262.28
I0828 10:51:57.461861 139779140274176 replay_runner.py:36] Average training steps per second: 262.28
I0828 10:51:57.671682 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -282.74
INFO:tensorflow:Starting iteration 9

Steps executed: 307 Episode length: 131 Return: -230.07997345088614
INFO:tensorflow:Average training steps per second: 321.04
I0828 10:52:04.157630 139779140274176 replay_runner.py:36] Average training steps per second: 321.04
I0828 10:52:04.341483 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -246.38
INFO:tensorflow:Starting iteration 10

Steps executed: 233 Episode length: 93 Return: -118.640923003784914
INFO:tensorflow:Average training steps per second: 324.23
I0828 10:52:10.799394 139779140274176 replay_runner.py:36] Average training steps per second: 324.23
I0828 10:52:10.943078 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -188.07
INFO:tensorflow:Starting iteration 11

Steps executed: 261 Episode length: 84 Return: -380.843645753197854
INFO:tensorflow:Average training steps per second: 321.98
I0828 10:52:17.434077 139779140274176 replay_runner.py:36] Average training steps per second: 321.98
I0828 10:52:17.579043 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -319.40
INFO:tensorflow:Starting iteration 12

Steps executed: 387 Episode length: 223 Return: -283.43279633080614
INFO:tensorflow:Average training steps per second: 320.89
I0828 10:52:24.072788 139779140274176 replay_runner.py:36] Average training steps per second: 320.89
I0828 10:52:24.326073 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -255.44
INFO:tensorflow:Starting iteration 13

Steps executed: 203 Episode length: 203 Return: -348.30633293842385
INFO:tensorflow:Average training steps per second: 315.50
I0828 10:52:30.862787 139779140274176 replay_runner.py:36] Average training steps per second: 315.50
I0828 10:52:31.010428 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -348.31
INFO:tensorflow:Starting iteration 14

Steps executed: 310 Episode length: 149 Return: -268.35784028459244
INFO:tensorflow:Average training steps per second: 318.26
I0828 10:52:37.547761 139779140274176 replay_runner.py:36] Average training steps per second: 318.26
I0828 10:52:37.734507 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.75
INFO:tensorflow:Starting iteration 15

Steps executed: 302 Episode length: 135 Return: -323.71287837006334
INFO:tensorflow:Average training steps per second: 331.25
I0828 10:52:44.158361 139779140274176 replay_runner.py:36] Average training steps per second: 331.25
I0828 10:52:44.348584 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -311.51
INFO:tensorflow:Starting iteration 16

Steps executed: 215 Episode length: 117 Return: -304.67385965676664
INFO:tensorflow:Average training steps per second: 332.53
I0828 10:52:50.767676 139779140274176 replay_runner.py:36] Average training steps per second: 332.53
I0828 10:52:50.879204 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.36
INFO:tensorflow:Starting iteration 17

Steps executed: 219 Episode length: 89 Return: -461.303753899907464
INFO:tensorflow:Average training steps per second: 337.37
I0828 10:52:57.255560 139779140274176 replay_runner.py:36] Average training steps per second: 337.37
I0828 10:52:57.376936 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -430.87
INFO:tensorflow:Starting iteration 18

Steps executed: 214 Episode length: 137 Return: -160.53081804160212
INFO:tensorflow:Average training steps per second: 336.74
I0828 10:53:03.807225 139779140274176 replay_runner.py:36] Average training steps per second: 336.74
I0828 10:53:03.948341 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.16
INFO:tensorflow:Starting iteration 19
I0828 10:53:07.420532 139779140274176 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 343.27

Steps executed: 532 Episode length: 532 Return: -151.49497262151672
I0828 10:53:11.110244 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.49
INFO:tensorflow:Starting iteration 20

Steps executed: 114 Episode length: 114 Return: -121.10406920199408
INFO:tensorflow:Average training steps per second: 339.79

Steps executed: 863 Episode length: 749 Return: -514.60161176505938
I0828 10:53:18.865820 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -317.85
INFO:tensorflow:Starting iteration 21

Steps executed: 207 Episode length: 97 Return: -583.545527658408978
INFO:tensorflow:Average training steps per second: 339.50
I0828 10:53:25.269939 139779140274176 replay_runner.py:36] Average training steps per second: 339.50
I0828 10:53:25.384486 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.54
INFO:tensorflow:Starting iteration 22

Steps executed: 302 Episode length: 158 Return: -651.37702316584758
INFO:tensorflow:Average training steps per second: 340.06
I0828 10:53:31.757840 139779140274176 replay_runner.py:36] Average training steps per second: 340.06
I0828 10:53:31.958225 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -462.84
INFO:tensorflow:Starting iteration 23

Steps executed: 265 Episode length: 169 Return: -126.85296993928658
INFO:tensorflow:Average training steps per second: 339.42
I0828 10:53:38.339855 139779140274176 replay_runner.py:36] Average training steps per second: 339.42
I0828 10:53:38.520542 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.19
INFO:tensorflow:Starting iteration 24
I0828 10:53:41.963574 139779140274176 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 353.25

Steps executed: 315 Episode length: 149 Return: -115.71474858216584
I0828 10:53:45.006062 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.12
INFO:tensorflow:Starting iteration 25

Steps executed: 221 Episode length: 123 Return: -88.557733687530944
INFO:tensorflow:Average training steps per second: 342.91
I0828 10:53:51.376018 139779140274176 replay_runner.py:36] Average training steps per second: 342.91
I0828 10:53:51.504352 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.75
INFO:tensorflow:Starting iteration 26

Steps executed: 262 Episode length: 116 Return: -122.63178217964058
INFO:tensorflow:Average training steps per second: 352.51
I0828 10:53:57.741897 139779140274176 replay_runner.py:36] Average training steps per second: 352.51
I0828 10:53:57.871925 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.80
INFO:tensorflow:Starting iteration 27

Steps executed: 238 Episode length: 238 Return: -336.07234493121188
INFO:tensorflow:Average training steps per second: 329.61
I0828 10:54:04.246880 139779140274176 replay_runner.py:36] Average training steps per second: 329.61
I0828 10:54:04.392571 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -336.07
INFO:tensorflow:Starting iteration 28

Steps executed: 273 Episode length: 138 Return: -198.18126755888204
INFO:tensorflow:Average training steps per second: 335.50
I0828 10:54:10.516999 139779140274176 replay_runner.py:36] Average training steps per second: 335.50
I0828 10:54:10.667856 139779140274176 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.89
INFO:tensorflow:Starting iteration 29
I0828 10:54:13.996294 139779140274176 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 351.11

Steps executed: 1000 Episode length: 1000 Return: -71.32720630623633

Done fixed training! Episode length: 1000 Return: -71.32720630623633