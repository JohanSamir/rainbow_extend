Loaded trained dqn in cartpole
Training fixed agent 7, please be patient, may be a while...
I0901 12:15:46.701925 140540456830976 run_experiment.py:549] Creating TrainRunner ...
I0901 12:15:46.709208 140540456830976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:15:46.709468 140540456830976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:15:46.709627 140540456830976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:15:46.709715 140540456830976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:15:46.709847 140540456830976 dqn_agent.py:275] 	 update_period: 4
I0901 12:15:46.709932 140540456830976 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:15:46.710001 140540456830976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:15:46.710091 140540456830976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:15:46.710194 140540456830976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:15:46.710286 140540456830976 dqn_agent.py:280] 	 optimizer: adam
I0901 12:15:46.710340 140540456830976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:15:46.710411 140540456830976 dqn_agent.py:283] 	 seed: 1630498546709145
I0901 12:15:46.712200 140540456830976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:15:46.712330 140540456830976 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:15:46.712422 140540456830976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:15:46.712489 140540456830976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:15:46.712547 140540456830976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:15:46.712601 140540456830976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:15:46.712689 140540456830976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:15:46.712757 140540456830976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:15:46.712835 140540456830976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:15:46.760031 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:15:47.143671 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:15:47.156210 140540456830976 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:15:47.163992 140540456830976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:15:47.164257 140540456830976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:15:47.164408 140540456830976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:15:47.164497 140540456830976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:15:47.164596 140540456830976 dqn_agent.py:275] 	 update_period: 4
I0901 12:15:47.164712 140540456830976 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:15:47.164795 140540456830976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:15:47.164905 140540456830976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:15:47.165020 140540456830976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:15:47.165098 140540456830976 dqn_agent.py:280] 	 optimizer: adam
I0901 12:15:47.165164 140540456830976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:15:47.165238 140540456830976 dqn_agent.py:283] 	 seed: 1630498547163937
I0901 12:15:47.167632 140540456830976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:15:47.167762 140540456830976 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:15:47.167832 140540456830976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:15:47.167913 140540456830976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:15:47.168040 140540456830976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:15:47.168164 140540456830976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:15:47.168233 140540456830976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:15:47.168309 140540456830976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:15:47.168400 140540456830976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:15:47.225700 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:15:47.245606 140540456830976 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:15:47.245946 140540456830976 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 155.16
I0901 12:15:53.691349 140540456830976 replay_runner.py:36] Average training steps per second: 155.16
Steps executed: 206 Episode length: 10 Return: 10.0
I0901 12:15:54.753005 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.36
INFO:tensorflow:Starting iteration 1

Steps executed: 203 Episode length: 8 Return: 8.0.0
INFO:tensorflow:Average training steps per second: 203.25
I0901 12:15:59.848973 140540456830976 replay_runner.py:36] Average training steps per second: 203.25
I0901 12:16:00.005071 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.23
INFO:tensorflow:Starting iteration 2

Steps executed: 240 Episode length: 62 Return: 62.0
INFO:tensorflow:Average training steps per second: 190.00
I0901 12:16:05.460698 140540456830976 replay_runner.py:36] Average training steps per second: 190.00
I0901 12:16:05.631663 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 60.00
INFO:tensorflow:Starting iteration 3

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 196.04
I0901 12:16:10.917437 140540456830976 replay_runner.py:36] Average training steps per second: 196.04
I0901 12:16:11.072687 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 4

Steps executed: 358 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 186.33
I0901 12:16:16.646408 140540456830976 replay_runner.py:36] Average training steps per second: 186.33
I0901 12:16:16.899800 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 179.00
INFO:tensorflow:Starting iteration 5

Steps executed: 162 Episode length: 162 Return: 162.0
INFO:tensorflow:Average training steps per second: 192.54
I0901 12:16:22.289530 140540456830976 replay_runner.py:36] Average training steps per second: 192.54

Steps executed: 318 Episode length: 156 Return: 156.0
INFO:tensorflow:Starting iteration 6

Steps executed: 303 Episode length: 153 Return: 153.0
INFO:tensorflow:Average training steps per second: 186.24
I0901 12:16:28.115214 140540456830976 replay_runner.py:36] Average training steps per second: 186.24
I0901 12:16:28.331979 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 151.50
INFO:tensorflow:Starting iteration 7

Steps executed: 352 Episode length: 163 Return: 163.0
INFO:tensorflow:Average training steps per second: 192.53
I0901 12:16:33.717273 140540456830976 replay_runner.py:36] Average training steps per second: 192.53
I0901 12:16:33.975147 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 176.00
INFO:tensorflow:Starting iteration 8

Steps executed: 278 Episode length: 144 Return: 144.0
INFO:tensorflow:Average training steps per second: 186.16
I0901 12:16:39.550234 140540456830976 replay_runner.py:36] Average training steps per second: 186.16
I0901 12:16:39.745807 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 139.00
INFO:tensorflow:Starting iteration 9

Steps executed: 270 Episode length: 149 Return: 149.0
INFO:tensorflow:Average training steps per second: 187.91
I0901 12:16:45.256704 140540456830976 replay_runner.py:36] Average training steps per second: 187.91
I0901 12:16:45.451594 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 135.00
INFO:tensorflow:Starting iteration 10

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 186.60
I0901 12:16:51.006742 140540456830976 replay_runner.py:36] Average training steps per second: 186.60
I0901 12:16:51.140852 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 11

Steps executed: 368 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 202.45
I0901 12:16:56.268608 140540456830976 replay_runner.py:36] Average training steps per second: 202.45
I0901 12:16:56.554516 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 184.00
INFO:tensorflow:Starting iteration 12

Steps executed: 373 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 186.71
I0901 12:17:02.107350 140540456830976 replay_runner.py:36] Average training steps per second: 186.71
I0901 12:17:02.371752 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 186.50
INFO:tensorflow:Starting iteration 13

Steps executed: 315 Episode length: 170 Return: 170.0
INFO:tensorflow:Average training steps per second: 188.89
I0901 12:17:07.862036 140540456830976 replay_runner.py:36] Average training steps per second: 188.89
I0901 12:17:08.094264 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 157.50
INFO:tensorflow:Starting iteration 14

Steps executed: 318 Episode length: 152 Return: 152.0
INFO:tensorflow:Average training steps per second: 183.23
I0901 12:17:13.732963 140540456830976 replay_runner.py:36] Average training steps per second: 183.23
I0901 12:17:13.957304 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 159.00
INFO:tensorflow:Starting iteration 15

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 189.68
I0901 12:17:19.419014 140540456830976 replay_runner.py:36] Average training steps per second: 189.68
I0901 12:17:19.573235 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 16
I0901 12:17:19.771348 140540456830976 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 187.63
I0901 12:17:25.101501 140540456830976 replay_runner.py:36] Average training steps per second: 187.63
I0901 12:17:25.231869 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 17
I0901 12:17:25.424487 140540456830976 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 191.78
I0901 12:17:30.639007 140540456830976 replay_runner.py:36] Average training steps per second: 191.78
I0901 12:17:30.791357 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 18
I0901 12:17:30.988733 140540456830976 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 189.78
I0901 12:17:36.258303 140540456830976 replay_runner.py:36] Average training steps per second: 189.78
I0901 12:17:36.400987 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 19
I0901 12:17:36.577047 140540456830976 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 188.52
I0901 12:17:41.882003 140540456830976 replay_runner.py:36] Average training steps per second: 188.52
I0901 12:17:42.035192 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 20
I0901 12:17:42.241806 140540456830976 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 191.35
I0901 12:17:47.468346 140540456830976 replay_runner.py:36] Average training steps per second: 191.35
I0901 12:17:47.597739 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 21
I0901 12:17:47.787145 140540456830976 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 187.36
I0901 12:17:53.124820 140540456830976 replay_runner.py:36] Average training steps per second: 187.36
I0901 12:17:53.274878 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 22
I0901 12:17:53.467050 140540456830976 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 190.23
I0901 12:17:58.724646 140540456830976 replay_runner.py:36] Average training steps per second: 190.23
I0901 12:17:58.870794 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 23
I0901 12:17:59.069695 140540456830976 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 184.42
I0901 12:18:04.492623 140540456830976 replay_runner.py:36] Average training steps per second: 184.42
I0901 12:18:04.649058 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 24
I0901 12:18:04.852944 140540456830976 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 190.93
I0901 12:18:10.090764 140540456830976 replay_runner.py:36] Average training steps per second: 190.93
I0901 12:18:10.241731 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 25
I0901 12:18:10.440308 140540456830976 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 185.16
I0901 12:18:15.841607 140540456830976 replay_runner.py:36] Average training steps per second: 185.16
I0901 12:18:15.988476 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26

Steps executed: 292 Episode length: 154 Return: 154.0
INFO:tensorflow:Average training steps per second: 190.70
I0901 12:18:21.431826 140540456830976 replay_runner.py:36] Average training steps per second: 190.70
I0901 12:18:21.654858 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 146.00
INFO:tensorflow:Starting iteration 27
I0901 12:18:21.859207 140540456830976 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 193.68

Steps executed: 200 Episode length: 200 Return: 200.0
I0901 12:18:27.180363 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 28

Steps executed: 176 Episode length: 176 Return: 176.0
INFO:tensorflow:Average training steps per second: 185.29
I0901 12:18:32.780915 140540456830976 replay_runner.py:36] Average training steps per second: 185.29

Steps executed: 376 Episode length: 200 Return: 200.0
INFO:tensorflow:Starting iteration 29

Done fixed training!Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 197.09
I0901 12:18:38.312014 140540456830976 replay_runner.py:36] Average training steps per second: 197.09
I0901 12:18:38.453598 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00