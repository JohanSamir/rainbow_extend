WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0828 00:02:18.510235 140707354712064 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0828 00:02:18.559501 140707354712064 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 00:02:18.560375 140707354712064 dqn_agent.py:272] 	 gamma: 0.990000
I0828 00:02:18.560439 140707354712064 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 00:02:18.560513 140707354712064 dqn_agent.py:274] 	 min_replay_history: 500
I0828 00:02:18.560567 140707354712064 dqn_agent.py:275] 	 update_period: 4
I0828 00:02:18.560622 140707354712064 dqn_agent.py:276] 	 target_update_period: 100
I0828 00:02:18.560672 140707354712064 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 00:02:18.560800 140707354712064 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 00:02:18.560854 140707354712064 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 00:02:18.560923 140707354712064 dqn_agent.py:280] 	 optimizer: adam
I0828 00:02:18.560985 140707354712064 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 00:02:18.561045 140707354712064 dqn_agent.py:283] 	 seed: 1630108938559452
I0828 00:02:18.562400 140707354712064 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 00:02:18.562524 140707354712064 circular_replay_buffer.py:156] 	 observation_shape: (2, 1)
I0828 00:02:18.562601 140707354712064 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 00:02:18.562663 140707354712064 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 00:02:18.562718 140707354712064 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 00:02:18.562775 140707354712064 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 00:02:18.562859 140707354712064 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 00:02:18.562927 140707354712064 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 00:02:18.562983 140707354712064 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 00:02:19.739809 140707354712064 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.010000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 00:02:19.804854 140707354712064 run_experiment.py:516] Beginning training...
I0828 00:02:19.805014 140707354712064 run_experiment.py:447] Starting iteration 0
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
Training agent 2, please be patient, may be a while...
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
W0828 00:02:21.736757 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
error: Choose a correct Normalization Module
Steps executed: 600 Episode length: 600 Return: -600.0
W0828 00:02:24.278436 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:02:24.278822 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00
error: Choose a correct Normalization Moduleurn: -600.0
error: Choose a correct Normalization Module















Steps executed: 124800 Episode length: 600 Return: -600.0
I0828 00:02:56.165148 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00
I0828 00:02:56.202831 140707354712064 run_experiment.py:447] Starting iteration 1


Steps executed: 1043 Episode length: 600 Return: -600.0.0
W0828 00:03:00.111484 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:03:00.111789 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -521.50
















Steps executed: 123000 Episode length: 600 Return: -600.0
I0828 00:03:32.811340 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:03:37.451535 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:03:37.451918 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 118800 Episode length: 600 Return: -600.0
I0828 00:04:10.138180 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 337 Episode length: 337 Return: -337.00.0

Steps executed: 937 Episode length: 600 Return: -600.00.0
W0828 00:04:16.220200 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:04:16.220590 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -512.33
















Steps executed: 118800 Episode length: 600 Return: -600.0
I0828 00:04:48.056301 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00


Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:04:50.402846 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:04:52.657149 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:04:52.657659 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 124200 Episode length: 600 Return: -600.0
I0828 00:05:24.842896 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:05:29.570472 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:05:29.570764 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 118800 Episode length: 600 Return: -600.0

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:06:02.722006 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:06:04.980138 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:06:04.980617 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 123600 Episode length: 600 Return: -600.0
I0828 00:06:37.263429 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:06:41.847760 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:06:41.848110 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 124800 Episode length: 600 Return: -600.0
I0828 00:07:13.091838 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:07:17.669366 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:07:17.669774 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 119400 Episode length: 600 Return: -600.0
I0828 00:07:50.140143 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:07:54.649389 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:07:54.649872 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 123600 Episode length: 600 Return: -600.0
I0828 00:08:25.264183 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:08:30.122241 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:08:30.122673 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 118321 Episode length: 172 Return: -172.0
I0828 00:09:00.750682 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -378.91

Steps executed: 125040 Episode length: 174 Return: -174.0

Steps executed: 600 Episode length: 600 Return: -600.04.0
W0828 00:09:05.511600 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:09:05.511959 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 120000 Episode length: 600 Return: -600.0
I0828 00:09:38.351081 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:09:42.960433 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:09:42.960741 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 119400 Episode length: 600 Return: -600.0
I0828 00:10:14.757212 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00


Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:10:17.103642 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:10:19.348634 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:10:19.348908 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 125400 Episode length: 600 Return: -600.0
I0828 00:10:51.312109 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00
I0828 00:10:51.368193 140707354712064 run_experiment.py:447] Starting iteration 14

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:10:55.968683 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:10:55.969022 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 120600 Episode length: 600 Return: -600.0
I0828 00:11:26.555332 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0

Steps executed: 920 Episode length: 320 Return: -320.00.0
W0828 00:11:32.357632 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:11:32.357925 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -506.67
















Steps executed: 120000 Episode length: 600 Return: -600.0
I0828 00:12:04.879881 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:12:09.440973 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:12:09.441508 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 119400 Episode length: 600 Return: -600.0
I0828 00:12:40.664327 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:12:45.234998 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:12:45.235316 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 124177 Episode length: 600 Return: -600.0
I0828 00:13:17.648302 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -320.66

Steps executed: 125377 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:13:22.154739 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:13:22.155141 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 120000 Episode length: 600 Return: -600.0
I0828 00:13:52.911170 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:13:57.579976 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:13:57.580446 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 118200 Episode length: 600 Return: -600.0
I0828 00:14:27.421697 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:14:32.334327 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:14:32.334693 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 121800 Episode length: 600 Return: -600.0
I0828 00:15:04.652112 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:15:09.233694 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:15:09.234002 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 123000 Episode length: 600 Return: -600.0
I0828 00:15:40.571579 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:15:45.124321 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:15:45.124656 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 125400 Episode length: 600 Return: -600.0
I0828 00:16:17.542632 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00
I0828 00:16:17.609431 140707354712064 run_experiment.py:447] Starting iteration 23

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:16:22.127080 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:16:22.127391 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 123000 Episode length: 600 Return: -600.0
I0828 00:16:52.316636 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:16:56.948098 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:16:56.948420 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00

















Steps executed: 125400 Episode length: 600 Return: -600.0
I0828 00:17:29.777152 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00
I0828 00:17:29.848101 140707354712064 run_experiment.py:447] Starting iteration 25

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:17:34.358126 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:17:34.358563 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 121200 Episode length: 600 Return: -600.0
I0828 00:18:07.185071 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 476 Episode length: 476 Return: -476.00.0
W0828 00:18:11.267742 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:18:11.268008 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -538.00
















Steps executed: 119400 Episode length: 600 Return: -600.0
I0828 00:18:43.611382 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00


Steps executed: 600 Episode length: 600 Return: -600.00.0

Steps executed: 1200 Episode length: 600 Return: -600.0.0
W0828 00:18:48.209520 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:18:48.209820 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00















Steps executed: 120000 Episode length: 600 Return: -600.0
I0828 00:19:19.636113 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00


Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:19:21.983359 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
W0828 00:19:24.233174 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:19:24.233591 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 123600 Episode length: 600 Return: -600.0
I0828 00:19:56.924756 140707354712064 run_experiment.py:428] Average undiscounted return per evaluation episode: -600.00

Steps executed: 125400 Episode length: 600 Return: -600.0

Steps executed: 600 Episode length: 600 Return: -600.00.0
W0828 00:20:01.542091 140707354712064 dqn_agent.py:453] _store_transition function doesn't have episode_end arg.
I0828 00:20:01.542431 140707354712064 run_experiment.py:406] Average undiscounted return per training episode: -600.00
















Steps executed: 122400 Episode length: 600 Return: -600.0

Done training!: 125400 Episode length: 600 Return: -600.0