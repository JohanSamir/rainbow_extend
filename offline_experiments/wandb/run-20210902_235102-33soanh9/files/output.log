Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0902 23:51:09.150997 140310902786048 run_experiment.py:549] Creating TrainRunner ...
I0902 23:51:09.162692 140310902786048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:51:09.162976 140310902786048 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:51:09.163090 140310902786048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:51:09.163172 140310902786048 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:51:09.163286 140310902786048 dqn_agent.py:275] 	 update_period: 4
I0902 23:51:09.163484 140310902786048 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:51:09.163662 140310902786048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:51:09.163813 140310902786048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:51:09.163913 140310902786048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:51:09.164027 140310902786048 dqn_agent.py:280] 	 optimizer: adam
I0902 23:51:09.164151 140310902786048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:51:09.164278 140310902786048 dqn_agent.py:283] 	 seed: 1630626669162613
I0902 23:51:09.167108 140310902786048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:51:09.167350 140310902786048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:51:09.167506 140310902786048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:51:09.167596 140310902786048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:51:09.167717 140310902786048 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:51:09.167819 140310902786048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:51:09.167886 140310902786048 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:51:09.167949 140310902786048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:51:09.168010 140310902786048 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:51:09.210752 140310902786048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:51:09.605856 140310902786048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:51:09.620214 140310902786048 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:51:09.630061 140310902786048 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:51:09.630403 140310902786048 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:51:09.630639 140310902786048 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:51:09.630789 140310902786048 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:51:09.631000 140310902786048 dqn_agent.py:275] 	 update_period: 4
I0902 23:51:09.631165 140310902786048 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:51:09.631309 140310902786048 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:51:09.631460 140310902786048 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:51:09.631703 140310902786048 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:51:09.631894 140310902786048 dqn_agent.py:280] 	 optimizer: adam
I0902 23:51:09.632168 140310902786048 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:51:09.632766 140310902786048 dqn_agent.py:283] 	 seed: 1630626669629988
I0902 23:51:09.663736 140310902786048 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:51:09.664182 140310902786048 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:51:09.664458 140310902786048 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:51:09.664674 140310902786048 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:51:09.665150 140310902786048 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:51:09.665316 140310902786048 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:51:09.665423 140310902786048 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:51:09.665566 140310902786048 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:51:09.665680 140310902786048 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:51:09.697617 140310902786048 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:51:09.722407 140310902786048 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:51:09.722738 140310902786048 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 160.12
I0902 23:51:15.969063 140310902786048 replay_runner.py:36] Average training steps per second: 160.12
I0902 23:51:17.547211 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.64
Steps executed: 213 Episode length: 113 Return: -88.61958431485202
INFO:tensorflow:Starting iteration 1

Steps executed: 250 Episode length: 136 Return: -364.72746888102336
INFO:tensorflow:Average training steps per second: 215.88
I0902 23:51:26.553831 140310902786048 replay_runner.py:36] Average training steps per second: 215.88
I0902 23:51:26.782235 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -335.36
INFO:tensorflow:Starting iteration 2

Steps executed: 550 Episode length: 392 Return: -40.259784513999526
INFO:tensorflow:Average training steps per second: 220.85
I0902 23:51:35.694854 140310902786048 replay_runner.py:36] Average training steps per second: 220.85
I0902 23:51:36.485884 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -165.72
INFO:tensorflow:Starting iteration 3

Steps executed: 95 Episode length: 95 Return: -350.2458089080429526
INFO:tensorflow:Average training steps per second: 223.65

Steps executed: 1056 Episode length: 961 Return: -489.2649402064733
I0902 23:51:49.648812 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -419.76
INFO:tensorflow:Starting iteration 4

Steps executed: 265 Episode length: 158 Return: -469.43289283799023
INFO:tensorflow:Average training steps per second: 238.89
I0902 23:51:58.163642 140310902786048 replay_runner.py:36] Average training steps per second: 238.89
I0902 23:51:58.391711 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -465.11
INFO:tensorflow:Starting iteration 5
I0902 23:52:02.725827 140310902786048 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 224.50

Steps executed: 1000 Episode length: 1000 Return: -111.11864351929063
I0902 23:52:09.641471 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.12
INFO:tensorflow:Starting iteration 6
I0902 23:52:13.985876 140310902786048 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 224.32

Steps executed: 492 Episode length: 492 Return: -391.3262749946813063
I0902 23:52:19.375470 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -391.33
INFO:tensorflow:Starting iteration 7
I0902 23:52:23.698928 140310902786048 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 215.77

Steps executed: 1000 Episode length: 1000 Return: -160.43912310358868
I0902 23:52:30.605323 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.44
INFO:tensorflow:Starting iteration 8
I0902 23:52:34.928979 140310902786048 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 221.86

Steps executed: 1000 Episode length: 1000 Return: -91.292104311789918
I0902 23:52:42.256755 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -91.29
INFO:tensorflow:Starting iteration 9
I0902 23:52:46.614429 140310902786048 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 228.37

Steps executed: 991 Episode length: 991 Return: -164.4925368749064218
I0902 23:52:53.875756 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.49
INFO:tensorflow:Starting iteration 10

Steps executed: 91 Episode length: 91 Return: -450.355816560666964218
INFO:tensorflow:Average training steps per second: 224.39
I0902 23:53:02.634427 140310902786048 replay_runner.py:36] Average training steps per second: 224.39

Steps executed: 1091 Episode length: 1000 Return: -49.561845476006838
INFO:tensorflow:Starting iteration 11

Steps executed: 256 Episode length: 175 Return: -347.8472164691358838
INFO:tensorflow:Average training steps per second: 226.22
I0902 23:53:14.154242 140310902786048 replay_runner.py:36] Average training steps per second: 226.22
I0902 23:53:14.401741 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -440.09
INFO:tensorflow:Starting iteration 12
I0902 23:53:18.774174 140310902786048 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 225.13

Steps executed: 285 Episode length: 285 Return: -132.2526943741487538
I0902 23:53:23.574554 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.25
INFO:tensorflow:Starting iteration 13
I0902 23:53:27.825596 140310902786048 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 222.88

Steps executed: 1000 Episode length: 1000 Return: -126.67559095823849
I0902 23:53:34.816865 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.68
INFO:tensorflow:Starting iteration 14

Steps executed: 206 Episode length: 101 Return: -159.1685849540399149
INFO:tensorflow:Average training steps per second: 216.90
I0902 23:53:43.742142 140310902786048 replay_runner.py:36] Average training steps per second: 216.90
I0902 23:53:43.943118 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.07
INFO:tensorflow:Starting iteration 15

Steps executed: 172 Episode length: 119 Return: -330.9285739899216149
INFO:tensorflow:Average training steps per second: 224.73

Steps executed: 614 Episode length: 442 Return: -240.1824959130113149
I0902 23:53:53.494644 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -235.69
INFO:tensorflow:Starting iteration 16

Steps executed: 332 Episode length: 140 Return: -41.82179933670053449
INFO:tensorflow:Average training steps per second: 219.03
I0902 23:54:02.388092 140310902786048 replay_runner.py:36] Average training steps per second: 219.03
I0902 23:54:02.692013 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.77
INFO:tensorflow:Starting iteration 17

Steps executed: 238 Episode length: 62 Return: -144.23852207220179649
INFO:tensorflow:Average training steps per second: 219.73
I0902 23:54:11.596863 140310902786048 replay_runner.py:36] Average training steps per second: 219.73
I0902 23:54:11.811461 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.39
INFO:tensorflow:Starting iteration 18

Steps executed: 237 Episode length: 53 Return: -139.43991867051847349
INFO:tensorflow:Average training steps per second: 222.40
I0902 23:54:20.626705 140310902786048 replay_runner.py:36] Average training steps per second: 222.40
I0902 23:54:20.857091 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.14
INFO:tensorflow:Starting iteration 19

Steps executed: 288 Episode length: 288 Return: -256.6987876228289349
INFO:tensorflow:Average training steps per second: 219.69
I0902 23:54:29.831061 140310902786048 replay_runner.py:36] Average training steps per second: 219.69
I0902 23:54:30.217600 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.70
INFO:tensorflow:Starting iteration 20

Steps executed: 186 Episode length: 186 Return: -86.75471058125976349
INFO:tensorflow:Average training steps per second: 225.16
I0902 23:54:39.003907 140310902786048 replay_runner.py:36] Average training steps per second: 225.16

Steps executed: 359 Episode length: 173 Return: -158.5514161127358349
INFO:tensorflow:Starting iteration 21

Steps executed: 254 Episode length: 115 Return: -287.5072721397671749
INFO:tensorflow:Average training steps per second: 225.80
I0902 23:54:48.097218 140310902786048 replay_runner.py:36] Average training steps per second: 225.80
I0902 23:54:48.303893 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -219.31
INFO:tensorflow:Starting iteration 22

Steps executed: 216 Episode length: 76 Return: -664.80506003273113749
INFO:tensorflow:Average training steps per second: 225.07
I0902 23:54:57.119724 140310902786048 replay_runner.py:36] Average training steps per second: 225.07
I0902 23:54:57.326164 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -459.30
INFO:tensorflow:Starting iteration 23

Steps executed: 365 Episode length: 202 Return: -184.5838319670803649
INFO:tensorflow:Average training steps per second: 221.18
I0902 23:55:06.147567 140310902786048 replay_runner.py:36] Average training steps per second: 221.18
I0902 23:55:06.492457 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.00
INFO:tensorflow:Starting iteration 24

Steps executed: 204 Episode length: 54 Return: -372.73465635197563649
INFO:tensorflow:Average training steps per second: 224.58
I0902 23:55:15.200330 140310902786048 replay_runner.py:36] Average training steps per second: 224.58
I0902 23:55:15.371109 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -429.88
INFO:tensorflow:Starting iteration 25

Steps executed: 203 Episode length: 62 Return: -528.36580282366295349
INFO:tensorflow:Average training steps per second: 221.01
I0902 23:55:24.255701 140310902786048 replay_runner.py:36] Average training steps per second: 221.01
I0902 23:55:24.443776 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.74
INFO:tensorflow:Starting iteration 26

Steps executed: 238 Episode length: 65 Return: -560.80791576887015349
INFO:tensorflow:Average training steps per second: 223.06
I0902 23:55:33.326710 140310902786048 replay_runner.py:36] Average training steps per second: 223.06
I0902 23:55:33.540712 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -509.86
INFO:tensorflow:Starting iteration 27

Steps executed: 245 Episode length: 57 Return: -428.24366745085973349
INFO:tensorflow:Average training steps per second: 229.47
I0902 23:55:42.301734 140310902786048 replay_runner.py:36] Average training steps per second: 229.47
I0902 23:55:42.515631 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -510.57
INFO:tensorflow:Starting iteration 28

Steps executed: 225 Episode length: 68 Return: -531.45351719483385349
INFO:tensorflow:Average training steps per second: 235.14
I0902 23:55:51.056521 140310902786048 replay_runner.py:36] Average training steps per second: 235.14
I0902 23:55:51.248383 140310902786048 run_experiment.py:428] Average undiscounted return per evaluation episode: -588.75
INFO:tensorflow:Starting iteration 29

Steps executed: 213 Episode length: 83 Return: -741.48102470928175349
INFO:tensorflow:Average training steps per second: 225.99
I0902 23:56:00.072764 140310902786048 replay_runner.py:36] Average training steps per second: 225.99

Done fixed training!Episode length: 83 Return: -741.48102470928175349