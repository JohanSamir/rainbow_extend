I0901 12:29:58.963048 140460307478528 run_experiment.py:549] Creating TrainRunner ...
I0901 12:29:58.975500 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:29:58.975857 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:29:58.976000 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:29:58.976389 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:29:58.976584 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 12:29:58.976746 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:29:58.977214 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:29:58.977355 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:29:58.977477 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:29:58.977614 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 12:29:58.977740 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:29:58.977844 140460307478528 dqn_agent.py:283] 	 seed: 1630499398975438
I0901 12:29:58.980669 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:29:58.980827 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:29:58.980920 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:29:58.981044 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:29:58.981162 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:29:58.981262 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:29:58.981423 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:29:58.981562 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:29:58.981653 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:29:59.193472 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:29:59.657995 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:29:59.672235 140460307478528 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:29:59.682002 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:29:59.682308 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:29:59.682486 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:29:59.682641 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:29:59.682824 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 12:29:59.682957 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:29:59.683086 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:29:59.683201 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:29:59.683329 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:29:59.683478 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 12:29:59.683613 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:29:59.683738 140460307478528 dqn_agent.py:283] 	 seed: 1630499399681931
I0901 12:29:59.686011 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:29:59.686163 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:29:59.686243 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:29:59.686310 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:29:59.686367 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:29:59.686441 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:29:59.686651 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:29:59.686907 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:29:59.687034 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:29:59.722310 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:29:59.746856 140460307478528 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:29:59.747127 140460307478528 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 161.09
I0901 12:30:05.954965 140460307478528 replay_runner.py:36] Average training steps per second: 161.09
I0901 12:30:07.224805 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -347.72
Steps executed: 251 Episode length: 89 Return: -702.5245378149567
INFO:tensorflow:Starting iteration 1
I0901 12:30:11.502196 140460307478528 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 226.65
I0901 12:30:15.914781 140460307478528 replay_runner.py:36] Average training steps per second: 226.65

Steps executed: 241 Episode length: 241 Return: -13.230762507371992
INFO:tensorflow:Starting iteration 2

Steps executed: 293 Episode length: 161 Return: -272.28016944807007
INFO:tensorflow:Average training steps per second: 222.02
I0901 12:30:25.037946 140460307478528 replay_runner.py:36] Average training steps per second: 222.02
I0901 12:30:25.326998 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -312.14
INFO:tensorflow:Starting iteration 3

Steps executed: 219 Episode length: 127 Return: -9.8898476031534707
INFO:tensorflow:Average training steps per second: 220.33
I0901 12:30:34.179048 140460307478528 replay_runner.py:36] Average training steps per second: 220.33
I0901 12:30:34.365675 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.57
INFO:tensorflow:Starting iteration 4

Steps executed: 266 Episode length: 77 Return: -731.294083543861847
INFO:tensorflow:Average training steps per second: 223.24
I0901 12:30:43.167222 140460307478528 replay_runner.py:36] Average training steps per second: 223.24
I0901 12:30:43.401627 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -493.71
INFO:tensorflow:Starting iteration 5

Steps executed: 281 Episode length: 151 Return: -8.8238320830344327
INFO:tensorflow:Average training steps per second: 237.16
I0901 12:30:52.046362 140460307478528 replay_runner.py:36] Average training steps per second: 237.16
I0901 12:30:52.288327 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -26.63
INFO:tensorflow:Starting iteration 6

Steps executed: 278 Episode length: 87 Return: -682.303609806707403
INFO:tensorflow:Average training steps per second: 236.22
I0901 12:31:00.852962 140460307478528 replay_runner.py:36] Average training steps per second: 236.22
I0901 12:31:01.083023 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -558.37
INFO:tensorflow:Starting iteration 7

Steps executed: 303 Episode length: 114 Return: -535.71151647944573
INFO:tensorflow:Average training steps per second: 232.35
I0901 12:31:09.848428 140460307478528 replay_runner.py:36] Average training steps per second: 232.35
I0901 12:31:10.159689 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -583.15
INFO:tensorflow:Starting iteration 8
I0901 12:31:14.558720 140460307478528 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 229.48

Steps executed: 309 Episode length: 110 Return: -263.55805616051913
I0901 12:31:19.205948 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -251.35
INFO:tensorflow:Starting iteration 9

Steps executed: 207 Episode length: 117 Return: -13.666657197253983
INFO:tensorflow:Average training steps per second: 234.82
I0901 12:31:27.784777 140460307478528 replay_runner.py:36] Average training steps per second: 234.82
I0901 12:31:27.970161 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -353.16
INFO:tensorflow:Starting iteration 10

Steps executed: 215 Episode length: 119 Return: 4.54468418355175283
INFO:tensorflow:Average training steps per second: 234.63
I0901 12:31:36.633063 140460307478528 replay_runner.py:36] Average training steps per second: 234.63
I0901 12:31:36.803288 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.19
INFO:tensorflow:Starting iteration 11

Steps executed: 242 Episode length: 85 Return: -63.7227407182148343
INFO:tensorflow:Average training steps per second: 233.16
I0901 12:31:45.505480 140460307478528 replay_runner.py:36] Average training steps per second: 233.16
I0901 12:31:45.696395 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.37
INFO:tensorflow:Starting iteration 12

Steps executed: 264 Episode length: 90 Return: -111.930189151757743
INFO:tensorflow:Average training steps per second: 228.80
I0901 12:31:54.467092 140460307478528 replay_runner.py:36] Average training steps per second: 228.80
I0901 12:31:54.672676 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -238.56
INFO:tensorflow:Starting iteration 13

Steps executed: 206 Episode length: 85 Return: -325.986727075530568
INFO:tensorflow:Average training steps per second: 224.42
I0901 12:32:03.492432 140460307478528 replay_runner.py:36] Average training steps per second: 224.42
I0901 12:32:03.666082 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.75
INFO:tensorflow:Starting iteration 14

Steps executed: 282 Episode length: 115 Return: -173.61974544245356
INFO:tensorflow:Average training steps per second: 222.82
I0901 12:32:12.559725 140460307478528 replay_runner.py:36] Average training steps per second: 222.82
I0901 12:32:12.805243 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -229.58
INFO:tensorflow:Starting iteration 15

Steps executed: 278 Episode length: 82 Return: -181.627261259573376
INFO:tensorflow:Average training steps per second: 228.34
I0901 12:32:21.601639 140460307478528 replay_runner.py:36] Average training steps per second: 228.34
I0901 12:32:21.806915 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.33
INFO:tensorflow:Starting iteration 16

Steps executed: 271 Episode length: 90 Return: -261.035193375430256
INFO:tensorflow:Average training steps per second: 220.43
I0901 12:32:30.720546 140460307478528 replay_runner.py:36] Average training steps per second: 220.43
I0901 12:32:30.930704 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -240.16
INFO:tensorflow:Starting iteration 17

Steps executed: 220 Episode length: 78 Return: -310.075661647886256
INFO:tensorflow:Average training steps per second: 228.34
I0901 12:32:39.718652 140460307478528 replay_runner.py:36] Average training steps per second: 228.34
I0901 12:32:39.879703 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.00
INFO:tensorflow:Starting iteration 18

Steps executed: 215 Episode length: 116 Return: -297.91017237242016
INFO:tensorflow:Average training steps per second: 222.75
I0901 12:32:48.816800 140460307478528 replay_runner.py:36] Average training steps per second: 222.75
I0901 12:32:49.013331 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.27
INFO:tensorflow:Starting iteration 19

Steps executed: 255 Episode length: 59 Return: -115.413233176146636
INFO:tensorflow:Average training steps per second: 220.99
I0901 12:32:57.999280 140460307478528 replay_runner.py:36] Average training steps per second: 220.99
I0901 12:32:58.183832 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.44
INFO:tensorflow:Starting iteration 20
I0901 12:33:02.521203 140460307478528 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 226.29
I0901 12:33:06.941018 140460307478528 replay_runner.py:36] Average training steps per second: 226.29

Steps executed: 282 Episode length: 104 Return: -666.08781788928736
INFO:tensorflow:Starting iteration 21

Steps executed: 287 Episode length: 91 Return: -314.275597151552316
INFO:tensorflow:Average training steps per second: 223.67
I0901 12:33:16.185502 140460307478528 replay_runner.py:36] Average training steps per second: 223.67
I0901 12:33:16.473412 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.73
INFO:tensorflow:Starting iteration 22

Steps executed: 220 Episode length: 68 Return: -289.674919712664616
INFO:tensorflow:Average training steps per second: 227.49
I0901 12:33:25.319216 140460307478528 replay_runner.py:36] Average training steps per second: 227.49
I0901 12:33:25.491071 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.08
INFO:tensorflow:Starting iteration 23

Steps executed: 322 Episode length: 145 Return: -312.79208141394247
INFO:tensorflow:Average training steps per second: 224.53
I0901 12:33:34.368289 140460307478528 replay_runner.py:36] Average training steps per second: 224.53
I0901 12:33:34.678006 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -343.76
INFO:tensorflow:Starting iteration 24

Steps executed: 219 Episode length: 108 Return: -318.84186733600023
INFO:tensorflow:Average training steps per second: 227.67
I0901 12:33:43.500054 140460307478528 replay_runner.py:36] Average training steps per second: 227.67
I0901 12:33:43.694034 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -287.14
INFO:tensorflow:Starting iteration 25

Steps executed: 206 Episode length: 67 Return: -301.268553377573653
INFO:tensorflow:Average training steps per second: 235.30
I0901 12:33:52.293047 140460307478528 replay_runner.py:36] Average training steps per second: 235.30
I0901 12:33:52.463746 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.58
INFO:tensorflow:Starting iteration 26
I0901 12:33:56.844432 140460307478528 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 231.95

Steps executed: 265 Episode length: 68 Return: -553.776823151532853
I0901 12:34:01.357100 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -440.46
INFO:tensorflow:Starting iteration 27

Steps executed: 274 Episode length: 138 Return: -296.01326213745228
INFO:tensorflow:Average training steps per second: 224.32
I0901 12:34:10.027976 140460307478528 replay_runner.py:36] Average training steps per second: 224.32
I0901 12:34:10.260422 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.43
INFO:tensorflow:Starting iteration 28

Steps executed: 235 Episode length: 56 Return: -34.5956547196500144
INFO:tensorflow:Average training steps per second: 224.72
I0901 12:34:19.090294 140460307478528 replay_runner.py:36] Average training steps per second: 224.72
I0901 12:34:19.287249 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.24
INFO:tensorflow:Starting iteration 29

Steps executed: 207 Episode length: 66 Return: -521.566215498294544
INFO:tensorflow:Average training steps per second: 222.16
I0901 12:34:28.213975 140460307478528 replay_runner.py:36] Average training steps per second: 222.16

Done fixed training!Episode length: 66 Return: -521.566215498294544