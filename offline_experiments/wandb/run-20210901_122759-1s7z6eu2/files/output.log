Loaded trained dqn in cartpole
Training fixed agent 7, please be patient, may be a while...
I0901 12:28:05.936885 140540456830976 run_experiment.py:549] Creating TrainRunner ...
I0901 12:28:05.951897 140540456830976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:28:05.952203 140540456830976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:28:05.952348 140540456830976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:28:05.952465 140540456830976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:28:05.952578 140540456830976 dqn_agent.py:275] 	 update_period: 4
I0901 12:28:05.952734 140540456830976 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:28:05.952940 140540456830976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:28:05.953098 140540456830976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:28:05.953215 140540456830976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:28:05.953328 140540456830976 dqn_agent.py:280] 	 optimizer: adam
I0901 12:28:05.953478 140540456830976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:28:05.953594 140540456830976 dqn_agent.py:283] 	 seed: 1630499285951831
I0901 12:28:05.956939 140540456830976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:28:05.957187 140540456830976 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:28:05.957337 140540456830976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:28:05.957906 140540456830976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:28:05.958220 140540456830976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:28:05.958472 140540456830976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:28:05.958606 140540456830976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:28:05.958706 140540456830976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:28:05.958999 140540456830976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:28:06.050390 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:28:06.612193 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:28:06.627169 140540456830976 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:28:06.640033 140540456830976 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:28:06.640477 140540456830976 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:28:06.640670 140540456830976 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:28:06.640768 140540456830976 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:28:06.640852 140540456830976 dqn_agent.py:275] 	 update_period: 4
I0901 12:28:06.640948 140540456830976 dqn_agent.py:276] 	 target_update_period: 100
I0901 12:28:06.641121 140540456830976 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:28:06.641270 140540456830976 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:28:06.641536 140540456830976 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:28:06.641699 140540456830976 dqn_agent.py:280] 	 optimizer: adam
I0901 12:28:06.641830 140540456830976 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:28:06.642100 140540456830976 dqn_agent.py:283] 	 seed: 1630499286639963
I0901 12:28:06.645136 140540456830976 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:28:06.645350 140540456830976 circular_replay_buffer.py:156] 	 observation_shape: (4, 1)
I0901 12:28:06.645469 140540456830976 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:28:06.645576 140540456830976 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:28:06.645656 140540456830976 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:28:06.645794 140540456830976 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:28:06.645943 140540456830976 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:28:06.646042 140540456830976 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:28:06.646162 140540456830976 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:28:06.683296 140540456830976 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:28:06.709450 140540456830976 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:28:06.709804 140540456830976 replay_runner.py:41] Starting iteration 0
Steps executed: 207 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 140.83
I0901 12:28:13.810751 140540456830976 replay_runner.py:36] Average training steps per second: 140.83
I0901 12:28:15.002486 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.41
INFO:tensorflow:Starting iteration 1

Steps executed: 203 Episode length: 12 Return: 12.0
INFO:tensorflow:Average training steps per second: 198.21
I0901 12:28:20.241287 140540456830976 replay_runner.py:36] Average training steps per second: 198.21
I0901 12:28:20.382339 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 10.68
INFO:tensorflow:Starting iteration 2

Steps executed: 205 Episode length: 10 Return: 10.0
INFO:tensorflow:Average training steps per second: 188.50
I0901 12:28:25.872287 140540456830976 replay_runner.py:36] Average training steps per second: 188.50
I0901 12:28:26.011657 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 9.76
INFO:tensorflow:Starting iteration 3

Steps executed: 216 Episode length: 75 Return: 75.0
INFO:tensorflow:Average training steps per second: 205.12
I0901 12:28:31.062944 140540456830976 replay_runner.py:36] Average training steps per second: 205.12
I0901 12:28:31.205785 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 72.00
INFO:tensorflow:Starting iteration 4

Steps executed: 244 Episode length: 54 Return: 54.0
INFO:tensorflow:Average training steps per second: 196.49
I0901 12:28:36.475030 140540456830976 replay_runner.py:36] Average training steps per second: 196.49
I0901 12:28:36.638675 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 61.00
INFO:tensorflow:Starting iteration 5

Steps executed: 202 Episode length: 53 Return: 53.0
INFO:tensorflow:Average training steps per second: 200.99
I0901 12:28:41.866451 140540456830976 replay_runner.py:36] Average training steps per second: 200.99
I0901 12:28:42.002772 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 50.50
INFO:tensorflow:Starting iteration 6

Steps executed: 222 Episode length: 40 Return: 40.0
INFO:tensorflow:Average training steps per second: 192.02
I0901 12:28:47.461272 140540456830976 replay_runner.py:36] Average training steps per second: 192.02
I0901 12:28:47.619113 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 37.00
INFO:tensorflow:Starting iteration 7

Steps executed: 204 Episode length: 37 Return: 37.0
INFO:tensorflow:Average training steps per second: 197.44
I0901 12:28:52.879071 140540456830976 replay_runner.py:36] Average training steps per second: 197.44
I0901 12:28:53.030063 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 34.00
INFO:tensorflow:Starting iteration 8

Steps executed: 207 Episode length: 34 Return: 34.0
INFO:tensorflow:Average training steps per second: 199.22
I0901 12:28:58.252479 140540456830976 replay_runner.py:36] Average training steps per second: 199.22
I0901 12:28:58.399599 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 34.50
INFO:tensorflow:Starting iteration 9

Steps executed: 201 Episode length: 22 Return: 22.0
INFO:tensorflow:Average training steps per second: 190.70
I0901 12:29:03.843622 140540456830976 replay_runner.py:36] Average training steps per second: 190.70
I0901 12:29:03.991214 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 25.12
INFO:tensorflow:Starting iteration 10

Steps executed: 207 Episode length: 24 Return: 24.0
INFO:tensorflow:Average training steps per second: 194.35
I0901 12:29:09.334529 140540456830976 replay_runner.py:36] Average training steps per second: 194.35
I0901 12:29:09.477213 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 20.70
INFO:tensorflow:Starting iteration 11

Steps executed: 235 Episode length: 47 Return: 47.0
INFO:tensorflow:Average training steps per second: 194.10
I0901 12:29:14.826225 140540456830976 replay_runner.py:36] Average training steps per second: 194.10
I0901 12:29:14.997710 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 47.00
INFO:tensorflow:Starting iteration 12

Steps executed: 271 Episode length: 74 Return: 74.0
INFO:tensorflow:Average training steps per second: 191.80
I0901 12:29:20.383045 140540456830976 replay_runner.py:36] Average training steps per second: 191.80
I0901 12:29:20.587696 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 67.75
INFO:tensorflow:Starting iteration 13
I0901 12:29:20.791939 140540456830976 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 196.23
I0901 12:29:25.888481 140540456830976 replay_runner.py:36] Average training steps per second: 196.23

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Starting iteration 14
I0901 12:29:26.225311 140540456830976 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 188.47
I0901 12:29:31.531517 140540456830976 replay_runner.py:36] Average training steps per second: 188.47
I0901 12:29:31.674350 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 15

Steps executed: 276 Episode length: 146 Return: 146.0
INFO:tensorflow:Average training steps per second: 191.17
I0901 12:29:37.096560 140540456830976 replay_runner.py:36] Average training steps per second: 191.17
I0901 12:29:37.286490 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 138.00
INFO:tensorflow:Starting iteration 16

Steps executed: 310 Episode length: 155 Return: 155.0
INFO:tensorflow:Average training steps per second: 193.10
I0901 12:29:42.658764 140540456830976 replay_runner.py:36] Average training steps per second: 193.10
I0901 12:29:42.872427 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 155.00
INFO:tensorflow:Starting iteration 17

Steps executed: 320 Episode length: 161 Return: 161.0
INFO:tensorflow:Average training steps per second: 189.34
I0901 12:29:48.346393 140540456830976 replay_runner.py:36] Average training steps per second: 189.34
I0901 12:29:48.579078 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 160.00
INFO:tensorflow:Starting iteration 18

Steps executed: 333 Episode length: 172 Return: 172.0
INFO:tensorflow:Average training steps per second: 198.58
I0901 12:29:53.811073 140540456830976 replay_runner.py:36] Average training steps per second: 198.58
I0901 12:29:54.045023 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 166.50
INFO:tensorflow:Starting iteration 19

Steps executed: 323 Episode length: 165 Return: 165.0
INFO:tensorflow:Average training steps per second: 196.29
I0901 12:29:59.335016 140540456830976 replay_runner.py:36] Average training steps per second: 196.29
I0901 12:29:59.563134 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 161.50
INFO:tensorflow:Starting iteration 20

Steps executed: 314 Episode length: 162 Return: 162.0
INFO:tensorflow:Average training steps per second: 200.61
I0901 12:30:04.739215 140540456830976 replay_runner.py:36] Average training steps per second: 200.61
I0901 12:30:04.955522 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 157.00
INFO:tensorflow:Starting iteration 21
I0901 12:30:05.137956 140540456830976 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 195.55
I0901 12:30:10.252218 140540456830976 replay_runner.py:36] Average training steps per second: 195.55

Steps executed: 292 Episode length: 150 Return: 150.0
INFO:tensorflow:Starting iteration 22

Steps executed: 365 Episode length: 183 Return: 183.0
INFO:tensorflow:Average training steps per second: 195.37
I0901 12:30:15.756952 140540456830976 replay_runner.py:36] Average training steps per second: 195.37
I0901 12:30:16.004877 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 182.50
INFO:tensorflow:Starting iteration 23

Steps executed: 200 Episode length: 200 Return: 200.0
INFO:tensorflow:Average training steps per second: 197.50
I0901 12:30:21.265375 140540456830976 replay_runner.py:36] Average training steps per second: 197.50
I0901 12:30:21.399954 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 24
I0901 12:30:21.586274 140540456830976 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 190.83
I0901 12:30:26.827101 140540456830976 replay_runner.py:36] Average training steps per second: 190.83
I0901 12:30:26.964443 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 25
I0901 12:30:27.157762 140540456830976 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 196.63
I0901 12:30:32.243770 140540456830976 replay_runner.py:36] Average training steps per second: 196.63
I0901 12:30:32.388241 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 26
I0901 12:30:32.581581 140540456830976 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 191.61
I0901 12:30:37.800938 140540456830976 replay_runner.py:36] Average training steps per second: 191.61
I0901 12:30:37.942903 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 27
I0901 12:30:38.123123 140540456830976 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 191.19
I0901 12:30:43.353967 140540456830976 replay_runner.py:36] Average training steps per second: 191.19
I0901 12:30:43.497954 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 28
I0901 12:30:43.696480 140540456830976 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 199.47
I0901 12:30:48.710500 140540456830976 replay_runner.py:36] Average training steps per second: 199.47
I0901 12:30:48.837701 140540456830976 run_experiment.py:428] Average undiscounted return per evaluation episode: 200.00
INFO:tensorflow:Starting iteration 29
I0901 12:30:49.026650 140540456830976 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 198.75
I0901 12:30:54.058512 140540456830976 replay_runner.py:36] Average training steps per second: 198.75

Done fixed training!Episode length: 200 Return: 200.0