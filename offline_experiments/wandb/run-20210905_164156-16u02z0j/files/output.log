I0905 16:42:02.692551 140334269278208 run_experiment.py:549] Creating TrainRunner ...
I0905 16:42:02.702477 140334269278208 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:42:02.702656 140334269278208 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:42:02.702734 140334269278208 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:42:02.702798 140334269278208 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:42:02.702854 140334269278208 dqn_agent.py:275] 	 update_period: 4
I0905 16:42:02.702939 140334269278208 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:42:02.703124 140334269278208 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:42:02.703253 140334269278208 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:42:02.703469 140334269278208 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:42:02.703707 140334269278208 dqn_agent.py:280] 	 optimizer: adam
I0905 16:42:02.703803 140334269278208 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:42:02.704030 140334269278208 dqn_agent.py:283] 	 seed: 1630860122702426
I0905 16:42:02.706312 140334269278208 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:42:02.706434 140334269278208 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:42:02.706537 140334269278208 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:42:02.706684 140334269278208 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:42:02.706800 140334269278208 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:42:02.706867 140334269278208 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:42:02.706962 140334269278208 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:42:02.707040 140334269278208 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:42:02.707120 140334269278208 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:42:03.993058 140334269278208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0905 16:42:04.619898 140334269278208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:42:04.627815 140334269278208 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:42:04.633126 140334269278208 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:42:04.633254 140334269278208 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:42:04.633328 140334269278208 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:42:04.633390 140334269278208 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:42:04.633446 140334269278208 dqn_agent.py:275] 	 update_period: 4
I0905 16:42:04.633522 140334269278208 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:42:04.633654 140334269278208 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:42:04.633734 140334269278208 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:42:04.633806 140334269278208 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:42:04.633875 140334269278208 dqn_agent.py:280] 	 optimizer: adam
I0905 16:42:04.633942 140334269278208 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:42:04.634003 140334269278208 dqn_agent.py:283] 	 seed: 1630860124633097
I0905 16:42:04.635343 140334269278208 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:42:04.635442 140334269278208 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:42:04.635506 140334269278208 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:42:04.635571 140334269278208 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:42:04.635620 140334269278208 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:42:04.635693 140334269278208 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:42:04.635753 140334269278208 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:42:04.635820 140334269278208 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:42:04.635887 140334269278208 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:42:04.653601 140334269278208 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:42:04.667569 140334269278208 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:42:04.667688 140334269278208 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 192.29
I0905 16:42:09.868466 140334269278208 replay_runner.py:36] Average training steps per second: 192.29
Steps executed: 304 Episode length: 162 Return: -269.65088886249373
I0905 16:42:10.862137 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -239.71
INFO:tensorflow:Starting iteration 1
I0905 16:42:14.526710 140334269278208 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 267.25

Steps executed: 261 Episode length: 120 Return: -390.06878580091313
I0905 16:42:18.541463 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.25
INFO:tensorflow:Starting iteration 2

Steps executed: 284 Episode length: 225 Return: -347.73401415417393
INFO:tensorflow:Average training steps per second: 245.03
I0905 16:42:26.704778 140334269278208 replay_runner.py:36] Average training steps per second: 245.03
I0905 16:42:27.054276 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.68
INFO:tensorflow:Starting iteration 3
I0905 16:42:31.230202 140334269278208 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 213.24

Steps executed: 1000 Episode length: 1000 Return: -121.17231807631877
I0905 16:42:39.423060 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.17
INFO:tensorflow:Starting iteration 4
I0905 16:42:43.402393 140334269278208 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 228.18

Steps executed: 1000 Episode length: 1000 Return: -129.35504634434247
I0905 16:42:50.088443 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.36
INFO:tensorflow:Starting iteration 5
I0905 16:42:53.977155 140334269278208 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 233.82

Steps executed: 1000 Episode length: 1000 Return: -215.71135005571277
I0905 16:43:00.895153 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.71
INFO:tensorflow:Starting iteration 6
I0905 16:43:04.994930 140334269278208 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 251.68

Steps executed: 1000 Episode length: 1000 Return: -1719.8447875898835
I0905 16:43:11.685160 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -1719.84
INFO:tensorflow:Starting iteration 7
I0905 16:43:15.916541 140334269278208 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 245.35

Steps executed: 689 Episode length: 689 Return: -526.3528352768898835
I0905 16:43:21.857198 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -526.35
INFO:tensorflow:Starting iteration 8
I0905 16:43:26.026498 140334269278208 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 242.20

Steps executed: 1000 Episode length: 1000 Return: -29.931263225221095
I0905 16:43:33.038781 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -29.93
INFO:tensorflow:Starting iteration 9

Steps executed: 449 Episode length: 449 Return: -571.8756120739031095
INFO:tensorflow:Average training steps per second: 237.45
I0905 16:43:41.262388 140334269278208 replay_runner.py:36] Average training steps per second: 237.45
I0905 16:43:42.084374 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -571.88
INFO:tensorflow:Starting iteration 10
I0905 16:43:46.090767 140334269278208 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 227.60

Steps executed: 1000 Episode length: 1000 Return: -115.02566566551084
I0905 16:43:52.475482 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.03
INFO:tensorflow:Starting iteration 11
I0905 16:43:56.587063 140334269278208 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 246.39

Steps executed: 492 Episode length: 492 Return: -250.8303948721666084
I0905 16:44:01.343412 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -250.83
INFO:tensorflow:Starting iteration 12

Steps executed: 364 Episode length: 364 Return: -262.7021228890046084
INFO:tensorflow:Average training steps per second: 235.03
I0905 16:44:09.660022 140334269278208 replay_runner.py:36] Average training steps per second: 235.03
I0905 16:44:10.219448 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -262.70
INFO:tensorflow:Starting iteration 13
I0905 16:44:13.998912 140334269278208 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 226.59

Steps executed: 1000 Episode length: 1000 Return: -211.70679643893135
I0905 16:44:20.485966 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.71
INFO:tensorflow:Starting iteration 14
I0905 16:44:24.258962 140334269278208 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 220.70

Steps executed: 1000 Episode length: 1000 Return: -96.066255219674225
I0905 16:44:30.760301 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.07
INFO:tensorflow:Starting iteration 15
I0905 16:44:34.345410 140334269278208 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 224.48

Steps executed: 1000 Episode length: 1000 Return: -109.85448918524497
I0905 16:44:41.449632 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.85
INFO:tensorflow:Starting iteration 16
I0905 16:44:45.405167 140334269278208 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 230.40

Steps executed: 1000 Episode length: 1000 Return: -176.60617162835967
I0905 16:44:52.495818 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.61
INFO:tensorflow:Starting iteration 17
I0905 16:44:56.718739 140334269278208 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 244.77

Steps executed: 1000 Episode length: 1000 Return: -151.37405828436266
I0905 16:45:03.220857 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -151.37
INFO:tensorflow:Starting iteration 18

Steps executed: 484 Episode length: 484 Return: -730.9033003155894266
INFO:tensorflow:Average training steps per second: 247.14
I0905 16:45:11.484630 140334269278208 replay_runner.py:36] Average training steps per second: 247.14
I0905 16:45:12.163046 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -730.90
INFO:tensorflow:Starting iteration 19
I0905 16:45:16.316780 140334269278208 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 242.20

Steps executed: 440 Episode length: 440 Return: -226.1412503797184266
I0905 16:45:21.310998 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -226.14
INFO:tensorflow:Starting iteration 20

Steps executed: 382 Episode length: 382 Return: 222.23945088372884266
INFO:tensorflow:Average training steps per second: 258.45
I0905 16:45:29.339912 140334269278208 replay_runner.py:36] Average training steps per second: 258.45
I0905 16:45:29.809989 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: 222.24
INFO:tensorflow:Starting iteration 21

Steps executed: 245 Episode length: 56 Return: -36.329025351689827466
INFO:tensorflow:Average training steps per second: 235.00
I0905 16:45:38.207216 140334269278208 replay_runner.py:36] Average training steps per second: 235.00
I0905 16:45:38.484110 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -49.64
INFO:tensorflow:Starting iteration 22
I0905 16:45:42.615020 140334269278208 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 234.57

Steps executed: 649 Episode length: 649 Return: 162.41773194121131466
I0905 16:45:48.857703 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: 162.42
INFO:tensorflow:Starting iteration 23

Steps executed: 275 Episode length: 97 Return: -41.601703596315886466
INFO:tensorflow:Average training steps per second: 219.13
I0905 16:45:57.354111 140334269278208 replay_runner.py:36] Average training steps per second: 219.13
I0905 16:45:57.598648 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -106.40
INFO:tensorflow:Starting iteration 24

Steps executed: 399 Episode length: 399 Return: -28.62199373244918466
INFO:tensorflow:Average training steps per second: 228.64
I0905 16:46:05.701330 140334269278208 replay_runner.py:36] Average training steps per second: 228.64
I0905 16:46:06.474308 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -28.62
INFO:tensorflow:Starting iteration 25
I0905 16:46:10.369482 140334269278208 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 239.47

Steps executed: 521 Episode length: 374 Return: 6.7660971587988146466
I0905 16:46:15.435594 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.18
INFO:tensorflow:Starting iteration 26

Steps executed: 218 Episode length: 102 Return: -470.0741784767785766
INFO:tensorflow:Average training steps per second: 254.39
I0905 16:46:23.356905 140334269278208 replay_runner.py:36] Average training steps per second: 254.39
I0905 16:46:23.554655 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -421.50
INFO:tensorflow:Starting iteration 27

Steps executed: 243 Episode length: 67 Return: -169.61479165243764766
INFO:tensorflow:Average training steps per second: 249.74
I0905 16:46:31.632864 140334269278208 replay_runner.py:36] Average training steps per second: 249.74
I0905 16:46:31.851646 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: -448.94
INFO:tensorflow:Starting iteration 28

Steps executed: 275 Episode length: 143 Return: -19.53120169154725366
INFO:tensorflow:Average training steps per second: 227.76
I0905 16:46:40.113828 140334269278208 replay_runner.py:36] Average training steps per second: 227.76
I0905 16:46:40.379338 140334269278208 run_experiment.py:428] Average undiscounted return per evaluation episode: 0.27
INFO:tensorflow:Starting iteration 29

Steps executed: 85 Episode length: 85 Return: -350.568748208755225366
INFO:tensorflow:Average training steps per second: 238.02
I0905 16:46:48.272464 140334269278208 replay_runner.py:36] Average training steps per second: 238.02


Done fixed training!Episode length: 385 Return: 241.09234069578965366