Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0901 12:19:51.837804 140460307478528 run_experiment.py:549] Creating TrainRunner ...
I0901 12:19:51.853721 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:19:51.854019 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:19:51.854207 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:19:51.854354 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:19:51.854555 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 12:19:51.854716 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:19:51.854871 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:19:51.854996 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:19:51.855108 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:19:51.855216 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 12:19:51.855320 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:19:51.855423 140460307478528 dqn_agent.py:283] 	 seed: 1630498791853649
I0901 12:19:51.858878 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:19:51.859096 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:19:51.859263 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:19:51.859606 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:19:51.859760 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:19:51.859928 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:19:51.860064 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:19:51.860212 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:19:51.860346 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:19:51.942271 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:19:52.318748 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:19:52.353706 140460307478528 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:19:52.363340 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:19:52.363554 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:19:52.363662 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:19:52.363745 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:19:52.363827 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 12:19:52.363909 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:19:52.364009 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:19:52.364267 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:19:52.364372 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:19:52.364444 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 12:19:52.364515 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:19:52.364609 140460307478528 dqn_agent.py:283] 	 seed: 1630498792363288
I0901 12:19:52.366994 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:19:52.367198 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:19:52.367358 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:19:52.367463 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:19:52.367621 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:19:52.367860 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:19:52.368022 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:19:52.368168 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:19:52.368332 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:19:52.401388 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:19:52.421878 140460307478528 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:19:52.422088 140460307478528 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 163.15
I0901 12:19:58.551890 140460307478528 replay_runner.py:36] Average training steps per second: 163.15
Steps executed: 200 Episode length: 200 Return: -307.64579336446195
I0901 12:19:59.690618 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.65
INFO:tensorflow:Starting iteration 1

Steps executed: 234 Episode length: 94 Return: -342.203494125128037
INFO:tensorflow:Average training steps per second: 224.08
I0901 12:20:08.546100 140460307478528 replay_runner.py:36] Average training steps per second: 224.08
I0901 12:20:08.754949 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.47
INFO:tensorflow:Starting iteration 2

Steps executed: 291 Episode length: 152 Return: -93.547690245873948
INFO:tensorflow:Average training steps per second: 222.89
I0901 12:20:17.735991 140460307478528 replay_runner.py:36] Average training steps per second: 222.89
I0901 12:20:18.011011 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.72
INFO:tensorflow:Starting iteration 3

Steps executed: 172 Episode length: 172 Return: -130.56947794447277
INFO:tensorflow:Average training steps per second: 220.32

Steps executed: 603 Episode length: 431 Return: -54.002482324142377
I0901 12:20:27.763315 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -92.29
INFO:tensorflow:Starting iteration 4
I0901 12:20:32.167521 140460307478528 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 226.36

Steps executed: 1000 Episode length: 1000 Return: -129.22595003738525
I0901 12:20:38.738933 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.23
INFO:tensorflow:Starting iteration 5
I0901 12:20:43.047815 140460307478528 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 227.79

Steps executed: 1000 Episode length: 1000 Return: -65.315676424990035
I0901 12:20:49.356908 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.32
INFO:tensorflow:Starting iteration 6
I0901 12:20:53.761957 140460307478528 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 222.60

Steps executed: 1000 Episode length: 1000 Return: -144.06880006264365
I0901 12:21:01.011360 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.07
INFO:tensorflow:Starting iteration 7
I0901 12:21:05.471701 140460307478528 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 219.18

Steps executed: 1000 Episode length: 1000 Return: -131.03312852959573
I0901 12:21:14.405790 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.03
INFO:tensorflow:Starting iteration 8
I0901 12:21:18.788019 140460307478528 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 222.48

Steps executed: 900 Episode length: 900 Return: -480.0713107846109473
I0901 12:21:26.416823 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -480.07
INFO:tensorflow:Starting iteration 9

Steps executed: 379 Episode length: 379 Return: -253.7976107519419673
INFO:tensorflow:Average training steps per second: 220.67
I0901 12:21:35.321714 140460307478528 replay_runner.py:36] Average training steps per second: 220.67
I0901 12:21:35.751516 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.80
INFO:tensorflow:Starting iteration 10

Steps executed: 264 Episode length: 85 Return: -450.79091964570846973
INFO:tensorflow:Average training steps per second: 242.57
I0901 12:21:44.143435 140460307478528 replay_runner.py:36] Average training steps per second: 242.57
I0901 12:21:44.382134 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.55
INFO:tensorflow:Starting iteration 11
I0901 12:21:48.729071 140460307478528 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 228.02

Steps executed: 669 Episode length: 669 Return: -658.3256948931597973
I0901 12:21:54.464187 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -658.33
INFO:tensorflow:Starting iteration 12

Steps executed: 320 Episode length: 320 Return: -713.7103887610583973
INFO:tensorflow:Average training steps per second: 234.36
I0901 12:22:03.002294 140460307478528 replay_runner.py:36] Average training steps per second: 234.36
I0901 12:22:03.398954 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -713.71
INFO:tensorflow:Starting iteration 13

Steps executed: 164 Episode length: 164 Return: -75.78120526366567973
INFO:tensorflow:Average training steps per second: 242.23
I0901 12:22:11.737371 140460307478528 replay_runner.py:36] Average training steps per second: 242.23

Steps executed: 355 Episode length: 191 Return: -162.4334321824323473
INFO:tensorflow:Starting iteration 14
I0901 12:22:16.387606 140460307478528 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 222.37

Steps executed: 1000 Episode length: 1000 Return: -27.986269489657385
I0901 12:22:24.045651 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -27.99
INFO:tensorflow:Starting iteration 15

Steps executed: 442 Episode length: 442 Return: -29.39058991712427485
INFO:tensorflow:Average training steps per second: 217.83
I0901 12:22:33.042540 140460307478528 replay_runner.py:36] Average training steps per second: 217.83
I0901 12:22:33.783366 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -29.39
INFO:tensorflow:Starting iteration 16
I0901 12:22:38.120891 140460307478528 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 215.74

Steps executed: 1000 Episode length: 1000 Return: -96.699826577986815
I0901 12:22:46.525695 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.70
INFO:tensorflow:Starting iteration 17
I0901 12:22:50.873184 140460307478528 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 222.00

Steps executed: 1000 Episode length: 1000 Return: -144.94176046051095
I0901 12:22:58.731233 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -144.94
INFO:tensorflow:Starting iteration 18

Steps executed: 262 Episode length: 262 Return: -263.6501501257268095
INFO:tensorflow:Average training steps per second: 221.99
I0901 12:23:07.670669 140460307478528 replay_runner.py:36] Average training steps per second: 221.99
I0901 12:23:07.986060 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.65
INFO:tensorflow:Starting iteration 19

Steps executed: 202 Episode length: 202 Return: -0.888517205314045195
INFO:tensorflow:Average training steps per second: 221.30
I0901 12:23:16.836679 140460307478528 replay_runner.py:36] Average training steps per second: 221.30
I0901 12:23:17.062939 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -0.89
INFO:tensorflow:Starting iteration 20
I0901 12:23:21.433405 140460307478528 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 225.11

Steps executed: 135 Episode length: 135 Return: -70.28553428939198195

Steps executed: 895 Episode length: 760 Return: -534.2858445706698195
INFO:tensorflow:Starting iteration 21

Steps executed: 280 Episode length: 114 Return: -103.6407152208690495
INFO:tensorflow:Average training steps per second: 215.96
I0901 12:23:36.796144 140460307478528 replay_runner.py:36] Average training steps per second: 215.96
I0901 12:23:37.086809 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.01
INFO:tensorflow:Starting iteration 22
I0901 12:23:41.530309 140460307478528 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 220.74
I0901 12:23:46.060901 140460307478528 replay_runner.py:36] Average training steps per second: 220.74

Steps executed: 219 Episode length: 127 Return: -407.9813201389773795
INFO:tensorflow:Starting iteration 23

Steps executed: 234 Episode length: 85 Return: -135.60238878551593795
INFO:tensorflow:Average training steps per second: 219.87
I0901 12:23:55.206074 140460307478528 replay_runner.py:36] Average training steps per second: 219.87
I0901 12:23:55.445004 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -145.04
INFO:tensorflow:Starting iteration 24

Steps executed: 356 Episode length: 159 Return: -132.2145720987548795
INFO:tensorflow:Average training steps per second: 225.03
I0901 12:24:04.243608 140460307478528 replay_runner.py:36] Average training steps per second: 225.03
I0901 12:24:04.592689 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.67
INFO:tensorflow:Starting iteration 25

Steps executed: 299 Episode length: 163 Return: -278.1438611010123695
INFO:tensorflow:Average training steps per second: 221.65
I0901 12:24:13.322964 140460307478528 replay_runner.py:36] Average training steps per second: 221.65
I0901 12:24:13.594229 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.72
INFO:tensorflow:Starting iteration 26

Steps executed: 219 Episode length: 78 Return: -672.31272177629016795
INFO:tensorflow:Average training steps per second: 223.38
I0901 12:24:22.366191 140460307478528 replay_runner.py:36] Average training steps per second: 223.38
I0901 12:24:22.574218 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -345.30
INFO:tensorflow:Starting iteration 27

Steps executed: 253 Episode length: 198 Return: 8.4506487829250576795
INFO:tensorflow:Average training steps per second: 230.16
I0901 12:24:31.389208 140460307478528 replay_runner.py:36] Average training steps per second: 230.16
I0901 12:24:31.664157 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -58.02
INFO:tensorflow:Starting iteration 28

Steps executed: 276 Episode length: 276 Return: 237.06861507923326795
INFO:tensorflow:Average training steps per second: 224.05
I0901 12:24:40.451065 140460307478528 replay_runner.py:36] Average training steps per second: 224.05
I0901 12:24:40.829623 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: 237.07
INFO:tensorflow:Starting iteration 29

Steps executed: 400 Episode length: 400 Return: 250.32338197057632795
INFO:tensorflow:Average training steps per second: 241.67
I0901 12:24:49.327372 140460307478528 replay_runner.py:36] Average training steps per second: 241.67

Done fixed training!Episode length: 400 Return: 250.32338197057632795