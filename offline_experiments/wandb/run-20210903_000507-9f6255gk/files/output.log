I0903 00:05:13.095103 140099460519936 run_experiment.py:549] Creating TrainRunner ...
I0903 00:05:13.103968 140099460519936 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:05:13.104118 140099460519936 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:05:13.104199 140099460519936 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:05:13.104257 140099460519936 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:05:13.104327 140099460519936 dqn_agent.py:275] 	 update_period: 4
I0903 00:05:13.104397 140099460519936 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:05:13.104500 140099460519936 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:05:13.104587 140099460519936 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:05:13.104647 140099460519936 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:05:13.104906 140099460519936 dqn_agent.py:280] 	 optimizer: adam
I0903 00:05:13.105066 140099460519936 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:05:13.105165 140099460519936 dqn_agent.py:283] 	 seed: 1630627513103932
I0903 00:05:13.107966 140099460519936 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:05:13.108120 140099460519936 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:05:13.108226 140099460519936 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:05:13.108332 140099460519936 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:05:13.108424 140099460519936 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:05:13.108507 140099460519936 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:05:13.108600 140099460519936 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:05:13.108687 140099460519936 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:05:13.108772 140099460519936 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:05:13.146745 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:05:13.403732 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:05:13.413043 140099460519936 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0903 00:05:13.419081 140099460519936 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0903 00:05:13.419226 140099460519936 dqn_agent.py:272] 	 gamma: 0.990000
I0903 00:05:13.419303 140099460519936 dqn_agent.py:273] 	 update_horizon: 1.000000
I0903 00:05:13.419366 140099460519936 dqn_agent.py:274] 	 min_replay_history: 500
I0903 00:05:13.419421 140099460519936 dqn_agent.py:275] 	 update_period: 4
I0903 00:05:13.419491 140099460519936 dqn_agent.py:276] 	 target_update_period: 300
I0903 00:05:13.419593 140099460519936 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0903 00:05:13.419671 140099460519936 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0903 00:05:13.419727 140099460519936 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0903 00:05:13.419795 140099460519936 dqn_agent.py:280] 	 optimizer: adam
I0903 00:05:13.419871 140099460519936 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0903 00:05:13.419945 140099460519936 dqn_agent.py:283] 	 seed: 1630627513419050
I0903 00:05:13.422241 140099460519936 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0903 00:05:13.422444 140099460519936 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0903 00:05:13.422542 140099460519936 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0903 00:05:13.422634 140099460519936 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0903 00:05:13.422728 140099460519936 circular_replay_buffer.py:159] 	 stack_size: 1
I0903 00:05:13.422822 140099460519936 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0903 00:05:13.422932 140099460519936 circular_replay_buffer.py:161] 	 batch_size: 128
I0903 00:05:13.423003 140099460519936 circular_replay_buffer.py:162] 	 update_horizon: 1
I0903 00:05:13.423077 140099460519936 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0903 00:05:13.442646 140099460519936 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0903 00:05:13.455826 140099460519936 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0903 00:05:13.455995 140099460519936 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 242.52
I0903 00:05:17.579573 140099460519936 replay_runner.py:36] Average training steps per second: 242.52
I0903 00:05:18.406673 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -379.75
Steps executed: 294 Episode length: 101 Return: -326.55880996516385
INFO:tensorflow:Starting iteration 1
I0903 00:05:21.696200 140099460519936 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 328.42

Steps executed: 303 Episode length: 153 Return: -463.22577106876185
I0903 00:05:24.939601 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -499.56
INFO:tensorflow:Starting iteration 2

Steps executed: 427 Episode length: 252 Return: -67.994674811045513
INFO:tensorflow:Average training steps per second: 357.24
I0903 00:05:30.998578 140099460519936 replay_runner.py:36] Average training steps per second: 357.24
I0903 00:05:31.359576 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -249.52
INFO:tensorflow:Starting iteration 3

Steps executed: 352 Episode length: 189 Return: -324.66200399324085
INFO:tensorflow:Average training steps per second: 351.70
I0903 00:05:37.606664 140099460519936 replay_runner.py:36] Average training steps per second: 351.70
I0903 00:05:37.878408 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -299.35
INFO:tensorflow:Starting iteration 4
I0903 00:05:41.318554 140099460519936 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 352.62

Steps executed: 1000 Episode length: 1000 Return: -78.79614340426131
I0903 00:05:46.362135 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.80
INFO:tensorflow:Starting iteration 5
I0903 00:05:49.702368 140099460519936 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 337.41

Steps executed: 1000 Episode length: 1000 Return: -36.53865872663641
I0903 00:05:54.549899 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -36.54
INFO:tensorflow:Starting iteration 6
I0903 00:05:57.916017 140099460519936 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 340.80

Steps executed: 1000 Episode length: 1000 Return: -168.82079736682408
I0903 00:06:03.100822 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -168.82
INFO:tensorflow:Starting iteration 7
I0903 00:06:06.525994 140099460519936 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 341.90

Steps executed: 948 Episode length: 948 Return: -965.4894071115315408
I0903 00:06:11.887773 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -965.49
INFO:tensorflow:Starting iteration 8
I0903 00:06:15.357831 140099460519936 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 347.09

Steps executed: 1000 Episode length: 1000 Return: -194.47278622493613
I0903 00:06:20.201213 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -194.47
INFO:tensorflow:Starting iteration 9
I0903 00:06:23.738189 140099460519936 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 354.78

Steps executed: 1000 Episode length: 1000 Return: -219.14449951175166
I0903 00:06:27.764269 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -219.14
INFO:tensorflow:Starting iteration 10
I0903 00:06:31.226275 140099460519936 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 331.77

Steps executed: 1000 Episode length: 1000 Return: -154.35798658353897
I0903 00:06:36.315585 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -154.36
INFO:tensorflow:Starting iteration 11

Steps executed: 356 Episode length: 169 Return: -560.9500843276636897
INFO:tensorflow:Average training steps per second: 322.98
I0903 00:06:42.752938 140099460519936 replay_runner.py:36] Average training steps per second: 322.98
I0903 00:06:43.020949 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -539.50
INFO:tensorflow:Starting iteration 12
I0903 00:06:46.421056 140099460519936 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 336.25

Steps executed: 1000 Episode length: 1000 Return: -90.210494467712597
I0903 00:06:52.629731 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.21
INFO:tensorflow:Starting iteration 13
I0903 00:06:56.078063 140099460519936 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 331.21

Steps executed: 431 Episode length: 431 Return: -134.7548523175853597
I0903 00:06:59.590385 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.75
INFO:tensorflow:Starting iteration 14
I0903 00:07:03.052046 140099460519936 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 327.97

Steps executed: 1000 Episode length: 1000 Return: -269.63377718125197
I0903 00:07:08.110989 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.63
INFO:tensorflow:Starting iteration 15

Steps executed: 309 Episode length: 309 Return: -90.52105037030365197
INFO:tensorflow:Average training steps per second: 327.96
I0903 00:07:14.594089 140099460519936 replay_runner.py:36] Average training steps per second: 327.96
I0903 00:07:14.868560 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.52
INFO:tensorflow:Starting iteration 16
I0903 00:07:18.270719 140099460519936 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 326.53

Steps executed: 337 Episode length: 217 Return: -2.307664984288635497
I0903 00:07:21.546365 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.91
INFO:tensorflow:Starting iteration 17
I0903 00:07:24.927720 140099460519936 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 333.04
I0903 00:07:27.930752 140099460519936 replay_runner.py:36] Average training steps per second: 333.04

Steps executed: 792 Episode length: 792 Return: -97.37776866257299497
INFO:tensorflow:Starting iteration 18

Steps executed: 383 Episode length: 383 Return: -52.72225435838213497
INFO:tensorflow:Average training steps per second: 338.81
I0903 00:07:35.769706 140099460519936 replay_runner.py:36] Average training steps per second: 338.81
I0903 00:07:36.190241 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -52.72
INFO:tensorflow:Starting iteration 19
I0903 00:07:39.674553 140099460519936 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 344.04

Steps executed: 1000 Episode length: 1000 Return: -120.84587446652543
I0903 00:07:44.996077 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.85
INFO:tensorflow:Starting iteration 20
I0903 00:07:48.449567 140099460519936 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 346.99
I0903 00:07:51.331788 140099460519936 replay_runner.py:36] Average training steps per second: 346.99

Steps executed: 829 Episode length: 829 Return: -96.84068425256007543
INFO:tensorflow:Starting iteration 21
I0903 00:07:56.542395 140099460519936 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 331.10

Steps executed: 494 Episode length: 494 Return: -533.3931169532218543
I0903 00:08:00.309685 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -533.39
INFO:tensorflow:Starting iteration 22

Steps executed: 218 Episode length: 218 Return: -78.51256488330556543
INFO:tensorflow:Average training steps per second: 323.62
I0903 00:08:06.585578 140099460519936 replay_runner.py:36] Average training steps per second: 323.62
I0903 00:08:06.727996 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -78.51
INFO:tensorflow:Starting iteration 23
I0903 00:08:09.943813 140099460519936 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 327.41
I0903 00:08:12.998412 140099460519936 replay_runner.py:36] Average training steps per second: 327.41

Steps executed: 503 Episode length: 503 Return: 265.18996433774086543
INFO:tensorflow:Starting iteration 24

Steps executed: 277 Episode length: 132 Return: -108.7350540216096743
INFO:tensorflow:Average training steps per second: 328.86
I0903 00:08:19.955776 140099460519936 replay_runner.py:36] Average training steps per second: 328.86
I0903 00:08:20.117358 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -120.22
INFO:tensorflow:Starting iteration 25

Steps executed: 323 Episode length: 323 Return: -484.9784483545701743
INFO:tensorflow:Average training steps per second: 333.27
I0903 00:08:26.236266 140099460519936 replay_runner.py:36] Average training steps per second: 333.27
I0903 00:08:26.565192 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -484.98
INFO:tensorflow:Starting iteration 26
I0903 00:08:29.669869 140099460519936 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 321.80

Steps executed: 1000 Episode length: 1000 Return: -32.489391633422464
I0903 00:08:34.960010 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -32.49
INFO:tensorflow:Starting iteration 27
I0903 00:08:38.284641 140099460519936 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 323.46

Steps executed: 239 Episode length: 239 Return: -51.10654082028168464
I0903 00:08:41.587027 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -51.11
INFO:tensorflow:Starting iteration 28

Steps executed: 386 Episode length: 187 Return: -78.82240958805066464
INFO:tensorflow:Average training steps per second: 315.07
I0903 00:08:48.059413 140099460519936 replay_runner.py:36] Average training steps per second: 315.07
I0903 00:08:48.322841 140099460519936 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.84
INFO:tensorflow:Starting iteration 29

Steps executed: 252 Episode length: 252 Return: -1032.377327476681864
INFO:tensorflow:Average training steps per second: 316.33
I0903 00:08:54.797182 140099460519936 replay_runner.py:36] Average training steps per second: 316.33

Done fixed training!Episode length: 252 Return: -1032.377327476681864