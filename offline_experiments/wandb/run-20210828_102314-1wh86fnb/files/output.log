Loaded trained dqn in lunarlander
Training fixed agent 3, please be patient, may be a while...
I0828 10:23:21.410413 140618562066432 run_experiment.py:549] Creating TrainRunner ...
I0828 10:23:21.421859 140618562066432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:23:21.422138 140618562066432 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:23:21.422339 140618562066432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:23:21.422472 140618562066432 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:23:21.422567 140618562066432 dqn_agent.py:275] 	 update_period: 4
I0828 10:23:21.422724 140618562066432 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:23:21.422837 140618562066432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:23:21.422907 140618562066432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:23:21.422971 140618562066432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:23:21.423056 140618562066432 dqn_agent.py:280] 	 optimizer: adam
I0828 10:23:21.423119 140618562066432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:23:21.423182 140618562066432 dqn_agent.py:283] 	 seed: 1630146201421790
I0828 10:23:21.424878 140618562066432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:23:21.425000 140618562066432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:23:21.425073 140618562066432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:23:21.425153 140618562066432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:23:21.425300 140618562066432 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:23:21.425398 140618562066432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:23:21.425465 140618562066432 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:23:21.425534 140618562066432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:23:21.425596 140618562066432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:23:21.461733 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:21.923379 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:21.936751 140618562066432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:23:21.946483 140618562066432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:23:21.946752 140618562066432 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:23:21.946968 140618562066432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:23:21.947072 140618562066432 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:23:21.947219 140618562066432 dqn_agent.py:275] 	 update_period: 4
I0828 10:23:21.947340 140618562066432 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:23:21.947430 140618562066432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:23:21.947502 140618562066432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:23:21.947777 140618562066432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:23:21.947871 140618562066432 dqn_agent.py:280] 	 optimizer: adam
I0828 10:23:21.947948 140618562066432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:23:21.948002 140618562066432 dqn_agent.py:283] 	 seed: 1630146201946433
I0828 10:23:21.950748 140618562066432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:23:21.950963 140618562066432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:23:21.951150 140618562066432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:23:21.951283 140618562066432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:23:21.951368 140618562066432 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:23:21.951443 140618562066432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:23:21.951733 140618562066432 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:23:21.951930 140618562066432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:23:21.952031 140618562066432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:23:21.984028 140618562066432 dqn_agent.py:70] Creating Adam optimizer with settings lr=5.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:23:22.004089 140618562066432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:23:22.004278 140618562066432 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 159.22
I0828 10:23:28.285366 140618562066432 replay_runner.py:36] Average training steps per second: 159.22
Steps executed: 252 Episode length: 68 Return: -535.29766093547053
I0828 10:23:29.574284 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -503.04
INFO:tensorflow:Starting iteration 1

Steps executed: 206 Episode length: 68 Return: -156.15883050593146
INFO:tensorflow:Average training steps per second: 220.71
I0828 10:23:38.339896 140618562066432 replay_runner.py:36] Average training steps per second: 220.71
I0828 10:23:38.488016 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -153.98
INFO:tensorflow:Starting iteration 2

Steps executed: 267 Episode length: 79 Return: -864.00990942345363
INFO:tensorflow:Average training steps per second: 222.68
I0828 10:23:47.312359 140618562066432 replay_runner.py:36] Average training steps per second: 222.68
I0828 10:23:47.568702 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -567.45
INFO:tensorflow:Starting iteration 3

Steps executed: 264 Episode length: 66 Return: -654.37065601774784
INFO:tensorflow:Average training steps per second: 219.68
I0828 10:23:56.511100 140618562066432 replay_runner.py:36] Average training steps per second: 219.68
I0828 10:23:56.744714 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -550.73
INFO:tensorflow:Starting iteration 4

Steps executed: 220 Episode length: 81 Return: -751.12689279268454
INFO:tensorflow:Average training steps per second: 225.23
I0828 10:24:05.456286 140618562066432 replay_runner.py:36] Average training steps per second: 225.23
I0828 10:24:05.660206 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -659.41
INFO:tensorflow:Starting iteration 5

Steps executed: 238 Episode length: 56 Return: -506.32324328730474
INFO:tensorflow:Average training steps per second: 227.17
I0828 10:24:14.393105 140618562066432 replay_runner.py:36] Average training steps per second: 227.17
I0828 10:24:14.596139 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -530.49
INFO:tensorflow:Starting iteration 6

Steps executed: 62 Episode length: 62 Return: -547.906500327277774
INFO:tensorflow:Average training steps per second: 236.03

Steps executed: 227 Episode length: 81 Return: -754.80562645405714
I0828 10:24:23.371408 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -745.95
INFO:tensorflow:Starting iteration 7

Steps executed: 202 Episode length: 58 Return: -539.56069989151644
INFO:tensorflow:Average training steps per second: 239.71
I0828 10:24:31.596140 140618562066432 replay_runner.py:36] Average training steps per second: 239.71
I0828 10:24:31.758978 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -609.16
INFO:tensorflow:Starting iteration 8

Steps executed: 238 Episode length: 62 Return: -573.55603468223914
INFO:tensorflow:Average training steps per second: 262.55
I0828 10:24:39.816123 140618562066432 replay_runner.py:36] Average training steps per second: 262.55
I0828 10:24:40.023273 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -493.98
INFO:tensorflow:Starting iteration 9

Steps executed: 200 Episode length: 57 Return: -425.05594495266945
INFO:tensorflow:Average training steps per second: 241.29
I0828 10:24:48.116827 140618562066432 replay_runner.py:36] Average training steps per second: 241.29
I0828 10:24:48.284435 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -573.79
INFO:tensorflow:Starting iteration 10

Steps executed: 211 Episode length: 49 Return: -414.96057920182545
INFO:tensorflow:Average training steps per second: 227.24
I0828 10:24:56.912866 140618562066432 replay_runner.py:36] Average training steps per second: 227.24
I0828 10:24:57.104201 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -410.07
INFO:tensorflow:Starting iteration 11

Steps executed: 256 Episode length: 59 Return: -523.09433564369625
INFO:tensorflow:Average training steps per second: 227.62
I0828 10:25:05.769997 140618562066432 replay_runner.py:36] Average training steps per second: 227.62
I0828 10:25:06.002897 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -560.63
INFO:tensorflow:Starting iteration 12

Steps executed: 222 Episode length: 84 Return: -613.35472450507235
INFO:tensorflow:Average training steps per second: 226.04
I0828 10:25:14.767102 140618562066432 replay_runner.py:36] Average training steps per second: 226.04
I0828 10:25:14.971149 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -637.08
INFO:tensorflow:Starting iteration 13

Steps executed: 221 Episode length: 76 Return: -675.36885085994025
INFO:tensorflow:Average training steps per second: 229.04
I0828 10:25:23.716608 140618562066432 replay_runner.py:36] Average training steps per second: 229.04
I0828 10:25:23.929109 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -675.51
INFO:tensorflow:Starting iteration 14

Steps executed: 234 Episode length: 82 Return: -724.99213634039975
INFO:tensorflow:Average training steps per second: 229.67
I0828 10:25:32.641869 140618562066432 replay_runner.py:36] Average training steps per second: 229.67
I0828 10:25:32.871236 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -749.72
INFO:tensorflow:Starting iteration 15
I0828 10:25:37.336384 140618562066432 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 229.41

Steps executed: 255 Episode length: 71 Return: -664.57927495550834
I0828 10:25:41.928211 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -592.57
INFO:tensorflow:Starting iteration 16

Steps executed: 248 Episode length: 51 Return: -410.56629643403364
INFO:tensorflow:Average training steps per second: 226.96
I0828 10:25:50.642627 140618562066432 replay_runner.py:36] Average training steps per second: 226.96
I0828 10:25:50.879055 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -481.62
INFO:tensorflow:Starting iteration 17

Steps executed: 154 Episode length: 72 Return: -475.50939376316126
INFO:tensorflow:Average training steps per second: 226.31
I0828 10:25:59.579935 140618562066432 replay_runner.py:36] Average training steps per second: 226.31

Steps executed: 238 Episode length: 84 Return: -796.93696603709376
INFO:tensorflow:Starting iteration 18

Steps executed: 244 Episode length: 69 Return: -531.96561457301946
INFO:tensorflow:Average training steps per second: 227.27
I0828 10:26:08.596941 140618562066432 replay_runner.py:36] Average training steps per second: 227.27
I0828 10:26:08.810778 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -479.97
INFO:tensorflow:Starting iteration 19

Steps executed: 219 Episode length: 55 Return: -365.54022300508896
INFO:tensorflow:Average training steps per second: 228.72
I0828 10:26:17.624212 140618562066432 replay_runner.py:36] Average training steps per second: 228.72
I0828 10:26:17.818391 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -670.96
INFO:tensorflow:Starting iteration 20

Steps executed: 216 Episode length: 66 Return: -546.63190418736186
INFO:tensorflow:Average training steps per second: 229.36
I0828 10:26:26.626507 140618562066432 replay_runner.py:36] Average training steps per second: 229.36
I0828 10:26:26.822980 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -586.23
INFO:tensorflow:Starting iteration 21
I0828 10:26:31.182191 140618562066432 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 232.56

Steps executed: 249 Episode length: 80 Return: -438.90447032041326
I0828 10:26:35.714982 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -545.33
INFO:tensorflow:Starting iteration 22

Steps executed: 251 Episode length: 63 Return: -516.48346299752946
INFO:tensorflow:Average training steps per second: 228.49
I0828 10:26:44.491855 140618562066432 replay_runner.py:36] Average training steps per second: 228.49
I0828 10:26:44.711224 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -485.26
INFO:tensorflow:Starting iteration 23

Steps executed: 144 Episode length: 78 Return: -562.01320023979776
INFO:tensorflow:Average training steps per second: 228.36
I0828 10:26:53.441945 140618562066432 replay_runner.py:36] Average training steps per second: 228.36

Steps executed: 201 Episode length: 57 Return: -464.24994877591433
INFO:tensorflow:Starting iteration 24

Steps executed: 227 Episode length: 227 Return: -1724.2461030334975
INFO:tensorflow:Average training steps per second: 230.76
I0828 10:27:02.371105 140618562066432 replay_runner.py:36] Average training steps per second: 230.76
I0828 10:27:02.660129 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -1724.25
INFO:tensorflow:Starting iteration 25

Steps executed: 277 Episode length: 85 Return: -508.579860376103445
INFO:tensorflow:Average training steps per second: 231.82
I0828 10:27:11.386233 140618562066432 replay_runner.py:36] Average training steps per second: 231.82
I0828 10:27:11.632307 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -626.81
INFO:tensorflow:Starting iteration 26

Steps executed: 258 Episode length: 170 Return: -1128.0125355032062
INFO:tensorflow:Average training steps per second: 242.99
I0828 10:27:20.141954 140618562066432 replay_runner.py:36] Average training steps per second: 242.99
I0828 10:27:20.384582 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -816.02
INFO:tensorflow:Starting iteration 27

Steps executed: 233 Episode length: 56 Return: -476.348311630630762
INFO:tensorflow:Average training steps per second: 243.34
I0828 10:27:28.808268 140618562066432 replay_runner.py:36] Average training steps per second: 243.34
I0828 10:27:28.983083 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -461.27
INFO:tensorflow:Starting iteration 28

Steps executed: 205 Episode length: 57 Return: -517.970481402289262
INFO:tensorflow:Average training steps per second: 233.59
I0828 10:27:37.474592 140618562066432 replay_runner.py:36] Average training steps per second: 233.59
I0828 10:27:37.652381 140618562066432 run_experiment.py:428] Average undiscounted return per evaluation episode: -624.82
INFO:tensorflow:Starting iteration 29

Steps executed: 233 Episode length: 76 Return: -694.442307337865862
INFO:tensorflow:Average training steps per second: 239.71
I0828 10:27:46.132776 140618562066432 replay_runner.py:36] Average training steps per second: 239.71

Done fixed training!Episode length: 76 Return: -694.442307337865862