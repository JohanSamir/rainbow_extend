I0901 13:19:53.794311 139809518303232 run_experiment.py:549] Creating TrainRunner ...
I0901 13:19:53.803167 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:19:53.803303 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:19:53.803377 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:19:53.803464 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:19:53.803578 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 13:19:53.803747 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:19:53.803870 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:19:53.803949 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:19:53.804088 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:19:53.804252 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 13:19:53.804351 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:19:53.804427 139809518303232 dqn_agent.py:283] 	 seed: 1630502393803111
I0901 13:19:53.806407 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:19:53.806528 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:19:53.806610 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:19:53.806694 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:19:53.806819 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:19:53.806906 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:19:53.806990 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:19:53.807154 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:19:53.807243 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:19:53.835676 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:54.092547 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:54.101711 139809518303232 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:19:54.108816 139809518303232 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:19:54.108951 139809518303232 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:19:54.109024 139809518303232 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:19:54.109086 139809518303232 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:19:54.109141 139809518303232 dqn_agent.py:275] 	 update_period: 4
I0901 13:19:54.109205 139809518303232 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:19:54.109291 139809518303232 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:19:54.109361 139809518303232 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:19:54.109417 139809518303232 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:19:54.109479 139809518303232 dqn_agent.py:280] 	 optimizer: adam
I0901 13:19:54.109560 139809518303232 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:19:54.109627 139809518303232 dqn_agent.py:283] 	 seed: 1630502394108784
I0901 13:19:54.111212 139809518303232 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:19:54.111330 139809518303232 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:19:54.111403 139809518303232 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:19:54.111468 139809518303232 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:19:54.111525 139809518303232 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:19:54.111596 139809518303232 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:19:54.111652 139809518303232 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:19:54.111737 139809518303232 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:19:54.111810 139809518303232 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:19:54.134316 139809518303232 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:54.150158 139809518303232 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:19:54.150409 139809518303232 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
Steps executed: 263 Episode length: 137 Return: -54.769821176993235
INFO:tensorflow:Average training steps per second: 233.59
I0901 13:19:58.431774 139809518303232 replay_runner.py:36] Average training steps per second: 233.59
I0901 13:19:59.328370 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -185.23
INFO:tensorflow:Starting iteration 1

Steps executed: 206 Episode length: 105 Return: -175.56355325391058
INFO:tensorflow:Average training steps per second: 330.53
I0901 13:20:05.709877 139809518303232 replay_runner.py:36] Average training steps per second: 330.53
I0901 13:20:05.839642 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.15
INFO:tensorflow:Starting iteration 2

Steps executed: 219 Episode length: 105 Return: -442.59516236925435
INFO:tensorflow:Average training steps per second: 336.05
I0901 13:20:12.258433 139809518303232 replay_runner.py:36] Average training steps per second: 336.05
I0901 13:20:12.415848 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -425.79
INFO:tensorflow:Starting iteration 3

Steps executed: 299 Episode length: 183 Return: 49.0889496980514985
INFO:tensorflow:Average training steps per second: 335.24
I0901 13:20:18.803499 139809518303232 replay_runner.py:36] Average training steps per second: 335.24
I0901 13:20:19.027332 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -3.38
INFO:tensorflow:Starting iteration 4
I0901 13:20:22.409147 139809518303232 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 329.35

Steps executed: 496 Episode length: 496 Return: -263.80940037393275
I0901 13:20:26.041294 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -263.81
INFO:tensorflow:Starting iteration 5

Steps executed: 74 Episode length: 74 Return: -246.8548690273446275
INFO:tensorflow:Average training steps per second: 336.87

Steps executed: 996 Episode length: 922 Return: -322.06661152434485
I0901 13:20:33.708396 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -284.46
INFO:tensorflow:Starting iteration 6
I0901 13:20:36.955181 139809518303232 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 318.66

Steps executed: 890 Episode length: 890 Return: -392.38295804971115
I0901 13:20:41.804989 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -392.38
INFO:tensorflow:Starting iteration 7

Steps executed: 239 Episode length: 239 Return: -174.73556478807575
INFO:tensorflow:Average training steps per second: 314.32
I0901 13:20:48.225956 139809518303232 replay_runner.py:36] Average training steps per second: 314.32
I0901 13:20:48.417466 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -174.74
INFO:tensorflow:Starting iteration 8

Steps executed: 221 Episode length: 104 Return: 9.54241574527213755
INFO:tensorflow:Average training steps per second: 317.50
I0901 13:20:54.898472 139809518303232 replay_runner.py:36] Average training steps per second: 317.50
I0901 13:20:55.049793 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: 2.26
INFO:tensorflow:Starting iteration 9

Steps executed: 107 Episode length: 107 Return: -213.69460936725613
INFO:tensorflow:Average training steps per second: 320.87

Steps executed: 555 Episode length: 448 Return: -249.59426425700764
I0901 13:21:02.087550 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -231.64
INFO:tensorflow:Starting iteration 10
I0901 13:21:05.412154 139809518303232 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 336.39

Steps executed: 876 Episode length: 876 Return: -347.51967824725734
I0901 13:21:10.021017 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -347.52
INFO:tensorflow:Starting iteration 11

Steps executed: 381 Episode length: 234 Return: -246.16460865502915
INFO:tensorflow:Average training steps per second: 316.80
I0901 13:21:16.449909 139809518303232 replay_runner.py:36] Average training steps per second: 316.80
I0901 13:21:16.746922 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.48
INFO:tensorflow:Starting iteration 12

Steps executed: 260 Episode length: 260 Return: -160.34555563411712
INFO:tensorflow:Average training steps per second: 320.59
I0901 13:21:23.177124 139809518303232 replay_runner.py:36] Average training steps per second: 320.59
I0901 13:21:23.418510 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.35
INFO:tensorflow:Starting iteration 13
I0901 13:21:26.787072 139809518303232 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 320.23

Steps executed: 229 Episode length: 229 Return: -227.73307280023846
I0901 13:21:30.094803 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.73
INFO:tensorflow:Starting iteration 14

Steps executed: 251 Episode length: 122 Return: -56.567215319289526
INFO:tensorflow:Average training steps per second: 324.43
I0901 13:21:36.557603 139809518303232 replay_runner.py:36] Average training steps per second: 324.43
I0901 13:21:36.709304 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.72
INFO:tensorflow:Starting iteration 15

Steps executed: 429 Episode length: 429 Return: -178.00370407149788
INFO:tensorflow:Average training steps per second: 326.55
I0901 13:21:43.182140 139809518303232 replay_runner.py:36] Average training steps per second: 326.55
I0901 13:21:43.788460 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.00
INFO:tensorflow:Starting iteration 16

Steps executed: 246 Episode length: 246 Return: -260.81821262350206
INFO:tensorflow:Average training steps per second: 340.97
I0901 13:21:50.123147 139809518303232 replay_runner.py:36] Average training steps per second: 340.97
I0901 13:21:50.319095 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.82
INFO:tensorflow:Starting iteration 17

Steps executed: 496 Episode length: 496 Return: -210.15404367310182
INFO:tensorflow:Average training steps per second: 352.79
I0901 13:21:56.638306 139809518303232 replay_runner.py:36] Average training steps per second: 352.79
I0901 13:21:57.384923 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -210.15
INFO:tensorflow:Starting iteration 18

Steps executed: 277 Episode length: 277 Return: -244.68523591266927
INFO:tensorflow:Average training steps per second: 354.69
I0901 13:22:03.691277 139809518303232 replay_runner.py:36] Average training steps per second: 354.69
I0901 13:22:03.963910 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.69
INFO:tensorflow:Starting iteration 19

Steps executed: 253 Episode length: 253 Return: -237.47521183108807
INFO:tensorflow:Average training steps per second: 359.91
I0901 13:22:10.286709 139809518303232 replay_runner.py:36] Average training steps per second: 359.91
I0901 13:22:10.456463 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -237.48
INFO:tensorflow:Starting iteration 20

Steps executed: 444 Episode length: 444 Return: -156.58274233868417
INFO:tensorflow:Average training steps per second: 339.57
I0901 13:22:16.815342 139809518303232 replay_runner.py:36] Average training steps per second: 339.57
I0901 13:22:17.278619 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.58
INFO:tensorflow:Starting iteration 21
I0901 13:22:20.667395 139809518303232 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 315.42

Steps executed: 459 Episode length: 459 Return: -180.77551873093353
I0901 13:22:24.267783 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -180.78
INFO:tensorflow:Starting iteration 22

Steps executed: 502 Episode length: 502 Return: -260.21317744447424
INFO:tensorflow:Average training steps per second: 334.04
I0901 13:22:30.615808 139809518303232 replay_runner.py:36] Average training steps per second: 334.04
I0901 13:22:31.230499 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.21
INFO:tensorflow:Starting iteration 23

Steps executed: 159 Episode length: 159 Return: -143.66119903943155
INFO:tensorflow:Average training steps per second: 351.07

Steps executed: 1159 Episode length: 1000 Return: -0.18766632215674228
I0901 13:22:39.303699 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -71.92
INFO:tensorflow:Starting iteration 24

Steps executed: 159 Episode length: 159 Return: -126.62873902307146228
INFO:tensorflow:Average training steps per second: 347.84
I0901 13:22:45.551898 139809518303232 replay_runner.py:36] Average training steps per second: 347.84

Steps executed: 1159 Episode length: 1000 Return: -137.208391536928768
INFO:tensorflow:Starting iteration 25

Steps executed: 339 Episode length: 339 Return: -77.713550339190588768
INFO:tensorflow:Average training steps per second: 324.20
I0901 13:22:54.393233 139809518303232 replay_runner.py:36] Average training steps per second: 324.20
I0901 13:22:54.723339 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.71
INFO:tensorflow:Starting iteration 26

Steps executed: 695 Episode length: 695 Return: -696.51714123796658768
INFO:tensorflow:Average training steps per second: 317.25
I0901 13:23:01.117008 139809518303232 replay_runner.py:36] Average training steps per second: 317.25
I0901 13:23:01.867412 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -696.52
INFO:tensorflow:Starting iteration 27

Steps executed: 249 Episode length: 249 Return: -977.95614826871148768
INFO:tensorflow:Average training steps per second: 300.94
I0901 13:23:08.404785 139809518303232 replay_runner.py:36] Average training steps per second: 300.94
I0901 13:23:08.619475 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -977.96
INFO:tensorflow:Starting iteration 28
I0901 13:23:11.936610 139809518303232 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 296.96

Steps executed: 1000 Episode length: 1000 Return: -22.8837236661546368
I0901 13:23:16.735213 139809518303232 run_experiment.py:428] Average undiscounted return per evaluation episode: -22.88
INFO:tensorflow:Starting iteration 29
I0901 13:23:20.150544 139809518303232 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 310.06

Steps executed: 795 Episode length: 795 Return: -178.82889150064943368

Done fixed training!Episode length: 795 Return: -178.82889150064943368