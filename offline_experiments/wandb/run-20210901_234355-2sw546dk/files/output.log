I0901 23:44:02.142785 140053067847680 run_experiment.py:549] Creating TrainRunner ...
I0901 23:44:02.155003 140053067847680 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:44:02.155252 140053067847680 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:44:02.155453 140053067847680 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:44:02.155570 140053067847680 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:44:02.155648 140053067847680 dqn_agent.py:275] 	 update_period: 4
I0901 23:44:02.155941 140053067847680 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:44:02.156091 140053067847680 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:44:02.156235 140053067847680 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:44:02.156321 140053067847680 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:44:02.156413 140053067847680 dqn_agent.py:280] 	 optimizer: adam
I0901 23:44:02.156565 140053067847680 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:44:02.156816 140053067847680 dqn_agent.py:283] 	 seed: 1630539842154947
I0901 23:44:02.159982 140053067847680 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:44:02.160205 140053067847680 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:44:02.160368 140053067847680 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:44:02.160505 140053067847680 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:44:02.160630 140053067847680 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:44:02.160802 140053067847680 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:44:02.160881 140053067847680 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:44:02.160943 140053067847680 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:44:02.161059 140053067847680 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 4, please be patient, may be a while...
I0901 23:44:03.720198 140053067847680 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:44:04.103391 140053067847680 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:44:04.116901 140053067847680 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:44:04.126908 140053067847680 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:44:04.127117 140053067847680 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:44:04.127737 140053067847680 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:44:04.127869 140053067847680 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:44:04.127940 140053067847680 dqn_agent.py:275] 	 update_period: 4
I0901 23:44:04.128080 140053067847680 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:44:04.128264 140053067847680 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:44:04.128419 140053067847680 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:44:04.128571 140053067847680 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:44:04.128673 140053067847680 dqn_agent.py:280] 	 optimizer: adam
I0901 23:44:04.128781 140053067847680 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:44:04.128872 140053067847680 dqn_agent.py:283] 	 seed: 1630539844126860
I0901 23:44:04.143531 140053067847680 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:44:04.143807 140053067847680 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:44:04.143922 140053067847680 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:44:04.144018 140053067847680 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:44:04.144112 140053067847680 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:44:04.144211 140053067847680 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:44:04.144309 140053067847680 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:44:04.144406 140053067847680 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:44:04.144527 140053067847680 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:44:04.200306 140053067847680 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:44:04.259244 140053067847680 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:44:04.259552 140053067847680 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 173.31
I0901 23:44:10.030055 140053067847680 replay_runner.py:36] Average training steps per second: 173.31
Steps executed: 394 Episode length: 265 Return: -147.37955669823224
I0901 23:44:11.642841 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -209.89
INFO:tensorflow:Starting iteration 1

Steps executed: 347 Episode length: 169 Return: -333.85343031685585
INFO:tensorflow:Average training steps per second: 233.25
I0901 23:44:20.512605 140053067847680 replay_runner.py:36] Average training steps per second: 233.25
I0901 23:44:20.837479 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -338.27
INFO:tensorflow:Starting iteration 2

Steps executed: 261 Episode length: 261 Return: -341.25759116472275
INFO:tensorflow:Average training steps per second: 238.23
I0901 23:44:29.419257 140053067847680 replay_runner.py:36] Average training steps per second: 238.23
I0901 23:44:29.721849 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -341.26
INFO:tensorflow:Starting iteration 3
I0901 23:44:33.857250 140053067847680 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 227.83

Steps executed: 1000 Episode length: 1000 Return: -189.88349196548333
I0901 23:44:41.129242 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.88
INFO:tensorflow:Starting iteration 4
I0901 23:44:45.255989 140053067847680 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 230.24

Steps executed: 1000 Episode length: 1000 Return: -195.28302624834842
I0901 23:44:52.413441 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.28
INFO:tensorflow:Starting iteration 5
I0901 23:44:56.831224 140053067847680 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 222.02

Steps executed: 1000 Episode length: 1000 Return: -124.38200372396565
I0901 23:45:03.967474 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.38
INFO:tensorflow:Starting iteration 6
I0901 23:45:08.253834 140053067847680 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 223.27

Steps executed: 1000 Episode length: 1000 Return: -113.30540547321061
I0901 23:45:15.130341 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.31
INFO:tensorflow:Starting iteration 7
I0901 23:45:19.554327 140053067847680 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 219.15

Steps executed: 437 Episode length: 437 Return: -199.4864263965861361
I0901 23:45:24.859759 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.49
INFO:tensorflow:Starting iteration 8
I0901 23:45:29.221761 140053067847680 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 220.60

Steps executed: 429 Episode length: 429 Return: -475.6204414967488761
I0901 23:45:34.534155 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -475.62
INFO:tensorflow:Starting iteration 9
I0901 23:45:38.887131 140053067847680 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 221.44

Steps executed: 1000 Episode length: 1000 Return: -128.86425048312891
I0901 23:45:45.317067 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.86
INFO:tensorflow:Starting iteration 10
I0901 23:45:49.681424 140053067847680 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 220.59

Steps executed: 682 Episode length: 682 Return: -234.9067062539400391
I0901 23:45:55.491771 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -234.91
INFO:tensorflow:Starting iteration 11
I0901 23:45:59.665611 140053067847680 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 221.68
I0901 23:46:04.177377 140053067847680 replay_runner.py:36] Average training steps per second: 221.68

Steps executed: 266 Episode length: 266 Return: -253.9348880166926391
INFO:tensorflow:Starting iteration 12
I0901 23:46:08.827630 140053067847680 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 222.36

Steps executed: 1000 Episode length: 1000 Return: -124.77400565514745
I0901 23:46:16.837589 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.77
INFO:tensorflow:Starting iteration 13
I0901 23:46:20.996034 140053067847680 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 221.78

Steps executed: 1000 Episode length: 1000 Return: -327.59217432127775
I0901 23:46:28.944105 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.59
INFO:tensorflow:Starting iteration 14
I0901 23:46:33.307890 140053067847680 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 223.92

Steps executed: 1000 Episode length: 1000 Return: -170.19197696873704
I0901 23:46:41.481181 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.19
INFO:tensorflow:Starting iteration 15
I0901 23:46:45.664595 140053067847680 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 222.57


Steps executed: 1053 Episode length: 1000 Return: -88.286376213960544
I0901 23:46:53.706006 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.57
INFO:tensorflow:Starting iteration 16
I0901 23:46:57.967075 140053067847680 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 214.34

Steps executed: 477 Episode length: 371 Return: -633.4639324706013544
I0901 23:47:03.299367 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -456.66
INFO:tensorflow:Starting iteration 17
I0901 23:47:07.582857 140053067847680 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 220.70
I0901 23:47:12.114143 140053067847680 replay_runner.py:36] Average training steps per second: 220.70

Steps executed: 1000 Episode length: 1000 Return: -101.13035227180054
INFO:tensorflow:Starting iteration 18

Steps executed: 244 Episode length: 126 Return: -377.0517486085143454
INFO:tensorflow:Average training steps per second: 229.01
I0901 23:47:25.334919 140053067847680 replay_runner.py:36] Average training steps per second: 229.01
I0901 23:47:25.533518 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -349.98
INFO:tensorflow:Starting iteration 19

Steps executed: 268 Episode length: 133 Return: -279.6071562604325454
INFO:tensorflow:Average training steps per second: 232.79
I0901 23:47:34.185092 140053067847680 replay_runner.py:36] Average training steps per second: 232.79
I0901 23:47:34.376060 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.04
INFO:tensorflow:Starting iteration 20
I0901 23:47:38.523046 140053067847680 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 224.01

Steps executed: 223 Episode length: 223 Return: 28.954851881713385454
I0901 23:47:43.204694 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: 28.95
INFO:tensorflow:Starting iteration 21

Steps executed: 253 Episode length: 116 Return: -412.8827363344412354
INFO:tensorflow:Average training steps per second: 229.34
I0901 23:47:51.750876 140053067847680 replay_runner.py:36] Average training steps per second: 229.34
I0901 23:47:51.967061 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.33
INFO:tensorflow:Starting iteration 22
I0901 23:47:56.333613 140053067847680 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 229.43
I0901 23:48:00.692449 140053067847680 replay_runner.py:36] Average training steps per second: 229.43

Steps executed: 273 Episode length: 273 Return: -570.7141676908112354
INFO:tensorflow:Starting iteration 23
I0901 23:48:05.494457 140053067847680 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 225.20

Steps executed: 678 Episode length: 678 Return: -309.1405967604344354
I0901 23:48:11.414725 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.14
INFO:tensorflow:Starting iteration 24

Steps executed: 218 Episode length: 218 Return: -245.3209929429261354
INFO:tensorflow:Average training steps per second: 221.00
I0901 23:48:20.129591 140053067847680 replay_runner.py:36] Average training steps per second: 221.00
I0901 23:48:20.369358 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.32
INFO:tensorflow:Starting iteration 25
I0901 23:48:24.812715 140053067847680 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 223.55

Steps executed: 242 Episode length: 119 Return: -744.1443875835274354
I0901 23:48:29.505054 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: -739.62
INFO:tensorflow:Starting iteration 26
I0901 23:48:33.833319 140053067847680 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 221.96

Steps executed: 720 Episode length: 720 Return: 130.03461338537178354
I0901 23:48:40.675616 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: 130.03
INFO:tensorflow:Starting iteration 27
I0901 23:48:45.012713 140053067847680 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 220.17

Steps executed: 839 Episode length: 839 Return: 191.94632600537204354
I0901 23:48:51.710183 140053067847680 run_experiment.py:428] Average undiscounted return per evaluation episode: 191.95
INFO:tensorflow:Starting iteration 28
I0901 23:48:55.910980 140053067847680 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 224.67
I0901 23:49:00.362349 140053067847680 replay_runner.py:36] Average training steps per second: 224.67

Steps executed: 955 Episode length: 955 Return: 133.85684517855665354
INFO:tensorflow:Starting iteration 29

Steps executed: 209 Episode length: 209 Return: -6.319078578930728354
INFO:tensorflow:Average training steps per second: 228.66
I0901 23:49:12.150000 140053067847680 replay_runner.py:36] Average training steps per second: 228.66

Done fixed training!Episode length: 209 Return: -6.319078578930728354