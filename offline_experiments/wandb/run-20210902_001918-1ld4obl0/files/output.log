I0902 00:19:23.988919 140252174653440 run_experiment.py:549] Creating TrainRunner ...
I0902 00:19:23.996520 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:19:23.996653 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:19:23.996726 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:19:23.996787 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:19:23.996841 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0902 00:19:23.996920 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:19:23.997019 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:19:23.997078 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:19:23.997141 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:19:23.997216 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0902 00:19:23.997276 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:19:23.997338 140252174653440 dqn_agent.py:283] 	 seed: 1630541963996483
I0902 00:19:23.999505 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:19:23.999640 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:19:23.999727 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:19:23.999798 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:19:23.999916 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:19:24.000041 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:19:24.000134 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:19:24.000199 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:19:24.000267 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:19:24.024995 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:24.277710 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:24.287060 140252174653440 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:19:24.293393 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:19:24.293524 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:19:24.293603 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:19:24.293664 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:19:24.293721 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0902 00:19:24.293795 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:19:24.293881 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:19:24.293949 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:19:24.294006 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:19:24.294081 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0902 00:19:24.294148 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:19:24.294222 140252174653440 dqn_agent.py:283] 	 seed: 1630541964293362
I0902 00:19:24.295617 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:19:24.295723 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:19:24.295793 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:19:24.295855 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:19:24.295912 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:19:24.296007 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:19:24.296071 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:19:24.296125 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:19:24.296202 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:19:24.315612 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:24.330839 140252174653440 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:19:24.330985 140252174653440 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 240.10
I0902 00:19:28.496109 140252174653440 replay_runner.py:36] Average training steps per second: 240.10
I0902 00:19:29.174586 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -504.52
Steps executed: 276 Episode length: 120 Return: -536.6889871366213
INFO:tensorflow:Starting iteration 1
I0902 00:19:32.502480 140252174653440 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 328.81

Steps executed: 322 Episode length: 179 Return: -421.2074736170449
I0902 00:19:35.743077 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -390.67
INFO:tensorflow:Starting iteration 2
I0902 00:19:38.996997 140252174653440 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 346.23

Steps executed: 1000 Episode length: 1000 Return: -41.690909715294424
I0902 00:19:44.083137 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -41.69
INFO:tensorflow:Starting iteration 3

Steps executed: 542 Episode length: 542 Return: -128.3325877667387524
INFO:tensorflow:Average training steps per second: 336.72
I0902 00:19:50.271076 140252174653440 replay_runner.py:36] Average training steps per second: 336.72
I0902 00:19:50.899464 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.33
INFO:tensorflow:Starting iteration 4
I0902 00:19:54.325134 140252174653440 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 342.58

Steps executed: 1000 Episode length: 1000 Return: -160.72258760598004
I0902 00:19:58.503525 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.72
INFO:tensorflow:Starting iteration 5
I0902 00:20:01.891208 140252174653440 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 340.64

Steps executed: 1000 Episode length: 1000 Return: -102.71154852399918
I0902 00:20:06.627267 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -102.71
INFO:tensorflow:Starting iteration 6
I0902 00:20:09.963401 140252174653440 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 324.31

Steps executed: 1000 Episode length: 1000 Return: -171.83343414707668
I0902 00:20:15.405949 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.83
INFO:tensorflow:Starting iteration 7
I0902 00:20:18.776078 140252174653440 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 330.38

Steps executed: 1000 Episode length: 1000 Return: -175.73877030219128
I0902 00:20:23.606340 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.74
INFO:tensorflow:Starting iteration 8
I0902 00:20:26.953194 140252174653440 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 351.56

Steps executed: 1000 Episode length: 1000 Return: -207.35306762947718
I0902 00:20:31.543962 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.35
INFO:tensorflow:Starting iteration 9
I0902 00:20:34.937043 140252174653440 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 362.44

Steps executed: 1000 Episode length: 1000 Return: -191.55436939148657
I0902 00:20:39.913615 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.55
INFO:tensorflow:Starting iteration 10
I0902 00:20:43.184957 140252174653440 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 354.81

Steps executed: 1000 Episode length: 1000 Return: -215.91741781633797
I0902 00:20:47.573323 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -215.92
INFO:tensorflow:Starting iteration 11
I0902 00:20:50.827464 140252174653440 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 358.76

Steps executed: 1000 Episode length: 1000 Return: -74.673574244336497
I0902 00:20:55.318411 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.67
INFO:tensorflow:Starting iteration 12
I0902 00:20:58.586477 140252174653440 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 374.20

Steps executed: 783 Episode length: 783 Return: -134.7104028606857497
I0902 00:21:02.388309 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.71
INFO:tensorflow:Starting iteration 13
I0902 00:21:05.838929 140252174653440 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 379.07

Steps executed: 1000 Episode length: 1000 Return: -123.49617162165809
I0902 00:21:11.046243 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.50
INFO:tensorflow:Starting iteration 14
I0902 00:21:14.217351 140252174653440 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 352.02

Steps executed: 1000 Episode length: 1000 Return: -110.18141747503897
I0902 00:21:19.394854 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -110.18
INFO:tensorflow:Starting iteration 15
I0902 00:21:22.487534 140252174653440 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 343.47

Steps executed: 974 Episode length: 974 Return: -157.0487734989445497
I0902 00:21:27.804469 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -157.05
INFO:tensorflow:Starting iteration 16
I0902 00:21:30.911425 140252174653440 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 312.83

Steps executed: 410 Episode length: 410 Return: -115.5074076044913597
I0902 00:21:34.567137 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.51
INFO:tensorflow:Starting iteration 17

Steps executed: 253 Episode length: 253 Return: 29.560543461130038597
INFO:tensorflow:Average training steps per second: 320.41
I0902 00:21:41.001485 140252174653440 replay_runner.py:36] Average training steps per second: 320.41
I0902 00:21:41.197587 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: 29.56
INFO:tensorflow:Starting iteration 18

Steps executed: 330 Episode length: 171 Return: -23.29274821593297497
INFO:tensorflow:Average training steps per second: 333.92
I0902 00:21:47.486357 140252174653440 replay_runner.py:36] Average training steps per second: 333.92
I0902 00:21:47.722365 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: 7.61
INFO:tensorflow:Starting iteration 19

Steps executed: 363 Episode length: 363 Return: -9.034947161215413497
INFO:tensorflow:Average training steps per second: 336.00
I0902 00:21:54.044562 140252174653440 replay_runner.py:36] Average training steps per second: 336.00
I0902 00:21:54.395558 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -9.03
INFO:tensorflow:Starting iteration 20

Steps executed: 797 Episode length: 797 Return: -412.9004573101653497
INFO:tensorflow:Average training steps per second: 353.20
I0902 00:22:00.633981 140252174653440 replay_runner.py:36] Average training steps per second: 353.20
I0902 00:22:01.825184 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -412.90
INFO:tensorflow:Starting iteration 21
I0902 00:22:05.223024 140252174653440 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 343.75

Steps executed: 1000 Episode length: 1000 Return: -4.1638809598555497
I0902 00:22:10.577064 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -4.16
INFO:tensorflow:Starting iteration 22

Steps executed: 328 Episode length: 164 Return: -27.46950265208792597
INFO:tensorflow:Average training steps per second: 327.12
I0902 00:22:16.923283 140252174653440 replay_runner.py:36] Average training steps per second: 327.12
I0902 00:22:17.127511 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -41.30
INFO:tensorflow:Starting iteration 23

Steps executed: 337 Episode length: 337 Return: -607.0509436733958597
INFO:tensorflow:Average training steps per second: 330.79
I0902 00:22:23.443365 140252174653440 replay_runner.py:36] Average training steps per second: 330.79
I0902 00:22:23.806082 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -607.05
INFO:tensorflow:Starting iteration 24

Steps executed: 169 Episode length: 169 Return: -17.04105522127163497
INFO:tensorflow:Average training steps per second: 343.85

Steps executed: 809 Episode length: 640 Return: -642.0957691241186497
I0902 00:22:31.124857 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.57
INFO:tensorflow:Starting iteration 25

Steps executed: 411 Episode length: 313 Return: -1.856797571826405197
INFO:tensorflow:Average training steps per second: 344.59
I0902 00:22:37.419955 140252174653440 replay_runner.py:36] Average training steps per second: 344.59
I0902 00:22:37.750751 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.39
INFO:tensorflow:Starting iteration 26
I0902 00:22:41.157941 140252174653440 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 353.41

Steps executed: 1000 Episode length: 1000 Return: 93.4632060516001197
I0902 00:22:45.636766 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: 93.46
INFO:tensorflow:Starting iteration 27

Steps executed: 222 Episode length: 222 Return: -212.0462446271209197
INFO:tensorflow:Average training steps per second: 360.22
I0902 00:22:51.927881 140252174653440 replay_runner.py:36] Average training steps per second: 360.22
I0902 00:22:52.083581 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -212.05
INFO:tensorflow:Starting iteration 28

Steps executed: 347 Episode length: 158 Return: -123.0339442975980597
INFO:tensorflow:Average training steps per second: 332.61
I0902 00:22:58.437058 140252174653440 replay_runner.py:36] Average training steps per second: 332.61
I0902 00:22:58.647284 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -74.21
INFO:tensorflow:Starting iteration 29

Steps executed: 560 Episode length: 560 Return: -73.12665521468908597
INFO:tensorflow:Average training steps per second: 329.75
I0902 00:23:04.967684 140252174653440 replay_runner.py:36] Average training steps per second: 329.75

Done fixed training!Episode length: 560 Return: -73.12665521468908597