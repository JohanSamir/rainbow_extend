Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 23:34:24.240194 140413705484288 run_experiment.py:549] Creating TrainRunner ...
I0901 23:34:24.252861 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:34:24.253113 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:34:24.253226 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:34:24.253346 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:34:24.253465 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0901 23:34:24.253569 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:34:24.253707 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:34:24.253786 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:34:24.253865 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:34:24.253932 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0901 23:34:24.254010 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:34:24.254089 140413705484288 dqn_agent.py:283] 	 seed: 1630539264252781
I0901 23:34:24.257111 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:34:24.257384 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:34:24.257784 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:34:24.258012 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:34:24.258204 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:34:24.258347 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:34:24.258768 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:34:24.258949 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:34:24.259101 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:34:24.304887 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:24.760872 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:24.774961 140413705484288 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:34:24.785404 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:34:24.785677 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:34:24.785877 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:34:24.786154 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:34:24.786350 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0901 23:34:24.786485 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:34:24.786653 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:34:24.786793 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:34:24.786884 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:34:24.786957 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0901 23:34:24.787031 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:34:24.787125 140413705484288 dqn_agent.py:283] 	 seed: 1630539264785329
I0901 23:34:24.789945 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:34:24.790194 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:34:24.790390 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:34:24.790515 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:34:24.790662 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:34:24.790748 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:34:24.790862 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:34:24.791260 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:34:24.791472 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:34:24.818768 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:34:24.842999 140413705484288 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:34:24.843274 140413705484288 replay_runner.py:41] Starting iteration 0
Steps executed: 216 Episode length: 74 Return: -125.13432395325609
INFO:tensorflow:Average training steps per second: 172.60
I0901 23:34:30.637445 140413705484288 replay_runner.py:36] Average training steps per second: 172.60
I0901 23:34:31.674379 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.06
INFO:tensorflow:Starting iteration 1

Steps executed: 207 Episode length: 71 Return: -117.59571712289494
INFO:tensorflow:Average training steps per second: 233.88
I0901 23:34:40.325314 140413705484288 replay_runner.py:36] Average training steps per second: 233.88
I0901 23:34:40.450917 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.22
INFO:tensorflow:Starting iteration 2

Steps executed: 244 Episode length: 76 Return: -135.92171794717942
INFO:tensorflow:Average training steps per second: 232.02
I0901 23:34:49.165887 140413705484288 replay_runner.py:36] Average training steps per second: 232.02
I0901 23:34:49.326212 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.67
INFO:tensorflow:Starting iteration 3

Steps executed: 257 Episode length: 89 Return: -90.796917008156182
INFO:tensorflow:Average training steps per second: 230.95
I0901 23:34:58.014902 140413705484288 replay_runner.py:36] Average training steps per second: 230.95
I0901 23:34:58.186458 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.56
INFO:tensorflow:Starting iteration 4

Steps executed: 205 Episode length: 68 Return: -117.79673194274199
INFO:tensorflow:Average training steps per second: 244.56
I0901 23:35:06.571014 140413705484288 replay_runner.py:36] Average training steps per second: 244.56
I0901 23:35:06.687679 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -130.50
INFO:tensorflow:Starting iteration 5

Steps executed: 224 Episode length: 82 Return: -137.21879850739674
INFO:tensorflow:Average training steps per second: 276.44
I0901 23:35:14.745832 140413705484288 replay_runner.py:36] Average training steps per second: 276.44
I0901 23:35:14.864583 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.60
INFO:tensorflow:Starting iteration 6

Steps executed: 209 Episode length: 53 Return: -131.94238265772046
INFO:tensorflow:Average training steps per second: 240.19
I0901 23:35:23.114488 140413705484288 replay_runner.py:36] Average training steps per second: 240.19
I0901 23:35:23.228228 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.98
INFO:tensorflow:Starting iteration 7

Steps executed: 222 Episode length: 58 Return: -149.19378868066537
INFO:tensorflow:Average training steps per second: 236.39
I0901 23:35:31.673611 140413705484288 replay_runner.py:36] Average training steps per second: 236.39
I0901 23:35:31.814295 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.44
INFO:tensorflow:Starting iteration 8

Steps executed: 252 Episode length: 90 Return: -179.19276098745934
INFO:tensorflow:Average training steps per second: 231.54
I0901 23:35:40.520839 140413705484288 replay_runner.py:36] Average training steps per second: 231.54
I0901 23:35:40.690500 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.85
INFO:tensorflow:Starting iteration 9

Steps executed: 213 Episode length: 74 Return: -111.40790446672335
INFO:tensorflow:Average training steps per second: 230.79
I0901 23:35:49.469525 140413705484288 replay_runner.py:36] Average training steps per second: 230.79
I0901 23:35:49.604356 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -142.32
INFO:tensorflow:Starting iteration 10
I0901 23:35:53.948973 140413705484288 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 234.12

Steps executed: 217 Episode length: 75 Return: -138.69600352439696
I0901 23:35:58.364452 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.43
INFO:tensorflow:Starting iteration 11

Steps executed: 225 Episode length: 65 Return: -158.07462553805294
INFO:tensorflow:Average training steps per second: 226.20
I0901 23:36:07.159300 140413705484288 replay_runner.py:36] Average training steps per second: 226.20
I0901 23:36:07.303966 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -121.12
INFO:tensorflow:Starting iteration 12

Steps executed: 209 Episode length: 72 Return: -123.33377064964193
INFO:tensorflow:Average training steps per second: 227.22
I0901 23:36:16.033378 140413705484288 replay_runner.py:36] Average training steps per second: 227.22
I0901 23:36:16.162618 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -132.18
INFO:tensorflow:Starting iteration 13

Steps executed: 250 Episode length: 61 Return: -125.69734370521157
INFO:tensorflow:Average training steps per second: 235.45
I0901 23:36:24.831428 140413705484288 replay_runner.py:36] Average training steps per second: 235.45
I0901 23:36:24.986579 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -137.41
INFO:tensorflow:Starting iteration 14

Steps executed: 209 Episode length: 90 Return: -83.483886168161065
INFO:tensorflow:Average training steps per second: 231.25
I0901 23:36:33.655170 140413705484288 replay_runner.py:36] Average training steps per second: 231.25
I0901 23:36:33.793424 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.25
INFO:tensorflow:Starting iteration 15
I0901 23:36:38.171336 140413705484288 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 226.65

Steps executed: 240 Episode length: 83 Return: -197.12603334965934
I0901 23:36:42.750004 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.08
INFO:tensorflow:Starting iteration 16

Steps executed: 278 Episode length: 82 Return: -153.12388773161456
INFO:tensorflow:Average training steps per second: 225.64
I0901 23:36:51.507817 140413705484288 replay_runner.py:36] Average training steps per second: 225.64
I0901 23:36:51.687704 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.86
INFO:tensorflow:Starting iteration 17
I0901 23:36:56.076849 140413705484288 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 226.28
I0901 23:37:00.496468 140413705484288 replay_runner.py:36] Average training steps per second: 226.28

Steps executed: 243 Episode length: 87 Return: -181.01562104963426
INFO:tensorflow:Starting iteration 18

Steps executed: 200 Episode length: 62 Return: -152.92204086946725
INFO:tensorflow:Average training steps per second: 227.31
I0901 23:37:09.417934 140413705484288 replay_runner.py:36] Average training steps per second: 227.31
I0901 23:37:09.540215 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.88
INFO:tensorflow:Starting iteration 19
I0901 23:37:13.929976 140413705484288 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 229.28
I0901 23:37:18.291889 140413705484288 replay_runner.py:36] Average training steps per second: 229.28

Steps executed: 236 Episode length: 93 Return: -172.36588344413332
INFO:tensorflow:Starting iteration 20

Steps executed: 248 Episode length: 88 Return: -128.92575418121888
INFO:tensorflow:Average training steps per second: 228.34
I0901 23:37:27.176540 140413705484288 replay_runner.py:36] Average training steps per second: 228.34
I0901 23:37:27.344098 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.02
INFO:tensorflow:Starting iteration 21

Steps executed: 140 Episode length: 81 Return: -125.98277849635138
INFO:tensorflow:Average training steps per second: 222.81
I0901 23:37:36.161581 140413705484288 replay_runner.py:36] Average training steps per second: 222.81

Steps executed: 220 Episode length: 80 Return: -166.16057601690756
INFO:tensorflow:Starting iteration 22

Steps executed: 204 Episode length: 64 Return: -167.31464340732987
INFO:tensorflow:Average training steps per second: 223.82
I0901 23:37:45.083223 140413705484288 replay_runner.py:36] Average training steps per second: 223.82
I0901 23:37:45.208217 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.47
INFO:tensorflow:Starting iteration 23

Steps executed: 214 Episode length: 72 Return: 11.3061769282950882
INFO:tensorflow:Average training steps per second: 225.28
I0901 23:37:54.019870 140413705484288 replay_runner.py:36] Average training steps per second: 225.28
I0901 23:37:54.154466 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.71
INFO:tensorflow:Starting iteration 24

Steps executed: 251 Episode length: 71 Return: -127.18957508204565
INFO:tensorflow:Average training steps per second: 236.68
I0901 23:38:02.680455 140413705484288 replay_runner.py:36] Average training steps per second: 236.68
I0901 23:38:02.817538 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -117.26
INFO:tensorflow:Starting iteration 25

Steps executed: 218 Episode length: 83 Return: -102.55430971839883
INFO:tensorflow:Average training steps per second: 233.82
I0901 23:38:11.460913 140413705484288 replay_runner.py:36] Average training steps per second: 233.82
I0901 23:38:11.588055 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -129.91
INFO:tensorflow:Starting iteration 26

Steps executed: 264 Episode length: 75 Return: -139.27762140352962
INFO:tensorflow:Average training steps per second: 238.69
I0901 23:38:19.960864 140413705484288 replay_runner.py:36] Average training steps per second: 238.69
I0901 23:38:20.130580 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.40
INFO:tensorflow:Starting iteration 27

Steps executed: 141 Episode length: 83 Return: -143.16876692452368
INFO:tensorflow:Average training steps per second: 237.18
I0901 23:38:28.479609 140413705484288 replay_runner.py:36] Average training steps per second: 237.18

Steps executed: 205 Episode length: 64 Return: -152.70729721403868
INFO:tensorflow:Starting iteration 28

Steps executed: 213 Episode length: 67 Return: -133.92783095087992
INFO:tensorflow:Average training steps per second: 232.76
I0901 23:38:37.004584 140413705484288 replay_runner.py:36] Average training steps per second: 232.76
I0901 23:38:37.139462 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -160.51
INFO:tensorflow:Starting iteration 29

Steps executed: 241 Episode length: 75 Return: -143.57390866638434
INFO:tensorflow:Average training steps per second: 227.91
I0901 23:38:45.779889 140413705484288 replay_runner.py:36] Average training steps per second: 227.91

Done fixed training!Episode length: 75 Return: -143.57390866638434