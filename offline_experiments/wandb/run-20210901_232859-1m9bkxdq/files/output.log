I0901 23:29:06.037943 139919604459520 run_experiment.py:549] Creating TrainRunner ...
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0901 23:29:06.038504 139919604459520 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0901 23:29:06.101275 139919604459520 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:29:06.102500 139919604459520 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:29:06.102585 139919604459520 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:29:06.102679 139919604459520 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:29:06.102761 139919604459520 dqn_agent.py:275] 	 update_period: 4
I0901 23:29:06.102816 139919604459520 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:29:06.102909 139919604459520 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:29:06.103024 139919604459520 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:29:06.103090 139919604459520 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:29:06.103184 139919604459520 dqn_agent.py:280] 	 optimizer: adam
I0901 23:29:06.103267 139919604459520 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:29:06.103351 139919604459520 dqn_agent.py:283] 	 seed: 1630538946101220
I0901 23:29:06.105296 139919604459520 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:29:06.105454 139919604459520 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 23:29:06.105545 139919604459520 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:29:06.105634 139919604459520 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:29:06.105694 139919604459520 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:29:06.105793 139919604459520 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:29:06.105878 139919604459520 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:29:06.105977 139919604459520 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:29:06.106057 139919604459520 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in acrobot
I0901 23:29:12.924101 139919604459520 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:29:13.429548 139919604459520 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:29:13.452678 139919604459520 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:29:13.473272 139919604459520 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:29:13.476348 139919604459520 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:29:13.476899 139919604459520 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:29:13.477270 139919604459520 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:29:13.477643 139919604459520 dqn_agent.py:275] 	 update_period: 4
I0901 23:29:13.477999 139919604459520 dqn_agent.py:276] 	 target_update_period: 100
I0901 23:29:13.478374 139919604459520 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:29:13.478777 139919604459520 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:29:13.479145 139919604459520 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:29:13.479483 139919604459520 dqn_agent.py:280] 	 optimizer: adam
I0901 23:29:13.479794 139919604459520 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:29:13.480101 139919604459520 dqn_agent.py:283] 	 seed: 1630538953473214
I0901 23:29:13.483427 139919604459520 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:29:13.500646 139919604459520 circular_replay_buffer.py:156] 	 observation_shape: (6, 1)
I0901 23:29:13.501174 139919604459520 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:29:13.501779 139919604459520 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:29:13.502322 139919604459520 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:29:13.502679 139919604459520 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:29:13.502991 139919604459520 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:29:13.503295 139919604459520 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:29:13.503599 139919604459520 circular_replay_buffer.py:163] 	 gamma: 0.990000
Training fixed agent 2, please be patient, may be a while...
I0901 23:29:14.207551 139919604459520 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:29:14.363356 139919604459520 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:29:14.363687 139919604459520 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 113.13
I0901 23:29:23.203538 139919604459520 replay_runner.py:36] Average training steps per second: 113.13
Steps executed: 239 Episode length: 239 Return: -238.0
I0901 23:29:24.222288 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -238.00
INFO:tensorflow:Starting iteration 1
I0901 23:29:24.427520 139919604459520 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 203.86

Steps executed: 500 Episode length: 500 Return: -500.0
I0901 23:29:29.794135 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -500.00
INFO:tensorflow:Starting iteration 2

Steps executed: 360 Episode length: 213 Return: -212.0
INFO:tensorflow:Average training steps per second: 187.42
I0901 23:29:35.379566 139919604459520 replay_runner.py:36] Average training steps per second: 187.42
I0901 23:29:35.676056 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -179.00
INFO:tensorflow:Starting iteration 3

Steps executed: 313 Episode length: 129 Return: -128.0
INFO:tensorflow:Average training steps per second: 186.34
I0901 23:29:41.268130 139919604459520 replay_runner.py:36] Average training steps per second: 186.34
I0901 23:29:41.561651 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.33
INFO:tensorflow:Starting iteration 4

Steps executed: 352 Episode length: 178 Return: -177.0
INFO:tensorflow:Average training steps per second: 202.37
I0901 23:29:46.751762 139919604459520 replay_runner.py:36] Average training steps per second: 202.37
I0901 23:29:47.056853 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.00
INFO:tensorflow:Starting iteration 5

Steps executed: 258 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Average training steps per second: 185.05
I0901 23:29:52.697513 139919604459520 replay_runner.py:36] Average training steps per second: 185.05
I0901 23:29:52.910413 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.00
INFO:tensorflow:Starting iteration 6

Steps executed: 274 Episode length: 102 Return: -101.0
INFO:tensorflow:Average training steps per second: 202.63
I0901 23:29:58.073122 139919604459520 replay_runner.py:36] Average training steps per second: 202.63
I0901 23:29:58.307590 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.33
INFO:tensorflow:Starting iteration 7

Steps executed: 92 Episode length: 92 Return: -91.01.0
INFO:tensorflow:Average training steps per second: 190.69
I0901 23:30:03.791305 139919604459520 replay_runner.py:36] Average training steps per second: 190.69

Steps executed: 213 Episode length: 121 Return: -120.0
INFO:tensorflow:Starting iteration 8

Steps executed: 225 Episode length: 147 Return: -146.0
INFO:tensorflow:Average training steps per second: 206.49
I0901 23:30:09.044924 139919604459520 replay_runner.py:36] Average training steps per second: 206.49
I0901 23:30:09.239561 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.50
INFO:tensorflow:Starting iteration 9

Steps executed: 319 Episode length: 232 Return: -231.0
INFO:tensorflow:Average training steps per second: 192.72
I0901 23:30:14.648326 139919604459520 replay_runner.py:36] Average training steps per second: 192.72
I0901 23:30:14.915735 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.50
INFO:tensorflow:Starting iteration 10
I0901 23:30:15.164569 139919604459520 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 203.37

Steps executed: 594 Episode length: 500 Return: -500.0
I0901 23:30:20.589378 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -296.50
INFO:tensorflow:Starting iteration 11

Steps executed: 99 Episode length: 99 Return: -98.00.0
INFO:tensorflow:Average training steps per second: 194.47
I0901 23:30:25.973769 139919604459520 replay_runner.py:36] Average training steps per second: 194.47

Steps executed: 251 Episode length: 152 Return: -151.0
INFO:tensorflow:Starting iteration 12

Steps executed: 253 Episode length: 63 Return: -62.0.0
INFO:tensorflow:Average training steps per second: 198.81
I0901 23:30:31.488434 139919604459520 replay_runner.py:36] Average training steps per second: 198.81
I0901 23:30:31.688861 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.33
INFO:tensorflow:Starting iteration 13

Steps executed: 240 Episode length: 133 Return: -132.0
INFO:tensorflow:Average training steps per second: 198.62
I0901 23:30:36.959801 139919604459520 replay_runner.py:36] Average training steps per second: 198.62
I0901 23:30:37.171947 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.00
INFO:tensorflow:Starting iteration 14

Steps executed: 242 Episode length: 72 Return: -71.0.0
INFO:tensorflow:Average training steps per second: 200.07
I0901 23:30:42.424878 139919604459520 replay_runner.py:36] Average training steps per second: 200.07
I0901 23:30:42.627218 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.67
INFO:tensorflow:Starting iteration 15

Steps executed: 250 Episode length: 76 Return: -75.0.0
INFO:tensorflow:Average training steps per second: 197.55
I0901 23:30:47.923303 139919604459520 replay_runner.py:36] Average training steps per second: 197.55
I0901 23:30:48.156494 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.33
INFO:tensorflow:Starting iteration 16

Steps executed: 301 Episode length: 301 Return: -300.0
INFO:tensorflow:Average training steps per second: 193.16
I0901 23:30:53.568231 139919604459520 replay_runner.py:36] Average training steps per second: 193.16
I0901 23:30:53.817779 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -300.00
INFO:tensorflow:Starting iteration 17

Steps executed: 234 Episode length: 82 Return: -81.0.0
INFO:tensorflow:Average training steps per second: 199.42
I0901 23:30:59.086007 139919604459520 replay_runner.py:36] Average training steps per second: 199.42
I0901 23:30:59.295129 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.00
INFO:tensorflow:Starting iteration 18

Steps executed: 254 Episode length: 76 Return: -75.0.0
INFO:tensorflow:Average training steps per second: 196.02
I0901 23:31:04.651923 139919604459520 replay_runner.py:36] Average training steps per second: 196.02
I0901 23:31:04.850183 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.67
INFO:tensorflow:Starting iteration 19
I0901 23:31:05.085297 139919604459520 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 198.18

Steps executed: 233 Episode length: 86 Return: -85.0.0
I0901 23:31:10.343446 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.67
INFO:tensorflow:Starting iteration 20

Steps executed: 201 Episode length: 95 Return: -94.0.0
INFO:tensorflow:Average training steps per second: 197.26
I0901 23:31:15.674912 139919604459520 replay_runner.py:36] Average training steps per second: 197.26
I0901 23:31:15.845533 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.50
INFO:tensorflow:Starting iteration 21

Steps executed: 200 Episode length: 62 Return: -61.0.0
INFO:tensorflow:Average training steps per second: 196.21
I0901 23:31:21.191901 139919604459520 replay_runner.py:36] Average training steps per second: 196.21
I0901 23:31:21.366626 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.67
INFO:tensorflow:Starting iteration 22

Steps executed: 260 Episode length: 102 Return: -101.0
INFO:tensorflow:Average training steps per second: 196.86
I0901 23:31:26.692175 139919604459520 replay_runner.py:36] Average training steps per second: 196.86
I0901 23:31:26.914500 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.67
INFO:tensorflow:Starting iteration 23
I0901 23:31:27.151423 139919604459520 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 198.10
I0901 23:31:32.199956 139919604459520 replay_runner.py:36] Average training steps per second: 198.10

Steps executed: 220 Episode length: 71 Return: -70.0.0
INFO:tensorflow:Starting iteration 24

Steps executed: 273 Episode length: 108 Return: -107.0
INFO:tensorflow:Average training steps per second: 199.27
I0901 23:31:37.642782 139919604459520 replay_runner.py:36] Average training steps per second: 199.27
I0901 23:31:37.876132 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.00
INFO:tensorflow:Starting iteration 25

Steps executed: 270 Episode length: 96 Return: -95.0.0
INFO:tensorflow:Average training steps per second: 195.90
I0901 23:31:43.226671 139919604459520 replay_runner.py:36] Average training steps per second: 195.90
I0901 23:31:43.463177 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.00
INFO:tensorflow:Starting iteration 26

Steps executed: 216 Episode length: 129 Return: -128.0
INFO:tensorflow:Average training steps per second: 197.79
I0901 23:31:48.758196 139919604459520 replay_runner.py:36] Average training steps per second: 197.79
I0901 23:31:48.931797 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.00
INFO:tensorflow:Starting iteration 27

Steps executed: 133 Episode length: 133 Return: -132.0
INFO:tensorflow:Average training steps per second: 198.11
I0901 23:31:54.221352 139919604459520 replay_runner.py:36] Average training steps per second: 198.11

Steps executed: 226 Episode length: 93 Return: -92.0.0
INFO:tensorflow:Starting iteration 28

Steps executed: 228 Episode length: 113 Return: -112.0
INFO:tensorflow:Average training steps per second: 206.14
I0901 23:31:59.510206 139919604459520 replay_runner.py:36] Average training steps per second: 206.14
I0901 23:31:59.711498 139919604459520 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.00
INFO:tensorflow:Starting iteration 29
I0901 23:31:59.970843 139919604459520 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 202.35
I0901 23:32:04.913437 139919604459520 replay_runner.py:36] Average training steps per second: 202.35

Done fixed training!Episode length: 500 Return: -500.0