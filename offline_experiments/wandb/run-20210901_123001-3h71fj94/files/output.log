Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0901 12:30:08.166690 140240877414400 run_experiment.py:549] Creating TrainRunner ...
I0901 12:30:08.178508 140240877414400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:30:08.178849 140240877414400 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:30:08.179003 140240877414400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:30:08.179147 140240877414400 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:30:08.179250 140240877414400 dqn_agent.py:275] 	 update_period: 4
I0901 12:30:08.179386 140240877414400 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:30:08.179491 140240877414400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:30:08.179750 140240877414400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:30:08.179918 140240877414400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:30:08.179995 140240877414400 dqn_agent.py:280] 	 optimizer: adam
I0901 12:30:08.180177 140240877414400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:30:08.180299 140240877414400 dqn_agent.py:283] 	 seed: 1630499408178439
I0901 12:30:08.183336 140240877414400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:30:08.183544 140240877414400 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:30:08.183683 140240877414400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:30:08.183842 140240877414400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:30:08.183974 140240877414400 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:30:08.184082 140240877414400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:30:08.184275 140240877414400 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:30:08.184397 140240877414400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:30:08.184546 140240877414400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:30:08.392510 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:30:08.812455 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:30:08.827379 140240877414400 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:30:08.836281 140240877414400 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:30:08.836536 140240877414400 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:30:08.836684 140240877414400 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:30:08.836871 140240877414400 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:30:08.836995 140240877414400 dqn_agent.py:275] 	 update_period: 4
I0901 12:30:08.837110 140240877414400 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:30:08.837224 140240877414400 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:30:08.837617 140240877414400 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:30:08.837813 140240877414400 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:30:08.838281 140240877414400 dqn_agent.py:280] 	 optimizer: adam
I0901 12:30:08.838462 140240877414400 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:30:08.838642 140240877414400 dqn_agent.py:283] 	 seed: 1630499408836226
I0901 12:30:08.841202 140240877414400 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:30:08.841363 140240877414400 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:30:08.841476 140240877414400 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:30:08.841595 140240877414400 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:30:08.841738 140240877414400 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:30:08.841838 140240877414400 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:30:08.841927 140240877414400 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:30:08.842012 140240877414400 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:30:08.842105 140240877414400 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:30:08.879529 140240877414400 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:30:08.904095 140240877414400 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:30:08.904472 140240877414400 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 157.62
I0901 12:30:15.249078 140240877414400 replay_runner.py:36] Average training steps per second: 157.62
Steps executed: 354 Episode length: 162 Return: -612.4379909955055
I0901 12:30:16.621052 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -364.43
INFO:tensorflow:Starting iteration 1

Steps executed: 227 Episode length: 86 Return: -656.09577333404597
INFO:tensorflow:Average training steps per second: 219.31
I0901 12:30:25.458185 140240877414400 replay_runner.py:36] Average training steps per second: 219.31
I0901 12:30:25.672245 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -570.34
INFO:tensorflow:Starting iteration 2

Steps executed: 234 Episode length: 144 Return: -248.23059649854923
INFO:tensorflow:Average training steps per second: 217.05
I0901 12:30:34.574528 140240877414400 replay_runner.py:36] Average training steps per second: 217.05
I0901 12:30:34.804511 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -222.05
INFO:tensorflow:Starting iteration 3
I0901 12:30:39.171541 140240877414400 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 219.07
I0901 12:30:43.736859 140240877414400 replay_runner.py:36] Average training steps per second: 219.07

Steps executed: 226 Episode length: 87 Return: -419.637462122225597
INFO:tensorflow:Starting iteration 4

Steps executed: 269 Episode length: 135 Return: -111.81438230857214
INFO:tensorflow:Average training steps per second: 229.47
I0901 12:30:52.647287 140240877414400 replay_runner.py:36] Average training steps per second: 229.47
I0901 12:30:52.882016 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.71
INFO:tensorflow:Starting iteration 5

Steps executed: 319 Episode length: 132 Return: -168.99723586681144
INFO:tensorflow:Average training steps per second: 233.52
I0901 12:31:01.466004 140240877414400 replay_runner.py:36] Average training steps per second: 233.52
I0901 12:31:01.746632 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -260.45
INFO:tensorflow:Starting iteration 6

Steps executed: 322 Episode length: 147 Return: 4.10315938308923544
INFO:tensorflow:Average training steps per second: 229.38
I0901 12:31:10.468678 140240877414400 replay_runner.py:36] Average training steps per second: 229.38
I0901 12:31:10.744994 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -326.01
INFO:tensorflow:Starting iteration 7

Steps executed: 306 Episode length: 109 Return: -15.340880301518283
INFO:tensorflow:Average training steps per second: 222.71
I0901 12:31:19.600513 140240877414400 replay_runner.py:36] Average training steps per second: 222.71
I0901 12:31:19.874148 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -75.55
INFO:tensorflow:Starting iteration 8

Steps executed: 268 Episode length: 132 Return: -431.47661503616864
INFO:tensorflow:Average training steps per second: 224.91
I0901 12:31:28.618664 140240877414400 replay_runner.py:36] Average training steps per second: 224.91
I0901 12:31:28.862929 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -407.81
INFO:tensorflow:Starting iteration 9

Steps executed: 226 Episode length: 77 Return: -290.759615891618954
INFO:tensorflow:Average training steps per second: 231.24
I0901 12:31:37.579670 140240877414400 replay_runner.py:36] Average training steps per second: 231.24
I0901 12:31:37.744394 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.32
INFO:tensorflow:Starting iteration 10

Steps executed: 381 Episode length: 198 Return: -116.10685428204505
INFO:tensorflow:Average training steps per second: 225.11
I0901 12:31:46.582359 140240877414400 replay_runner.py:36] Average training steps per second: 225.11
I0901 12:31:46.924269 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -307.27
INFO:tensorflow:Starting iteration 11

Steps executed: 324 Episode length: 129 Return: -346.85547737498666
INFO:tensorflow:Average training steps per second: 221.09
I0901 12:31:55.727578 140240877414400 replay_runner.py:36] Average training steps per second: 221.09
I0901 12:31:56.020718 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -356.16
INFO:tensorflow:Starting iteration 12

Steps executed: 285 Episode length: 86 Return: -327.289988613611566
INFO:tensorflow:Average training steps per second: 221.47
I0901 12:32:04.878688 140240877414400 replay_runner.py:36] Average training steps per second: 221.47
I0901 12:32:05.109960 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.08
INFO:tensorflow:Starting iteration 13

Steps executed: 222 Episode length: 88 Return: -273.779722208043846
INFO:tensorflow:Average training steps per second: 219.32
I0901 12:32:14.073999 140240877414400 replay_runner.py:36] Average training steps per second: 219.32
I0901 12:32:14.260168 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -178.41
INFO:tensorflow:Starting iteration 14

Steps executed: 229 Episode length: 110 Return: -221.76546480940917
INFO:tensorflow:Average training steps per second: 223.37
I0901 12:32:23.125964 140240877414400 replay_runner.py:36] Average training steps per second: 223.37
I0901 12:32:23.345632 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -201.54
INFO:tensorflow:Starting iteration 15

Steps executed: 203 Episode length: 88 Return: -352.902673364631777
INFO:tensorflow:Average training steps per second: 216.47
I0901 12:32:32.244210 140240877414400 replay_runner.py:36] Average training steps per second: 216.47
I0901 12:32:32.397339 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -256.62
INFO:tensorflow:Starting iteration 16

Steps executed: 245 Episode length: 131 Return: -249.98088783310544
INFO:tensorflow:Average training steps per second: 216.21
I0901 12:32:41.382052 140240877414400 replay_runner.py:36] Average training steps per second: 216.21
I0901 12:32:41.628819 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.92
INFO:tensorflow:Starting iteration 17

Steps executed: 213 Episode length: 63 Return: -153.002144201479784
INFO:tensorflow:Average training steps per second: 215.62
I0901 12:32:50.672272 140240877414400 replay_runner.py:36] Average training steps per second: 215.62
I0901 12:32:50.835735 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -173.24
INFO:tensorflow:Starting iteration 18

Steps executed: 226 Episode length: 133 Return: -319.87475943070064
INFO:tensorflow:Average training steps per second: 220.67
I0901 12:32:59.795485 140240877414400 replay_runner.py:36] Average training steps per second: 220.67
I0901 12:33:00.004013 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -308.84
INFO:tensorflow:Starting iteration 19

Steps executed: 243 Episode length: 56 Return: -169.255661101167334
INFO:tensorflow:Average training steps per second: 216.69
I0901 12:33:09.052568 140240877414400 replay_runner.py:36] Average training steps per second: 216.69
I0901 12:33:09.240764 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.88
INFO:tensorflow:Starting iteration 20
I0901 12:33:13.650191 140240877414400 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 217.18

Steps executed: 224 Episode length: 154 Return: -537.23413714735654
I0901 12:33:18.482052 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -505.12
INFO:tensorflow:Starting iteration 21

Steps executed: 278 Episode length: 82 Return: -131.626965589440774
INFO:tensorflow:Average training steps per second: 221.61
I0901 12:33:27.355573 140240877414400 replay_runner.py:36] Average training steps per second: 221.61
I0901 12:33:27.577302 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -156.75
INFO:tensorflow:Starting iteration 22

Steps executed: 284 Episode length: 284 Return: -571.29146578204224
INFO:tensorflow:Average training steps per second: 221.88
I0901 12:33:36.475967 140240877414400 replay_runner.py:36] Average training steps per second: 221.88
I0901 12:33:36.869275 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -571.29
INFO:tensorflow:Starting iteration 23

Steps executed: 301 Episode length: 111 Return: -438.75670913868345
INFO:tensorflow:Average training steps per second: 219.97
I0901 12:33:45.787828 140240877414400 replay_runner.py:36] Average training steps per second: 219.97
I0901 12:33:46.069106 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -430.88
INFO:tensorflow:Starting iteration 24

Steps executed: 251 Episode length: 136 Return: -358.01219426599687
INFO:tensorflow:Average training steps per second: 229.12
I0901 12:33:54.776461 140240877414400 replay_runner.py:36] Average training steps per second: 229.12
I0901 12:33:54.995752 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.26
INFO:tensorflow:Starting iteration 25

Steps executed: 245 Episode length: 129 Return: -232.32656572601957
INFO:tensorflow:Average training steps per second: 234.02
I0901 12:34:03.564554 140240877414400 replay_runner.py:36] Average training steps per second: 234.02
I0901 12:34:03.784743 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -138.62
INFO:tensorflow:Starting iteration 26

Steps executed: 235 Episode length: 163 Return: -253.35409944509362
INFO:tensorflow:Average training steps per second: 222.83
I0901 12:34:12.714730 140240877414400 replay_runner.py:36] Average training steps per second: 222.83
I0901 12:34:12.939519 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.31
INFO:tensorflow:Starting iteration 27

Steps executed: 258 Episode length: 77 Return: -17.7051741910105852
INFO:tensorflow:Average training steps per second: 217.19
I0901 12:34:22.013568 140240877414400 replay_runner.py:36] Average training steps per second: 217.19
I0901 12:34:22.210876 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -113.63
INFO:tensorflow:Starting iteration 28

Steps executed: 254 Episode length: 62 Return: -590.885075037400442
INFO:tensorflow:Average training steps per second: 223.96
I0901 12:34:31.112212 140240877414400 replay_runner.py:36] Average training steps per second: 223.96
I0901 12:34:31.347788 140240877414400 run_experiment.py:428] Average undiscounted return per evaluation episode: -511.64
INFO:tensorflow:Starting iteration 29

Steps executed: 147 Episode length: 63 Return: -121.770374689306072
INFO:tensorflow:Average training steps per second: 218.66
I0901 12:34:40.280107 140240877414400 replay_runner.py:36] Average training steps per second: 218.66


Done fixed training!Episode length: 173 Return: -748.31731829097052