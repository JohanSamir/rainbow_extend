Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0901 13:19:03.740862 140298343233536 run_experiment.py:549] Creating TrainRunner ...
I0901 13:19:03.749620 140298343233536 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:19:03.749785 140298343233536 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:19:03.749884 140298343233536 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:19:03.749975 140298343233536 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:19:03.750055 140298343233536 dqn_agent.py:275] 	 update_period: 4
I0901 13:19:03.750184 140298343233536 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:19:03.750312 140298343233536 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:19:03.750425 140298343233536 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:19:03.750512 140298343233536 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:19:03.750589 140298343233536 dqn_agent.py:280] 	 optimizer: adam
I0901 13:19:03.750696 140298343233536 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:19:03.750795 140298343233536 dqn_agent.py:283] 	 seed: 1630502343749578
I0901 13:19:03.753039 140298343233536 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:19:03.753182 140298343233536 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:19:03.753283 140298343233536 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:19:03.753371 140298343233536 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:19:03.753451 140298343233536 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:19:03.753532 140298343233536 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:19:03.753651 140298343233536 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:19:03.753744 140298343233536 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:19:03.753823 140298343233536 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:19:03.785595 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:04.075027 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:04.084818 140298343233536 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 13:19:04.093210 140298343233536 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 13:19:04.093426 140298343233536 dqn_agent.py:272] 	 gamma: 0.990000
I0901 13:19:04.093530 140298343233536 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 13:19:04.093611 140298343233536 dqn_agent.py:274] 	 min_replay_history: 500
I0901 13:19:04.093689 140298343233536 dqn_agent.py:275] 	 update_period: 4
I0901 13:19:04.093763 140298343233536 dqn_agent.py:276] 	 target_update_period: 300
I0901 13:19:04.093841 140298343233536 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 13:19:04.093944 140298343233536 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 13:19:04.094024 140298343233536 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 13:19:04.094103 140298343233536 dqn_agent.py:280] 	 optimizer: adam
I0901 13:19:04.094184 140298343233536 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 13:19:04.094240 140298343233536 dqn_agent.py:283] 	 seed: 1630502344093156
I0901 13:19:04.095743 140298343233536 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 13:19:04.095864 140298343233536 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 13:19:04.095937 140298343233536 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 13:19:04.096008 140298343233536 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 13:19:04.096065 140298343233536 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 13:19:04.096140 140298343233536 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 13:19:04.096199 140298343233536 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 13:19:04.096271 140298343233536 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 13:19:04.096339 140298343233536 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 13:19:04.120934 140298343233536 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 13:19:04.137927 140298343233536 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 13:19:04.138146 140298343233536 replay_runner.py:41] Starting iteration 0
Steps executed: 257 Episode length: 132 Return: -365.5917681316555
INFO:tensorflow:Average training steps per second: 238.57
I0901 13:19:08.329939 140298343233536 replay_runner.py:36] Average training steps per second: 238.57
I0901 13:19:09.048933 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -316.97
INFO:tensorflow:Starting iteration 1
I0901 13:19:12.426403 140298343233536 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 349.49

Steps executed: 288 Episode length: 182 Return: -10.403133857623004
I0901 13:19:15.420299 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.34
INFO:tensorflow:Starting iteration 2

Steps executed: 300 Episode length: 165 Return: -314.54496011919096
INFO:tensorflow:Average training steps per second: 337.47
I0901 13:19:21.578560 140298343233536 replay_runner.py:36] Average training steps per second: 337.47
I0901 13:19:21.811618 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -331.13
INFO:tensorflow:Starting iteration 3

Steps executed: 247 Episode length: 142 Return: -425.57191068530256
INFO:tensorflow:Average training steps per second: 346.57
I0901 13:19:28.122264 140298343233536 replay_runner.py:36] Average training steps per second: 346.57
I0901 13:19:28.253333 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -380.82
INFO:tensorflow:Starting iteration 4

Steps executed: 299 Episode length: 157 Return: -373.02144118195963
INFO:tensorflow:Average training steps per second: 350.70
I0901 13:19:34.674693 140298343233536 replay_runner.py:36] Average training steps per second: 350.70
I0901 13:19:34.836504 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -204.95
INFO:tensorflow:Starting iteration 5

Steps executed: 195 Episode length: 93 Return: -50.2800271260905666
INFO:tensorflow:Average training steps per second: 340.21

Steps executed: 1195 Episode length: 1000 Return: -78.05577148582678
I0901 13:19:43.912357 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -46.26
INFO:tensorflow:Starting iteration 6

Steps executed: 143 Episode length: 143 Return: -171.146495690981978
INFO:tensorflow:Average training steps per second: 326.69

Steps executed: 1011 Episode length: 868 Return: -1466.5834045858098
I0901 13:19:52.505487 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -818.86
INFO:tensorflow:Starting iteration 7

Steps executed: 266 Episode length: 90 Return: -180.9749082618602098
INFO:tensorflow:Average training steps per second: 318.82
I0901 13:19:59.039522 140298343233536 replay_runner.py:36] Average training steps per second: 318.82
I0901 13:19:59.171550 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.44
INFO:tensorflow:Starting iteration 8

Steps executed: 142 Episode length: 74 Return: -168.1715824580628698
INFO:tensorflow:Average training steps per second: 344.61

Steps executed: 643 Episode length: 501 Return: -291.699191454148798
I0901 13:20:06.098488 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -193.58
INFO:tensorflow:Starting iteration 9

Steps executed: 366 Episode length: 199 Return: -229.936318056389048
INFO:tensorflow:Average training steps per second: 340.29
I0901 13:20:12.457158 140298343233536 replay_runner.py:36] Average training steps per second: 340.29
I0901 13:20:12.730997 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -207.79
INFO:tensorflow:Starting iteration 10
I0901 13:20:16.141056 140298343233536 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 325.60

Steps executed: 467 Episode length: 467 Return: -288.479897994450348
I0901 13:20:19.846501 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.48
INFO:tensorflow:Starting iteration 11

Steps executed: 545 Episode length: 369 Return: -319.625803869569278
INFO:tensorflow:Average training steps per second: 320.29
I0901 13:20:26.361662 140298343233536 replay_runner.py:36] Average training steps per second: 320.29
I0901 13:20:26.977200 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -259.54
INFO:tensorflow:Starting iteration 12

Steps executed: 230 Episode length: 141 Return: -116.236723534258278
INFO:tensorflow:Average training steps per second: 330.08
I0901 13:20:33.300830 140298343233536 replay_runner.py:36] Average training steps per second: 330.08
I0901 13:20:33.444695 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.74
INFO:tensorflow:Starting iteration 13
I0901 13:20:36.748696 140298343233536 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 326.98

Steps executed: 250 Episode length: 54 Return: -351.6922450968238538
I0901 13:20:39.983515 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -299.59
INFO:tensorflow:Starting iteration 14
I0901 13:20:43.331749 140298343233536 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 341.53

Steps executed: 1000 Episode length: 1000 Return: -65.51410658395822
I0901 13:20:48.605540 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.51
INFO:tensorflow:Starting iteration 15
I0901 13:20:51.910501 140298343233536 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 320.94

Steps executed: 916 Episode length: 916 Return: -355.989969703756862
I0901 13:20:56.224888 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -355.99
INFO:tensorflow:Starting iteration 16
I0901 13:20:59.556507 140298343233536 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 321.81

Steps executed: 1000 Episode length: 1000 Return: -213.19624271543893
I0901 13:21:04.401469 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.20
INFO:tensorflow:Starting iteration 17

Steps executed: 364 Episode length: 220 Return: -86.31862775280385893
INFO:tensorflow:Average training steps per second: 318.64
I0901 13:21:10.848854 140298343233536 replay_runner.py:36] Average training steps per second: 318.64
I0901 13:21:11.075490 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -86.63
INFO:tensorflow:Starting iteration 18
I0901 13:21:14.384915 140298343233536 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 321.86

Steps executed: 564 Episode length: 564 Return: -119.3983598369849193
I0901 13:21:18.528780 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.40
INFO:tensorflow:Starting iteration 19
I0901 13:21:21.917793 140298343233536 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 325.67

Steps executed: 1000 Episode length: 1000 Return: -211.26828214046895
I0901 13:21:27.709168 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -211.27
INFO:tensorflow:Starting iteration 20
I0901 13:21:31.201048 140298343233536 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 349.42

Steps executed: 398 Episode length: 398 Return: -442.3493589702777895
I0901 13:21:34.522979 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -442.35
INFO:tensorflow:Starting iteration 21

Steps executed: 529 Episode length: 529 Return: -227.7235936060721195
INFO:tensorflow:Average training steps per second: 346.84
I0901 13:21:40.911615 140298343233536 replay_runner.py:36] Average training steps per second: 346.84
I0901 13:21:41.672215 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -227.72
INFO:tensorflow:Starting iteration 22
I0901 13:21:45.184978 140298343233536 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 349.07

Steps executed: 1000 Episode length: 1000 Return: -68.895406383687815
I0901 13:21:49.783313 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -68.90
INFO:tensorflow:Starting iteration 23

Steps executed: 209 Episode length: 76 Return: -20.021517644730963415
INFO:tensorflow:Average training steps per second: 358.92
I0901 13:21:56.070154 140298343233536 replay_runner.py:36] Average training steps per second: 358.92
I0901 13:21:56.172915 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.89
INFO:tensorflow:Starting iteration 24

Steps executed: 359 Episode length: 240 Return: -58.60198481346234215
INFO:tensorflow:Average training steps per second: 361.89
I0901 13:22:02.534261 140298343233536 replay_runner.py:36] Average training steps per second: 361.89
I0901 13:22:02.755018 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.54
INFO:tensorflow:Starting iteration 25
I0901 13:22:06.333837 140298343233536 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 361.25

Steps executed: 1000 Episode length: 1000 Return: -97.104700362190365
I0901 13:22:10.740280 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.10
INFO:tensorflow:Starting iteration 26

Steps executed: 378 Episode length: 378 Return: -116.3615935253258465
INFO:tensorflow:Average training steps per second: 334.86
I0901 13:22:17.159320 140298343233536 replay_runner.py:36] Average training steps per second: 334.86
I0901 13:22:17.498533 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.36
INFO:tensorflow:Starting iteration 27
I0901 13:22:20.955858 140298343233536 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 332.58

Steps executed: 220 Episode length: 109 Return: -294.1894254511438565
I0901 13:22:24.079911 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -134.89
INFO:tensorflow:Starting iteration 28

Steps executed: 816 Episode length: 816 Return: -323.7288917941766665
INFO:tensorflow:Average training steps per second: 336.88
I0901 13:22:30.411315 140298343233536 replay_runner.py:36] Average training steps per second: 336.88
I0901 13:22:31.752765 140298343233536 run_experiment.py:428] Average undiscounted return per evaluation episode: -323.73
INFO:tensorflow:Starting iteration 29
I0901 13:22:35.109883 140298343233536 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 348.58

Steps executed: 376 Episode length: 376 Return: 191.15796251919983665

Done fixed training!Episode length: 376 Return: 191.15796251919983665