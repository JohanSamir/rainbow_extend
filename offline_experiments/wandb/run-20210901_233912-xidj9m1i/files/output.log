Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
I0901 23:39:19.171093 140149719906304 run_experiment.py:549] Creating TrainRunner ...
I0901 23:39:19.183025 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:39:19.183328 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:39:19.183482 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:39:19.183612 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:39:19.183751 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0901 23:39:19.183851 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:39:19.183928 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:39:19.184003 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:39:19.184056 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:39:19.184109 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0901 23:39:19.184215 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:39:19.184286 140149719906304 dqn_agent.py:283] 	 seed: 1630539559182974
I0901 23:39:19.187454 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:39:19.187682 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:39:19.188094 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:39:19.188226 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:39:19.188334 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:39:19.188442 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:39:19.188520 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:39:19.188616 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:39:19.188710 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:39:19.222762 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:19.609106 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:19.626933 140149719906304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:39:19.637423 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:39:19.637697 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:39:19.637808 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:39:19.637889 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:39:19.637990 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0901 23:39:19.638161 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:39:19.638247 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:39:19.638389 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:39:19.638499 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:39:19.638706 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0901 23:39:19.638910 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:39:19.639051 140149719906304 dqn_agent.py:283] 	 seed: 1630539559637370
I0901 23:39:19.642538 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:39:19.642821 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:39:19.643049 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:39:19.643435 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:39:19.643562 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:39:19.643741 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:39:19.643979 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:39:19.644135 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:39:19.644451 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:39:19.710641 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:19.731002 140149719906304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:39:19.731315 140149719906304 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 165.95
I0901 23:39:25.758134 140149719906304 replay_runner.py:36] Average training steps per second: 165.95
Steps executed: 211 Episode length: 90 Return: -631.8165534391152
I0901 23:39:26.930995 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -568.55
INFO:tensorflow:Starting iteration 1

Steps executed: 243 Episode length: 68 Return: -564.4667369563623
INFO:tensorflow:Average training steps per second: 219.42
I0901 23:39:35.885374 140149719906304 replay_runner.py:36] Average training steps per second: 219.42
I0901 23:39:36.119639 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -593.51
INFO:tensorflow:Starting iteration 2

Steps executed: 229 Episode length: 83 Return: -693.8872609322011
INFO:tensorflow:Average training steps per second: 223.34
I0901 23:39:45.021986 140149719906304 replay_runner.py:36] Average training steps per second: 223.34
I0901 23:39:45.234409 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -651.80
INFO:tensorflow:Starting iteration 3

Steps executed: 216 Episode length: 58 Return: -532.6189945903011
INFO:tensorflow:Average training steps per second: 216.02
I0901 23:39:54.227225 140149719906304 replay_runner.py:36] Average training steps per second: 216.02
I0901 23:39:54.425137 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -619.77
INFO:tensorflow:Starting iteration 4

Steps executed: 284 Episode length: 122 Return: -1007.824571001941
INFO:tensorflow:Average training steps per second: 224.31
I0901 23:40:03.184577 140149719906304 replay_runner.py:36] Average training steps per second: 224.31
I0901 23:40:03.475753 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -857.10
INFO:tensorflow:Starting iteration 5

Steps executed: 215 Episode length: 58 Return: -521.80251702364761
INFO:tensorflow:Average training steps per second: 218.31
I0901 23:40:12.484327 140149719906304 replay_runner.py:36] Average training steps per second: 218.31
I0901 23:40:12.678271 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -685.20
INFO:tensorflow:Starting iteration 6

Steps executed: 262 Episode length: 71 Return: -726.90861997319033
INFO:tensorflow:Average training steps per second: 218.01
I0901 23:40:21.621840 140149719906304 replay_runner.py:36] Average training steps per second: 218.01
I0901 23:40:21.860152 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -540.20
INFO:tensorflow:Starting iteration 7

Steps executed: 117 Episode length: 59 Return: -566.09324889159553
INFO:tensorflow:Average training steps per second: 214.84
I0901 23:40:30.825889 140149719906304 replay_runner.py:36] Average training steps per second: 214.84

Steps executed: 200 Episode length: 83 Return: -752.74186085074753
INFO:tensorflow:Starting iteration 8

Steps executed: 244 Episode length: 78 Return: -560.20577702346576
INFO:tensorflow:Average training steps per second: 216.87
I0901 23:40:39.970262 140149719906304 replay_runner.py:36] Average training steps per second: 216.87
I0901 23:40:40.213021 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.41
INFO:tensorflow:Starting iteration 9

Steps executed: 296 Episode length: 97 Return: -583.46942872476762
INFO:tensorflow:Average training steps per second: 217.71
I0901 23:40:49.218142 140149719906304 replay_runner.py:36] Average training steps per second: 217.71
I0901 23:40:49.510160 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -535.10
INFO:tensorflow:Starting iteration 10

Steps executed: 257 Episode length: 80 Return: -448.68486776919906
INFO:tensorflow:Average training steps per second: 222.85
I0901 23:40:58.310741 140149719906304 replay_runner.py:36] Average training steps per second: 222.85
I0901 23:40:58.549729 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -583.09
INFO:tensorflow:Starting iteration 11
I0901 23:41:02.744953 140149719906304 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 228.65

Steps executed: 305 Episode length: 109 Return: -741.1004618843136
I0901 23:41:07.465965 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -1096.15
INFO:tensorflow:Starting iteration 12

Steps executed: 220 Episode length: 118 Return: -870.3908768145357
INFO:tensorflow:Average training steps per second: 232.81
I0901 23:41:15.961341 140149719906304 replay_runner.py:36] Average training steps per second: 232.81
I0901 23:41:16.173822 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -785.28
INFO:tensorflow:Starting iteration 13

Steps executed: 273 Episode length: 78 Return: -582.39583671083875
INFO:tensorflow:Average training steps per second: 230.34
I0901 23:41:24.699866 140149719906304 replay_runner.py:36] Average training steps per second: 230.34
I0901 23:41:25.012010 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -636.50
INFO:tensorflow:Starting iteration 14
I0901 23:41:29.096260 140149719906304 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 235.56

Steps executed: 204 Episode length: 83 Return: -568.40728868286411
I0901 23:41:33.530512 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -607.19
INFO:tensorflow:Starting iteration 15

Steps executed: 277 Episode length: 86 Return: -459.66638679312412
INFO:tensorflow:Average training steps per second: 231.62
I0901 23:41:41.941783 140149719906304 replay_runner.py:36] Average training steps per second: 231.62
I0901 23:41:42.231153 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -997.21
INFO:tensorflow:Starting iteration 16

Steps executed: 91 Episode length: 91 Return: -479.942749462438772
INFO:tensorflow:Average training steps per second: 228.05

Steps executed: 391 Episode length: 300 Return: -2714.9254169457404
I0901 23:41:51.524148 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -1597.43
INFO:tensorflow:Starting iteration 17

Steps executed: 271 Episode length: 102 Return: -661.23016352835674
INFO:tensorflow:Average training steps per second: 219.68
I0901 23:42:00.322188 140149719906304 replay_runner.py:36] Average training steps per second: 219.68
I0901 23:42:00.601009 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -555.92
INFO:tensorflow:Starting iteration 18
I0901 23:42:04.969104 140149719906304 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 218.63

Steps executed: 279 Episode length: 116 Return: -830.84041935277254
I0901 23:42:09.827031 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -597.17
INFO:tensorflow:Starting iteration 19

Steps executed: 386 Episode length: 190 Return: -1588.8143076208946
INFO:tensorflow:Average training steps per second: 225.38
I0901 23:42:18.410961 140149719906304 replay_runner.py:36] Average training steps per second: 225.38
I0901 23:42:18.823490 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -944.96
INFO:tensorflow:Starting iteration 20

Steps executed: 265 Episode length: 100 Return: -422.51705780715093
INFO:tensorflow:Average training steps per second: 220.38
I0901 23:42:27.756026 140149719906304 replay_runner.py:36] Average training steps per second: 220.38
I0901 23:42:28.021802 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -509.32
INFO:tensorflow:Starting iteration 21

Steps executed: 223 Episode length: 223 Return: -1673.6882776799134
INFO:tensorflow:Average training steps per second: 226.50
I0901 23:42:36.804560 140149719906304 replay_runner.py:36] Average training steps per second: 226.50
I0901 23:42:37.067203 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -1673.69
INFO:tensorflow:Starting iteration 22

Steps executed: 233 Episode length: 143 Return: -839.41038835524584
INFO:tensorflow:Average training steps per second: 221.27
I0901 23:42:45.913931 140149719906304 replay_runner.py:36] Average training steps per second: 221.27
I0901 23:42:46.146470 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -726.30
INFO:tensorflow:Starting iteration 23

Steps executed: 302 Episode length: 130 Return: -767.05013971305524
INFO:tensorflow:Average training steps per second: 225.45
I0901 23:42:54.855945 140149719906304 replay_runner.py:36] Average training steps per second: 225.45
I0901 23:42:55.151373 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -684.02
INFO:tensorflow:Starting iteration 24

Steps executed: 309 Episode length: 210 Return: -1764.8616819917394
INFO:tensorflow:Average training steps per second: 218.58
I0901 23:43:04.147202 140149719906304 replay_runner.py:36] Average training steps per second: 218.58
I0901 23:43:04.513100 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -1248.20
INFO:tensorflow:Starting iteration 25
I0901 23:43:08.784936 140149719906304 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 223.48

Steps executed: 277 Episode length: 134 Return: -786.65655261944227
I0901 23:43:13.545334 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -896.68
INFO:tensorflow:Starting iteration 26

Steps executed: 285 Episode length: 106 Return: -711.68276191832987
INFO:tensorflow:Average training steps per second: 226.07
I0901 23:43:22.214533 140149719906304 replay_runner.py:36] Average training steps per second: 226.07
I0901 23:43:22.498532 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -639.43
INFO:tensorflow:Starting iteration 27
I0901 23:43:26.919469 140149719906304 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 226.37

Steps executed: 536 Episode length: 441 Return: -5470.5305339613027
I0901 23:43:32.266503 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -3095.99
INFO:tensorflow:Starting iteration 28

Steps executed: 278 Episode length: 98 Return: -557.910425629606227
INFO:tensorflow:Average training steps per second: 226.53
I0901 23:43:40.967172 140149719906304 replay_runner.py:36] Average training steps per second: 226.53
I0901 23:43:41.257427 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -657.71
INFO:tensorflow:Starting iteration 29

Steps executed: 229 Episode length: 75 Return: -498.910918470242937
INFO:tensorflow:Average training steps per second: 219.35
I0901 23:43:50.249645 140149719906304 replay_runner.py:36] Average training steps per second: 219.35

Done fixed training!Episode length: 75 Return: -498.910918470242937