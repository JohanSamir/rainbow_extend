I0902 00:19:47.193496 140183943698432 run_experiment.py:549] Creating TrainRunner ...
I0902 00:19:47.205219 140183943698432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:19:47.205422 140183943698432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:19:47.205501 140183943698432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:19:47.205562 140183943698432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:19:47.205627 140183943698432 dqn_agent.py:275] 	 update_period: 4
I0902 00:19:47.205679 140183943698432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:19:47.205779 140183943698432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:19:47.205860 140183943698432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:19:47.205972 140183943698432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:19:47.206048 140183943698432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:19:47.206107 140183943698432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:19:47.206200 140183943698432 dqn_agent.py:283] 	 seed: 1630541987205164
I0902 00:19:47.209083 140183943698432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:19:47.209251 140183943698432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:19:47.209334 140183943698432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:19:47.209400 140183943698432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:19:47.209457 140183943698432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:19:47.209532 140183943698432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:19:47.209630 140183943698432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:19:47.209697 140183943698432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:19:47.209767 140183943698432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:19:47.246391 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:47.518977 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:47.532156 140183943698432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:19:47.543284 140183943698432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:19:47.543600 140183943698432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:19:47.543748 140183943698432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:19:47.543872 140183943698432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:19:47.543984 140183943698432 dqn_agent.py:275] 	 update_period: 4
I0902 00:19:47.544080 140183943698432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:19:47.544299 140183943698432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:19:47.544471 140183943698432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:19:47.544584 140183943698432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:19:47.544682 140183943698432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:19:47.544807 140183943698432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:19:47.544898 140183943698432 dqn_agent.py:283] 	 seed: 1630541987543222
I0902 00:19:47.547544 140183943698432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:19:47.547701 140183943698432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:19:47.547853 140183943698432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:19:47.548026 140183943698432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:19:47.548152 140183943698432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:19:47.548243 140183943698432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:19:47.548349 140183943698432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:19:47.548454 140183943698432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:19:47.548572 140183943698432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:19:47.581709 140183943698432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:47.605093 140183943698432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:19:47.605390 140183943698432 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
Steps executed: 281 Episode length: 156 Return: -222.29228893593452
INFO:tensorflow:Average training steps per second: 248.38
I0902 00:19:51.631627 140183943698432 replay_runner.py:36] Average training steps per second: 248.38
I0902 00:19:52.493808 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -288.27
INFO:tensorflow:Starting iteration 1

Steps executed: 243 Episode length: 243 Return: -243.87749790189486
INFO:tensorflow:Average training steps per second: 329.68
I0902 00:19:58.971043 140183943698432 replay_runner.py:36] Average training steps per second: 329.68
I0902 00:19:59.191616 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.88
INFO:tensorflow:Starting iteration 2

Steps executed: 258 Episode length: 122 Return: -315.37099478785035
INFO:tensorflow:Average training steps per second: 334.19
I0902 00:20:05.547975 140183943698432 replay_runner.py:36] Average training steps per second: 334.19
I0902 00:20:05.693360 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -200.26
INFO:tensorflow:Starting iteration 3

Steps executed: 247 Episode length: 247 Return: -37.677933115095035
INFO:tensorflow:Average training steps per second: 346.73
I0902 00:20:11.883569 140183943698432 replay_runner.py:36] Average training steps per second: 346.73
I0902 00:20:12.138207 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.68
INFO:tensorflow:Starting iteration 4

Steps executed: 241 Episode length: 241 Return: -62.053512102973915
INFO:tensorflow:Average training steps per second: 350.17
I0902 00:20:18.368744 140183943698432 replay_runner.py:36] Average training steps per second: 350.17
I0902 00:20:18.547150 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -62.05
INFO:tensorflow:Starting iteration 5
I0902 00:20:22.003889 140183943698432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 354.93

Steps executed: 1000 Episode length: 1000 Return: -97.81679805449676
I0902 00:20:27.141692 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.82
INFO:tensorflow:Starting iteration 6

Steps executed: 759 Episode length: 759 Return: -119.945677177647356
INFO:tensorflow:Average training steps per second: 342.37
I0902 00:20:33.438230 140183943698432 replay_runner.py:36] Average training steps per second: 342.37
I0902 00:20:34.484005 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -119.95
INFO:tensorflow:Starting iteration 7
I0902 00:20:37.769234 140183943698432 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 326.70

Steps executed: 1000 Episode length: 1000 Return: -116.95092295187855
I0902 00:20:42.313201 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.95
INFO:tensorflow:Starting iteration 8
I0902 00:20:45.556187 140183943698432 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 320.93

Steps executed: 1000 Episode length: 1000 Return: -40.552498720662626
I0902 00:20:49.939119 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -40.55
INFO:tensorflow:Starting iteration 9
I0902 00:20:53.185702 140183943698432 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 316.12

Steps executed: 1000 Episode length: 1000 Return: -79.638569716202436
I0902 00:20:58.424049 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.64
INFO:tensorflow:Starting iteration 10

Steps executed: 319 Episode length: 319 Return: -169.4979110348541636
INFO:tensorflow:Average training steps per second: 318.88
I0902 00:21:04.835922 140183943698432 replay_runner.py:36] Average training steps per second: 318.88
I0902 00:21:05.126891 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.50
INFO:tensorflow:Starting iteration 11

Steps executed: 641 Episode length: 641 Return: -343.9594837730411436
INFO:tensorflow:Average training steps per second: 315.88
I0902 00:21:11.513820 140183943698432 replay_runner.py:36] Average training steps per second: 315.88
I0902 00:21:12.314909 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -343.96
INFO:tensorflow:Starting iteration 12
I0902 00:21:15.468870 140183943698432 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 323.12

Steps executed: 1000 Episode length: 1000 Return: -170.57807894387526
I0902 00:21:19.802636 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -170.58
INFO:tensorflow:Starting iteration 13
I0902 00:21:22.848980 140183943698432 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 335.82

Steps executed: 1000 Episode length: 1000 Return: -70.056281231291326
I0902 00:21:27.690200 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -70.06
INFO:tensorflow:Starting iteration 14
I0902 00:21:30.804647 140183943698432 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 320.35

Steps executed: 1000 Episode length: 1000 Return: -9.2461216772382776
I0902 00:21:36.211320 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -9.25
INFO:tensorflow:Starting iteration 15

Steps executed: 584 Episode length: 584 Return: -53.95638510298246676
INFO:tensorflow:Average training steps per second: 351.44
I0902 00:21:42.440893 140183943698432 replay_runner.py:36] Average training steps per second: 351.44
I0902 00:21:43.305665 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -53.96
INFO:tensorflow:Starting iteration 16

Steps executed: 301 Episode length: 160 Return: -66.26354129741958676
INFO:tensorflow:Average training steps per second: 343.86
I0902 00:21:49.663084 140183943698432 replay_runner.py:36] Average training steps per second: 343.86
I0902 00:21:49.853724 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -176.43
INFO:tensorflow:Starting iteration 17
I0902 00:21:53.253250 140183943698432 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 341.30

Steps executed: 1000 Episode length: 1000 Return: 2.90670186690211456
I0902 00:21:58.021715 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: 2.91
INFO:tensorflow:Starting iteration 18

Steps executed: 236 Episode length: 96 Return: -118.66884104789481456
INFO:tensorflow:Average training steps per second: 332.38
I0902 00:22:04.460282 140183943698432 replay_runner.py:36] Average training steps per second: 332.38
I0902 00:22:04.580829 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -101.20
INFO:tensorflow:Starting iteration 19

Steps executed: 302 Episode length: 149 Return: -150.2453526162997356
INFO:tensorflow:Average training steps per second: 330.03
I0902 00:22:10.972033 140183943698432 replay_runner.py:36] Average training steps per second: 330.03
I0902 00:22:11.157335 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -230.99
INFO:tensorflow:Starting iteration 20
I0902 00:22:14.529928 140183943698432 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 339.56

Steps executed: 292 Episode length: 292 Return: -25.20624280097499356
I0902 00:22:17.686814 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -25.21
INFO:tensorflow:Starting iteration 21

Steps executed: 222 Episode length: 222 Return: -12.00534690500173356
INFO:tensorflow:Average training steps per second: 330.21
I0902 00:22:24.054944 140183943698432 replay_runner.py:36] Average training steps per second: 330.21
I0902 00:22:24.209868 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -12.01
INFO:tensorflow:Starting iteration 22

Steps executed: 471 Episode length: 471 Return: -53.92699381021846356
INFO:tensorflow:Average training steps per second: 336.01
I0902 00:22:30.559047 140183943698432 replay_runner.py:36] Average training steps per second: 336.01
I0902 00:22:31.055463 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -53.93
INFO:tensorflow:Starting iteration 23
I0902 00:22:34.451901 140183943698432 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 342.60

Steps executed: 441 Episode length: 441 Return: -115.2833021143116456
I0902 00:22:37.962460 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.28
INFO:tensorflow:Starting iteration 24

Steps executed: 584 Episode length: 584 Return: -89.14073858455293456
INFO:tensorflow:Average training steps per second: 352.58
I0902 00:22:44.254506 140183943698432 replay_runner.py:36] Average training steps per second: 352.58
I0902 00:22:45.009014 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.14
INFO:tensorflow:Starting iteration 25
I0902 00:22:48.543218 140183943698432 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 355.33

Steps executed: 935 Episode length: 935 Return: -657.9012422254604456
I0902 00:22:53.155123 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: -657.90
INFO:tensorflow:Starting iteration 26
I0902 00:22:56.612816 140183943698432 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 341.62
I0902 00:22:59.540487 140183943698432 replay_runner.py:36] Average training steps per second: 341.62

Steps executed: 334 Episode length: 181 Return: -27.11207803131873456
INFO:tensorflow:Starting iteration 27
I0902 00:23:03.094469 140183943698432 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 320.53
I0902 00:23:06.214619 140183943698432 replay_runner.py:36] Average training steps per second: 320.53

Steps executed: 1000 Episode length: 1000 Return: 34.9891976774817856
INFO:tensorflow:Starting iteration 28
I0902 00:23:11.079103 140183943698432 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 375.18

Steps executed: 451 Episode length: 451 Return: 214.38138709256816856
I0902 00:23:14.334758 140183943698432 run_experiment.py:428] Average undiscounted return per evaluation episode: 214.38
INFO:tensorflow:Starting iteration 29

Steps executed: 254 Episode length: 254 Return: -92.06968319645996856
INFO:tensorflow:Average training steps per second: 354.01
I0902 00:23:20.448283 140183943698432 replay_runner.py:36] Average training steps per second: 354.01

Done fixed training!Episode length: 254 Return: -92.06968319645996856