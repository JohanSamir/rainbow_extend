Loaded trained dqn in lunarlander
Training fixed agent 5, please be patient, may be a while...
I0902 23:45:50.938741 139926926592000 run_experiment.py:549] Creating TrainRunner ...
I0902 23:45:50.951000 139926926592000 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:45:50.951282 139926926592000 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:45:50.951447 139926926592000 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:45:50.951551 139926926592000 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:45:50.951635 139926926592000 dqn_agent.py:275] 	 update_period: 4
I0902 23:45:50.951747 139926926592000 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:45:50.951859 139926926592000 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:45:50.951990 139926926592000 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:45:50.952119 139926926592000 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:45:50.952282 139926926592000 dqn_agent.py:280] 	 optimizer: adam
I0902 23:45:50.952479 139926926592000 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:45:50.952582 139926926592000 dqn_agent.py:283] 	 seed: 1630626350950931
I0902 23:45:50.955952 139926926592000 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:45:50.956132 139926926592000 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:45:50.956293 139926926592000 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:45:50.956424 139926926592000 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:45:50.956498 139926926592000 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:45:50.956698 139926926592000 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:45:50.956825 139926926592000 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:45:50.956937 139926926592000 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:45:50.957341 139926926592000 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:45:50.995280 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:45:51.398172 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:45:51.411413 139926926592000 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:45:51.421595 139926926592000 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:45:51.421849 139926926592000 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:45:51.422035 139926926592000 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:45:51.423015 139926926592000 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:45:51.423198 139926926592000 dqn_agent.py:275] 	 update_period: 4
I0902 23:45:51.423312 139926926592000 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:45:51.423515 139926926592000 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:45:51.423834 139926926592000 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:45:51.424003 139926926592000 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:45:51.424095 139926926592000 dqn_agent.py:280] 	 optimizer: adam
I0902 23:45:51.424217 139926926592000 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:45:51.429517 139926926592000 dqn_agent.py:283] 	 seed: 1630626351421529
I0902 23:45:51.455613 139926926592000 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:45:51.455880 139926926592000 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:45:51.455987 139926926592000 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:45:51.456086 139926926592000 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:45:51.456218 139926926592000 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:45:51.456431 139926926592000 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:45:51.456597 139926926592000 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:45:51.456786 139926926592000 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:45:51.457109 139926926592000 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:45:51.488446 139926926592000 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:45:51.511385 139926926592000 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:45:51.511657 139926926592000 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 163.28
I0902 23:45:57.636867 139926926592000 replay_runner.py:36] Average training steps per second: 163.28
Steps executed: 248 Episode length: 106 Return: -256.5247319535158
I0902 23:45:58.875529 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -305.63
INFO:tensorflow:Starting iteration 1

Steps executed: 429 Episode length: 270 Return: -508.98013530354694
INFO:tensorflow:Average training steps per second: 218.46
I0902 23:46:07.720885 139926926592000 replay_runner.py:36] Average training steps per second: 218.46
I0902 23:46:08.163925 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -505.44
INFO:tensorflow:Starting iteration 2

Steps executed: 219 Episode length: 105 Return: -234.05683524907377
INFO:tensorflow:Average training steps per second: 214.14
I0902 23:46:17.117214 139926926592000 replay_runner.py:36] Average training steps per second: 214.14
I0902 23:46:17.309000 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -224.96
INFO:tensorflow:Starting iteration 3

Steps executed: 318 Episode length: 206 Return: -363.70789876326984
INFO:tensorflow:Average training steps per second: 218.93
I0902 23:46:26.217775 139926926592000 replay_runner.py:36] Average training steps per second: 218.93
I0902 23:46:26.530404 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -333.87
INFO:tensorflow:Starting iteration 4

Steps executed: 239 Episode length: 239 Return: -883.50130519215384
INFO:tensorflow:Average training steps per second: 225.90
I0902 23:46:35.215995 139926926592000 replay_runner.py:36] Average training steps per second: 225.90
I0902 23:46:35.475286 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -883.50
INFO:tensorflow:Starting iteration 5
I0902 23:46:39.712051 139926926592000 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 227.43

Steps executed: 1000 Episode length: 1000 Return: -276.09760862899435
I0902 23:46:46.184103 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -276.10
INFO:tensorflow:Starting iteration 6
I0902 23:46:50.319694 139926926592000 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 228.32


Steps executed: 1050 Episode length: 1000 Return: -120.51510331100812
I0902 23:46:57.203771 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.53
INFO:tensorflow:Starting iteration 7
I0902 23:47:01.503643 139926926592000 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 225.19

Steps executed: 1000 Episode length: 1000 Return: -55.642044289856436
I0902 23:47:08.315304 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -55.64
INFO:tensorflow:Starting iteration 8
I0902 23:47:12.655443 139926926592000 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 215.28

Steps executed: 1000 Episode length: 1000 Return: -99.537979685128666
I0902 23:47:19.738120 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.54
INFO:tensorflow:Starting iteration 9

Steps executed: 192 Episode length: 192 Return: -182.1239774870011666
INFO:tensorflow:Average training steps per second: 217.29

Steps executed: 354 Episode length: 162 Return: -192.3789931133412466
I0902 23:47:29.021892 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.25
INFO:tensorflow:Starting iteration 10
I0902 23:47:33.302267 139926926592000 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 218.90

Steps executed: 1000 Episode length: 1000 Return: -274.81201351928985
I0902 23:47:40.229864 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.81
INFO:tensorflow:Starting iteration 11
I0902 23:47:44.498759 139926926592000 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 220.09

Steps executed: 1000 Episode length: 1000 Return: -37.377230980855485
I0902 23:47:53.697233 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.38
INFO:tensorflow:Starting iteration 12
I0902 23:47:58.024761 139926926592000 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 219.77

Steps executed: 1000 Episode length: 1000 Return: -84.687917205313075
I0902 23:48:04.911110 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -84.69
INFO:tensorflow:Starting iteration 13

Steps executed: 438 Episode length: 438 Return: -82.69165000380265075
INFO:tensorflow:Average training steps per second: 216.26
I0902 23:48:13.832898 139926926592000 replay_runner.py:36] Average training steps per second: 216.26
I0902 23:48:14.466134 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -82.69
INFO:tensorflow:Starting iteration 14
I0902 23:48:18.615609 139926926592000 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 215.84

Steps executed: 418 Episode length: 263 Return: -120.9617326654445675
I0902 23:48:23.652129 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -123.56
INFO:tensorflow:Starting iteration 15

Steps executed: 410 Episode length: 226 Return: -213.6197214396673375
INFO:tensorflow:Average training steps per second: 213.58
I0902 23:48:32.612583 139926926592000 replay_runner.py:36] Average training steps per second: 213.58
I0902 23:48:33.057358 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -279.45
INFO:tensorflow:Starting iteration 16
I0902 23:48:37.480351 139926926592000 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 214.72
I0902 23:48:42.137960 139926926592000 replay_runner.py:36] Average training steps per second: 214.72

Steps executed: 257 Episode length: 88 Return: -405.03412667013992375
INFO:tensorflow:Starting iteration 17
I0902 23:48:46.692704 139926926592000 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 215.15

Steps executed: 557 Episode length: 387 Return: -512.3004934642258375
I0902 23:48:52.140543 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -244.97
INFO:tensorflow:Starting iteration 18

Steps executed: 387 Episode length: 272 Return: -95.49130439060812375
INFO:tensorflow:Average training steps per second: 230.51
I0902 23:49:00.800289 139926926592000 replay_runner.py:36] Average training steps per second: 230.51
I0902 23:49:01.186362 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.51
INFO:tensorflow:Starting iteration 19

Steps executed: 321 Episode length: 202 Return: -197.8050377405649375
INFO:tensorflow:Average training steps per second: 218.55
I0902 23:49:10.014616 139926926592000 replay_runner.py:36] Average training steps per second: 218.55
I0902 23:49:10.313566 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.95
INFO:tensorflow:Starting iteration 20

Steps executed: 233 Episode length: 233 Return: -162.1260792422167575
INFO:tensorflow:Average training steps per second: 218.69
I0902 23:49:19.233212 139926926592000 replay_runner.py:36] Average training steps per second: 218.69
I0902 23:49:19.457428 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.13
INFO:tensorflow:Starting iteration 21

Steps executed: 373 Episode length: 212 Return: 49.689859968083965475
INFO:tensorflow:Average training steps per second: 221.95
I0902 23:49:28.289259 139926926592000 replay_runner.py:36] Average training steps per second: 221.95
I0902 23:49:28.632029 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -54.25
INFO:tensorflow:Starting iteration 22

Steps executed: 386 Episode length: 386 Return: -594.6391508207998475
INFO:tensorflow:Average training steps per second: 215.65
I0902 23:49:37.623600 139926926592000 replay_runner.py:36] Average training steps per second: 215.65
I0902 23:49:38.258613 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -594.64
INFO:tensorflow:Starting iteration 23
I0902 23:49:42.431933 139926926592000 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 214.55

Steps executed: 226 Episode length: 102 Return: -132.3439850294925675
I0902 23:49:47.291230 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.96
INFO:tensorflow:Starting iteration 24

Steps executed: 351 Episode length: 203 Return: -136.4427826190621675
INFO:tensorflow:Average training steps per second: 214.58
I0902 23:49:56.064382 139926926592000 replay_runner.py:36] Average training steps per second: 214.58
I0902 23:49:56.379249 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.37
INFO:tensorflow:Starting iteration 25

Steps executed: 121 Episode length: 121 Return: -78.05924154763214675
INFO:tensorflow:Average training steps per second: 218.23

Steps executed: 515 Episode length: 394 Return: -294.9856264022930675
I0902 23:50:05.848250 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -186.52
INFO:tensorflow:Starting iteration 26

Steps executed: 156 Episode length: 156 Return: -148.6395056592890975
INFO:tensorflow:Average training steps per second: 212.52

Steps executed: 462 Episode length: 306 Return: -663.7004868953503975
I0902 23:50:15.410725 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -406.17
INFO:tensorflow:Starting iteration 27

Steps executed: 244 Episode length: 53 Return: -99.864272939809513975
INFO:tensorflow:Average training steps per second: 219.07
I0902 23:50:24.197320 139926926592000 replay_runner.py:36] Average training steps per second: 219.07
I0902 23:50:24.390015 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.63
INFO:tensorflow:Starting iteration 28

Steps executed: 186 Episode length: 59 Return: -126.69023585204329475
INFO:tensorflow:Average training steps per second: 220.26

Steps executed: 282 Episode length: 96 Return: -437.15104480615304475
I0902 23:50:33.479636 139926926592000 run_experiment.py:428] Average undiscounted return per evaluation episode: -320.89
INFO:tensorflow:Starting iteration 29

Steps executed: 201 Episode length: 54 Return: -100.78549476511819475
INFO:tensorflow:Average training steps per second: 222.13
I0902 23:50:42.234373 139926926592000 replay_runner.py:36] Average training steps per second: 222.13

Done fixed training!Episode length: 54 Return: -100.78549476511819475