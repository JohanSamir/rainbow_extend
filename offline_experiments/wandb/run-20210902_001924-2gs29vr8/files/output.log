I0902 00:19:29.956129 140149719906304 run_experiment.py:549] Creating TrainRunner ...
I0902 00:19:29.963953 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:19:29.964168 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:19:29.964360 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:19:29.964507 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:19:29.964592 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0902 00:19:29.964681 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:19:29.964771 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:19:29.964858 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:19:29.964958 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:19:29.965040 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0902 00:19:29.965119 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:19:29.965186 140149719906304 dqn_agent.py:283] 	 seed: 1630541969963910
I0902 00:19:29.966991 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:19:29.967102 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:19:29.967207 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:19:29.967294 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:19:29.967354 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:19:29.967443 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:19:29.967524 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:19:29.967590 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:19:29.967656 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:19:29.993636 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:30.253132 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:30.262338 140149719906304 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:19:30.268283 140149719906304 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:19:30.268438 140149719906304 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:19:30.268512 140149719906304 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:19:30.268580 140149719906304 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:19:30.268642 140149719906304 dqn_agent.py:275] 	 update_period: 4
I0902 00:19:30.268696 140149719906304 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:19:30.268775 140149719906304 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:19:30.268867 140149719906304 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:19:30.268925 140149719906304 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:19:30.269000 140149719906304 dqn_agent.py:280] 	 optimizer: adam
I0902 00:19:30.269094 140149719906304 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:19:30.269150 140149719906304 dqn_agent.py:283] 	 seed: 1630541970268250
I0902 00:19:30.270779 140149719906304 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:19:30.270888 140149719906304 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:19:30.270960 140149719906304 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:19:30.271024 140149719906304 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:19:30.271139 140149719906304 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:19:30.271307 140149719906304 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:19:30.271447 140149719906304 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:19:30.271542 140149719906304 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:19:30.271638 140149719906304 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:19:30.292642 140149719906304 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:19:30.306498 140149719906304 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:19:30.306651 140149719906304 replay_runner.py:41] Starting iteration 0
Loaded trained dqn in lunarlander
Training fixed agent 7, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 245.55
I0902 00:19:34.379225 140149719906304 replay_runner.py:36] Average training steps per second: 245.55
I0902 00:19:35.213407 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -501.38
Steps executed: 260 Episode length: 161 Return: -425.1510669047738
INFO:tensorflow:Starting iteration 1

Steps executed: 146 Episode length: 146 Return: -466.25798344596274
INFO:tensorflow:Average training steps per second: 342.13
I0902 00:19:41.411477 140149719906304 replay_runner.py:36] Average training steps per second: 342.13

Steps executed: 299 Episode length: 153 Return: -467.87681897183666
INFO:tensorflow:Starting iteration 2

Steps executed: 249 Episode length: 137 Return: -377.71919247021765
INFO:tensorflow:Average training steps per second: 357.18
I0902 00:19:47.426961 140149719906304 replay_runner.py:36] Average training steps per second: 357.18
I0902 00:19:47.583671 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -253.04
INFO:tensorflow:Starting iteration 3

Steps executed: 333 Episode length: 155 Return: -149.70032350230002
INFO:tensorflow:Average training steps per second: 349.76
I0902 00:19:53.819015 140149719906304 replay_runner.py:36] Average training steps per second: 349.76
I0902 00:19:54.040399 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -111.13
INFO:tensorflow:Starting iteration 4

Steps executed: 161 Episode length: 161 Return: -471.77065860353252
INFO:tensorflow:Average training steps per second: 343.34

Steps executed: 1028 Episode length: 867 Return: -306.08201267697495
I0902 00:20:02.370612 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -388.93
INFO:tensorflow:Starting iteration 5
I0902 00:20:05.791941 140149719906304 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 364.00

Steps executed: 1000 Episode length: 1000 Return: -131.4254547654909
I0902 00:20:10.254411 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -131.43
INFO:tensorflow:Starting iteration 6
I0902 00:20:13.733951 140149719906304 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 355.59

Steps executed: 1000 Episode length: 1000 Return: -48.752455006946796
I0902 00:20:18.199698 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -48.75
INFO:tensorflow:Starting iteration 7
I0902 00:20:21.654642 140149719906304 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 345.64

Steps executed: 1000 Episode length: 1000 Return: -89.714068722561836
I0902 00:20:26.129595 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -89.71
INFO:tensorflow:Starting iteration 8
I0902 00:20:29.514324 140149719906304 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 346.74

Steps executed: 1000 Episode length: 1000 Return: -77.280052925630636
I0902 00:20:34.422007 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -77.28
INFO:tensorflow:Starting iteration 9
I0902 00:20:37.707689 140149719906304 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 328.42

Steps executed: 1000 Episode length: 1000 Return: -146.37533304560226
I0902 00:20:42.213439 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -146.38
INFO:tensorflow:Starting iteration 10
I0902 00:20:45.429224 140149719906304 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 316.15
I0902 00:20:48.592567 140149719906304 replay_runner.py:36] Average training steps per second: 316.15

Steps executed: 1000 Episode length: 1000 Return: -273.33959186703546
INFO:tensorflow:Starting iteration 11
I0902 00:20:53.248778 140149719906304 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 322.74

Steps executed: 1000 Episode length: 1000 Return: -115.09447083337115
I0902 00:20:59.154502 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.09
INFO:tensorflow:Starting iteration 12
I0902 00:21:02.511736 140149719906304 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 332.06

Steps executed: 1000 Episode length: 1000 Return: -61.793657597483795
I0902 00:21:06.824578 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -61.79
INFO:tensorflow:Starting iteration 13
I0902 00:21:10.202434 140149719906304 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 339.78

Steps executed: 1000 Episode length: 1000 Return: -97.825470169329225
I0902 00:21:14.901373 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.83
INFO:tensorflow:Starting iteration 14
I0902 00:21:18.369549 140149719906304 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 350.89

Steps executed: 1000 Episode length: 1000 Return: -47.776123125983715
I0902 00:21:23.012479 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -47.78
INFO:tensorflow:Starting iteration 15
I0902 00:21:26.500607 140149719906304 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 334.80

Steps executed: 1000 Episode length: 1000 Return: -18.620167917956906
I0902 00:21:31.871813 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -18.62
INFO:tensorflow:Starting iteration 16
I0902 00:21:35.320867 140149719906304 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 362.08

Steps executed: 624 Episode length: 624 Return: -88.66494107670388906
I0902 00:21:39.232258 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -88.66
INFO:tensorflow:Starting iteration 17

Steps executed: 268 Episode length: 268 Return: -56.32237510830769606
INFO:tensorflow:Average training steps per second: 350.51
I0902 00:21:45.463855 140149719906304 replay_runner.py:36] Average training steps per second: 350.51
I0902 00:21:45.685450 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -56.32
INFO:tensorflow:Starting iteration 18
I0902 00:21:49.106452 140149719906304 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 342.84
I0902 00:21:52.023545 140149719906304 replay_runner.py:36] Average training steps per second: 342.84

Steps executed: 332 Episode length: 332 Return: -238.7902234425010606
INFO:tensorflow:Starting iteration 19

Steps executed: 296 Episode length: 139 Return: -118.6624448798034506
INFO:tensorflow:Average training steps per second: 350.49
I0902 00:21:58.623223 140149719906304 replay_runner.py:36] Average training steps per second: 350.49
I0902 00:21:58.799901 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -94.38
INFO:tensorflow:Starting iteration 20

Steps executed: 439 Episode length: 439 Return: -45.86633569191640406
INFO:tensorflow:Average training steps per second: 352.12
I0902 00:22:05.123607 140149719906304 replay_runner.py:36] Average training steps per second: 352.12
I0902 00:22:05.618640 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -45.87
INFO:tensorflow:Starting iteration 21
I0902 00:22:09.098564 140149719906304 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 352.91
I0902 00:22:11.932541 140149719906304 replay_runner.py:36] Average training steps per second: 352.91

Steps executed: 845 Episode length: 845 Return: -97.61019238811696406
INFO:tensorflow:Starting iteration 22

Steps executed: 217 Episode length: 217 Return: -497.1502030276369606
INFO:tensorflow:Average training steps per second: 372.05
I0902 00:22:20.271882 140149719906304 replay_runner.py:36] Average training steps per second: 372.05
I0902 00:22:20.393541 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -497.15
INFO:tensorflow:Starting iteration 23

Steps executed: 274 Episode length: 117 Return: -284.6331436604732606
INFO:tensorflow:Average training steps per second: 348.31
I0902 00:22:26.764499 140149719906304 replay_runner.py:36] Average training steps per second: 348.31
I0902 00:22:26.880148 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -159.93
INFO:tensorflow:Starting iteration 24
I0902 00:22:30.296827 140149719906304 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 328.03

Steps executed: 973 Episode length: 973 Return: -220.9366785015532606
I0902 00:22:36.284337 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -220.94
INFO:tensorflow:Starting iteration 25

Steps executed: 237 Episode length: 120 Return: -609.3801147193954306
INFO:tensorflow:Average training steps per second: 339.55
I0902 00:22:42.597258 140149719906304 replay_runner.py:36] Average training steps per second: 339.55
I0902 00:22:42.731159 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -358.49
INFO:tensorflow:Starting iteration 26

Steps executed: 97 Episode length: 97 Return: -83.5052924964320554306
INFO:tensorflow:Average training steps per second: 327.08

Steps executed: 1097 Episode length: 1000 Return: 101.372321218987476
I0902 00:22:51.598131 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: 8.93
INFO:tensorflow:Starting iteration 27

Steps executed: 212 Episode length: 74 Return: -214.73584734594988476
INFO:tensorflow:Average training steps per second: 329.47
I0902 00:22:57.996994 140149719906304 replay_runner.py:36] Average training steps per second: 329.47
I0902 00:22:58.118677 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.09
INFO:tensorflow:Starting iteration 28
I0902 00:23:01.448372 140149719906304 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 335.88

Steps executed: 228 Episode length: 228 Return: 267.44962287255527476
I0902 00:23:04.597266 140149719906304 run_experiment.py:428] Average undiscounted return per evaluation episode: 267.45
INFO:tensorflow:Starting iteration 29

Steps executed: 289 Episode length: 116 Return: -652.7137402659863476
INFO:tensorflow:Average training steps per second: 367.63
I0902 00:23:10.706434 140149719906304 replay_runner.py:36] Average training steps per second: 367.63

Done fixed training!Episode length: 116 Return: -652.7137402659863476