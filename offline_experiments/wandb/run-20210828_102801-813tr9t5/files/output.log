Loaded trained dqn in lunarlander
Training fixed agent 1, please be patient, may be a while...
I0828 10:28:08.232306 140251198892032 run_experiment.py:549] Creating TrainRunner ...
I0828 10:28:08.243791 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:28:08.244077 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:28:08.244214 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:28:08.244331 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:28:08.244490 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:28:08.244597 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:28:08.244840 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:28:08.244960 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:28:08.245072 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:28:08.245223 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:28:08.245361 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:28:08.245522 140251198892032 dqn_agent.py:283] 	 seed: 1630146488243719
I0828 10:28:08.248539 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:28:08.248761 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:28:08.248895 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:28:08.248994 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:28:08.249081 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:28:08.249167 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:28:08.249256 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:28:08.249341 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:28:08.249431 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:28:08.292557 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:08.657901 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:08.670814 140251198892032 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0828 10:28:08.680439 140251198892032 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0828 10:28:08.680681 140251198892032 dqn_agent.py:272] 	 gamma: 0.990000
I0828 10:28:08.680840 140251198892032 dqn_agent.py:273] 	 update_horizon: 1.000000
I0828 10:28:08.680940 140251198892032 dqn_agent.py:274] 	 min_replay_history: 500
I0828 10:28:08.681045 140251198892032 dqn_agent.py:275] 	 update_period: 4
I0828 10:28:08.681126 140251198892032 dqn_agent.py:276] 	 target_update_period: 300
I0828 10:28:08.681206 140251198892032 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0828 10:28:08.681845 140251198892032 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0828 10:28:08.682030 140251198892032 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0828 10:28:08.682181 140251198892032 dqn_agent.py:280] 	 optimizer: adam
I0828 10:28:08.682301 140251198892032 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0828 10:28:08.682412 140251198892032 dqn_agent.py:283] 	 seed: 1630146488680383
I0828 10:28:08.685373 140251198892032 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0828 10:28:08.685570 140251198892032 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0828 10:28:08.685729 140251198892032 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0828 10:28:08.685828 140251198892032 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0828 10:28:08.685966 140251198892032 circular_replay_buffer.py:159] 	 stack_size: 1
I0828 10:28:08.686053 140251198892032 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0828 10:28:08.686160 140251198892032 circular_replay_buffer.py:161] 	 batch_size: 128
I0828 10:28:08.686251 140251198892032 circular_replay_buffer.py:162] 	 update_horizon: 1
I0828 10:28:08.686364 140251198892032 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0828 10:28:08.714086 140251198892032 dqn_agent.py:70] Creating Adam optimizer with settings lr=2.000000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0828 10:28:08.773340 140251198892032 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0828 10:28:08.773598 140251198892032 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 162.39
I0828 10:28:14.931724 140251198892032 replay_runner.py:36] Average training steps per second: 162.39
Steps executed: 237 Episode length: 69 Return: -544.1960906929087
I0828 10:28:16.188446 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -491.99
INFO:tensorflow:Starting iteration 1

Steps executed: 218 Episode length: 67 Return: -450.57349789959757
INFO:tensorflow:Average training steps per second: 223.07
I0828 10:28:25.014047 140251198892032 replay_runner.py:36] Average training steps per second: 223.07
I0828 10:28:25.211628 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -523.16
INFO:tensorflow:Starting iteration 2

Steps executed: 254 Episode length: 84 Return: -128.45723472039825
INFO:tensorflow:Average training steps per second: 222.29
I0828 10:28:34.078862 140251198892032 replay_runner.py:36] Average training steps per second: 222.29
I0828 10:28:34.312403 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.62
INFO:tensorflow:Starting iteration 3

Steps executed: 215 Episode length: 75 Return: -132.43662365885208
INFO:tensorflow:Average training steps per second: 219.78
I0828 10:28:43.203759 140251198892032 replay_runner.py:36] Average training steps per second: 219.78
I0828 10:28:43.350198 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -109.31
INFO:tensorflow:Starting iteration 4

Steps executed: 271 Episode length: 80 Return: -850.83209147826028
INFO:tensorflow:Average training steps per second: 216.76
I0828 10:28:52.369103 140251198892032 replay_runner.py:36] Average training steps per second: 216.76
I0828 10:28:52.625383 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -645.48
INFO:tensorflow:Starting iteration 5

Steps executed: 216 Episode length: 139 Return: -191.33208461178887
INFO:tensorflow:Average training steps per second: 222.87
I0828 10:29:01.436868 140251198892032 replay_runner.py:36] Average training steps per second: 222.87
I0828 10:29:01.663159 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.10
INFO:tensorflow:Starting iteration 6

Steps executed: 263 Episode length: 166 Return: -479.86890272987237
INFO:tensorflow:Average training steps per second: 218.35
I0828 10:29:10.626605 140251198892032 replay_runner.py:36] Average training steps per second: 218.35
I0828 10:29:10.875067 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -468.16
INFO:tensorflow:Starting iteration 7

Steps executed: 242 Episode length: 80 Return: -665.385474515414337
INFO:tensorflow:Average training steps per second: 217.72
I0828 10:29:19.834505 140251198892032 replay_runner.py:36] Average training steps per second: 217.72
I0828 10:29:20.064498 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -753.71
INFO:tensorflow:Starting iteration 8

Steps executed: 247 Episode length: 64 Return: -480.311941312504837
INFO:tensorflow:Average training steps per second: 220.06
I0828 10:29:28.875660 140251198892032 replay_runner.py:36] Average training steps per second: 220.06
I0828 10:29:29.101605 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -488.72
INFO:tensorflow:Starting iteration 9

Steps executed: 251 Episode length: 58 Return: -463.599978168674557
INFO:tensorflow:Average training steps per second: 219.10
I0828 10:29:37.884848 140251198892032 replay_runner.py:36] Average training steps per second: 219.10
I0828 10:29:38.119904 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -501.16
INFO:tensorflow:Starting iteration 10

Steps executed: 216 Episode length: 82 Return: -821.082054025917157
INFO:tensorflow:Average training steps per second: 219.20
I0828 10:29:46.947050 140251198892032 replay_runner.py:36] Average training steps per second: 219.20
I0828 10:29:47.146426 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -558.44
INFO:tensorflow:Starting iteration 11

Steps executed: 185 Episode length: 60 Return: -544.602406186659857
INFO:tensorflow:Average training steps per second: 221.00

Steps executed: 253 Episode length: 68 Return: -525.470896485310557
I0828 10:29:56.380374 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -544.51
INFO:tensorflow:Starting iteration 12

Steps executed: 250 Episode length: 55 Return: -454.731070379211367
INFO:tensorflow:Average training steps per second: 217.77
I0828 10:30:05.285932 140251198892032 replay_runner.py:36] Average training steps per second: 217.77
I0828 10:30:05.513012 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -479.01
INFO:tensorflow:Starting iteration 13

Steps executed: 219 Episode length: 77 Return: -732.279817188148367
INFO:tensorflow:Average training steps per second: 220.19
I0828 10:30:14.409787 140251198892032 replay_runner.py:36] Average training steps per second: 220.19
I0828 10:30:14.616441 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -727.45
INFO:tensorflow:Starting iteration 14

Steps executed: 303 Episode length: 156 Return: -798.25910173380187
INFO:tensorflow:Average training steps per second: 234.53
I0828 10:30:22.967640 140251198892032 replay_runner.py:36] Average training steps per second: 234.53
I0828 10:30:23.325394 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -803.79
INFO:tensorflow:Starting iteration 15

Steps executed: 88 Episode length: 88 Return: -321.8166542325288387
INFO:tensorflow:Average training steps per second: 234.59
I0828 10:30:31.951735 140251198892032 replay_runner.py:36] Average training steps per second: 234.59

Steps executed: 215 Episode length: 60 Return: -564.930628489774187
INFO:tensorflow:Starting iteration 16

Steps executed: 236 Episode length: 69 Return: -638.379700816613387
INFO:tensorflow:Average training steps per second: 229.31
I0828 10:30:40.878758 140251198892032 replay_runner.py:36] Average training steps per second: 229.31
I0828 10:30:41.082292 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -505.41
INFO:tensorflow:Starting iteration 17

Steps executed: 200 Episode length: 68 Return: -567.398045351823887
INFO:tensorflow:Average training steps per second: 230.14
I0828 10:30:49.714193 140251198892032 replay_runner.py:36] Average training steps per second: 230.14
I0828 10:30:49.907131 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -510.83
INFO:tensorflow:Starting iteration 18
I0828 10:30:54.121126 140251198892032 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 230.96
I0828 10:30:58.451309 140251198892032 replay_runner.py:36] Average training steps per second: 230.96

Steps executed: 213 Episode length: 74 Return: -614.691693481498987
INFO:tensorflow:Starting iteration 19

Steps executed: 239 Episode length: 67 Return: -330.699488259488767
INFO:tensorflow:Average training steps per second: 229.40
I0828 10:31:07.157773 140251198892032 replay_runner.py:36] Average training steps per second: 229.40
I0828 10:31:07.379186 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -290.65
INFO:tensorflow:Starting iteration 20

Steps executed: 131 Episode length: 64 Return: -380.848199282435647
INFO:tensorflow:Average training steps per second: 221.70
I0828 10:31:16.096625 140251198892032 replay_runner.py:36] Average training steps per second: 221.70

Steps executed: 256 Episode length: 61 Return: -357.511932128156247
INFO:tensorflow:Starting iteration 21

Steps executed: 206 Episode length: 107 Return: -539.29851211501847
INFO:tensorflow:Average training steps per second: 214.94
I0828 10:31:25.293267 140251198892032 replay_runner.py:36] Average training steps per second: 214.94
I0828 10:31:25.483902 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -507.88
INFO:tensorflow:Starting iteration 22
I0828 10:31:29.880612 140251198892032 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 221.29
I0828 10:31:34.399928 140251198892032 replay_runner.py:36] Average training steps per second: 221.29

Steps executed: 264 Episode length: 79 Return: -468.591142069682577
INFO:tensorflow:Starting iteration 23

Steps executed: 286 Episode length: 90 Return: -94.5203951458732467
INFO:tensorflow:Average training steps per second: 214.58
I0828 10:31:43.591207 140251198892032 replay_runner.py:36] Average training steps per second: 214.58
I0828 10:31:43.785617 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -140.13
INFO:tensorflow:Starting iteration 24
I0828 10:31:48.113306 140251198892032 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 218.90

Steps executed: 362 Episode length: 261 Return: -902.95279685284327
I0828 10:31:53.125913 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -636.42
INFO:tensorflow:Starting iteration 25

Steps executed: 283 Episode length: 94 Return: -545.184899753387556
INFO:tensorflow:Average training steps per second: 219.85
I0828 10:32:02.013465 140251198892032 replay_runner.py:36] Average training steps per second: 219.85
I0828 10:32:02.340891 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -991.47
INFO:tensorflow:Starting iteration 26

Steps executed: 263 Episode length: 75 Return: -190.263048286583086
INFO:tensorflow:Average training steps per second: 218.02
I0828 10:32:11.175440 140251198892032 replay_runner.py:36] Average training steps per second: 218.02
I0828 10:32:11.354084 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.99
INFO:tensorflow:Starting iteration 27

Steps executed: 208 Episode length: 68 Return: -687.471148497553386
INFO:tensorflow:Average training steps per second: 220.89
I0828 10:32:20.253016 140251198892032 replay_runner.py:36] Average training steps per second: 220.89
I0828 10:32:20.443758 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -655.46
INFO:tensorflow:Starting iteration 28

Steps executed: 203 Episode length: 64 Return: -349.181313392590986
INFO:tensorflow:Average training steps per second: 221.79
I0828 10:32:29.317203 140251198892032 replay_runner.py:36] Average training steps per second: 221.79
I0828 10:32:29.523218 140251198892032 run_experiment.py:428] Average undiscounted return per evaluation episode: -400.60
INFO:tensorflow:Starting iteration 29

Steps executed: 427 Episode length: 253 Return: -2139.6103692586456
INFO:tensorflow:Average training steps per second: 229.95
I0828 10:32:38.206005 140251198892032 replay_runner.py:36] Average training steps per second: 229.95

Done fixed training!Episode length: 253 Return: -2139.6103692586456