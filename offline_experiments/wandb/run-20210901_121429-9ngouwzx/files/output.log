Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 12:14:36.421278 140315766171648 run_experiment.py:549] Creating TrainRunner ...
I0901 12:14:36.433800 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:14:36.434021 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:14:36.434197 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:14:36.434338 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:14:36.434434 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 12:14:36.434566 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:14:36.434703 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:14:36.434828 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:14:36.435280 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:14:36.435452 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 12:14:36.435544 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:14:36.435770 140315766171648 dqn_agent.py:283] 	 seed: 1630498476433746
I0901 12:14:36.439645 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:14:36.439962 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:14:36.440147 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:14:36.440246 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:14:36.440344 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:14:36.440460 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:14:36.440559 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:14:36.440854 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:14:36.440973 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:14:36.512805 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:14:37.242351 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:14:37.258201 140315766171648 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:14:37.268697 140315766171648 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:14:37.268976 140315766171648 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:14:37.269126 140315766171648 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:14:37.269460 140315766171648 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:14:37.269596 140315766171648 dqn_agent.py:275] 	 update_period: 4
I0901 12:14:37.269683 140315766171648 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:14:37.269754 140315766171648 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:14:37.269834 140315766171648 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:14:37.269984 140315766171648 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:14:37.270076 140315766171648 dqn_agent.py:280] 	 optimizer: adam
I0901 12:14:37.270166 140315766171648 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:14:37.270288 140315766171648 dqn_agent.py:283] 	 seed: 1630498477268636
I0901 12:14:37.273724 140315766171648 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:14:37.273932 140315766171648 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:14:37.274057 140315766171648 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:14:37.274181 140315766171648 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:14:37.274273 140315766171648 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:14:37.274351 140315766171648 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:14:37.274425 140315766171648 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:14:37.274507 140315766171648 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:14:37.274727 140315766171648 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:14:37.308024 140315766171648 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:14:37.330759 140315766171648 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:14:37.331824 140315766171648 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 165.02
I0901 12:14:43.392400 140315766171648 replay_runner.py:36] Average training steps per second: 165.02
Steps executed: 248 Episode length: 141 Return: -305.7618203466349
I0901 12:14:44.608251 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -373.18
INFO:tensorflow:Starting iteration 1

Steps executed: 289 Episode length: 101 Return: -386.8502543309875
INFO:tensorflow:Average training steps per second: 225.19
I0901 12:14:53.451225 140315766171648 replay_runner.py:36] Average training steps per second: 225.19
I0901 12:14:53.724821 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -325.67
INFO:tensorflow:Starting iteration 2

Steps executed: 284 Episode length: 284 Return: -87.62850726630532
INFO:tensorflow:Average training steps per second: 223.92
I0901 12:15:02.644080 140315766171648 replay_runner.py:36] Average training steps per second: 223.92
I0901 12:15:03.066257 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -87.63
INFO:tensorflow:Starting iteration 3
I0901 12:15:07.520103 140315766171648 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 222.42

Steps executed: 1000 Episode length: 1000 Return: -171.87680440145076
I0901 12:15:15.326442 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -171.88
INFO:tensorflow:Starting iteration 4
I0901 12:15:19.660500 140315766171648 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 233.01

Steps executed: 1000 Episode length: 1000 Return: -213.57130004584977
I0901 12:15:25.970226 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.57
INFO:tensorflow:Starting iteration 5
I0901 12:15:30.230083 140315766171648 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 236.66
I0901 12:15:34.456321 140315766171648 replay_runner.py:36] Average training steps per second: 236.66

Steps executed: 1000 Episode length: 1000 Return: -106.47474115609008
INFO:tensorflow:Starting iteration 6
I0901 12:15:40.522196 140315766171648 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 240.05
I0901 12:15:44.688553 140315766171648 replay_runner.py:36] Average training steps per second: 240.05

Steps executed: 833 Episode length: 833 Return: -413.0404015513898008
INFO:tensorflow:Starting iteration 7

Steps executed: 595 Episode length: 595 Return: -380.9619707330526008
INFO:tensorflow:Average training steps per second: 221.80
I0901 12:15:55.072080 140315766171648 replay_runner.py:36] Average training steps per second: 221.80
I0901 12:15:55.966198 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -380.96
INFO:tensorflow:Starting iteration 8
I0901 12:16:00.335913 140315766171648 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 217.50

Steps executed: 1000 Episode length: 1000 Return: -352.96811776739617
I0901 12:16:07.387850 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -352.97
INFO:tensorflow:Starting iteration 9

Steps executed: 339 Episode length: 339 Return: -191.4767589701937617
INFO:tensorflow:Average training steps per second: 212.94
I0901 12:16:16.440664 140315766171648 replay_runner.py:36] Average training steps per second: 212.94
I0901 12:16:16.898008 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.48
INFO:tensorflow:Starting iteration 10

Steps executed: 78 Episode length: 78 Return: -95.8083673628068837617
INFO:tensorflow:Average training steps per second: 207.83

Steps executed: 554 Episode length: 476 Return: -390.2067067058555617
I0901 12:16:27.065820 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -243.01
INFO:tensorflow:Starting iteration 11
I0901 12:16:31.489809 140315766171648 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 210.11

Steps executed: 267 Episode length: 267 Return: -192.5176933936157617
I0901 12:16:36.601608 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -192.52
INFO:tensorflow:Starting iteration 12

Steps executed: 223 Episode length: 223 Return: -223.9539756709837717
INFO:tensorflow:Average training steps per second: 210.34
I0901 12:16:45.762829 140315766171648 replay_runner.py:36] Average training steps per second: 210.34
I0901 12:16:46.008905 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -223.95
INFO:tensorflow:Starting iteration 13

Steps executed: 201 Episode length: 201 Return: -104.4472355271568617
INFO:tensorflow:Average training steps per second: 216.33
I0901 12:16:55.107679 140315766171648 replay_runner.py:36] Average training steps per second: 216.33
I0901 12:16:55.313075 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.45
INFO:tensorflow:Starting iteration 14

Steps executed: 276 Episode length: 151 Return: -295.9728488070171617
INFO:tensorflow:Average training steps per second: 218.05
I0901 12:17:04.334776 140315766171648 replay_runner.py:36] Average training steps per second: 218.05
I0901 12:17:04.576778 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -236.64
INFO:tensorflow:Starting iteration 15
I0901 12:17:08.909460 140315766171648 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 212.66

Steps executed: 1000 Episode length: 1000 Return: -116.25329287716568
I0901 12:17:15.702565 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -116.25
INFO:tensorflow:Starting iteration 16

Steps executed: 400 Episode length: 248 Return: -112.3244079605937768
INFO:tensorflow:Average training steps per second: 207.58
I0901 12:17:24.927837 140315766171648 replay_runner.py:36] Average training steps per second: 207.58
I0901 12:17:25.344191 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -169.55
INFO:tensorflow:Starting iteration 17
I0901 12:17:29.759777 140315766171648 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 220.35

Steps executed: 981 Episode length: 981 Return: -367.1875426265147668
I0901 12:17:36.514245 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -367.19
INFO:tensorflow:Starting iteration 18

Steps executed: 422 Episode length: 296 Return: -236.8581311239907768
INFO:tensorflow:Average training steps per second: 211.54
I0901 12:17:45.669807 140315766171648 replay_runner.py:36] Average training steps per second: 211.54
I0901 12:17:46.165252 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.30
INFO:tensorflow:Starting iteration 19

Steps executed: 759 Episode length: 581 Return: -86.45624876435025268
INFO:tensorflow:Average training steps per second: 209.67
I0901 12:17:55.223285 140315766171648 replay_runner.py:36] Average training steps per second: 209.67
I0901 12:17:56.680131 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.05
INFO:tensorflow:Starting iteration 20
I0901 12:18:01.041105 140315766171648 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 211.67

Steps executed: 640 Episode length: 640 Return: -498.6489884491025268
I0901 12:18:07.250792 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -498.65
INFO:tensorflow:Starting iteration 21
I0901 12:18:11.668929 140315766171648 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 211.32

Steps executed: 1000 Episode length: 1000 Return: -37.399573744820438
I0901 12:18:20.379544 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.40
INFO:tensorflow:Starting iteration 22
I0901 12:18:24.845643 140315766171648 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 209.53

Steps executed: 1000 Episode length: 1000 Return: -103.41779613911148
I0901 12:18:32.919858 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -103.42
INFO:tensorflow:Starting iteration 23

Steps executed: 322 Episode length: 141 Return: -545.6051113489395848
INFO:tensorflow:Average training steps per second: 229.80
I0901 12:18:41.654972 140315766171648 replay_runner.py:36] Average training steps per second: 229.80
I0901 12:18:41.910335 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -221.82
INFO:tensorflow:Starting iteration 24
I0901 12:18:46.144879 140315766171648 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 226.13

Steps executed: 426 Episode length: 426 Return: -63.84608414201986848
I0901 12:18:51.212515 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -63.85
INFO:tensorflow:Starting iteration 25

Steps executed: 243 Episode length: 243 Return: -83.52768059377534848
INFO:tensorflow:Average training steps per second: 240.87
I0901 12:18:59.648473 140315766171648 replay_runner.py:36] Average training steps per second: 240.87
I0901 12:18:59.946568 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -83.53
INFO:tensorflow:Starting iteration 26

Steps executed: 137 Episode length: 137 Return: -293.7453595754758848
INFO:tensorflow:Average training steps per second: 230.64
I0901 12:19:08.617443 140315766171648 replay_runner.py:36] Average training steps per second: 230.64

Steps executed: 284 Episode length: 147 Return: -273.1064725089291348
INFO:tensorflow:Starting iteration 27

Steps executed: 302 Episode length: 137 Return: -178.3718675718214448
INFO:tensorflow:Average training steps per second: 225.20
I0901 12:19:17.620443 140315766171648 replay_runner.py:36] Average training steps per second: 225.20
I0901 12:19:17.879500 140315766171648 run_experiment.py:428] Average undiscounted return per evaluation episode: -128.59
INFO:tensorflow:Starting iteration 28
I0901 12:19:22.271553 140315766171648 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 217.45
I0901 12:19:26.870731 140315766171648 replay_runner.py:36] Average training steps per second: 217.45

Steps executed: 231 Episode length: 100 Return: -477.5593806599083648
INFO:tensorflow:Starting iteration 29

Steps executed: 269 Episode length: 71 Return: -490.54431716261723648
INFO:tensorflow:Average training steps per second: 220.20
I0901 12:19:35.871422 140315766171648 replay_runner.py:36] Average training steps per second: 220.20

Done fixed training!Episode length: 71 Return: -490.54431716261723648