I0902 23:09:47.492337 140369919707136 run_experiment.py:549] Creating TrainRunner ...
WARNING:tensorflow:From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
W0902 23:09:47.492886 140369919707136 deprecation.py:345] From /home/joaoguilhermearujo/miniconda3/envs/rain/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
I0902 23:09:47.565078 140369919707136 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:09:47.566262 140369919707136 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:09:47.566386 140369919707136 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:09:47.566453 140369919707136 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:09:47.566514 140369919707136 dqn_agent.py:275] 	 update_period: 4
I0902 23:09:47.566568 140369919707136 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:09:47.566620 140369919707136 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:09:47.566671 140369919707136 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:09:47.566723 140369919707136 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:09:47.566779 140369919707136 dqn_agent.py:280] 	 optimizer: adam
I0902 23:09:47.566837 140369919707136 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:09:47.566956 140369919707136 dqn_agent.py:283] 	 seed: 1630624187565021
I0902 23:09:47.568685 140369919707136 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:09:47.568836 140369919707136 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:09:47.568917 140369919707136 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:09:47.568980 140369919707136 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:09:47.569036 140369919707136 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:09:47.569123 140369919707136 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:09:47.569229 140369919707136 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:09:47.569316 140369919707136 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:09:47.569393 140369919707136 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:09:53.383212 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
Loaded trained dqn in lunarlander
I0902 23:09:56.061951 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:09:56.113054 140369919707136 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:09:56.134497 140369919707136 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:09:56.134717 140369919707136 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:09:56.134853 140369919707136 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:09:56.134974 140369919707136 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:09:56.135139 140369919707136 dqn_agent.py:275] 	 update_period: 4
I0902 23:09:56.135267 140369919707136 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:09:56.135484 140369919707136 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:09:56.135613 140369919707136 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:09:56.135823 140369919707136 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:09:56.135947 140369919707136 dqn_agent.py:280] 	 optimizer: adam
I0902 23:09:56.136047 140369919707136 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:09:56.136144 140369919707136 dqn_agent.py:283] 	 seed: 1630624196134448
I0902 23:09:56.138744 140369919707136 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:09:56.138905 140369919707136 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:09:56.139068 140369919707136 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:09:56.139229 140369919707136 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:09:56.139361 140369919707136 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:09:56.139603 140369919707136 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:09:56.139718 140369919707136 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:09:56.139810 140369919707136 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:09:56.139894 140369919707136 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:09:57.187572 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:09:57.220717 140369919707136 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:09:57.221251 140369919707136 replay_runner.py:41] Starting iteration 0
Training fixed agent 6, please be patient, may be a while...
INFO:tensorflow:Average training steps per second: 152.87
I0902 23:10:03.763794 140369919707136 replay_runner.py:36] Average training steps per second: 152.87
I0902 23:10:04.612080 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -456.52
Steps executed: 223 Episode length: 129 Return: -323.54760232838265
INFO:tensorflow:Starting iteration 1
I0902 23:10:08.725000 140369919707136 replay_runner.py:41] Starting iteration 1
INFO:tensorflow:Average training steps per second: 205.58
I0902 23:10:13.590178 140369919707136 replay_runner.py:36] Average training steps per second: 205.58

Steps executed: 227 Episode length: 148 Return: -281.01556985836885
INFO:tensorflow:Starting iteration 2
I0902 23:10:17.992765 140369919707136 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 206.10
I0902 23:10:22.846537 140369919707136 replay_runner.py:36] Average training steps per second: 206.10

Steps executed: 288 Episode length: 120 Return: -346.12304659182645
INFO:tensorflow:Starting iteration 3
I0902 23:10:27.302288 140369919707136 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 209.66

Steps executed: 828 Episode length: 828 Return: -336.55654973992625
I0902 23:10:34.098706 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -336.56
INFO:tensorflow:Starting iteration 4
I0902 23:10:38.102913 140369919707136 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 213.27

Steps executed: 1000 Episode length: 1000 Return: -191.45644840483874
I0902 23:10:45.863511 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -191.46
INFO:tensorflow:Starting iteration 5
I0902 23:10:50.011178 140369919707136 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 220.46

Steps executed: 1000 Episode length: 1000 Return: -297.41766383398567
I0902 23:10:58.215285 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -297.42
INFO:tensorflow:Starting iteration 6
I0902 23:11:02.426258 140369919707136 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 218.12

Steps executed: 659 Episode length: 659 Return: -405.0136746322735567
I0902 23:11:08.132128 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -405.01
INFO:tensorflow:Starting iteration 7
I0902 23:11:12.440132 140369919707136 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 219.59
I0902 23:11:16.994395 140369919707136 replay_runner.py:36] Average training steps per second: 219.59

Steps executed: 314 Episode length: 314 Return: -536.8635294927199567
INFO:tensorflow:Starting iteration 8
I0902 23:11:21.558064 140369919707136 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 223.79

Steps executed: 825 Episode length: 825 Return: -525.7985739504187567
I0902 23:11:28.255426 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -525.80
INFO:tensorflow:Starting iteration 9
I0902 23:11:32.488824 140369919707136 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 224.79

Steps executed: 1000 Episode length: 1000 Return: -112.96128244189482
I0902 23:11:40.648116 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -112.96
INFO:tensorflow:Starting iteration 10
I0902 23:11:44.986672 140369919707136 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 222.99

Steps executed: 371 Episode length: 371 Return: -202.4522318281188482
I0902 23:11:50.015522 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.45
INFO:tensorflow:Starting iteration 11

Steps executed: 232 Episode length: 166 Return: -125.0969987819003882
INFO:tensorflow:Average training steps per second: 218.01
I0902 23:11:58.771450 140369919707136 replay_runner.py:36] Average training steps per second: 218.01
I0902 23:11:58.947033 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -122.09
INFO:tensorflow:Starting iteration 12
I0902 23:12:03.188829 140369919707136 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 222.74

Steps executed: 593 Episode length: 593 Return: -197.2883499271842782
I0902 23:12:08.964711 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -197.29
INFO:tensorflow:Starting iteration 13

Steps executed: 100 Episode length: 100 Return: -607.4539827911855782
INFO:tensorflow:Average training steps per second: 222.71
I0902 23:12:17.560801 140369919707136 replay_runner.py:36] Average training steps per second: 222.71

Steps executed: 243 Episode length: 143 Return: -457.0303656915307782
INFO:tensorflow:Starting iteration 14

Steps executed: 142 Episode length: 142 Return: -136.4899912020464782
INFO:tensorflow:Average training steps per second: 229.54
I0902 23:12:26.497230 140369919707136 replay_runner.py:36] Average training steps per second: 229.54

Steps executed: 792 Episode length: 650 Return: -292.2997182915349782
INFO:tensorflow:Starting iteration 15

Steps executed: 468 Episode length: 468 Return: -100.2435069006830282
INFO:tensorflow:Average training steps per second: 228.58
I0902 23:12:36.593966 140369919707136 replay_runner.py:36] Average training steps per second: 228.58
I0902 23:12:37.547852 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -100.24
INFO:tensorflow:Starting iteration 16

Steps executed: 204 Episode length: 56 Return: -124.25087542661073282
INFO:tensorflow:Average training steps per second: 239.53
I0902 23:12:46.098482 140369919707136 replay_runner.py:36] Average training steps per second: 239.53
I0902 23:12:46.218611 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -133.18
INFO:tensorflow:Starting iteration 17

Steps executed: 376 Episode length: 376 Return: -162.4810387003169282
INFO:tensorflow:Average training steps per second: 253.31
I0902 23:12:54.009404 140369919707136 replay_runner.py:36] Average training steps per second: 253.31
I0902 23:12:54.410128 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.48
INFO:tensorflow:Starting iteration 18

Steps executed: 493 Episode length: 300 Return: -298.2046671348624482
INFO:tensorflow:Average training steps per second: 242.32
I0902 23:13:02.478305 140369919707136 replay_runner.py:36] Average training steps per second: 242.32
I0902 23:13:03.013153 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -273.34
INFO:tensorflow:Starting iteration 19
I0902 23:13:07.194531 140369919707136 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 223.77

Steps executed: 670 Episode length: 670 Return: -104.5365541309597482
I0902 23:13:13.648515 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -104.54
INFO:tensorflow:Starting iteration 20

Steps executed: 319 Episode length: 319 Return: -272.2918956940044482
INFO:tensorflow:Average training steps per second: 226.56
I0902 23:13:22.476220 140369919707136 replay_runner.py:36] Average training steps per second: 226.56
I0902 23:13:22.897884 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -272.29
INFO:tensorflow:Starting iteration 21

Steps executed: 106 Episode length: 106 Return: 85.188768541643544482
INFO:tensorflow:Average training steps per second: 225.58

Steps executed: 1106 Episode length: 1000 Return: -40.565550327921622
I0902 23:13:34.900441 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: 22.31
INFO:tensorflow:Starting iteration 22
I0902 23:13:39.215926 140369919707136 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 226.78
I0902 23:13:43.626827 140369919707136 replay_runner.py:36] Average training steps per second: 226.78

Steps executed: 749 Episode length: 749 Return: -26.30866920368950422
INFO:tensorflow:Starting iteration 23
I0902 23:13:50.238633 140369919707136 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 225.45

Steps executed: 1000 Episode length: 1000 Return: -17.924454707375936
I0902 23:13:58.419967 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -17.92
INFO:tensorflow:Starting iteration 24

Steps executed: 307 Episode length: 144 Return: -127.8035579066592136
INFO:tensorflow:Average training steps per second: 225.05
I0902 23:14:07.321486 140369919707136 replay_runner.py:36] Average training steps per second: 225.05
I0902 23:14:07.630524 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -69.53
INFO:tensorflow:Starting iteration 25
I0902 23:14:12.009919 140369919707136 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 227.29

Steps executed: 1000 Episode length: 1000 Return: 65.2691511057480136
I0902 23:14:19.429819 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: 65.27
INFO:tensorflow:Starting iteration 26
I0902 23:14:23.714241 140369919707136 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 232.99
I0902 23:14:28.006778 140369919707136 replay_runner.py:36] Average training steps per second: 232.99

Steps executed: 225 Episode length: 225 Return: -6.308777612697156136
INFO:tensorflow:Starting iteration 27

Steps executed: 259 Episode length: 259 Return: -37.00077351084711136
INFO:tensorflow:Average training steps per second: 222.50
I0902 23:14:37.054064 140369919707136 replay_runner.py:36] Average training steps per second: 222.50
I0902 23:14:37.357345 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -37.00
INFO:tensorflow:Starting iteration 28
I0902 23:14:41.672416 140369919707136 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 222.02


Steps executed: 1181 Episode length: 1000 Return: -72.665066620192736
I0902 23:14:49.210248 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -47.18
INFO:tensorflow:Starting iteration 29
I0902 23:14:53.564054 140369919707136 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 230.81

Steps executed: 1000 Episode length: 1000 Return: 19.1417876389012566

Done fixed training! Episode length: 1000 Return: 19.1417876389012566