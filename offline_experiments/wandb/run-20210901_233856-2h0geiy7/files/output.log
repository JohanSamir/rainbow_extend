Loaded trained dqn in lunarlander
Training fixed agent 9, please be patient, may be a while...
I0901 23:39:02.918879 140413705484288 run_experiment.py:549] Creating TrainRunner ...
I0901 23:39:02.929761 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:39:02.929957 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:39:02.930040 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:39:02.930104 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:39:02.930192 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0901 23:39:02.930369 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:39:02.930469 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:39:02.930598 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:39:02.930675 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:39:02.930802 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0901 23:39:02.930922 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:39:02.931196 140413705484288 dqn_agent.py:283] 	 seed: 1630539542929708
I0901 23:39:02.934818 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:39:02.935060 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:39:02.935184 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:39:02.935271 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:39:02.935363 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:39:02.935441 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:39:02.935527 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:39:02.935671 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:39:02.935794 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:39:02.969607 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:03.350219 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:03.363547 140413705484288 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:39:03.372663 140413705484288 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:39:03.372966 140413705484288 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:39:03.373097 140413705484288 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:39:03.373212 140413705484288 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:39:03.373723 140413705484288 dqn_agent.py:275] 	 update_period: 4
I0901 23:39:03.373878 140413705484288 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:39:03.374027 140413705484288 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:39:03.374151 140413705484288 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:39:03.374240 140413705484288 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:39:03.374415 140413705484288 dqn_agent.py:280] 	 optimizer: adam
I0901 23:39:03.374525 140413705484288 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:39:03.374588 140413705484288 dqn_agent.py:283] 	 seed: 1630539543372586
I0901 23:39:03.377613 140413705484288 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:39:03.377832 140413705484288 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:39:03.377964 140413705484288 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:39:03.378050 140413705484288 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:39:03.378175 140413705484288 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:39:03.378254 140413705484288 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:39:03.378327 140413705484288 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:39:03.378457 140413705484288 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:39:03.378610 140413705484288 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:39:03.412389 140413705484288 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:39:03.483617 140413705484288 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:39:03.483965 140413705484288 replay_runner.py:41] Starting iteration 0
Steps executed: 210 Episode length: 81 Return: -725.2213048434567
INFO:tensorflow:Average training steps per second: 175.35
I0901 23:39:09.187558 140413705484288 replay_runner.py:36] Average training steps per second: 175.35
I0901 23:39:10.302860 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -616.82
INFO:tensorflow:Starting iteration 1

Steps executed: 207 Episode length: 80 Return: -802.3160512323075
INFO:tensorflow:Average training steps per second: 232.94
I0901 23:39:19.001559 140413705484288 replay_runner.py:36] Average training steps per second: 232.94
I0901 23:39:19.177389 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -639.88
INFO:tensorflow:Starting iteration 2

Steps executed: 234 Episode length: 69 Return: -645.0648028046915
INFO:tensorflow:Average training steps per second: 221.41
I0901 23:39:28.065582 140413705484288 replay_runner.py:36] Average training steps per second: 221.41
I0901 23:39:28.342648 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -725.85
INFO:tensorflow:Starting iteration 3
I0901 23:39:32.745384 140413705484288 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 219.05
I0901 23:39:37.311326 140413705484288 replay_runner.py:36] Average training steps per second: 219.05

Steps executed: 274 Episode length: 77 Return: -672.3468503455008
INFO:tensorflow:Starting iteration 4

Steps executed: 157 Episode length: 81 Return: -831.4130400380612
INFO:tensorflow:Average training steps per second: 223.43
I0901 23:39:46.416314 140413705484288 replay_runner.py:36] Average training steps per second: 223.43

Steps executed: 223 Episode length: 66 Return: -659.9349236092255
INFO:tensorflow:Starting iteration 5

Steps executed: 204 Episode length: 71 Return: -471.17816956545573
INFO:tensorflow:Average training steps per second: 224.40
I0901 23:39:55.420608 140413705484288 replay_runner.py:36] Average training steps per second: 224.40
I0901 23:39:55.592530 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -486.97
INFO:tensorflow:Starting iteration 6

Steps executed: 248 Episode length: 61 Return: -467.09032204132023
INFO:tensorflow:Average training steps per second: 217.76
I0901 23:40:04.440244 140413705484288 replay_runner.py:36] Average training steps per second: 217.76
I0901 23:40:04.672093 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -502.42
INFO:tensorflow:Starting iteration 7

Steps executed: 240 Episode length: 240 Return: -2001.532211298824
INFO:tensorflow:Average training steps per second: 228.02
I0901 23:40:13.416153 140413705484288 replay_runner.py:36] Average training steps per second: 228.02
I0901 23:40:13.721660 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -2001.53
INFO:tensorflow:Starting iteration 8

Steps executed: 171 Episode length: 104 Return: -387.4101511673986
INFO:tensorflow:Average training steps per second: 221.07
I0901 23:40:22.572489 140413705484288 replay_runner.py:36] Average training steps per second: 221.07

Steps executed: 242 Episode length: 71 Return: -670.06991230989266
INFO:tensorflow:Starting iteration 9

Steps executed: 246 Episode length: 246 Return: -1784.035689470227
INFO:tensorflow:Average training steps per second: 219.61
I0901 23:40:31.766731 140413705484288 replay_runner.py:36] Average training steps per second: 219.61
I0901 23:40:32.071146 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -1784.04
INFO:tensorflow:Starting iteration 10

Steps executed: 225 Episode length: 131 Return: -1018.2842084411184
INFO:tensorflow:Average training steps per second: 216.76
I0901 23:40:41.066247 140413705484288 replay_runner.py:36] Average training steps per second: 216.76
I0901 23:40:41.286810 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -804.99
INFO:tensorflow:Starting iteration 11

Steps executed: 256 Episode length: 109 Return: -617.46510750046475
INFO:tensorflow:Average training steps per second: 223.23
I0901 23:40:50.133475 140413705484288 replay_runner.py:36] Average training steps per second: 223.23
I0901 23:40:50.386250 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -877.86
INFO:tensorflow:Starting iteration 12
I0901 23:40:54.771389 140413705484288 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 231.97

Steps executed: 219 Episode length: 100 Return: -679.88618516813485
I0901 23:40:59.284304 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -694.02
INFO:tensorflow:Starting iteration 13

Steps executed: 251 Episode length: 137 Return: -926.87257611219525
INFO:tensorflow:Average training steps per second: 226.01
I0901 23:41:07.995468 140413705484288 replay_runner.py:36] Average training steps per second: 226.01
I0901 23:41:08.222681 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -830.30
INFO:tensorflow:Starting iteration 14

Steps executed: 233 Episode length: 102 Return: -781.06991223738355
INFO:tensorflow:Average training steps per second: 231.14
I0901 23:41:16.817440 140413705484288 replay_runner.py:36] Average training steps per second: 231.14
I0901 23:41:17.031318 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -716.31
INFO:tensorflow:Starting iteration 15

Steps executed: 231 Episode length: 141 Return: -692.60606591198775
INFO:tensorflow:Average training steps per second: 234.14
I0901 23:41:25.514895 140413705484288 replay_runner.py:36] Average training steps per second: 234.14
I0901 23:41:25.735509 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -613.00
INFO:tensorflow:Starting iteration 16

Steps executed: 271 Episode length: 83 Return: -525.406647273443455
INFO:tensorflow:Average training steps per second: 234.85
I0901 23:41:34.025615 140413705484288 replay_runner.py:36] Average training steps per second: 234.85
I0901 23:41:34.250754 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -575.23
INFO:tensorflow:Starting iteration 17

Steps executed: 230 Episode length: 151 Return: -915.08328215317425
INFO:tensorflow:Average training steps per second: 232.88
I0901 23:41:42.631424 140413705484288 replay_runner.py:36] Average training steps per second: 232.88
I0901 23:41:42.846265 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -752.65
INFO:tensorflow:Starting iteration 18

Steps executed: 231 Episode length: 156 Return: -833.88509732365715
INFO:tensorflow:Average training steps per second: 229.84
I0901 23:41:51.472525 140413705484288 replay_runner.py:36] Average training steps per second: 229.84
I0901 23:41:51.710043 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -633.27
INFO:tensorflow:Starting iteration 19

Steps executed: 204 Episode length: 102 Return: -502.83050725066555
INFO:tensorflow:Average training steps per second: 225.52
I0901 23:42:00.487910 140413705484288 replay_runner.py:36] Average training steps per second: 225.52
I0901 23:42:00.687880 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -517.03
INFO:tensorflow:Starting iteration 20
I0901 23:42:05.073935 140413705484288 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 229.18

Steps executed: 226 Episode length: 140 Return: -689.62872908107835
I0901 23:42:09.682160 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -641.26
INFO:tensorflow:Starting iteration 21

Steps executed: 280 Episode length: 135 Return: -1023.3429922334988
INFO:tensorflow:Average training steps per second: 228.07
I0901 23:42:18.421554 140413705484288 replay_runner.py:36] Average training steps per second: 228.07
I0901 23:42:18.710904 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -916.66
INFO:tensorflow:Starting iteration 22
I0901 23:42:23.116131 140413705484288 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 227.75

Steps executed: 436 Episode length: 253 Return: -2039.2752521793054
I0901 23:42:28.038578 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -1117.73
INFO:tensorflow:Starting iteration 23

Steps executed: 284 Episode length: 127 Return: -975.07770899381755
INFO:tensorflow:Average training steps per second: 229.56
I0901 23:42:36.685286 140413705484288 replay_runner.py:36] Average training steps per second: 229.56
I0901 23:42:36.979211 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -1092.97
INFO:tensorflow:Starting iteration 24

Steps executed: 276 Episode length: 77 Return: -561.984592071629845
INFO:tensorflow:Average training steps per second: 226.94
I0901 23:42:45.760165 140413705484288 replay_runner.py:36] Average training steps per second: 226.94
I0901 23:42:46.023428 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -636.68
INFO:tensorflow:Starting iteration 25

Steps executed: 88 Episode length: 88 Return: -662.0513018146527845
INFO:tensorflow:Average training steps per second: 225.24
I0901 23:42:54.831809 140413705484288 replay_runner.py:36] Average training steps per second: 225.24

Steps executed: 254 Episode length: 166 Return: -1231.7035906836625
INFO:tensorflow:Starting iteration 26

Steps executed: 219 Episode length: 146 Return: -1075.8811344211645
INFO:tensorflow:Average training steps per second: 225.41
I0901 23:43:03.958333 140413705484288 replay_runner.py:36] Average training steps per second: 225.41
I0901 23:43:04.188725 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -754.31
INFO:tensorflow:Starting iteration 27

Steps executed: 205 Episode length: 122 Return: -829.11161594627925
INFO:tensorflow:Average training steps per second: 227.97
I0901 23:43:12.928538 140413705484288 replay_runner.py:36] Average training steps per second: 227.97
I0901 23:43:13.145325 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -626.86
INFO:tensorflow:Starting iteration 28

Steps executed: 380 Episode length: 213 Return: -1571.8647472176078
INFO:tensorflow:Average training steps per second: 226.52
I0901 23:43:21.938766 140413705484288 replay_runner.py:36] Average training steps per second: 226.52
I0901 23:43:22.386787 140413705484288 run_experiment.py:428] Average undiscounted return per evaluation episode: -867.87
INFO:tensorflow:Starting iteration 29
I0901 23:43:26.801017 140413705484288 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 228.34

Steps executed: 245 Episode length: 115 Return: -643.32781509971688

Done fixed training!Episode length: 115 Return: -643.32781509971688