I0905 16:28:12.269268 139967707396096 run_experiment.py:549] Creating TrainRunner ...
I0905 16:28:12.277611 139967707396096 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:28:12.277771 139967707396096 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:28:12.277847 139967707396096 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:28:12.277938 139967707396096 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:28:12.277995 139967707396096 dqn_agent.py:275] 	 update_period: 4
I0905 16:28:12.278061 139967707396096 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:28:12.278114 139967707396096 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:28:12.278166 139967707396096 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:28:12.278227 139967707396096 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:28:12.278314 139967707396096 dqn_agent.py:280] 	 optimizer: adam
I0905 16:28:12.278376 139967707396096 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:28:12.278429 139967707396096 dqn_agent.py:283] 	 seed: 1630859292277567
I0905 16:28:12.280731 139967707396096 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:28:12.280861 139967707396096 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:28:12.280978 139967707396096 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:28:12.281047 139967707396096 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:28:12.281104 139967707396096 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:28:12.281190 139967707396096 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:28:12.281261 139967707396096 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:28:12.281319 139967707396096 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:28:12.281372 139967707396096 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 2, please be patient, may be a while...
I0905 16:28:13.921727 139967707396096 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:14.257451 139967707396096 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:14.280821 139967707396096 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0905 16:28:14.288729 139967707396096 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0905 16:28:14.288947 139967707396096 dqn_agent.py:272] 	 gamma: 0.990000
I0905 16:28:14.289060 139967707396096 dqn_agent.py:273] 	 update_horizon: 1.000000
I0905 16:28:14.289154 139967707396096 dqn_agent.py:274] 	 min_replay_history: 500
I0905 16:28:14.289246 139967707396096 dqn_agent.py:275] 	 update_period: 4
I0905 16:28:14.289331 139967707396096 dqn_agent.py:276] 	 target_update_period: 300
I0905 16:28:14.289450 139967707396096 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0905 16:28:14.289545 139967707396096 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0905 16:28:14.289633 139967707396096 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0905 16:28:14.289716 139967707396096 dqn_agent.py:280] 	 optimizer: adam
I0905 16:28:14.289812 139967707396096 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0905 16:28:14.289990 139967707396096 dqn_agent.py:283] 	 seed: 1630859294288679
I0905 16:28:14.292272 139967707396096 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0905 16:28:14.292461 139967707396096 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0905 16:28:14.292579 139967707396096 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0905 16:28:14.292685 139967707396096 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0905 16:28:14.292782 139967707396096 circular_replay_buffer.py:159] 	 stack_size: 1
I0905 16:28:14.292917 139967707396096 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0905 16:28:14.293031 139967707396096 circular_replay_buffer.py:161] 	 batch_size: 128
I0905 16:28:14.293139 139967707396096 circular_replay_buffer.py:162] 	 update_horizon: 1
I0905 16:28:14.293262 139967707396096 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0905 16:28:14.323092 139967707396096 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0905 16:28:14.342962 139967707396096 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0905 16:28:14.343228 139967707396096 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 212.34
I0905 16:28:19.052917 139967707396096 replay_runner.py:36] Average training steps per second: 212.34
Steps executed: 399 Episode length: 202 Return: -556.57037845776681
I0905 16:28:20.095824 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -329.85
INFO:tensorflow:Starting iteration 1

Steps executed: 243 Episode length: 140 Return: -385.60216185961383
INFO:tensorflow:Average training steps per second: 305.71
I0905 16:28:27.121341 139967707396096 replay_runner.py:36] Average training steps per second: 305.71
I0905 16:28:27.285065 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -416.96
INFO:tensorflow:Starting iteration 2

Steps executed: 279 Episode length: 173 Return: -337.14886594560473
INFO:tensorflow:Average training steps per second: 294.15
I0905 16:28:34.395594 139967707396096 replay_runner.py:36] Average training steps per second: 294.15
I0905 16:28:34.574955 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -310.99
INFO:tensorflow:Starting iteration 3

Steps executed: 299 Episode length: 162 Return: -378.14774930052334
INFO:tensorflow:Average training steps per second: 305.44
I0905 16:28:41.570144 139967707396096 replay_runner.py:36] Average training steps per second: 305.44
I0905 16:28:41.737424 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -251.72
INFO:tensorflow:Starting iteration 4

Steps executed: 272 Episode length: 129 Return: -169.45102362555795
INFO:tensorflow:Average training steps per second: 296.50
I0905 16:28:48.805296 139967707396096 replay_runner.py:36] Average training steps per second: 296.50
I0905 16:28:48.965379 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -217.96
INFO:tensorflow:Starting iteration 5
I0905 16:28:52.627574 139967707396096 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 311.66

Steps executed: 969 Episode length: 969 Return: -424.19599969547795
I0905 16:28:57.914715 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -424.20
INFO:tensorflow:Starting iteration 6

Steps executed: 291 Episode length: 291 Return: -206.13092335749997
INFO:tensorflow:Average training steps per second: 312.03
I0905 16:29:04.689367 139967707396096 replay_runner.py:36] Average training steps per second: 312.03
I0905 16:29:04.934608 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -206.13
INFO:tensorflow:Starting iteration 7
I0905 16:29:08.585408 139967707396096 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 294.13

Steps executed: 592 Episode length: 592 Return: -676.01695306420397
I0905 16:29:12.588857 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -676.02
INFO:tensorflow:Starting iteration 8
I0905 16:29:16.329329 139967707396096 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 262.80

Steps executed: 767 Episode length: 767 Return: -2841.5539687107897
I0905 16:29:21.462426 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -2841.55
INFO:tensorflow:Starting iteration 9

Steps executed: 74 Episode length: 74 Return: -80.50184864659002897
INFO:tensorflow:Average training steps per second: 247.73

Steps executed: 1074 Episode length: 1000 Return: -51.04244402403711
I0905 16:29:31.776656 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -65.77
INFO:tensorflow:Starting iteration 10
I0905 16:29:35.901618 139967707396096 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 233.58

Steps executed: 782 Episode length: 782 Return: -583.295647948138411
I0905 16:29:41.744902 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -583.30
INFO:tensorflow:Starting iteration 11
I0905 16:29:46.008884 139967707396096 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 237.00

Steps executed: 1000 Episode length: 1000 Return: -199.6845771647938
I0905 16:29:52.583159 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -199.68
INFO:tensorflow:Starting iteration 12
I0905 16:29:56.841793 139967707396096 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 231.82

Steps executed: 706 Episode length: 706 Return: -427.194160408113258
I0905 16:30:02.786683 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -427.19
INFO:tensorflow:Starting iteration 13

Steps executed: 218 Episode length: 218 Return: -242.619750984938438
INFO:tensorflow:Average training steps per second: 238.55
I0905 16:30:11.211710 139967707396096 replay_runner.py:36] Average training steps per second: 238.55
I0905 16:30:11.391114 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -242.62
INFO:tensorflow:Starting iteration 14

Steps executed: 282 Episode length: 282 Return: -57.4913412353367438
INFO:tensorflow:Average training steps per second: 229.00
I0905 16:30:19.998575 139967707396096 replay_runner.py:36] Average training steps per second: 229.00
I0905 16:30:20.277876 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.49
INFO:tensorflow:Starting iteration 15

Steps executed: 243 Episode length: 106 Return: -114.444683461453638
INFO:tensorflow:Average training steps per second: 236.58
I0905 16:30:28.752655 139967707396096 replay_runner.py:36] Average training steps per second: 236.58
I0905 16:30:28.949786 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.76
INFO:tensorflow:Starting iteration 16

Steps executed: 72 Episode length: 72 Return: -103.22213600936121638
INFO:tensorflow:Average training steps per second: 241.77

Steps executed: 990 Episode length: 918 Return: -354.301096294920638
I0905 16:30:39.528954 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -228.76
INFO:tensorflow:Starting iteration 17

Steps executed: 65 Episode length: 65 Return: -150.58264850294290638
INFO:tensorflow:Average training steps per second: 239.06

Steps executed: 1065 Episode length: 1000 Return: -81.35863734580573
I0905 16:30:51.133941 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -115.97
INFO:tensorflow:Starting iteration 18

Steps executed: 247 Episode length: 247 Return: -108.728972750302153
INFO:tensorflow:Average training steps per second: 236.91
I0905 16:30:59.639658 139967707396096 replay_runner.py:36] Average training steps per second: 236.91
I0905 16:30:59.856524 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -108.73
INFO:tensorflow:Starting iteration 19
I0905 16:31:04.076522 139967707396096 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 235.56
I0905 16:31:08.322223 139967707396096 replay_runner.py:36] Average training steps per second: 235.56

Steps executed: 304 Episode length: 304 Return: 9.890707222012693153
INFO:tensorflow:Starting iteration 20

Steps executed: 474 Episode length: 352 Return: -262.167780468581453
INFO:tensorflow:Average training steps per second: 235.94
I0905 16:31:17.153253 139967707396096 replay_runner.py:36] Average training steps per second: 235.94
I0905 16:31:17.700435 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -359.94
INFO:tensorflow:Starting iteration 21

Steps executed: 277 Episode length: 90 Return: -311.6485878739599753
INFO:tensorflow:Average training steps per second: 240.09
I0905 16:31:26.105047 139967707396096 replay_runner.py:36] Average training steps per second: 240.09
I0905 16:31:26.296611 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -332.78
INFO:tensorflow:Starting iteration 22
I0905 16:31:30.571573 139967707396096 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 236.92

Steps executed: 243 Episode length: 117 Return: -165.634921288536253
I0905 16:31:35.000696 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.90
INFO:tensorflow:Starting iteration 23

Steps executed: 206 Episode length: 206 Return: -189.500687645137563
INFO:tensorflow:Average training steps per second: 244.60
I0905 16:31:43.381698 139967707396096 replay_runner.py:36] Average training steps per second: 244.60
I0905 16:31:43.559675 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -189.50
INFO:tensorflow:Starting iteration 24

Steps executed: 220 Episode length: 52 Return: -166.1129652538720363
INFO:tensorflow:Average training steps per second: 259.59
I0905 16:31:51.571942 139967707396096 replay_runner.py:36] Average training steps per second: 259.59
I0905 16:31:51.697857 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -324.30
INFO:tensorflow:Starting iteration 25

Steps executed: 391 Episode length: 200 Return: -183.723267110185653
INFO:tensorflow:Average training steps per second: 243.78
I0905 16:31:59.865749 139967707396096 replay_runner.py:36] Average training steps per second: 243.78
I0905 16:32:00.170665 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -164.29
INFO:tensorflow:Starting iteration 26

Steps executed: 218 Episode length: 159 Return: -612.429497672126753
INFO:tensorflow:Average training steps per second: 196.21
I0905 16:32:09.602471 139967707396096 replay_runner.py:36] Average training steps per second: 196.21
I0905 16:32:09.816497 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -552.81
INFO:tensorflow:Starting iteration 27

Steps executed: 257 Episode length: 153 Return: -247.672903831188533
INFO:tensorflow:Average training steps per second: 187.87
I0905 16:32:19.598788 139967707396096 replay_runner.py:36] Average training steps per second: 187.87
I0905 16:32:19.857505 139967707396096 run_experiment.py:428] Average undiscounted return per evaluation episode: -475.85
INFO:tensorflow:Starting iteration 28

Steps executed: 194 Episode length: 50 Return: -415.1449168832249433
INFO:tensorflow:Average training steps per second: 185.80
I0905 16:32:30.261950 139967707396096 replay_runner.py:36] Average training steps per second: 185.80

Steps executed: 328 Episode length: 134 Return: -135.616849403837483
INFO:tensorflow:Starting iteration 29

Steps executed: 265 Episode length: 78 Return: -190.4641005828787333
INFO:tensorflow:Average training steps per second: 159.69
I0905 16:32:42.067792 139967707396096 replay_runner.py:36] Average training steps per second: 159.69

Done fixed training!Episode length: 78 Return: -190.4641005828787333