I0902 23:30:00.730796 140369919707136 run_experiment.py:549] Creating TrainRunner ...
I0902 23:30:00.745279 140369919707136 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:30:00.745639 140369919707136 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:30:00.745890 140369919707136 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:30:00.746007 140369919707136 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:30:00.746139 140369919707136 dqn_agent.py:275] 	 update_period: 4
I0902 23:30:00.746426 140369919707136 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:30:00.746629 140369919707136 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:30:00.746760 140369919707136 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:30:00.746971 140369919707136 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:30:00.747104 140369919707136 dqn_agent.py:280] 	 optimizer: adam
I0902 23:30:00.747174 140369919707136 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:30:00.747343 140369919707136 dqn_agent.py:283] 	 seed: 1630625400745189
I0902 23:30:00.750962 140369919707136 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:30:00.751098 140369919707136 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:30:00.751185 140369919707136 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:30:00.751344 140369919707136 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:30:00.751523 140369919707136 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:30:00.751631 140369919707136 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:30:00.751706 140369919707136 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:30:00.751785 140369919707136 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:30:00.751860 140369919707136 circular_replay_buffer.py:163] 	 gamma: 0.990000
Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0902 23:30:02.660797 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:03.071621 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:03.089694 140369919707136 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 23:30:03.098037 140369919707136 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 23:30:03.098397 140369919707136 dqn_agent.py:272] 	 gamma: 0.990000
I0902 23:30:03.098609 140369919707136 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 23:30:03.098737 140369919707136 dqn_agent.py:274] 	 min_replay_history: 500
I0902 23:30:03.099057 140369919707136 dqn_agent.py:275] 	 update_period: 4
I0902 23:30:03.099294 140369919707136 dqn_agent.py:276] 	 target_update_period: 300
I0902 23:30:03.099582 140369919707136 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 23:30:03.099713 140369919707136 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 23:30:03.099863 140369919707136 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 23:30:03.099985 140369919707136 dqn_agent.py:280] 	 optimizer: adam
I0902 23:30:03.100181 140369919707136 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 23:30:03.100304 140369919707136 dqn_agent.py:283] 	 seed: 1630625403097970
I0902 23:30:03.103231 140369919707136 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 23:30:03.103426 140369919707136 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 23:30:03.103592 140369919707136 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 23:30:03.103727 140369919707136 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 23:30:03.103840 140369919707136 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 23:30:03.104037 140369919707136 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 23:30:03.104160 140369919707136 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 23:30:03.104270 140369919707136 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 23:30:03.104420 140369919707136 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 23:30:03.138915 140369919707136 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 23:30:03.161492 140369919707136 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 23:30:03.161982 140369919707136 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 163.56
I0902 23:30:09.276429 140369919707136 replay_runner.py:36] Average training steps per second: 163.56
Steps executed: 239 Episode length: 103 Return: -236.35815139004546
I0902 23:30:10.579641 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -286.06
INFO:tensorflow:Starting iteration 1

Steps executed: 320 Episode length: 206 Return: -572.67689711363214
INFO:tensorflow:Average training steps per second: 228.70
I0902 23:30:19.270682 140369919707136 replay_runner.py:36] Average training steps per second: 228.70
I0902 23:30:19.586589 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -376.72
INFO:tensorflow:Starting iteration 2
I0902 23:30:23.941594 140369919707136 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 222.84

Steps executed: 356 Episode length: 203 Return: -241.17985227854444
I0902 23:30:28.769869 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -222.22
INFO:tensorflow:Starting iteration 3

Steps executed: 251 Episode length: 111 Return: -155.56115092022245
INFO:tensorflow:Average training steps per second: 229.48
I0902 23:30:37.388907 140369919707136 replay_runner.py:36] Average training steps per second: 229.48
I0902 23:30:37.644155 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -105.54
INFO:tensorflow:Starting iteration 4

Steps executed: 303 Episode length: 140 Return: -102.08877152830192
INFO:tensorflow:Average training steps per second: 232.65
I0902 23:30:46.169808 140369919707136 replay_runner.py:36] Average training steps per second: 232.65
I0902 23:30:46.455125 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -93.53
INFO:tensorflow:Starting iteration 5
I0902 23:30:50.783471 140369919707136 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 228.49

Steps executed: 1000 Episode length: 1000 Return: -269.83159023614985
I0902 23:30:58.430820 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.83
INFO:tensorflow:Starting iteration 6
I0902 23:31:02.820722 140369919707136 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 225.54

Steps executed: 1000 Episode length: 1000 Return: -245.49646755103612
I0902 23:31:09.638058 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -245.50
INFO:tensorflow:Starting iteration 7
I0902 23:31:13.900072 140369919707136 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 229.33
I0902 23:31:18.261018 140369919707136 replay_runner.py:36] Average training steps per second: 229.33

Steps executed: 1000 Episode length: 1000 Return: -243.25546821650988
INFO:tensorflow:Starting iteration 8
I0902 23:31:25.179899 140369919707136 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 237.51

Steps executed: 1000 Episode length: 1000 Return: -421.51638540899097
I0902 23:31:32.051044 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -421.52
INFO:tensorflow:Starting iteration 9
I0902 23:31:36.438212 140369919707136 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 238.74
I0902 23:31:40.627388 140369919707136 replay_runner.py:36] Average training steps per second: 238.74

Steps executed: 216 Episode length: 216 Return: -240.8107173685342097
INFO:tensorflow:Starting iteration 10
I0902 23:31:45.067448 140369919707136 replay_runner.py:41] Starting iteration 10
INFO:tensorflow:Average training steps per second: 224.26

Steps executed: 1000 Episode length: 1000 Return: -269.28298255430057
I0902 23:31:53.766249 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -269.28
INFO:tensorflow:Starting iteration 11
I0902 23:31:58.119731 140369919707136 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 227.97

Steps executed: 1000 Episode length: 1000 Return: -213.72961208315456
I0902 23:32:05.185269 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -213.73
INFO:tensorflow:Starting iteration 12
I0902 23:32:09.440723 140369919707136 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 221.95

Steps executed: 1000 Episode length: 1000 Return: -99.113104486889946
I0902 23:32:16.122481 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.11
INFO:tensorflow:Starting iteration 13
I0902 23:32:20.438187 140369919707136 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 222.32

Steps executed: 1000 Episode length: 1000 Return: -60.936227812193496
I0902 23:32:27.893180 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -60.94
INFO:tensorflow:Starting iteration 14
I0902 23:32:32.337890 140369919707136 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 226.51

Steps executed: 1000 Episode length: 1000 Return: -167.25982807429648
I0902 23:32:40.184282 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -167.26
INFO:tensorflow:Starting iteration 15
I0902 23:32:44.575212 140369919707136 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 225.98
I0902 23:32:49.000976 140369919707136 replay_runner.py:36] Average training steps per second: 225.98

Steps executed: 1000 Episode length: 1000 Return: -40.719374821477798
INFO:tensorflow:Starting iteration 16
I0902 23:32:57.257589 140369919707136 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 219.31

Steps executed: 1000 Episode length: 1000 Return: -39.423475769048515
I0902 23:33:06.235351 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -39.42
INFO:tensorflow:Starting iteration 17
I0902 23:33:10.666423 140369919707136 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 227.32

Steps executed: 1000 Episode length: 1000 Return: -49.838271891900824
I0902 23:33:19.008472 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -49.84
INFO:tensorflow:Starting iteration 18

Steps executed: 332 Episode length: 332 Return: -251.8372877360346824
INFO:tensorflow:Average training steps per second: 230.36
I0902 23:33:27.684291 140369919707136 replay_runner.py:36] Average training steps per second: 230.36
I0902 23:33:28.182313 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -251.84
INFO:tensorflow:Starting iteration 19
I0902 23:33:32.243682 140369919707136 replay_runner.py:41] Starting iteration 19
INFO:tensorflow:Average training steps per second: 219.22

Steps executed: 523 Episode length: 523 Return: -23.44914644827986224
I0902 23:33:37.919657 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -23.45
INFO:tensorflow:Starting iteration 20
I0902 23:33:42.229436 140369919707136 replay_runner.py:41] Starting iteration 20
INFO:tensorflow:Average training steps per second: 242.04

Steps executed: 1000 Episode length: 1000 Return: -39.719904762536824
I0902 23:33:49.109673 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -39.72
INFO:tensorflow:Starting iteration 21

Steps executed: 239 Episode length: 239 Return: -85.12977181408965824
INFO:tensorflow:Average training steps per second: 232.81
I0902 23:33:57.738151 140369919707136 replay_runner.py:36] Average training steps per second: 232.81
I0902 23:33:57.989804 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.13
INFO:tensorflow:Starting iteration 22
I0902 23:34:02.349006 140369919707136 replay_runner.py:41] Starting iteration 22
INFO:tensorflow:Average training steps per second: 227.16

Steps executed: 1000 Episode length: 1000 Return: -158.75774705434972
I0902 23:34:10.024409 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -158.76
INFO:tensorflow:Starting iteration 23
I0902 23:34:14.289101 140369919707136 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 223.46

Steps executed: 708 Episode length: 708 Return: 162.63534083791853972
I0902 23:34:20.787080 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: 162.64
INFO:tensorflow:Starting iteration 24

Steps executed: 212 Episode length: 212 Return: -85.56758754697366972
INFO:tensorflow:Average training steps per second: 227.36
I0902 23:34:29.399025 140369919707136 replay_runner.py:36] Average training steps per second: 227.36
I0902 23:34:29.611278 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -85.57
INFO:tensorflow:Starting iteration 25
I0902 23:34:33.767813 140369919707136 replay_runner.py:41] Starting iteration 25
INFO:tensorflow:Average training steps per second: 238.09

Steps executed: 1000 Episode length: 1000 Return: -80.620817680624782
I0902 23:34:40.957860 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -80.62
INFO:tensorflow:Starting iteration 26

Steps executed: 114 Episode length: 114 Return: -141.1864224094623582
INFO:tensorflow:Average training steps per second: 227.95

Steps executed: 1114 Episode length: 1000 Return: -40.135857043560222
I0902 23:34:53.116722 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.66
INFO:tensorflow:Starting iteration 27

Steps executed: 335 Episode length: 335 Return: -107.0145481717201222
INFO:tensorflow:Average training steps per second: 224.85
I0902 23:35:01.947103 140369919707136 replay_runner.py:36] Average training steps per second: 224.85
I0902 23:35:02.430254 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -107.01
INFO:tensorflow:Starting iteration 28

Steps executed: 172 Episode length: 172 Return: -80.46561160472422222
INFO:tensorflow:Average training steps per second: 232.95

Steps executed: 1172 Episode length: 1000 Return: -35.056602645272352
I0902 23:35:15.792019 140369919707136 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.76
INFO:tensorflow:Starting iteration 29
I0902 23:35:20.037340 140369919707136 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 219.04
I0902 23:35:24.603182 140369919707136 replay_runner.py:36] Average training steps per second: 219.04


Done fixed training!Episode length: 571 Return: 127.28951097607643352