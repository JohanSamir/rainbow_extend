Loaded trained dqn in lunarlander
Training fixed agent 6, please be patient, may be a while...
I0902 00:15:20.107462 139825600018432 run_experiment.py:549] Creating TrainRunner ...
I0902 00:15:20.118355 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:15:20.118552 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:15:20.118637 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:15:20.118700 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:15:20.118756 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0902 00:15:20.118846 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:15:20.118960 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:15:20.119039 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:15:20.119152 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:15:20.119313 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:15:20.119448 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:15:20.119579 139825600018432 dqn_agent.py:283] 	 seed: 1630541720118305
I0902 00:15:20.123415 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:15:20.123625 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:15:20.123802 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:15:20.123952 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:15:20.124042 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:15:20.124119 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:15:20.124227 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:15:20.124396 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:15:20.124514 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:15:20.163125 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:20.529654 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:20.543850 139825600018432 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0902 00:15:20.553795 139825600018432 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0902 00:15:20.554086 139825600018432 dqn_agent.py:272] 	 gamma: 0.990000
I0902 00:15:20.554214 139825600018432 dqn_agent.py:273] 	 update_horizon: 1.000000
I0902 00:15:20.554336 139825600018432 dqn_agent.py:274] 	 min_replay_history: 500
I0902 00:15:20.554694 139825600018432 dqn_agent.py:275] 	 update_period: 4
I0902 00:15:20.554957 139825600018432 dqn_agent.py:276] 	 target_update_period: 300
I0902 00:15:20.555160 139825600018432 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0902 00:15:20.555319 139825600018432 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0902 00:15:20.555427 139825600018432 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0902 00:15:20.555547 139825600018432 dqn_agent.py:280] 	 optimizer: adam
I0902 00:15:20.555779 139825600018432 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0902 00:15:20.555946 139825600018432 dqn_agent.py:283] 	 seed: 1630541720553720
I0902 00:15:20.559079 139825600018432 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0902 00:15:20.559211 139825600018432 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0902 00:15:20.559318 139825600018432 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0902 00:15:20.559391 139825600018432 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0902 00:15:20.559449 139825600018432 circular_replay_buffer.py:159] 	 stack_size: 1
I0902 00:15:20.559504 139825600018432 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0902 00:15:20.559558 139825600018432 circular_replay_buffer.py:161] 	 batch_size: 128
I0902 00:15:20.559626 139825600018432 circular_replay_buffer.py:162] 	 update_horizon: 1
I0902 00:15:20.559786 139825600018432 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0902 00:15:20.590656 139825600018432 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0902 00:15:20.653997 139825600018432 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0902 00:15:20.654280 139825600018432 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 170.60
I0902 00:15:26.516256 139825600018432 replay_runner.py:36] Average training steps per second: 170.60
Steps executed: 285 Episode length: 135 Return: -328.5840346205244
I0902 00:15:27.806682 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.63
INFO:tensorflow:Starting iteration 1

Steps executed: 306 Episode length: 153 Return: -321.04235227456786
INFO:tensorflow:Average training steps per second: 221.59
I0902 00:15:36.689599 139825600018432 replay_runner.py:36] Average training steps per second: 221.59
I0902 00:15:36.997101 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -437.04
INFO:tensorflow:Starting iteration 2
I0902 00:15:41.257385 139825600018432 replay_runner.py:41] Starting iteration 2
INFO:tensorflow:Average training steps per second: 225.12

Steps executed: 228 Episode length: 228 Return: -274.52459515525426
I0902 00:15:45.981279 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -274.52
INFO:tensorflow:Starting iteration 3

Steps executed: 242 Episode length: 104 Return: -462.99665560307284
INFO:tensorflow:Average training steps per second: 224.95
I0902 00:15:54.718094 139825600018432 replay_runner.py:36] Average training steps per second: 224.95
I0902 00:15:54.944039 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -342.02
INFO:tensorflow:Starting iteration 4
I0902 00:15:59.224066 139825600018432 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 228.13

Steps executed: 1000 Episode length: 1000 Return: -57.78520843974522
I0902 00:16:06.137761 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -57.79
INFO:tensorflow:Starting iteration 5
I0902 00:16:10.465406 139825600018432 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 222.47
I0902 00:16:14.960889 139825600018432 replay_runner.py:36] Average training steps per second: 222.47

Steps executed: 1000 Episode length: 1000 Return: -87.08448333827874
INFO:tensorflow:Starting iteration 6
I0902 00:16:22.471834 139825600018432 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 221.43

Steps executed: 1000 Episode length: 1000 Return: -39.801002989998345
I0902 00:16:30.566096 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -39.80
INFO:tensorflow:Starting iteration 7
I0902 00:16:34.829471 139825600018432 replay_runner.py:41] Starting iteration 7
INFO:tensorflow:Average training steps per second: 223.08

Steps executed: 541 Episode length: 541 Return: -195.6256885145251445
I0902 00:16:40.353236 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -195.63
INFO:tensorflow:Starting iteration 8

Steps executed: 286 Episode length: 286 Return: -635.7514005196175445
INFO:tensorflow:Average training steps per second: 234.97
I0902 00:16:48.737398 139825600018432 replay_runner.py:36] Average training steps per second: 234.97
I0902 00:16:49.118184 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -635.75
INFO:tensorflow:Starting iteration 9
I0902 00:16:53.310383 139825600018432 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 244.96

Steps executed: 666 Episode length: 666 Return: -261.3366075814626645
I0902 00:16:58.341646 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.34
INFO:tensorflow:Starting iteration 10

Steps executed: 619 Episode length: 619 Return: -309.2512910574575645
INFO:tensorflow:Average training steps per second: 251.98
I0902 00:17:06.447406 139825600018432 replay_runner.py:36] Average training steps per second: 251.98
I0902 00:17:07.600766 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -309.25
INFO:tensorflow:Starting iteration 11
I0902 00:17:11.719953 139825600018432 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 256.21

Steps executed: 1000 Episode length: 1000 Return: -162.43392107891345
I0902 00:17:18.280261 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -162.43
INFO:tensorflow:Starting iteration 12
I0902 00:17:22.433977 139825600018432 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 259.75

Steps executed: 372 Episode length: 206 Return: -123.8998497032657645
I0902 00:17:26.644437 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.92
INFO:tensorflow:Starting iteration 13

Steps executed: 342 Episode length: 342 Return: -216.5251142579625745
INFO:tensorflow:Average training steps per second: 261.41
I0902 00:17:34.624724 139825600018432 replay_runner.py:36] Average training steps per second: 261.41
I0902 00:17:35.025596 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -216.53
INFO:tensorflow:Starting iteration 14
I0902 00:17:39.082324 139825600018432 replay_runner.py:41] Starting iteration 14
INFO:tensorflow:Average training steps per second: 255.26

Steps executed: 1000 Episode length: 1000 Return: -99.871734931691155
I0902 00:17:45.592897 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -99.87
INFO:tensorflow:Starting iteration 15

Steps executed: 333 Episode length: 333 Return: -232.2291903305513255
INFO:tensorflow:Average training steps per second: 271.48
I0902 00:17:53.246522 139825600018432 replay_runner.py:36] Average training steps per second: 271.48
I0902 00:17:53.604570 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -232.23
INFO:tensorflow:Starting iteration 16
I0902 00:17:57.293688 139825600018432 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 293.54

Steps executed: 911 Episode length: 911 Return: -491.2564941784055555
I0902 00:18:02.589850 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -491.26
INFO:tensorflow:Starting iteration 17
I0902 00:18:06.181779 139825600018432 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 300.72

Steps executed: 1000 Episode length: 1000 Return: -183.42877012198738
I0902 00:18:11.421591 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -183.43
INFO:tensorflow:Starting iteration 18
I0902 00:18:15.052889 139825600018432 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 334.66

Steps executed: 1000 Episode length: 1000 Return: -79.167849337559058
I0902 00:18:21.018551 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -79.17
INFO:tensorflow:Starting iteration 19

Steps executed: 200 Episode length: 200 Return: -28.96343684459114358
INFO:tensorflow:Average training steps per second: 290.14
I0902 00:18:27.837124 139825600018432 replay_runner.py:36] Average training steps per second: 290.14
I0902 00:18:27.990698 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -28.96
INFO:tensorflow:Starting iteration 20

Steps executed: 214 Episode length: 99 Return: -134.43907551646367358
INFO:tensorflow:Average training steps per second: 307.60
I0902 00:18:34.547364 139825600018432 replay_runner.py:36] Average training steps per second: 307.60
I0902 00:18:34.690036 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.71
INFO:tensorflow:Starting iteration 21

Steps executed: 271 Episode length: 271 Return: -23.14846937846117358
INFO:tensorflow:Average training steps per second: 303.68
I0902 00:18:41.329604 139825600018432 replay_runner.py:36] Average training steps per second: 303.68
I0902 00:18:41.530145 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -23.15
INFO:tensorflow:Starting iteration 22

Steps executed: 275 Episode length: 275 Return: -177.0231580990096358
INFO:tensorflow:Average training steps per second: 305.29
I0902 00:18:47.951244 139825600018432 replay_runner.py:36] Average training steps per second: 305.29
I0902 00:18:48.186232 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -177.02
INFO:tensorflow:Starting iteration 23
I0902 00:18:51.311902 139825600018432 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 313.23

Steps executed: 304 Episode length: 132 Return: -316.7647242104334358
I0902 00:18:54.725016 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.46
INFO:tensorflow:Starting iteration 24

Steps executed: 586 Episode length: 413 Return: -589.1426665845344358
INFO:tensorflow:Average training steps per second: 324.25
I0902 00:19:00.980702 139825600018432 replay_runner.py:36] Average training steps per second: 324.25
I0902 00:19:01.651948 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -457.11
INFO:tensorflow:Starting iteration 25

Steps executed: 361 Episode length: 248 Return: -773.8227418369764458
INFO:tensorflow:Average training steps per second: 313.85
I0902 00:19:07.958326 139825600018432 replay_runner.py:36] Average training steps per second: 313.85
I0902 00:19:08.265209 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -588.45
INFO:tensorflow:Starting iteration 26
I0902 00:19:11.384492 139825600018432 replay_runner.py:41] Starting iteration 26
INFO:tensorflow:Average training steps per second: 323.12

Steps executed: 369 Episode length: 369 Return: -494.0691699321431458
I0902 00:19:14.924452 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -494.07
INFO:tensorflow:Starting iteration 27
I0902 00:19:17.984243 139825600018432 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 336.92
I0902 00:19:20.952556 139825600018432 replay_runner.py:36] Average training steps per second: 336.92

Steps executed: 1000 Episode length: 1000 Return: -155.85870644639976
INFO:tensorflow:Starting iteration 28
I0902 00:19:25.483412 139825600018432 replay_runner.py:41] Starting iteration 28
INFO:tensorflow:Average training steps per second: 333.24

Steps executed: 617 Episode length: 617 Return: -261.2823930495297976
I0902 00:19:29.059914 139825600018432 run_experiment.py:428] Average undiscounted return per evaluation episode: -261.28
INFO:tensorflow:Starting iteration 29

Steps executed: 233 Episode length: 233 Return: -47.75508208337139976
INFO:tensorflow:Average training steps per second: 329.65
I0902 00:19:35.423026 139825600018432 replay_runner.py:36] Average training steps per second: 329.65

Done fixed training!Episode length: 233 Return: -47.75508208337139976