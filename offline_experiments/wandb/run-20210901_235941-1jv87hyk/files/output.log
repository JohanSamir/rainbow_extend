Loaded trained dqn in lunarlander
Training fixed agent 8, please be patient, may be a while...
I0901 23:59:48.024030 140252174653440 run_experiment.py:549] Creating TrainRunner ...
I0901 23:59:48.051407 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:59:48.051648 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:59:48.051813 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:59:48.051995 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:59:48.052131 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0901 23:59:48.052302 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:59:48.052464 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:59:48.052614 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:59:48.052756 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:59:48.052907 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0901 23:59:48.053038 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:59:48.053319 140252174653440 dqn_agent.py:283] 	 seed: 1630540788051338
I0901 23:59:48.057006 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:59:48.057772 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:59:48.058207 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:59:48.058683 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:59:48.058805 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:59:48.059323 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:59:48.059440 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:59:48.059947 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:59:48.060467 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:59:48.110446 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:59:48.793889 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:59:48.806987 140252174653440 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 23:59:48.814259 140252174653440 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 23:59:48.814422 140252174653440 dqn_agent.py:272] 	 gamma: 0.990000
I0901 23:59:48.814523 140252174653440 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 23:59:48.814594 140252174653440 dqn_agent.py:274] 	 min_replay_history: 500
I0901 23:59:48.814853 140252174653440 dqn_agent.py:275] 	 update_period: 4
I0901 23:59:48.815181 140252174653440 dqn_agent.py:276] 	 target_update_period: 300
I0901 23:59:48.815307 140252174653440 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 23:59:48.815562 140252174653440 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 23:59:48.815677 140252174653440 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 23:59:48.815760 140252174653440 dqn_agent.py:280] 	 optimizer: adam
I0901 23:59:48.815847 140252174653440 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 23:59:48.815953 140252174653440 dqn_agent.py:283] 	 seed: 1630540788814217
I0901 23:59:48.818612 140252174653440 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 23:59:48.818778 140252174653440 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 23:59:48.818949 140252174653440 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 23:59:48.819184 140252174653440 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 23:59:48.819285 140252174653440 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 23:59:48.819390 140252174653440 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 23:59:48.819561 140252174653440 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 23:59:48.819678 140252174653440 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 23:59:48.819786 140252174653440 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 23:59:48.845681 140252174653440 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 23:59:48.866299 140252174653440 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 23:59:48.866548 140252174653440 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 172.74
I0901 23:59:54.655902 140252174653440 replay_runner.py:36] Average training steps per second: 172.74
Steps executed: 203 Episode length: 101 Return: -495.4401862333465
I0901 23:59:55.951568 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -395.67
INFO:tensorflow:Starting iteration 1

Steps executed: 262 Episode length: 112 Return: -275.0880822480159
INFO:tensorflow:Average training steps per second: 230.48
I0902 00:00:04.531872 140252174653440 replay_runner.py:36] Average training steps per second: 230.48
I0902 00:00:04.743424 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -396.51
INFO:tensorflow:Starting iteration 2

Steps executed: 316 Episode length: 316 Return: -535.0665630500835
INFO:tensorflow:Average training steps per second: 235.54
I0902 00:00:13.224587 140252174653440 replay_runner.py:36] Average training steps per second: 235.54
I0902 00:00:13.673459 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -535.07
INFO:tensorflow:Starting iteration 3

Steps executed: 726 Episode length: 618 Return: -640.92841849634215
INFO:tensorflow:Average training steps per second: 227.11
I0902 00:00:22.362054 140252174653440 replay_runner.py:36] Average training steps per second: 227.11
I0902 00:00:23.645547 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -499.19
INFO:tensorflow:Starting iteration 4
I0902 00:00:27.956156 140252174653440 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 223.45

Steps executed: 1000 Episode length: 1000 Return: -139.7579317294265
I0902 00:00:35.620549 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.76
INFO:tensorflow:Starting iteration 5
I0902 00:00:39.876842 140252174653440 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 219.73

Steps executed: 625 Episode length: 625 Return: -512.678876014766265
I0902 00:00:45.992439 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -512.68
INFO:tensorflow:Starting iteration 6
I0902 00:00:50.317151 140252174653440 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 221.68

Steps executed: 1000 Episode length: 1000 Return: -410.44447315207213
I0902 00:00:58.279350 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -410.44
INFO:tensorflow:Starting iteration 7

Steps executed: 548 Episode length: 548 Return: -291.6605805029315713
INFO:tensorflow:Average training steps per second: 223.46
I0902 00:01:06.978863 140252174653440 replay_runner.py:36] Average training steps per second: 223.46
I0902 00:01:07.997700 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -291.66
INFO:tensorflow:Starting iteration 8
I0902 00:01:12.525690 140252174653440 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 226.96

Steps executed: 1000 Episode length: 1000 Return: -90.149444779075763
I0902 00:01:20.021198 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -90.15
INFO:tensorflow:Starting iteration 9
I0902 00:01:24.287056 140252174653440 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 223.62

Steps executed: 1000 Episode length: 1000 Return: -72.622142039595453
I0902 00:01:32.266597 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -72.62
INFO:tensorflow:Starting iteration 10

Steps executed: 458 Episode length: 458 Return: -149.1266712514137753
INFO:tensorflow:Average training steps per second: 225.35
I0902 00:01:41.097708 140252174653440 replay_runner.py:36] Average training steps per second: 225.35
I0902 00:01:41.687970 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.13
INFO:tensorflow:Starting iteration 11

Steps executed: 522 Episode length: 522 Return: -114.3989776141008653
INFO:tensorflow:Average training steps per second: 232.30
I0902 00:01:50.259877 140252174653440 replay_runner.py:36] Average training steps per second: 232.30
I0902 00:01:51.304240 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.40
INFO:tensorflow:Starting iteration 12
I0902 00:01:55.570750 140252174653440 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 228.90

Steps executed: 973 Episode length: 973 Return: -283.8129571554856653
I0902 00:02:02.566691 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -283.81
INFO:tensorflow:Starting iteration 13
I0902 00:02:06.872645 140252174653440 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 224.21

Steps executed: 1000 Episode length: 1000 Return: -152.47722859766293
I0902 00:02:15.697809 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -152.48
INFO:tensorflow:Starting iteration 14


Steps executed: 275 Episode length: 85 Return: -193.50866156795095293
INFO:tensorflow:Average training steps per second: 235.84
I0902 00:02:24.299757 140252174653440 replay_runner.py:36] Average training steps per second: 235.84
I0902 00:02:24.562363 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -184.31
INFO:tensorflow:Starting iteration 15

Steps executed: 245 Episode length: 126 Return: -98.90625652644013693
INFO:tensorflow:Average training steps per second: 227.99
I0902 00:02:33.426543 140252174653440 replay_runner.py:36] Average training steps per second: 227.99
I0902 00:02:33.639997 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -114.83
INFO:tensorflow:Starting iteration 16
I0902 00:02:37.854359 140252174653440 replay_runner.py:41] Starting iteration 16
INFO:tensorflow:Average training steps per second: 229.30

Steps executed: 676 Episode length: 550 Return: -533.7444406262982693
I0902 00:02:43.171029 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -330.04
INFO:tensorflow:Starting iteration 17

Steps executed: 220 Episode length: 220 Return: -118.0165575735035993
INFO:tensorflow:Average training steps per second: 228.52
I0902 00:02:51.784476 140252174653440 replay_runner.py:36] Average training steps per second: 228.52
I0902 00:02:51.978359 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -118.02
INFO:tensorflow:Starting iteration 18
I0902 00:02:56.275888 140252174653440 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 226.80

Steps executed: 1000 Episode length: 1000 Return: -139.53242491632233
I0902 00:03:03.299377 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -139.53
INFO:tensorflow:Starting iteration 19

Steps executed: 154 Episode length: 154 Return: -462.1695447081476733
INFO:tensorflow:Average training steps per second: 233.39
I0902 00:03:11.893038 140252174653440 replay_runner.py:36] Average training steps per second: 233.39

Steps executed: 373 Episode length: 219 Return: -440.1094144683692733
INFO:tensorflow:Starting iteration 20

Steps executed: 237 Episode length: 186 Return: -120.1051421802891933
INFO:tensorflow:Average training steps per second: 231.82
I0902 00:03:21.135183 140252174653440 replay_runner.py:36] Average training steps per second: 231.82
I0902 00:03:21.364133 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -126.02
INFO:tensorflow:Starting iteration 21

Steps executed: 57 Episode length: 57 Return: -143.327437211792391933
INFO:tensorflow:Average training steps per second: 224.60
I0902 00:03:30.212177 140252174653440 replay_runner.py:36] Average training steps per second: 224.60

Steps executed: 315 Episode length: 120 Return: -140.8178662686825933
INFO:tensorflow:Starting iteration 22

Steps executed: 323 Episode length: 130 Return: -127.3860585143370133
INFO:tensorflow:Average training steps per second: 222.31
I0902 00:03:39.384613 140252174653440 replay_runner.py:36] Average training steps per second: 222.31
I0902 00:03:39.659389 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -124.88
INFO:tensorflow:Starting iteration 23
I0902 00:03:44.052410 140252174653440 replay_runner.py:41] Starting iteration 23
INFO:tensorflow:Average training steps per second: 222.79

Steps executed: 446 Episode length: 265 Return: -172.5721271874449533
I0902 00:03:48.988996 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -161.15
INFO:tensorflow:Starting iteration 24

Steps executed: 291 Episode length: 152 Return: -112.9705763820881133
INFO:tensorflow:Average training steps per second: 226.94
I0902 00:03:57.790442 140252174653440 replay_runner.py:36] Average training steps per second: 226.94
I0902 00:03:58.035519 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -76.72
INFO:tensorflow:Starting iteration 25

Steps executed: 266 Episode length: 142 Return: -151.6740064470485533
INFO:tensorflow:Average training steps per second: 222.76
I0902 00:04:06.813500 140252174653440 replay_runner.py:36] Average training steps per second: 222.76
I0902 00:04:07.043192 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -157.86
INFO:tensorflow:Starting iteration 26

Steps executed: 226 Episode length: 168 Return: -144.5096576180378533
INFO:tensorflow:Average training steps per second: 224.66
I0902 00:04:15.804840 140252174653440 replay_runner.py:36] Average training steps per second: 224.66
I0902 00:04:16.010864 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -135.55
INFO:tensorflow:Starting iteration 27
I0902 00:04:20.327557 140252174653440 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 223.49

Steps executed: 264 Episode length: 70 Return: -161.59881844233317533
I0902 00:04:25.034149 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -187.22
INFO:tensorflow:Starting iteration 28

Steps executed: 254 Episode length: 127 Return: -686.5401584581164533
INFO:tensorflow:Average training steps per second: 224.38
I0902 00:04:33.872117 140252174653440 replay_runner.py:36] Average training steps per second: 224.38
I0902 00:04:34.105938 140252174653440 run_experiment.py:428] Average undiscounted return per evaluation episode: -621.33
INFO:tensorflow:Starting iteration 29
I0902 00:04:38.419252 140252174653440 replay_runner.py:41] Starting iteration 29
INFO:tensorflow:Average training steps per second: 233.57
I0902 00:04:42.700985 140252174653440 replay_runner.py:36] Average training steps per second: 233.57


Done fixed training!Episode length: 93 Return: -459.78634210654957533