Loaded trained dqn in lunarlander
Training fixed agent 10, please be patient, may be a while...
I0901 12:14:33.228926 140460307478528 run_experiment.py:549] Creating TrainRunner ...
I0901 12:14:33.242186 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:14:33.242468 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:14:33.242609 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:14:33.242728 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:14:33.242838 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 12:14:33.242984 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:14:33.243161 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:14:33.243276 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:14:33.243402 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:14:33.243527 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 12:14:33.243662 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:14:33.243776 140460307478528 dqn_agent.py:283] 	 seed: 1630498473242094
I0901 12:14:33.246796 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:14:33.246988 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:14:33.247229 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:14:33.247409 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:14:33.247560 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:14:33.247674 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:14:33.247806 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:14:33.247922 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:14:33.248221 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:14:33.311187 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:14:33.689793 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:14:33.706838 140460307478528 run_experiment.py:269] Reloaded checkpoint and will start from iteration 30
I0901 12:14:33.743505 140460307478528 dqn_agent.py:271] Creating JaxDQNAgentNew agent with the following parameters:
I0901 12:14:33.743743 140460307478528 dqn_agent.py:272] 	 gamma: 0.990000
I0901 12:14:33.743884 140460307478528 dqn_agent.py:273] 	 update_horizon: 1.000000
I0901 12:14:33.743983 140460307478528 dqn_agent.py:274] 	 min_replay_history: 500
I0901 12:14:33.744070 140460307478528 dqn_agent.py:275] 	 update_period: 4
I0901 12:14:33.744215 140460307478528 dqn_agent.py:276] 	 target_update_period: 300
I0901 12:14:33.744494 140460307478528 dqn_agent.py:277] 	 epsilon_train: 0.010000
I0901 12:14:33.744635 140460307478528 dqn_agent.py:278] 	 epsilon_eval: 0.001000
I0901 12:14:33.744754 140460307478528 dqn_agent.py:279] 	 epsilon_decay_period: 250000
I0901 12:14:33.744892 140460307478528 dqn_agent.py:280] 	 optimizer: adam
I0901 12:14:33.745061 140460307478528 dqn_agent.py:282] 	 max_tf_checkpoints_to_keep: 4
I0901 12:14:33.745176 140460307478528 dqn_agent.py:283] 	 seed: 1630498473743451
I0901 12:14:33.748111 140460307478528 circular_replay_buffer.py:155] Creating a OutOfGraphPrioritizedReplayBuffer replay memory with the following parameters:
I0901 12:14:33.748369 140460307478528 circular_replay_buffer.py:156] 	 observation_shape: (8, 1)
I0901 12:14:33.748526 140460307478528 circular_replay_buffer.py:157] 	 observation_dtype: <class 'jax._src.numpy.lax_numpy.float64'>
I0901 12:14:33.748680 140460307478528 circular_replay_buffer.py:158] 	 terminal_dtype: <class 'numpy.uint8'>
I0901 12:14:33.748790 140460307478528 circular_replay_buffer.py:159] 	 stack_size: 1
I0901 12:14:33.748895 140460307478528 circular_replay_buffer.py:160] 	 replay_capacity: 50000
I0901 12:14:33.749031 140460307478528 circular_replay_buffer.py:161] 	 batch_size: 128
I0901 12:14:33.749176 140460307478528 circular_replay_buffer.py:162] 	 update_horizon: 1
I0901 12:14:33.749433 140460307478528 circular_replay_buffer.py:163] 	 gamma: 0.990000
I0901 12:14:33.785693 140460307478528 dqn_agent.py:70] Creating Adam optimizer with settings lr=0.001000, beta1=0.900000, beta2=0.999000, eps=0.000313
I0901 12:14:34.071035 140460307478528 run_experiment.py:516] Beginning training...
INFO:tensorflow:Starting iteration 0
I0901 12:14:34.071408 140460307478528 replay_runner.py:41] Starting iteration 0
INFO:tensorflow:Average training steps per second: 163.58
I0901 12:14:40.185259 140460307478528 replay_runner.py:36] Average training steps per second: 163.58
Steps executed: 282 Episode length: 126 Return: -434.31531356514944
I0901 12:14:41.477892 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -368.51
INFO:tensorflow:Starting iteration 1

Steps executed: 298 Episode length: 161 Return: -370.74954316010906
INFO:tensorflow:Average training steps per second: 226.53
I0901 12:14:50.313211 140460307478528 replay_runner.py:36] Average training steps per second: 226.53
I0901 12:14:50.585475 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -272.54
INFO:tensorflow:Starting iteration 2

Steps executed: 308 Episode length: 190 Return: -366.67425155400496
INFO:tensorflow:Average training steps per second: 222.76
I0901 12:14:59.392270 140460307478528 replay_runner.py:36] Average training steps per second: 222.76
I0901 12:14:59.705600 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -327.96
INFO:tensorflow:Starting iteration 3
I0901 12:15:04.096429 140460307478528 replay_runner.py:41] Starting iteration 3
INFO:tensorflow:Average training steps per second: 222.07

Steps executed: 1000 Episode length: 1000 Return: -148.8690208144741
I0901 12:15:11.450909 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -148.87
INFO:tensorflow:Starting iteration 4
I0901 12:15:15.782615 140460307478528 replay_runner.py:41] Starting iteration 4
INFO:tensorflow:Average training steps per second: 225.35

Steps executed: 619 Episode length: 619 Return: -172.717971725180441
I0901 12:15:21.948022 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -172.72
INFO:tensorflow:Starting iteration 5
I0901 12:15:26.278312 140460307478528 replay_runner.py:41] Starting iteration 5
INFO:tensorflow:Average training steps per second: 224.20

Steps executed: 1000 Episode length: 1000 Return: -149.20663341244543
I0901 12:15:34.093660 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -149.21
INFO:tensorflow:Starting iteration 6
I0901 12:15:38.195745 140460307478528 replay_runner.py:41] Starting iteration 6
INFO:tensorflow:Average training steps per second: 233.56

Steps executed: 1000 Episode length: 1000 Return: -97.757023165800183
I0901 12:15:45.890936 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.76
INFO:tensorflow:Starting iteration 7

Steps executed: 544 Episode length: 544 Return: -363.8745343807333483
INFO:tensorflow:Average training steps per second: 232.59
I0901 12:15:54.062791 140460307478528 replay_runner.py:36] Average training steps per second: 232.59
I0901 12:15:54.985261 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -363.87
INFO:tensorflow:Starting iteration 8
I0901 12:15:59.336380 140460307478528 replay_runner.py:41] Starting iteration 8
INFO:tensorflow:Average training steps per second: 219.34

Steps executed: 713 Episode length: 713 Return: -439.8194037264346483
I0901 12:16:05.453761 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -439.82
INFO:tensorflow:Starting iteration 9
I0901 12:16:09.781683 140460307478528 replay_runner.py:41] Starting iteration 9
INFO:tensorflow:Average training steps per second: 215.03

Steps executed: 1000 Episode length: 1000 Return: -175.03656509028953
I0901 12:16:17.439837 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -175.04
INFO:tensorflow:Starting iteration 10

Steps executed: 337 Episode length: 337 Return: -408.3107896920913653
INFO:tensorflow:Average training steps per second: 215.42
I0901 12:16:26.503338 140460307478528 replay_runner.py:36] Average training steps per second: 215.42
I0901 12:16:26.951669 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -408.31
INFO:tensorflow:Starting iteration 11
I0901 12:16:31.389439 140460307478528 replay_runner.py:41] Starting iteration 11
INFO:tensorflow:Average training steps per second: 215.11

Steps executed: 1000 Episode length: 1000 Return: -414.81421781610073
I0901 12:16:38.153989 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -414.81
INFO:tensorflow:Starting iteration 12
I0901 12:16:42.572206 140460307478528 replay_runner.py:41] Starting iteration 12
INFO:tensorflow:Average training steps per second: 217.49

Steps executed: 571 Episode length: 571 Return: -380.7187217410708073
I0901 12:16:48.497122 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -380.72
INFO:tensorflow:Starting iteration 13
I0901 12:16:52.864171 140460307478528 replay_runner.py:41] Starting iteration 13
INFO:tensorflow:Average training steps per second: 220.00

Steps executed: 538 Episode length: 538 Return: -202.8309247817748073
I0901 12:16:58.413387 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -202.83
INFO:tensorflow:Starting iteration 14

Steps executed: 159 Episode length: 159 Return: -134.9368866210017073
INFO:tensorflow:Average training steps per second: 225.50
I0901 12:17:07.163316 140460307478528 replay_runner.py:36] Average training steps per second: 225.50

Steps executed: 352 Episode length: 193 Return: 76.985581817621047073
INFO:tensorflow:Starting iteration 15
I0901 12:17:12.012165 140460307478528 replay_runner.py:41] Starting iteration 15
INFO:tensorflow:Average training steps per second: 221.01
I0901 12:17:16.537670 140460307478528 replay_runner.py:36] Average training steps per second: 221.01

Steps executed: 1000 Episode length: 1000 Return: -107.75742789780373
INFO:tensorflow:Starting iteration 16

Steps executed: 299 Episode length: 299 Return: -97.36977365430320373
INFO:tensorflow:Average training steps per second: 222.79
I0901 12:17:28.282875 140460307478528 replay_runner.py:36] Average training steps per second: 222.79
I0901 12:17:28.656796 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -97.37
INFO:tensorflow:Starting iteration 17
I0901 12:17:33.174274 140460307478528 replay_runner.py:41] Starting iteration 17
INFO:tensorflow:Average training steps per second: 223.09

Steps executed: 370 Episode length: 370 Return: -423.1700374817062373
I0901 12:17:38.353763 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -423.17
INFO:tensorflow:Starting iteration 18
I0901 12:17:42.855810 140460307478528 replay_runner.py:41] Starting iteration 18
INFO:tensorflow:Average training steps per second: 223.88

Steps executed: 321 Episode length: 321 Return: -293.7453208298045373
I0901 12:17:47.824536 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -293.75
INFO:tensorflow:Starting iteration 19

Steps executed: 230 Episode length: 90 Return: -306.90563306308642373
INFO:tensorflow:Average training steps per second: 212.97
I0901 12:17:56.814089 140460307478528 replay_runner.py:36] Average training steps per second: 212.97
I0901 12:17:57.007924 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -361.51
INFO:tensorflow:Starting iteration 20

Steps executed: 206 Episode length: 137 Return: -468.3145393174987373
INFO:tensorflow:Average training steps per second: 214.62
I0901 12:18:05.978954 140460307478528 replay_runner.py:36] Average training steps per second: 214.62
I0901 12:18:06.160323 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -254.19
INFO:tensorflow:Starting iteration 21
I0901 12:18:10.572597 140460307478528 replay_runner.py:41] Starting iteration 21
INFO:tensorflow:Average training steps per second: 217.78

Steps executed: 287 Episode length: 151 Return: -369.3694687899972373
I0901 12:18:15.480204 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -586.44
INFO:tensorflow:Starting iteration 22

Steps executed: 249 Episode length: 116 Return: -704.1538577596419773
INFO:tensorflow:Average training steps per second: 219.17
I0901 12:18:24.472368 140460307478528 replay_runner.py:36] Average training steps per second: 219.17
I0901 12:18:24.712620 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -504.51
INFO:tensorflow:Starting iteration 23

Steps executed: 467 Episode length: 467 Return: 254.88002306208742773
INFO:tensorflow:Average training steps per second: 219.30
I0901 12:18:33.745993 140460307478528 replay_runner.py:36] Average training steps per second: 219.30
I0901 12:18:34.499579 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: 254.88
INFO:tensorflow:Starting iteration 24
I0901 12:18:38.882882 140460307478528 replay_runner.py:41] Starting iteration 24
INFO:tensorflow:Average training steps per second: 245.90
I0901 12:18:42.950237 140460307478528 replay_runner.py:36] Average training steps per second: 245.90

Steps executed: 427 Episode length: 427 Return: 176.41718437582986773
INFO:tensorflow:Starting iteration 25

Steps executed: 226 Episode length: 226 Return: -277.3327792136933673
INFO:tensorflow:Average training steps per second: 235.64
I0901 12:18:51.969878 140460307478528 replay_runner.py:36] Average training steps per second: 235.64
I0901 12:18:52.213572 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -277.33
INFO:tensorflow:Starting iteration 26

Steps executed: 478 Episode length: 355 Return: -25.99842481467810373
INFO:tensorflow:Average training steps per second: 248.36
I0901 12:19:00.349409 140460307478528 replay_runner.py:36] Average training steps per second: 248.36
I0901 12:19:00.997344 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -96.75
INFO:tensorflow:Starting iteration 27
I0901 12:19:05.461917 140460307478528 replay_runner.py:41] Starting iteration 27
INFO:tensorflow:Average training steps per second: 241.91

Steps executed: 869 Episode length: 869 Return: -522.0074258008176373
I0901 12:19:12.521486 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -522.01
INFO:tensorflow:Starting iteration 28

Steps executed: 120 Episode length: 120 Return: -665.8295018113686373
INFO:tensorflow:Average training steps per second: 233.37

Steps executed: 1120 Episode length: 1000 Return: -37.804922707568025
I0901 12:19:25.363738 140460307478528 run_experiment.py:428] Average undiscounted return per evaluation episode: -351.82
INFO:tensorflow:Starting iteration 29

Steps executed: 305 Episode length: 305 Return: -358.3583483813596325
INFO:tensorflow:Average training steps per second: 226.53
I0901 12:19:33.997739 140460307478528 replay_runner.py:36] Average training steps per second: 226.53

Done fixed training!Episode length: 305 Return: -358.3583483813596325